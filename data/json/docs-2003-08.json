{"83506":{"abstract":"The unprecedented explosion in the volume of readily accessible data in <br\/>recent years, although highly desirable, comes at a heavy price - it is now <br\/>considerably more difficult to locate the answer to a specific question, or to <br\/>find patterns and correlations that are central to a phenomenon. The PI's <br\/>propose to study general-purpose clustering as a solution to the problem of <br\/>locating relevant information and organizing it in an intelligible way. <br\/><br\/>The proposal falls into two tracks. The first track is to develop measures <br\/>and criteria that accurately re the quality of a clustering. The PI's have <br\/>initiated work in this direction, and plan to build a theory of clustering criteria firmly grounded in the intuition of practitioners. <br\/><br\/>The second track is the design of efficient algorithms to find near-optimal <br\/>clustering under the right measures. The PI's propose to develop algorithms <br\/>based on the so-called \"spectral methods\" and other techniques. They plan <br\/>to make them efficient by the use of random (non-uniform) sampling. The <br\/>PI's also plan to implement some of the algorithms and empirically evaluate <br\/>them. <br\/><br\/>The PI's propose to ensure that any positive impact from their research <br\/>is maximized by (a) widely disseminating the results via conferences and <br\/>also by inviting other researchers to discuss the ideas, (b) by making the <br\/>preliminary implementations of clustering algorithms available.","title":"ITR Collaborative Research: Models. Algorithms, and Analyses for Clustering Data","awardID":"0312339","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["565103"],"PO":["562984"]},"82428":{"abstract":"This project examines several statistical inference tasks for data best described as a collection of heterogeneous linked objects. For each task, models are proposed, algorithms for both learning and making inferences using the models are developed and extensive empirical evaluation is performed. New approaches to mining linked data are needed because traditional statistical learning algorithms often make independence assumptions that are inappropriate for linked data.<br\/><br\/>The first task studied is predicting the classification of an object based on attributes of the object and on a description of the objects to which it is linked. We are developing efficient collective classification algorithms that take into account the dependence between the object classifications. The next task examined is the use of labeled and unlabeled data for link-based classification. The use of unlabeled data to improve classification performance in propositional domains has received considerable attention in recent years; the use of unlabeled data for prediction in linked data is even more interesting, as it gives information about both the object distributions and the link distributions. The third task examined is link-based cluster analysis, i.e. finding similar objects based on both the object attributes and link properties. <br\/><br\/>Results from this work will provide insight into effective statistical analysis for large linked heterogeneous domains. This has applications for discovering patterns in social networks, including criminal and terrorist networks, biological data such as epidemiological studies and a wide range of other collections of heterogeneous linked data.","title":"Link Mining and Discovery","awardID":"0308030","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V260","name":"NSA-LINK MINING & DISCOVERY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V517","name":"NGA-KNOW THE EARTH-SHOW THE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V941","name":"NIA-LINK BASED ENTITY RESOLUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V955","name":"NGIA-STAT REL LEARNING FOR SEM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V145","name":"CIA-KNOWLEDGE DISCOVERY & DISS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V203","name":"CIA-KDD WORKING GROUP"}}],"PIcoPI":["518332"],"PO":["564318"]},"81944":{"abstract":"0306140<br\/>Robert Cartwright<br\/>William Marsh Rice University<br\/>EI: Can We Teach Object-Oriented Design to Beginners?<br\/>$420,000<br\/>This project involves the development of a curriculum for teaching 'truly' Object Oriented Design (OOD) at the introductory level with the support of a unique tool suite. A current educational trend is to teach OO design as early as possible. However, this trend may entail a potentially higher risk of pedagogic failure than an object-based approach because computing educators lack a proven curriculum for teaching OO design to beginners. This project explores how sophisticated OOD concepts might be simplified and distilled for beginners. The proposers set forth two reasons for presenting OOD at the introductory level. First, the growth of object-orientation has been fostered by breakthroughs in the understanding of the OO design process. Computing researchers have assembled a comprehensive catalog of OO design patterns that form the conceptual vocabulary for constructing OO programs. These design patterns are templates codifying data abstraction mechanisms that exploit polymorphism to simplify control structure, eliminate replicated code, and facilitate subsequent program extension. They provide detailed, prescriptive guidance on OO design that can be made accessible to novice programmers. Second, the investigators have successfully taught OO design at the CS2 level, supported by a pedagogic programming-environment that provides a simple, transparent interface and simplifies clerical issues involved in writing programs. This change enables instructors to focus attention on teaching program design. The outcomes of this project are expected to be a curriculum, plus supporting tools and materials, for a new introductory programming sequence (CS1\/CS2) that focuses on OO program design. The curriculum will teach the principles of OO design using a series of progressively more expressive sub-languages of Java. These sub-languages are supported by a new edition of DrJava, an open-source project available on the web. An introductory programming curriculum focusing on OOD could have a dramatic impact on the preparedness of the nation's workforce in designing object-oriented systems.","title":"EI: Can We Teach Object-Oriented Design to Beginners?","awardID":"0306140","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["264468",213705,"495364"],"PO":["535244"]},"81966":{"abstract":"3D shape matching, massive dataset visualization, and protein structure prediction.<br\/>The theoretical issues involve combinatorial geometry, algorithm design<br\/>and basic complexity theory. This effort is aimed at deriving new<br\/>computational methods for solving problems of a geometric or biological nature<br\/>that have resisted past investigations because of one two reasons: either the input<br\/>data is too massive to be processed directly and it can only be \"sampled\" cleverly or<br\/>the number of variables is itself so high that standard methods suffer from an exponential blowup<br\/>in the time it takes to run them. New dimension reduction techniques are needed to resolve this bottleneck.","title":"Collaborative Research: A Formal Theory of Robust Numerical Computation Geometry and Its Validation on Configuration Space Construction","awardID":"0306214","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["402028"],"PO":["321058"]},"83715":{"abstract":"Abstract<br\/><br\/>Proposal number: 0313411<br\/>Title: A Semantic-Based Approach for Automated Response to Attacks<br\/>PI: Karl Levitt<br\/><br\/>Historically computer security efforts have focused on relatively simple prevention mechanisms, on detecting attacks that are not prevented, and manual efforts to stop the attack and\/or clean up afterwards. These procedures are ineffective when faced with fast moving, programmed attacks or in jumping ahead of an attacker using a complex series of malicious procedures. In these cases, automated response procedures are required. Practitioners, however, are wary about automatic response because of the high false positive rates generated by today's intrusion detection systems. If automated response systems are allowed to block detected attacks, many legitimate transactions would be accidentally blocked. Furthermore, an attacker could exploit the automated response to launch a denial of service attack. This project will investigate a new approach to automated response reasoning. The approach is based upon a semantic model of the effects on the system due to both attacks and possible responses. Planning of responses is performed with the goal of removing attacker capabilities without affecting the critical capabilities of the system. A successful response system will stop fast-moving programmed attacks automatically without hindering the normal operations of the protected system.","title":"ITR: A Semantic-Based Approach for Automated Response to Attacks","awardID":"0313411","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["521752","560876","521753"],"PO":["543507"]},"81923":{"abstract":"0306050<br\/>Mark Guzdial<br\/>Georgia Technology Research Corp - Georgia Institute of Technology<br\/>Introduction to Media Computation: A new CS1 approach aimed at non-majors and under-represented populations<br\/>$250,998<br\/>This proposal focuses on creating a new kind of CS1 course centered on media computation. The project is founded on the hypothesis that, for many students, computation is about communication and introducing computation in a communications context engages students and leads to increased motivation. Media computation is the use of computation to create, modify, and transform media. Multimedia, having passed the stage of requiring complex activities to create video effects or to generate novel sounds, enjoys a state of the art that makes it feasible to move its concepts from late-undergraduate\/early-graduate courses to introductory courses. This project challenges traditional CS1\/CS2 content which may not reflect the most common kinds of activities that software developers engage in today in the workforce. More commonly, what contemporary IT professionals do involves solving new kinds of problems in new kinds of ways. A large number of IT professionals construct multimedia as part of their careers, and that number may be increasing. While the project goal is not to prepare students for such jobs only, the point is that multimedia manipulation is an activity that can engage students. Once engaged, the students' potential for learning how to implement those \"computer-based solutions to non-computing problems\" is enhanced. The PI for this project hypothesizes that introducing multimedia early has the potential to improve enrollment and success rates in introductory courses. The proposal plan has three components: To build an integrated development environment for students that supports media computation; To develop a set of Java-based materials to improve dissemination of the proposed approach; To evaluate the impact of these developments -- that is, the ease of integration of a media computation approach into traditional CS courses.","title":"Introduction to Media Computation: A New CS1 Approach Aimed at Non-Majors and Under-Represented Populations","awardID":"0306050","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["521278"],"PO":["551712"]},"82902":{"abstract":"Project Summary: Energy-aware Synthesis of Embedded Systems on<br\/>Multiprocessor Platforms <br\/><br\/>Sanjoy Baruah James H. Anderson<br\/><br\/>Two evident trends in the real-time embedded systems domain are (i)<br\/>the proliferation of multiprocessor platforms, and (ii) the<br\/>proliferation of applications for which energy consumption must be<br\/>minimized. In the years ahead, it is reasonable to expect these two<br\/>trends to converge: indeed, one major advantage of multiprocessor<br\/>implementations over uniprocessor ones is that the former tend to be<br\/>more energy-efficient. To date, however, the little work that has<br\/>been done on energy-aware multiprocessor designs has been limited to<br\/>relatively simple table-driven scheduling schemes; a precise<br\/>characterization of the energy savings realized by moving to a<br\/>multiprocessor implementation is not known.<br\/><br\/>These observations point to a significant need for research to be<br\/>conducted on the tradeoffs that exist when designing energy-aware<br\/>multiprocessor systems. This project proposes to fill this need by<br\/>developing and experimentally evaluating design methodologies and<br\/>scheduling algorithms that facilitate the synthesis of embedded<br\/>real-time systems upon multiprocessor platforms, with the primary goal<br\/>of minimizing energy consumption.<br\/><br\/>Broader impact. Based partially on the results of this project, two<br\/>new courses will be developed: an introductory graduate course on<br\/>embedded systems, and a graduate seminar on multiprocessor embedded<br\/>designs. The introductory embedded-systems course will be created as<br\/>a follow-on to current real-time systems and advanced operating<br\/>systems courses. The seminar course on multiprocessor designs will be<br\/>a follow-on to the introductory course. A concerted effort will be<br\/>made to involve underrepresented groups in our research. Results from<br\/>the algorithmic research will be disseminated through publications.<br\/>Any software of general utility that results from this project will be<br\/>made publically available on the web.","title":"Energy-Aware Synthesis of Embedded Systems on Multiprocessor Platforms","awardID":"0309825","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["31436","518412"],"PO":["561889"]},"81505":{"abstract":"In this project, we propose to develop nanoscale 3D structures and use the nanostructures as 3D substrates to address problems in biosensing. To achieve this objective, we will expand our newly developed nanofabrication technique - glancing angle deposition (GLAD) - to fabricating nanoscale 3D pillars such that the size, height, spacing, shape and location of the nanopillars (or nanorods) will be controlled, and multiple layers of nanorods will be realized. This development will provide several unique features to suit the needs for biosensing applications. We will derive nanoscale glucose sensors by functionalizing the nanorods through enzyme immobilization.<br\/><br\/>With this proposed project, we aim to achieve the following specific objectives: (1) to fabricate nanostructures with controlled parameters, such as size, spacing, height, shape and location, for developing nanoelectrodes; (2) to immobilize enzymes onto well-prepared nanostructures to achieve high sensitivity and activity; (3) to control the size and separation of the top layer nanorods to be within 20 nm, so that a mechanical filtration can be realized for antifouling; (4) to passivate the top layer nanorods using self-assembly monolayer (SAM) technique to further improve antifouling; and (5) to fabricate prototype glucose sensors and assess their sensitivity, stability and antifouling behavior.<br\/><br\/>(1) The intellectual merit of the proposed activity: The novelty of this project lies in the following areas: (1) with the multilayer and vertically aligned and high aspect-ratio metallic nanorods serving as 3D electrodes, the sensitivity and response time of the glucose sensors will be significantly improved; (2) with the size and spacing of the top-layer nanorods controlled less than 20 nm, a mechanical filtration to prevent protein penetration will be achieved; (3) with selective passivation (using a specific SAM, such as Oligo(ethylene glycol)-terminated alkanethiols) of the top-layer nanorods, further protein adsorption will be prevented; and (4) the entire development process is compatible with mass microfabrication procedures. Thus, we anticipate that by integrating the novel nanostructures into biosensing applications, we will be able to address concerns of sensitivity, biofouling (via both the chemical passivation and mechanical filtration), and miniaturization. The proposed project is feasible because it is well within the expertise of all PIs.<br\/><br\/>(2) The broader impacts resulting from the proposed activity: This proposed project seeks to integrate biotechnology and nanotechnology for advancing fundamental knowledge in this nascent frontier, and for deriving useful applications to benefit the general public and humankind. The success of this project will not only lead to a new technique for developing high performance glucose sensors, but also serve as a knowledge base, groundwork, and technical foundation for developing nanoscale structures for other types of chemical and biological sensors. It will also open new opportunities for incorporating multilayer nanostructures (as nano-membranes) into realization of multifunctional and multi-specie chemical and biological sensing. This project will also provide unique opportunities for both graduate and undergraduate students to gain precious hands-on experience and training in the multidisciplinary fields of materials science, nanotechnology, and biological engineering.","title":"NIRT: Enhancing the Sensitivity and Stability of Biosensors by Novel Nanostructures","awardID":"0304340","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["478614","542282",212505],"PO":["564900"]},"83937":{"abstract":"Proposal Number: 0314161<br\/><br\/>TITLE: DIMACS Special Focus on Communication Security and Information Privacy<br\/><br\/>PI: Fred S Roberts<br\/><br\/><br\/>Abstract:<br\/><br\/>Vitally important aspects of our modern society have become dependent on rapid and secure communication, which is increasingly electronic. The new electronic age offers vast potential for new services and applications, but gives rise to serious new vulnerabilities and security threats. Moreover, many of the most important new applications come at the price of threats to privacy. The Center for Discrete Mathematics and Theoretical Computer Science (DIMACS) will initiate a three-year \"special focus\" on Communication Security and Information Privacy that will explore the new vulnerabilities and threats and new methods for dealing with them. The activities planned for support under this special focus will include working groups, workshops, and tutorials on several themes, including Computer Security; Software Security; Large-scale Internet Attacks; Intellectual Property Protection; Security of Web Services and E-Commerce; Cryptography: Theory Meets Practice; Security Analysis of Protocols; Mobile and Wireless Security; On-line Privacy: Threats and Tools; Privacy\/Confidentiality of Health Care Data; Intrusion Detection and Network Security Management Systems; Security and Trust Issues Associated with Ad-Hoc Computing\/Pervasive Networking; Secure, Efficient Extraction of Joint Information from Multiple Datasets; Database Security: Query Authorization and Information Inference; Electronic Voting -- Theory and Practice; and Mobile Code Security.","title":"DIMACS Special Focus on Communication Security and Information Privacy","awardID":"0314161","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["264120"],"PO":["362818"]},"83706":{"abstract":"In many data-compression applications the underlying distribution is not known. In these applications one typically assumes that the distribution belongs to a large class of natural distributions and tries to devise compression algorithms that perform well for all <br\/>distributions in the class. For distributions over finite alphabets a lot is known. For example, it was shown that any stationary ergodic sequence can be compressed as well as when the distribution is known in advance. However in many real applications, such as text and image compression, the alphabet is large compared to the string length, often even infinite. Unfortunately, it has been shown that for large alphabets, universal compression cannot be achieved, and as the size of the alphabet grows, the redundancy, namely, the penalty for not knowing the distribution, increases to infinity.<br\/><br\/>Recently, we took a different approach to the compression of strings over large alphabets. The description of any string, over any alphabet, can be decomposed into two parts: description of the dictionary, namely the symbols appearing in the string, and of their pattern, namely the order in which they appear. The descriptions of the pattern and the dictionary can be viewed as two separate problems. The pattern is related to the high-level structure of the string whereas the dictionary relates to the composition of the symbols. In many applications such as language modeling for speech recognition, the pattern is more significant.<br\/><br\/>We have shown that patterns of strings drawn according to independent and identically distributed random variables can be compressed as if the distribution were known in advance. We now study extensions of this result that, if proven, will render it more powerful and practical. We are studying sequential compression algorithms that compress the sequence one symbol at a time, practical algorithms that can be performed using few operations per symbol, and extensions of these results to distributions with memory; such distributions model several practical applications. We are also trying to improve the upper and lower bounds on the best compression rate that can be achieved.","title":"Universal Compression of Infinite Alphabets with Applications to Language Modeling","awardID":"0313367","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["486456"],"PO":["348215"]},"83607":{"abstract":"Chandy<br\/>Abstract Information Infrastructures for Crisis Management<br\/><br\/>This project carries out research on fundamental computer science problems that arise in the development of information infrastructures for preventing or managing crises such as terrorist attacks, pandemics, chemical spills, hurricanes and earthquakes. Crises have elements of the unexpected despite the planning that goes into preparing for them. The element of surprise implies that crisis-management platforms are on-demand systems that are created when the crisis strikes and that are modified as requirements change. The on-demand aspect of crisis management implies that task force members, other than information technology specialists, must be able to specify and deploy software agents that help the task force manage the crisis. Since the membership of a task force dealing with a crisis is often not known until the crisis strikes, the underlying computing and communication systems available to the task force may not be known until the task force is formed. <br\/><br\/>This project develops platforms that can be used to implement crisis-management infrastructures on top of heterogeneous systems used by different institutions in a task force. The infrastructure must be able to deal gracefully with changing coalition membership and changing amounts and types of computing resources by adjusting the net processing rate and the machines on which agents are deployed. The project develops theories, methods and tools to help deal with this uncertainty by making agents and messages persistent, stored in databases or file systems in persistent storage systems, and theories and prototypes for dynamic creation of agents and continuous evolution of compositional structures. The project integrates research in many fields to develop infrastructures that support crisis management.","title":"\"ITR: Information Infrastructures for Crisis Management\"","awardID":"0312778","effectiveDate":"2003-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["499268"],"PO":["561889"]},"83619":{"abstract":"Chong<br\/><br\/><br\/><br\/>ITR: Synchroscalar, Exploiting Synchronized Clock Domains for Energy<br\/>Efficient Multirate Embedded Systems<br\/><br\/>Abstract<br\/><br\/>Ubiquitous computation and communication devices will dominate the social and economic landscape of the new millennium. As the functionality of these devices evolve, current microprocessor designs cannot keep up with the battery life and the performance requirements. We propose to address this problem with a novel microprocessor design that uses a combination of two approaches. First, we break the work into many parallel pieces to increase performance. Second, to save power, we run each piece at the minimal speed necessary to achieve the quality of communication desired. <br\/><br\/>Specifically, we propose the Synchroscalar architecture, a two-dimensional mesh of processing tiles in which each column forms a separate clock and voltage domain. Clock frequencies are related by a rational factor, which will be exploited to schedule data transfers between different clock domains without incurring the overhead of asynchronous communication between clock boundaries, yet retaining the benefits of optimal clocking for each column. This organization gives us the many of the energy advantages of asynchronous systems while maintaining the simplicity of a synchronous system.<br\/><br\/>The success of these approaches will significantly increase the impact of information technology on the nation, enabling many \"wired\" applications to become wireless and mobile.","title":"ITR: Synchroscalar: Exploiting Synchronized Clock Domains for Energy Efficient Multirate Embedded Computation","awardID":"0312837","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["485984","486140","551167"],"PO":["325495"]},"83509":{"abstract":"The unprecedented explosion in the volume of readily accessible data in <br\/>recent years, although highly desirable, comes at a heavy price - it is now <br\/>considerably more difficult to locate the answer to a specific question, or to <br\/>find patterns and correlations that are central to a phenomenon. The PI's <br\/>propose to study general-purpose clustering as a solution to the problem of <br\/>locating relevant information and organizing it in an intelligible way. <br\/><br\/>The proposal falls into two tracks. The first track is to develop measures <br\/>and criteria that accurately re the quality of a clustering. The PI's have <br\/>initiated work in this direction, and plan to build a theory of clustering criteria firmly grounded in the intuition of practitioners. <br\/><br\/>The second track is the design of efficient algorithms to find near-optimal <br\/>clustering under the right measures. The PI's propose to develop algorithms <br\/>based on the so-called \"spectral methods\" and other techniques. They plan <br\/>to make them efficient by the use of random (non-uniform) sampling. The <br\/>PI's also plan to implement some of the algorithms and empirically evaluate <br\/>them. <br\/><br\/>The PI's propose to ensure that any positive impact from their research <br\/>is maximized by (a) widely disseminating the results via conferences and <br\/>also by inviting other researchers to discuss the ideas, (b) by making the <br\/>preliminary implementations of clustering algorithms available.","title":"Collaborative Research: ITR: Models, Algorithms and Analyses for Clustering Data","awardID":"0312354","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["320878"],"PO":["562984"]},"81408":{"abstract":"NIRT: Modeling and Simulation Framework at the Nanoscale<br\/>Abstract<br\/><br\/>This proposal was received in response to Nanoscale Science and Engineering initiative, NSF 02-148, category NIRT. The goal of the research effort is the development of a generalized multiscale modeling and simulation methodology for nanostructured material systems. Project efforts will include the development of (i) a mathematically rigorous multiscale modeling methodology capable of coupling behaviors from the atomic scale through full scale system, (ii) a computational simulation framework built around this methodology into which techniques for investigating behaviors at the various scales can be effectively integrated, and (iii) a proof of concept of the developed core technologies using synergetic interactions with experimental work currently under way at Rensselaer. The project will bring together researchers with complementary expertise in: nanomechanics, multibody dynamics, multiscale computational techniques, and computational engineering.<br\/><br\/>Reliability of modeling and simulation at the nanoscale based on the formalism of adaptive hierarchical modeling is the key aspect of the project. Efforts will focus on the coupling of modeling methods applied at the atomic and continuum levels, including bridging of the appropriate time scales and integrating various physical phenomena. Specific consideration will be given to the estimates of modeling errors. These estimates will be based on a posteriori measurements that will be employed in new procedures for the adaptive selection of scales and methods applied throughout the space\/time domain of the simulation. <br\/><br\/>The core technologies developed will be incorporated into a component-based simulation framework. Building on advanced software technologies, this framework will efficiently support distributed parallel calculations on the evolving structures of adaptive multiscale simulations. To address the computational requirements of these simulations new numerical methods that reduce the computational effort of these simulations will be developed. <br\/><br\/>This effort is expected to impact science and industry's ability to model, analyze, and understand a vast array of nanomaterials used in applications, such as engines, lightweight components used in the aerospace and automotive industries, and coupled electro-mechanical devices (sensors). These applications represent enabling technologies for major U.S industries. Solid theoretical foundations and associated simulation capabilities are needed to support the breakthrough developments central to the growth of these industries. This project will take advantage of the faculty, programs and facilities being supported through the Rensselaer Strategic Plan. The program will also develop new interdisciplinary graduate and short courses in multiscale modeling with applications to nanotechnology in order to train a generation of scientists and engineers with superior mathematical and technological skills.","title":"NIRT: Modeling and Simulation Framework at the Nanoscale. Application to Process Simulation, Nanodevices, and Nanostructured Composites","awardID":"0303902","effectiveDate":"2003-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["525821","561789","491777","508246","441725"],"PO":["550859"]},"81937":{"abstract":"0306096<br\/>Frank Klassner<br\/>Villanova University<br\/>Education Innovation: LEGO MindStorms - Cost-Effectively Expanding CS students' Horizons and Enthusiasm Outside the (Desktop) Box<br\/>$490,000<br\/><br\/>This project involves investigators from three institutions - Villanova University, University of Mississippi, and Alma College - and is a follow up of a Proof of Concept grant, DUE-0088884, awarded by the DUE Division of NSF. The current project involves four activities: developing a set of 40 assignments and laboratory exercises that use LEGO MindStorms robot kits to promote active student learning across the ACM\/IEEE Computing Curricula 2001 (CC2001) guidelines; identifying and maintaining software technology that is needed to make the MindStorms platform support the range of assignments developed; motivating students' interest in, understanding of, and application of advanced computer science research results through exploration with the MindStorms platform; and measuring the pedagogical efficacy of the MindStorms platform. In part, this project was motivated by a survey of research efforts and employment opportunities in CISE fields over the past five years that showed several trends that may have serious implications for the traditional undergraduate computer science curriculum design - that is, greater emphasis on mobile networking, ubiquitous computing, large-scale networks, real time systems, agent architectures, embedded signal analysis systems in robotics and information retrieval systems, distributed system design, and world-wide-web language design in the research community, in part because of the explosion in network capabilities on the WWW. Employment opportunities for computer science BS graduates are increasingly requiring competence in distributed computing solutions and embedded programming solutions within the greater context of the World Wide Web. This institution's experience with hands-on robotics projects, in an NSF CCLI proof-of-concept grant, indicated that undergraduate students' motivation to learn new computing principles increases significantly when they apply those principles to constructing robots and designing problem-solving control code for their creations. However, scarcity of educational materials available to implement this approach is a deterrent to its pursuit. This project identifies seven out of the fourteen knowledge areas in the CC2001that might be pedagogically enhanced through robotics-oriented projects: Programming Fundamentals, Algorithms and Complexity, Programming Languages, Architecture, Operating Systems, Intelligent Systems, and Net-Centric Computing. All of the areas targeted in this project contain material that the committee has designated as 'core' topics. Thus, advanced and elective courses in a CC2001-based curriculum can seamlessly take advantage of students' experiences in the core topics when exploring advanced research results in the context of MindStorms robotics. The materials developed by this project will be disseminated both through the WWW and workshops.","title":"Education Innovation: LEGO MindStorms - Cost-Effectively Expanding CS Students' Horizons and Enthusiasm Outside the (Desktop) Box","awardID":"0306096","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["398367","458386","557468"],"PO":["551712"]},"82807":{"abstract":"Searching is a fundamental and pervasive operation in information processing. It can be expressed in a variety of forms such as (a) equivalence search (exact match search, not-equal-to search, similar-to search) (b) magnitude comparison search (smaller than, greater than, not-smaller-than, not-greater-than), (c) between limits search (search within a range or outside a range), (d) ordered retrieval search (ascending order, descending order), (e) extreme search (finding the maximum, the minimum, and the median), and (f) lookup search. These types of searches can be found in many information technology (IT) applications including database processing, artificial intelligence, pattern matching, security, and communications. In addition to its widespread use in information processing, searching plays a major role in data communication and routing where it serves as the basis for routing table lookup and classification necessary for packet routing. Conventional processors are often designed for numerical processing and search operations are delegated to software. Consequently, and for many applications, search operations are the most time consuming and create a major performance bottleneck.<br\/><br\/>In this research project, we propose to investigate the development and detailed analysis of novel photonic search engines, that can implement search operations in hardware as directly as possible, and thereby as efficiently as possible. This will not only provide for minimum execution time but will also increase efficiency in other areas. These engines can be used as co-processing assists within a larger electronic processing node for computation and\/or communication or as stand-alone search accelerators. We propose a novel approach that will combine device technology with architectural innovations in an efficient and practical manner with the aim of achieving a significant improvement in performance as well as reduction in system size. Our approach differs significantly from any on-going research on the subject. It represents a paradigm shift where search functions are directly executed in hardware instead of coded as lengthy subroutines using low-level instructions. It is anticipated that this approach will provide parallel search engines with low-power operation, high-speed processing (in the Terabits\/second range), high degree of parallelism (due to the exploitation of several degrees of freedom in optics), and small monolithically integrated system size. The proposed research will have a broader impact on information technology. It is likely that a new field of study, multi-wavelength guided-wave integrated optical processing, will emerge for designing smaller processing systems while providing even more computing power than before.","title":"Development and Feasibility Study of an Integrated High-speed Photonic Search Engine with Applications to Information Technology","awardID":"0309537","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["559883"],"PO":["562984"]},"90919":{"abstract":"Abstract<br\/>0310889<br\/>Robert D. Nowak<br\/>William Marsh Rice U<br\/><br\/>Today's private and public communications networks are critical systems of data terminals, routers, and switches that provide the backbone of our economic, scientific, and education systems. Consequently, signal processing methods for estimating performance characteristics and detecting key component failures and malevolent behavior are crucial for insuring the reliability and robustness for this vital infrastructure. Moreover, networks of sensors and actuators will soon be part of our information systems. These networks will provide critical links between our environment and our information-based society. Distributed and hierarchical algorithms for data analysis and signal processing will be central to the operation of such networks.<br\/>This research targets these important, emerging signal processing applications in networking. The proposed research blends the fields of adaptive and distributed signal processing, nonparametric estimation and classification, network traffic measurement and modeling, and network traffic analysis and tomography. The project involves the development of theories and methodologies for data analysis, estimation, and classification in networking applications. Most inference problems arising in networking are extremely challenging; the amount and nature of the data that is easily collected is very limited, and the estimation or classification tasks are often severely ill-posed. Common inference methodologies such as maximum likelihood are of limited utility in large-scale networking problems due to these confounding factors. Therefore, complexity regularization methods for estimation and classification provide the core computational signal processing tools in the project. These methods temper the trade-off between fitting to the data and model complexity (and hence variability).<br\/>Two core problems in network analysis and inference are the focus of this proposal. (1) Network Tomography: Network tomography involves estimating performance characteristics and traffic flow patterns from measured traffic at a limited number of points in the network. This problem is very ill-posed and existing schemes do not perform well in large-scale implementations. We propose novel complexity regularized approaches to network tomography that aim to capitalize on certain, naturally occurring, sparsity characteristics of the network tomography problems. (2) Multi-channel Network Traffic Analysis: Much work has been done in the area of network traffic analysis, but the focus has been mostly on signal point traces. Analysis and understanding of the relationships between traffic flows at different points in networks is crucial to overall performance. We propose to investigate and develop analysis methods capable of revealing important traffic interrelationships, dependencies, and coincidences at multiple<br\/>measurement points. The research investigates: 1) fundamental limits in network inference methods for estimating and detecting conditions critical to network performance; 2) integrated and flexible approaches to spatio-temporal analysis of internetwork traffic patterns; 3) scalable, distributed, and decentralized algorithms for network data analysis and inference; 4) basic theory of complexity regularization and distributed signal processing.","title":"Complexity Regularized Signal Processing for Networking Applications","awardID":"0350213","effectiveDate":"2003-08-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T047","name":"CIA-SPATIO-TEMPORAL NETWORK"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V577","name":"CIA-ANTENNE ARRAY PROCESSING"}}],"PIcoPI":["518179"],"PO":["564898"]},"86060":{"abstract":"The experimental part of this project is focusing on the construction of 3-dimensional DNA \"crystals\" where the goal is to create large error-free crystals of predetermined shape. In particular, control of the relative lengths of crystal facets and the angles between adjacent facets is being attempted. This research may ultimately lead to the construction of 3-dimensional computers, freeing us from the 2-dimensional restriction currently imposed by silicon. Another potential application might be 3-D crystals \"salted\" with flourophors or quantum dots for the creation of novel optical or quantum devices. The theoretical efforts are directed toward generating an understanding of the fundamental processes that govern self-assembly, and the development of new algorithms that will guide the design of practical and experimental systems. The functionality of DNA is determined, to a large extent, by its combinatorial structure, making algorithmic techniques particularly well suited for a theoretical study of DNA self-assembly.<br\/><br\/>As part of this project, two new courses on self-assembly are being developed, one at Stanford University and one at University of Southern California in the area of Molecular Self-Assembly: Models and Algorithms. The lecture notes from this sequence of courses will be made available to the scientific community.","title":"COLLABORATIVE RESEARCH: DNA Self-Assembly -- Experimentation and Theoretical Foundations","awardID":"0323766","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["429621"],"PO":["521045"]},"89371":{"abstract":"The term \\emph{peer-to-peer}(P2P) came to the force very publicly<br\/> with the rise and fall of Napster.<br\/>Although there are prior systems in this evolutionary phase of distributed computing,<br\/> P2P system first emerges as a significant social and technical phenomenon right after the<br\/> deployment of Napster.<br\/>Currently most of popular P2P systems are aiming at the file sharing applications,<br\/> where files are stored at some end-users' machines rather than at a central<br\/> server in the traditional client\/server model.<br\/><br\/>Wireless ad hoc networking is just a special case of P2P networking, where<br\/> no infrastructure or celluar networking is needed for communication.<br\/>Recent years saw a great amount of research <br\/> in wireless ad hoc networks. These<br\/>works involve a number of theoretical aspects of computer science, including<br\/>approximation algorithms, computational geometry, combinatorics, distributed<br\/>algorithms. However, there are still many challenges in wireless ad hoc<br\/>networks. Due to the limited capability of processing power, storage, and<br\/>energy supply, many conventional algorithms are too complicated to be<br\/>implemented in a wireless ad hoc networks. Some other algorithms did not take<br\/>advantage of the geometry nature of the wireless networks. Additionally, most<br\/>of the currently developed algorithms for wireless networks assumed a precise<br\/>position of each wireless node, which is impossible practically. Majority of<br\/>the algorithms developed in this area also assume all nodes have uniform<br\/>transmission range. These algorithms will likely fail when nodes have<br\/>disparity transmission ranges.<br\/><br\/>Furthermore, the wireless ad hoc networks requires efficient distributed<br\/>algorithms with low computation complexity and low communication complexity.<br\/>These algorithms are expected to take advantage of the geometry nature of the<br\/>wireless ad hoc networks. Several fundamental questions should be answered:<br\/>can we improve the performance of traditional distributed algorithms under<br\/>wireless ad hoc networks? Does the position information of wireless nodes make<br\/>difference in algorithms' performance?<br\/><br\/>We propose to organize a workshop to solicit the recent research efforts on<br\/>addressing these challenges. Specific topics include but are not limited to<br\/>the following issues:<br\/>Deployment for Connectivity,<br\/>Deployment for Coverage, <br\/> Throughput,<br\/>Mobility,<br\/>Channel Assignment,<br\/>Power\/Topology Control,<br\/>Localized Routing,<br\/>Cooperation Enforcement and Mechanism Design,<br\/>Security.<br\/><br\/>A number of junior faculty and graduate students from both domestic and<br\/>international have been actively working on addressing some of these<br\/>challenges. They will be the main component of potential attendees of this workshop.<br\/><br\/>The workshop is intended to bring together researchers in mobile computing and<br\/>distributed algorithms to foster cooperation. It is intended to be a lively<br\/>meeting, covering many of the algorithmic and discrete aspects of this field<br\/>going from operations research to radio engineering problems. It aims, in<br\/>particular, at fostering the cooperation among practitioners and theoreticians<br\/>of the field. We plan to hold this workshop on June 2nd, 2004 at Chicago,<br\/>Illinois. Workshop papers will be published in workshop proceedings and<br\/>selected papers will be published in a special issue of a journal.<br\/><br\/><br\/>By organizing the workshop on the theoretic aspects of wireless ad hoc networks<br\/> that addresses the a number of challenge and fundamental problems.<br\/>The potential attendees of the workshop will be junior faculty and senir PhD students<br\/> who had been actively working in the theoretic aspects of wireless ad hoc networks.<br\/>Thus, a successful workshop will initiate more junior faculty and PhD students<br\/> in the research of this area.<br\/>Our own experiences in working with PhD students has been excellent.<br\/>Our currently supported Ph.D. students have already<br\/> contributed to considerable number of papers published in major theoretical<br\/> and\/or networking conferences.<br\/>Exposure to this workshop organized by National Science Foundation will <br\/> increase their productivity.<br\/><br\/><br\/>Since the proposed research activities involve theoretical understanding<br\/> and solving of practical questions from wireless networking,<br\/> the proposed workshop will foster collaborations with faculties <br\/> from other discipline,<br\/> some researchers from industry to verify the developed theoretical methods in a<br\/> more practical settings to see its practical performance.<br\/>Additionally, since ad hoc networks support applications<br\/> related to disaster relief, public event coordination, and military and <br\/> law enforcement operations,<br\/> the proposed research has vast societal impact.","title":"Workshop Proposal on Theoretical Aspects of Wireless Ad Hoc Networks","awardID":"0342259","effectiveDate":"2003-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["560173"],"PO":["543507"]},"87150":{"abstract":"Robotics and Computer Vision Program<br\/><br\/>ABSTRACT<br\/><br\/><br\/>Proposal #: 0329106<br\/>Title: Micromanipulation of Flexible and Rigid Objects<br\/>PI: Ron Lumia<br\/>University of New Mexico<br\/><br\/>The goal of this work is to develop a better theoretical and practical understanding of how to grasp rigid and flexible objects that range in size between 1-100 microns. We will develop a model for the ionic polymer metal composite (IPMC) material that will be used to implement a microgripper. This electroactive material exhibits large deflection from only a few volts of actuation. Technically, there are two fundamental areas we will explore. The first relates to how small the IPMC material can be cut and still function as a microgripper. We will develop a new model for the microscale properties of this material. Using this model we will predict microgripper performance, e.g., strength, and test the model by building a variety of microgrippers. The second issue relates to releasing objects. Since gravity for small objects is several orders of magnitude smaller than other adhesive forces, a new approach to release objects will be explored. We propose to inject a short voltage pulse into a microgripper finger just at the moment it tries to release an object. This will change the polarity of the electrostatic charge stored at the finger, thus driving the object from the finger. The impact of this work can be significant because the microgripper is an enabling technology for a variety of applications. Microgrippers will be needed to grasp, manipulate, and place small components to create products. For flexible objects, microgrippers can manipulate cells for applications such as rapid and inexpensive DNA processing.","title":"Micromanipulation of Flexible and Rigid Objects","awardID":"0329106","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["449805"],"PO":["403839"]},"78350":{"abstract":"The explosive growth of the Internet and the continued dramatic increase for all wireless services are fueling the demand for increased capacity, data rates, supported multimedia services, and support for different Quality of Service (QoS) requirements for different classes of services. Wideband CDMA (WCDMA) has been proposed as a key air interface technique for third generation (3G) wireless systems, and will continue to be adopted as a strong candidate for 4G systems that will provide differentiated services to multimedia traffic. With the capability of dynamically varying user channel rates, WCDMA systems can provide more flexibility in bandwidth allocation. Although the out-coming new radio technology will bring more bandwidth at air interface, if not managed properly, the bandwidth resources will not meet the requirements of future users.<br\/>In order to address the overall problem of offering efficient and effective wireless multimedia services that meet the users' QoS (Quality of Service) requirements in mobile wireless networks we plan to provide an integrated solution by investigating the various involved problems from two different levels and angles which are aligned with the two main elements associated with the networks under consideration: wireless nature and mobility. <br\/>Specifically, given the strict multimedia user requirements, in order to satisfy the main objective of this proposal of designing efficient wireless resource allocation methods we first remove the traditional assumptions of infinite number of users and fixed packet lengths, and analyze the wireless system performance under a more general and realistic case with finite population of voice and data users, finite buffers and variable packet length for data users. Given the wireless nature of the environment under consideration and the variations in the channel capacity, an efficient data rate scheduling scheme that adapts to the changing channel condition is investigated in order to maximize the weighted system throughput. An adaptive compensation technique is also employed in order to guarantee the fair allocation of resources among the competing users despite of the variation of channel capacity. Furthermore in order to deal with the issue of mobility and congestion in mobile wireless networks and their impact on the users' QoS, we study the enhancement of admission control and handoff process by introducing and investigating the following additional dimensions: flexible advanced bandwidth reservation and reconfiguration to optimize the bandwidth utilization especially when services with flexible QoS are supported; integration of pricing and admission control to maximize the users' total utility and alleviate or minimize the network congestion; design of a mobile agent based system to provide a flexible and comprehensive framework to implement these management processes and schemes.<br\/>The proposed educational plan includes: undergraduate and graduate teaching; introduction of new courses; graduate student advising and mentoring; undergraduate project supervision; participation in an outreach program; lectures at local technical high schools; and finally, enhancement of existing laboratory infrastructure and facilities. Among the objectives of the education plan is to create an attractive research and educational environment in which both graduate and undergraduate students alike can collaborate and work together in order to learn and discover. Furthermore NJIT has a significant presence of minority and women students (~40% and ~18% respectively) and it is expected that some of these students will have the opportunity to contribute to this project. Finally I expect that the proposed plan will allow me to continue to expand on the already established international dimension of my career-development.","title":"CAREER: Efficient Resource Allocation and Control in Mobile Wireless Networks with Multimedia Services","awardID":"0237331","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["269272"],"PO":["565090"]},"89141":{"abstract":"Workshop","title":"Finite Metric Spaces and their Applications","awardID":"0340986","effectiveDate":"2003-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["542007"],"PO":["543507"]},"88184":{"abstract":"This small grant for exploratory research aims to develop an integrated architecture for intelligent behavior. Most work in this area has focused on a particular class of architectures - production systems. This work proposes a new novel cognitive architecture, Icarus, that embodies quite different principles. The research will make basic advances in representation, utilization, and acquisition of knowledge in intelligent physical agents. Moreover, it relies centrally on the integration of these capabilities into a unified cognitive architecture that must be general enough to operate in many domains. Such a unified framework for intelligent behavior could have a major impact on both artificial intelligence and cognitive science.","title":"SGER: New Research Directions in Integrated Cognitive Architectures","awardID":"0335353","effectiveDate":"2003-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["559662"],"PO":["564318"]},"88196":{"abstract":"The Nineteenth ACM Symposium on Operating Systems Principles will be held at Bolton's<br\/>Landing, Lake George, New York, October 19-22, 2003. For over 30 years SOSP has been the<br\/>leading forum for innovative research in operating systems. Like its predecessors, SOSP<br\/>2003 will bring together researchers from around the world to present and discuss the<br\/>latest results. In addition to such traditional topics as the performance, functionality,<br\/>and security of kernels, file systems, and networks, this year's conference will place<br\/>increasing attention on such emerging topics as ubiquitous and mobile computing, sensor<br\/>networks, overlay and peer-to-peer communications, and power management. Particularly<br\/>noteworthy papers will be forwarded to ACM Transactions on Computer Systems for possible<br\/>journal publication. There will also be poster and work-in-progress sessions for the<br\/>presentation of promising preliminary work.<br\/>This proposal requests funding to support the attendance of 20 US-based graduate students.<br\/>Participation in leading conferences is an extremely important part of the graduate<br\/>school experience, providing the opportunity to interact with more senior researchers and<br\/>to be exposed to leading edge work. The support requested in this proposal will make<br\/>possible the participation of students who would otherwise be unable to attend.","title":"Student Travel Support for 19TH ACM Symposium on Operating System Principles (SOSP); Lake George, NY; October 19-22, 2003","awardID":"0335406","effectiveDate":"2003-08-01","expirationDate":"2004-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["564815"],"PO":["309350"]},"83180":{"abstract":"Project Abstract:<br\/><br\/>Systems are only as secure as their weakest point of attack. Indeed,<br\/>the only way to increase the security of a system as a whole is to<br\/>improve the resilience of its most vulnerable component. Much<br\/>successful research has focused on developing cryptographic protocols<br\/>which are secure as long as some information (i.e., a key) is kept<br\/>secret from the adversary. However, as such algorithms are<br\/>increasingly deployed on inexpensive, mobile, and unprotected devices<br\/>(e.g., laptops, mobile phones, and PDAs), the risk of key exposure is<br\/>becoming a serious threat to the security of many real-world<br\/>systems. This project aims to develop new paradigms and to design<br\/>efficient algorithms for maintaining security even in the event of a<br\/>key exposure attack. Among other topics, the project will focus on (1)<br\/>forward-secure public-key encryption; (2) forward secrecy in<br\/>key-exchange protocols; and (3) protecting signcryption schemes<br\/>against key exposure attacks. The techniques developed as part of this<br\/>research are expected to help improve the security of a number of<br\/>different systems, from handheld devices to ad-hoc networks.<br\/><br\/>Graduate students will be involved in all aspects of this project, and<br\/>undergraduate involvement will be encouraged as well. The techniques<br\/>stemming from this research will be incorporated into undergraduate<br\/>and graduate courses in cryptography and computer security. In these<br\/>ways, the project will help train future scientists in the important<br\/>area of information security.","title":"Collaborative Research: Mitigating the Damaging Effects of Key Exposure","awardID":"0310751","effectiveDate":"2003-08-15","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["519626"],"PO":["521752"]},"84192":{"abstract":"Language conveys meaning but how so? At first the answer seems simple: One person talks while the other listens, and then they exchange roles. Understanding seems to boil down to the listener knowing the meaning of the spoken words plus some rules of grammar. But that is not the whole story. To understand language, people bring to bear memories of related interactions with objects in their world and with other people. It is as though they imagine, consciously or unconsciously, the situations described within the conversation-successful understanding is more closely tied to successful imagination than to grammatical analysis. With NSF-support, Dr. Arthur Glenberg will investigate these characteristics of language and imagination. For example, to understand the sentence \"The strong wind caused the sailboat to capsize\" may require a form of imagination in which an imagined wind exerts enough force to tip over the boat. This form of imagination may invoke the same processes of mind that would understand the perception of a sailboat capsized by a strong wind. Dr. Glenberg explores such possibilities using a newly developed procedure in which people press a lever while reading sentences that imply force in the opposite or same direction. The action of pressing makes it easier to read sentences that entail force in the same direction, or harder to read for forces in the opposite direction. This is interpreted as evidence that the same mental process is tapped in language and perception. Additional research examines the application of these ideas to languages other than English and to performance in non-linguistic domains such as mathematics. Broader impacts of this research are used to guide the design of reading remediation technologies and the creation of new types of educational tools.","title":"Perception and Action Systems in High-Level Cognition","awardID":"0315434","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V574","name":"CIA-RES ON DECEPTION DETECTION"}}],"PIcoPI":["533487","552833"],"PO":["565250"]},"86062":{"abstract":"Endohedral fullerenes (molecular compounds in which an atom with an electronic moment resides inside a hollow \"buckyball\" molecule) are attractive candidates for quantum bits (qubits) because the endohedral fullerene chemically and electrically protects the electronic moment that will serve as a qubit leading to long spin relaxation times and the opportunity to build the computer on surface without the need for burying. The goal of the project is the application of a magnetic resonance force microscope to the detection and study of individual endohedral fullerenes, and to the fabrication, characterization and readout of the computer, ultimately with single spin sensitivity, it is hoped. To achieve this techniques for manipulating and studying fullerenes on surfaces will be developed, and high sensitivity magnetic resonance force microscopy studies of their magnetic properties will be performed.","title":"Magnetic Resonance Force Microscopy for Characterization and Read-out","awardID":"0323783","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["462828",224733],"PO":["521045"]},"78571":{"abstract":"The proposed research is directed towards developing networking solutions for ubiquitous computing - which has the promise to open up many new applications leading to an overall improvement of productivity at our homes and offices and would result in a better quality of life. The networking challenge is to design seamless, high quality wireless adhoc communication among a large number of small inexpensive computers. These nodes are expected to self-organize into networks capable of discharging complex computing and communication functionalities which lead to acute resource limitations. The constrained resources are bandwidth, power and buffer memory. Furthermore, the dynamic nature of the topology and the geographical separation of nodes require distributed control. The proposed research seeks to provide the desired quality of service to users in spite of the resource limitations. We note that bandwidth, memory and power are interdependent resources. The coupling is due to the fact that the temporary scarcity of one can be compensated by leveraging the availability of another. This interdependence can be exploited to design a comprehensive management scheme, for power, memory and bandwidth, which significantly enhances the traffic carrying capability of wireless networks. The next key observation is that in ubiquitous computing individual nodes are idle most of the time, but must handle occasional bursts of activity. The traffic handling capability increases many-fold if idle resources of the neighbors are leveraged. <br\/><br\/>The research goal is to design an optimal distributed control framework which uses local observations and partial information of the resource requirements and availabilities at other nodes to attain (a) an efficient and comprehensive utilization of individual resources and (b) a judicious usage of others idle resources when the individuals resources are not sufficient. The resulting protocols are expected to be robust to variations in networking traffic and dynamic topological changes on account of mobility.<br\/><br\/>The activity will promote the training of high caliber students to fill the expanding need for capable scientists and engineers in the information technology field. Undergraduates will be involved in wireless research through creative design projects. The design projects will target adhoc applications of societal significance such as adhoc networking of vehicles e.g., cars for preventing low-visibility related accidents. Supervision of doctoral research will be a core component of the overall activity.<br\/><br\/>The overall education mission of the home institution (University of Pennsylvania) will be furthered through the design of two new courses in the wireless area at undergraduate and graduate level, and introduction of seminars and industry collaborations. The outreach activity will motivate women towards careers in engineering. The specific plan is to reach out to women students by participating in (a) girl scout activities as group leader\/mentor and (b) local IEEE student branches, society of women in engineering (SWIE) and synergistic activities in local community colleges, involve them in innovative projects and subsequently proactively hire women PhD students.","title":"CAREER: Realizing the Potential of Wireless Adhoc Networks Through Holistic Resource Allocation","awardID":"0238340","effectiveDate":"2003-08-15","expirationDate":"2009-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["517945"],"PO":["565090"]},"88174":{"abstract":"Proposal Number: 0335324<br\/><br\/>TITLE: Exposing Grand Challenges in Information Security and Assurance<br\/><br\/>PI: Eugene Spafford <br\/><br\/><br\/>Abstract:<br\/><br\/>The last decade has seen a huge growth in the spread of computing in commerce, government, research and personal life. However, as our dependence on these technologies has grown, there have also been an increasing number of threats to this same technology, and to the information and processing managed by it. The conference to be supported by this proposal will seek to identify \"grand challenges\" in the areas of information security and information assurance, or more broadly in Cyber Trust. The conference is one of a series of conferences on grand research challenges in computer science and engineering that began in June 2002 with the \"Grand Research Challenges in Information Systems\" conference. A broad range of viewpoints will be included at the conference, which will product a report laying out a dynamic research agenda that will lead to substantive progress in IS\/IA. The agenda is expected to be of value not only to agencies and companies wishing to establish a long-term research agenda, but to the research and academic communities to help seed new projects.","title":"Exposing Grand Challenges in Information Security & Assurance","awardID":"0335324","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":[231182,"522969"],"PO":["521752"]},"89286":{"abstract":"Robotics and Computer Vision Program<br\/>Division of Information and Intelligent Systems<br\/><br\/><br\/>Abstract<br\/><br\/>SGER Proposal 0341840<br\/>Compliant Actuation for Human-Machine Interaction<br\/>PI: Thomas Sugar<br\/>Arizona State University<br\/><br\/>With National Science Foundation support, Dr. T. Sugar will conduct one year of study in actively controlling compliance and designing and constructing actuators that physically interact with the user. The study of compliant actuation is an essential part of integrated systems that will aid users in locomotion and standing from a sitting position, and offers a rich framework for exploratory research. Novel designs for compliant actuators for powered orthotics and mobile assistants will be developed. These actuators will allow for safe compliant human-interactions. The research activities will lay the groundwork for the development of rehabilitation aids for the elderly. <br\/>New, selective-compliant actuators based on dynamically changing the equilibrium position of springs will lead to more functional human robotic interactions. The proposed research will overcome the outlined challenges that include the tradeoff between precision, bandwidth, and compliance, and the robust sensing of forces. From this research, the next generation of interfaces will be developed for users to interact with personal robotic assistants.","title":"SGER: Compliant Actuation for Human-Machine Interaction","awardID":"0341840","effectiveDate":"2003-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["351991"],"PO":[234178]},"79023":{"abstract":"This project introduces a new measurement and analysis methodology that can be used to characterize end-end performance measures (such as loss and delay along a path) as well as internal network characteristics (such as loss experienced along distant path segments) from measurements taken at a single point within the network. The proposed \"measurement-in-the-middle\" approach uses time-stamped, packet-level traces gathered at this single measurement point together with probabilistic state-based sender\/receiver models and statistical inferencing techniques to infer end-end performance measures. These metrics include the loss and delay along paths between a source, destination, and measurement point, and along portions of these paths as well. The research performed in this project will develop and analyze (through modeling, simulation, and empirical study) the theoretical foundations and practical considerations needed for this new approach towards network performance measurement and analysis. The ability to infer end-to-end and path-portion performance from a single point within the network has many advantages. Most importantly, because measurements are taken \"in-the-middle,\" the end-end behavior of a large and diverse mix of source\/destination pairs can be measured, without having to instrument individual senders and receivers. This research will develop a fundamentally new approach to network measurement methodology that will allow network operations, engineering and research users to measure a larger, and more diverse, mix of network traffic than has been possible in the past. In addition to more fully characterizing network traffic, a richer set of measurements and a better understanding of network traffic can also play an important role in improved network management, network modeling, and network\/protocol design.","title":"Measurement-in-the-Middle","awardID":"0240487","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["499259","545655"],"PO":["565090"]},"83291":{"abstract":"Algorithmic issues concerning several problems in Computational Biology<br\/>will be investigated. Problems on Gene Networks, DNA Sequence<br\/>Assembly and DNA Sequence Analysis will be emphasized. A Gene Network tries<br\/>to explain the observed lethality of a cell due to pairwise deletion of genes<br\/>in its genome. In the DNA Sequence Assembly area, we propose development of<br\/>algorithms for a better utilization of mate pairs data. The proposed<br\/>problems in the DNA Sequence Analysis deal with the construction of<br\/>space efficient dynamic data structures for performing fast approximate<br\/>match queries.","title":"Some Algorithmic Issues in Computational Biology","awardID":"0311321","effectiveDate":"2003-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["328532"],"PO":["279077"]},"86470":{"abstract":"Proposal: CCR-0325529 (Lead)<br\/>PI: Lu, Chenyang <br\/>Institution: Washington University - St. Louis<br\/><br\/>Proposal: CCR-0325197 <br\/>PI: Stankovic, John <br\/>Institution: University of Virginia <br\/><br\/>Title: ITR: Collaborative Research: Spatiotemporal Protocols and Analyses for Wireless Sensor Networks<br\/><br\/><br\/>Large-scale wireless sensor networks can change the way humans interact with physical environments through a broad range of applications including highway traffic coordination and security surveillance. Future sensor-based applications will have to meet new kinds of spatiotemporal specifications under severe resource limitations. Our fundamental hypothesis is that communication protocols and their analysis must incorporate the notions of space, time, and mobility in a unified framework, something not addressed directly by earlier research. <br\/><br\/>This project, a collaboration between Washington University and the University of Virginia. An overarching goal of the project is to establish a spatiotemporal communication framework for wireless sensor networks the integration of real-time systems and mobile computing research. The project develops a new communication protocol stack optimized for sensor networks by incorporating timing and space properties in scheduling and routing algorithms, thereby enabling analytic guarantees for the spatiotemporal specifications of sensor network services in mobile environments. Our protocol stack finds instantiation in a sensor network middleware that is readily reusable by a broad range of applications. Developing a rigorous spatiotemporal analysis that draws upon theories on real-time schedulable utilization bound, network geometry, and decentralized feedback control forms a key element of this project. The end results will be a methodology for designing dependable sensor networks able to support mission critical applications in which performance predictability is a paramount concern. The team is also committed to integrating cutting-edge research with teaching and outreach programs, leveraging off strong existing programs at Washington University and the University of Virginia. A special relation with the St. Louis Science Center will further expand our outreach efforts to students and the public at larger through exhibits placed in the information technology exhibit area. .","title":"ITR: Collaborative Research: Spatiotemporal Protocols and Analyses for Wireless Sensor Networks","awardID":"0325529","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["384032","560533"],"PO":["561889"]},"87581":{"abstract":"This award provides funds to subsidize the travel and housing expenses of students selected to participate in the Twentieth International Conference on Machine Learning (ICML), which will be held on August 21-24, 2003, in Washington, DC.<br\/><br\/>At the conference, students will present results of their research in poster sessions as part of the normal conference schedule. Members of the Program Committee will be required to visit at least three posters to provide feedback to the students. This provides the students with invaluable exposure to outside perspectives on their work, at a critical time in their research, and also enables them to explore their career objectives. This workshop contributes to the professional development of young scientists who will lead this growing field in the coming decades.","title":"Student Participant Support for the International Conference on Machine Learning 2003","awardID":"0331758","effectiveDate":"2003-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["554550","460641"],"PO":["564318"]},"87240":{"abstract":"The project will develop an integrated approach to decision making under uncertainty based on robust extraction of probabilistic spatio-temporal information from sensor network data, efficient management of collections of such information, dynamic situation assessment with the aid of these collections, and representations of decision problems about these situations in terms of partially observable Markov decision processes. This work will bring together recent advances in the fields of visual sensor processing and database technology for management of uncertain information.","title":"SENSORS: Decision Making Using Sensor Network Data - Integrating Perception and Reasoning","awardID":"0329851","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["460460","379378"],"PO":["563751"]},"96084":{"abstract":"This project investigates the detection of functional errors caused by timing faults in hardware-software systems. A hardware-software system can be defined as one in which hardware and software must be designed together, and must interact to properly implement system functionality. The widespread use of these systems in cost-critical and life-critical applications motivates the need for a systematic approach to verify functionality. The complexity of the verification problem for large, heterogeneous hardware-software systems necessitates the development of simulation-based covalidation approaches, which uniformly validate hardware, software, and their interaction. <br\/><br\/>Hardware-software systems are typically composed of several behaviors, or processes, which may be mapped to different hardware and software components. The correctness of process interactions depends on the synchronization between the executions of communicating processes. Correct synchronization depends on the adherence of the system to numerous timing relationships between inter-process communication events. Verifying these timing relationships is central to the hardware-software covalidation problem, and is the focus of this project.<br\/><br\/>The goal of this research effort is to provide hardware-software system designers with a set of CAD tools that partially automate the timing covalidation process. The CAD tools are being developed to support a generic codesign\/covalidation flow. At different intermediate steps of the codesign process, cosimulation is performed using a functional test sequence. Designers need the ability to evaluate the completeness of an existing functional test sequence, and the ability to automatically generate a functional test sequence. To support this codesign flow, we explore the following specific research objectives:<br\/><br\/>1. Develop a design fault model to describe design errors in hardware-software systems, specifically targeting errors in the timing of inter-process communication events.<br\/><br\/>2. Develop a fault simulation approach for the design fault model which evaluates the degree to which a given test sequence detects all design errors.<br\/><br\/>3. Develop techniques for automatic test pattern generation (ATPG) for a hardware-software description. The ATPG tool developed must target the proposed design fault model in order to ensure the detection of design errors.","title":"Covalidation of Timing Faults in Hardware-Software Systems","awardID":"0418725","effectiveDate":"2003-08-31","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":[251935],"PO":["562984"]},"79463":{"abstract":"Continual data streams are a generalization of continuous data streams due to two major factors: (1) irregular data bursts and (2) the need to integrate all kinds of data and metadata, instead of pure time series or multimedia. Continual data streams naturally have a trade-off between performance scalability properties and system survivability properties. On the one hand, survivability requires increased redundancy since node and network instability inevitably renders parts of the system unavailable. On the other hand, scalability requires a decrease in data redundancy, to reduce update and propagation costs. This inherent trade-off between survivability and scalability is a major research challenge due to the irregular arrival and integration of continual data streams. The project will investigate the approaches that span the spectrum between absolute consistency guarantees for replicas in traditional replication on one extreme and by-chance consistency\/zero guarantees for cached copies in traditional proxy caches on the other extreme. Formally, this approach is based on the notion of bounded inconsistency such as Epsilon Serializability. The main technical idea is to keep the distance between a replica and the original to within the specified threshold (to handle bursts) while optimizing the performance scalability and integrating heterogeneous data streams.","title":"Survivable Continual Data Streams","awardID":"0242397","effectiveDate":"2003-08-01","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7228","name":"DATA AND APPLICATIONS SECURITY"}}],"PIcoPI":["532971"],"PO":["469867"]},"89045":{"abstract":"To support the hands-on laboratory sessions, a testbed will be established that will host <br\/>widely used middleware produced by projects in the US, the EU, and in Asia Pacific <br\/>(AP). The testbed will be connected to major international science grids and thus <br\/>provide a rich environment for hands-on learning and experimentation. The laboratory <br\/>will be populated with one PC for every two students. <br\/> <br\/>The target audience consists of young researchers and practitioners (from technical <br\/>industries, research laboratories, and academic environments) who have recently <br\/>started (or are about to start) working on grid computing projects. <br\/> <br\/>The school will have a broad impact because it will prepare a substantial number of <br\/>researchers to engage in grid projects, both building and deploying grid infrastructure <br\/>and using it for applications. The students who have applied for admission are engaged <br\/>in grid projects for a wide variety of application areas, including astronomy, biology, <br\/>chemistry, earth science, medicine, and physics. There are also students who are <br\/>involved in projects that are conducting research on grid middleware and on network <br\/>technologies for grids. As a result, this school will seed many projects with people who <br\/>have gained a good understanding of grid technologies.","title":"NGS: International Summer School on Grid Computing","awardID":"0340542","effectiveDate":"2003-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5980","name":"WESTERN EUROPE PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["142322"],"PO":["551712"]},"89056":{"abstract":"Proposal: IIS-0340597<br\/>Institution: University of Illinois<br\/>PI: John Downie<br\/> Title: Workshop on the Evaluation of Music Information Retrieval<br\/><br\/><br\/>This proposal is to convene a workshop as part of the 26th Annual International ACM SIGIR Conference to be held in Toronto this summer. Music information Retrieval (MIR) is a rapidly emerging research area requiring new expertise and approaches. The amount of digital music information being created and often available via the internet has been increasing at exponential rates and has promoted new approaches within the field of information retrieval to deal with this unique content. The SGIR Conference is a major meeting on information retrieval and affords many the opportunity to participate in the workshop who might otherwise not be able to attend. Two earlier meetings in July 2002 (JCDL) anb October 2002 (ISMIR) have provided valuable background for this workshop and demonstrated the intense and growing interest in music information retrieval.","title":"Workshop on the Evaluation of Music Information Retrieval (MIR) Systems","awardID":"0340597","effectiveDate":"2003-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["559417"],"PO":["433760"]},"83270":{"abstract":"Bahar<br\/><br\/><br\/>Combining Hardware and Software Monitoring for Improved Power and Performance Tuning<br\/><br\/>Abstract<br\/><br\/>Dynamically configuring processor resources to match a program's needs has been shown to be an effective means of reducing CPU power dissipation without sacrificing performance. This research focuses on combining software profiling and hardware monitoring techniques to drive the reconfiguration process. The proposed approach is based on the premise that each has different strengths and weaknesses and their combination will give a better prediction of the dynamic behavior of an application. Using this information, parts of the processor can be run at reduced power or shut down completely when they are not needed and powered up just before they are.<br\/><br\/>Three methods that will be explored for reducing power are: (1) fetch halting, (2) deactivating parts of the logic that select instructions for execution and parts of the issue queue, and (3) deactivating some of the ALU's. The three components are interrelated because fetch halting can decrease the number of instructions that become ready to issue, which can cause some of the functional units to become idle. In addition, not halting the fetch unit can cause the issue queue to fill up and delay turning off queue entries. The goal of this research is to find effective ways of combining software and hardware techniques to significantly lower energy consumption over a range of architectures that may include features such as multithreading and multiple processors on a chip.","title":"Combining Hardware and Software Monitoring for Improved Power and Performance Tuning","awardID":"0311180","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["501145","550256"],"PO":["550859"]},"87153":{"abstract":"This project develops a general methodology for generating and evaluating confidence intervals\/bands for Receiver Operating Characteristic (ROC) curves, a common tool for comparing classification models. Usually two or more ROC curves are compared in one of three ways: by simple visual inspection without confidence assessments, by focusing on one particular point of the ROC curve and generating confidence intervals around that point, or by comparing the areas under the curves. Little work has studied the soundness of ROC confidence intervals, or their use for comparing entire curves. <br\/><br\/>This project consists of six main activities: (1) surveying existing techniques for generating confidence intervals\/bands for ROC curves, (2) creating new evaluation metrics that are more appropriate for confidence bands, (3) developing a general framework for generating and evaluating intervals\/bands, (4) developing new techniques for creating and optimizing bands, (5) creating a suite of benchmark problems, and (6) evaluating the intervals\/bands through large-scale empirical studies to analyze and to characterize their expected containment.<br\/><br\/>The work will lead to a new suite of benchmarks for these types of problems, as well as a general framework for evaluating confidence bands for ROC curves, enabling future researchers to perform similar studies in a well-understood setting. More importantly, the knowledge and techniques that this project produces will affect the many fields, such as medicine, that regularly use ROC analysis. Finally, this project will produce open-source toolkits, so that ROC studies will become much easier.","title":"Generation & Evaluation of Confidence Bounds for ROC Curves","awardID":"0329135","effectiveDate":"2003-08-15","expirationDate":"2004-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":[228052,228053],"PO":["564318"]},"86185":{"abstract":"Project Abstract<br\/>SES 0324310<br\/>William Newman, Indiana University<br\/>\"The 'Chymistry' of Isaac Newton\"<br\/><br\/>The \"chymical\" papers of Isaac Newton remain an enigma despite the pioneering studies of B.J.T. Dobbs, Richard Westfall, Karin Figala, and other scholars. Although Newton wrote about a million words--over 130 manuscripts--on the subject, only a tiny fraction of this has been examined seriously: even less has been edited. No systematic attempt has been made to determine the chronology of Newton's chymical papers, nor have his sources been examined in an exhaustive and critical manner. As a result, historians have been notoriously unreliable in determining such basic issues as which of the manuscripts are actually Newtonian compositions as opposed to being mere transcriptions or patchwork mosaics of other authors' words. Because of these and other problems, historians are in no position yet to determine what Newton's ultimate goals for his chymistry were, despite claims that he found his concept of attractive forces there or that he saw his chymistry as part of a quest to discover the vitalistic principles that underlie the cosmos. <br\/>The present proposal aims to remedy these problems by means of an innovative, integrated approach of considerable intellectual merit. The PI will do research on Newton's chymistry with the goal of composing a new book on the subject, while at the same time overseeing a project to digitize Newton's chymical papers for an online edition (under the general direction of The Newton Project at Imperial College London). In order to facilitate our understanding of Newton's chymistry, the PI will carry out research on Newton's laboratory notebooks and manuscripts with the help of Indiana University Chemistry Department (a number of Newton's experiments have already been replicated by the research team for an upcoming NOVA-BBC joint documentary). The project for editing the chymical papers will be carried out at Indiana University under the PI's direction. <br\/>The broader impacts of this project will be multiple. First, the new study will not consider Newton's interests in alchemy merely as ancillary to his physics but will place them within the history of chemistry broadly construed, which will give a new and undistorted picture of the subject. The interest of NOVA and BBC in this project shows that the public will also be eager for the results of this research. The electronic edition will vastly aid Newman and other scholars in studying the development of Newton's chymical project, since the word-searchability of the electronic edition will provide a powerful new tool for helping determine the relative chronology of the manuscripts by means of source criticism and related techniques. At the same time, employing sophisticated techniques of electronic editing already being implemented by The Newton Project at Imperial College, the editors will produce a web-based edition of great accessibility to the public. The electronic edition will enable end users to navigate through text using a search and retrieval mechanism that will link transcript in one window to an image of the autograph text in a corresponding frame. Using on-screen windows, it will be possible to manipulate the high-resolution images and juxtapose them in ways not possible with the bound originals. The advanced user interface will also allow a user to label, group, sequence, re-sequence, and annotate discrete sections of text, effectively allowing the user to create his or her own \"edition.\" The result of this project will be a resource that is available not only to professional historians and other scholars, but to anyone with an interest in the fascinating subject of Newton's chymistry, including public schools and other institutions.","title":"The \"Chymistry\" of Isaac Newton: A Proposal for STS 01-159 and International Digital Libraries 02-085","awardID":"0324310","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"1353","name":"Hist & Philosophy of SET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["456230"],"PO":["563324"]},"78573":{"abstract":"The long-term career goal of the PI is to help transform the Internet into a robust, stable, and secure routing infrastructure that delivers highly reliable and predictable performance. Considering the critical role that the Internet plays in our day-to-day lives, the current routing architecture is surprisingly fragile. Fiber cuts, faulty or mis-configured equipment, and malicious attacks (e.g., the Nimda worm) have led to a widespread loss of global connectivity. To achieve our vision, we have developed the following four research agendas: <br\/><br\/>1. PI argue that an essential starting point is a thorough characterization of wide-area failure scenarios and how much they impact the traffic-forwarding plane. Through the PI's collaboration with Sprint, will monitor an operational Tier-1 Internet Service Provider's backbone to collect routing and traffic data. Based on successive conditioning of the data, will derive a wide-area failure (WARF) model that can be used by the research community to generate realistic failures in simulation or testbed environments.<br\/><br\/>2. PI will undertake a complementary effort to design a statistical BGP anomaly detector that automates the process of differentiating abnormal and expected routing behavior. The design follows basic intrusion detection principles in creating a historical profile and performing short-term testing. <br\/><br\/>3. PI will investigate an alternative approach to policy routing by designing and developing an Overlay Policy Control Architecture (OPCA) that facilitates fast route convergence and traffic engineering. OPCA will allow the concurrent use of multiple types of metrics in intra- and inter-domain routing, and illustrate that such functionality is warranted in the IP core.<br\/><br\/>4. PI will design a Routing Introspection and Feedback System (RIFS) that provides timely feedback to higher-layer entities such as overlay networks and transport or application layer proxies. will extend our study to explore a hybrid channel coding and retransmission scheme to optimize video streaming based on detection of failures and routing loops. <br\/><br\/>The outcome of this work strives to enable Internet-based distributed computing by making the core Internet more reliable and stable. Effective routing across heterogeneous networks (including wireless and satellite) is the key to truly ubiquitous connectivity, which will have a broad impact on societal applications. The hypothesis and methodologies tested in this project will help advance the knowledge in the field of wide-area routing and form a foundation for analyzing the reliability issues of other large-scale distributed systems. Will make the failure models, tools, and prototypes developed in this project available to other researchers online and via publications and training workshops. <br\/><br\/>The PI's educational mission is to train undergraduate and graduate students to become capable network engineers by incorporating real-life operational experience and anecdotes of wide-area Internet behavior into classroom teaching. This includes developing a capstone design course that gives students hands-on experience in network management and routing modules. The PI will actively recruit underrepresented women and minority students into the engineering curriculum and her research projects by collaborating with the Women in Engineering (WIE) and the Mathematics, Engineering, and Science Achievement (MESA) programs at U. C. Davis.","title":"CAREER: Robust, Stable and Secure Routing via a vertically integrated monitoring and introspection system","awardID":"0238348","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["551132"],"PO":["565090"]},"87098":{"abstract":"This proposal seeks support for the analysis of previously collected quantitative and qualitative data on how people use communications technologies to construct their availability and manage the boundaries between work and everyday life. The project is risky and exploratory because the relationship between technology use and the construction of personal boundaries has never been examined. The project promises to yield important insights into how new technologies affect the ecology of everyday life. In particular, the study could significantly influence the literature on work and family by drawing attention to the role technologies play in the social construction of boundaries. It could also have important societal impacts in helping employers and employees to better understand how new technologies could enhance the quality of everyday life.","title":"Communication Technology and the Social Construction of Availability","awardID":"0328662","effectiveDate":"2003-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["518944"],"PO":["564456"]},"82270":{"abstract":"This project combines new design representations and computational approaches to enable computational conceptual design. The design representations and computational methods leverage the constant increases in computational power and information retrieval reasoning algorithms. Descriptive methods, stored knowledge, and algorithmic reasoning provide the potential for a computational theory of conceptual design that could greatly benefit the designer during difficult stages of concept generation. The underlying theme is the combination and formalization of function-based synthesis, constraint management and state space search. The primary objective of the work is to create a computational theory of conceptual design that can compute design alternatives. The computation will result in a comprehensive space of concept variants and search it for feasible candidates.<br\/><br\/>The activity of concept generation is one of the cornerstones of engineering design. Until recently, the only resources available to a designer during conceptual design were personal experiences and innate abilities. While the designer's resources have advanced significantly in the last three decades, there is still a lack of continuity between computational design tools and conceptual design methods. Many formal methods of conceptual design have yet to be realized as computational algorithms. <br\/><br\/>This research will develop representations and computational methods that allow design concepts to be created from the functional description of a needed product. Through the development of a design knowledge repository and a concept generator that uses the stored knowledge, this research extends the current understanding of the relationship between function and form and codifies it. Also, novel component representations enable computers to determine component compatibility and thus synthesize a concept variant. Additionally, this work is useful for comparison to human design behaviors, as it is built on commonly used design practices.<br\/><br\/>This work is both basic and practical in nature. Thus, the broader impacts extend beyond publication to the usage of the resultant knowledge, methods and tools in education, engineering practice and research. For example, students will be able to use the concept generator to create solutions that, because of their limited experience, they might otherwise not have developed. These solutions will expose students to different disciplines and engineering and scientific domains. The results of this research impact industry and research in a similar manner. In both cases, the research can be used to generate a broader array of solutions much more quickly than would have been possible without it.","title":"Collaborative Research: Creating a Computational Theory for Conceptual Design","awardID":"0307419","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["540515","527806"],"PO":["387198"]},"83370":{"abstract":"This project is focused on efficient algorithms for performing trusted<br\/>computations in a networked environment, with applications to<br\/>cyber-security.<br\/><br\/>Intellectual Merit.<br\/><br\/>The following topics will be investigated:<br\/><br\/>- Authenticated data structures and algorithms. We will study methods<br\/> for authenticating the results of data structures and algorithms,<br\/> even when those computations are performed by an untrusted third<br\/> party on behalf of a trusted source.<br\/><br\/>- Audited algorithms. Bringing together recent research on program<br\/> checking and space-efficient computations for streaming data, the<br\/> project will explore a new computational framework in which<br\/> computations are performed by a community of untrusted users and are<br\/> checked by an external auditor with limited computational resources.<br\/><br\/>Broader Impacts.<br\/><br\/>The proposal is directed at a subject area of critical importance to<br\/>society -- methods for efficiently maintaining the security of<br\/>computations and computational resources, including the networks that<br\/>communicate vital data.","title":"Collaborative Research: An Algorithmic Approach to Cyber-Security","awardID":"0311720","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["521484"],"PO":["499399"]},"86450":{"abstract":"There are potentially valuable nuggets of information hidden in document collections generated by multiple authors, working independently at various times. Such information is not explicit, but can be inferred by following chains of concepts and associations. Users surfing the web may need to be monitored with the goal of deriving their true information need, which could be motivated by malicious intent. The problem of unintended information revelation (UIR) is a special case of text mining where the documents represent some pre-selected subset of interest to a user, generated through purposeful querying or surfing. The goal is to quantify the information revealed by this subset and to detect significant chains of concepts and associations. <br\/><br\/>This effort focuses on the development of a UIR framework and toolkit that covers the following areas: (i) probabilistic frameworks for concept chain graphs (CCG): a new information representation conducive to text mining; (ii) automatic construction of CCGs from representative document collections using pre-existing ontologies and machine learning techniques in information extraction; (iii) discovery tools that quantify information revealed and reveal hidden, information rich paths within the CCG, and (iv) interactive visualization tools for the CCG. This new framework facilitates better visualization and analysis of information than existing information retrieval (IR) representations. <br\/><br\/>This project should impact several applications, most notably homeland defense applications. The UIR toolkit has the potential to expose sensitive information available on unclassified websites. It can also be used to ascertain whether that information is benign or safe to disseminate. Applications in discovery from scientific documents are also enabled.","title":"ITR: Unapparent Information Revelation - Creation, Visualization and Mining of Concept Chain Graphs","awardID":"0325404","effectiveDate":"2003-08-15","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T472","name":"CIA-KNOWLEDGE DISC & DISSEM PR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V240","name":"CIA-KNOWLEDGE DISCOVERY & DISS"}}],"PIcoPI":[225943,225944,"429487",225946],"PO":["565215"]},"87231":{"abstract":"ABSTRACT<br\/>0329794<br\/>Lixin Gao<br\/>Jie Wu<br\/>U of Massachusetts Amherst<br\/><br\/>Spurred by the fast increasing capabilities and declining costs of computing and communication devices, it becomes increasingly viable to embed sensors in physical devices and link these sensors through wireless networks. These sensor networks can be deployed for a wide range of applications that can improve quality of life, and even save lives. These applications include healthcare (e.g., health monitoring and coordination among doctors and nurses), aircraft flight control, weather forecasting, home appliance control, and protection against bioterrorism. One of the key challenges in the deployment of sensor networks is how to prolong the lifetime of the networks. Sensor networks will stress power sources because of the their <br\/>need for long operating lifetimes and high energy density. Therefore, energy efficiency is critical for the wide deployment of sensor networks. <br\/><br\/><br\/>The investigators study energy management techniques for sensor networks. The key idea is to take advantage of the physical layer design that facilitates the combining of partial information. A node can receive <br\/>several partial signals and combine these signals to retrieve the complete signal. This is referred to as hitchhiking. Hitchhiking can potentially conserve energy for transmitting data in sensor networks. <br\/>By the effective use of partial signals, a packet can be delivered with less nodes and\/or less transmission power at each node. The investigators will systematically study the energy management techniques for sensor <br\/>networks as follows. First, the investigators will study the physical layer design of hitchhiking. <br\/>Second, the investigators will study power control for broadcast networks and unicast networks. <br\/>Third, the investigators will study power saving protocols to reduce the energy consumption for idle modes.","title":"Collaborative Research: SENSORS: Energy Efficient Communication in Sensor Networks","awardID":"0329794","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["564706",228280],"PO":["564898"]},"86032":{"abstract":"This is an experimental program centered on the implementation and investigation of continuous-variable (CV) quantum information. This program is based on the use of ultra-stable optical parametric oscillators (OPO) above threshold, emitting bright entangled fields. Significant experimental challenges associated with these systems, such as the need for exquisite frequency- and intensity-stability of the OPO, have been overcome recently by our group by use of brute force approaches involving sophisticated optical design and electronic servo-stabilization. The objectives are the generation of CV GHZ states, the realization of a quantum optical teleportation network (including CV entanglement swapping), and the implementation of quantum error correction. These studies fit in the broader scope of applying quantum optical CV to quantum computing.<br\/><br\/>Broader impacts of the proposed activity comprise graduate education in Physics and the development of interdisciplinary collaborations with other Departments and Schools at the University of Virginia, in particular in the context of the University of Virginia 2020 Initiative for the Sciences. In addition, the PI is active in the teaching and dissemination of quantum physics and quantum information in Virginia high schools.","title":"Continuous-Variable Quantum Information with Bright-Beam Entanglement","awardID":"0323623","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["512011"],"PO":["521045"]},"87143":{"abstract":"Mobile robots (mobots) have a wide range of applications in humanitarian operations, including search and rescue operations. To successfully accomplish these missions, mobots must maintain high mobility by carrying their own energy sources, and they must make efficient use of their limited energy resources in order to be capable of operating for extended periods of time. In this project, the PI and his team will investigate a new methodology of constructing distributed energy-efficient mobots. They will design, implement, and evaluate a team of mobots controlled by using biologically inspired engineering principles, and where inter-mobot communication is conducted through wireless ad hoc networks with peer-to-peer overlay protocols. Speci?cally, the team will study:<br\/><br\/>(1) Biologically inspired algorithms for sensing, planning, coordination, and control. This is motivated by the observation that many creatures, through natural selection, use energy efficiently. Soft computing and multi-agent systems will be adopted to manage the team coordination as well as the activities of individual mobots. Neuro-fuzzy logic will be used to control multiple robots with energy efficiency.<br\/><br\/>(2) Energy-efficient, scalable, and robust wireless networks for inter-mobot communication. Peer-to-peer overlay networks will be constructed on mobile ad hoc networks to support the high mobility and to handle the possibility of losing or adding mobots during missions. Packets will be transmitted through energy-efficient routes; these routes will be dynamically determined based on the current locations and the remaining energy of the mobots.<br\/><br\/>(3) Energy models for each component in a mobot, the interactions among the components inside each mobot, and the interactions among mobots. These models will be used to evaluate the energy efficiency of the control algorithms developed in (1) and the communication mechanism presented in (2). In addition, a comprehensive simulator will be constructed to study a large number of mobots: the team movement, con?guration, coordination, and the communication among them. The simulator will also validate whether biological systems indeed use energy efficiently.<br\/><br\/>The outcomes of this research will consist of: (i) biologically inspired neuro-fuzzy control algorithms to improve energy efficiency; (ii) efficient inter-mobot communication mechanisms; (iii) three mobot prototypes for experiments and instrumentation; and (iv) a detailed simulator to study various scenarios with a large team of mobots.<br\/><br\/>Broader Impacts: This project has broader impacts on society, education, and outreach. Mobots will be able to operate for signi?cantly longer times in humanitarian missions and outer space exploration. Research results will be incorporated into graduate and undergraduate courses at Purdue, and the lab will host an open session to local K-12 students every year to demonstrate the mobot prototypes and to encourage participation by students in engineering and science activities.","title":"Distributed Energy-Efficient Mobile Robots","awardID":"0329061","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["335186","550994","550994","540778"],"PO":["565227"]},"79476":{"abstract":"Digital watermarking is being investigated as an underlying technology for digital rights management systems (which provide content authentication, copy and access control, or proof of ownership). This proposal aims to develop a complexity-theoretic foundation that allows rigorous and quantitative studies of security, transparency, efficiency and capacity of digital image watermarking systems. Unlike previous works on modeling watermarking, two fundamental constraints on the insertion and extraction algorithms are taken into account, namely, they must be fast and also preserve the perceptual fidelity of their inputs. A key effort of this research will be to obtain formal characterizations of the class of algorithms which preserve perceptual fidelity of input images under various distortion metrics based on current theories of vision. Another goal is to settle the current debate as to whether computationally secure digital image watermarking systems exist, and if so, how to design them. Other planned activities include characterizations of tradeoff relationships between transparency, security, and capacity; applications to approximate data matching problems and indexing\/querying multimedia databases and libraries; and development of an undergraduate-level course in digital watermarking at Santa Clara University.","title":"A Complexity-Theoretic Foundation for Digital Image Watermarking Systems","awardID":"0242435","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7228","name":"DATA AND APPLICATIONS SECURITY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[206931],"PO":["565136"]},"89277":{"abstract":"Quantum computation is often viewed as the next frontier in computing and communication. Consider the following:<br\/><br\/>1. Some quantum algorithms run asymptotically faster than their classical counterparts. The most striking example is Shor's number-factoring algorithm. This algorithm, in theory, can break the widely used RSA cryptosystem (used in \"Internet codes\") in polynomial time. Significant challenges remain to physically implement Shor's algorithm for factoring large numbers, and it is currently unclear which technology is most promising.<br\/><br\/>2. Quantum cryptography provides fundamentally more secure communications. Quantum key distribution (QKD) has been demonstrated at distances over one mile in free space and over 100 miles in fiber. The Swiss company IdQuantique is selling QKD hardware and the U.S. company MagiQ Technologies has recently announced related products.<br\/><br\/>3. Quantum computation can, in principle, be done at a much smaller scale than contemporary semiconductor devices. One molecule in liquid NMR technologies or one photon in optical implementations can perform quantum computation or store quantum information.<br\/><br\/>4. Classical computation is commonly used to model numerous aspects of the physical world - from sending mail and reproducing paintings to simulating natural disasters and armed conflicts. Yet, classical computation is fundamentally limited in its ability to simulate quantum-mechanical effects, such as photosynthesis, radioactive decay and nuclear fusion. Quantum computers may offer more efficient simulation in this context. <br\/><br\/>Quantum circuits currently constitute a dominant model for quantum computation, and our proposed work addresses automatic synthesis of quantum circuits. This work applies to any quantum implementation technology, but it also can take into account specific constraints and optimizations entailed by popular technologies. In particular, practical implementations of known quantum algorithms may require minimizing the use of gates that are expensive, slow or especially faulty in particular technologies. <br\/><br\/>Quantum computations can be described by unitary matrices. In order to effect a quantum computation on a quantum computer, one must decompose such a matrix into a quantum circuit, which consists of elementary quantum gates connected by Kronecker (tensor) and matrix products. Those connections are often represented using quantum circuit schematics. The matrix and graph-based notations for quantum circuits are analogous to how classical logic circuits are modelled by Boolean polynomials, e.g., during logic synthesis. Classical logic synthesis uses algorithms for factoring polynomials, and we therefore guess that quantum synthesis algorithms will benefit from matrix factorizations. Our preliminary research shows that this is, indeed, the case. Motivated by our findings, we propose to take a deeper look at the algebraic theory behind matrix factorizations (SVD, QR, polar and others) and possible applications to quantum circuit synthesis.","title":"SGER: Automated Synthesis of Quantum Circuits","awardID":"0341784","effectiveDate":"2003-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["508348","549690"],"PO":["562984"]},"83250":{"abstract":"Integrity Monitoring and Recovery Techniques for Error-Prone Submicron Microprocessors<br\/><br\/>As advances in VLSI technology reduce circuit dimensions dramatically, processor chips become more vulnerable to soft errors. Thus dependability is becoming an increasingly important quality measure of microprocessors. A transient and\/or permanent processor failure could have diverse impacts on our daily lives. The goals of the proposed research are: <br\/><br\/>(1) to characterize soft error behavior on commercial microprocessors through fault injection experiments; <br\/>(2) to provide a guideline for exploiting soft error susceptibility in integrity checking strategy and predicting the error characteristics from the processor's architecture; and <br\/>(3) to develop comprehensive micro-architectural solutions.<br\/><br\/>We will investigate individual components of the processor with circuit-level approaches. Subsequently, we will study the area overhead vs. fault coverage trade-off to show the effectiveness of our proposed solutions. We will be developing specific tailored dependability solutions that are independent of technology and based on fault occurrence and error propagation characteristics of a given processor architecture. The techniques are easily adapted to future generations of architectures.<br\/><br\/>Since use of microprocessors and micro controllers is very wide spread and affects every aspect of our lives, improvement in the dependability of such systems would have the widest possible broader impact.","title":"Integrity Monitoring and Recovery Techniques for Next Generation Submicron Microprocessors","awardID":"0311061","effectiveDate":"2003-08-01","expirationDate":"2008-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["521840"],"PO":["550859"]},"82040":{"abstract":"The power of the national information infrastructure has expanded<br\/>enormously over the last decade. Commercial Internet service and<br\/>government-sponsored advanced networks for research and education<br\/>support a range of national priorities. Unfortunately, rapid<br\/>development and deployment of robust, adaptive network software is<br\/>hampered by a fundamental obstacle: prototype systems are difficult to<br\/>evaluate due to scale and complexity of their host environment---the<br\/>Internet.<br\/><br\/>This proposal seeks to remove this obstacle by constructing a software<br\/>environment for evaluating prototype network software systems under<br\/>realistic, controlled, repeatable conditions through scalable Internet<br\/>emulation. The proposed system, ModelNet, emulates a wide-area<br\/>network on a high-speed cluster, enabling researchers to deploy<br\/>unmodified software prototypes in a configurable Internet-like<br\/>environment and subject them to faults and varying network conditions.<br\/><br\/>This research will first investigate techniques for scaling network<br\/>emulation to thousands of unmodified applications with aggregate<br\/>communication bandwidth of over 10 Gb\/s. Second, it will enable the<br\/>community to leverage large-scale network emulation as a primary<br\/>technique for rapidly developing and evaluating next-generation<br\/>Internet services and applications. Finally, the research will seek<br\/>fundamental improvements in network service robustness and performance<br\/>by providing a controlled environment for subjecting network services<br\/>to a range of realistic deployment scenarios.","title":"Evaluating Global-scale Distributed Systems using Scalable Network Emulation","awardID":"0306490","effectiveDate":"2003-08-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["553906","485593"],"PO":["309350"]},"83371":{"abstract":"CCR-0311723<br\/><br\/>Vulnerabilities Analysis<br\/><br\/>Matt Bishop<br\/><br\/>This project will develop and test a new classification scheme<br\/>for security vulnerabilities in existing computer systems and<br\/>software. A vulnerability exists when a system meets certain<br\/>conditions, the precise conditions dictating the nature of the<br\/>vulnerability. The classification scheme will be based upon these<br\/>conditions. The goal of this research is to: (1) determine<br\/>whether every vulnerability has a unique, minimally-sized set<br\/>of such conditions; (2) determine whether vulnerabilities share<br\/>these conditions; and (3) determine whether, for a large enough<br\/>set of vulnerabilities, the number of conditions is less than<br\/>the number of vulnerabilities. The methodology will be to<br\/>examine vulnerabilities in open source systems and programs, and<br\/>determine the exact conditions under which a vulnerability<br\/>can be exploited. The expression of the conditions will be refined<br\/>iteratively, as more is learned about the conditions needed to<br\/>exploit vulnerabilities.<br\/><br\/>The significance of this work is that it will lead to a deeper<br\/>understanding of why vulnerabilities occur in systems, how to<br\/>detect them, and how to prevent them. Its broader impact is that,<br\/>if the hypotheses are true, negating conditions on a system could<br\/>eliminate vulnerabilities not known at the time. Vendors and<br\/>security analysts would be able to use the approach we will develop<br\/>to test systems for vulnerabilities more readily than the current,<br\/>hit-and-miss methods. Finally, this work would provide a<br\/>more rigorous basis for developing and teaching methods of<br\/>writing programs with fewer vulnerabilities than occur now.","title":"Vulnerabilities Analysis","awardID":"0311723","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["560876"],"PO":["543507"]},"83261":{"abstract":"LGORITHMIC SYNTHESIS OF EMBEDDED CONTROLLERS<br\/><br\/>In recent years, microprocessors have invaded the physical world, resulting in <br\/>sophisticated but complicated networked embedded systems that defy theoretical <br\/>understanding, resulting in inadequate design tools for the modern embedded <br\/>system engineer. Embedded systems require the development of new theories, <br\/>methods, and tools providing the correct understanding of these systems and<br\/>accelerated analysis and design methods in order to ensure safety<br\/>but also substantially decrease their design time. Embedded systems require very novel, very challenging specifications that have <br\/>to deal with synchronization, sequencing, and temporal ordering of different<br\/>tasks. Mathematically formulating such desired specifications cannot be <br\/>achieved using traditional mathematical formulations in control theory. On the <br\/>other hand, computer aided verification has popularized the use of several <br\/>temporal logics to describe complex specifications. However, the emphasis has <br\/>been on verification of these properties for purely discrete systems, and not <br\/>on synthesis for systems with a continuous component.<br\/><br\/>In this research, a novel approach for automatically synthesizing hybrid <br\/>controllers is pursued in order to satisfy specifications that are expressed <br\/>in temporal logics. In particular, methodologies are developed to extract <br\/>finite abstractions of linear control systems, that will be used to design <br\/>controllers meeting the desired temporal logic specifications. Contrary to <br\/>other approaches, this project considers specification dependent abstractions <br\/>for continuous control systems as opposed to continuous dynamical systems. The <br\/>proposed framework will provide algorithms and tools for the computation of <br\/>discrete controllers, which by refinement will lead to embedded, hybrid <br\/>controllers for the original system while providing performance and <br\/>correctness guarantees.<br\/><br\/>The educational agenda of the proposal focuses on the development of a cross-<br\/>departmental, undergraduate, signals and systems course that broadens the <br\/>definition of systems in order to capture software and hardware systems in <br\/>addition to traditional control or communication systems. This course has been <br\/>carefully coordinated with recent curriculum changes and aims at the <br\/>educational uniformity of signals and systems concepts in both the discrete and <br\/>the continuous world.","title":"Algorithmic Synthesis of Embedded Controllers","awardID":"0311123","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["526896"],"PO":["561889"]},"82051":{"abstract":"The goal of this project is to develop fast and accurate physics-based parallel transient electromagnetic solvers that are geared towards applications to high-speed circuits. This is being achieved via a combination of high performance parallel algorithms, novel advances in numerical schemes that permit hierarchical computation and finally, the hybridization of different numerical techniques. More specifically, the following objectives are being pursued: (i) development of novel numerical schemes that reduce the overall computational work and the corresponding parallel schemes; (ii) development of parallel and numerical methods for analyzing transient fields in diffusive and dispersive material media; (iii) development of parallel methodologies for integrating differential equation and integral equation based schemes such that one can reap the advantages of both; (iv) and finally, integrating the EM solver developed in the last item into the circuit simulation tool SPICE, to enable fullwave EM simulation of circuits. The principal impact of the proposed research is the development of high performance transient electromagnetic analysis tools that are applicable to a variety of design and analysis problems. The techniques developed are being used to analyze issues in high-speed circuits including on-chip signal integrity, non-linear devices, cross-talk, reflections, and non-linear terminations.<br\/><br\/>Electromagnetic (EM) phenomena constitute the physical underpinnings of applications ranging from electrical to electronic to communication to computer technologies and are completely described by Maxwell's equations. Fast and accurate physics-based simulation tools offer a second modality of investigation into electromagnetic phenomena, and are rapidly becoming indispensable in civilian and military R & D settings. As a part of this endeavor, researchers at Michigan State University and Iowa State University are collaborating on developing an arsenal of fast and accurate simulation tools that permit on-the-fly optimization that can be used for rapid design prototyping of electromagnetic devices. To this end, novel numerical methods for transient electromagnetic analysis and algorithms to parallelize these are being developed. The techniques developed are being applied to the design and analysis of electromagnetic devices.","title":"Collaborative Research: Parallel Hybrid Differential and Integral Equation Based Solvers for Time Domain Electromagnetic Analysis with Application to High-Speed Circuits","awardID":"0306512","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["565135"],"PO":["381214"]},"83294":{"abstract":"Large communication networks, such as the Web or the Internet, give rise to <br\/>a number of challenging algorithmic questions. Our increased dependence on<br\/>networks means that reliability and availability of the communication<br\/>infrastructure is becoming more critical than ever. This project will consider<br\/>some of the algorithmic question raised by such networks. The goal of<br\/>the project is to develop algorithms with provable performance guarantees.<br\/><br\/>The project focuses on two closely related issues. Over the last 20 years or <br\/>so, many powerful techniques have been developed for approximation algorithms. <br\/>This project focuses on developing new algorithmic techniques, and aims to <br\/>develop new techniques for approximation algorithms, and obtain large improvements <br\/>in the achievable solution quality for a number of important problems, <br\/>where the previous techniques failed.<br\/><br\/>A second goal of the project is to develop algorithmic techniques for the <br\/>distributed, and selfish environment of large networks, like the Internet. <br\/>In such settings the traditional approach of algorithm design is not <br\/>appropriate: there is no single entity that has the information or the power <br\/>to run such an algorithm. While centralized algorithms cannot be used directly <br\/>in such selfish environments, there are very strong ties with certain <br\/>algorithmic techniques and some of the central questions in algorithmic game <br\/>theory. This project considers two of these issues, cost-sharing and the<br\/>price of anarchy. The project will develop new methods for designing<br\/>cost-sharing algorithms, and understanding what environments lead to<br\/>low price of anarchy. The cost-sharing problem is closely related to the <br\/>primal dual method of approximation algorithms. Evaluating the price of <br\/>anarchy is closely related to approximation algorithms based on local search.","title":"Approximation Algorithms and Applications in Network Games","awardID":"0311333","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["516907"],"PO":["499399"]},"87111":{"abstract":"Many of today's educational standards, such as those for science education, call for student use of computational tools for doing substantive inquiry-based activities to develop a better understanding of science practices. Combating the reality of poor student-to-computer ratio in schools and occasional access to technology, handheld computers (sometimes referred to as PDAs) offer an intriguing, more pervasive solution to the computer access problem given their increasing functionality and decreasing costs. However, technology aimed at learning must also be supportive of learner needs and be designed from a learner-centered perspective to develop scaffolds for those tools, with software features (e.g., prompts, process maps) that physically realize literature-based conceptual scaffolding strategies (e.g., \"visualize complex tasks\") aimed at supporting learners to mindfully do and learn complex new activities and content. This project explores the design and assessment of effective scaffolds for handheld-based software tools in the context of science education. While a significant research community has explored desktop-based scaffolds, we lack similar design information for handheld-based scaffolds. User interface design decisions for desktop computers do not necessarily \"scale down\" to handheld computers due to differences in screen size, input methods, processor speed, etc., so new design guidelines are needed to develop handheld-based scaffolds. In this study the PIs will engage in an established learner-centered design methodology to design scaffolds for four handheld-based science tools. They will classroom test those tools in Detroit middle schools, and assess the impact of those scaffolds on student science work. Design guidelines will be coupled with assessment about the \"effects with\" the scaffolds (i.e., how do students work with the individual scaffolds to do their work?) and the \"effects of\" the scaffolds (i.e., what did students learn after using the scaffolded tools?). The main outcome will be to develop and articulate design guidelines about scaffolds for handheld computers. <br\/><br\/>Broader Impacts: The broader impacts of the proposed work are: to impact HCI research by shedding light on effective and ineffective user interface decisions for the \"non-desktop\" computational devices that are becoming more prevalent, and also by distilling a set of design guidelines that articulate different scaffolding approaches for handheld tools and assessment information (from classroom testing) describing the impact those scaffolds had on learners; to advance discovery while promoting teaching, training and learning by integrating research activities into science education and teaching at the K-12 level: to broaden participation of under-represented groups by bringing innovative technologies to under-represented classrooms in the Detroit Public Schools; and to enhance scientific and technological understanding by disseminating the resulting software, curricula, and assessment information to teachers, school board members, and other educational policy makers.","title":"Design Guidelines for Learner-Centered Scaffolding on Handheld Computers","awardID":"0328797","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["561136","549235","452599"],"PO":["565227"]},"78564":{"abstract":"In this research the PI will investigate the fundamental tradeoff, lower bound, and impossibility results in important areas of computer networks. Such results are important since they typically end the vigorous search for a better algorithm that does not exist, or lead to provably optimal algorithms. They will also help clarify the fundamental issues and structures of the problem domain under study. Obtaining such results is challenging because they require a deep understanding of the domain knowledge and a solid background in theoretical computer science.<br\/><br\/>In the beginning, the PI will focus on lower bound and tradeoff results in two main areas: (1) packet scheduling, and (2) peer-to-peer (P2P) networks. In the research on lower bound problems in packet scheduling, the PI plans to extend the accomplished tradeoff results between delay bound and computational complexity to a much stronger and more practical computational model. The PI will also look into the complexity of establishing other QoS guarantees such as bandwidth, jitter bound and short-term fairness. Finally, the PI will study the complexity needed to exactly track the GPS (General Processor Sharing) clock, and\/or to approximate GPS time within a certain error range.<br\/>In the research on lower bound problems in P2P networks, the PI plans to continue his research on the tradeoffs between the routing table size and network diameter in P2P networks, and answer the fundamental research questions such as \"what is tradeoff between the fault-tolerance overhead of the P2P routing algorithms and their routing efficiency?.\" In addition to investigating lower bound and tradeoff problems in these two areas, the PI will apply the insights and expertise obtained to other areas of networking such as application-level multicast and mobile computing.<br\/><br\/>The goal of the proposed project is not only to advance research on theoretical and foundational aspects of networking, but also to educate and prepare graduate as well as undergraduate students for identifying, characterizing and answering such theoretical questions. The PI observes that there is limited coverage of such issues in the conventional networking curriculum. To fill this gap, the PI will actively take part in synergistic educational activities including curriculum development, course teaching, student mentoring, and professional skill development.<br\/><br\/>Since the proposed work on lower bounds and tradeoffs is fundamental research, it has the potential to significantly impact the networking field in multiple dimensions. First, such results delineate feasible \"regions\" in which an algorithm can achieve with given assumptions. Second, during this process, it significantly clarifies the issues and structures of the problem, which may lead to new problems to solve. Finally, in cases where existing algorithms are not yet optimal, the tradeoff research guides researchers to find algorithms that are better or optimal. Although the proposed research is theoretical in nature, it has important applications to real algorithms and protocols, and constitutes a fundamental contribution if successful. The broader impact of the work includes the PI's sustained outreach efforts to broaden the participation of under-represented groups (HBCU institutions) in research and education, and to engage undergraduate students in theoretical networking research.","title":"CAREER: Fundamental Lower Bound and Tradeoff Problems in Networking","awardID":"0238315","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["349186"],"PO":["402055"]},"78586":{"abstract":"The proposed program concerns distributed network architectures that are based on reinforcement learning by individual users. The main goal of the program is to develop a general framework for dynamic and distributed resource sharing mechanisms that are suitable for large networks. A generic formulation is considered in which users access network resources in one of several alternative ways. Each user is restricted to observe its own interpretation of the outcomes only, where this outcome depends also on the actions of other users. The proposed framework involves non-cooperative decision making by network users based on this local information, in turn it is scalable in the size of the network. The research program will identify macroscopic dynamics of the network in terms of nonlinear differential equations that are asymptotically exact in algorithmic parameters. The limit system is closely related to certain dynamical systems that arise in the context of evolutionary biology. Successfully completed program will identify possible equilibrium regimes, will characterize distributed algorithms that lead to stable network operation, and will develop network design and management guidelines that maintain desired operating regimes for the network. Robustness of the proposed algorithms will be investigated analytically, and verification of obtained results will be carried out via simulations and experiments.<br\/><br\/>Educational aspects of the proposed program involves course development and teaching with the ultimate goal of a strong research program and close industrial collaboration, mentoring at both graduate and undergraduate levels, and active research participation from undergraduate students.","title":"CAREER: Scalable Architectures for Self-Managed Networks","awardID":"0238397","effectiveDate":"2003-08-15","expirationDate":"2009-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["451601"],"PO":["565090"]},"78487":{"abstract":"In this proposal the goal is to increase the capacity of ad hoc networks by efficiently using power control and smart antennas. Traditionally there has been a clear separation between the layers of the protocol stack. In particular, the design and development of protocols at the physical and higher layers has tended to proceed independently. In order to exploit the functionalities provided by a particular layer it is important that the other layers be made aware of the features at the other layers. In particular, traditional protocols do not exploit the ability to tune transmission power or the presence of smart antennas effectively. In fact, many of them fail to function correctly or suffer from degraded performance. The PI propose cross-layer architectures that would consist of new inter-dependent protocols at the MAC, routing and the transport layers that can effectively exploit the aforementioned physical layer features. <br\/><br\/>First the proposer propose a power aware cross-layer architecture wherein the layers jointly co-operate to dynamically choose the correct transmission power levels in response to both short term and long term factors. Short-term power management is based on increasing the power levels temporarily to re-establish links that fail due to mobility to provide the higher layer protocols a short grace period to recuperate from failures. Towards this the proposer propose methods that help in determining whether link failures are due to mobility or are induced due to congestion effects. Based on such determinations, intelligent decisions on how the power levels ought to be tuned are taken. Long-term power management is based on choosing transmission power levels for long periods of time such that the topology of the network is shaped to achieve the best throughput. The choice of the power levels are jointly made based on interactions between the layers such that appropriate trade-offs between performance metrics such as throughput and power consumption are achieved. Our methods are applicable in cases wherein the nodes in the network are heterogeneous in terms of power capabilities, i.e., the maximum powers with which different nodes are able to transmit are potentially different. <br\/><br\/>Second, the proposer propose a cross-layer architecture that exploits the presence of smart antennas. The architecture facilitates close interactions between the MAC, routing and transport layers to exploit both directional transmissions and receptions in a highly dynamic environment. The interactions help choose the right local connectivity to ensure that a high level of spatial re-use of the spectrum is achieved while keeping the communication overheads fairly small. <br\/><br\/>The educational plan is expected to enhance awareness of wireless networking among their students and motivate them to further explore the exciting field of wireless networking. In addition, outreach activities are expected to increase the awareness of wireless networking in the local community.<br\/><br\/><br\/> <br\/>Broader Impact:<br\/><br\/>The research will have a big impact on ad hoc network design by bridging the gap between the physical layer and higher layer technologies. It is expected that the cross layer architectures that we will develop will lead to a significant enhancement in the capacity of ad hoc networks. This in turn, may be expected to further the potential of the widespread deployment of these networks. Examples of such deployments may be in vehicular networks, disaster recovery missions, and tactical battlefields missions. Furthermore, the mechanisms that will be developed are expected to provide considerable power savings that would reduce battery drainage and thereby extend the longevity of the network. <br\/><br\/>It is envisioned that this work will motivate future research and development in terms of other possible cross-layer technologies wherein higher layer protocols can exploit other physical layer functionalities such as variable modulation techniques or the ability to dynamically vary the level of error control coding. <br\/><br\/>Research agenda is complemented by a strong educational plan that includes (a) the enhancement of the content of existing courses in networking and the initiation of new and exciting courses on wireless networks at both the undergraduate and graduate levels (b) increase our outreach activities to bring wireless technology to the local community by demonstrations and talks at local high schools and (c) close collaboration with industry to improve our students' awareness of commercial systems.<br\/><br\/><br\/>Major Intellectual Contributions: <br\/><br\/>The major intellectual contribution in this proposal is to exploit cross-layer dependencies to provide interactions between layers to fully exploit features at the physical layer in mobile ad hoc networks. In particular the proposer focus on the presence of smart antennas and the ability to tune transmission power levels at the p","title":"CAREER: Cross-Layer Architectures for Power Adaptive and Smart Antenna Equipped Mobile Ad Hoc Networks","awardID":"0237920","effectiveDate":"2003-08-15","expirationDate":"2009-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["550738"],"PO":["565090"]},"83361":{"abstract":"CCR-0311671<br\/><br\/>Balancing Privacy and Analysis in Data Sanitization<br\/><br\/>Matt Bishop<br\/><br\/>When handling an intrusion, one organization may need to share<br\/>logs and network traces with other organizations. However, the<br\/>data to be shared may contain sensitive information that the<br\/>first organization does not wish to disclose to the other parties.<br\/>The solution is to sanitize the data by removing information from<br\/>the data. This protects the privacy of the organization. However,<br\/>the data removed may be essential for the analysis of the data that<br\/>the other organizations must perform. This research explores the<br\/>tension between privacy and security analysis. The goals of this<br\/>research are to: (1) develop a sanitizing language to describe<br\/>the requirements for privacy and security analysis in such a way<br\/>that the requirements can be automatically checked for inconsistencies;<br\/>(2) determine the conditions under which \"perfect sanitization\"<br\/>can occur, if any; and (3) examine the problem of sanitizing<br\/>a dynamic data set that changes as the sanitization proceeds.<br\/>This will involve developing and testing the sanitization<br\/>language on both data extracted from a network, and on files<br\/>containing student grades. The former will provide examples of both<br\/>static and dynamic data. Perfect sanitization will be studied by<br\/>translating the sanitization process into functions and analyzing<br\/>their ranges and domains.<br\/><br\/>The significance of this work is in the balance of privacy and security.<br\/>Previous work focuses on sanitizing data in an ad hoc manner, rather<br\/>than analyzing the balance between privacy and security and allowing<br\/>the sanitizers to choose among particular requirements when the needs<br\/>of privacy and security analysis conflict. Its impact is that if<br\/>successful, the results can be used in a wide variety of fields in<br\/>which privacy and analysis (not just security analysis) must<br\/>be balanced.","title":"Balancing Privacy and Analysis in Data Sanitization","awardID":"0311671","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["521752","560876"],"PO":["543507"]},"83273":{"abstract":"CCR-0311204<br\/>Dynamic Security Policies<br\/>Stephan A. Zdancewic<br\/><br\/>This research concentrates on the theoretical foundations and implementation of dynamic security policies--security policies that describe how confidential or high integrity data should be handled by computer systems in an environment that is unknown when the system is built. The key idea is to extend well understood static type systems that express information-flow security policies with dynamic mechanisms that capture security policy information available only at run time. Such policies are important to the design of secure systems that can cope with change in the environment and that can evolve over time.<br\/><br\/>The main objectives are: (1) To design a type system and an accompanying soundness proof for a security-typed language that includes first-class principals, authentication, first-class confidentiality labels, and mechanisms to construct and inspect these policy components at run time. Part of this work is to extend previous research on downgrading. (2) To implement these ideas in the Jif compiler, a security-typed language based on Java. (3) To validate the approach by developing a suite of programs that stress-test the implementation. Most of these programs will be small benchmarks that test corner cases, but the intent is to have students develop larger applications.","title":"Dynamic Security Policies","awardID":"0311204","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["556654"],"PO":["521752"]},"83185":{"abstract":"Abstract<br\/><br\/><br\/>This project is developing a new approach called usage control to protection<br\/>of information and system resources in cyberspace. In addition to the<br\/>traditional concept of authorization (whereby access is authorized by<br\/>explicit or implicit permissions and rights), usage control includes<br\/>obligations (conditions which must be met before and during access) and<br\/>conditions (environmental and system conditions). Usage control further<br\/>recognizes continuity of access enforcement so the decision to allow access<br\/>is not only made prior to access, but also while the access is underway.<br\/>Finally, usage control recognizes the need for mutability whereby<br\/>appropriate attributes need to be updated as access proceeds. This project<br\/>will develop, refine and formalize models for usage control. It will<br\/>consider applications from healthcare, digital rights management and<br\/>electronic commerce domains. Concurrently it will investigate architectures<br\/>for enforcing usage control. This research seeks to give clarity and<br\/>intellectual cohesion to a variety of proposals to enhance the classic<br\/>access matrix model. This intellectual foundation will in turn foster<br\/>additional basic and applied research. The results of this research are being<br\/>taught in existing GMU courses as they emerge. These results will influence<br\/>and shape the next generation of access control systems.","title":"TC: Usage Control Models, Architectures and Mechanisms Based on Integrating Authorizations, Obligations and Conditions","awardID":"0310776","effectiveDate":"2003-08-15","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["483863"],"PO":["521752"]},"86001":{"abstract":"0323452<br\/>Chengde Mao<br\/>Purdue University<br\/><br\/>Application of Engineered DNA Nanostructures in Nanofabrication<br\/><br\/><br\/> The long-term goal of this project is to develop novel methods for nanofabrication of materials of computational interest by using engineered DNA nanostructures as templates, and to bridge the size gap between lithography (a top-down approach) and self-assembly (a bottom-up approach) in nanofabrication.<br\/><br\/> The specific objectives of this proposal are threefold: (1) constructing of equilateral DNA triangles in the size range of 5-30 nm, (2) depositing DNA nanostructures controllably on microstructured substrates, and (3) performing DNA templated nanofabrication.<br\/><br\/> The broader impact of this research is that this is highly interdisciplinary research, and provides participating students excellent learning opportunities. Special efforts are also being made to recruit women and minority students into this project.","title":"QuBIC: Application of Engineered DNA Nanostructures in Nanofabrication","awardID":"0323452","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["555489"],"PO":["521045"]},"78510":{"abstract":"The core of this proposal is the design and implementation of Ivy, a fully decentralized read\/write file system built from untrusted network storage. Ivy will act as a case study in a larger effort to explore how to build robust and trustworthy systems from unreliable and mutually-distrustful components. The Ivy project will further network research by providing a challenging test case for DHTs and overlay networks.<br\/><br\/>Ivy will itself demonstrate new levels of availability and security, and will provide a powerful new platform to support distributed collaboration. The motivating application for Ivy is collaboration among distributed groups of users. The users might be cooperating in writing a document, maintaining a web site, or developing software. Such collaboration is often awkward with current technology, especially if the different users are in different organizations, or if their organization has insufficient financial or technical resources. For example, cooperating people in different companies, or in different government agencies, often have to resort to e-mail to exchange updates to shared documents. The reason that this happens is that a more sophisticated solution would typically require all participants to place undue trust in each other or in some central entity. For example, if a distributed group of collaborators decide to share a single NFS file server, then they must all trust whoever runs it to keep it reliable and secure, and they may also have to have a formal financial arrangement in order to pay for the server. The group members would have to trust each other to update shared files in a responsible way, and (equivalently) to keep their hosts secure against outsiders breaking in and modifying shared files. If the participants have any degree of mutual distrust, a conventional file server won't be appropriate. Such a group would like to enjoy the illusion of a reliable central file server, trustable to control updates by any member, without having to trust or rely on any single system component or user. <br\/><br\/>Ivy will explore this theme in an extreme form, viewing the Internet as a location-transparent data store rather than as a communication system. The main obstacles to realization of this vision are the unreliability and untrustworthiness of Internet nodes. Thus Ivy's design has two main concerns: avoidance of single points of failure, in the form of either critical components or critical data structures; and achieving integrity with untrusted participants. The core of Ivy's design is that it keeps all information in per-participant logs. Participants append update operations to their own logs, and scan the other participants' logs to determine the current state of the file system. Ivy stores and replicates the log records in the DHash peer-to-peer block storage system, so that a participant's log is available even when the participant is not. This use of logs greatly aids both elimination of single points of failure and dealing with untrusted participants. The fact that each log has a single writer makes log data easy to authenticate. It also means that Ivy need not use locks internally, since it has no directly shared mutable data structures; this eliminates both reliability and trust problems in the case of an unresponsive lock holder. The presence of the logs offers the potential of recovering from accidental or malicious damage, by ignoring suspect logs or log entries. <br\/><br\/>This proposal has intellectual merit as both systems and algorithmic research. The Ivy system will provide a unique combination of standard read\/write file system semantics, complete decentralization, high availability, and arms-length trust relationship among participants. The work will also drive research into algorithms that turn untrusted and unreliable components into systems with well-defined reliability and security properties. This is an aspect of distributed systems that is facing new and exciting challenges with the advent of Internet-wide systems. <br\/><br\/>This proposal will have broad impact by involving both undergraduates and graduate students at MIT. The work contains a number of sub-projects suitable for students at both levels; as a result these students will learn how to design and build practical distributed systems out of untrusted components. The PI is currently developing a graduate-level course in distributed systems. Initial work on Ivy has already influenced revisions in the course structure and formed<br\/>the basis for new lab assignments.","title":"CAREER: A Robust Fully Decentralized Read\/Write File System","awardID":"0238028","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["541752"],"PO":["565090"]},"78994":{"abstract":"Abstract<br\/><br\/>Proposal Number: IIS-0240334<br\/>Institution: Carnegie Mellon University<br\/>Principal Investigator: Jamie Callan<br\/><br\/><br\/>This proposal applies peer-to-peer architectural approaches to the issues associated with federated search of digital libraries. The problem of integrating large numbers of disgital libraries into a coherent, federated system is a fundamental goal and challenge for present day digital libraries research efforts. Large-scale integration in a meaningful way involves overcoming the issues of heterogeneity of query languages, resource description and service descriptons . Peer-to-peer architectures differ from earlier approaches which attempt to enforce single ,uniform approaches by adding networking components with translation capability between difference scchemas. Peer-to-peer architectures have the consequence of removing control from single organizations, but at the same time result in increased complexity and potential for congestion. This project is a coordinated effort between researchers at Carnegie Mellon University and the University of Dortmund, Germany.","title":"Peer-to-Peer Architectures for Federated Search of Complex Digital Libraries","awardID":"0240334","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["541869"],"PO":["433760"]},"88366":{"abstract":"Word Sense Disambiguation (WSD) is a core task in natural language processing and is considered essential for major applications like text understanding, common sense reasoning, and machine translation. Previous research on WSD has produced good disambiguation schemes for the relatively few words for which training data has been available. In contrast, there have been few attempts to create systems that disambiguate all words in open text. The goal of this one-year project is to conduct exploratory research of various WSD techniques to enable the development of a tool for semantic tagging of all words in open text.<br\/><br\/>The methods to be investigated rely on inner and outer representations of word sense. The inner representation comes from examples of word meanings; whereas, the outer representation is given by semantic relations between word senses. These two representations correspond to two different views on word meanings that can be used to derive complementary WSD techniques, which ultimately can be combined, yielding a tool for resolving the semantic ambiguity of all words in open text.<br\/><br\/>The techniques developed as part of this project are expected to significantly improve the performance level of WSD applications for open text and should have an impact on other important applications in natural language processing.","title":"SGER: Exploratory Research of Word Sense Disambiguation Methods for All Words in Open Text","awardID":"0336793","effectiveDate":"2003-08-01","expirationDate":"2005-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}}],"PIcoPI":["564432"],"PO":["565215"]},"87156":{"abstract":"This research project will develop planning algorithms and a set of general methods for evaluating probabilistic planners. Probabilistic planning is the area of sequential decision making concerned with choosing operators that change the state of the world when the available operators have uncertain outcomes. The driving goal of this project is to advance the state of the art of probabilistic planners toward increased efficiency, improved robustness to problem variations, and broadened applicability to real-world problems. To accomplish its goal, the project will focus on two interrelated tasks. First, it will propose and develop a methodology for evaluating probabilistic planners. This will require studying a set of alternatives and running experiments to correlate evaluation metrics with desirable outcomes in increasingly realistic domains. The project efforts will be coordinated closely with the larger research community through the biannual International Planning Competition (IPC), which will soon introduce a probabilistic track to its existing structure. This project will organize the track and will provide the community with a set of software programs for executing and evaluating plans in probabilistic domains. Second, the project members will pursue the development of their own planning algorithms, with a particular emphasis on approaches that exploit the relationship between probabilistic planning and reinforcement learning.<br\/><br\/>The project will have definite research impacts in its study of the problem of probabilistic planning and how progress should be measured in the field. It will also advance the state of the art in planning and reinforcement learning through the exploration of instance-based techniques for learning to plan more effectively. However, the focus of the majority of the work will be on its broader impacts on the planning community as a whole, with concrete domain description languages, evaluation software, and benchmark problems that will serve to focus the community's efforts toward developing algorithms to solve problems of significant scientific and economic interest.","title":"Evaluating Next Generation Probabilistic Planners","awardID":"0329153","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["550488"],"PO":["387198"]},"90270":{"abstract":"ABSTRACT<br\/>0346938<br\/>Kevin Sullivan<br\/>U of Virginia<br\/><br\/>The purpose of this proposal is to request support for the organization of two workshops on the Science of Design. The first workshop will be held October 12-14, 2003. It is planned for Airlie Center near Warrenton, Virginia. The second workshop will be held in the first quarter of 2004, and is also tentatively planned for Airlie Center. The workshops will support the National Science Foundation.s Directorate for Computer and Information Science and Engineering (CISE) in formulating and establishing research priorities for a science of design. The workshops will be organized based on national calls for position <br\/>papers on the formulation and prioritization of research needs of the field. After a careful selection process, a diverse group of participants will be invited to each workshop to refine and develop an initial position synthesized from the contributions of the invited participants. The final product of each workshop will be a report, which will be available to National Science Foundation managers to plan and coordinate their activities, to the broad research community, and to the public. The first workshop will draw largely on <br\/>researchers organized around the CISE division of Computer-Communications Research (CCR); the second will draw on the entire CISE research community. <br\/>Intellectual Merit The Science of Design is perhaps unique among sciences for accommodating normative <br\/>elements, and thus has the potential to create a new bridge between traditional, purely descriptive natural sciences and the normative realm of value that is today largely the domain of fields such as humanities, the arts, and religion. The disciplines of computer and information science and engineering have both the need and the means to represent norm-driven design, from the structures of designed artifacts to the behaviors of the human and organizational processes that create them.ultimately to derive appropriate design structures and processes from the consideration of explicitly represented norms.","title":"Workshops on the Science of Design","awardID":"0346938","effectiveDate":"2003-08-01","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["469318"],"PO":["564388"]},"90391":{"abstract":"ABSTRACT<br\/>0347514<br\/>Anna Scaglione<br\/>Cornell U<br\/><br\/>Electronic devices become more reliable and can be integrated at very small scales. Sensors combined with embedded intelligence meet an increasing number of applications. The value of gathering and processing information locally is tied to the ability to communicate the information itself remotely. The scale of the communication devices developed thus far and their purpose do not meet the requirement of distributed, dynamic, energy limited networks of gigantic scale. I addition, most of the research at the physical layer has been focused on channel access. Cellular networks and wireless local area networks are designed following the principles developed in years of research on multiple access.<br\/>The backbone of these networks is not wireless and this has clearly polarized the research on mobile communications towards solving the access problem. Networking large numbers of these devices with traditional methods requires prohibitive costs that soon become incompatible with the dynamic nature of the network and the limited capabilities of each node. Recent results also indicate that as the density of the nodes increases peer to peer communications become unfeasible, even under the best multiple access and routing scheme. This results reinforce the need of a paradigm shift in the design and this is what this project is trying to pioneer.<br\/>The key inspiration in this project stems from the observation that distributed sensing ability and communications ver large scale networks are common in nature and are at the basis of any biological architecture referred to as swarm. Human intelligence is believed to be a remarkable example of such architecture. The communications within the network occur in a very different fashion compared to man-made communication networks and emerge from very simple building blocks. The nodes cooperate and aggregate their signals operating as distributed sources and receivers, where peer to peer transmissions are completely lost.","title":"SGER: Scalable Cooperative Communications in Adaptive Large Scale Networks Inspired by Natural Swarms","awardID":"0347514","effectiveDate":"2003-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["550699"],"PO":["564898"]},"79028":{"abstract":"This research project presents a novel practical solution for providing a routing service under a strong adversarial model, capable of adversarial omissions (black hole attack). An ad-hoc wireless network is an autonomous self-organizing system of mobile nodes connected by wireless links where nodes not in direct range can communicate via inter-mediate nodes. A common technique used in routing protocols for ad hoc wireless net-works is to establish the routing paths on-demand, as opposed to continually maintaining a complete routing table. A significant concern in routing is the ability to function in the presence of Byzantine failures, which include nodes that drop, modify, or mis-route packets in an attempt to disrupt the routing service. This project designs an on-demand routing protocol for ad hoc wireless networks that provides resilience to Byzantine fail-ures caused by individual or colluding nodes. The first proposed adaptive probing tech-nique detects a malicious link after log n faults have occurred, where n is the length of the path. These links are then avoided by multiplicatively increasing their weights and by us-ing an on-demand route discovery protocol that finds a least weight path to the destina-tion. A great deal of work will be required in order to further improve and experimentally validate the proposed solution. This project would involve further development and an implementation of the secure routing protocol and provide a detailed comparison with other existing ad hoc routing protocols under both normal and adversarial conditions.","title":"On-Demand Secure Routing Resilient to Byzantine Failures","awardID":"0240551","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["343097"],"PO":["565090"]},"83571":{"abstract":"Yang<br\/><br\/><br\/>HELP: A Profiling Tool for Disk I\/O and Networked Storage Systems<br\/><br\/>Abstract<br\/><br\/><br\/>The major goal of this proposed research is to design and implement a hardware environment for low-overhead profiling\/optimization, named HELP. HELP is a framework consisting of a hardware embedded system board and a set of easy-to-use APIs to allow system architects to develop their own efficient profiling and optimization tools for storage operations. A HELP board can be directly plugged into a server or storage system to speed up storage operations. Unlike most existing profiling and optimization techniques, our approach minimizes profiling overheads and data skews resulting in more accurate analysis of disk I\/O behavior. By offloading profiling\/optimization functions from the host, HELP makes it possible to do runtime monitoring, collecting, analyzing, and optimizing disk I\/O and data storage operations in a production system. A system architect is able to explore more opportunities than ever in designing tools for profiling and optimization, studying behavior of storage accesses, and inventing new storage architectures using HELP.<br\/><br\/>Successful completion of the proposed research will result in an effective tool that will have great impact on computer architecture research as well as broader IT community. Researchers can benefit greatly from our HELP system in guiding their search for new architectures and new algorithms for data storage. IT industries can also benefit greatly from our tool in making design choices for storage systems and solutions. It will also have significant impact on computer architecture education by facilitating better understanding of detailed system behavior.","title":"ITR--Benchmarking and Profiling Tools for Disk I\/O and Networked Storage Systems","awardID":"0312613","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["414327"],"PO":["474792"]},"93251":{"abstract":"PIs will pursue a comprehensive theory of diffusive soil transport and hillslope evolution associated with biological activity and surface rainsplash, building on recent, key developments in hillslope geomorphology. Their objectives are: (i) to clarify the fundamental ingredients and forms of constitutive (transport) laws describing these processes, demonstrating the conditions under which transport is proportional to the land-surface gradient or to the product of the soil thickness and surface gradient; (ii) to provide the analogue of a kinetic theory for the diffusion-like coefficient used in hillslope evolution models, demonstrating how it is an explicit nonlinear function of soil-particle activity, particle size, soil porosity and soil thickness, and indirectly related to climatic and biological conditions; (iii) to experimentally obtain the form of the constitutive law for transport by rainsplash using high-speed video and particle tracking techniques; (iv) to illustrate the fundamental significance of particle-activity gradients in producing transport, and demonstrate this using sandbox experiments for the case of rainsplash, and using field measurements of soil properties and tracer particles for the case of subsurface transport; (v) to clarify the ingredients of surface and subsurface particle dispersal, mixing and sorting, demonstrating how these processes contribute to hillslope catena structure; and (vi) to develop an advanced computational model of diffusive transport and hillslope evolution for exploring the full coupling between land-surface geometry, soil transport, soil thickness and soil production, including nonlinear responses to external and boundary forcing. This four-year program will mesh theoretical, experimental, field-based and computational components. The PIs theoretical work will focus on clarifying: (i) the ingredients of particle dispersal, mixing and sorting soil-depth and catena scale; and (ii) the forms of constitutive transport laws. PIs experimental\/field work will: (i) focus on the process of rainsplash, and on particle mixing and sorting within soils, and at the soil surface; and (ii) be designed to test\/validate the theoretical and computational aspects of their work. They will also apply high-performance algorithms based on discontinuous spectral element methods in developing advanced computational codes for simulating particle behavior at the soil-depth scale, and for simulating hillslope evolution at geomorphic scales. Under the auspices of the Center for Earth Surface Processes Center (CESPR), this project will involve collaboration of scientists expert in geomorphology, fluid mechanics, applied mathematics and advanced computations. The results of this work will constitute a major, and critical, contribution to the growing theoretical foundation of hillslope geomorphology.","title":"Diffusive Soil Transport and Hillslope Evolution","awardID":"0405119","effectiveDate":"2003-08-08","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0603","name":"Division of EARTH SCIENCES","abbr":"EAR"},"pgm":{"id":"1571","name":"SCEC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}}],"PIcoPI":["520219"],"PO":["54897"]},"82130":{"abstract":"Due to the wide range of geographic scales and complex tasks the Government must administer, its data is split in many different ways and is collected at different times by different agencies. The resulting massive data heterogeneity means one cannot effectively locate, share, or compare data across sources, let alone achieve computational data interoperability. To date, all approaches to wrap data collections, or even to create mappings across comparable datasets, require manual effort. Despite some promising work, the automated creation of such mappings is still in its infancy, since equivalences and differences manifest themselves at all levels, from individual data values through metadata to the explanatory text surrounding the data collection as a whole. More general methods are required to effectively address this problem. Viewing the data mapping problem as a variant of the cross-language mapping problem of Machine Translation (MT), this project will employ the new statistical algorithms developed since 1990 in the MT community to discover correspondences across comparable datasets at all levels. In MT, the techniques align words and word sequences across languages. This research will adapt and extend the techniques to consider not only data values (the analogue of words) but also data format\/orthography, metadata information, and associated textual information (metadata descriptions, footnotes, etc.) in the alignment process, and to perform alignment learning at three levels: individual data cell level, set of cells (column) level, and multi-column level. Multi-level alignment has not been attempted in MT before. These powerful learning techniques have never been applied to metadata schema integration and\/or database alignment or wrapping. If these automatically learned mappings are effective, the amount of manual labor required in database wrapping should be significantly reduced. <br\/><br\/>Two sets of domain data will be used. Air quality data will be provided by EPA staff at the California Air Resources Board in Sacramento, who periodically integrate data from some 35 regional Air Quality Management Districts throughout California into a single California-wide database, and pass this along to the Federal EPA in North Carolina. Fire emissions data will be provided by a different set of EPA offices, the USDA\/Forest Service, and the Department of Interior.","title":"Automating the Integration of EPA Databases","awardID":"0306899","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["543277"],"PO":["371077"]},"83230":{"abstract":"Making computers go fast requires optimizing software that exploits the<br\/>hardware. Exploring new hardware ideas requires hardware simulators, AND<br\/>optimizing software matching the imagined hardware. It is time-consuming<br\/>and error-prone to build these and get them to match. The CoGenT project is<br\/>automating the building of simulators and matching software tools, so that<br\/>more people can explore more ideas, more quickly, for modern computers and<br\/>programming languages.<br\/><br\/>CoGenT, which stands for Co-Generation of (simulation and compilation)<br\/>Tools, with machine descriptions. From instruction format, execution, and<br\/>timing information, we produce predictive simulators for Java programs on<br\/>the described hardware. The Java system includes optimizing and<br\/>non-optimizing compilers, and we retarget both compilers to the target<br\/>hardware. We do this by using the same description forms for the compiler's<br\/>abstract machine as for the hardware target. We generate code generation<br\/>rules by searching for target instructions to match each possible abstract<br\/>code fragment. We are also concerned with automated construction of the<br\/>rest of the compiler back end, and with efficiency of the simulators we build.<br\/><br\/>While certain hardware innovations clearly demand entirely new techniques<br\/>to exploit them effectively, we automate those aspects addressed in the<br\/>existing optimizing compiler. Our contributions lie in the increased degree<br\/>of automation and integration of the techniques, and in improved simulator<br\/>performance. While the primary setting is simulation, the results are<br\/>useful in compiler retargeting, dynamic binary translation, and beyond.","title":"Bridging the Compiler-Simulator Gap: Faster and Easier Hardware\/Software Optimization","awardID":"0310988","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["550864","517880"],"PO":["565272"]},"83241":{"abstract":"Proposal Number: 0311024<br\/><br\/>TITLE: Intrusion Detection Techniques for Mobile Ad Hoc Networks<br\/><br\/>PI: Wenke Lee<br\/><br\/><br\/>Abstract:<br\/><br\/>A mobile ad hoc network (MANET) is formed by a group of mobile wireless nodes often without the assistance of fixed or existing network infrastructure. A MANET is very vulnerable to attacks because of its characteristics of open medium, dynamically changing network topology, lack of centralized monitoring and management point, and lack of computing resources and (battery) power. This research focuses on developing intrusion detection capabilities for a MANET.<br\/><br\/>A distributed intrusion detection architecture is investigated. Each MANET node can be the monitoring node for itself, or a cluster of neighboring MANET nodes can elect a monitoring node for the neighborhood. A detection agent runs on each monitoring node to detect local intrusions and collaborates with other agents to investigate the source of intrusion and coordinate responses. This research develops a learning-based algorithm that can automatically compute detection models based on the correlations among a large set of features. For efficiency, a cascaded detection scheme is studied where simple and energy efficient models can first filter out the vast amount of normal data so that the more complex and energy consuming models only need to analyze a small amount of suspicious data.<br\/><br\/>The novel intrusion detection architecture and algorithms in this research will be valuable to not only MANET but also other existing and future technologies.","title":"Intrusion Detection Techniques for Mobile Ad Hoc Networks","awardID":"0311024","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["543138"],"PO":["521752"]},"83373":{"abstract":"Embedded platforms are increasingly used to connect to the Web and are executing mobile code. These platforms are a resource-constrained environment in which interpreted execution of mobile codes is the norm because dynamic compilation is not feasible. At the same time, the performance of the executed code is of critical importance and is often a limiting factor in both the capabilities of the system and user perception. <br\/><br\/>The goals of the research proposed here are 1) to significantly improve interpreter performance for mobile code on embedded platforms without increasing resource requirements and 2) to design a resource constrained dynamic compilation system to be used with an interpreter for adaptive optimization to further improve the performance. <br\/><br\/>The goals will be achieved by using extensive compile-time analysis and by passing the results of the analysis to the interpreter running on a client system via code annotations. Annotations will identify super-operators, groups of instructions that can be executed as a unit and optimized together. This will allow a more efficient interpretation by minimizing communication overhead and dispatch costs. Annotations will also permit adaptive dynamic optimization requiring fewer resources and little or no overhead.","title":"A Framework for Speeding Up Mobile Code Execution in Embedded Systems Using Superoperators and Annotations","awardID":"0311738","effectiveDate":"2003-08-15","expirationDate":"2008-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["532656","532654"],"PO":["565272"]},"85452":{"abstract":"This project, enhancing database, data delivery, and data visualization in collaboration with the University of Illinois-Chicago, targets the development of technology to address problems in the areas of spatial, temporal, moving objects, and data visualization. Results from the research will be used to enhance TerraFly, an interactive Web-enabled system at http:\/\/TerraFly.fiu.edu designed to aid in the visualization of spatial and remote sensed imagery. This research testbed at FIU creates simulated moving object data in real-time and generates overlays of moving objects in real time for display by the TerraFly client. TerraFly, the subject of a cooperative Research and Development Agreement between FIU and USGS, presently takes more than 13 terabytes of aerial photography covering US and makes it available to its users. This mass data, combined with point and polygonal data (made available for TerraFly research by Navigational Technologies) and moving data mined from Internet sources, combined with additional simulated moving object data created by the infrastructure, is expected to allow performance of realistic tests of spatial indexing techniques. Research activities include:<br\/> Storage and Visualization of Spatial Data<br\/> Storage and Visualization of Moving Object Data<br\/> Spatio-Temporal Data Indexing<br\/>TerraFly includes land, urban, and coastal imagery data collected by satellites, aerial photography and other remote sensing means. The first activity involves enhancements allowing storage of additional metadata, queries, and data processing routines and algorithms, and also to allow on-the-fly incorporation of data stored at remote sites. The second includes handling data update intervals, query languages (linguistic issues), indexing, and uncertainty\/imprecision. The third activity performs research toward a new data structure for spatial searching with S-trees (multidimensional search trees optimized for extremely fast updates and queries). The proposed S-Tree is a hybrid data structure that uses a combination of a hash table and a quadtree (a multidimensional binary search tree that divides the space into regions at the points being inserted in the tree).<br\/>Results of the research will be made available to disaster managers and thus benefit society. Moreover, underrepresented students will be offered hand-on experience for research efforts, thus enabling more potential PhD students in the CS\/CE pipeline.","title":"Acquisition of Research Instrumentation for Web-based Visualization of Spatio-Temporal Data","awardID":"0320956","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["558108","557651"],"PO":["557609"]},"83395":{"abstract":"Prasanna<br\/><br\/><br\/>Performance Modeling and Algorithm Design for Reconfigurable System-on-Chip Architectures<br\/><br\/>Abstract<br\/><br\/><br\/>This project will explore algorithmic techniques to optimize application performance on reconfigurable System-on-Chip (RSoC) architectures based on a novel concept of malleable algorithms. Malleable algorithms are architecture-platform aware specification of alternate implementations of a given functionality, and form the basis of a new methodology for performance modeling and algorithm design for RSoC architectures. The proposed research will have the following main thrusts.<br\/><br\/>1. Domain-specific modeling: hybrid performance modeling using high-level analytic performance models and low-level simulations. <br\/>2. Energy-efficient designs with malleable algorithms: design of energy-efficient malleable algorithms for a set of embedded benchmarks and applications. <br\/>3. System-level optimization: combinatorial approaches including formulations using interval arithmetic and generalized assignment problem.<br\/><br\/>The proposed effort will lead to the development of highly optimized portable and reusable solutions for implementing embedded applications, and the definition of a new methodology for designing energy-efficient soft-IP cores for hybrid architectures consisting of multiple tightly integrated heterogeneous computing elements. The research will complement ongoing advances in design automation, and bridge the gap between the application developer and RSoC platform architectures.","title":"Performance Modeling and Algorithm Design for Reconfigurable System-on-Chip Architectures","awardID":"0311823","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["563658"],"PO":["562984"]},"83043":{"abstract":"This project focuses on research issues concerning integer based algorithms in which each word is capable of storing only a w-bit integer. The notion of the integer based computation differs<br\/>from the traditional comparison based computation in that the model is more realistic and practical. The goals of this project are: (1) To study and compare comparison based computation and integer based computation and to develop methodologies, paradigms, strategies and <br\/>techniques for designing integer based algorithms. (2) To quest for<br\/>the ultimate limit of integer based computation and to discover<br\/>algorithms(resp. lower bounds) of complexity that matches or approaches the lower (resp. upper) bound for fundamental problems such as sorting and searching. (3) To investigate and refine methods for designing<br\/>integer based algorithms for a wide range of computational problems, e.g. graph problems and problems in algebra. (4) To investigate and propose integer based algorithms which are not only fast in big-O <br\/>notion of complexity but also having a simpler structure, more intuitive and more practical.<br\/> <br\/>Sorting is probably the most basic and fundamental problem in algorithm design. Sorting provides one of the most basic building blocks for the design of many other algorithms. With the speedup of the sorting algorithm, many other algorithms can be speeded up. In the past comparison sorting was used as one of the major tools for the design of algorithms for many problems. As fast integer sorting algorithms are discovered they can be used to replace comparison sorting in many situations. The techniques invented in the design of fast sorting and searching algorithms can be applied to the algorithm design for many other problems including minimum spanning tree, shortest path, network flow, etc. <br\/><br\/>Sorting and searching are problems encountered in many science and engineering problems. For example, sorting has been used in database design, computer graphics, computational geometry, network management, computational robotics, data mining, data warehouse, etc., etc.. Due to the vast wide applicability of sorting and searching, the impacts of fast integer sorting and searching algorithms are huge. Sorting and searching also serve as a basic vehicle for the education of computation for undergraduate and graduate students. Discovering fast integer sorting and searching algorithms can benefit this purpose. The simple structured integer sorting and searching algorithms can be lectured in the undergraduate courses and advanced integer sorting and searching algorithms can be lectured in graduate level courses. Education with integer sorting and searching algorithms will present to the students the common techniques in constructing an efficient algorithm.","title":"Speeding up Integer Based Algorithms","awardID":"0310245","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[216386],"PO":["499399"]},"86431":{"abstract":"PROJECT TITLE: ITR: Built-In Test of High Speed\/RF Mixed Signal Electronics<br\/><br\/>PROPOSAL NO.: 0325555<br\/>INSTITUTION: Georgia Inst. Technology, GA<br\/>PRINCIPAL INVESTIGATOR: Abhijit Chatterjee (lead PI)<br\/><br\/>PROPOSAL NO.: 0325371<br\/>INSTITUTION: U. Texas, Austin, TX<br\/>PRINCIPAL INVESTIGATOR: Jacob Abrahams (coPI)<br\/><br\/>PROPOSAL NO.: 0325426<br\/>INSTITUTION: Auburn University, Alabama<br\/>PRINCIPAL INVESTIGATOR: Adit D. Singh (coPI)<br\/><br\/>PROPOSAL NO.: 0325340<br\/>INSTITUTION: University of Florida<br\/>PRINCIPAL INVESTIGATOR:William R. Eisenstadt (coPI)<br\/><br\/>ABSTRACT:<br\/>In the recent past, there has been a tremendous surge in the wired communications\/wireless\/high-speed IC manufacturing sector. While the design community has pushed the design envelope far into the future, the test barriers have not kept pace with the test requirements of high speed, integrated wireless and wired communications designs. Every IC that is manufactured, needs to be tested against its design specifications before shipment to the customer. As the speeds of these ICs increase, so do the requirements of the testers needed to test these ICs in manufacturing production. High-speed testers above 2 GHz are prohibitively expensive. Consequently, for speeds beyond a few GHz (2 - 25 GHz), built-in test (BIT) of high-speed\/RF systems is a very attractive solution. Built-in test involves incorporation of test circuitry in the IC itself to facilitate the manufacturing test process. In this way, many of the test functions are performed \"on-chip,\" alleviating the need for a high-speed (expensive) external tester. Since test cost is projected to escalate to about 40% of the total manufacturing cost of complex communications ICs in the near future, the use of built-in test is expected to significantly impact the cost of the manufactured ICs themselves and the ability of companies to compete in the marketplace.<br\/>The core concept behind the proposed built-in test methodology is easy to follow. Instead of directly measuring the high-speed test specifications of the IC-under-test, a new paradigm for BIT of high-speed\/RF circuits using alternate tests is proposed. Alternate tests are compact tests that are much more simpler to run than the original specification tests but contain as much information (or more) about the performance of the circuit-under-test as the original tests themselves. Furthermore, it is possible to design these tests so that pass-fail decisions can be made, based on analysis of analog signals using analog circuitry. In this way, two problems are solved: (a) that of being able to measure complex high-speed test specifications using simple on-chip test resources and a low-cost external tester, and (b) that of being able to analyze very high-speed signals (> 2 Ghz) without the need to digitize them (such digitizers are not available or are very expensive at these frequencies). The proposed work is interdisciplinary and will involve the use of concepts from computer algorithms, analog\/RF circuit design, mathematics and statistics and fundamental electrical engineering and device physics.","title":"ITR: Built-In Test of High Speed\/RF Mixed Signal Electronics","awardID":"0325340","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["456658"],"PO":["562984"]},"87597":{"abstract":"This award supports the travel and subsistence expenses of student participants in the Second International Conference on Autonomous Agents and Multi-Agents Systems (AAMAS), being held July 14 - 18, 2003 in Melbourne, Australia. This conference is entirely devoted to all aspects of research and application of agents technology, an important area of research in the success of the World Wide Web, electronic commerce, digital libraries, search agents, personal agents and synthetic agents. Participation in this conference will allow a diverse group of students, representing a wide range of research areas and methodologies, to present their research to the agents' community. In addition, special mentoring activities are planned for them.","title":"Workshop Proposal: Student Travel Support for AAMAS'03","awardID":"0331832","effectiveDate":"2003-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["541779"],"PO":["495796"]},"86398":{"abstract":"Proposal: CCR-0325529 (Lead)<br\/>PI: Lu, Chenyang <br\/>Institution: Washington University - St. Louis<br\/><br\/>Proposal: CCR-0325197 <br\/>PI: Stankovic, John <br\/>Institution: University of Virginia <br\/><br\/>Title: ITR: Collaborative Research: Spatiotemporal Protocols and Analyses for Wireless Sensor Networks<br\/><br\/><br\/>Large-scale wireless sensor networks can change the way humans interact with physical environments through a broad range of applications including highway traffic coordination and security surveillance. Future sensor-based applications will have to meet new kinds of spatiotemporal specifications under severe resource limitations. Our fundamental hypothesis is that communication protocols and their analysis must incorporate the notions of space, time, and mobility in a unified framework, something not addressed directly by earlier research. <br\/><br\/>This project, a collaboration between Washington University and the University of Virginia. An overarching goal of the project is to establish a spatiotemporal communication framework for wireless sensor networks the integration of real-time systems and mobile computing research. The project develops a new communication protocol stack optimized for sensor networks by incorporating timing and space properties in scheduling and routing algorithms, thereby enabling analytic guarantees for the spatiotemporal specifications of sensor network services in mobile environments. Our protocol stack finds instantiation in a sensor network middleware that is readily reusable by a broad range of applications. Developing a rigorous spatiotemporal analysis that draws upon theories on real-time schedulable utilization bound, network geometry, and decentralized feedback control forms a key element of this project. The end results will be a methodology for designing dependable sensor networks able to support mission critical applications in which performance predictability is a paramount concern. The team is also committed to integrating cutting-edge research with teaching and outreach programs, leveraging off strong existing programs at Washington University and the University of Virginia. A special relation with the St. Louis Science Center will further expand our outreach efforts to students and the public at larger through exhibits placed in the information technology exhibit area. .","title":"ITR: Collaborative Research: Spatiotemporal Protocols and Analysis for Sensor Nets","awardID":"0325197","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["550342","553633"],"PO":["561889"]},"88224":{"abstract":"This small grant for exploratory research will support development of novel techniques for extending the ability of computed tomography (CT) imaging to be used as a front-line non-invasive screening tool for detection of cardiovascular vulnerable patients. Coronary heart disease (CHD) is still the major cause of death in most of the developed countries, including the United States. The grant will develop and validate the computational framework that will allow mining CT imaging data to extract information that will allow the detection and classification of plaque. This will in turn lead to the development of a quantitative method for the cumulative risk assessment of vulnerable patients.","title":"SGER: Cardiovascular Informatics","awardID":"0335578","effectiveDate":"2003-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["554348"],"PO":["565136"]},"86057":{"abstract":"The experimental part of this project is focusing on the construction of 3-dimensional DNA \"crystals\" where the goal is to create large error-free crystals of predetermined shape. In particular, control of the relative lengths of crystal facets and the angles between adjacent facets is being attempted. This research may ultimately lead to the construction of 3-dimensional computers, freeing us from the 2-dimensional restriction currently imposed by silicon. Another potential application might be 3-D crystals \"salted\" with flourophors or quantum dots for the creation of novel optical or quantum devices. The theoretical efforts are directed toward generating an understanding of the fundamental processes that govern self-assembly, and the development of new algorithms that will guide the design of practical and experimental systems. The functionality of DNA is determined, to a large extent, by its combinatorial structure, making algorithmic techniques particularly well suited for a theoretical study of DNA self-assembly.<br\/><br\/>As part of this project, two new courses on self-assembly are being developed, one at Stanford University and one at University of Southern California in the area of Molecular Self-Assembly: Models and Algorithms. The lecture notes from this sequence of courses will be made available to the scientific community.","title":"COLLABORATIVE RESEARCH: DNA Self Assembly: Experimentation and Theoretical Foundations","awardID":"0323749","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["316715","348187"],"PO":["521045"]},"78379":{"abstract":"ABSTRACT<br\/>This research is focused on efficient algorithms for analyzing, comparing, and operating on shapes, and addresses three classes of problems connected with shapes: (1) Shape fitting, which is the problem of fitting a known simple shape, such as a line, to a given set of points; (2) Shape matching, which is the problem of estimating the similarity between two discretized shapes; and (3) Shape simplification, which is the problem of replacing a complex shape with a simpler one while preserving as much of the topology and geometry efficient as specified. This research views these problems as geometric optimization problems and emphasizes the development of approximation algorithms for solving them.<br\/><br\/>Shape fitting is a problem that arises in discovering trends in statistical data or in estimating how well a manufactured part meets its specifications. Shape matching is a problem that arises in estimating how closely two objects resemble each other; the objects being compared could be two web documents or two human images in a biometrics application. Shape simplification is an important problem in scenarios such as flight simulation when trying to display a scene at the appropriate level of detail. This research views computer programs for these problems as algorithms for geometric optimization, where we want to maximize a certain quantity subject to several constraints. Algorithms that try to find the best solution to such problems are often too slow to be of practical use. This research emphasizes approximation algorithms, which find a solution within a known tolerance of the best solution rather than the best solution. In most applications an approximate optimum is sufficient. Approximation algorithms are generally considerably faster, simpler, and more robust than algorithms that find the best solution. The main goal of this research is to discover powerful techniques for developing such approximation algorithms.","title":"CAREER: Algorithms for fitting, matching, and simplifying shapes","awardID":"0237431","effectiveDate":"2003-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["550204"],"PO":["550859"]},"81581":{"abstract":"Photons have proven to be most useful for encoding special quantum states and for transmitting them through free space or optical fibers. For local quantum-state operations photons are less favorable and well-localized quantum systems are desirable. In this respect quantum dots, often referred to as artificial atoms, are particularly attractive. This research aims at combining the advantages of photons with those of artificial atoms. <br\/><br\/>The main objective is to transfer the polarization quantum state of a single photon onto excitons in quantum dots and visa versa. The anticipated results are: a novel positioning technique for a quantum dot in the center of an optical waveguide, the demonstration of a single-photon absorption and reemission by a single quantum dot inside a micro-pillar with intrinsic lensing, the demonstration of the polarization quantum-state transfer between single photons and single quantum dots, and creating entanglement between a quantum dot and a photon and between two quantum dots. The first requirement to achieve the objectives is that the coupling between photons and quantum dots has to be resonant in order to preserve the quantum-phase coherences. For this optical-cavities resonant both with the incoming photon and the quantum dot inside the cavity will be used. Two novel ways of achieving a strong optical mode overlap with the quantum dots will be explored. The first is to use quantum dots inside micro pillars that containing optical lensing through the use of tapered oxidation layer. The second is to develop a technique to position a single quantum dot in the center of an optical micro cavity. The second requirement is that the quantum dots have to be effectively symmetric in order to obtain exciton spin degeneracy. For this magnetic fields and\/or strain-induced effects on the micro-pillars will be explored. The third requirement is that the reemitted photon from the quantum dot should be distinguishable from photons reflected from the sample surface. For this a Michelson interferometer will be used where the two end mirrors are replaced by one micro-cavity containing a quantum dot on resonance and one micro-pillar containing no quantum dots on resonance. <br\/><br\/>Reaching the objectives will be a major step forwards in quantum-state control and harnessing and understanding quantum decoherence in nano-structures. The research is based on a close collaboration between the Materials, Engineering and Physics Departments at the University of California Santa Barbara. This collaboration provides an excellent opportunity for young researchers to perform interdisciplinary research on important topics in quantum (and classical) communication and information processing and in nano-structure fabrication. Reaching the objectives will initiate future research in storage of quantum information and in implementing the quantum repeater scheme (enabling long-distance quantum cryptography), quantum error correction and quantum networks.","title":"NIRT: Quantum-State Transfer Between Photons and Nanostructures","awardID":"0304678","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1248","name":"PHYSICS-OTHER"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}}],"PIcoPI":["416940","399761","548405"],"PO":["384749"]},"83660":{"abstract":"One consequence of the phenomenal storage density improvement is the<br\/>emergence of highly compact disk storage that can be integrated into<br\/>various computing and networking devices of various shapes and forms.<br\/>Our conjecture is that mobile storage will become a dominant form of<br\/>storage in the near future, especially for personal user data,<br\/>subsuming conventional disks enshrined in server rooms. This proposal<br\/>describes a project that studies how to build, manage, and use<br\/>discrete storage devices to form ad hoc, distributed storage systems.<br\/><br\/>In this project, we propose to build system software to intelligently<br\/>coordinate the discrete storage elements. The system has four core<br\/>mechanisms: (1) a multicast-like data location mechanism, (2) an<br\/>invalidation mechanism for purging obsolete data from the system, (3)<br\/>a snapshot mechanism for supporting sharing and backup, and (4) a<br\/>storage level solution that can support existing file systems. In<br\/>this proposal, we describe how combinations of these four core<br\/>mechanisms allow us to achieve our consistency, transparency,<br\/>reliability, security, and performance goals.<br\/><br\/>Furthermore, the data management needs addressed by this project are<br\/>by no means limited to traditional desktop applications. As the data<br\/>management functionalities are separated from cumbersome generic<br\/>computing devices, and as these functionalities are cleanly<br\/>encapsulated in modular small form factor devices that can readily<br\/>interact with other consumer electronic devices (such as cameras, MP3<br\/>players, phones, and email devices), these application-specific<br\/>devices would be freed from the burden of having to solve and re-solve<br\/>a difficult mobile storage problem, and we may multiply the utility of<br\/>these devices and potentially foster new applications.","title":"ITR: Ubiquitous Mobile Storage","awardID":"0313089","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["52508",218116],"PO":["309350"]},"81482":{"abstract":"This NIRT proposal focuses on the preparation of ordered arrays of nanodots and nanowires and incorporating them into device structures. This is a critical problem in nanometer-scale science of semiconductors. The NIRT research will build on our ability to grow quantum heterostructures with layer thickness down to a few atomic layers and to prepare ordered nanostructured templates. The two approaches will be combined to form structures and devices ordered on the nanometer scale in three dimensions. The research will include self-assembly of alumina masks, with pore sizes as small as 10 nm, on semiconductor substrates and deposition of semiconductor dots and nanowires into these pores using selective epitaxy. By either removing the alumina template or leaving it in place, we will have produced an array of identical semiconductor quantum dots. These will be compared with dots produced by epitaxial self-assembly. We will apply knowledge gained from these experiments to prepare ultraviolet light emitting devices based on the AlN\/AlGaN heterostructures. These techniques will also be applied to the formation of nanowires of dilute magnetic semiconductors and to investigate spin transport and device applications of the (Ga, Mn)N and (In,Mn)N systems. Equally important, results of this research will be used to inject nanoscience into current courses, producing new laboratory based courses, and to educate science and engineering graduate students in this important area. <br\/> Intellectual Merit: This proposal addresses fundamental problems that need to be solved in order to produce useful ultraviolet optoelectronic and spin-based devices. Advanced growth methods will be developed to produce nanoarrays of technologically important semiconductors. Devices will be fabricated out of these nanoarrays and their properties explored. There are several reasons to study three-dimensional quantum structures based on GaN and related compounds: 1. Quantum dots have higher radiative efficiency than two-dimensional layers, thus providing better device performance. Superior spin transport is expected in nanowires of dilute semiconductors. 2. Ordered nanostructures - devices grown with vertical (heterostructure) and lateral (nanodot) control will allow us to engineer properties on a quantum level, resulting in new device functionalities. 3. Further miniaturization of device structures requires better understanding of the self-assembly processes and finer control over nanodot and nanowire quality. <br\/> Broader Impact: The assembly of nanostructured semiconductors into nanoscale devices will enable new applications in electronics, spintronics, and photonics. At the same time, preparation of such devices challenges our understanding of fundamental limits of size and scalability that determine electrical and optical properties of nanostructures. New approaches to research and education are needed to meet this challenge. Under this NIRT proposal the research plan will be closely integrated with educational activities. Specific steps that will be taken towards this goal include involvement of graduate and undergraduate students in advanced interdisciplinary research. Their participation will develop critical technical, team, and leadership abilities. New components of classroom and laboratory courses will be produced based on nanofabrication, attracting students from diverse backgrounds into research.","title":"NIRT: Nano-Arrays of Large Bandgap Semiconductors for Light Emitting and Spintronic Devices","awardID":"0304224","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["306060","492202","457073","472804","536809"],"PO":["460979"]},"82131":{"abstract":"This research will develop a flexible data query and analysis system based on the web services paradigm. As an application domain several goods movement planning problems will be examined along with their effects on spatial urban structure. The research has three objectives: <br\/><br\/>1) to advance computer science research by developing an expressive web services description language and techniques for dynamically<br\/>composing web services, <br\/>2) to develop and conduct test applications of an intra-metropolitan goods movement flow model using web services in cooperation with government partners, and <br\/>3) to use the model to conduct social science research on intra-metropolitan economic linkages and spatial structure. <br\/><br\/>Although the focus is on the specific topic of urban goods movement, the approach to web service composition is general and can be applied to other scientific data gathering and analysis tasks. The first objective is to develop Argos, a general framework for dynamically composing web services. Many scientific problems can be modeled as a workflow that includes information gathering and processing operations. Argos will provide graphical tools for manual specification and composition of web services, as well as automatic composition based on expressive web service descriptions for given application domains (such as transportation planning). The second objective is to use Argos in an actual metropolitan planning application. In consultation with an advisory team of government representatives, from the Los Angeles County Metropolitan Transportation Authority, the San Bernardino Associated Governments, the Southern California Association of Governments and the Port of Long Beach. a scenario analysis using the Los Angeles region as a case study will be conducted. The scenario analysis will allow evaluation of Argos both in terms of its utility as a transportation planning tool as well as its ease of use by practitioners. The third objective is to extend the transportation planning domain to address problems of urban spatial structure that heretofore have not been practical for social science researchers to study due to the lack of tools for integrating and analyzing available data. There is an extensive theoretical literature on employment location; transport of freight inputs and outputs are critical elements of these models. Empirical research on employment location is limited, because of the lack of availability of freight flow data. The research team will analyze the relationships between industry mix, flows, and urban spatial structure, using the Los Angeles region as a case study.","title":"ARGOS: Dynamic Composition of Web Services for Goods Movement Analysis and Planning","awardID":"0306905","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["487472",214166,"486525"],"PO":["469867"]},"83594":{"abstract":"As the manufacturing technologies move toward nanometer ranges, one of the major challenges is to ensure consistency between the behavior expected of a design and its actual behavior in a real silicon chip. Due to Deep Sub-Micron (DSM) effects such as process variations, small defects, and electrical noise, it has become increasingly difficult to predict the design's timing behavior on silicon, or to guarantee such timing behavior before the design goes into production. To avoid slowdowns in manufacturing, the industry needs novel post-silicon validation and diagnosis tools that will effectively resolve the inconsistency between a design model and its implementation on a silicon chip. To meet the challenge, the PIs propose novel statistical approaches that will better model, and more accurately simulate, the timing behavior of a device. The PIs propose three research components in this project to be integrated with their planned educational activities: (1) diagnosis of timing problems, (2) post-silicon validation and debugging, and (3) prediction of timing quality. In diagnosis, techniques will be developed to locate timing problems on faulty chips, determining whether these problems may be due to manufacturing defects. In validation and debugging, techniques will be developed to ensure consistency between the timing behavior of models used to design a chip and that which is observed during the manufacturing process. For the third component, prediction of timing quality, techniques will be developed to draw statistical inference about the timing quality level in the stages of mass production. <br\/><br\/>The proposed research will complement other research efforts in the modeling of DSM circuits and process variations by taking the analysis to a more abstract level. Rather than dealing directly with transistors and wires, the proposed tools will operate on correlated random variables that model the timing behavior of transistors and wires. This project will facilitate the development of practical tools for large and complex designs. When the proposed statistical tools and methodologies become available, chip designers can relax the metrics of various parameters in order to obtain the best design tradeoff, thus pushing manufacturing technologies to the cutting edge. When silicon's timing problems can be more effectively detected and better understood, companies can avoid wasting resources in struggling with manufacturing uncertainties and devote these resources to more productive uses.","title":"ITR: Post-Silicon Validation and Diagnosis Based Upon Statistical Delay Models","awardID":"0312701","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["287642","535169"],"PO":["562984"]},"83242":{"abstract":"Vahid<br\/>CCR-0322026<br\/><br\/>eBlocks: Embedded Systems Building Blocks<br\/><br\/>This project develops a set of building blocks that can be used by people,<br\/>having no special training, to build simple but useful embedded<br\/>computing systems. The types of systems are those that monitor switches<br\/>and sensors (motion, light, temperature, etc.) and control basic outputs,<br\/>like lights, buzzers, electric relays, and simple actuators. The project<br\/>defines an intuitive set of eBlocks, incorporates compute intelligence into <br\/>previously passive sensors and outputs, defines the communication and<br\/>coordination protocols between eblocks, and develops methods to assist<br\/>people in creating and configuring eBlock systems. The result is a set of<br\/>eBlocks that can be connected into systems by nearly anybody to perform<br\/>useful tasks. Example systems include detecting a garage door left open at<br\/>night, notifying a deaf person of noise, turning on a fan after a certain<br\/>temperature is reached in a scientific experiment, finding commonly lost<br\/>items, and tallying votes anonymously in a classroom or meeting.<br\/>The broader impacts not only involve improved control over home, office, <br\/>store, school, and other environments, but also the improved support of <br\/>research in a diversity of other scientific disciplines relying on sensors<br\/>and control, as well as use in design courses in colleges and high schools.","title":"eBlocks: Embedded System Building Blocks","awardID":"0311026","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["518640","450944",216989],"PO":["561889"]},"83363":{"abstract":"Proposal Number: NSF Collaborative Proposals CCR-0311808 and<br\/>CCR-0311686<br\/><br\/>Title: Automated and Adaptive Diversity for Improving Computer System<br\/>Security<br\/><br\/>PI: Stephanie Forrest<br\/><br\/>Abstract: Diversity is an important source of robustness in biological systems. Because each individual has slightly different properties, it is unlikely that any single pathogen will eliminate or escape the<br\/>entire population. By contrast, today's computer systems are largely homogeneous, being overwhelmingly dominated by one or two operating systems and a few common applications from a handful of software<br\/>vendors. This fact is routinely exploited by attackers via Internet worms such as Code Red, which infected over 250,000 systems in just nine hours using a single buffer overflow vulnerability.<br\/><br\/>The project will develop methods for diversifying computer systems automatically and systematically -- exploring diversity at various levels of a system and for various purposes, e.g., to make a system<br\/>more difficult to compromise, to make a system more difficult to damage even after a successful compromise, and to make it more difficult for a successful compromise to evade detection. In order<br\/>to succeed, many of the mechanisms explored in this work must hide or disguise information about system specifics from an attacker, and this theme will underlie several of the projects.","title":"Collaborative Research: Automated and Adaptive Diversity for Improving Computer Systems Security","awardID":"0311686","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["461864"],"PO":["521752"]},"86410":{"abstract":"Information available for security threat detection\/assessment is often generated from distributed heterogeneous sources. Although it may possess a significant qualitative component and lack sufficient time synchrony, this data may provide potentially critical information. This work describes a framework for effective knowledge discovery in such environments via the following tasks: refinement and generalization of the Dempster-Shafer belief theoretic framework; development of the data mining methods of association rule mining and classification; and development of methods enabling the use of timing information in the fusion process to improve threat detection\/assessment tasks. The proposed notions will be validated via the development of an experimental platform consisting of a small-scale fusion and decision-making network located at each of the participating institutions. It will possess various sensing capabilities and will mimic the security zones plus gateways structure that characterizes a typical threat detection\/assessment environment.<br\/> The work being proposed significantly advances the state-of-the-art in distributed information fusion environments that forms the basis for numerous other application scenarios. The research results and experimental platforms developed will be integrated into courses that already exist and those to be newly developed; various other outreach activities will also be undertaken.","title":"ITR: Collaborative Research: Distributed Information Fusion Networks for Threat Detection and Assessment","awardID":"0325260","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["560250",225806],"PO":["563727"]},"85574":{"abstract":"This project, upgrading capabilities of a Core DNA Analysis Facility, builds on a successful NSF CCLI award. The acquisition of a capillary based genetic analyzer and a real-time PCR detection system is proposed to complete investigations in a variety of fields ranging from studies of gene regulation, to the mentoring and modeling of disease spread, to molecular systematics, and conservation genetics. Ten of the on-going projects use DNA sequencing for various purposes, including molecular systematics, mapping of phenotypic characters, examination of population structure, understanding biogeography, and identification and characterization of specific genes. Of four genotyping projects, three use analysis of highly variable microsatellites for fine scale population analyses, analyses of kinship (genetic fingerprinting), or mutation detection. One genotyping project uses AFLP analysis to conduct genome-wide sampling for use in GIS modeling that includes a genotypic \"landscape.\" Two projects rely simply on genotype detection or mutation detection by analysis of the presence\/absence or condition of PCR products. In line with the mission to foster combined research\/education, this work carries a good success story.<br\/><br\/>The project, accommodating the increased demand for usage of the facility by students and faculty, not only enhances faculty research programs, but also involves research training in an undergraduate institution. Moreover, teacher training is expected to impact on K-12 education.","title":"MRI\/RUI: Acquisition of Genetic Analyzer and Sequence Detection System for the Sonoma State University Core DNA Analysis Facility","awardID":"0321367","effectiveDate":"2003-08-01","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[223342,223343,"476806",223345],"PO":["557609"]},"83297":{"abstract":"Abstract:<br\/><br\/>Hybrid systems consist of discrete time systems interacting with<br\/>continuous time systems. Most frequently they arise when a discrete<br\/>computational device functions in a continuous physical environment.<br\/>Such systems have become very common, thanks to the proliferation of<br\/>software in controlling physical systems. Modeling and analysis of<br\/>hybrid systems is, therefore, paramount for efficient development of<br\/>high quality safe devices. Formal models of hybrid systems have been developed by combining discrete<br\/>state transition formalisms with continuous dynamical systems. Developing<br\/>analysis technology for such expressive formalisms is a challenging task.<br\/>In recent years, several analysis tools have been developed for<br\/>specialized classes of hybrid models that either restrict the continuous<br\/>behavior or the discrete behavior severely. The continuous component of a<br\/>hybrid system, in particular, presents a great challenge to the<br\/>development of sound analysis techniques. <br\/><br\/>This project aims to develop sound and effective techniques and tools for<br\/>analysis of large hybrid system models. The approach centers around the<br\/>construction of approximate abstractions for hybrid systems using<br\/>intelligent abstraction mappings that yield effective computability and<br\/>scalability. The project builds on the hybrid abstraction technique that combines<br\/>predicate abstraction for discrete systems with qualitative abstraction of<br\/>continuous dynamical systems. It focuses on (i) improving techniques to generate<br\/>the most appropriate abstraction mappings by structurally analyzing the<br\/>continuous dynamics; (ii) the exploitation of the modular structure of the<br\/>discrete and continuous components, and the compositional structure of the<br\/>hybrid system; and (iii) developing the necessary symbolic methods for<br\/>effective automation.<br\/><br\/>The tools and techniques developed under this project will have broader impacts by making analysis<br\/>amenable to intermediate and large hybrid system models in application areas such as embedded system<br\/>design for automotive and other applications and bioinformatics. It also<br\/>helps students develop intuitions about complex system behaviors without<br\/>analytically solving them. The results are disseminated through research<br\/>publications and the tools are made available for academic use.","title":"Symbolic Approaches to Analysis and Hybrid Systems","awardID":"0311348","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["451280"],"PO":["561889"]},"88621":{"abstract":"0338093<br\/>Nandkumar<br\/><br\/>This award supports the participation of eleven US computer scientists and a graduate student in a workshop with Australian counterparts to discuss desirable characteristics and capabilities of Grid supercomputing and areas for future collaboration that will benefit from these advanced capabilities. The co-organizers of the meeting are Dr. Radha Nandkumar and Dr. Daniel Reed, Director of the National Center for Supercomputer Applications (NCSA) located at the University of Illinois at Urbana-Champaign, and Dr. John O'Callaghan of the Australian National University, who is Executive Director of the Australian Partnership for Advanced Computing (APAC.) The workshop will be held following the annual meeting of APAC in Queensland, Australia, which will be attended by representatives of all significant supercomputer user groups among Australian academic institutions as well as the CSIRO. The U.S. participants will come from the NCSA and other NSF TerraGrid sites. Australia has recently begun a Grid initiative. This workshop provides the opportunity to define future complementary development activities that will ensure that the grid infrastructures being built in the U.S. and Australia can support and provide a testing ground for interoperability. It will catalyze joint projects and demonstrations and enhance the benefits of grid computing by sharing and integrating the intellectual resources of the two countries.<br\/><br\/>Broader Impacts<br\/><br\/>An important outcome of the workshop will be to strengthen connections among the supercomputer and grid users of Australia and the U.S. This stronger relationship will facilitate international research opportunities for graduate students and postdoctoral\/early career scientists of the two countries. It will also leverage the expertise of the two research communities to promote the solution of complex truly global scale problems in a variety of scientific and engineering disciplines.","title":"U.S.-Australia Workshop on Strengthening Collaborations in High Performance Computing and Applications Research, October 2-4, 2003, Gold Coast, Australia","awardID":"0338093","effectiveDate":"2003-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5978","name":"EAST ASIA AND PACIFIC PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4066","name":"PART FOR ADVANCED COMP INFRA"}}],"PIcoPI":["562707","436368",232451],"PO":["449696"]},"83187":{"abstract":"1) Abstract<br\/>===========<br\/><br\/>Proposal Number:<br\/>CCR-0310793, CCR-0310490, CCR-0310159 and CCR-0310571<br\/><br\/>TITLE:<br\/>Graphical Passwords -- Design, Analysis, and Human Factors<br\/><br\/><br\/>PI: J.C. Birget and Dawei Hong (Rutgers-Camden),<br\/><br\/><br\/>Co-PIs:<br\/><br\/>S. Man (Southwest State U., Minnesota),<br\/>N. Memon (Polytechnic U., Brooklyn),<br\/>S. Wiedenbeck (Drexel).<br\/><br\/><br\/>Abstract:<br\/><br\/>Humans are not good at remembering alpha-numeric passwords, if the passwords are complicated enough to be secure. Graphical passwords seem easier to remember and to use. Here, an image is displayed and the user chooses a few places in the image. To log in, the user has to click close to these places again. Older systems use preprocessed images with predefined click regions, among which a user has to choose. The investigators designed systems that allow users to choose any points as click points, and that allow users to import their own images. The investigators invented a ``robust discretization'' of images; this enables users to produce exactly the same discrete password even though they cannot click on exactly the same pixels at each login. Passwords are vulnerable to ``shoulder surfing'', which consists of a user being observed, or filmed, during login. The investigators designed password systems that are immune to shoulder surfing.<br\/><br\/>One of the objectives of this proposal is a human factors study, concerning learnability, memorability, speed, security (unsafe practices), and user satisfaction of graphical password systems. A second objective is to design new graphical password systems, based on curves, movement, and three-dimensional scenes, as well as to design ``bundles'' of passwords that a user can use on different accounts, and that are easy to remember (and distinguish) as a group. New robust discretization algorithms and probabilistic analyses of the security of graphical password systems will be developed.","title":"Collaborative Research: Graphical passwords -- design, analysis, and human factors","awardID":"0310793","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":[216818,216819],"PO":["521752"]},"86454":{"abstract":"PROJECT TITLE: ITR: Built-In Test of High Speed\/RF Mixed Signal Electronics<br\/><br\/>PROPOSAL NO.: 0325555<br\/>INSTITUTION: Georgia Inst. Technology, GA<br\/>PRINCIPAL INVESTIGATOR: Abhijit Chatterjee (lead PI)<br\/><br\/>PROPOSAL NO.: 0325371<br\/>INSTITUTION: U. Texas, Austin, TX<br\/>PRINCIPAL INVESTIGATOR: Jacob Abrahams (coPI)<br\/><br\/>PROPOSAL NO.: 0325426<br\/>INSTITUTION: Auburn University, Alabama<br\/>PRINCIPAL INVESTIGATOR: Adit D. Singh (coPI)<br\/><br\/>PROPOSAL NO.: 0325340<br\/>INSTITUTION: University of Florida<br\/>PRINCIPAL INVESTIGATOR:William R. Eisenstadt (coPI)<br\/><br\/>ABSTRACT:<br\/>In the recent past, there has been a tremendous surge in the wired communications\/wireless\/high-speed IC manufacturing sector. While the design community has pushed the design envelope far into the future, the test barriers have not kept pace with the test requirements of high speed, integrated wireless and wired communications designs. Every IC that is manufactured, needs to be tested against its design specifications before shipment to the customer. As the speeds of these ICs increase, so do the requirements of the testers needed to test these ICs in manufacturing production. High-speed testers above 2 GHz are prohibitively expensive. Consequently, for speeds beyond a few GHz (2 - 25 GHz), built-in test (BIT) of high-speed\/RF systems is a very attractive solution. Built-in test involves incorporation of test circuitry in the IC itself to facilitate the manufacturing test process. In this way, many of the test functions are performed \"on-chip,\" alleviating the need for a high-speed (expensive) external tester. Since test cost is projected to escalate to about 40% of the total manufacturing cost of complex communications ICs in the near future, the use of built-in test is expected to significantly impact the cost of the manufactured ICs themselves and the ability of companies to compete in the marketplace.<br\/>The core concept behind the proposed built-in test methodology is easy to follow. Instead of directly measuring the high-speed test specifications of the IC-under-test, a new paradigm for BIT of high-speed\/RF circuits using alternate tests is proposed. Alternate tests are compact tests that are much more simpler to run than the original specification tests but contain as much information (or more) about the performance of the circuit-under-test as the original tests themselves. Furthermore, it is possible to design these tests so that pass-fail decisions can be made, based on analysis of analog signals using analog circuitry. In this way, two problems are solved: (a) that of being able to measure complex high-speed test specifications using simple on-chip test resources and a low-cost external tester, and (b) that of being able to analyze very high-speed signals (> 2 Ghz) without the need to digitize them (such digitizers are not available or are very expensive at these frequencies). The proposed work is interdisciplinary and will involve the use of concepts from computer algorithms, analog\/RF circuit design, mathematics and statistics and fundamental electrical engineering and device physics.","title":"ITR: Built-In Test of High Speed\/RF Mixed Signal Electronics","awardID":"0325426","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["550443"],"PO":["562984"]},"86465":{"abstract":"ABSTRACT<br\/>0325496<br\/>Muriel Medard<br\/>Massachusetts Inst. of Tech<br\/><br\/>Network Coding --- From Theory to Practice<br\/><br\/>The efficient use of network resources is a central objective in making information available in today's society. Despite an enormous effort in understanding the modes in which networks can, do, and<br\/>should operate, a unified and concise theory of networking has remained elusive. Before this backdrop, this research aims at developing and leveraging a combined view of a number of traditionally separate, network-related issues. In this context, the research team will investigate issues varying from fundamental questions about the structure of networks employing network coding over an array of specific network scenarios, network robustness, network information theoretic aspects to questions involving practical aspects of networks.<br\/>This ambitious project is driven by the notion of \"Network Coding\", a recent discovery that is central to this proposal. Not only is network coding a fresh and sharp tool that has the potential to open up stagnant fundamental areas of research, but due to its cross-cutting nature it naturally suggests a unified treatment of previously segmented areas. In particular, the research addresses the interplay of network coding in the context of network management, network information theory, compression and channel codes in networks and<br\/>distributed scheduling and routing algorithms. The understanding of intrinsic fundamental performance limits of networks across different tasks, holds the potential to not only create a cornerstone in the<br\/>theory of networks but also to build new and robust bridges between previously unconnected areas.","title":"Collaborative Research: ITR: Network Coding - From Theory to Practice","awardID":"0325496","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["486265","316455"],"PO":["564898"]},"87224":{"abstract":"ABSTRACT<br\/>0329741\/0329794<br\/>Jie Wu<br\/>Lixin Gao<br\/>Florida Atlantic University<br\/><br\/>Spurred by the fast increasing capabilities and declining costs of computing and communication devices, it becomes increasingly viable to embed sensors in physical devices and link these sensors through wireless networks. These sensor networks can be deployed for a wide range of applications that can improve quality of life, and even save lives. These applications include healthcare (e.g., health monitoring and coordination among doctors and nurses), aircraft flight control, weather forecasting, home appliance control, and protection against bioterrorism. One of the key challenges in the deployment of sensor networks is how to prolong the lifetime of the networks. Sensor networks will stress power sources because of the their need for long operating lifetimes and high energy density. Therefore, energy efficiency is critical for the wide deployment of sensor networks. <br\/><br\/><br\/>The investigators study energy management techniques for sensor networks. The key idea is to take advantage of the physical layer design that facilitates the combining of partial information. A node can receive several partial signals and combine these signals to retrieve the complete signal. This is referred to as hitchhiking. Hitchhiking can potentially conserve energy for transmitting data in sensor networks. <br\/>By the effective use of partial signals, a packet can be delivered with less nodes and\/or less transmission power at each node. The investigators will systematically study the energy management techniques for sensor networks as follows. First, the investigators will study the physical layer design of hitchhiking. Second, the investigators will study power control for broadcast networks and unicast networks. Third, the investigators will study power saving protocols to reduce the energy consumption for idle modes.","title":"Collaborative Research: SENSORS: Energy Efficient Communication in Sensor Networks","awardID":"0329741","effectiveDate":"2003-08-15","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["7594","391670","321436"],"PO":["564898"]},"89567":{"abstract":"This project provides support for two workshops at the National Science Foundation in<br\/>August 2003, a workshop August 5-6, 2003 addressing problems of on-going placement issues for students in the Scholarships for Service (SFS) program and a workshop August 7-8, 2003 addressing national cybersecurity workforce needs and educational innovation. It includes pre-, post-, and onsite support for travel and lodging planning and workshop logistics and for post-workshop support in editing and disseminating workshop results. This project is important because it will allow the experiences of current institutional awardees to inform and improve the framework governing the future awards in the SFS program. It will allow society to fully benefit from a more secure computing infrastructure by ensuring that qualified graduates are more properly and efficiently placed in government service.","title":"Combined Workshop Support","awardID":"0343215","effectiveDate":"2003-08-15","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":["529428"],"PO":["236005"]},"87147":{"abstract":"Although computer programming has existed in its modern form for half a century, it remains accessible only to a small fraction of the population. While programming is an inherently difficult activity, there are currently many barriers that prevent large portions of the population from learning to program a computer. Some of these barriers can be overcome through new facilities in programming environments. Current advanced programming environments provide a number of tools to help programmers construct programs: direct manipulation facilities to set up user interface widgets, code editors with coloring and indenting, and various pop-up menus that help construct code. However, there is little support to help users write the code that handles the dynamic responses to events and high-level behaviors. Furthermore, the tools for debugging code when something goes wrong are not much different than what has been available for 60 years: print statements, break-points and inspecting the values of variables. This is in spite of the fact that research shows that debugging and specifying the dynamic behavior of code are some of the most difficult aspects of programming.<br\/><br\/>In this project, Alice, a programming environment that makes it very easy to program interactive 3D graphics, will be augmented to provide significantly better tools to help both novice and expert programmers develop and debug their programs. A number of novel ideas that have not yet appeared in any system will be implemented, along with the best ideas from prior systems and research (which have never been combined into one system). Thorough formative and summative user testing of the ideas will provide an understanding of which of the features are most useful; this will guide further refinement of Alice so it does the best possible job of guiding programmers to create correctly working solutions.<br\/><br\/>In addition to addressing the mechanical issues of programming, Alice provides an opportunity to address the fact that relatively few women learn to program, which can be called a sociological barrier. Many girls turn away from science and technology during their middle school years, usually never to return. Middle school girls represent a particularly difficult challenge, requiring a highly motivating system with tremendous mechanical support. The PIs' approach to lowering the social barriers is to provide programming as a means to other motivating ends, especially storytelling.<br\/><br\/>The intellectual merit of the proposed research will be to discover new techniques to aide in the construction and debugging of programs, and to measure and validate the impact and effectiveness of these techniques with both novice and expert programmers. The techniques envisioned to help with code creation include: graphical and textual editors for storyboards that will help transition story ideas into code; demonstrational and direct manipulation techniques for specifying dynamic behaviors; check-pointing and undo facilities so programmers can more easily explore multiple solutions and backtrack to a known state when necessary; smart copy-and-paste that will help in transforming and reusing code; support for collaboration and sharing of code; tools that will suggest likely causes and fixes for run-time errors; and embedded special-purpose editors to help construct Boolean expressions and scientific formulas. Techniques to support understanding, testing and debugging include: providing easy inspection of data so programmers can tell what is happening; pausing or break-pointing on any program event including objects that are being changed, created, or deleted; changing values at run time to explore the effects; providing a time-line visualization to show important events and enabling programs to run forwards and backwards from any point; support for asking \"why\" questions that will tie graphics and program events to the code that caused them; support for asking \"why not\" questions, which will use heuristics to propose reasons why some event did not happen; and search capabilities so programmers can find variables with particular values, or objects with certain properties.<br\/><br\/>Broader Impacts: The broader impacts resulting from this research will be to help make programming more accessible to novice programmers, and more effective for both novice and expert programmers. One important target group will be middle school boys and girls who are not necessarily motivated to learn programming. The PIs believe they can make programming accessible and compelling to this audience, while at the same time making it easier for experienced programmers. These benefits will be evaluated using thorough user tests at all points of the design and implementation.","title":"Lowering the Barriers to Successful Programming","awardID":"0329090","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["548127","233332"],"PO":["565227"]},"83650":{"abstract":"Papachristou<br\/><br\/><br\/>A Dynamic Reconfigurable Processing Fabric<br\/><br\/>Abstract<br\/><br\/>This project deals with design methods and tools for a new dynamic reconfigurable hardware fabric that can be embedded in a System-on-Chip (SoC) platform. The objective is to address needs and requirements for adaptable SoCs in high performance on-board processing and communications.<br\/><br\/>SoC technology is well suited for many new compute-intensive applications such as multimedia, visualization, signal and image processing, wireless communications and networking. In more sensitive environments such as networking, satellites and airborne vehicles, SoCs will need to function in multiple roles and moreover need to be dynamically reconfigured in response to environment changes. Reconfigurable computing and reconfigurable hardware will be a key enabler technology to achieve these objectives.<br\/><br\/>Our approach employs an architecture with two key hardware and software layers: the reconfigurable fabric and the manager configuration kernel. We provide a pervasive dynamic configuration scheme based on the coordination and interaction of the hardware and software layers. Our proposed reconfigurable system has significant advantages over FPGA-based systems and other reconfigurable architectures in terms of flexibility, word length scalability, cost, and compatibility with SoC technology.<br\/><br\/>Our work will involve 1) analysis, simulation and design of the hardware fabric using commercial CAD tools; 2) design and development of the software configuration kernel; 3) a prototype test bed of the reconfigurable system and emulation on advanced FPGA platforms.","title":"A Dynamic Reconfigurable Processing Fabric","awardID":"0313004","effectiveDate":"2003-08-01","expirationDate":"2007-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":[218084],"PO":["325495"]},"82110":{"abstract":"This small exploratory grant will examine the use of optical character recognition (OCR) for handwriting in pre-hospital admission related to emergency medical services. When such information is put into digital form, it can be queried and accessed for various forms of analysis.<br\/>Epidemiological analysis for identification and tracking of diseases will be one area of interest where statistical data available quickly after hospital admission is critical. Several government agencies in New York will participate, including the New York State Dept. of Health.","title":"Epidemiological Analysis and Early Warning of Disease Outbreaks by Automated Reading and Mining of Pre-Hospital Care Reports","awardID":"0306762","effectiveDate":"2003-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["359532","548306","540676","214892"],"PO":["371077"]},"83122":{"abstract":"Abstract<br\/><br\/>This project will investigate the problem of trust computation (or trust inference) within distributed and completely decentralized systems. Work will specifically focus on trust inference in peer-to-peer networks for distributed resource sharing, where no central authority is assumed. Most systems of this sort are designed based on the assumption that a large fraction of users are \"altrusitic\" while a smaller percentage of users may be arbitrarily \"malicious\". This research is intended to address the more realistic case where all users are \"selfish\" (or \"rational\"), and are motivated by their own self-interest.<br\/><br\/>This work aims to develop appropriate models for analyzing trust inference in distributed systems; to design efficient protocols and mechanisms to ensure cooperative behavior by the users of the system; and to implement such protocols (and test their effectiveness) within the NICE framework developed at the University of Maryland as well as other existing peer-to-peer applications.<br\/><br\/>Graduate and undergraduate students will be involved in all aspects of this research. Software developed as part of this research will be freely distributed for public use.","title":"Distributed Trust Computations for Decentralized Systems","awardID":"0310499","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["548322","519626"],"PO":["561889"]},"82033":{"abstract":"Cluster-based network servers are a cost-effective platform for<br\/>constructing <br\/>large-scale network services. However, service clustering presents<br\/>significant <br\/>challenges to system designers. Many components of the clustering<br\/>support are <br\/>often implemented using centralized or hierarchical architectures, in<br\/>order to <br\/>meet desired performance, consistency, and policy requirements. The<br\/>effectiveness<br\/>of these approaches has been demonstrated under well-controlled<br\/>environments,<br\/>but customized enhancements are often needed to deal with transient<br\/>component <br\/>failures and fluctuating service loads.<br\/><br\/>Peer-to-peer systems are distributed systems without any centralized<br\/>control<br\/>or hierarchical organization, and with functionally equivalent software<br\/>running<br\/>at each node. The primary goal of this project is to improve the<br\/>robustness of<br\/>cluster-based network services using peer-to-peer system design<br\/>principles.<br\/>Specifically, this effort exploits three main principles of peer-to-peer<br\/>system<br\/>design: functionally symmetric architecture, slow-scaling overhead, and<br\/>non-determinism. This project covers various components in service<br\/>clustering<br\/>support, including service location lookup, membership management,<br\/>cluster-wide<br\/>resource management, and replication consistency support.<br\/><br\/>Techniques investigated in this project can greatly benefit network<br\/>service<br\/>designers, for whom it can offer significant improvements in system<br\/>robustness.<br\/>In a broader context, this research complements the ongoing efforts of<br\/>building<br\/>global-scale peer-to-peer systems and services. In addition, this<br\/>project<br\/>directly benefits systems-area instruction improvement at the PI's<br\/>institution.","title":"Improving the Robustness of Cluster-based Network Services Using Peer-to-peer Design Principles","awardID":"0306473","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["550397"],"PO":["543507"]},"83364":{"abstract":"Proposal number: CCR-0311690<br\/><br\/>Title: Quantitative Network Security Analysis<br\/><br\/>PIs: David Moore, Geoffrey M. Voelker, Stefan Savage<br\/><br\/>The research investigates the following questions: how does the nature of<br\/>large-scale Internet security threats change over time, how effective<br\/>are attackers at compromising services, and how well do existing<br\/>security countermeasures provide a meaningful defense against these<br\/>threats in practice?<br\/><br\/>This requires the development of a combination of network analysis<br\/>techniques and network measurement infrastructure to analyze these<br\/>threats. In particular, this project has three specific goals. First,<br\/>our prototype measurement infrastructure will be re-engineered to<br\/>provide real-time analysis about current Internet-wide security<br\/>anomalies. This will allow for active measurements to characterize the<br\/>impact of attacks, the presence and effectiveness of security<br\/>countermeasures and patches, and to better correlate this data with<br\/>other sources of network measurement data. Second, tracking these<br\/>events on a long-term basis allows extraction of trends in the<br\/>prevalence, make-up, and staging of large-scale Internet attacks.<br\/>Creating this kind of longitudinal dataset is essential for<br\/>understanding the evolution of the threats and vulnerabilities being<br\/>exploited. Finally, while there has been initial validation of results<br\/>concerning large-scale homogenous attacks, it is an open question how<br\/>well these techniques can be used for also observing smaller or highly<br\/>skewed attack distributions. This research will evaluate the resolution<br\/>of techniques by comparing with smaller scale monitors and direct<br\/>measurements on individual networks. Together these efforts will<br\/>produce the first meaningful datasets about large-scale network attacks<br\/>on the Internet. It is hoped that this data will ultimately have impact<br\/>beyond the individual results of this research, and will change the way<br\/>network security decisions are made.","title":"Quantitative Network Security Analysis","awardID":"0311690","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["525660","538350","525661"],"PO":["521752"]},"82154":{"abstract":"GeoInformatic surveillance data combined with the right statistical interpretation can enable detection of anomalies, or hot spots, either geographically, over time, or both. The need may be for monitoring, etiology, management, or early warning on topics that are natural, accidental or natural. Many government applications can benefit from such detection, such as carbon budgets, ecosystem health, crop pathogens, invasive species, and public health. This multi-disciplinary grant will develop a prototype system and tool set in collaboration with several Federal agencies using a statistical method known as upper level set scan statistic. The prioritization scheme will be based on multiple criteria using revealing Hasse diagrams and partially ordered sets.","title":"Project Geoinformatic Surveillance: Hotspot Detection and Prioritization Across Geographic Regions and Networks for Digital Government in the 21st Century","awardID":"0307010","effectiveDate":"2003-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["501013",214226,"365516",214228,214229],"PO":["427499"]},"83012":{"abstract":"1) Abstract<br\/>===========<br\/><br\/>Proposal Number:<br\/>CCR-0310793, CCR-0310490, CCR-0310159 and CCR-0310571<br\/><br\/>TITLE:<br\/>Graphical Passwords -- Design, Analysis, and Human Factors<br\/><br\/><br\/>PI: J.C. Birget and Dawei Hong (Rutgers-Camden),<br\/><br\/><br\/>Co-PIs:<br\/><br\/>S. Man (Southwest State U., Minnesota),<br\/>N. Memon (Polytechnic U., Brooklyn),<br\/>S. Wiedenbeck (Drexel).<br\/><br\/><br\/>Abstract:<br\/><br\/>Humans are not good at remembering alpha-numeric passwords, if the passwords are complicated enough to be secure. Graphical passwords seem easier to remember and to use. Here, an image is displayed and the user chooses a few places in the image. To log in, the user has to click close to these places again. Older systems use preprocessed images with predefined click regions, among which a user has to choose. The investigators designed systems that allow users to choose any points as click points, and that allow users to import their own images. The investigators invented a ``robust discretization'' of images; this enables users to produce exactly the same discrete password even though they cannot click on exactly the same pixels at each login. Passwords are vulnerable to ``shoulder surfing'', which consists of a user being observed, or filmed, during login. The investigators designed password systems that are immune to shoulder surfing.<br\/><br\/>One of the objectives of this proposal is a human factors study, concerning learnability, memorability, speed, security (unsafe practices), and user satisfaction of graphical password systems. A second objective is to design new graphical password systems, based on curves, movement, and three-dimensional scenes, as well as to design ``bundles'' of passwords that a user can use on different accounts, and that are easy to remember (and distinguish) as a group. New robust discretization algorithms and probabilistic analyses of the security of graphical password systems will be developed.","title":"Collaborative Research: Graphical passwords: design, analysis and human factors","awardID":"0310159","effectiveDate":"2003-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["559652"],"PO":["521752"]},"83375":{"abstract":"Project Abstract:<br\/><br\/>In this research, we develop efficient congestion control<br\/>mechanisms for high-performance interconnection networks used in<br\/>multiprocessors, distributed network-based multicomputer clusters,<br\/>storage systems, and IP router fabrics. Techniques will be<br\/>explored that allow rapid advancement of packets directly involved<br\/>in network congestion. Our approach is based on adding minimal<br\/>intelligence to routers and network interfaces---in the form of<br\/>speculative scheduling capability---such that resources are maximally<br\/>utilized while packets are efficiently routed. This can be done by<br\/>more effectively steering packets around congested areas and by more<br\/>precisely detecting and handling potential deadlock situations arising<br\/>from cyclically-correlated congestion on a closed set of resources.<br\/>A by-product is that global expansion of congestion trees\/cycles which<br\/>can seriously degrade performance is prevented. In addition to<br\/>developing formal theoretical support for the approach, detailed<br\/>evaluations will be carried out through modeling and simulation.<br\/><br\/>The significance of this research is two-fold. First, by effectively<br\/>dispersing packets out of congested regions of the network, higher<br\/>sustained throughput and lower, more predictable latency can be<br\/>achieved. That is, more data can be sent and received through the<br\/>network over a given period of time, and the time it takes for the<br\/>network to deliver the data can be reduced, with less variability.<br\/>Second, by efficiently resolving deadlock in the network, the<br\/>routing of packets is guaranteed never to come to a halt. These<br\/>important factors allow computer applications which require a great<br\/>amount of communication between system components to run much<br\/>faster and dependably.","title":"High-Performance Network Architecture with Speculative Scheduling for Globally Active Congestion Control","awardID":"0311742","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["293075","325495"],"PO":["562984"]},"83276":{"abstract":"DNA microarrays provide a very effective approach to monitor expression levels of thousands of genes simultaneously. In microarray data analysis, class prediction is a crucial task. The goal of class prediction is to classify and predict the diagnostic category of a sample by its gene expression profile. This project studies class prediction by gene expression profiles and contains four main objectives. First, a new statistical method is proposed to select genes. Second, stochastic discrimination (SD) is proposed to build class predictors. The principle of SD is that it first generates many \"weak\" rules, each of which can serve as a classification method usually with a \"big\" classification error, and then combines these \"weak rules\" in a way to form a strong classifier having a low classification error rate. Multi-class SD predictors will be established by using the two-class technique. Theoretical results on the prediction accuracies of SD predictors will be investigated. Geometric properties of SD predictors will be explored. It is believed that these results will not only significantly enhance understanding the predictors but also constitute the important theoretical support for the application of predictors. Third, a novel procedure is proposed to compare various class predictors. It will address whether or not the true accuracies of predictors differ significantly by statistics, and if such a difference is significant, what range is this difference. Forth, an extensive evaluation of the proposed research work is proposed to be conducted through simulation and by applying the predictors to real life gene expression data sets and comparing the performance of SD predictors with that from other competing algorithms","title":"SD Class Prediction by Gene Expression Profiles","awardID":"0311252","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["438415"],"PO":["499399"]},"83166":{"abstract":"ABSTRACT<br\/>We are studying folding and unfolding processes for polygonal linkages (and other partially rigid structures with many degrees of freedom) in dimensions two and three, with particular emphasis on applications in molecular biology. Our primary focus is on fundamental mathematical properties (topologic, geometric, algebraic) and novel algorithmic approaches, with the long run goal of understanding the fundamental laws of the protein folding simulation problem. We are proposing a novel Monte Carlo approach for move generators in energy minimization simulations in two dimensions, based on mechanisms which simultaneously change many angles and are guaranteed to be collision free, and we investigate the feasibility of extending the approach in three dimensions. The mathematics involved in this research includes techniques from algebraic topology, algebraic geometry and rigidity theory, while the computational effort is expected to lead to developing efficient data structures and algorithms for planning, analyzing, approximating, and tracking such motions. <br\/><br\/>Besides its intrinsic scientific merit, we anticipate this project to have broader impact through a novel way of integrating research, teaching, inter-institutional and interdisciplinary collaborations. The grant will allow one of the PIs, who teaches at the undergraduate level at a women's college, to establish an integrated research group including (besides undergraduates) graduate students. By bringing top research resources and powerful collaborations to an undergraduate institution devoted to promoting the technical education of women in a liberal arts environment, we expect to influence the interdisciplinary curriculum of the future, enhance the infrastructure for research and education at the only women's college with an engineering program, and generate models for training a diverse body of students for graduate work, research and teaching.","title":"Folding and Unfolding of Polygonal Linkages, with Applications to Structural Biology","awardID":"0310661","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1260","name":"INFRASTRUCTURE PROGRAM"}}],"PIcoPI":["264576","312372","521232","550373"],"PO":["565157"]},"82077":{"abstract":"ABSTRACT<br\/>0306613<br\/>Perry, Dewayne<br\/>U of Texas<br\/><br\/>The transformation of a system's software requirements into an appropriate architecture is an extremely difficult task. The architecture represents the creation of a system structure that provides the context of how a software system will implement what the system is supposed to do. The difficulty of this transformation task is exacerbated by the fact that requirements are often ambiguous, incomplete and unstable. Factoring in the need to accommodate as yet unknown uses of the system and requirements that will change during the evolutionary life of that system only makes the task more difficult.<br\/>Our proposal is a continuation of our initial research (the Preskiptor Process [2, 3, 4]) on bridging the gap between a requirements specification for a software system and the architectural specification of that system. This initial is an approach that begins with formal requirements specifications (in van Lamsweerde's KAOS [6, 11, 12]) that are transformed by means of a systematic process into an architectural prescription [11, 12] where the formal logical language for specifying the architectural prescriptions is the same language as that used for specifying the requirement goals. The advantage of this approach is that the abstractions (i.e., the domain specific concepts, the concepts in the problem domain) used in both specifications are easily understood in both contexts and represent the problem domain. Our initial approach solves the basic problem: creating an architectural structure that satisfies the functional requirements specification.","title":"Transforming Requirement Specifications into Architectural Prescriptions","awardID":"0306613","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["486519"],"PO":["564388"]},"86433":{"abstract":"One of the major sources of inefficiency in supply-chain management is information asymmetry; i.e., information that is available to one or more organizations in the chain (e.g., manufacturer, retailer) is not available to others. Information asymmetry is known to create inefficiencies in managing supply chains, among them under-investment in capacity, leading to shortages, misallocation of inventory and transportation, increased prices, and reduced customer service. It can also lead to increased use of premium shipping, increased penalties resulting from line shutdowns, and lost future business contracts. There are several causes of information asymmetry, among them fear that a powerful buyer or supplier will take advantage of private information, that information will leak to a competitor, etc.<br\/><br\/>The Secure Supply-Chain Collaboration (SSCC) protocols we propose will enable supply-chain partners to cooperatively achieve desired system-wide goals without revealing any private information, even though the jointly-computed decisions depend on the private information of all the parties..<br\/><br\/>This project will create new research tools in supply-chain management and foster the development of new techniques in computer science. SSCC also has the potential to profoundly impact supply-chain management practice; and, thereby, improve productivity and stimulate economic growth.","title":"ITR: Secure Supply-Chain Protocols","awardID":"0325345","effectiveDate":"2003-08-15","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[225884,"553652",225886],"PO":["469867"]},"85487":{"abstract":"This project, supporting various collaborative and integrated research projects in networking, bioinformatics, computational chemistry, wireless communication, molecular\/cell biology, and molecular electronics, expands an existing 200-node cluster to an 800-node cluster at LASCA (VaTech Laboratory for Advanced Scientific Computing and Applications). The computational increase enables 8 projects:<br\/> Advanced networking in massive parallel network emulation,<br\/> Cell cycle modeling, <br\/> Multidisciplinary design optimization,<br\/> Microarray bioinformatics, <br\/> Nanoscale molecular electronics, <br\/> Quantum mechanical descriptions of molecular properties, <br\/> Molecular modeling of proteins, <br\/> Design and analysis of wideband wireless communication system.<br\/>The cluster serves as the LASCA focal point for minority internship programs enabling team oriented multidisciplinary graduate education. Moreover, new courses in networking and high performance computing are under development.","title":"Acquisition of a Large Scale Cluster for Research in Computational Sciences and Engineering","awardID":"0321066","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["346629","309296","498314","309299"],"PO":["557609"]},"95167":{"abstract":"Air quality computer models are widely used investigation tools in environmental research;<br\/>many physical and chemical processes are modeled and their integrated impacts on atmospheric pollutant<br\/>concentrations studied. These models are also important tools for regulatory and policy communities, and<br\/>are used to develop optimal emission control strategies for atmospheric pollutants, as required by<br\/>the National Ambient Air Quality Standards.<br\/><br\/>The level of confidence in modeling results depends critically on the accuracy of numerical methods<br\/>employed, as well as on the robustness of the underlying implementation. This research will<br\/>develop state-of-the-art computational methods and software techniques for use in air quality modeling<br\/>work on time stepping methods. Special purpose algorithms will be developed for simultaneous treatment of box model processes, including aerosol dynamics, gas and liquid phase chemistry and interphase mass transfer. Higher accuracies and lower computational times are targeted.<br\/><br\/>Particulate matter (aerosol) processes have recently became a priority focus area in environmental science. Incorporating aerosol processes in the models leads to an order of magnitude increase in the overall computational time. The research will extend into the area of solving the integro-differential equations that<br\/>govern particle evolution; specifically, the proposed work will improve the theoretical framework and will<br\/>build fast and reliable numerical techniques for aerosol dynamics-chemistry simulations.<br\/><br\/>Together with the physical\/chemical process understanding and numerical algorithm design, software tech-<br\/>nology is an important component of these models. Another objective of the project is to explore software<br\/>design techniques and tools that will make the modeling software easier to use, to maintain and to develop.<br\/>The resulting object-oriented version of a generic Eulerian model will illustrate the new approach to soft-<br\/>ware construction and will constitute an ideal environment for developing and testing specialized numerical<br\/>methods.<br\/><br\/>The educational goal is to enhance interdisciplinary education in computationally-oriented disciplines.<br\/>Since much of the science and technology of the future and many of the new industries will cross the<br\/>boundaries of traditional disciplines, interdisciplinary education becomes increasingly important. Some of<br\/>the newest high demand areas involve computing and information technology together with other fields:<br\/>teaching and research will support the development of cutting-edge computationally-involved B.S. programs at Michigan Technological University, and continue to contribute to the Ph.D. program in Computational Science and Engineering.","title":"CAREER: Development of Computational Methods for the New Generation of Air Quality Models","awardID":"0413872","effectiveDate":"2003-08-10","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["518306"],"PO":["565272"]},"83199":{"abstract":"Byrd<br\/><br\/><br\/><br\/>Multiprocessor Performance Optimization using Slipstream Execution Mode<br\/><br\/>Abstract<br\/><br\/>Slipstream execution mode for multiprocessors involves running redundant copies of a parallel task on each processor in a dual-core chip multiprocessor (CMP). One copy of the task is shortened by removing synchronization events and stores to shared memory. This speeds up the execution of the other task through prefetching and other coherence optimizations enabled by a future view of shared memory references.<br\/><br\/>The first objective of this project is to implement slipstream execution mode on actual CMP-based hardware. Given a multiprocessor built from dual-core CMP's, each with shared L2 cache, slipstream mode can be implemented with no changes to hardware. This implementation will validate the utility and scalability of sliptream-mode prefetching on full-sized applications. The second objective is to automate and optimize the mechanism for local synchronization between the redundant tasks, known as A-R synchronization. The choice of mode, ranging from tightly coupled to loosely coupled, can significantly affect the performance of an application. The project will develop run-time and compile-time mechanisms to select the best A-R synchronization mode for an application or region of execution.<br\/><br\/>Slipstream execution mode is a new alternative for shared-memory parallel computation. As more systems are built from CMPs and multithreaded processors, it is imperative that we investigate efficient ways to exploit parallelism at all levels. Slipstream mode offers a performance boost for applications that cannot otherwise take advantage of additional thread-level parallelism. This work will impact important scientific applications, such as quantum mechanics and computational biology that use shared-memory multiprocessing to address large-scale problems.","title":"Multiprocessor Performance Optimization using Slipstream Execution Mode","awardID":"0310847","effectiveDate":"2003-08-01","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["332138","518384"],"PO":["325495"]},"86587":{"abstract":"Shatz<br\/>CCR-0326223<br\/><br\/>A workshop is supported on \"Software Engineering for <br\/>Embedded Systems: From Requirements to Implementation\". This workshop, supported by NSF, ARO, ONR, and AFOSR, considers software engineering issues in embedded systems. The workshop is devoted to exploring the critical problems associated with cost-effective development of high-quality software systems. The purpose of the workshop is two-fold: first, to assess the state-of-the-research in current \"point solution\" approaches to specific problems in this domain; and second, to define a roadmap for future research that bridges gaps left by<br\/>current tools and methodologies and articulates a more complete set <br\/>of technology requirements to guide goal-driven research. The first objective is addressed through presentations by leaders in a variety of relevant areas. The second objective is addressed through presentations of position papers and extensive open discussion periods.<br\/><br\/>The workshop convenes in Chicago in September 2003. Participants are US and international researchers, selected for their expertise in one or more system and software engineering challenge areas related to embedded systems.","title":"Workshop on Software Engineering for Embedded Systems: From Requirements to Implementation","awardID":"0326223","effectiveDate":"2003-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["339525"],"PO":["561889"]},"88303":{"abstract":"During the Fall semester of 2003 the Mathematical Sciences Research<br\/>Institute (MSRI) in Berkeley, California will sponsor a special program in<br\/>Discrete and Computational Geometry. The organizers for this semester-long<br\/>program are Jesus De Loera (University of California at Davis), Herbert<br\/>Edelsbrunner (Duke University), Jacob E. Goodman (City University of New<br\/>York), Janos Pach (New York University), Micha Sharir (Tel Aviv<br\/>University), Emo Welzl (ETH Zuerich), and Guenter Ziegler (Technische<br\/>Universitaet Berlin). The program will have many activities, including<br\/>public lectures, research for undergraduates, mini-courses, weekly<br\/>seminars, and three workshops. This award provides funding to help cover<br\/>lodging and travel expenses for participants in the workshops.<br\/><br\/>The Introductory Workshop is designed to introduce a broad range of<br\/>computer scientists, mathematicians, scientists working in related fields,<br\/>and others interested in the topics of the program to current research in<br\/>these areas. The second workshop, on Mathematical Foundations of Geometric<br\/>Algorithms, is intended more as a forum for researchers in computer<br\/>science and mathematics to discuss their recent work with other active<br\/>researchers. This workshop will focus on the design and analysis of<br\/>geometric algorithms, and on the mathematical and algorithmic techniques<br\/>needed to make these algorithms efficient. The third workshop, on<br\/>Combinatorial and Discrete Geometry, will study discrete geometric objects<br\/>(polyhedra, geometric graphs, sphere packings, tilings, lattices, and so<br\/>forth) and their combinatorial structure, stressing the connections<br\/>between discrete geometry and algebra, combinatorics, and topology.<br\/><br\/>The Introductory Workshop in particular will extend the impact of the<br\/>program well beyond the core of recognized researchers in this particular<br\/>area. MSRI's Human Resources Advisory Committee established the<br\/>introductory workshops in 1992 as a vehicle for making the material of<br\/>MSRI's major programs available to a broad scientific audience,<br\/>particularly women and minorities who are still much too underrepresented<br\/>in the scientific enterprise. Through outreach activities such as a<br\/>special weekend on geometry at Howard University in September 2002, MSRI<br\/>has recruited participants from underrepresented groups to participate in<br\/>its 2003-04 programs and particularly the introductory workshops, and will<br\/>work with these participants to help make the material of the workshops<br\/>useful for their endeavors at their home institutions. The PI and co-PI<br\/>for this grant have already recruited several participants for these<br\/>workshops who are from historically Black colleges and universities, and<br\/>who have expressed a strong interest in bringing material from these<br\/>workshops into contact with students in their undergraduate research<br\/>programs and classrooms.","title":"Discrete and Computational Geometry Workshops at MSRI","awardID":"0336393","effectiveDate":"2003-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["441633","476667"],"PO":["543507"]},"78513":{"abstract":"This project will perform a systematic analysis and design of a network with heterogeneous transport mechanisms. Specifically, the proposer perform the following tasks. First, by mapping all transport mechanisms into the same function space, the proposer will compare the bandwidth received by different transport mechanisms, under different router mechanisms. The following research tasks will be carried out:<br\/>1. Will propose and investigate the effectiveness of router mechanisms to control the difference of the bandwidth received by two transport mechanisms. Instead of designing router mechanisms with indirect objectives, will use optimal control to design them. <br\/>2. Second, by using stochastic differential equations to model aggregated flow dynamics, will analyze the stability and performance of such heterogeneous networks. Will analyze the effects of the mixture of flows on network stability and performance. Will investigate the effectiveness of using adaptive control to control a network with unknown or changing flow dynamics. <br\/>3. Third, will design an end-to-end priority scheme using different transport. This scheme is flexible and deployable because it does not involve modifications to the routers. We will implement applications to demonstrate the usage. <br\/>4. Fourth, will investigate the transport issues in mobile ad-hoc networks, where the limiting resources will be not only bandwidth as in wired network but also energy. Furthermore, such resources will be managed by mobile nodes that will be selfish. Applying an integrated optimization and game-theoretic approach, will investigate heterogeneous transport systems for mobile ad-hoc networks. <br\/>5. Fifth, will also evaluate the effects of application requirements and application adaptation.<br\/><br\/>The proposed research will be integrated in an educational plan which seeks to involve graduate and undergraduate students in the research effort. The PI will also a new class on system modeling and analysis, and add new instructional materials to two courses on computer networks.","title":"CAREER: Networks with Multiple Transport Mechanisms","awardID":"0238038","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["555996"],"PO":["565090"]},"87346":{"abstract":"based architecture to create layered approach to enabling scalable fault tolerance. The This project will focus on the middleware layer used to provide message passing capabilities for distributed memory applications. The system will use a component-design and implementation of the message passing system will provide sufficient flexibility to accommodate a wide variety of application state management and recovery mechanisms. <br\/><br\/>The proposed message passing system will have the following capabilities.<br\/>o Failure detection;<br\/>o Fault tolerance of the run-time system;<br\/>o Fault tolerance of the message passing layer (MPI);<br\/>o Meaningful semantics for the message passing layer in the presence of faults;<br\/>o Flexible application interface for fault notification; and<br\/>o Support for application state management and recovery.<br\/><br\/>This work will be realized as part of the component framework of LAM\/MPI, an existing high-quality implementation of the Message Passing Interface standard.<br\/><br\/>This project will have broader impacts in several areas. Availability of a scalable and reliable middleware layer will enable new levels of application scalability. In addition, new capabilities for MPI jobs can be realized, including process migration, non-stop behavior, and gang scheduling. Since the proposed middleware will be realized in the context of MPI, applications written with MPI can immediately benefit from this work.<br\/>And, since the work will be integrated into a production-quality implementation of MPI, the results can actually be used by a widespread audience. The modular component-based design of our implementation will allow the middleware to be used by a wide variety of state management and application-specific fault tolerance schemes. Finally, important contributions from this work are in the form of interface designs-other implementations of MPI will also be able to adopt these approaches to provide reliability","title":"Scalable Fault Tolerance for MPI","awardID":"0330620","effectiveDate":"2003-08-15","expirationDate":"2008-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["562709"],"PO":["434241"]},"87148":{"abstract":"This project's goal is to develop new motion capture and movement representations inspired by Laban Movement Analysis (LMA). Consider a statement such as: \"Hey, that's John striding across the quad, I'd recognize his bold confident walk anywhere!\" Every human being has his\/her own unique perceivable movement style-repeated recognizable movement elements that can be notated-which a Laban movement analyst would call a \"movement signature.\" These elements in their combinations and phrasing capture the liveliness of a person's movement-his or her dynamic expressiveness. Despite advances in the motion capture process, many important subtleties still get diminished or lost. If applied to computer animation, current motion capture results lack the original dynamic life-quality; the person's movement signature is not preserved, and the animations look rather artificial and robotic. So it is unlikely that John would look like himself in an animation done using current motion capture techniques. The PI will collaborate with artists and scientists that are movement specialists, to study current motion capture shortcomings and to develop LMA filters that explicitly capture perceptually important features and amplify them as necessary to achieve more expressive animations. To this end, the PI plans to exploit new factorization-based capture techniques, and new representations of dynamics that are estimated from example LMA data. The PI will also develop new motion retargeting techniques to transfer and modify the measured dynamic LMA features to other character models. . The PI will apply his techniques to medical analysis and rehabilitation, gesture recognition, and archiving and annotation of movement databases.<br\/><br\/>Broader Impacts: This project will lead to a better understanding of human movement analysis, and to better computer tools that can be used for human movement in applications related to HCI, medicine, psychology, education, entertainment and the arts.","title":"Laban Capture","awardID":"0329098","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["355388",228036],"PO":["565227"]},"82892":{"abstract":"RUI: Using Communication Reduction Techniques to Improve Throughput in High-Performance Networks<br\/><br\/>Abstract<br\/><br\/>This project will develop new techniques to improve throughput in High-Performance Computer Networks by reducing the inherent communication overhead. To meet growing computing needs high performance systems using multiple processors are employed to reduce task latency. While using multiple processors has been successful in reducing the computation time, the overall processing time has not been reduced proportionally. This is due to the communication overhead that occurs when data is exchanged between these processing elements. This research will develop techniques to reduce this communication overhead (thereby improving their throughput) by scheduling these message transmissions. <br\/><br\/>The expected results include new scheduling techniques that can be used in a variety of computing environments such as supercomputers, networks of workstations, mobile networks, the Internet and other architectures to improve overall performance. Additionally, this project will have a profound positive effect on the Computer Science department at IUSB and specifically on the training of its students. The department recently started a Master's degree program and this project will provide the first support for a graduate student and the initial equipment for a cluster of workstations laboratory. Recent studies have shown that involvement in research efforts greatly enhances the education of undergraduate students. With the support of this project, undergraduate students at IUSB will now be given an opportunity to become involved in an exciting research endeavor.","title":"RUI: Using Communication Reduction Techniques to Improve Throughput in High-Performance Networks","awardID":"0309797","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":[216030],"PO":["550859"]},"83640":{"abstract":"This research will develop systematic procedures which take advantage of computer-related developments and advanced combinatorial optimization techniques, to build on previously successful ad-hoc methods for optimizing feature selection in data analysis, with special attention to bioinformatics. Knowledge extraction from data represents a fundamental challenge in information technology research. A very frequent type of knowledge extraction problem is that of analyzing archives of records or observations in order to discover hidden structural relationships. Problems of this type appear in numerous areas of science, technology, medicine, management, and in countless other areas of activity. The advent of the computer and of the Internet have radically increased the role of data analysis, by allowing not only the creation of large, meaningful datasets, but also by making them accessible to researchers all over the globe.<br\/><br\/>One of the most prominent areas of applications of data analysis is in systems biology and bioinformatics. In contrast to molecular biology investigations, which typically focus on single molecules, systems biology pays attention to tens or even hundreds of thousands of biological attributes at the same time. Moreover, the number of attributes included in a dataset is predicted to increase dramatically in the very near future. The new global approach to systems biology has been enabled by new technologies that have allowed the simultaneous measurement of large numbers of attributes and the generation of large multiparameter datasets. These biological datasets represent the domain of bioinformatics. Beside the classic methods of statistics, new approaches to the analysis of data are required. Among others, these methodologies prompt the development of entirely new research areas, including e.g., machine learning, data mining, neural networks, support vector machines. In all these areas of data analysis, the knowledge of a known (finite) subset of observations is used to derive conclusions about the entire set of possible observations.<br\/><br\/>While powerful analytic tools have been developed within the framework of statistics and of newer research areas based heavily on combinatorics, logic and optimization, the size of the problems in the area of bioinformatics (as well as in some other areas), leads to major computational difficulties, and raises the challenge of developing new approaches in which systematic heuristic procedures are integrated into solution algorithms, in order to intelligently reduce the size of the problems to be solved. By using ad-hoc combinations of heuristics and of combinatorics, logic, and optimization based algorithms, this project aims to achieve spectacular reductions of problem size without significant loss in the accuracy of the resulting models.<br\/><br\/>This project will introduce new concepts for evaluating the role and the impact of features in data analysis problems. These concepts combine elements of statistics, combinatorics, information theory, the theory of Boolean functions, the theories of games and of voting. On the algorithmic side, they open possibilities for systematic heuristic approaches to the elimination of redundant features. The project will also introduce new concepts for the comparative evaluation of pairs of features, including those of similarity and domination. These concepts combine elements from statistics, the theory of partially ordered sets, and that of Boolean algebra, and can add to the arsenal of tools available for the elimination of unnecessary features. As opposed to previous studies which view the sets of attributes just as collections of individual attributes, the project proposes a study of the combined efforts of attributes. The research plan includes the development of a local optimality criterion for a set of attributes which should combine the two desired characteristics of a \"support set\": it should allow the construction of accurate models, and it should, at the same time, be of a computationally manageable size. <br\/><br\/>In addition, the project will introduce new, synthetic \"logical\" attributes which allow, on the one hand, the compression of the dataset and, on the other hand, the possibility of finding clearly understandable and practical usable \"logical\" discriminants, which distinguish the positive observations from the negative ones. A very significant application of these ideas is the proposed algorithmic framework for optimizing feature selection. In the field of biological research and bioinformatics, the project introduces: (i) the concept of \"groups of biomarkers\" (obtainable through combinatorial optimization techniques), (ii) an algorithmic hypothesis generator for biological research, and (iii) a new approach for discovering new classes of observations with highly similar characteristics. A publicly available software package will result from the work and is expected to stimulate substantial ","title":"ITR: Optimal Support Set Selection in Data Analysis with Applications to Bioinformatics","awardID":"0312953","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[218057,218058],"PO":["564456"]},"82441":{"abstract":"Proposal #: 0308096<br\/>Title: Augmenting Visual Perception with Real-Time Tomographic Holography<br\/>PI: Stetten, George<br\/>U of Pittsburgh<br\/><br\/>A number of emerging imaging technologies permit inspection directly through walls, into luggage, beneath rubble, and through turbid water or smoke. This proposal describes a new method of displaying such data in situ by merging a stable virtual image of the data with a direct view of its physical location, using a Holographic Optical Element (HOE). The method, Real Time Tomographic (RTT) Display, requires no tracking or head-mounted apparatus, and will operate in the 0.1-5 meter range around the observer, permitting the observer to look directly through intervening structures as though transparent, while taking full advantage of natural hand-eye coordination, stereoscopic vision, and motion cues. The proposed HOE-based technique relates to a recent innovation, the Sonic Flashlight, which uses a half-silvered mirror to perform the same function at a smaller scale for medical ultrasound. The present proposal extends the concept to larger-scale non-medical imaging modalities, including those based on laser or ultrasonic range-finders, ultra-wideband radar, and close-range (underwater) sonar. <br\/>RTT displays represent an important new method of augmenting natural interaction with tomographic data. Investigator George Stetten developed the original mirror-based Sonic Flashlight system and Investigator Andreas Nowatzyk developed the theory for the HOE-based version. <br\/>CMU is a premier center for research and education, especially strong in Robotics, Graphics, and Human\/Computer Interfaces. Student participation is anticipated, including graduate thesis research.","title":"Augmenting Visual Perception with Real-Time Tomographic Holography","awardID":"0308096","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7339","name":"COMPUTER VISION"}}],"PIcoPI":[214953],"PO":["564318"]},"83200":{"abstract":"Rotenberg<br\/><br\/>Virtual Simple Architecture (VISA): Exceeding the Complexity Limit in Safe Real-Time Systems<br\/><br\/>Abstract<br\/><br\/>This project resolves a long-standing problem in embedded systems: bounding the worst-case execution times (WCET) of tasks on contemporary processors. WCETs are essential for real-time scheduling; yet deriving them for contemporary processors is intractable. The Virtual Simple Architecture (VISA) framework shifts the burden of bounding the WCETs of tasks, in part, to hardware. A VISA is the pipeline timing specification of a hypothetical simple processor. WCET is derived for a task assuming the VISA. At run-time, the task is executed speculatively on an unsafe complex processor, and its progress is continuously gauged. If continued safe progress appears to be in jeopardy, the complex processor is reconfigured to a simple mode of operation that directly implements the VISA, thereby explicitly bounding the task's overall execution time by the WCET.<br\/><br\/>VISA provides a general framework for safe operation on unsafe processors, setting up new opportunities for exploiting higher performance in embedded systems.<br\/><br\/>The project anticipates and contributes to a major shift in computing (the kind that occurs once every decade), thus helping to preserve the nation's leadership in this area. Computers have always evolved by integrating higher levels of complexity and performance into smaller systems. In the 1990s, this evolution led to highly functional personal computers (PC) with supercomputer-like performance. Now, in the post-PC era, users interact with embedded computers continuously, transparently, and in real time (e.g., cell phones, cars, airplanes, appliances, industry\/military applications, etc.). This project radically increases the performance, functionality, and reliability of embedded systems, which are vital to the day-to-day functioning of our society.","title":"Virtual Simple Architecture (VISA): Exceeding the Complexity Limit in Safe Real-Time Systems","awardID":"0310860","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["518384","553590"],"PO":["550859"]},"83563":{"abstract":"Lebeck<br\/><br\/><br\/><br\/>Architectural Support for Service Level Agreements<br\/><br\/>Abstract<br\/><br\/><br\/>Data centers comprise an integral part of today's internet-based computing infrastructure upon which society relies. Applications ranging from e-commerce and web servers to grid computing for scientific research use the computation and storage provided by data centers. By consolidating resources, including hardware and system administration, data center customers can reduce expenses. However, customers expect a reasonable level of service from data centers, even with varying demand for the services these systems provide. To maximize service across all customers, a data center can provide differentiated service levels to various applications (customers) based on a contracted Service Level Agreement (SLA).<br\/><br\/>SLAs specify requirements in terms of agreed upon metrics (e.g., performance, availability, output bandwidth, server load), and they usually include several price points for different service levels. Unfortunately, with multithreaded system models (e.g., multiprocessors) simple extensions to conventional uniprocessor metrics can be misleading. The challenge is to develop metrics that bridge the gap between low-level hardware behavior and high-level metrics.<br\/><br\/>The proposed research addresses this need by exploring a design space that includes SLA metrics, system models, hardware-level metrics, and implementations. The project will develop hardware-level metrics by considering both the system model and the intended use of the metric. Once the metric is defined, various hardware implementations can be explored. A case study SLA performance metric and a corresponding hardware metric called Critical Instructions Per Cycle (CIPC) have been developed. Preliminary results with full-system simulation and commercial workloads reinforce the hypothesis that metrics must capture the behavior of low-level hardware.","title":"ITR: Architectural Support for Service Level Agreements","awardID":"0312561","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["555929","536996"],"PO":["325495"]},"83684":{"abstract":"Cryptography is a powerful security tool that has not reached its <br\/>full potential in applications. <br\/>This project investigates approaches to making cryptography easier to <br\/>use at multiple levels: easier for the protocol designer, for the software <br\/>applications, and the policy maker. The project is naturally divided <br\/>into three areas, roughly corresponding to the above list:<br\/> - The study of formal verification methods for protocol design. These<br\/>methods will help the designer to make sure that protocols meet the <br\/>robust security standards accepted by the cryptographic and complexity <br\/>theory communities. <br\/> - The design of versatile cryptographic primitives whose performance <br\/>can be tuned to the needs of specific applications. This includes the <br\/>analysis of cryptographic primitives with respect to modern efficiency <br\/>and security measures, e.g., history independence, incrementality, <br\/>forward security, and combined uses of the above.<br\/> - The analysis of the security and privacy desires of individual users<br\/>and policy makers, and the study of innovative solutions to their problems. <br\/>For example, the project explores the design of identification cards that <br\/>provide secure identification without violating the privacy of the users.<br\/><br\/>Broad impact: Security is vital to ensure public confidence in the information <br\/>infrastructure, and cryptography is a potent tool for computer security.<br\/>Yet, cryptography is currently under-utilized and frequently misused.<br\/>By making cryptographic tools easier to use and understand, the project <br\/>aims to facilitate increased and better informed use of cryptography. <br\/>The project also aims to contribute to the national debate on appropriate <br\/>uses of information technology, and, in particular, explore ways to <br\/>protect individual privacy without damaging national security. Finally, the <br\/>project will contribute to the education of cryptographic specialists <br\/>who can communicate clearly with non-specialists, such as implementers and <br\/>legal experts.","title":"ITR: Cryptography: from user needs to protocol design","awardID":"0313241","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["515842","486529"],"PO":["499399"]},"83211":{"abstract":"Kaeli<br\/><br\/><br\/>Combining Hardware and Software Monitoring for Improved Power and Performance Tuning<br\/><br\/>Abstract<br\/><br\/><br\/>This research will develop state-of-the-art virus detection and recovery mechanisms that will be directly integrated into the microarchitecture of microprocessors. The project will initially focus on addressing stack-smashing attacks, the most common form of malicious code intrusion. The project will explore how to utilize multiple threads to perform lightweight virus detection and recovery. This project will also look to develop new architectural features that support the efficient execution of anti-virus software.","title":"Architectural Support for Virus Detection and Recovery","awardID":"0310891","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["557272"],"PO":["325495"]},"83453":{"abstract":"In Information Technology decisions must typically be made before all inputs are available. Whether it is setting up virtual circuits in order to carry IP traffic over ATM networks, deciding whether to leave a disk spinning in between accesses to data, or keeping cache coherent in a multiprocessor architecture -- online algorithms play a crucial role in such diverse areas as machine learning, robotics, operating systems, network routing, distributed systems, databases.<br\/>It is somewhat surprising that despite such need for online algorithms in Information Technology many fundamental problems remain open.<br\/><br\/>Many problems under investigation are from a 2002 Dagstuhl Workshop on online algorithms, where, in an open problems session, those problems were selected, whose solution were considered to have greatest impact. The investigators focus on these and other problems, some of which represent long-standing challenges in computer science, and whose solution are likely to have enormous impact on Information Technology.<br\/><br\/>The investigators, who have a record of successful research in the area of online algorithms, as well as in other areas of computer science, give substantial effort to cracking some of the hardest outstanding open problems in the area, not by seeking ad hoc techniques, but by developing general tools. A new tool that is used in this project is the concept of knowledge states, which had not been previously formulated by other researchers. In addition to investigating online algorithms in the usual models, the investigators consider other models that involve restrictions on computation resources or information flow, such as tracklessness, limited memory, and limited computational time. These restrictions are intended to model real-life constraints.<br\/><br\/>The investigators concentrate their efforts specifically on the following problems: the deterministic k-server problem for k = 3, the randomized k-server problem for k = 2, the metrical task system problem, the CNN problem, and the cache problem. The investigators examine some additional online problems, such as the weighted server problem, the weighted cache problem, and online scheduling.<br\/><br\/>This research activity aims at significant advancement of knowledge and understanding across a broad area. The investigators are especially seeking a better understanding of the true nature of online randomization. Online algorithms are needed for an enormous variety of practical situations, in fact, most real-life problems require online algorithms, as decisions must typically be made before all inputs are available. Very wide application of the techniques is expected.<br\/><br\/>Broader Impacts: The project seeks to strengthen UNLV as a center for undergraduate and graduate student education in theoretical computer science for Nevada, which as an EPSCOR state has limited funding. In the past, NSF funding has enabled students from Southern Nevada, and especially women and other underrepresented groups to pursue theory at UNLV, and it is important for UNLV to further gain momentum in this area. As in the past, the results of this research are used as teaching material in courses at UNLV. More importantly, a substantial quantity of the material is being made available on the World Wide Web in the form of tutorials, where it is available broadly across the network, especially to non-traditional students. The results are to be disseminated in conferences and society will benefit as the online techniques the investigators develop are applied to many areas, including computer networking, memory management, and databases.","title":"ITR: Online Algorithms and Information Technology","awardID":"0312093","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[217595,217596],"PO":["499399"]},"83695":{"abstract":"Trends in Internet infrastructure drive a shift toward service-based<br\/>computing. Internet-based service providers are adding new data center<br\/>capacity for a variety of services including Web hosting, application<br\/>services, outsourced storage, electronic markets, and other network<br\/>services. In these large scale and rapidly evolving data centers, one of<br\/>the most important challenges is the energy and thermal problem. Data<br\/>centers typically have very high power requirement, which significantly<br\/>increases the difficulty of deploying and expanding a data center due to<br\/>the need for a large power generation infrastructure. Moreover, high<br\/>power consumption can result in high electricity bills and negative<br\/>environmental implications. Another consequence of power consumption is<br\/>heat dissipation. A recent report shows that heat density per product<br\/>footprint in a data center increases around 28% per year, increasing the<br\/>cooling costs for air conditioning. If the temperature is not cooled<br\/>down effectively, excessive heat can cause malfunctions of many devices<br\/>and even shutdown of the entire data center.<br\/><br\/>The proposed research addresses the above problem. More specifically, we<br\/>investigate innovative energy and thermal management schemes for data<br\/>centers with an emphasis on back-end storage, which is one of the<br\/>biggest energy consumers in data centers. To conserve energy and reduce<br\/>heat dissipation, we explore energy and thermal aware storage<br\/>organizations and investigate cross-layer and cross-node,<br\/>energy-efficient, thermally safe and performance-effective management<br\/>schemes for data centers. Moreover, we revisit and redesign existing<br\/>highly-performance-optimized control policies to be energy and thermal<br\/>aware.","title":"ITR: Energy and Thermal Management for Data Centers","awardID":"0313286","effectiveDate":"2003-08-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["551063","551097"],"PO":["325495"]},"83585":{"abstract":"An automaton has states and transitions between states; some states are marked as \"accepting\". Starting from the initial state, a sequence of input symbols causes the automaton to change states in response. If a sequence can cause the automaton to end up at an accepting state, the sequence of input symbols is said to be accepted and is defined to be in the language of the automaton. Finite state machines (FSMs) differ from automata in that all states are accepting and each input symbol is divided into an input part and an output part. Automata and FSMs are used to define \"regular\" languages. <br\/><br\/>Many interesting problems can be defined in terms of automata, FSMs, or Petri nets and the languages involved. These include problems in binary and multi-valued logic synthesis, engineering change, design of discrete controllers, logic verification, testing, deriving winning strategies for discrete games, construction of protocols, and cryptography. It was observed by our group that these diverse applications could be formalized in a unified way in terms of language solving. In general, these problems can be stated in terms of the synthesis of a subsystem or component, given a known environment and an external specification. The component to be synthesized may already exist, in which case the goal is to provide a better or optimum alternative. In other cases, no implementation may yet exist, and the goal is to check if such a desired subsystem exists, and if so to find an optimal implementation. An example of the former is a digital system as found on a microchip composed of interacting components. The system may operate correctly as is, i.e. the system already satisfies its external specification, but one of the components should be improved, in terms of speed, cost, power, etc. An example in which an implementation may be unknown is a control system where we are given a \"plant\" and an external specification, stating that the output of the plant always stays within certain bounds (is stable), and we want to synthesize a Moore type FSM feedback control unit which does the job. \"Engineering change\", occurs when a system has been almost completely designed, but at the last moment, a bug in its concept requires the system's specification to be changed. A question arises if just one component can be changed while the other components are left alone. In a biological system, the ability to make measurements inside a component is often limited, but a model of the component is required to be synthesized. <br\/><br\/>There can be several ways that two subsystems interact (can be composed). In hardware, typically two components are wired together and their interaction synchronized using a clock; on each clock tick, information is exchanged. In software, the communication is \"asynchronous\"; information is sent to another component only after enough time has passed so that the other component has had enough \"cycles\" to compute its result.<br\/><br\/>Such problems can be reduced to solving an equation of the form, ,where X is the unknown component to be derived, A describes the behavior (or environment) of the known part of the system, S is the external specification or desired behavior, is a type of parallel composition operator describing how A and X, are to communicate, and is a conformance relation stating when the overall system satisfies the specification. Like many systems of equations, the solution may not be unique; hence there is also the problem of finding a \"best\" solution. Sets of restricted solutions that have appropriate additional properties are of interest, e.g. no deadlocks or livelocks, or a solution that is a Moore-type FSM.<br\/><br\/>We propose to:<br\/>1. Develop the mathematical tools required for solving equations over various mathematical machines, composition operators and conformance relations.<br\/>2. Determine and characterize, for various problem areas, subsets of restricted solutions, which are of practical interest.<br\/>3. Develop efficient computer tools for constructing solutions within different mathematical representations.<br\/>4. Study and formulate the types of equations that are useful for different applications. <br\/>5. Develop methods for extracting optimum solutions.<br\/>6. Build a software system where the equation is easily specified and efficient tools for constructing optimum solutions have been implemented.<br\/>The last goal is important because the known methods of solutions are computationally complex. This has led to the lack of any system for constructing solutions and exploring these problems. We have already developed a system, MVSIS, for the synthesis and optimization of multi-level, multi-valued, non-deterministic networks. It has been made especially efficient in manipulating logic. We propose to represent language solving problems in MVSIS and develop new implementations of various operations required to derive the solutions. In addition, we will develop methods which find ","title":"ITR: Synthesis System for Discrete Event Systems through Solving Equations over Mathematical Machines","awardID":"0312676","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["518632"],"PO":["562984"]},"82023":{"abstract":"The goal of this project is to develop fast and accurate physics-based parallel transient electromagnetic solvers that are geared towards applications to high-speed circuits. This is being achieved via a combination of high performance parallel algorithms, novel advances in numerical schemes that permit hierarchical computation and finally, the hybridization of different numerical techniques. More specifically, the following objectives are being pursued: (i) development of novel numerical schemes that reduce the overall computational work and the corresponding parallel schemes; (ii) development of parallel and numerical methods for analyzing transient fields in diffusive and dispersive material media; (iii) development of parallel methodologies for integrating differential equation and integral equation based schemes such that one can reap the advantages of both; (iv) and finally, integrating the EM solver developed in the last item into the circuit simulation tool SPICE, to enable fullwave EM simulation of circuits. The principal impact of the proposed research is the development of high performance transient electromagnetic analysis tools that are applicable to a variety of design and analysis problems. The techniques developed are being used to analyze issues in high-speed circuits including on-chip signal integrity, non-linear devices, cross-talk, reflections, and non-linear terminations.<br\/><br\/>Electromagnetic (EM) phenomena constitute the physical underpinnings of applications ranging from electrical to electronic to communication to computer technologies and are completely described by Maxwell's equations. Fast and accurate physics-based simulation tools offer a second modality of investigation into electromagnetic phenomena, and are rapidly becoming indispensable in civilian and military R & D settings. As a part of this endeavor, researchers at Michigan State University and Iowa State University are collaborating on developing an arsenal of fast and accurate simulation tools that permit on-the-fly optimization that can be used for rapid design prototyping of electromagnetic devices. To this end, novel numerical methods for transient electromagnetic analysis and algorithms to parallelize these are being developed. The techniques developed are being applied to the design and analysis of electromagnetic devices.","title":"Collaborative Research: Parallel Hybrid Differential and Integral Equation Based Solvers for Time Domain Electromagnetic Analysis with Application to High-Speed Circuits","awardID":"0306436","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["532976"],"PO":["381214"]},"83596":{"abstract":"Information Technology is making great progress in the operating room. In the practice of minimally invasive surgery, three-dimensional modeling techniques are enabling preoperative planning, new image acquisition and display techniques, and superior dexterity through teleoperated robotic systems. However, one sensory channel is presently ignored in these technological improvements: touch. In manual surgeries, haptic feedback is crucial for palpation, suture manipulation, and detection of puncture events. Sensation of forces is particularly important for invasive tool-tissue interaction tasks such as grasping, cutting, dissection, and percutaneous (GCDP) therapy. Lack of haptic information overloads the visual sensing required of the surgeon, requiring a demanding level attention. For information technology to truly enhance the practice of surgery, multiple sensory channels must be utilized. <br\/> <br\/>We propose to develop instrumentation and algorithms for modeling the haptic aspect of tool-tissue interaction in four common surgical tasks, namely: grasping, cutting, dissection, and percutaneous therapy. This system will significantly enhance information display in three ways. First, data acquired in real time will be used to provide feedback to the surgeon during model-based teleoperated procedures, increasing the transparency. of the robot-assisted surgical system. Second, real-time modeling techniques will enable model-based teleoperation, removing the strict constraints imposed by time delays in traditional, direct teleoperation. Third, realistic surgical simulations will improve training, increasing surgeon competence and patient safety. The instrumentation and modeling algorithms will be used to determine parameter values for different tissue types, particularly liver, prostate, spleen, and kidney. Ex-vivo tissues and phantom hydrogel tissues will be used in these experiments. Once the instrumentation and modeling techniques are developed, we will proceed to extensive validation of the three applications of enhanced information display. Performance experiments will verify improvements in accuracy and precision for direct and model-based teleoperation, and a computer vision\/force sensing system will determine the realism of force and deformation models developed for surgical simulation. This proposal addresses the ITR challenge for developing an information-enhanced display with computational, simulation, and data analysis methods for modeling common surgical GCDP tasks for which currently there is no systematic model. <br\/> <br\/>Intellectual merit: The specific goal of this project is to significantly improve the information-enhanced operating room through the sensing and acquisition of models representing haptic information during tool-tissue interactions in minimally invasive surgery. This research will significantly impact: (a) tool-tissue interaction models that reflect the actual forces and deformation occurring during surgery, (b) haptic feedback to the surgeon during direct or modelbased teleoperation, thereby improving surgical outcomes, c) the development of realistic simulations for training current and future health care professionals, and d) the development of instrumented smart tools for both traditional minimally invasive and robot-assisted surgeries. <br\/> <br\/>Broader Impacts: The PIs from both institutions have an excellent history of involving undergraduate students (both men and women) in research projects through Research Experience for Undergraduates (REU). Additionally, the Drexel Research Experience for Teachers (RET) site proposal recommended for funding by NSF, along with an established RET program at Johns Hopkins, will involve high-school math and science teachers from high schools to participate in summer research projects related to this proposal. These activities will enhance participation of underrepresented groups from inner-city schools and lead to broader dissemination of scientific and technological education of the students and teachers. <br\/>For graduate students, the interdisciplinary nature of this research offers new opportunities in education, broadening the interaction of mechanical engineers and medical professionals. Finally, the proposed research will lead to improvements in surgical outcomes, benefiting the patient and the society at large. <br\/> <br\/>Due to the diverse areas of research required by this project, the proposed research will benefit from the collaboration of PIs from Drexel and JHU. Drexel has expertise in haptics, FEM modeling, grasping\/dissection tasks, and phantom tissues while JHU has expertise in reality-based modeling for cutting\/percutaneous therapies, haptics, and validation experiments for human-machine systems. The unique facilities and collaborations at both institutions, along with strong ties to medical professionals, make this work appropriate as a collaborative research project.","title":"ITR: Collaborative Research: Modeling and Display of Haptic Information for Enhanced Performance of Computer-Integrated Surgery","awardID":"0312709","effectiveDate":"2003-08-15","expirationDate":"2007-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["492593","379044"],"PO":["297837"]},"86500":{"abstract":"ABSTRACT<br\/>0325763<br\/>Ralf Koetter<br\/>U of Illinois @ Urbana-Champaign<br\/><br\/>Network Coding --- From Theory to Practice<br\/><br\/>The efficient use of network resources is a central objective in making information available in today's society. Despite an enormous effort in understanding the modes in which networks can, do, and<br\/>should operate, a unified and concise theory of networking has remained elusive. Before this backdrop, this research aims at developing and leveraging a combined view of a number of traditionally separate, network-related issues. In this context, the research team will investigate issues varying from fundamental questions about the structure of networks employing network coding over an array of specific network scenarios, network robustness, network information theoretic aspects to questions involving practical aspects of networks.<br\/>This ambitious project is driven by the notion of \"Network Coding\", a recent discovery that is central to this proposal. Not only is network coding a fresh and sharp tool that has the potential to open up stagnant fundamental areas of research, but due to its cross-cutting nature it naturally suggests a unified treatment of previously segmented areas. In particular, the research addresses the interplay of network coding in the context of network management, network information theory, compression and channel codes in networks and<br\/>distributed scheduling and routing algorithms. The understanding of intrinsic fundamental performance limits of networks across different tasks, holds the potential to not only create a cornerstone in the<br\/>theory of networks but also to build new and robust bridges between previously unconnected areas.","title":"Collaborative Research: ITR : Network Coding - From Theory to Practice","awardID":"0325673","effectiveDate":"2003-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["509442","320975"],"PO":["432103"]},"85422":{"abstract":"This project, acquiring a Beowulf supercomputer for research and research training in Physics and Chemistry, supports activities in three related research groups:<br\/> Cardiac Dynamics, <br\/> Belousov-Zahobontinsky (BZ) dynamics\/excitable media group, and<br\/> Molecular dynamics.<br\/>The first group studies initiation, evolution, and interaction of scroll waves in an extended system whose cells possess specific dynamic properties within the anatomies of real human and animal hearts. Additionally, this group studies the effect of tissue size on the stability of scroll waves employing computer simulations and models (anatomical, cellular electrophysiology, and means of analyzing wave activity). The second group, often employing partial differential equations with a broad range of temporal and spatial scales, explores mechanisms for the initiation of activity in excitable media, in the BZ reaction (the best-known experimental example of pattern formation in a simple system). This research entails two simulations: First, simulation of the full spatio-temporal dynamics of the onset of spontaneous activations, comparison of macroscopic dynamics with experimental observations, and determination of whether microscopic fluctuations can affect timing in the full reaction-diffusion system nucleating targets. Second, simulations of the full spatio-temporal dynamics of the onset of activations in the high-f regime and in the heart will be used to determine how mechanisms depend upon the excitable medium. In the projects involving proteins, the last group involves several projects in computational chemistry that work in molecular modeling. The Beowulf supercomputer is expected to contribute to visualize large molecules and perform molecular dynamic calculations on them. Its enhanced computational power and speed augment the projects involving quantum mechanical calculations. The molecules in the excited state electronic properties of substituted chalcones are of interest as potential non-linear optical materials and roles as antioxidants.<br\/>The project involves research training in an undergraduate institution. Moreover, training for teachers in community college will take place","title":"MRI\/RUI: Acquisition of a Beowulf supercomputer for physical science research","awardID":"0320865","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["279957","556916","561887",222695],"PO":["557609"]},"85433":{"abstract":"This project from an EPSCoR state, adding a new visualization capability by upgrading current RCF machine, provides high performance resources and training to a broad user base. The infrastructure doubles the current capacity and memory, servicing 15 departments distributed over four campuses. The shared-memory presented to the user by this SGI instrumentation provides a suitable architecture for algorithms that require large amounts of inter-processor communication. The visualization feature allows researchers to view animation or graphical output on their own display, making it possible to work remotely. The visualization capability enables up to 16 researchers to interact simultaneously from remote sites, thus enhancing distance collaboration and educational outreach. Research activities involve:<br\/> Grid Computing,<br\/> Middleware Research,<br\/> Atomistic Computer Simulation for the Nanoscale,<br\/> Mesoscale Meteorological Modeling,<br\/> Genome Research<br\/> Roadway Safety - Modeling Vehicle Crashworthiness, and<br\/> Reducing the Design-Testing Cycle in Systems on a Chip.<br\/>The university will use the infrastructure to enhance diversity.","title":"MRI: Acquisition of High Performance Computing and Data Visualization for Scientists and Engineers","awardID":"0320889","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["485828",222742,"366560","559285","559287"],"PO":["557609"]},"85796":{"abstract":"The motivation for studying walking robots arises from diverse sociological and commercial<br\/>interests, ranging from the desire to replace humans in hazardous occupations, to the restoration of<br\/>motion in the disabled, the possibility of using legged locomotion in terrain that is unsuitable for<br\/>wheeled locomotion, and the psychological appeal of machines that operate in anthropomorphic or<br\/>animal-like ways. Feedback control is an integral part of achieving bipedal locomotion.<br\/>Control system design for biped robots poses numerous challenges due to the many degrees of<br\/>freedom in the mechanisms, the intermittent and unilateral nature of the contact conditions with<br\/>the environment, and underactuation. The most technologically advanced biped robots today are<br\/>walking on the basis of a heuristic control principle that imposes a flat-footed walking motion in<br\/>order to avoid dealing with the underactuation that comes with foot rotation (i.e., toe roll and<br\/>heel strike). Professor Grizzle's research will develop the analytical foundations of walking with an<br\/>anthropomorphic gait. By not relying on heuristics, significantly improved feedback controllers will<br\/>be designed that allow the natural rotation of the foot during the stance phase of walking, while<br\/>still guaranteeing stability of the walking motion. Beyond a certain speed, walking is no longer<br\/>efficient (or even possible). The extremely challenging problem of controlling a running motion<br\/>of a bipedal robot will be investigated, both theoretically and experimentally. These results will<br\/>greatly enhance the ability to design machines that can perform human-like tasks. Another portion<br\/>of the research will look at controlling a robot with a passive knee (active damping but otherwise<br\/>unactuated), analogous to walking with a modern prosthetic.<br\/>Professor Grizzle is actively engaged in undergraduate and graduate student education. NSF<br\/>support of this research proposal is enhancing the research and education infrastructure at the<br\/>University of Michigan through the construction of a biped robot prototype. The robot affords<br\/>experimental facilities and numerous projects for students. This research grant provides for the<br\/>training of one PhD student, and a Research Experience for Undergraduates (REU) supplement to<br\/>this grant will provide a meaningful research experience for two undergraduate students. Special<br\/>attention is being paid to recruiting at least one of these students from an underrepresented group.<br\/>Professor Grizzle is also more broadly sharing the excitement of a research career in engineering<br\/>by making presentations on bipedal walking robots to undergraduate student groups, and high<br\/>school students. On the basis of his research findings in biped robot locomotion control, Professor<br\/>Grizzle is forging research relationships with colleagues in neurology and rehabilitation. His goal<br\/>is to transfer the deeper understanding of bipedal posture and locomotion that is resulting from<br\/>the study of robots, to the development of improved rehabilitation therapies for a class of patients<br\/>who have suffered strokes or spinal cord injuries.<br\/>The research findings of this grant are maintained on Professor Grizzle's web site; see above for<br\/>the URL.","title":"Feedback Control Design for Bipedal Robots","awardID":"0322395","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1518","name":"CONTROL, NETWORKS, & COMP INTE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1519","name":"INTEGRATIVE SYSTEMS"}}],"PIcoPI":["560444"],"PO":["564728"]},"83255":{"abstract":"Infinite-Dimensional Stochastic Hybrid Systems:<br\/>A Unified Framework for Distributed Control with Limited and Disrupted Communication<br\/><br\/>This project pursues a four-year research and education plan to develop a unified framework for distributed control with limited and potentially disrupted communication. This framework utilizes hybrid systems as the modeling tool of choice to combine physical continuous systems, event-based protocols, and real-time software. The project is focused on the specific needs of distributed control over communication networks. The algorithms developed are tested on two testbeds available at the University of California, Santa Barbara (UCSB): the ZEUS Surgical Robotic System and a wireless mobile robotic system.<br\/><br\/>The research pursues significant extensions of hybrid systems theory to address issues specific to distributed control and communication. In particular, the following fundamental issues are investigated:<br\/> Development of a theory for infinite-dimensional and functional hybrid systems, which is needed to deal with (possibly varying) communication and computation delays.<br\/> Extension of hybrid systems theory to a stochastic setting, capable of capturing noise, uncertainty and randomization present in most physical systems and in communication\/scheduling protocols.<br\/> Application to two existing test-beds of these extensions of hybrid systems theory, in order to understand the practical needs of distributed control over communication networks.<br\/><br\/>Broader impacts resulting from the project<br\/><br\/>This project aims at producing rigorous tools to analyze and design distributed control systems that are fully integrated with the communication networks that support them. The emphasis is in the design of systems that are provably correct by construction, minimizing the need for brute force a posteriori validation. The ultimate goal of this research is the design of control systems that are reliable in a realistic (thus not perfect) networked world.<br\/><br\/>The tools and technologies developed are applied to two testbeds: the ZEUS Surgical Robotic System and a wireless mobile robotic system based on ActivMedia's PIONEER-2 wheeled robot. These testbeds provide the practical validation of the fundamental research as well as demonstrate the role of hybrid systems as an enabling technology to areas such as medicine and biology; scientific and industrial sensing and control; and the support of experimental apparatus for science.<br\/><br\/>This project has a strong educational component. Aside from providing funding for students pursuing PhD programs, new courses are added to UCSB's curriculum in the area of hybrid control systems. These courses are interdisciplinary, aimed at students in the areas of control, communications, signal processing, mechanical, and chemical engineering. The intended audience consists of graduate students early in their MS and PhD programs or senior undergraduate students. To this effect (and to facilitate the enrollment of students in different departments) the courses are mostly self-contained with minimal prerequisites. Undergraduate education is specifically addressed through curricular changes to increase awareness towards hybrid dynamics as well as the development of experiments for the College of Engineering Interdisciplinary Control Engineering Laboratory (ICE Lab). By exposing the students to research, it is expected to enhance the transition to industry of the technologies developed and encourage students to develop the rigorous and analytical thinking required for success in scientific research and also in a professional career in electrical engineering.<br\/><br\/>All the results, including papers, reports, and software are available freely to the research community through the world-wide-web. The course materials (including lecture notes, homeworks, laboratory materials, etc.) are also freely available to the academic community.","title":"Infinite-Dimensional Stochastic Hybrid Systems: A Unified Framework for Distributed Control with Limited and Disrupted Communication","awardID":"0311084","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["523607","496514"],"PO":["561889"]},"82045":{"abstract":"The major thrust of this research is representation and operation on terrain data using computational geometry techniques. That includes operations such as data compression, visibility, mobility, and drainage, representing multiple related data layers, and multiple data source correlations, and nonlinear representations. This project is cognizant of the peculiar properties of terrain, including its low level of continuity, its long-range correlations (such as drainage basins), and its vertical asymmetry (there are many local maxima, but few local minima). New terraforming operators include scooping and deposition and erosion. Efficiency in both computational space and time is also a priority. <br\/><br\/>The importance of terrain modeling and computational cartography is attested by the number of companies specializing in this, and by the several database companies attempting to add these features to their generic products. New techniques are necessary because of the growing volume of data from sources such as LIDAR and IFSAR. The techniques developed here will be applicable in a growing range of domains from environmental planning, to radio communication on the Moon and Mars as well as on the earth, and to national defense. Visibility determination has applications from minimizing visual nuisances, to siting of military observers, and to route planning to avoid the other side's observers. The software resulting from this project will be freely available to other researchers.","title":"CG Techniques for Terrain Representation","awardID":"0306502","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["385994"],"PO":["532791"]},"83057":{"abstract":"NSF Proposal 0310297<br\/><br\/>Practical yet Provably Secure Public-Key Primitives<br\/><br\/>Victor Shoup<br\/><br\/><br\/><br\/>This research addresses the fundamental building blocks, or primitives, of<br\/>public-key cryptography, and attempts to design and analyze new primitives<br\/>that improve the state of the art, either through increased efficiency or<br\/>increased security. The objectives are to design new primitives suitable for<br\/>publication in academic journals, as well as for submission to relevant<br\/>standards bodies. The methods used include (1) the \"reductionist\" approach of<br\/>modern cryptography, whereby the security of a scheme is formally reduced to<br\/>the presumed intractability of well-studied mathematical problems (e.g.,<br\/>factoring), and (2) algorithmic techniques from number theory and algebra. <br\/><br\/>Public-key cryptography plays an essential role in securing computers and<br\/>communication networks. The two basic public-key primitives are public-key<br\/>encryption and digital signatures. The first primitive allows a sender to<br\/>secretly transmit a message to a receiver, where the sender only needs to know<br\/>a public key (known to everyone), while only the receiver needs to know the <br\/>corresponding secret key. The second primitive allows a signer, using a secret<br\/>key, to generate a digital signature on a message so that the signature can<br\/>later be verified by any party using a corresponding public key.<br\/><br\/>Although substantial progress has been made in recent years on these problems, <br\/>there is still more work to do, in terms of improving the efficiency of the<br\/>schemes, reducing the strength of the intractability assumptions, improving<br\/>the quality of the security reductions, and in developing practical distributed<br\/>versions of these schemes so as to avoid a single point of failure. These are<br\/>the specific tasks taken on by this research.","title":"Practical Yet Provably Secure Public-Key Primitives","awardID":"0310297","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["340000"],"PO":["521752"]},"78503":{"abstract":"The overall goal of the proposed research is to enable a systematic network provisioning and dimensioning and resource allocation based on accurate traffic modeling for diverse traffic with a vision of providing end-to-end QoS guarantees. The proposed work focuses on four major research thrusts:<br\/> 1. Development of stochastic and deterministic traffic models for elastic and real-time traffic : We will first build faithful stochastic traffic models to study the interaction between transport layer protocols and active queue management mechanisms for macro-management of a large number of connections. We will apply limiting theorems to investigate the asymptotic behavior of the system with a large number of flows and develop scalable macro-scale models. Our findings will be used to develop accurate and yet scalable nonlinear deterministic models to investigate the dynamics of a network with multiple bottlenecks and to predict the expected performance of flows. We will study the effects that congestion at one part of network has on other parts of network. We will also design distributed algorithms to enhance the stability (robustness) of network in case of instability. <br\/> 2. Design of pricing schemes for between end users and service providers and between domains: We will develop non-cooperative incomplete information game models and study the end users' behavior, where users are not assumed to be aware of the precise utilities\/actions of other users and\/or network state. Based on our findings we will design a pricing mechanism that will improve the system efficiency and fairness. We will generalize the models to cases where the selfish users do not know their own utilities precisely. We will also model the problem of inter-domain pricing and service level agreements as a non-cooperative game, where cooperation may emerge as a result of presence of credible threat or incentive. We will use both pricing and QoS parameters of service level agreements as design parameters to induce efficiency among domains and design a distributed algorithm that will ensure convergence to a desired operating point.<br\/> 3. Integration of physical and logical network management: We will propose the integration of physical and logical network management as a means of providing improved end-to-end QoS. We will formulate the problem of designing a unified suite of policies for managing the networks as a Multi-time scale Markov Decision Process (MMDP) problem. This will allow us to break the complex overall problem of designing integrated policies into several simpler MDP problems corresponding to different time scales. We will apply the detailed traffic models we develop for elastic and non-responsive traffic to predict the expected performance of a variety of applications as a function of network configurations and adopted policies. This will be used to design our optimal policies for different time scales, based on selected performance measures such as throughput of elastic traffic, packet loss rate and delay of real-time traffic, and a cost associated with reconfiguration of networks in the form of disrupted service for some flows. <br\/> 4. Wireless link scheduling for end-to-end QoS guarantees: We will extend the optimization problem framework we have proposed recently for resource allocation over a wireless link for non-real-time flows. Using this framework as a starting point we will design an opportunistic wireless scheduling algorithm for real-time and non-real-time applications, which exploits channel conditions of the users. Our approach will be based on multi-objective optimization, which will allow us to efficiently trade-off the performance of one class for that of the other, based on our detailed traffic models for both elastic and inelastic traffic. We will first develop a method of translating the multiple objective functions to a scalar objective function, which allows the designer to achieve Pareto optimality using the simpler scalar objective function. The existence of such a scalar objective function and a mapping has been recently proved by Fleischer. The scalar objective function will then be used to design a wireless link scheduling algorithm that achieves Pareto optimality. The selection of actual operating point on the Pareto frontier will be governed by a set of constraints we impose. This technique will be extended to other resource allocation problems with multi-objective functions. Based on the proposed wireless link scheduling algorithm and its performance, we will investigate the issue of wireless network provisioning.","title":"CAREER: Network Modeling and Resource Allocations","awardID":"0237997","effectiveDate":"2003-08-15","expirationDate":"2009-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["381525"],"PO":["402055"]},"87589":{"abstract":"0331786<br\/>Latecki<br\/>This award supports the PI and a students from Temple University in a collaboration with Christian Freksa of the Department of Informatics at the University of Bremen, Germany. The technical focus of the project is to develop an elaborate and cognitively motivated geometric representation and reasoning formalism for robot localization and mapping. The problems of self-localization, which allows a robot to determine its position using its internal spatial representation, and robot mapping, which uses mobile robots to acquire spatial models of physical environments, are of high importance to the field of mobile robotics. Although current robot mapping and localization techniques are very sophisticated, they do not yield the desired performance. The German group is well known for its work in this field and the Freksa is head of center on Reasoning about Paths, Shapes, and Configurations funded by the German equivalent of NSF, the DFG. Furthermore, the collaboration brings together complementary expertise and equipment.<br\/><br\/>The broader impacts of this collaboration are that it increases interactions between US researchers and those in Germany, it promotes collaborative opportunities and career development for US students, and it enhances the infrastructure for research and education by laying the groundwork for future international research and education opportunities.","title":"US-Germany Cooperative Research: Robot Localization and Robot Mapping Based on Shape Matching","awardID":"0331786","effectiveDate":"2003-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5980","name":"WESTERN EUROPE PROGRAM"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["541851"],"PO":["564152"]},"87248":{"abstract":"0329908<br\/>Anders Host-Madsen<br\/>University of Hawaii<br\/><br\/><br\/>This project considers the communication between sensors in a wireless sensor network. The capacity of such wireless sensor networks is limited both by the interference between different transmissions and by the impairments of the wireless channel, such as fading. This project investigates using cooperative diversity to overcome the limitations of the wireless communication. The gains promised by cooperative diversity are substantial, and the impact on the design of wireless sensor networks could be considerable. Simple forms of cooperative diversity can be build into wireless sensor networks in the near term relatively easily, while more advanced forms can be incorporated in future wireless networks as technology develops. Cooperative diversity can also have a large impact on military networks, both communications networks and sensor-actuator networks. <br\/><br\/>In cooperative diversity, several nodes form a kind of coalition to assist each other with the transmission. The sources jointly act like a multi-antenna transmit array, and the destinations act like a multi-antenna receive array through interchange of messages. There are three advantages from this: diversity, since different paths might fade independently, a power gain through beamforming, and interference mitigation through cooperation on messages transmission. The gain from cooperative diversity is both an increase in rate, measured by ergodic capacity, and diversity, measured by outage or outage capacity. Preliminary results already show very large gains while still hinting at the further considerable gains that can be obtained by optimum signaling. The work planned in this project is 1) Deriving upper and lower bounds for the Shannon capacity of cooperative diversity in fading channels. 2) Developing near-optimum signaling methods for cooperative diversity. 3) Developing simple signaling methods that can be utilized by even simple sensors.","title":"SENSORS: Cooperative Diversity for Wireless Sensor Networks","awardID":"0329908","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["451433"],"PO":["564898"]},"86038":{"abstract":"This research project focuses on a critical problem in network simulations, i.e. the gener-ating of application-dependent, network-independent synthetic traffic that corresponds to a valid, contemporary model of application or user behavior. Specifically, an abstract rep-resentation of network connections will be investigated that captures the dynamics of both end-user interactions and application-level protocols. The representation, called an a-b-t trace, models connections as a series of request\/response exchanges separated by inter-exchange think times. Network packet traces are \"reverse compiled\" into a collec-tion of a-b-t traces that serve as inputs to a synthetic traffic generation engine. The engine will, through a variety of techniques, sample from a collection of a-b-t traces to generate network-independent synthetic traffic that is statistically similar to the original packet trace. This project will investigate a variety of traffic generation techniques and will em-pirically and mathematically validate each. Furthermore, the use of statistical cluster analysis to identify subsets of a-b-t traces will be investigated that correspond to applica-tion connections that are generating statistically homogeneous traffic. The premise of the proposed cluster analysis work is that while literally tens of thousands of port pairs are in use at any one time, the number of distinct types of applications that are in use is far smaller. Beyond enabling better-controlled simulations, the proposed cluster analysis techniques will likely allow providers to better understand the fundamental make-up and structure of traffic currently seen on their networks. For example, instead of seeing 20 thousand active connections on seemingly random port pairs they can identify the 5-10 fundamental traffic classes present. The results of this research will contribute to more accurate and realistic simulations and hence a deeper understanding of the merits of pro-posed network technologies. Finally, the abstract network-independent characterization of network connections can be used to understand the fundamental makeup and evolution of Internet traffic.","title":"Generation and Validation of Synthetic Internet Traffic","awardID":"0323648","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["554765","491562","545866"],"PO":["565090"]},"78547":{"abstract":"Realizing the full potential of the information infrastructure requires building distributed applications in which the capabilities of these myriad devices are harnessed together. The Internet applications of today connect devices (i.e., connecting my browser with the CNN server). The Internet applications of the future will connect environments (i.e., proposer's office with the CNN newsroom). High-performance futuristic distributed applications will employ scores of media streams in conjunction with other types of information (e.g., 3D geometry, control information, structured XML documents, etc.). The networking challenges presented by these applications are fundamentally different than traditional client\/server applications. They are characterized by: <br\/><br\/>Multiple, semantically related flows of information.<br\/>Distributed application architectures.<br\/>Complex adaptive behaviors. <br\/>Extensibility and composability. <br\/>Large bandwidth-delay products. <br\/><br\/>Futuristic distributed applications are difficult to build because current networking infrastructures do not support their characteristic multistream architecture. Doing so is important because these types of applications (e.g., distance learning, tele-medicine, etc.) are most effective when all of the devices in an environment contribute to a rich and immersive experience. The proposed research addresses the networking challenges presented by futuristic distributed multiflow applications. The research will focus on the problems that arise when managing multiple semantically related flows of data within an application. Exploiting high-level semantic relationships between flows is important for achieving application-level goals and appropriately allocating limited network resources. Components of our approach to this problem include:<br\/><br\/>Building protocols informed by both aggregate application behavior and the state of related peer flows.<br\/>Experimenting with network mechanisms integrated across levels of the networking stack. <br\/>Specifically targeting distributed architectures in which applications are implemented across multiple devices. <br\/>Enabling distributed application-driven adaptation which exploits high-level semantic relationships between flows. <br\/>Developing data type (i.e. video, audio, geometry, etc.) representations that are more congruent with underlying protocol dynamics. <br\/>Demonstrating the effectiveness of multistreaming (i.e., transmitting complex media types in multiple flows possibly employing different protocols).","title":"CAREER: Enabling Futuristic Distributed Applications With Integrative Multistream Networking","awardID":"0238260","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["292988"],"PO":["402055"]},"89437":{"abstract":"Microfluidic systems are devices that can manipulate (e.g., handle, store, sort, and analyze) very small amounts of liquids (often much less than a microliter) with very high accuracy. Over the past decade, much progress has been achieved in miniaturizing components such as valves, pumps, and channels, and integrating them onto silicon, glass, or plastic chips. The anufacture of these systems often uses techniques derived from the integrated circuit and microprocessor industry. The goal is to create a <br\/>complete lab on a chip, which could be employed in particular for novel biomedical and chemical tasks, including genomics and proteomics research, pathogen detection, and homeland security.<br\/><br\/>The first generation of microfluidic devices has mostly used designs that are downscaled versions of conventional components, such as micro valves, micro pumps, and micro channels. However, recently a new generation of microfluidic systems has been introduced. These so-called digital microfluidic systemsexploit effects that are only available at very small scales. Electrowetting is such an effect: when a voltage is applied near a droplet that forms a bead on a hydrophobic surface then this droplet deforms in response to this voltage. By appropriate design, one can build systems that can move tiny droplets very rapidly and precisely across a surface. The big advantage of this approach is that the handling of liquid is performed by software and re-programmable at any time, depending on the task one wants to perform. This provides a level of flexibility that does <br\/>not exist in traditional lab equipment or even first generation microfluidics.<br\/><br\/>It is expected that these digital microfluidic systems could handle hundreds or thousands of droplets simultaneously, resulting in massively parallel performance of experiments. However, controlling such a large number the droplets is highly non-trivial: moving hundreds or thousands of droplets between reservoirs, analysis sites, reaction sites, and waste bins could be compared to a parking lot where some cars arrive, others want to <br\/>leave, and yet others maybe want to find a better, shady spot. Our goal is to find the optimal motion plan for all droplets, resulting in a strategy that minimizes the time it takes to perform all experiments simultaneously. <br\/><br\/>Theorists have shown that similar problems (such as the traveling salesman problem) are very difficult to solve optimally. Thus, our task in this project are to (a) develop a good theoretical understanding of the problem, (b) derive methods and computer software to automatically generate optimal solutions, and (c) if part b proves to be too hard, then find <br\/>approximations that are close to optimal but easier to compute. The end result should be a system that takes as input a description of a digital microfluidic system plus all the start and goal states of all droplets, and generates as output a plan that moves all droplets from start to goal in (near) optimal time.","title":"SGER: Optimal Strategies for Moving Droplets in Digital Microfluidic Systems","awardID":"0342632","effectiveDate":"2003-08-15","expirationDate":"2005-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["557263"],"PO":["562984"]},"78558":{"abstract":"This proposal is aimed at studying the resilience of the Internet. The proposer's goal is to answer the question how easy (difficult) it is to break (heal) current networks. Connectivity is a result of the interaction of two mechanisms: the static topology of nodes, links, and routers and the various protocols like routing and DNS that couple these nodes together. The research will be a rigorous evaluation of the complex interaction of the static and dynamic components of networks, the Internet in particular. Will also analyze the recovery behavior of networks, i.e. once a (portion of the) network is attacked or destroyed, how long does it take for the system to return to a state of statistical equilibrium and how far off are the effects of the damage felt. With the PI's prior experience in developing mathematical models for networks, we believe the expected contributions of successful completion of our research are:<br\/> Dynamical models of routing mechanisms on the Internet like BGP, OSPF, and IS-IS. <br\/> Models for other coupling mechanism on the Internet like DNS and various overlay routing mechanisms,<br\/> Modeling and analysis of the couplings between various layers of the Internet protocol architecture<br\/> Validation of the various models with simulation\/measurement studies; incorporation of the impact of hardware\/software implementation details into the models. <br\/> Investigation of the interaction of the mechanisms with real topologies.<br\/> Development of a mathematical theory of a \"recovery index\" for networks.<br\/>The proposer believe our efforts will greatly enhance our understanding of the resilience of networks, and both the research as well as operational communities will benefit with the insights gained. The research will be carried out together with a PhD student directly funded by the grant. The PI and the PhD student will regularly publish and give talks on results from the project. Additionally, money has been budgeted for summer internships for undergraduates that will participate in aspects of the project. The New York Academy of Sciences runs a summer program called \"Science Research Training Program\", which is an 8 week research internship for high school students. The PI is in touch with the program and high school students will be mentored as part of the project under the program. Columbia University also runs a successful outreach program for Bronx area high schools, offering summer internships for minority and underrepresented groups which we plan to participate in. The PI propose to conduct the simulation and test bed evaluation component of the project with the aid of interested high school students and undergraduates.<br\/>The PI teaches a graduate level course on Modeling and Performance Evaluation and a senior level course on Computer Networks on a regular basis. The analytical techniques and models that will emerge as part of the project will be incorporated into the graduate course. The PI has introduced a laboratory component into the undergraduate networks course, and the testbed that is developed as part of the project will be utilized to design novel and interesting lab exercises for the students.","title":"CAREER: Expecting the Unexpected: A Study of Network Vulnerabilities","awardID":"0238299","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["497480"],"PO":["565090"]},"83641":{"abstract":"Distributed applications comprising components from multiple<br\/>administrative domains, pose scalability and availability challenges<br\/>because of the lack of a central administrative authority. This<br\/>project investigates, in the context of the Web Services architecture,<br\/>whether application-level intelligence on the network path between<br\/>clients and services can help address these challenges. The<br\/>intelligence is embodied in modules for inspecting client traffic,<br\/>making decisions about service actions such as replication, request<br\/>redirection, or admission control, and finally realizing these<br\/>actions. The project combines a system architecture for executing<br\/>service-specific actions at intermediate routing nodes with<br\/>application-neutral algorithms for servicing client requests closer to<br\/>the network edge. Both the architecture and the algorithms work with<br\/>a semantic framework, which treats service requests as structured<br\/>accesses against a (physical or virtual) database.<br\/><br\/>The intellectual merits of the activity include (1) development of<br\/>novel techniques and algorithms for automatically scaling<br\/>component-based services in response to adverse client and network<br\/>load conditions; and (2) investigation of architectures for securely<br\/>and efficiently realizing service-specific actions on client requests<br\/>closer to the network edge.<br\/><br\/>Broader impacts of the activity include (1) techniques for improving<br\/>the resilience of the nation's cyber-infrastructure against malicious<br\/>attacks; and (2) integration of the research results into an<br\/>undergraduate-level course that will train students to build<br\/>component-based distributed systems.","title":"ITR: Intelligent Networks for Resilient Web Services","awardID":"0312956","effectiveDate":"2003-08-01","expirationDate":"2006-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[218060,"309341"],"PO":["348215"]},"83652":{"abstract":"Hu\/Vitek abstract<br\/><br\/>Large-scale compute-cycle sharing for complex and large scientific<br\/>applications is a long standing challenge in distributed<br\/>computing. Many cycle-sharing systems have been developed and have<br\/>delivered orders of magnitude improvement in available resources.<br\/>Nevertheless they are limited in their performance or capability.<br\/>Furthermore, other forms of resource sharing and coordination<br\/>are needed to achieve truly distributed access to scientific infrastructure.<br\/><br\/>The goal of this project is contribute to the national science and<br\/>technology infrastructure by developing enabling technologies for<br\/>virtual laboratories open to researchers from all disciplines. This<br\/>infrastructure will leverage resources in peer-to-peer computing and<br\/>programming languages to deliver an alternative architectural model<br\/>for resource sharing over wide area networks. The self-organizing<br\/>aspects of peer-to-peer networks promise to eliminate much of the<br\/>difficulty required to configure and maintain a large-scale globally<br\/>distributed computing and control system, and decentralization removes the<br\/>potential bottleneck and single point of failure of centralized<br\/>service nodes. This project's contributions will be to provide<br\/>abstractions for Peer-to-peer Computing based on extensions to the<br\/>object-oriented programming model and to develop a Peer-to-peer<br\/>Infrastructure which extends the current peer-to-peer networks<br\/>developed for routing and data-centric applications.<br\/><br\/>This project will work collaborativey with the DARPA Program<br\/>Composition for Embedded Systems (PCES) initiative to apply <br\/>the proposed resource-balancing techniques developed in this project<br\/>to sensor networks and distributed real-time systems of national importance.<br\/><br\/>The educational impact of the proposed research includes integration<br\/>of advanced distributed systems research into both undergraduate and<br\/>graduate curricula, and outreach activities that involve high schools<br\/>students into active participation in Internet-scale computing.","title":"PARTAGE: An Open Peer-to-Peer Infrastructure for Cycle-Sharing","awardID":"0313026","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["549800","550994"],"PO":["561889"]},"83542":{"abstract":"This award will provide for the development of a comprehensive system that can efficiently and intelligently extract, analyze and manage very large hyperspectral datasets used for classifying a large variety of land covers in environmentally sensitive ecosystems. <br\/><br\/>Hyperspectral data provide unprecendented spectral resolution which can translate to far superior characterization of remotely sensed areas, but pose significant challenges because of the large data volumes, high dimensionality, little labelled data and large number of potential land cover types or classes. These challenges are being addressed by new adaptive feature space reduction methods that exploit spectral correlations, by semi-supervised and active learning methods for dealing with small training sets, and by knowledge reuse and transfer mechanisms that adapt models developed for one area to new regions with related characteristics. In parallel, a knowledge repository that helps rapidly identify the most pertinent features\/classes for a given area, will be built to substantially reduce data storage requirements and processing time.<br\/><br\/>This inter-disciplinary project requires tight interaction between data acquisition and processing\/analysis, and will provide insights for other engineering problems as well. The visual nature of results from analysis of remotely sensed data make it a powerful modality of introducing the general population to issues of broad concern, such as the impact of global warming and disaster management. Finally, the knowledge transfer mechanisms will be useful for rapidly adapting existing solutions to somewhat different but related problems, thus substantially increasing the utility of existing point solutions in several application domains.","title":"ITR: Extraction and Interpretation of Information from Large-Scale Hyperspectral Data for Mapping and Monitoring Wetland Ecosystems","awardID":"0312471","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["456825","485856"],"PO":["563727"]},"83674":{"abstract":"Dynamic programming is a core algorithmic technique that is commonly used to find the optimal interpretation of ambiguous data (language, speech, genetics, music, vision, etc.) or an optimal response to data (such as a translation, route, plan, or proof). This project is developing a programming language and compiler for weighted dynamic programming. The user writes a simple specification of how to build bigger hypotheses from smaller ones. The compiled code automatically handles many issues such as efficient representation, efficient indexing, fast estimation of trainable parameters, hypothesis pruning, and decisions about which hypothesis to try extending next (based on probability estimates or learned heuristics). The compiler also carries out automatic program transformations that can improve the asymptotic efficiency of a dynamic program. In general, the research considers algorithmic tricks known for particular problems, and generalizes them so that they can be applied to arbitrary dynamic programs.<br\/><br\/>The system is being applied to various natural-language tasks such as parsing, syntax induction, and statistical machine translation. Such tasks benefit from the ability to experiment quickly with new models of language and hence with new dynamic programs. Concrete tasks also provide a testbed for improving the language and compiler.<br\/><br\/>The system will be widely shared. By letting researchers and students execute declarative specifications directly, using the most efficient techniques available, this work will make it much easier to build, train, and experimentally modify large-scale intelligent systems.","title":"ITR: Weighted Dynamic Programming for Statistical Natural Language Processing","awardID":"0313193","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["438772"],"PO":["565227"]},"83685":{"abstract":"Traditional design approaches that treat the processor node, network, and<br\/>sensor\/actuator subsystems as distinctly independent components do not<br\/>apply well to the domain of sensor webs. This is a result of sensor web<br\/>systems being comprised of hundreds of thousands of small, autonomous<br\/>devices that dynamically engage or disengage in the generation of data. <br\/>Nodes within these systems are deployed in an ad-hoc fashion, with no<br\/>a-priori knowledge of network and sensor\/actuator connectivity. <br\/><br\/>These new requirements call for a new machine model that more closely<br\/>supports the sensor webs unique operational and behavioral requirements. <br\/>This research focuses on a holistic system-centric approach that<br\/>defines such a new integrated communications\/computation machine model for<br\/>sensor web nodes. The new machine model is expressed in terms of a Meta<br\/>instruction set architecture (ISA). This Meta ISA defines primitive<br\/>system operations, such as domain selections, data reduction, and<br\/>broadcast across ad hoc networks of nodes, much like the ISA of a CPU<br\/>defining the CPU's primitive operations. The Meta ISA enables consistent<br\/>and reliable system level operation for dynamically changing numbers and<br\/>locations of sensors, and supports multimode data fusion. The Meta ISA<br\/>explicitly supports attribute based naming, which enables the dynamic<br\/>creation of unique knowledge domains across unknown numbers of<br\/>heterogeneous sensor types. A new routing protocol has is studied as an integral part of the integrated computation\/communication model. The protocol is active in<br\/>issuing and decoding Meta instructions throughout the sensor<br\/>web and has been designed specifically to support attribute-based naming<br\/>and formation of knowledge domains across large ad hoc webs. <br\/><br\/>The broader impact of this project includes the development of an educational focus area in the engineering of computer-based systems. Courses include embedded and real-time systems, sensor webs, run time software for embedded systems, and distributed systems. The project is achieving impact for both graduate and undergraduate students by integrating the research agenda and results into the classroom, and focusing collaborative activities. Software tools and hardware platforms developed in this project will enhance student laboratories for experimentation and projects.","title":"ITR: Computation and Communication in Sensor Webs","awardID":"0313242","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["434381","434381","332304","332304"],"PO":["561889"]},"83333":{"abstract":"New mechanism design issues, deeply rooted in algorithmic considerations, <br\/>have arisen with the Internet, since distribution of limited resources <br\/>among a large number of players with varying degrees of collaborative and<br\/>selfish motives is an important consideration in the latter.<br\/>Computational problems underlying solutions to<br\/>these issues, achieving desirable economic criteria, often turn<br\/>out to be \\NP-hard. It is therefore natural to apply notions from<br\/>the area of approximation algorithms to these problems. The<br\/>connection is made more meaningful by the fact that the two areas of<br\/>game theory and approximation algorithms share common methodology<br\/>-- both heavily use machinery from the theory of linear programming.<br\/><br\/>Recent works of the PI include using approximate fixed point computations <br\/>and the primal-dual schema to give a profit-maximizing pricing algorithm and <br\/>a cost sharing method ensuring fairness and truth-revealing for<br\/>multicast routing. Besides applying these techniques to other games,<br\/>the PI would like to characterize cross-monotone methods that<br\/>form the equitable methods of Jani and Vazirani.","title":"Polynomial Time Algorithms for Market Equilibria","awardID":"0311541","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["516928"],"PO":["499399"]},"86622":{"abstract":"This project proposes to perform research on new and theoretically sound profiling techniques for detection and identification of terrorists and cyber attacks. A common thread of problems in such attacks is how can we detect \"bad guys\" from good guys quickly? Various scientific techniques such as data modeling and integration, meta-data management, discrete mathematical models and algorithms, data mining, machine learning, visualization and statistical techniques will be investigated. For example, new mathematical models and algorithms for profiling \"bad guys\/transactions\" will be developed and tested. One research direction is to formulate the problem as a more generalized formulation of the current set covering problem. Efficient algorithms will be developed, and performance bounds of certain algorithms will be studied. Simulations will be done to compare the performance of the new algorithms with conventional algorithms, and the pros and cons of these algorithms will be identified.<br\/><br\/>Making the models more realistic and testing the algorithms\/techniques against more realistic data sets will be done by teaming with LSU's National Center for Security Research and Training (NCSRT) , FBI, AFRL, and others. The project team consists of diverse ethnic groups and plans to organize a workshop dedicated to women and under-represented minority.<br\/>.<br\/>If successful, this project can have significant impact on the scientific community and on the society.","title":"ITR: Research on the Profiling Problem in Cybersecurity and Anti-Terrorism","awardID":"0326387","effectiveDate":"2003-08-15","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["556912",226567,226568,"442377","313180"],"PO":["563751"]},"85533":{"abstract":"This project, developing a Distributed National University Wireless Testbed in cooperation with multi-disciplinary multi-university teams from UCLA, U Mass, and Ohio State, promotes the sharing of resources and expertise among various universities. The work leads towards a national experimentation infrastructure that can serve the wireless communication research and engineering community. The infrastructure enhances the existing local wireless testbed at Rice, contributing to the development of a distributed wireless testbed, and enabling researchers to access a wireless testbed in different remote university sites through web interfaces. The platform, intended to serve as a flexible, programmable, and publicly available testbed, provides a seamless integration of experiments with theory, supporting the following research activities:<br\/> Reconfigurable Wireless Architectures,<br\/> High Data Rate Communication, and<br\/> QoS Scheduling and Modeling for Dense Wireless Networks.<br\/>The web-enabled testbed allows researchers to test, validate, and design RF, baseband, VLSI, and networking components of future systems. At Rice, the research platform will be composed of programmable and configurable multiple antenna wireless communication transceivers based in high speed baseband processors, RF transmitters and receivers, channel emulators, and a programmable RF switching matrix.<br\/><br\/>Providing students a more well rounded education, this experimental communication research offers a<br\/>distinct advantage over a more traditional academic\/theoretical research environment. The distributed research and educational platform will also be utilized for outreach activities, both on campus and via the web interface.","title":"MRI: Development of a National University Wireless Testbed: Rice Configurable Baseband Architecture","awardID":"0321266","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["542042","50058","548311","312197"],"PO":["557609"]},"82024":{"abstract":"This proposal introduces an innovative modeling and rendering primitive, called the O-buffer, for sample-based graphics, such as images, volumes, and points. The two-dimensional or three-dimensional O-buffer is in essence a conventional image or a volume, respectively, except that samples are not restricted to a regular grid. A sample position in the O-buffer is recorded as an offset to the nearest grid point of a regular base grid (hence the name O-buffer). The offset is typically quantized for compact representation and efficient rendering. <br\/><br\/>This project investigates and develops representations, algorithms, applications, and a software system for O-buffers. The intellectual merits of the O-buffer are that it is more precise than a conventional image or volume, provides a more compact representation relative to a finer grid, accelerates rendering and supports low-bandwidth communications, improves image quality, is a flexible representation (e.g., non-regular, non-uniform, multi-resolution), and is a unified framework that can represent, render, and mix unstructured primitives. O-buffers can be harnessed in numerous applications, such as improving simulation systems, scientific visualization, Internet graphics, design and manufacturing, and health care, as well as enhancing and upgrading many other computer systems that use sampled-based data, such as images.","title":"O-buffer: A Framework for Sample Graphics","awardID":"0306438","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["541908"],"PO":["532791"]},"82046":{"abstract":"This project is concerned with the investigation of five specific topics in model reduction. (a) Decay rates of certain system related singular values (Hankel singular values and others related to approximation error bounds); (b) Model reduction for passive systems; (c) Convergence of Krylov-like projection algorithms for model reduction and the establishment of error bounds for such methods; (d) Reduction methods for periodically time-varying systems, and (e) Structure preserving reduction methods for second order dynamical systems.<br\/><br\/>Model reduction seeks to replace a large-scale system of differential or difference equations by a system of substantially lower dimension, that ideally, has the same response characteristics as the original system, yet requires far less computational resources for realization. Such large-scale systems arise in circuit simulation; they also arise through spatial discretization of certain time dependent PDE control systems and in many other applications. For example, an important step in chip manufacturing is the physical verification step, where a detailed simulation, modeling all constituent components of the chip must be carried out to check its behavior. Full simulation is out of the question due to computational complexity. Simulation based upon a reduced model is required to complete the computation in a reasonable period of time. However, it is essential that accuracy of the results is sufficient and that salient physical properties of the chip are faithfully preserved with the reduced model. This research is focused on the development, analysis, and implementation of reduction methods for very large problems. Where needed, the work will involve extending the underlying theory of dimension reduction, particularly for control problems. The primary goal is to provide reliable and efficient dimension reduction methods that preserve structure and system properties with rigorously established bounds on approximation error.","title":"Model Reduction for Structured Dynamical Systems","awardID":"0306503","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["551029","551030"],"PO":["321058"]},"76986":{"abstract":"ABSTRACT<br\/>0230858<br\/>Fred Roberts<br\/>Rutgers U New Brunswick<br\/><br\/>DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science, will<br\/>run a workshop entitled Computational Geometry and Computer-Aided Design and Manufacturing.<br\/>The purpose of this workshop is to promote the interaction between Computational<br\/>Geometry and Computer-Aided Design and Manufacturing by bringing together,<br\/>in a single forum, researchers from both of these .elds to assess the current state of work<br\/>at the interface of the two fields, to identify research needs, and to establish directions for<br\/>collaborative future work. Topics to be addressed include geometric aspects (modeling and<br\/>representation techniques, data structures, algorithms and analysis, software development,<br\/>implementation and testing, etc.) of: manufacturing processes, manufacturing and assembly<br\/>planning, rapid prototyping technologies, model acquisition\/reconstruction, reverse engineering,<br\/>computational metrology and tolerancing, mechanism design, constraint systems,<br\/>simulation and visualization in design and manufacturing, solid modeling related to manufacturing,<br\/>computer vision and robotics related to manufacturing, and manufacturing in<br\/>specific applications (e.g., biomedical, textile, automotive, aerospace engineering etc.).","title":"DIMACS Workshop on Computational Geometry and Computer-Aided Design and Manufacturing","awardID":"0230858","effectiveDate":"2003-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["264120"],"PO":["321058"]},"87304":{"abstract":"Majority of the research results in the field of wireless sensor networking have been substantiated mostly through simulations and empirical measurements, as is common in traditional networking research. For efficient design, in terms of latency, energy, robustness, etc., models that abstract node hardware and the network characteristics are needed for systematic algorithm design and analysis. The proposed work will demonstrate that models of computation for sensor networks (from a parallel and distributed systems' perspective) will create a modular, layered paradigm for application development.<br\/><br\/>The intellectual merit of this research is the development of computation models and robust, adaptive, energy-efficient collaborative algorithms for computation and communication in wireless sensor networks. High-level models will allow designers to make informed decisions regarding energy and time tradeoffs, and robustness at the node and network level - eliminating most of the ad-hoc-ness in application design for sensor networks. The benefits of our approach will be demonstrated on two classes of end-to-end applications. Highly optimized computation and communication kernels for information dissemination in sensor networks, and distributed image processing will be developed.<br\/><br\/>The broader impact of this work is in understanding, modeling, and exploiting sensor networks as a computing substrate - not just a loose federation of nodes equipped with sensors, processors, and radios. We expect this to lead towards a new discipline for programming sensor networks by providing the application developer with high-level technology-independent 'knobs' for analysis and performance optimization. A direct educational impact of the proposed activity will be the introduction of new curriculum in academia to impart knowledge on algorithm design for sensor networks.","title":"SENSORS: Models and Algorithms for Collaborative Computation in Sensor Networks","awardID":"0330445","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["563658"],"PO":["469867"]},"86479":{"abstract":"PROJECT TITLE: ITR: Built-In Test of High Speed\/RF Mixed Signal Electronics<br\/><br\/>PROPOSAL NO.: 0325555<br\/>INSTITUTION: Georgia Inst. Technology, GA<br\/>PRINCIPAL INVESTIGATOR: Abhijit Chatterjee (lead PI)<br\/><br\/>PROPOSAL NO.: 0325371<br\/>INSTITUTION: U. Texas, Austin, TX<br\/>PRINCIPAL INVESTIGATOR: Jacob Abrahams (coPI)<br\/><br\/>PROPOSAL NO.: 0325426<br\/>INSTITUTION: Auburn University, Alabama<br\/>PRINCIPAL INVESTIGATOR: Adit D. Singh (coPI)<br\/><br\/>PROPOSAL NO.: 0325340<br\/>INSTITUTION: University of Florida<br\/>PRINCIPAL INVESTIGATOR:William R. Eisenstadt (coPI)<br\/><br\/>ABSTRACT:<br\/>In the recent past, there has been a tremendous surge in the wired communications\/wireless\/high-speed IC manufacturing sector. While the design community has pushed the design envelope far into the future, the test barriers have not kept pace with the test requirements of high speed, integrated wireless and wired communications designs. Every IC that is manufactured, needs to be tested against its design specifications before shipment to the customer. As the speeds of these ICs increase, so do the requirements of the testers needed to test these ICs in manufacturing production. High-speed testers above 2 GHz are prohibitively expensive. Consequently, for speeds beyond a few GHz (2 - 25 GHz), built-in test (BIT) of high-speed\/RF systems is a very attractive solution. Built-in test involves incorporation of test circuitry in the IC itself to facilitate the manufacturing test process. In this way, many of the test functions are performed \"on-chip,\" alleviating the need for a high-speed (expensive) external tester. Since test cost is projected to escalate to about 40% of the total manufacturing cost of complex communications ICs in the near future, the use of built-in test is expected to significantly impact the cost of the manufactured ICs themselves and the ability of companies to compete in the marketplace.<br\/>The core concept behind the proposed built-in test methodology is easy to follow. Instead of directly measuring the high-speed test specifications of the IC-under-test, a new paradigm for BIT of high-speed\/RF circuits using alternate tests is proposed. Alternate tests are compact tests that are much more simpler to run than the original specification tests but contain as much information (or more) about the performance of the circuit-under-test as the original tests themselves. Furthermore, it is possible to design these tests so that pass-fail decisions can be made, based on analysis of analog signals using analog circuitry. In this way, two problems are solved: (a) that of being able to measure complex high-speed test specifications using simple on-chip test resources and a low-cost external tester, and (b) that of being able to analyze very high-speed signals (> 2 Ghz) without the need to digitize them (such digitizers are not available or are very expensive at these frequencies). The proposed work is interdisciplinary and will involve the use of concepts from computer algorithms, analog\/RF circuit design, mathematics and statistics and fundamental electrical engineering and device physics.","title":"ITR: Built-In Test of High-Speed\/RF Mixed-Signal Electronics","awardID":"0325555","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["550643"],"PO":["562984"]},"86006":{"abstract":"Spin-Based Quantum Computing Using Electrons on the Surface of Liquid Helium: Physics and Computer Architecture<br\/><br\/><br\/>This project is an interdisciplinary effort to investigate the physics and the architecture of a new implementation which uses the spin of electrons on the surface of liquid helium as the qubits.<br\/><br\/>The two major research components are the experimental investigation of the underlying physics of manipulating electrons on helium, and the development of architectures and applications that are best be able to utilize the spin-based system: scalable, but including such constrains as maintaining the electrons well separated and avoiding magnetic perturbations. A tight coupling between these activities guides the physics and device experiments on the one hand, and ensures the development of realistic models for the architecture designs on the other. Experiments are being conducted using gates, much like those in charge-coupled imagers, to control electrons on superfluid helium held in lithographically defined channels. Such parallel structures are prototypical of many spin-based implementations, and a particular focus of the architecture effort is on designs which follow from classical gate-array based accelerators for certain problems.<br\/><br\/>This project gives a broad training to the graduate student and postdoctoral fellow working on it. They conduct and are exposed to a wide range of research, including quantum physics, semiconductor technology, low-temperature physics, algorithms and computer architecture. The project provides a wealth of educational opportunities for undergraduates, both within Princeton and from other schools.","title":"Physics and Architecture of Spin-Based Quantum Computing with Electrons on the Surface of Liquid Helium","awardID":"0323472","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["490409","495323"],"PO":["521045"]},"78416":{"abstract":"Future Internet backbones will have a two-layered architecture: MPLS-capable IP network on top of WDM-based optical network, where the optical layer offers ultra-high bandwidth and the IP layer provides quality of service and traffic engineering capabilities. As businesses and individuals increasingly rely on computer networks to carry mission-critical traffic and real-time traffic, survivability must be a key ingredient of the future Optical Internet. In this project we will investigate various resilience schemes that enable IP over WDM networks to recover from network component failures with minimum service disruption and with efficient use of network resources. <br\/>The research work will focus on:<br\/> Developing intelligent optical layer lightpath protection\/restoration methods for dealing with single\/multiple network failures; <br\/> Developing a new scalable IP layer resilience framework that enbles fast IP flow restoration with low packet loss; <br\/> Developing algorithms for dynamically enhancing capacity and connectivity of logical topology to combat congestion and network partition caused by network failures; <br\/> Understanding various tradeoffs among restoration speed, spare capacity requirement, and algorithm\/protocol complexity; <br\/>Investigating whether handling multiple network failures requires significant amount of extra control complexity and network resources compared with handing single network failures. Performance of the developed algorithms and protocols will be evaluated via simulations. <br\/><br\/>The research efforts will have a significant impact on the evolution of the future survivable optical Internet. The education part of the program is centered around motivating both graduate and undergraduate students to participate in networking research and training students to conduct quality research in the networking area. The findings of this research will be included in class materials and seminars.","title":"CAREER: Resilience Schemes for Survivable IP over WDM Networks","awardID":"0237592","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":[204450],"PO":["565090"]},"89438":{"abstract":"The objectives of this project are to develop efficient and reliable algorithms for direct reinforcement, to learn risk-averse behaviors for problems with high degrees of uncertainty, and to apply the methods developed to an economically important problem: global asset allocation. Reinforcement learning (RL) enables a goal-directed agent to discover strategies through trial and error exploration with only limited feedback. Direct Reinforcement (DR, or \"policy gradient\") methods enable an agent to discover a strategy without the need to learn a value function.<br\/><br\/>Dynamic programming and related value function RL methods are often found to be inefficient, to produce unstable solutions, and to have difficulty scaling up to large problems. Hence, there have been relatively few real-world applications of the value function type RL. This project seeks to make several advancements in Direct Reinforcement that will enable the development of efficient and effective practical applications.<br\/><br\/>By controlling the \"exploration vs. exploitation\" trade-off during on-line learning, DR agents will be able to discover better policies and do so more efficiently. Stochastic optimization methods, such as stochastic \"search then converge\" or annealing of a Boltzmann temperature are candidate approaches. By developing risk-averse reinforcement methods, DR agents will be able to learn robust policies for uncertain or risky environments. Using risk-sensitive intertemporal utilities, DR agents will learn to avoid risky states or actions while they pursue long-term reward. Dynamic programming is widely used in economics and finance, but few attempts have been made to solve important financial problems with reinforcement learning. As a demonstration of risk-averse DR, this project will build a prototype global asset allocation system.<br\/><br\/>Risk-averse direct reinforcement may find application in a variety of engineering domains, from robotics to industrial control to autonomous agents. Many industries, such as energy and the airlines, need to manage operational and financial risks together, in order to avoid supply shortfalls or bankruptcy. Individual investors must manage risk while building their investment portfolios to meet future needs, such as children's college expenses or retirement. Risk-averse Direct Reinforcement may find application in many such contexts.","title":"ITR: Risk, Reward, and Reinforcement","awardID":"0342634","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[234597],"PO":["387198"]},"87018":{"abstract":"Robotics and Computer Vision Program<br\/>Division of Information and Intelligent Systems<br\/><br\/>Abstract<br\/><br\/>PROPOSAL NUMBER: 0328274INSTITUTION: University of Nevada RenoPRINCIPAL INVESTIGATOR: Kim, Kwang J. PROPOSAL NUMBER: 0328275INSTITUTION: University of Nevada Las VegasPRINCIPAL INVESTIGATOR: Yim, Woosoon<br\/><br\/>PROPOSAL TITLE: Collaborative Research: Biologically Inspired Cilia-Driven Microscale Robots<br\/><br\/>Recent advances in smart electroactive polymers have created a unique opportunity to combine microscale science, robotic engineering and biomimetics. These materials can be applied to microscale structures of arbitrary shape with biomimetic features. Largely inspired by nature, we propose an approach in integrating electroactive materials and control into a new class of cilia-driven microscale robots. The objective of the proposed research is to investigate key scientific issues on: i) materials development and identification, ii) biomimetic design of microscale cilia structures, and iii) robotic controls. The proposed cilia-driven microscale robot systems have a wide spectrum of future engineering applications such as drug delivery micro-robots and micro-colonoscopy systems.<br\/><br\/>The goal of the proposed research program is to provide students with the expertise to broadly address the future needs of industry and academia in small-scale science and engineering as well as robotics on small scales. Also, the proposed study will help increase the diversity in the research and educational mission of this effort.","title":"Collaborative Research: Biologically Inspired Cilia-Driven Microscale Robots","awardID":"0328274","effectiveDate":"2003-08-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["441459"],"PO":["335186"]},"89119":{"abstract":"The Society for Industrial and Applied Mathematics(SIAM) will present the Eleventh Conference on Parallel Processing for Scientific Computing. This series of conferences has played a key role in promoting parallel scientific computing and parallel numerical algorithms. The conference is distinguished by its emphasis on the information technology aspects of scientific computing on parallel machines and provides a forum for communication among the scientific computing, information technology, and computational science and engineering communities.<br\/><br\/>The bulk of this grant will support small travel grants to student and junior researchers. The grant will also support travel grants and small monetary awards to winners in a student paper competition and a poster competition. All award decisions will be made by the conference organizing committee (the PI is a Co-chair). SIAM will advertise and coordinate these activities and if this proposal is funded, NSF support will be clearly acknowledged at the conference and its web-site and related publications.","title":"Grant to Support Activities at the Eleventh SIAM Conference on Parallel Processing for Scientific Computing","awardID":"0340869","effectiveDate":"2003-08-15","expirationDate":"2004-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["550407"],"PO":["565272"]},"83521":{"abstract":"Machine learning algorithms are crucial for efficiently automating key tasks in content and information management such as content annotation and categorization, taxonomy creation, content linking, information routing and filtering, robust search, and information extraction. One key factor that has limited the success of machine learning methods in this domain is a conceptual mismatch: The formal assumptions with regard to the type and nature of available training information often differ from what is actually available in real-world applications. <br\/><br\/>This project addresses this mismatch by developing innovative machine learning algorithms and architectures that can make use of more realistic types of training information. This includes in particular the use of weakly labeled data, i.e. training data with ambiguous or incomplete annotations, and a systematic exploitation of dependencies between concepts and between concept annotations. The proposed research will lead to algorithms that have an increased range of applicability and that are more accurate and robust. The scope of the project encompasses well-known special cases like multiple instance learning, label ambiguity, learning with concept taxonomies, learning with overlapping concepts, and label sequence learning. As a proof of concept, tools for categorizing medical documents and for supporting content-based image search will be developed.","title":"ITR: Automatic Content Categorization and Annotation with Ambiguous Training Information","awardID":"0312401","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["236202"],"PO":["563751"]},"83774":{"abstract":"This research concerns the development of mathematical models integrating demographic and genetic mechanisms affecting the ecological and evolutionary dynamics of biological communities, including speciation, extinction, and phenotypic differentiation among populations and species. Research on these processes is usually pursued by independent investigators and relatively little effort has been made to understand their interactions. Integrating population demography with population genetic theory will be performed by employing established mathematical methods for describing and analyzing processes incorporating both deterministic and random components. The models will be applied to analyze data on several different groups of animals and plants using a variety of statistical methods.<br\/><br\/>Improved knowledge of community dynamics and diversification is increasingly important as human population increases, with concomitant destruction and fragmentation of natural habitats, and consequent loss of biodiversity. The ability of societies to preserve and restore mechanisms generating and maintaining biological diversity will significantly impact quality of both human and animal life in the coming decades and centuries. This research includes a substantial training component for graduate students, and a network of national and international collaborators. Results of the research will be widely disseminated in public lectures, peer-reviewed scientific publications, and educational materials for undergraduate and graduate students.","title":"QEIB: Community Dynamics and Diversification","awardID":"0313653","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1127","name":"EVOLUTIONARY PROCESSES CLUSTER"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1174","name":"POPULATION DYNAMICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7229","name":"MATHEMATICAL SCIENCES"}}],"PIcoPI":[218411,"498026","498027"],"PO":["406317"]},"82344":{"abstract":"This project combines new design representations and computational approaches to enable computational conceptual design. The design representations and computational methods leverage the constant increases in computational power and information retrieval reasoning algorithms. Descriptive methods, stored knowledge, and algorithmic reasoning provide the potential for a computational theory of conceptual design that could greatly benefit the designer during difficult stages of concept generation. The underlying theme is the combination and formalization of function-based synthesis, constraint management and state space search. The primary objective of the work is to create a computational theory of conceptual design that can compute design alternatives. The computation will result in a comprehensive space of concept variants and search it for feasible candidates.<br\/><br\/>The activity of concept generation is one of the cornerstones of engineering design. Until recently, the only resources available to a designer during conceptual design were personal experiences and innate abilities. While the designer's resources have advanced significantly in the last three decades, there is still a lack of continuity between computational design tools and conceptual design methods. Many formal methods of conceptual design have yet to be realized as computational algorithms. <br\/><br\/>This research will develop representations and computational methods that allow design concepts to be created from the functional description of a needed product. Through the development of a design knowledge repository and a concept generator that uses the stored knowledge, this research extends the current understanding of the relationship between function and form and codifies it. Also, novel component representations enable computers to determine component compatibility and thus synthesize a concept variant. Additionally, this work is useful for comparison to human design behaviors, as it is built on commonly used design practices.<br\/><br\/>This work is both basic and practical in nature. Thus, the broader impacts extend beyond publication to the usage of the resultant knowledge, methods and tools in education, engineering practice and research. For example, students will be able to use the concept generator to create solutions that, because of their limited experience, they might otherwise not have developed. These solutions will expose students to different disciplines and engineering and scientific domains. The results of this research impact industry and research in a similar manner. In both cases, the research can be used to generate a broader array of solutions much more quickly than would have been possible without it.","title":"Collaborative Research: Creating a Computational Theory for Conceptual Design","awardID":"0307665","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["564650"],"PO":["387198"]},"83202":{"abstract":"ABSTRACT<br\/>0310864<br\/>James E. Fowler<br\/>Mississippi State U<br\/><br\/>In video coding, multihypothesis motion compensation (MHMC) forms a prediction composed of multiple motion-compensated hypothesis predictions in an effort to combat the uncertainty inherent in the motion-estimation process. MHMC techniques---such as those that choose predictions that are diverse spatially (e.g., fractional-pixel prediction), as well as those exploiting temporal diversity (e.g., bidirectional prediction)---have formed an integral part of modern video coders. This research investigates a new form of MHMC---redundant wavelet multihypothesis (RWMH)---which performs motion compensation in the domain of an overcomplete, or redundant, wavelet transform in order to produce motion-compensated predictions that are diverse in transform phase. The redundancy of the transform yields distinct phases that view motion from different perspectives with each phase contributing its own hypothesis as to the true nature of the motion, resulting in rate-distortion performance significantly superior to traditional single-phase systems.<br\/><br\/>The present research focuses on the incorporation of RWMH into modern video-coding systems in order to demonstrate that the RWMH technique functions complementary to other advanced video-coding techniques. Specifically considered is the incorporation of RWMH into a traditional hybrid system consisting of motion-compensating prediction, transform, and quantization, namely the state-of-the-art H.264 reference model. Additionally, RMHW is deployed into modern 3D coders employing motion-compensated temporal filtering (MCTF) in an effort to provide full temporal, resolution, and fidelity scalability. In both systems, RWMH has the benefit that lower-resolution information is predicted with a greater number of hypotheses, corresponding to the greater difficulty inherent in estimating motion at low spatial resolution. Broader impacts of the work stem from the fact that all resulting source code is provided to the video-coding community as part of a large library under an open-source license.","title":"Video Coding Using Multihypothesis Motion Compensation in the Redundant Wavelet Domain","awardID":"0310864","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["530355"],"PO":["564898"]},"83323":{"abstract":"NSF CCR-0311485<br\/>Title: System Security through Fault-Tolerant Cryptography<br\/>PI: Gene Itkis and Leonid Reyzin<br\/><br\/>The research addresses the task of protecting large multi-user systems collecting and managing sensitive data, in which individual system components may be compromised by attacks. Typically, data confidentiality and integrity are ensured with the help of cryptographic tools, whose security relies on secrets, such as passwords and keys. However, in a hostile cyber-environment, these secrets themselves are subject to inevitable exposure. Thus, there is a need to ensure that leakage of secrets will have minimal negative effect: in other words, in order to secure the system, cryptography itself must be made fault-tolerant.<br\/><br\/>This need for cryptographic fault-tolerance is addressed through development and use of intrusion-resilient and tamper-evident techniques. Intrusion-resilient cryptography enables quick recovery from local security breaches. Tamper-evident cryptography provides externally detectable evidence of security breaches even when all the secrets are stolen by the attacker (and thus common cryptographic tools are rendered helpless).<br\/><br\/>The above techniques are applied to a specific system that collects and manages vast amounts of sensitive video data. Such systems have important potential benefits, from providing environments that assist the disabled to helping law enforcement. The research addresses serious privacy and security concerns that hamper their development and deployment.","title":"System Security through Fault-Tolerant Cryptography","awardID":"0311485","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":[217233,"449084"],"PO":["521752"]},"82003":{"abstract":"The promise of new devices and systems whose macroscopic behavior is driven by physical phenomena at the nanometer-scale can only be realized by the intelligent design and analysis of these systems with a well-structured engineering design methodology. The goal of this work is to develop such a methodology and tools that support design and analysis of these systems at multiple levels, from the nano- to the macro-scale.<br\/>The need for a design methodology is driven by the complexity of the emerging nano-technologies on which these systems are based. First, the systems span engineering disciplines (e.g., mechanical, electrical, and biological) and energy domains (e.g., electrical, mechanical, fluidic, and chemical); therefore, design, simulation and analysis tools must work across a multitude of domains. Second, the systems have processes that work at vastly different rates, from femto-seconds to hours, and thus span orders of magnitude in time scales. Finally, the unique property of these systems is that electro-chemical phenomena at the molecular, or nano-scale sets the properties and controls the behavior of systems at the macro, or human-scale. Thus, it is necessary to provide the design engineer with tools that span energy domains, time and length scales in order to design and analyze the ensemble behavior of these systems. <br\/>Therefore, the goal of this research is to create a computer aided design (CAD) framework for the intelligent design and analysis of multi-domain, micro- and nano-scale systems. We will initially focus on sensor and actuator systems. These systems are unique in that they leverage the manufacturing infrastructures of VLSI circuits and directed chemical self-assembly together with the ability to utilize sophisticated electronics to interface sensing components with digital signal processing. Very small physical changes (energies on the order of femto-Joules) can be detected, amplified, and fed to digital signal processing computers. Similarly, the small dimensions of the devices enable high-frequency energy conversion or modulation controlled by conventional digital electronics. <br\/>The results of this work will be new behavioral modeling methodologies and system-level simulation tools to enable multi-domain design flows based on techniques that have proven successful for electronics micro-systems design. Given these tools, micro and nano-system designers will be able to predict the behavior of these complex systems without recourse to time consuming and costly prototyping. This will both increase the number of new systems designed as well as reduce the time-to-market for the next generation of micro and nano-technology based systems.<br\/>Beyond the direct results of this work, the broader impact of this research will come from three efforts. First, will be the development of a new course and education of a group of graduate and undergraduate students in interdisciplinary engineering: developing CAD tools, using those tools to perform design and analysis, fabricating and testing completed designs. Second, will be an expanded infrastructure at the University of Pittsburgh based on collaborations with the John Swanson Center for Micro-and Nano-Systems. Third will be the dissemination of tools, techniques and methodologies for design of multi-domain micro and nano-systems.","title":"Behavioral Modeling of MEMS Sensors for System Level Design","awardID":"0306325","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["560649","549458"],"PO":["562984"]},"83334":{"abstract":"Panda<br\/><br\/><br\/>Designing High Performance and Scalable Communication Subsystems for Next Generation Clusters with InfiniBand Architecture <br\/><br\/>Abstract<br\/><br\/><br\/>Cluster computing systems are becoming increasingly popular for providing cost-effective and affordable computing environments for day-to-day computational needs for a wide range of applications in various disciplines. The emerging InfiniBand Architecture (IBA) standard is being positioned as a strong candidate for high-speed interconnect for next generation clusters. Compared to previous generation cluster interconnects, IBA provides many novel features such as multiple transport services, Remote DMA (RDMA) read\/write support, atomic operations, hardware multicast support, and multiple service levels (priorities). These novel features provide unique challenges and opportunities to design scalable and high-performance communication subsystems for next generation clusters. This research will focus along the following two directions to efficiently support message passing programming paradigm (using the Message Passing Interface (MPI) standard) on clusters: 1) Low-latency, high-bandwidth, and scalable point-to-point communication operations; and 2) High-performance and scalable collective communication operations. Optimal protocols and algorithms along these two directions will be developed while taking advantages of the novel features of IBA. The derived solutions will be evaluated through a set of micro-benchmarks and applications for performance and scalability. Best solutions will be integrated into an MPI implementation and will be available for public use. This will enable architects to design next generation high-end distributed-memory systems with IBA-based clusters. It will also facilitate the end-users to run their MPI applications on IBA-based clusters to harness best performance with scalability.","title":"Designing High Performance and Scalable Communication Subsystems for Next Generation Clusters with InfiniBand Architecture","awardID":"0311542","effectiveDate":"2003-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["561947"],"PO":["325495"]},"82036":{"abstract":"Over the last thirty years computer graphics research has created technology that improves both the realism and generation speed of computer-generated images. However, there is no widely used method for creating realistic images, and it remains difficult in practice to create realistic images. This project aims to develop a practical method for realistic image creation that addresses the visual effects believed to be salient by the graphics and perception communities. The method is intended to be robust, relatively simple, and to have the potential to be interactive in the next decade.<br\/><br\/>The ability to rapidly generate realistic images is useful in many applications. For example, flight and driving simulators rely on realistic imagery, but the interactive nature of these systems limits the realism that is feasible. The proposed work should extend these limits. The proposed method would also be useful for generating images for planning and education; images could be created to help visualize the results of reconstruction efforts, habitat change, and urban planning. Finally the method should be useful for generating synthetic images for input to automated vehicles, where many different scenes and atmospheric conditions could be generated rapidly and at low expense.","title":"Fifth Generation Graphics Hardware","awardID":"0306478","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["332385"],"PO":["565157"]},"85556":{"abstract":"This project from an MSI, developing reliable software in a collaborative setting, requests infrastructure to:<br\/>Create reliable and maintainable software that connects and disseminates geoscience data sets to the Earth Science community through the GEON grid.<br\/>Develop, apply, and disseminate techniques aimed at improving the integrity and reliability of software and data, and<br\/>Educate and train software engineers, particularly those from underrepresented populations who are able to join the workforce and contribute to multidisciplinary projects.<br\/><br\/>The project involves a network, containing two servers and a set of workstations. The first server contains the testbed data necessary for the development and verification of software to transfer and process geospatial data from disparate sources. The second server provides the computing throughput necessary to process large data sets and serves as the backbone of the experimental node on the GEON grid. The equipment supports development of the Geospatial Network (GeoNet) and a toolset for data validation, analysis, and visualization. The lab will also house an experimental node on the GEON Grid.<br\/>SMART Board Interactive Whiteboards with multicolor and touch-sensitive drawing tools are also requested. These boards interface easily with software available to collaborators and facilitate distance collaborations. The project targets the instrumentation of the Collaborative Affinity Research Laboratory (CARL), providing a collaborative environment that is configurable, and that supports local, remote, synchronous, and asynchronous collaborations. The university will continue using the infrastructure to enhance diversity utilizing their Affinity Research model. Thus, students will benefit.","title":"MRI: Acquisition of Equipment to Support Collaborative, Multi-Disciplinary Research and Development of Reliable Software","awardID":"0321328","effectiveDate":"2003-08-15","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["417940","559621","495130"],"PO":["557609"]},"87019":{"abstract":"Robotics and Computer Vision Program<br\/>Division of Information and Intelligent Systems<br\/><br\/>Abstract<br\/><br\/>PROPOSAL NUMBER: 0328274INSTITUTION: University of Nevada RenoPRINCIPAL INVESTIGATOR: Kim, Kwang J. PROPOSAL NUMBER: 0328275INSTITUTION: University of Nevada Las VegasPRINCIPAL INVESTIGATOR: Yim, Woosoon<br\/><br\/>PROPOSAL TITLE: Collaborative Research: Biologically Inspired Cilia-Driven Microscale Robots<br\/><br\/>Recent advances in smart electroactive polymers have created a unique opportunity to combine microscale science, robotic engineering and biomimetics. These materials can be applied to microscale structures of arbitrary shape with biomimetic features. Largely inspired by nature, we propose an approach in integrating electroactive materials and control into a new class of cilia-driven microscale robots. The objective of the proposed research is to investigate key scientific issues on: i) materials development and identification, ii) biomimetic design of microscale cilia structures, and iii) robotic controls. The proposed cilia-driven microscale robot systems have a wide spectrum of future engineering applications such as drug delivery micro-robots and micro-colonoscopy systems.<br\/><br\/>The goal of the proposed research program is to provide students with the expertise to broadly address the future needs of industry and academia in small-scale science and engineering as well as robotics on small scales. Also, the proposed study will help increase the diversity in the research and educational mission of this effort.","title":"Collaborative Research: Biologically Inspired Cilia-Driven Microscale-Robots","awardID":"0328275","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["434794"],"PO":["335186"]},"81992":{"abstract":"Manufacturing semiconductors is hard, making them work right is even harder, and making them work right the first time you turn them on is damn near impossible. <br\/><br\/>This difficult situation is caused by two strongly competing trends: the astounding and ever-increasing complexity of modern chips, and the ever-greater time-to-market demands of the modern technology product cycle. You can take some time and make a highly complex product, or you can make a simple product quickly, but it is extremely hard to make a highly-complex product very quickly. Unfortunately, this is exactly the dilemma faced by today's semiconductor companies.<br\/><br\/>We can't do anything about these market trends, and profitable products will always be complex and hard to build. But, we can do something about the daunting task of figuring out what is wrong with a many-million-transistor circuit that simply refuses to operate properly. This is where our work on fault diagnosis and silicon debug comes in.<br\/><br\/>We are working on ways of quickly but accurately determining the root cause of failure on a defective chip, even when many independent errors contribute to a single bad result. We have developed algorithms that analyze the way a circuit fails, and then use information about the circuit itself to infer the most likely cause of failure. We consider many types of circuit failure, from logic errors to intermittent or timing failures, and are targeting a range of defect mechanisms from common fabrication errors to complex and exotic defect scenarios. We are building tools that will be compatible with industry-standard data formats and toolflows so that our work can have immediate industrial benefit.<br\/><br\/>The goal of our research is to develop sophisticated but efficient algorithms that can deal with the enormous variety of ways that a modern chip can fail. Good diagnosis and debug tools are necessary if the semiconductor industry is to pursue its (nearly) impossible task of producing of higher-quality products at less expense and an ever-shorter time-to-market.","title":"Fault Diagnosis for Yield Improvement and Silicon Debug","awardID":"0306296","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["368045"],"PO":["562984"]},"83511":{"abstract":"The goal in text mining is automatic knowledge discovery from large text collections. The importance of text mining technology comes from its potential to enable the process of hypothesis generation and thereby influence the progress of science. This complex process, a crucial initial step for making scientific discoveries, relies on several factors including intangible ones such as prior experience and intuition. Oftentimes chance connections made serendipitously, later turn out to be fruitful. Text mining tools automatically scour large text collections to identify a small set of hypotheses that are both novel and interesting enough to warrant further research by the user. This research is a study of text mining algorithms, especially those that exploit the metadata associated with text. The specific aims are (1) to implement algorithms designed around three basic text mining functions in a prototype hypothesis generation and knowledge discovery tool and (2) to evaluate this prototype through a set of mining experiments designed to explore knowledge discovery within the biomedical domain. Although biomedicine forms the topical context of this study, the mining functions explored are general and may be applied to any subject area that has a large text database with associated metadata.","title":"ITR: Text Metadata Mining: Extending the Frontiers of Text Based Applications in Biomedicine","awardID":"0312356","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["500661"],"PO":["563751"]},"81333":{"abstract":"This project seeks to outfit offices, classrooms, and public spaces in the Computer Science Department at UNC with multi-projector displays that operate as a single wide-area logical computer display replacing the traditional CRT-based displays now found in these spaces. This infrastructure will enable fundamental basic research in computer graphics, networking, multimedia networking, collaborative systems, and human-computer interaction. The research will consist of an integrated computer systems research effort into the display environment of the future and a large-scale usage experiment to assess the impact of the environments we will construct.<br\/><br\/>As a computer systems research project we seek to explore new technologies and system architectures for supporting high-resolution distributed computer displays. This problem is fundamental to the future growth and development of the computer industry and the fields of computer science and engineering. Modern computer display architecture is a direct result of 1940's vintage television standards, which are outdated in today's digital world. The notion of a raster display that is periodically refreshed from a block of shared processor memory at a constant rate is a direct result of using Cathode Ray Tubes (CRTs) as early computer monitors. Moreover, this \"raster-scan\" approach assumes a dumb device with minimal state and a low-level interface. We believe providing local intelligence within displays will decouple the notion of a display device from the specific computer driving it.<br\/><br\/>We envision treating displays as shared resources that operate independently of the specific computing platforms that present data to them. Our approach provides seamless and symmetric access to the display from any host, and supports multiple simultaneous host connections to a single display. We propose to achieve this via the efficient transport of displayed information, and through the use of effective transport and network-level mechanisms for quality-of-service. Developing higher-level semantics for display interfaces will improve bandwidth utilization. The combination of higher-level interfaces and local intelligence will also improve interaction with the ability to adapt the presentation of a content stream to the specific display platform. In other words, an intelligent display will tailor its presentation according to whether the display is on a low-resolution mobile device or a wall-sized boardroom display. It will, likewise, adapt its display according to available communication bandwidth.<br\/><br\/>In this computer systems research we are proposing four new initiatives. We will investigate and develop new intelligent display architectures capable of overcoming the limitations of traditional frame-buffer architectures. We will develop higher-level and more bandwidth-efficient protocols for communicating data to visual displays. We will extend digital display interconnections so that they are more akin to real-time networks, thus increasing their utility and flexibility. Lastly, we will develop the synchronization and visual context-switching capabilities necessary to virtualize displays so that they can be used as distributed resources. Second, as a large-scale experiment into the use of wide-area displays in offices and classrooms we seek to study the effect of our proposed display architecture on personal work habits and productivity, teaching, student mentoring, and group and peer collaboration. We will undertake traditional user studies to assess the impact and efficacy of the environments we propose to construct.<br\/><br\/>Broader Impact. Ubiquitous displays, large and small, and decoupled from specific computers, will transform the way we live, work, and learn. In the workplace, these displays will enhance collaboration, and alleviate the need to synchronize and transfer files between computers. At home, intelligent displays will provide unprecedented access to information. For instance, displays, which normally show family photographs, could be queried for weather forecasts. At school large projection displays have the potential to revolutionize education and collaboration by enabling the presentation of true multimedia (multiple, independent media streams and windows) from arbitrary sources.","title":"RI: Tera-Pixels: Using High-Resolution Pervasive Displays to Transform Collaboration and Teaching","awardID":"0303590","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["371221","554765","491562","332385","292988"],"PO":["550859"]},"81575":{"abstract":"Abstract<br\/>Proposal No: 304665<br\/>Title: NER: Single Molecule Magnets for Quantum Computing<br\/><br\/><br\/>We are proposing a 1-year nanoscale exploratory research (NER) in the technologically and fundamentally important area of single molecule magnets (SMM) whose application in quantum computing has been the subject of intense speculation. The SMM's typically consist of 2 to 15 magnetic ions embedded in non-magnetic ligand groups. The magnetic interaction strengths within each SMM are in the range 1-100K, while that between SMM's is about 10 mK. These exchange interactions maybe ferromagnetic (FM) or antiferromagnetic (AFM). Although the AFM SMM's appear to exhibit more interesting low temperature quantum effects than do the FM SMM's, the latter have attracted a considerable interest, due to the suggestion that their properties might be exploited to construct useful magnetic storage devices and quantum computers. The two SMM's studied most extensively experimentally, Fe8 and Mn12, have multiple spin-spin interactions within a SMM unit, consisting of both FM and AFM signs, and are difficult to model theoretically. However, since a number of smaller SMM's can be made with magnetic cores that consist of as few as 2-4 magnetic ions, we propose to study initially the effects of the magnetic interactions within SMM's consisting of 3-4 magnetis ions in the electron paramagnetic resonance (EPR) configuration. This environment consists of a constant magnetic induction of strength B0 and a transverse oscillatory magnetic induction with frequency ?0 and strength B1, and can be used to investigate if the SMM's have special features that might allow one to read and write information on the scale of 1-2 nm using a static field that contains a large spatial gradient. By comparing these quantum results with the classical results for the dynamics of these systems, as measured by the various time correlation functions, better understanding would be possible for the larger systems. Such exactly solvable systems will also be studied to investigate the severity of the decoherence that can arise after a SMM has been excited by the oscillatory magnetic induction. This can be investigated by analyzing the EPR linewidths. The information obtained in this exploratory research is expected to provide the knowledge base necessary for developing reliable numerical methods to simulate the behavior of larger systems like Fe8 and Mn12 of more practical interest. A significant outcome of the proposed research will be the education and training of junior members of the PI's group in a subject at the forefront of exploratory research for future applications. Because of the simplicity of the systems, results of the research will be used by the PI for general educational purposes and broader dissemination to the educational community.","title":"NER: Single Molecule Magnets for Quantum Computing","awardID":"0304665","effectiveDate":"2003-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["545995"],"PO":["562984"]},"83401":{"abstract":"ABSTRACT<br\/>0311838<br\/>Pappas, Thrasyvoulos<br\/>Northwestern U<br\/><br\/>There has been much interest in supporting video communication over wireless networks. This is<br\/>not a simple task due to the stringent Quality of Service (QoS) required by video applications and<br\/>the many impairments of wireless channels. Two important QoS characteristics for video are the<br\/>degree of signal distortion and the transmission delay. Wireless channels are lossy, have a timevarying<br\/>response, and are subject to multi-user interference. Furthermore, since users of a wireless<br\/>network are mobile, e.ciently utilizing the available energy is a key consideration.<br\/>The di.culties inherent in wireless video can be addressed at both the physical layer and the<br\/>source coding layer. We jointly consider a combination of these approaches in a cross-layer framework.<br\/>Speci.cally, we consider jointly adapting source coding parameters, such as the quantization<br\/>step-size and prediction mode, along with physical layer resources, such as the transmission rate and<br\/>power. Our goal is to provide acceptable QoS while taking into account system constraints such as<br\/>the available energy. We propose a general framework that allows a number of resource\/distortion<br\/>optimal formulations for balancing the requirements of di.erent applications.","title":"A Framework for Efficient Wireless Video Communication: Dynamic Source\/Channel Adaptation and Distortion Evaluation","awardID":"0311838","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["560218","290859","467427"],"PO":["564898"]},"83533":{"abstract":"Proposal ID: 0312438<br\/>Institution: University of Illinois<br\/>Principal Investigator: Jean Ponce<br\/><br\/>This proposal addresses some of the key scientific challenges that still impede the deployment of technologies for acquiring realistic visual models of the shape and appearance of complex 3D scenes from collections of images. The ability to do this has wide application across a number of areas related to electronic commerce, entertainment iand broadcasting industries and human computer interaction environments. The project will produce novel models of object shape and appearance and effective algorithms for instantiating the models from image data. This will be acccomplished through research activities in the areas of image-based construction of mesh models of complex surfaces from photographs, automated matching and registration of photographs from different viewpoints and development of structure-from motion techniques.","title":"ITR: An Integrated Approach to 3D Photography Using Shape, Texture, and Motion Cues","awardID":"0312438","effectiveDate":"2003-08-15","expirationDate":"2007-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["290030"],"PO":["564456"]},"83654":{"abstract":"The Java programming language made writing multi-threaded programs a mainstream activity. Subtle issues arise in how to compile these multi-threaded programs so that common compiler optimizations are allowed while simultaneously ensuring that actions in one thread are viewed by other threads as occurring in a legal order, i.e. one that follows the programming language consistency model. Because previous languages either did not define a memory model or were not widely used, and because multi-threaded programming was done by a small number of experts, the trade-offs between memory model ease-of-use and the ease of compilation were not extensively investigated. In this project, we are building a compiler that will accept as input a programming language memory model definition, a hardware consistency model definition, and an application program. The compiler will then optimize the application program while abiding by the constraints of both the memory and consistency model, allowing the trade-offs between ease of use and compilation to be studied. It will also allow new memory models to be investigated, which will lead to the design of easier to use languages that can be effectively compiled, and used to produce more robust, safer software.","title":"ITR - Compiler analysis for portability across memory and consistency models","awardID":"0313033","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["533380","550995"],"PO":["565272"]},"83665":{"abstract":"McKinley<br\/><br\/>The rapid expansion of mobile computing infrastructure promises ubiquitous access to the Internet. However, the dynamics of this environment (variable conditions on wireless networks, changing security policies as users roam among wireless domains, and computing priorities that depend on battery life) pose a significant challenge in the design of software infrastructure for mobile systems. One approach to this problem is to introduce a layer of adaptive middleware between applications and underlying transport services. While a traditional role of middleware is to insulate application components from platform variations, an adaptive middleware layer should exploit services provided by the platform operating system to enhance functionality and performance. This project investigates the interaction between adaptive middleware and the operating system kernel. Specifically, the project focuses on the question: What services and interfaces should the operating system provide to enable adaptive middleware to better meet the needs of mobile computing applications? The key hypothesis to be tested is that this relationship is bidirectional: certain middleware functionality is more effective when pushed into the kernel, and certain kernel operations are more effective when combined with middleware-level information. <br\/><br\/>The Kernel-Middleware eXchange (KMX) project builds on the idea that, instead of viewing lower-level middleware as an \"operating system abstraction layer,\" it is also necessary to investigate how this part of the middleware might actively cooperate with the operating system in order to provide applications with supporting functionality that neither part could provide by itself. The project investigates three cross-cutting concerns: quality-of-service of multimedia communication on wireless networks; measures to enhance the security of mobile devices, including adaptive auditing and packet filtering; and managing battery lifetime through data transformations, adaptive process scheduling, and management of network interface card usage.","title":"ITR: Supporting Adaptable Pervasive Computing Through a Kernel-Middleware eXchange","awardID":"0313142","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["472159"],"PO":["561889"]},"83687":{"abstract":"Development of self-organizing sensor network applications can be <br\/>simplified with distributed composition services that cooperate with <br\/>distributed adaptation and lookup services to enable sensor nodes <br\/>to be self-aware, self-configurable, and responsive to real-time <br\/>changes. This research focuses on developing novel concepts, architecture <br\/>and mechanisms for distributed composition services that support <br\/>continuous operation of self-organizing applications to meet on-demand <br\/>needs in spite of ad-hoc deployment, frequent node failures, dynamic <br\/>reconfiguration, and mobility. The utility of the self-organizing <br\/>services will be demonstrated in collaborative sensor fusion <br\/>applications for detecting, classifying and tracking moving objects <br\/>and distributed sensor-actuator control. The testbed is an ad-hoc <br\/>network of sensor nodes that are equipped with embedded processors, <br\/>RF communication, multi-mode sensors and actuators. Sensors nodes <br\/>are augmented as reconfigurable smart components with capabilities <br\/>for impromptu networking, self-assembly, dynamically adaptation to <br\/>device failure and degradation, node mobility, and changes in task <br\/>and network requirements. They use innovative techniques including: <br\/>(1) Services and mechanisms for self-organizing sensor applications, <br\/>(2) scalable hierarchical composition services, (3) lightweight <br\/>reconfigurable communication mechanisms, and (4) implementation of <br\/>distributed services over event-based data-centric networks. Broader <br\/>impacts of this research include the development of advanced and <br\/>introductory course curriculum and innovative sensor network testbeds <br\/>and laboratories for education and research training of graduate and <br\/>undergraduate students including minority students.","title":"Distributed Composition Services for Self-Organizing Sensor Network Applications","awardID":"0313248","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["397118"],"PO":["565090"]},"82004":{"abstract":"Algorithms for large-scale numerical optimization that rely on derivative information require the repeated estimation of Jacobian and Hessian matrices. Since this is an expensive part of the computation, efficient methods for estimating these matrices via finite differences or automatic differentiation are needed. The problem of minimizing the number of function computations can be formulated as variants of distance-k graph coloring problems. In this research project, graph coloring algorithms to aid the solution of large-scale optimization problems are designed, analyzed, and implemented on serial and parallel computers. The specific coloring problem depends on the optimization context: whether the Jacobian or the Hessian is evaluated; whether all the nonzeros or only a subset need to be estimated; whether a direct method or substitution method is employed; and whether elements are estimated by partitions of columns alone, or partitions of both columns and rows. These variations lead to ten different matrix estimation problems and their graph coloring formulations. By unifying graph-theoretic formulations for estimating Jacobians and Hessians, a few general coloring problems that can be adapted to the different cases are identified. The focus is on developing new graph coloring algorithms and software for partial matrix estimation to precondition optimization problems.<br\/><br\/>Optimization involves choosing the best option among many possible scenarios from a computational model of a physical situation, such as a manufacturing process involving chemically reacting fluid flows, or the simulation of electronic devices and circuits. In many such large-scale applications of optimization, computing the derivatives is a tedious, error-prone, and expensive task. Automatic differentiation methods and finite difference techniques have been devised in recent years to make this task less demanding and more reliable. This research project provides software infrastructure to reduce the computational time and storage needed to compute the derivatives using automatic differentiation or finite differences in large-scale optimization. One postdoctoral research associate and a graduate student, the former from an under-represented group in computer science, are being trained in combinatorial scientific computing. A module on graph coloring for estimating Jacobians via finite differences is being incorporated into an undergraduate scientific computing course, and undergraduate students are involved in developing and testing components of the software. With the involvement of colleagues at the Department of Energy's Argonne National Laboratory and Sandia National Laboratories, the software from this research is being applied to simulate chemically reacting flows and circuit models.","title":"Distance-k Graph Coloring Algorithms for Numerical Optimization","awardID":"0306334","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["518525"],"PO":["381214"]},"83698":{"abstract":"Social isolation is an acute problem for those who are survivors of a Traumatic Brain Injury (TBI). Many of these individuals are left with long-lasting alterations in social, behavioral, physical, and cognitive functions. A typical TBI survivor is a young to mid-life adult, living either in government-assisted housing, with their family, or in rarer cases in their own house or apartment. Survivors are universally afflicted with social isolation. This project focuses on one aspect of social isolation, that of community access. Many TBI survivors are unable to do independent travel to go to the store, to see a doctor, to attend a community social event. Not only do they find it impossible to drive within the community, they also have problems using the bus system or even traveling by foot to a destination. It is clear that high technology, in the form of wearable navigation devices, has potential to help. What is missing are (1) solid data on the actual needs of TBI survivors in accessing their community, (2) a means to assess the skills and impairments of individual survivors in terms of using navigation devices, (3) a process that produces both a training plan and a \"prescription\" that matches a survivor with a custom device. This proposal takes on each of these questions. Its results will allow the assistive technology industry to (a) build devices that are useful to the TBI population, and (b) do the matching that is necessary to get the right device into the hands of an individual.<br\/><br\/>Broader Impacts: Prevalence estimates range from 2.5 to 6.5 million individuals living with the consequences of TBI, with that number growing with advances in medical procedures at the scene of the accident, in emergency medical care, and in neurosurgery. The incidence rates for the most severe traumatic brain injuries are higher than those for spinal cord injury, multiple sclerosis, cerebral palsy, and muscular dystrophy combined.","title":"Community Access for the Brain Injury Population","awardID":"0313324","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["449118","449119"],"PO":["565227"]},"85524":{"abstract":"This proposal, from a RUI institution in an EPSCoR state, developing tools and documentation, aims at reducing the learning curve and lowering the preparatory barriers that inhibit scientists from taking advantage of multi-processor computations. The project, proposing a 100 node Beowulf cluster, is expected to:<br\/>a. Assist in the conversion of single processor applications to a parallel computational environment, and<br\/>b. Reduce learning time and code porting time for scientists to effectively utilize the computational power of multi-processor systems.<br\/>The work spans two colleges, Engineering and the Arts and Sciences, and enjoys participation across six academic departments. Various problems, including topics in hydrology, seismology, civil engineering, atmospheric fluid mechanics, oceanic currents, wave propagation, mathematics (numerical methods and solving ODE's in parallel), electromagnetics, neural networks, will be ported to the cluster and include,<br\/>a. Inelastic Wave Propagation, Soil Dynamics, Soil Permeability, Atmospheric Modeling,<br\/>b. Parallel Computation, Character Recognition.<br\/>c. Hydraulic Tomography, Waveform Relaxation Methods,<br\/>d. High-Energy Astrophysics, and Nanotechnology.<br\/>The interaction between a team of computer scientists, client scientists, and students should result in a user paradigm facilitating the conversion of the diverse scientific problems. The platform should serve as an asset for future research and educational activities.","title":"Development of Tools to Enable the Port of Software to a Beowulf Cluster","awardID":"0321233","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[223130,"472939"],"PO":["557609"]},"83115":{"abstract":"The objective of the proposed research is to investigate and develop a comprehensive framework for the automatic synthesis of custom processors. The scope of the proposed framework includes all the necessary steps to generate the custom processor's architecture, starting from one or more embedded software programs that it is required to execute. The problems that we will tackle are as follows. We will develop techniques for efficient automatic generation of hardware extensions -- custom instructions and co-processors -- to a base processor platform, for large hierarchical application programs. The complexity of realistic application software, together with the multi-granular nature of the hardware extensions, necessitate the development of new techniques that start from a hierarchical program representation and identify custom instructions and co-processors that maximize performance or minimize energy consumption under given design constraints. The number of individual candidate custom instructions and co-processors can be quite large for even moderately sized programs, and hence the number of combinations thereof is even larger. We will develop techniques to efficiently explore the unified custom instruction and co-processor design space, and select an optimal combination of custom instructions and co-processors (from individual candidates) that maximizes performance or energy efficiency. High levels of hardware re-use are critical for deriving efficient implementations of custom processors. Various custom instructions derived for a given application may exhibit commonality that can be exploited to either reduce the area overhead or improve performance\/energy impact under a given area constraint. In addition to conventional fine-grained resource sharing techniques, we will develop new coarse-grained sharing techniques to obtain high quality designs. Software transformations, if appropriately applied to the target application program before attempting to derive hardware extensions, can facilitate the generation of higher quality custom instructions or co-processors, leading to much higher performance and energy gains. We will develop a method to automatically apply a suitable sequence of enabling transformations to the application. <br\/><br\/>Efficiency and flexibility are two major requirements driving embedded system design. Unfortunately, these two requirements are typically at conflict with each other - performance and energy efficiency are often obtained by hardwiring functionality and optimizing the system in an application-specific manner, which limits flexibility, while flexibility is obtained through configurability and\/or programmability, which carry associated overheads. Negotiating this tradeoff is critical in a wide variety of applications, ranging from high-performance systems to battery-driven systems. <br\/><br\/>Application-specific instruction set processors (ASIPs) offer a good tradeoff between efficiency and flexibility by realizing only the critical operations in the application(s) of interest using custom hardware. Conventional approaches to ASIP design are based on designing and implementing a new instruction set and processor architecture from scratch for each application. Unfortunately, the design turnaround time for such approaches may be large and is comparable to design cycles for custom hardware implementations. The recent evolution of customizable and extensible processor technology, such as Tensilica's Xtensa and ARC's ARCTangent processor cores, has provided embedded system designers with a mechanism to design ASIPs with rapid turnaround times through the use of re-targetable software development tool flows, and configurable soft intellectual property (IP). However, the task of customizing the processor and extending it with custom hardware (instruction units, co-processors, peripherals) are still largely manual and left to the designer's expertise. In order to realize the potential for energy efficiency as well as flexibility that ASIPs offer, it is necessary to develop high-level methodologies that automatically identify application hot-spots and map them to custom hardware that extends the underlying configurable platform. <br\/><br\/>No algorithms or tools exist for extensible processor platforms that address any of the above problems. We have taken the first step in this direction by developing algorithms and a tool to automatically identify custom instructions for extensible processors. This tool results in an average performance improvement of 3.4X (up to 5.4X) and an average energy-delay product improvement of 12.6X (up to 24.2X).","title":"Application-specific Instruction Set Processor Synthesis for Low Energy and High Performance using Extensible Processor Platforms","awardID":"0310477","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["550002"],"PO":["562984"]},"83478":{"abstract":"This project investigates web querying techniques for accessing web information resources. The term information resource refers to large web-accessible resources such as the ACM Digital Library. We propose a semantics-based way of accessing a web information resource: extract metadata about topics and relationships from the web resource, extend the metadata with \"importance scores\", and query it from a database. The query language is extended with constructs (a) to propagate importance scores to the query output to rank query output, and (b) to define \"stopping conditions\" to reduce query evaluation times.<br\/>For some query requests, the metadata in the database may not be sufficient to answer queries. Our research direction is to locate more informative query answers by mixing database querying with \"focused crawling\" in the web information resource, at the algebraic operator level of SQL queries. These queries allow time constraints, and relax the closed world assumption, making it necessary to redefine the notion of well-defined queries.<br\/>Data extraction techniques will be employed to extract metadata. Variations of our basic approach that do not require direct database query engine changes will be evaluated. Standalone web applications will be developed, and made available.","title":"ITR: Querying Web Resources Using Metadata in a Database","awardID":"0312200","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["448583","393279"],"PO":["563751"]},"92069":{"abstract":"Constrained Power and Performance Optimization for Embedded Systems<br\/><br\/>The goal of this research is to explore techniques for power management of<br\/>embedded systems with provable bounds on power efficiency as well as adverse<br\/>effects on latency due to power management. The current state of the art in<br\/>system-level power management is limited to shutting parts of a system after<br\/>a certain period of idle time, thus ignoring the application timing<br\/>constraints, runtime traffic and application usage information. This work<br\/>will develop power-performance control \"knobs\" that will allow us to make<br\/>effective online decisions. Specific applications will include power-aware<br\/>resource scheduling in RTOS, timing-aware power optimizations and tradeoffs<br\/>between power savings and application quality of service (e.g., missed<br\/>deadlines).<br\/><br\/>Our technical focus is on solving two key problems: (a) latency-constrained<br\/>power optimization, i.e., minimization of system-level power consumption<br\/>with constrains on the effect of system latency due to power management; and<br\/>(b) power-constrained performance optimization, e.g., system-level task<br\/>implementation and scheduling within a given power budget. As a first step,<br\/>we focus on analytic bounds on the effectiveness of online power management<br\/>algorithms and their efficiency by developing bounds on latency increases<br\/>due to power management. We introduce the notion of a competitive ratio as<br\/>a quantitative measure of how well a given power management algorithm<br\/>performs against an optimum power consumption profile. Next, we incorporate<br\/>these analytic bounds in a broader system-level timing and power simulation<br\/>engine which enables an accurate performance simulation while minimizing the<br\/>details related to actual system functionality. Our experimental evaluation<br\/>is through RTOS implementation of new power management services through<br\/>coordinated scheduling and resource shutdown.","title":"Constrained Power and Performance Optimization for Embedded Systems","awardID":"0355071","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["457653"],"PO":["562984"]},"83258":{"abstract":"Project Abstract:<br\/><br\/>Systems are only as secure as their weakest point of attack. Indeed,<br\/>the only way to increase the security of a system as a whole is to<br\/>improve the resilience of its most vulnerable component. Much<br\/>successful research has focused on developing cryptographic protocols<br\/>which are secure as long as some information (i.e., a key) is kept<br\/>secret from the adversary. However, as such algorithms are<br\/>increasingly deployed on inexpensive, mobile, and unprotected devices<br\/>(e.g., laptops, mobile phones, and PDAs), the risk of key exposure is<br\/>becoming a serious threat to the security of many real-world<br\/>systems. This project aims to develop new paradigms and to design<br\/>efficient algorithms for maintaining security even in the event of a<br\/>key exposure attack. Among other topics, the project will focus on (1)<br\/>forward-secure public-key encryption; (2) forward secrecy in<br\/>key-exchange protocols; and (3) protecting signcryption schemes<br\/>against key exposure attacks. The techniques developed as part of this<br\/>research are expected to help improve the security of a number of<br\/>different systems, from handheld devices to ad-hoc networks.<br\/><br\/>Graduate students will be involved in all aspects of this project, and<br\/>undergraduate involvement will be encouraged as well. The techniques<br\/>stemming from this research will be incorporated into undergraduate<br\/>and graduate courses in cryptography and computer security. In these<br\/>ways, the project will help train future scientists in the important<br\/>area of information security.","title":"Collaborative Research: Mitigating the Damaging Effects of Key Exposure","awardID":"0311095","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["550227"],"PO":["561889"]},"83269":{"abstract":"Orthogonal variable spreading factor (OVSF) code provides a means of<br\/>support of variable rate data service at low hardware cost in CDMA<br\/>wireless systems. In an OVSF-CDMA wireless ad hoc network, a code<br\/>assignment has to be conflict-free, i.e., two nodes can be assigned the<br\/>same codeword or two non-orthogonal codewords if and only if neither of<br\/>them is within the transmission range of the other and no other node is<br\/>located in the intersection of their transmission ranges. In this<br\/>proposal, we propose to study various optimization problems on<br\/>conflict-free channel assignments in OVSF-CDMA wireless ad hoc networks.<br\/>The proposed studies include conflict-free channel assignment for maximum<br\/>throughput, for maximum bottleneck rate, and for both at the same time,<br\/>and transmission scheduling for minimum schedule duration when all nodes<br\/>have specified transmission rate. All these optimization problems are<br\/>expected to be NP-hard even when all nodes have the uniform transmission<br\/>radii. We will prove the NP-hardness of these problems and develop<br\/>provably good polynomial-time approximation algorithms. These studies are<br\/>both theoretical challenging and practical important for the deployment of<br\/>OVSF-CDMA wireless ad hoc networks. Furthermore, since wireless ad hoc<br\/>networks support applications related to disaster relief, public event<br\/>coordination, and military and law enforcement operations, increasing<br\/>their throughput and communication bottleneck has vast societal impact.","title":"Prefix-Free Vertex Coloring for Channel Assignment in OVSF-CDMA Wireless Ad Hoc Networks","awardID":"0311174","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["518604","560173"],"PO":["499399"]},"85579":{"abstract":"This project, acquiring robotics equipment for an Intelligent Systems Laboratory (ISL), aims at facilitating the development of cross-disciplinary courses and providing exciting research possibilities. Furnishing opportunities of joint collaborations with other disciplines, ISL enables students and faculty to investigate, design, and implement control algorithms using non-traditional techniques derived from various subdisciplines of Artificial Intelligence, such as fuzzy logic, neural networks, genetic algorithms, hybrid approaches. ISL fosters research and development of solitary cooperating autonomous or teleoperative mobile robots for a variety of tasks such as gathering data from potentially hazardous environments and facilitating search and rescue missions.<br\/>Areas identified for research, motivated by terrorist attacks, include:<br\/> Design and deployment of intelligent agents for bio-surveillance and threat detection, and<br\/> Design and implementation of large-scale hybrid systems tools for soft computing, complexity analysis, and intelligent applications.<br\/>Robotics kits will be acquired, facilitating research, research training, and integrated research\/education activities at various academic levels. New interdisciplinary courses will be developed and cross-listed in Machine Intelligence, Intelligent Systems, Design and Applications, Intelligent Control, and Autonomous Robots. Moreover, participants will be recruited for Girls SRC, a Summer Robotics Camp for junior high school.","title":"MRI\/RUI - Aquisition of robotics equipment for an Intelligent Systems Laboratory","awardID":"0321385","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[223362,223363,223364],"PO":["557609"]},"86426":{"abstract":"ABSTRACT<br\/>0325324<br\/>Michelle Effors<br\/>California Instit. Of Tech<br\/><br\/>Network Coding --- From Theory to Practice<br\/><br\/>The efficient use of network resources is a central objective in making information available in today's society. Despite an enormous effort in understanding the modes in which networks can, do, and should operate, a unified and concise theory of networking has remained elusive. Before this backdrop, this research aims at developing and leveraging a combined view of a number of traditionally separate, network-related issues. In this context, the research team will investigate issues varying from fundamental questions about the structure of networks employing network coding over an array of specific network scenarios, network robustness, network information theoretic aspects to questions involving practical aspects of networks.<br\/>This ambitious project is driven by the notion of \"Network Coding\", a recent discovery that is central to this proposal. Not only is network coding a fresh and sharp tool that has the potential to open up stagnant fundamental areas of research, but due to its cross-cutting nature it naturally suggests a unified treatment of previously segmented areas. In particular, the research addresses the interplay of network coding in the context of network management, network information theory, compression and channel codes in networks and distributed scheduling and routing algorithms. The understanding of intrinsic fundamental performance limits of networks across different tasks, holds the potential to not only create a cornerstone in the theory of networks but also to build new and robust bridges between previously unconnected areas.","title":"Collaborative Research: ITR: Network Coding - From Theory to Practice","awardID":"0325324","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["551140"],"PO":["564898"]},"87306":{"abstract":"EXPERIMENTAL AND INTEGRATED ACTIVITIES <br\/><br\/><br\/>SENSORS: Fabrication of Reversible Microarray Sensors Using Thermally Responsive Biopolymers<br\/><br\/>Wilfred Chen<br\/>(EIA - 0330451)<br\/><br\/><br\/>Abstract<br\/><br\/>The ultimate goal of this research is to develop a simple and reversible patterning technique on an inexpensive substrate for biological molecules by thermally addressing a patterned hydrophobic surface template. Also, this research will investigate the utility of this powerful and simple patterning technique for the fabrication of antibody microarray sensors for the sensitive detection of multiple biological agents. The tunable biomolecules proposed here extends on ideas from nature, but toward entirely new objectives. The protein-protein recognition exhibited by stimuli-responsive elastin biopolymers is tailored specifically into tunable hydrophobic interactions, which is exploited as a non-covalent method to reversibly immobilize biomolecules in a functionally active orientation directly to an array surface. The end result is a simple and reversible patterning technique for micorarray sensor fabrication by thermally addressing a patterned hydrophobic surface template.<br\/><br\/>The broader impacts of this research are several-fold. This research will combine the multidisciplinary expertise of the PIs to develop a potentially reliable and economical technique for the fabrication of reversible microarray sensors. The use of elastin biopolymer for immobilization has significant advantages over existing covalent coupling because regeneration of the immobilization pattern is possible simply by modulating the solution environments. If successful, this technology will find applications in a variety of enzyme or antibodies arrays as well as the fabrication of DNA and protein microarrays for genomic analyses. The proposed research involves the intersection of principles and methods of molecular genetics, protein engineering, material research, and process engineering. Graduate students and postdoctoral researchers participating in this research will gain an integrated perspective of the important interfaces and synergies connecting biochemistry, modern genetics, and process engineering.","title":"SENSORS: Fabrication of Reversible Microarray Sensors using Thermally Responsive Biopolymers","awardID":"0330451","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"1491","name":"BIOTECH, BIOCHEM & BIOMASS ENG"}}],"PIcoPI":["544713","539835","539731"],"PO":["521045"]},"88219":{"abstract":"Abstract<br\/><br\/>Proposal number: 0335554<br\/>Title: Cyber Trust Point Meeting<br\/>PI: Gerald Masson, Johns Hopkins University<br\/><br\/>The Johns Hopkins University Information Security Institute (JHUISI) will host a Cyber Trust Point Conference on the Johns Hopkins University Homewood campus in Baltimore, Maryland, August 13, 2003 - August 15, 2003. The purpose of the meeting is to convene the set of Principal Investigators funded under the NSF programs that will be brought together under the Cyber Trust umbrella, including the Trusted Computing program, the Data and Application Security program, security aspects of the Embedded and Hybrid Systems program, and security-related work under the Network Research program. The meeting will encourage synergy among the researchers and research projects by means of planned technical sessions and opportunities for informal discussion. The participants will also produce a report on research topics related to theme topics that will be identified by NSF. To encourage broad participation and help establish NSF's role as a leader in Cyber Trust, the first full day of the the meeting will be open to other interested researchers, industry, and government participants, up to the capacity of the hall.","title":"Cyber Trust Point Meeting","awardID":"0335554","effectiveDate":"2003-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7228","name":"DATA AND APPLICATIONS SECURITY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["406250"],"PO":["529429"]},"81630":{"abstract":"3D shape matching, massive dataset visualization, and protein structure prediction. The theoretical issues involve combinatorial geometry, algorithm design and basic complexity theory. This effort is aimed at deriving new computational methods for solving problems of a geometric or biological nature that have resisted past investigations because of one two reasons: either the input data is too massive to be processed directly and it can only be \"sampled\" cleverly or the number of variables is itself so high that standard methods suffer from an exponential blowup<br\/><br\/>in the time it takes to run them. New dimension reduction techniques are needed to resolve this bottleneck.","title":"Collaborative Research: A Formal Theory of Robust Numerical Computational Geometry and Its Validation on Configuration Space Construction","awardID":"0304955","effectiveDate":"2003-08-15","expirationDate":"2007-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["401957"],"PO":["321058"]},"81553":{"abstract":"NIRT: Optical Interconnects for High-Performance Processors: Architectures, Circuits, and Devices<br\/><br\/>Abstract<br\/><br\/>This proposal was received in response to Nanoscale Science and Engineering initiative, NSF 02-148, category NIRT. This project involves the development of nanoscale-silicon-based optical interconnect technology and associated design methodologies to alleviate the global signaling problem in future CMOS chips. The device research focuses on two specific building blocks, namely a silicon laser and silicon modulators\/switches. The laser is made using silicon quantum dots as the gain medium. Both optically pumped and electrically pumped laser structures are being investigated. The modulators\/switches are made of tunable photonic bandgap structures made of silicon infiltrated with an electrically active material such as liquid crystals. In addition, optimal signaling at both the data and control levels is being explored, and solutions developed, while taking into consideration both the structural characteristics of the system architecture and the impedance and physical constraints of the electrical\/optical interface. In the process, an integrated modeling environment spanning the nanoscale device, integrated circuit, and architecture levels is being created in order to conduct this research. Top-down and bottom-up design methodologies are being developed for potential incorporation into commercial design automation tools.<br\/><br\/>Several educational initiatives are intricately linked with this research (including undergraduate design projects, summer employment of undergraduates, graduate student research, participation in diversity programs, and tutorials given at leading conferences and forums) in order to educate current and future applied physicists, electrical engineers, and computer scientists in the broad aspects of this interdisciplinary field.","title":"Optical Interconnects for High Performance Processors: Architectures, Circuits, and Devices","awardID":"0304574","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["507032","553419","550887"],"PO":["550859"]},"81444":{"abstract":"A new and important phenomenon involving single photon tunneling has been discovered recently by a multidisciplinary team of researchers at the University of Maryland. Transmission of light through nanometer-scale pinholes in a gold film covered by a nonlinear dielectric saturates at a few thousand photons per second. The transmittance of such a nanometer-scale hole is nonlinear with light intensity, and at the single photon level corresponds to each photon in the process of being transmitted through the hole controlling the transmittance of successive photons. This result is analogous to the Coulomb blockade observed in single electron tunneling experiments. The phenomenon was initially observed only for random nanoscale pinholes that occur naturally in thin evaporated gold films. Further work has shown that the transmittance of both individual nanofabricated holes (nanopores), and arrays of nanopores, both made by focused ion-beam nanaofabrication techniques, has shown not only the simple iiphoton-blockadel effects, but also controlled photon transmission. For example, the transmittance of a nanopore or nanopore array at one wavelength can be controlled by illumination with a second, different, wavelength.<br\/><br\/>In this project a multidisciplinary team of optical scientists, theorists and nanofabricators<br\/>will study of this new phenomenon and explore potential applications based on fabricated nanopores or arrays of nanopores in metal films. They expect that a detailed study of optical properties of such well-controlled nanopore and other nanostructures will reveal novel quantum phenomena in nonlinear optical transmission. For example, electrons in a Coulomb blockade tunnel one at a time, at more or less fixed time intervals. If photons tunneling through nonlinear optical nanopores show similar behavior (as an initial experiments suggest), the fabricated nanopores will become very unusual and useful light sources emitting individual photon periodically, one at a time. Such controlled light sources are being actively pursued by researchers in the areas of quantum communication and quantum cryptography.<br\/><br\/>In addition, novel and potentially important applications of nonlinear nanopore materials may also be expected in the areas of optical communications and all-optical signal processing. Optical signal processing relies on nonlinear interactions of light, which usually happen at very high optical intensities. Preliminary results indicate that the local optical field in a nanopore is enhanced by at least six or eight orders of magnitude, enabling nonlinear optical interactions to occur at much lower illuminating light intensities. This opens the door to devices where light is used to gate light, which they have already demonstrated at a fundamental level. Thus, a great number of optical communication and optical signal processing devices, such as all-optical switches, and signal and image processing devices, may be realized on a microscopic scale, and at much smaller operating optical powers than macro-devices.","title":"NIRT: Nanofabricated All-Optical Computing, Switching, and Signal Processing Devices Based on Single Photon Tunneling","awardID":"0304046","effectiveDate":"2003-08-01","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1518","name":"CONTROL, NETWORKS, & COMP INTE"}}],"PIcoPI":["554332",212275,"491930","276028","537959"],"PO":["563109"]},"83512":{"abstract":"Privacy concerns can prevent constructing a centralized data warehouse to support data mining. For example, the Centers for Disease Control (CDC) may want to mine insurance companies' data to identify trends and patterns in disease outbreaks, such as understanding and predicting the progression of a flu epidemic. Gathering all patient data into a single warehouse increases opportunities for privacy breaches and misuse. We propose an alternative: secure collaborative computing between the parties holding the data that produce the desired data mining results, while provably preventing disclosure of private data.<br\/><br\/>This project will enable knowledge discovery under the following assumptions:<br\/>1. data are distributed across multiple sources, with security\/privacy concerns that limit data sharing, and<br\/>2. if data were gathered into a centralized warehouse, data mining tools could identify patterns or relationships that give beneficial knowledge.<br\/>Developed techniques will replicate or approximate the results of centralized data mining, with quantifiable limits on the disclosure of data from each site. The goal is to develop a toolkit of privacy-preserving distributed computation techniques that can be assembled to solve specific real-world problems. By simplifying component assembly so it becomes development rather than research, widespread use of privacy-preserving distributed data mining will become feasible.","title":"Collaborative Research: ITR: Distributed Data Mining to Protect Information Privacy","awardID":"0312357","effectiveDate":"2003-08-15","expirationDate":"2006-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["553652","562974"],"PO":["469867"]},"83633":{"abstract":"Exposing the compiler to the hardware: Memory Subsystem Optimizations through Compiler\/Micro-architecture Cooperation using Set Membership Information and Color<br\/><br\/>Abstract<br\/><br\/>(Onder)<br\/><br\/>This research proposes to make use of the static knowledge obtained by the compiler in the dynamic decision making of the micro-architecture. In that respect, the compiler exposes compile-time analysis to the micro-architecture fully using set membership information, and the micro-architecture uses this information to make critical scheduling and memory optimization decisions. This approach allows the examination of solutions to the memory wall problem that are impossible to do using a hardware-only or fully compiler-managed solution. Using set membership as a framework, this research will pursue the following problems:<br\/><br\/>1. Cost-effective run-time memory disambiguation of load\/store operations to increase the number of parallel memory operations;<br\/><br\/>2. Scalable cache and load\/store queue designs that can sustain multiple memory accesses every cycle for wide-issue superscalar processors;<br\/><br\/>3. Novel cache designs formed in cooperation with compiler-generated working-set information to reduce the number of conflict and capacity misses; and,<br\/><br\/>4. Working-set based prefetching techniques to reduce the number of misses and the miss penalty.<br\/><br\/>The proposed research will significantly improve the performance of scientific applications. These applications are at the heart of basic science research, and their performance is crucial for the advancement of many fields of science. This research will also strengthen the synergy between compilers and micro-architectures, and advance the state-of-the-art in information technology.","title":"ITR: Exposing the compiler to the hardware: Memory Subsystem Optimizations through Compiler\/Micro-architecture Cooperation using Set Membership Information and Color Sets","awardID":"0312892","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["485798","530278"],"PO":["325495"]},"81587":{"abstract":"This project uses econometric methods to estimate the impact of nanoscale science and technology (nano S&T) research, and associated interdisciplinary research, directly on firms' entry and success and hence on U.S. economic growth, standard of living, and competitiveness. The research team also performs scientometric and institutional analyses of diffusion and networks in nano S&T and converging fields, and the reciprocal effects of institutions on nano S&T and of academic scientists' involvement in commercialization on their scientific productivity and teaching. These substantive studies address issues that are particularly important to sustaining long-term support of nano and associated S&T. Undergraduate, graduate and postdoctoral students will be engaged in this research continuously, through hands-on participation and summer and academic-year internships. Results of the research will be translated into courses for MBAs and practicing entrepreneurs, including scientists. <br\/><br\/>Accurate and convincing analysis of these impacts requires building an integrated database, which will be made available as a public, web-deployed digital library (DL) called NanoBank.org. The database will be useful to other researchers pursuing different social-science analyses, as well as investors and firms seeking to allocate investment to promising new technologies, policymakers attempting to assess the effects of alternative policy proposals, and nano scientists and engineers, who will be able to trace relevant research, for instance, whether a key scientist is author of an article, inventor on a patent, or collaborator or officer of a firm. A NanoBank user might also seek all publications, patents, collaborations, alliances, and stock-price returns of firms working, say, on a particular use of carbon nanotubes and trace all academic publications and research grants in nano S& T tied to each firm involved in that use. <br\/><br\/>The project DL experts will solve challenging technical DL problems to enable NanoBank users to search multiple and quality-weighted (e.g., by patent or article citations or employment growth) fields across a variety of databases, with sophisticated matching of variant names of frequently appearing organizations and individuals. The team is rich in expertise in carrying out matches using combined computer and judgment methods that will accelerate the construction of more fully automated matching\/search systems. Nanoscience and technology experts affiliated with the project are also interested in the substantive economic, business, and policy questions for which NanoBank can be the key and are willing to provide the expert input necessary to build a methodology for tracking and including patents, articles, firms, grants, and products that should fall within nano S&T and to assess proposed measures of business activity. They provide access to important knowledge that is often tacit and transferred by working at the bench level and in industry. <br\/><br\/>Preliminary empirical results show that where and when firms enter nanotechnology correlates with regional measures of highly cited academic articles, federal research funding to universities, and labor force quality. NanoBank will enable us to provide more definitive estimates of the factors affecting firm entry and furthermore trace the effects of university-to-firm knowledge flows on firm success, and of commercial participation on scientists and engineers. Scientometric analysis can identify emerging fields and explain trends in cross-discipline research in nano S& T. <br\/><br\/>This project will begin to answer questions about the economic retum to public investment in nano S& T research, the channels that knowledge of valuable new discoveries travels, how discoveries alter these channels, and what institutions contribute to returns on this investment. The project will directly involve future and young social, physical, and life scientists in research on the processes which convert knowledge into valuable goods and services. NanoBank's availability will attract ambitious social scientists to study of societal impacts, like high-energy physicists with a new detector, while it also facilitates discovery by scientists working in other research areas of the National Nanotechnology Initiative.<br\/><br\/>This Nanoscale Interdisciplinary Research Team (NIRT) proposal was submitted in response to the solicitation \"Nanoscale Science and Engineering\" (NSF 02-148). It is being supported by the Directorate for Social, Behavioral and Economic Sciences (SBE), the Directorate for Computer Science and Engineering (CISE), the Directorate for Engineering (ENG), and the Directorate for Mathematical and Physical Sciences (MPS). Three divisions in MPS are co-sponsoring this effort: Mathematical Sciences, Physics, and Materials Research.","title":"NIRT: Science and Commercialization NanoBank, Database and Analysis","awardID":"0304727","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1248","name":"PHYSICS-OTHER"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1712","name":"DMR SHORT TERM SUPPORT"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8815","name":"Studies of Policy Sci Eng Tech"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"1385","name":"SPECIAL STUDIES AND ANALYSES"}}],"PIcoPI":["541941","506763","446827","329413","369288",212818],"PO":["471668"]},"83325":{"abstract":"Peterson<br\/><br\/>Mapping Polygranular Parallel Programs (P3) to Shared, Heterogeneous, High Performance Reconfigurable Computers (HPRC)<br\/><br\/>Abstract<br\/><br\/><br\/>The proposed project aims at the development of performance models and mapping algorithms as the theoretical foundation of a design infrastructure to support polygranular parallel programs executing on shared, heterogeneous, High Performance Reconfigurable Computers (HPRC). The project will develop a mathematical framework for characterizing the performance of polygranular parallel applications executing on HPRC systems. Moreover, the project will investigate computationally efficient approaches for optimally mapping applications to HPRC systems, providing dramatic improvement in design automation efficiency for HPRC and related computational platforms. Given the emergence of both embedded systems and the Grid as the basis for ubiquitous computing, the project will specifically address issues related to polygranular parallel application execution in a shared, heterogeneous environment.<br\/><br\/>This project addresses the area of emerging computer systems architectures with the broader objective of providing the theoretic performance modeling and mapping infrastructure necessary to effectively exploit current and emerging hardware platforms with polygranular parallel programs. Hence, the program supports national efforts to meet next-generation computational needs with the grid and with embedded systems including system-on-chip. The computational capabilities of HPRC platforms promise significant performance and cost improvements for a spectrum of problem domains, such as image processing and graph algorithms.","title":"Mapping Polygranular Parallel Processing to Shared, Heterogeneous, High-Performance Reconfigurable Computers","awardID":"0311500","effectiveDate":"2003-08-15","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":[217240,"364563","559172"],"PO":["325495"]},"82115":{"abstract":"This grant will bring together a multi-disciplinary team (technical and social\/organizational) to explore deployment of and impact of e-government services in Puerto Rico, with security, privacy and other enabling IT capabilities. The City of Mayaguez will be the government partner. Multi-lingualism will be one of the technical themes, along with automated representation and extraction of semantic information, and collaborative secure wide area government to government databases. Social science aspects include study of economic\/social barriers to technological adoption. Most e-gov deployments operate on the principle of 'build it and they will come'; unfortunately many times they don't come. This project will help us understand the barriers to citizens' full embrace of e-gov services in an environment which will allow leapfrogging of older web technologies, working with a populace that is not sophisticated and is inexperienced with e-gov services. Strong leverage will be provided by the City and the University.","title":"Multidisciplinary E-Government Research and Education as a Catalyst for Effective Information Technology Transfer to Regional Governments","awardID":"0306791","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[214115,214116,"266269","384523",214119],"PO":["371077"]},"83127":{"abstract":"Molecular nanomagnets and nanoparticles represent the ultimate limit of miniaturization of magnetic memory units. They have also been proposed as candidates for qubits - elements of quantum computers. This project is advancing the knowledge of magnetism at the nanoscale by answering fundamental questions of quantum physics of small magnets and questions about applications of nanomagnets for the information technology of the future. Decoherence of spin states of nanomagnets interacting with a solid matrix is being investigated. The approach is being explored that maps the spin-tunneling problem with dissipation onto the problem of particle localization. Theory of resonant spin tunneling via Landau-Zener effect is being extended to a system of interacting molecular magnets. Spontaneous emission of the electromagnetic radiation by high-spin molecules is being studied and the possibility of superradiance by the ensemble of nanomagnets is being investigated. Theory of resonant spin tunneling due to the spin-lattice coupling, hyperfine and dipolar interactions is being developed for such nanomagnets as Mn12, [Mn4]2 dimer, Fe8 crystals of LiHoxY1-xF, and others. Cooperation with U.S. and foreign theorists and experimentalists working in the field of nanomagnetism is being developed. The knowledge of traditional and modern magnetism is being transferred to graduate and undergraduate students.","title":"ITR: Theory of Nanomagnets","awardID":"0310517","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["508127"],"PO":["521045"]},"85558":{"abstract":"This project from a RUI institution, servicing the area of parallel and distributed computing, aims providing a network of workstations for research. Research projects underway include:<br\/> Paradigm-Oriented Distributed Computing Using Mobile Agents,<br\/> Mobile Agent Management, and<br\/> Distributed Secure Information Management System.<br\/>The first exploits the benefits of a mobile agents infrastructure and develops an environment for paradigm-oriented distributed computing. The second focuses on the use of mobile agents and their impact on networks performance. The last allows multiple servers to share the key to an encrypted file, and separates the access authentication and verification from the information storage.<br\/>The equipment is expected to provide a solid computing infrastructure for research projects having computation-intensive applications (specifically, biology, physics, and mobile computing). Investigations to be conducted follow:<br\/> Wavelet Based Image Reconstruction Algorithms,<br\/> A Computational Screening Approach to Engineering Thermostable Proteins through Mutation of Protein Surface Residues,<br\/> Development and Application of a Biased Brownian Dynamics Algorithm, and<br\/> Parallel Mobile Action Generators.<br\/>The first investigates the use of various wavelets in the new wavelet-based multiresolution EM algorithm for medical reconstruction; the second develops and applies Poisson-Boltzmann (PB) continuum electrostatics methods to a variety of biochemical systems; the third uses PB electrostatics in conjunction with biased Brownian dynamics simulation methods to calculate biomolecular encounter rates; and the fourth aims at improving the performance of a mobile action generator developed for the mobility management in wireless communication networks.<br\/>The infrastructure will provide a state-of-the-art hands-on instructional laboratory for training and education of students to be part of the high-tech workforce.","title":"Acquisition of a Network of Workstations for Research in Parallel and Distributed Computing","awardID":"0321333","effectiveDate":"2003-08-01","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[223262,"478530",223264,223265,223266,223267],"PO":["557609"]},"83138":{"abstract":"1) Abstract<br\/>===========<br\/><br\/>Proposal Number:<br\/>CCR-0310793, CCR-0310490, CCR-0310159 and CCR-0310571<br\/><br\/>TITLE:<br\/>Graphical Passwords -- Design, Analysis, and Human Factors<br\/><br\/><br\/>PI: J.C. Birget and Dawei Hong (Rutgers-Camden),<br\/><br\/><br\/>Co-PIs:<br\/><br\/>S. Man (Southwest State U., Minnesota),<br\/>N. Memon (Polytechnic U., Brooklyn),<br\/>S. Wiedenbeck (Drexel).<br\/><br\/><br\/>Abstract:<br\/><br\/>Humans are not good at remembering alpha-numeric passwords, if the passwords are complicated enough to be secure. Graphical passwords seem easier to remember and to use. Here, an image is displayed and the user chooses a few places in the image. To log in, the user has to click close to these places again. Older systems use preprocessed images with predefined click regions, among which a user has to choose. The investigators designed systems that allow users to choose any points as click points, and that allow users to import their own images. The investigators invented a ``robust discretization'' of images; this enables users to produce exactly the same discrete password even though they cannot click on exactly the same pixels at each login. Passwords are vulnerable to ``shoulder surfing'', which consists of a user being observed, or filmed, during login. The investigators designed password systems that are immune to shoulder surfing.<br\/><br\/>One of the objectives of this proposal is a human factors study, concerning learnability, memorability, speed, security (unsafe practices), and user satisfaction of graphical password systems. A second objective is to design new graphical password systems, based on curves, movement, and three-dimensional scenes, as well as to design ``bundles'' of passwords that a user can use on different accounts, and that are easy to remember (and distinguish) as a group. New robust discretization algorithms and probabilistic analyses of the security of graphical password systems will be developed.","title":"Collaborative Research: Graphical Passwords -- design, analysis and human factors","awardID":"0310571","effectiveDate":"2003-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":[216654],"PO":["521752"]},"88209":{"abstract":"Non-specialists often have difficulty designing the features used to formulate machine learning problems. This small grant for exploratory research will explore the possibility of automating this \"feature engineering\" aspect of machine learning problems. Specifically, this project will investigate the feasibility of representing the background knowledge in a modern knowledge representation language and then automatically (or semi-automatically) deriving the relevant input features. The project will study two application problems where there is extensive background knowledge but sparse training data: (a) predicting future grasshopper infestations; and (b) understanding the spread of West Nile virus. This research will provide a deeper understanding of the process of feature engineering and help articulate an agenda for future research.","title":"SGER: Exploiting Contextual Knowledge to Design Input Representations for Machine Learning","awardID":"0335525","effectiveDate":"2003-08-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["554550","237846"],"PO":["564318"]},"91553":{"abstract":"This project evaluates the use and social impacts of Blacksburg Electronic Village, one of the prominent American community networking projects of the 1990s. It employs community surveys, detailed interviews, session logging, a participatory evaluation forum, and a variety of psychological scales. It addresses a variety of key issues: Who participates in community networks? What are the networks used for? How are local business activities and opportunities changed, and how direct a cause is the network? In what ways does access to local government information, or to public decision-making change? What are the consequences for community life, and for community health and well-being? How is participation in community life greater or more diverse? Do people feel safer in a community networking context than in the general Internet context? Do they feel their personal data is safer? Can a community network enhance self-perceptions of collective self-efficacy in the community? Has the social capital of the Blacksburg community increased as a consequence of the BEV? And what are the causes and effects of unequal participation throughout the community? The vision of community networking is inspiring; it extends creative participation to citizens through computing. Systematic evaluation of these new opportunities is timely and appropriate.","title":"ITR: Interdisciplinary Views of the Blacksburg Electronic Village","awardID":"0353097","effectiveDate":"2003-08-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["549541"],"PO":["495796"]},"83710":{"abstract":"High-volume data streams exchanged in XML form are becoming crucial to a wide range of applications in the scientific, government and business domains. However, taking advantage of them raises significant technical challenges and opportunities. First, stream queries require computations to be performed in memory that is limited with comparison to the arbitrarily large data stream. Second, the rapid increase of network bandwidths surpasses the increase of CPU-to-memory and CPU-to-disk transfer rates. The result is that high bandwidth networks will be delivering stream data faster than they can be processed by conventional approaches. Efficient on-the-fly data stream processing is necessary. <br\/><br\/>This project will develop a comprehensive approach to querying data streams in XML form, covering the spectrum from formal foundations all the way to systems. The expected outcome of the project will be a qualitatively new architecture, technology and query processor for XML data streams, with impact on a wide range of applications. The approach will be tested on seismic data provided by the ROADNet project. However, we expect that the research will have broader impact on voluminous XML data streams.","title":"ITR: Querying Sequentially Accessed XML Data","awardID":"0313384","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["409520","525612","538708","518657"],"PO":["469867"]},"81895":{"abstract":"Demand for broadband access anytime anywhere continues to grow. While it is important to reduce to power consumption in personal terminals, it is equally important to reduce silicon cost in applications such as settop boxes, DSL modems in central office or a wireless base stations. This proposal addresses low-power and\/or low-cost implementations of a number of key building blocks which are common to many personal or central embedded communications terminals. <br\/><br\/>Iterative decoders have found wide applications in wireless terminals, wireless infrastructure, satellite communications, etc. Recently, low-density parity check (LDPC) coders are receiving much attention due to their computation simplicity in every iteration, and ability to parallelize. These codes do not suffer from the error floor problem and are well suited for applications such as optical transmission and disk drives. Earlier work on parallel turbo decoder architectures will be extended to address efficient memory arbitration and memory management issues, and to reduce power consumption by appropriate parallelism level and memory selections. There is also interest in design of a new class of parallel turbo coders which can lend itself well for parallel implementations. In earlier work on LDPC coders, a new (3,k)-regular LDPC code which lends itself well for a partly-parallel implementations was demonstrated. The proposed effort will build upon this past work to generate more general LDPC coders. The desire to accommodate varying rates, varying frame sizes demands the generalization or construction otherwise of (j,k)-regular LDPC coders which can be implemented in partly-parallel manner. Placement and routing issues in these coders and memory size reduction issues will be addressed. <br\/><br\/>The intellectual merit of this proposal lies in the unique ability to jointly consider algorithm and architectural issues to reduce power consumption of many components of broadband systems. Algorithm and architectural level power reduction can result in dramatic cost and power savings. The proposed effort will have an impact in various applications such as satellite communications, optical communications, storage devices, personal video recorders, settop boxes, wireless base stations and cell phones. The broader impacts will be far reaching. This research will pave the way for use of these technologies in industrial products. It will make an impact through research training of students working on this project, but the impact will be even greater through graduate education by transferring these research results to new or existing graduate classes.","title":"Architecture Design Methodologies for Embedded Communications Terminals","awardID":"0305941","effectiveDate":"2003-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["550262"],"PO":["562984"]},"83600":{"abstract":"This research proposes to develop a semantic image database that could serve investigations in cellular pathology within three sub domains: (1) Cancer, the storage\/detection of tumor\/cellular images; (2) Cellular biology, requiring the identification of nuclei in different stages of cellular division; and (3) Neurobiology, quantification of cell types and neuropathological objects in human or animal brain tissue. <br\/><br\/>The proposed research advances and integrates two basic information technologies: iterative image object classification and object relational knowledge base. The former is employed to interact with domain experts to define models of object and concept, and the latter is employed to retrieve image information based on such models in a declarative fashion. Based on such, the research is aimed to develop a complete set of key concepts to support semantic biological image retrieval in neurobiology and cancer research.<br\/><br\/>Although semantic retrieval of arbitrary images is, in general, a very difficult problem, specific domains of biological images may be sufficiently constrained in contents that one might hope to achieve semantic retrieval. The success of the proposed research will be a demonstration of this principle and lead to the development of many other special purpose semantic image systems. Finally, the proposed research will introduce new requirements to the areas of object relational database, decision support system and data mining system.","title":"ITR: Semantic Biological Image Management & Analysis (SBIMA)","awardID":"0312721","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[217949],"PO":["563751"]},"83623":{"abstract":"Biometric Access Control uses quantative anatomical, physiological or behavioral traits to automatically and accurately verify the identity of an individual. The goal is to control or restrict acces to appropriate individuals. Accuracy and reliabilty requirements are high, and today, such systems play an increasingly important role in authentication and authorization of individuals. Face recognition has long been regarded as anideal biometric resource, but the complexity of analysis and comparison of facial characteristics has limited successful application of 2D and other current techniques in this domain. Typical 2D applications currently in use have high error rates and are hampered by variations such as lighting and orientation.<br\/>This project will develop and apply true 3D spatial analysis tools and techniques to acurately recognize and compare distinct 3D facial features.. In addition, we will create, maintain, and distribute via the web, a 3D digital library of 1,000 face type examples to test algorythms, and develop initial standards for true 3D facial comparison. The result will be algorythms to quickly and accurately recognize distinctive facial features, and to viably recognize and authenticate indivuals against the database.","title":"ITR: 3D Face Authentication for Biometric Access Control","awardID":"0312849","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["455160","279394","268713"],"PO":["563727"]},"81566":{"abstract":"Title: An Acoustic Tweezer for Nanoparticle Manipulation<br\/>Abstract<br\/>The goal of this project is to demonstrate the feasibility of using of acoustic fields for three-dimensional manipulation (3-D) of a nanoparticle in the air. An acoustic field generated by solid state acoustic transducers will provide a non-contact means of delivering a mechanical force to the particle, and by controlling the distribution of the force in space one will control the 3-D position of the particle. Features such as levitation and horizontal and rotational motions will be studied under different operating conditions. Experimental and theoretical efforts leading to understanding the physical mechanisms of operation of an Acoustic Tweezer for Nanoparticle Manipulator (ATNM) will be undertaken.<br\/>The work proposed falls into three broad activities: device development, theoretical modeling and the concept validation. These three areas are not mutually exclusive and will proceed simultaneously. Device development includes design, fabrication and testing of acoustic transducers and accompanying electronics for efficient generation of interfacial forces. Theoretical models describing the interaction of a particle with the surface of a transducer will incorporate the nanoscale complexity of the system and the multiple length scales of the systems to be studied. These developments will be validated using dedicated measurement techniques in which various aspects created by particle size and interfacial forces will be examined in carefully controlled or simulated experimental conditions. Finally, the measured ATNM characteristics will be correlated with standard optical (micron-size particles), Atomic Force Microscope (AFM) and Near Field Optical Microscope (NSOM) (nanoparticles) techniques.<br\/>The acoustic manipulation technique, once developed, will be complementary to current micro- and nano-particle manipulation techniques, such as laser tweezers, magnetic tweezers and scanning probe microscopes. In particular, this technique will provide an efficient method for separating nanoparticles according to their size, shape or interaction properties. The acoustic manipulation technique will be effective on nanoparticles regardless of their optical, electrical and magnetic properties, and thus can be used in various environments and in different media. These unique features of the acoustic manipulation technique will significantly impact the fields of characterization and application of nanoparticles. The long-term objective of this research is to develop an ATNM chip capable of autonomous and programmable manipulation of nanoparticles in gases and liquids. ATNM chip will provide an experimental platform for designing and monitoring various bio-chemical and bio-physical processes involving inorganic nanoparticles as well biological objects such as proteins or cells.","title":"NER: An Acoustic Tweezer for Nanoparticle Manipulation","awardID":"0304639","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1630","name":"MECHANICS OF MATERIALS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1415","name":"PARTICULATE &MULTIPHASE PROCES"}}],"PIcoPI":["415050"],"PO":["562984"]},"91246":{"abstract":"ITR-0082655<br\/><br\/>Newby, Gregory B.<br\/><br\/>School of Information and Library Science, University<br\/>of North Carolina at Chapel Hill<br\/><br\/>ITR\/SW: TeraScale Retrieval<br\/><br\/>TeraScale Retrieval addresses the scientific investigation of<br\/>large-scale information retrieval (IR). TeraScale Retrieval will<br\/>facilitate experimentation to advance knowledge of information<br\/>retrieval, especially text retrieval, by implementing a software<br\/>toolkit for IR research and development. IR systems seek to identify<br\/>documents or passages from documents that satisfy a human information<br\/>need. Text retrieval is directed at collections of relatively<br\/>unstructured documents, such as HTML documents, as well as more<br\/>structured documents (e.g., XML). In order to advance scientific<br\/>knowledge and improve performance of IR, there is a need for a<br\/>software toolkit that enables rapid and practical implementation of<br\/>experimental IR systems. The TeraScale Retrieval toolkit will<br\/>emphasize large-scale performance with terascale datasets: hundreds of<br\/>millions of documents with terabytes of raw data, millions of unique<br\/>terms, multiple languages, and potential for quadrillions (petascale)<br\/>of sub-documents or document fragments. The toolkit will emphasize<br\/>software reuse, high-performance algorithms, and modularity for rapid<br\/>prototyping and evaluation. Rather than moving quickly from academic<br\/>use to commercialization, TeraScale Retrieval will focus on<br\/>experimentation and evaluation to contribute to scientific knowledge<br\/>about information seeking and use.","title":"ITR: TeraScale Retrieval","awardID":"0352029","effectiveDate":"2003-08-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V203","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W295","name":"CIA-KNOWLEDGE DISC & DISSEMIN"}}],"PIcoPI":["543243"],"PO":["564388"]},"83634":{"abstract":"This project will develop the theory, concepts and tools to track changes and detect emerging structure in large networks. It combines a theoretical investigation of how networks and communities evolve over time with empirical studies using the NEC CiteSeer database. Clustering plays a crucial role in detecting community structure. However, tracking changes in structure over time places new demands on clustering algorithms. In particular it requires a stability not usually demanded of clustering techniques. This project starts from the premise that there actually are real communities of various sizes in the data and that these communities are invariant under changes such as random removal of 5-10% of the papers in the database.<br\/><br\/>If a clustering technique gives a radically different clustering when an additional 10,000 papers are added to the database, it will be impossible to separate small changes in the evolving structure from artifacts of the clustering technique. The project builds upon a concept of natural communities of various sizes that can be identified under quite strong changes in the data. A central component of the work is to develop a principled generative model of growing random graphs which has complex evolving community structure and in which the concept of a natural community arises. Tools will be developed to find these natural communities with sufficient stability to track real changes in the clusters over time and identify when new communities emerge.<br\/><br\/>The ability to track emerging trends and detect hidden structure in large networked digital data sources should be of potentially great societal benefit. In particular, it would allow the end-user to search for information in a more informed manner, and enable a pro-active approach towards emerging trends and new developments.","title":"ITR: Emerging Communities in Large Linked Networks: Theory Meets Practice","awardID":"0312910","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["382681","560669"],"PO":["564456"]},"81104":{"abstract":"Principal Investigator: Shuhong Gao <br\/>Proposal Number: 0302549<br\/>Institution: Clemson University<br\/><br\/>Abstract: Algorithms for polynomial systems<br\/><br\/>The proposed research belongs to the interface between mathematics and computer science. Professor Gao will investigate efficient algorithms for polynomial systems. Topics include large systems of linear equations, polynomial factorization, primary decomposition, and Hilbert irreducibility theorems. These topics are closely interrelated and are fundamentally important in algebra, number theory, and symbolic computation.<br\/><br\/>Algebra and number theory are the oldest branches of mathematics, and polynomial systems play an important role throughout the history of mathematics. With the increasing use of computers in science and engineering, efficient solution of various problems related to polynomials are of vital importance. In addition, many cryptographic schemes for protecting sensitive digital information (from cellular phone communications, bank transactions, e-commerce to national security) are based on algebraic structures, and their security relies on various hard problems in algebra and number theory. The current research studies a sample of problems related to these applicati","title":"Algorithms for polynomial systems","awardID":"0302549","effectiveDate":"2003-08-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7316","name":"EAPSI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["445138"],"PO":["565280"]},"83656":{"abstract":"The aim of this project is to augment traditional 2D-video content with depth using computer vision approaches. To achieve this goal the camera motion and settings will also have to be recovered from the video data. The main application that is envisioned is converting existing 2D-video to 3D-video to provide sufficient content for stereoscopic displays and enable applications such 3D-TV to emerge and flourish. Besides this, the intended research potentially also has important applications in the context of video analysis and compression. Advances in 3D from video will also have a broader impact in areas such as archaeology, cultural heritage, movie special effects, medical, forensics and military reconnaissance applications. The educational impact will not be limited to students directly involved in this project, but will potentially reach many more through tools for video analysis in art schools or educational 3D-videos. We intend to develop a reliable fully automatic approach. Since it will not always be possible to compute the depth from the available image content (e.g. fixed camera), we intend to correctly deal with ambiguities and provide perceptually acceptable results (e.g. fade depth when it can't be computed anymore). Given a 2D video stream, we intend to (1) compute the relative motion between the scene and the camera for each shot, (2) detect independent moving objects and computer their motion and deformation, (3) compute a detailed depth representation for each video.","title":"Converting 2D Video to 3D with Applications to 3D-TV, Video Analysis and Compression","awardID":"0313047","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[218101],"PO":["563751"]},"83667":{"abstract":"This proposal aims to provide this deep understanding of server behavior during overload, in the<br\/>case of both static and dynamic content. The approach is interdisciplinary: There is a theoretical<br\/>component which aims to prove new theorems on M\/G\/1 queues with time-dependent load; an implementation<br\/>component which performs a rigorous systematic study of web server and database server<br\/>performance under overload as a function of various networking parameters; and a workload and client<br\/>characterization component which aims to understand statistical properties of the request stream during<br\/>transient overload and incorporate these into the design of a web workload generator for overload.<br\/>This proposal also introduces a very simple idea for improving the performance of web servers<br\/>under overload: a kernel-based implementation of SRPT connection scheduling. The idea is simple<br\/>and intuitive. Connection scheduling does not require purchasing more hardware, or any other costly<br\/>system upgrades. It appears to allow the server to survive much longer periods of overload, and to allow<br\/>clients to experience better performance during these periods of overload. Furthermore, it appears<br\/>to enable the server to recuperate from overload much faster. The proposal will provide a detailed<br\/>evaluation of the benefits of SRPT connection scheduling and will aim to introduce similar scheduling<br\/>policies for databases. The above concludes the intellectual merit portion of the proposal.<br\/>The broader impacts resulting from the proposed activity include online availability of all source<br\/>code generated during the project including modifications to the Apache code and to Linux, as well<br\/>as online availability of all trace logs collected during this project, and a web workload generator for<br\/>overload. The project initiates collaborations across various academic disciplines including: mathematics,<br\/>computer systems, and operations management, as well as between universities and industry.<br\/>The project will also provide a research opportunity for a minority undergraduate student.<br\/>The proposal involves 1 faculty member (1 summer month only), 1.5 graduate students, and 1<br\/>undergraduate, over the course of 3 years.","title":"ITR: Improving the Performance of Web Servers under Overload","awardID":"0313148","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["555524"],"PO":["348215"]},"83689":{"abstract":"This project aims to build a MetaIntegrator for integrating databases on the Internet. To realize large-scale integration over this \"deep Web,\" the research pursues the \"shallow integration\" philosophy, which does not rely on deep semantic annotations or deep probing of sources. In particular, it takes a holistic approach, which essentially leverages the challenge of large-scale itself as an opportunity, by resorting to hidden statistical regularities for enabling shallow integration. Specifically, this project focuses on three tasks: (1) Deep Web survey: To characterize the nature of the deep Web (as pertinent to semantic integration), this project extensively surveys databases on the Web. (2) Source selection: Since there are so many potential sources, \"what sources should be involved in answering a given query?\" This project thus develops the dynamic selection of sources for matching a query. (3) Schema integration: Since sources are heterogeneous, in querying the problem \"how does an attribute in one source correspond to that in another?\" Needs to be resolved. This project thus studies the matching and unification of schemas across myriad sources. Information on this project will be posted on the Web (http:\/\/eagle.cs.uiuc.edu\/metaquerier) and the results are expected to have broad impact by advancing the understanding of dynamic, large-scale integration and develop a set of general techniques, and constructing a MetaIntegrator for providing access to (selected domains of) the deep Web. These fundamental results are likely to have technology transfer into a broad spectrum of Web applications.","title":"ITR: Shallow Integration over the Deep Web: A Holistic Approach","awardID":"0313260","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["451869"],"PO":["563727"]},"83216":{"abstract":"Reconfigurable Computing: Bridging the Gap<br\/><br\/><br\/>Reconfigurable computing exploits the ability of hardware to adapt its structure and function to suit a given problem. Theoretical models have established its power and versatility, and commercially available devices have exploited reconfiguration in solutions to a variety of problems, yet a significant gap exists between theory and practice. Theoretical models make assumptions that are unlikely to be realizable. Practical solutions are often tied to device-specific features, solving the given problem, but offering little beyond that in developing broad techniques. This project seeks to bridge this gap by tethering theory in reality, while abstracting solutions from device details.<br\/><br\/>We approach the task of bridging the gap between theory and practice from two directions: (1) theoretical models (primarily the R-Mesh) and (2) commercially available hardware (primarily FPGAs). The first direction will realistically account for practical considerations (like bus delay and power consumption), while exploiting the power of reconfiguration. The second direction will construct problem solutions (in areas like image processing and networking) on practical hardware with an aim of extracting and applying general principles. We expect these directions to open the door to hybrid architectures that seek to build on the strengths of the two platforms and fill each other's deficiencies.","title":"Reconfigurable Computing: Bridging the Gap","awardID":"0310916","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[216913,216914,216915],"PO":["550859"]},"85999":{"abstract":"This project is developing technology for the rapid de novo fabrication of large DNA molecules up to and including entire genomes directly from a computer. Presently the field of genetic engineering is limited to the de novo engineering of single genes. This project seeks to enable the engineering and fabrication of vastly more complex systems including complete biochemical pathways and genetic networks. It is anticipated that the capabilities developed by this project will be enabling for new disciplines such as genetic circuit and transcriptional-translational logic engineering. Those attempting to model large genetic networks would be able to physically construct and test these networks.<br\/><br\/>Ultimately the ability to engineer genetic networks and biochemical pathways has extremely broad promise. Several early applications of great interest include 1) Detoxification of various types of both chemical and biological waste; and 2) Production of useful chemicals, such as plastics, pharmaceuticals, and hydrogen gas for fuel cells.","title":"De Novo Single Shot Whole Genome Fabrication","awardID":"0323439","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["341404","243786"],"PO":["521045"]},"83117":{"abstract":"1) Abstract<br\/>===========<br\/><br\/>Proposal Number:<br\/>CCR-0310793, CCR-0310490, CCR-0310159 and CCR-0310571<br\/><br\/>TITLE:<br\/>Graphical Passwords -- Design, Analysis, and Human Factors<br\/><br\/><br\/>PI: J.C. Birget and Dawei Hong (Rutgers-Camden),<br\/><br\/><br\/>Co-PIs:<br\/><br\/>S. Man (Southwest State U., Minnesota),<br\/>N. Memon (Polytechnic U., Brooklyn),<br\/>S. Wiedenbeck (Drexel).<br\/><br\/><br\/>Abstract:<br\/><br\/>Humans are not good at remembering alpha-numeric passwords, if the passwords are complicated enough to be secure. Graphical passwords seem easier to remember and to use. Here, an image is displayed and the user chooses a few places in the image. To log in, the user has to click close to these places again. Older systems use preprocessed images with predefined click regions, among which a user has to choose. The investigators designed systems that allow users to choose any points as click points, and that allow users to import their own images. The investigators invented a ``robust discretization'' of images; this enables users to produce exactly the same discrete password even though they cannot click on exactly the same pixels at each login. Passwords are vulnerable to ``shoulder surfing'', which consists of a user being observed, or filmed, during login. The investigators designed password systems that are immune to shoulder surfing.<br\/><br\/>One of the objectives of this proposal is a human factors study, concerning learnability, memorability, speed, security (unsafe practices), and user satisfaction of graphical password systems. A second objective is to design new graphical password systems, based on curves, movement, and three-dimensional scenes, as well as to design ``bundles'' of passwords that a user can use on different accounts, and that are easy to remember (and distinguish) as a group. New robust discretization algorithms and probabilistic analyses of the security of graphical password systems will be developed.","title":"Collaborative Research: Graphical Passwords -- Design, Analysis, and Human Factors","awardID":"0310490","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["503162"],"PO":["521752"]},"82039":{"abstract":"Many applications today have the need for tracking changes and notifying users of changes when certain update thresholds are met. However, large-scale fresh information delivery systems have received very limited system software support. The proposed research aims at investigating research issues and evaluation methods for building decentralized Peer-to-Peer (P2P) information monitoring systems. The PI plans to develop a suite of system facilities at the Peer-to-Peer protocol layer to support large scale peer-to-peer information monitoring applications. Concretely, this research project will be carried out in two consecutive phases. First, it will undertake a systematic study of research issues in design and evaluation of a scalable peer-to-peer protocol and its supporting system architecture. Second, the project will conduct an in-depth investigation of technical and engineering issues in constructing an Internet-scale peer-to-peer information monitoring system PeerCQ. Specific issues of interest include load balance among heterogeneous peers, system utilization, mechanisms for efficient, scalable, and reliable processing of large numbers of information monitoring requests. The PeerCQ prototype will be delivered as an open source software to promote and enhance research and education in peer-to-peer computing and distributed information monitoring. The methodology and algorithms developed in this project will aid in the engineering, implementation, and evaluation of peer-to-peer information monitoring applications in real world.","title":"A Peer to Peer Approach to Large Scale Information Monitoring","awardID":"0306488","effectiveDate":"2003-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["521101"],"PO":["561889"]},"86439":{"abstract":"PROJECT TITLE: ITR: Built-In Test of High Speed\/RF Mixed Signal Electronics<br\/><br\/>PROPOSAL NO.: 0325555<br\/>INSTITUTION: Georgia Inst. Technology, GA<br\/>PRINCIPAL INVESTIGATOR: Abhijit Chatterjee (lead PI)<br\/><br\/>PROPOSAL NO.: 0325371<br\/>INSTITUTION: U. Texas, Austin, TX<br\/>PRINCIPAL INVESTIGATOR: Jacob Abrahams (coPI)<br\/><br\/>PROPOSAL NO.: 0325426<br\/>INSTITUTION: Auburn University, Alabama<br\/>PRINCIPAL INVESTIGATOR: Adit D. Singh (coPI)<br\/><br\/>PROPOSAL NO.: 0325340<br\/>INSTITUTION: University of Florida<br\/>PRINCIPAL INVESTIGATOR:William R. Eisenstadt (coPI)<br\/><br\/>ABSTRACT:<br\/>In the recent past, there has been a tremendous surge in the wired communications\/wireless\/high-speed IC manufacturing sector. While the design community has pushed the design envelope far into the future, the test barriers have not kept pace with the test requirements of high speed, integrated wireless and wired communications designs. Every IC that is manufactured, needs to be tested against its design specifications before shipment to the customer. As the speeds of these ICs increase, so do the requirements of the testers needed to test these ICs in manufacturing production. High-speed testers above 2 GHz are prohibitively expensive. Consequently, for speeds beyond a few GHz (2 - 25 GHz), built-in test (BIT) of high-speed\/RF systems is a very attractive solution. Built-in test involves incorporation of test circuitry in the IC itself to facilitate the manufacturing test process. In this way, many of the test functions are performed \"on-chip,\" alleviating the need for a high-speed (expensive) external tester. Since test cost is projected to escalate to about 40% of the total manufacturing cost of complex communications ICs in the near future, the use of built-in test is expected to significantly impact the cost of the manufactured ICs themselves and the ability of companies to compete in the marketplace.<br\/>The core concept behind the proposed built-in test methodology is easy to follow. Instead of directly measuring the high-speed test specifications of the IC-under-test, a new paradigm for BIT of high-speed\/RF circuits using alternate tests is proposed. Alternate tests are compact tests that are much more simpler to run than the original specification tests but contain as much information (or more) about the performance of the circuit-under-test as the original tests themselves. Furthermore, it is possible to design these tests so that pass-fail decisions can be made, based on analysis of analog signals using analog circuitry. In this way, two problems are solved: (a) that of being able to measure complex high-speed test specifications using simple on-chip test resources and a low-cost external tester, and (b) that of being able to analyze very high-speed signals (> 2 Ghz) without the need to digitize them (such digitizers are not available or are very expensive at these frequencies). The proposed work is interdisciplinary and will involve the use of concepts from computer algorithms, analog\/RF circuit design, mathematics and statistics and fundamental electrical engineering and device physics.","title":"ITR: Built-in Test for High Speed\/RF Mixed-Signal Electronics","awardID":"0325371","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[225904],"PO":["562984"]},"78618":{"abstract":"Recent years have witnessed a tremendous growth in the demand for ubiquitous information access. Current wireless networks, however, are still far from meeting this demand. A central problem in the design of wireless systems is how to efficiently transmit bursty multimedia traffic over wireless links. It is expected that developing network-level solutions that take advantage of the interplay between the communication channel and the upper protocol layers would yield significant performance gains. Optimal design across multiple layers opens a new promising area with many design issues unresolved. It is therefore of vital importance to develop theory and methodology that help propel significant advances and lead to revolutionary breakthroughs in this area.<br\/><br\/>In this project, the PI proposes to take a cross-layer design approach to devising a suite of resource allocation and multi-access schemes, aiming to establish a comprehensive framework for transmitting bursty traffic over fading channels. The proposed research is centered around two areas: 1) bursty traffic over CDMA: a key goal of this thrust is to obtain overriding principles for cross-layer optimization of bursty traffic transmissions in interference-limited systems; and 2) \"opportunistic\" access control for bursty traffic: this thrust aims at a deep understanding of how to exploit traffic information for novel access control in opportunistic communication systems (which are basically TDMA systems equipped with opportunistic scheduling). A common thread encountered throughout is to \"exploit\" (rather than \"combat\") traffic burstiness and channel variation. The two thrusts are outlined as follows:<br\/>1) Bursty traffic transmission in CDMA networks: Building on the PI's recent finding that the multi-access interference (MAI) is long-range dependent, the PI will<br\/> a. conduct a comprehensive study on the MAI long-range dependence and identify the predictive MAI structure, and exploit the MAI structure to develop efficient measurement-based interference prediction. The impact of traffic burstiness, fading, and feedback delay will be examined;<br\/> b. utilize interference prediction to explore efficient resource allocation and access control.<br\/>2) Bursty traffic transmission in opportunistic communication systems: The PI will:<br\/> a. investigate traffic-aided admission control for opportunistic communication systems;<br\/> b. devise innovative opportunistic scheduling for streaming multimedia to exploit multi-user diversity gain embedded in both channel variation and traffic burstiness.","title":"CAREER: Efficient Resource Management and Multi-Access Protocols for Bursty Traffic Over Wireless Networks: A Cross-Layer Design Approach","awardID":"0238550","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["518327"],"PO":["565090"]},"90971":{"abstract":"Despite the general belief that research in dense linear algebra libraries has been exhausted, history shows that as new architectural features appear in high-performance computers used for scientific applications, the need for the renewed investigation of widely used dense linear algebra packages resurfaces. This has been the case when vector supercomputers first appeared in the 1970s, when microprocessor based workstations appeared in the 1980s, and when distributed memory parallel architectures appeared in the 1990s. Now, with the emergence of multi-level memories in both sequential and parallel architectures, a redesign is once again warranted, as the performance attained by the current generation of dense linear algebra packages does not match that of the best optimizations of algorithms for individual operations. A closely related concern is that the existing libraries do not always have the functionality nor the performance required by the scientific computing community.<br\/><br\/>The fundamental problem with the traditional approach to developing a new dense linear algebra library from a previous library is that it has been inherently evolutionary. There has been a heavy emphasis on maximal code-reuse in the belief that the ``correctness'' (established largely through exhaustive testing) of the previous library is then inherited by the new library, thus reducing the effort required to produce that new library. Unfortunately, there are identifiable reasons why the evolutionary approach has failed in the past and is doomed to failure in the future. The fundamental premise behind this proposed project is that a revolutionary approach must be developed if the repeated investment of effort is to be avoided.<br\/><br\/>Recent research has uncovered a systematic approach to the derivation of provably correct dense linear algebra algorithms via the application of classic derivation techniques from computer science. The practical solutions that may now be within reach include the (partially) automatic development (derivation, implementation, and cost and stability analysis) of high-performance dense and banded linear algebra libraries. This is in contrast to the traditional<br\/>approaches for implementation of such libraries for which the development, debugging, and maintenance are tedious and error-prone processes because of their complexity. The proposed work promises to deliver libraries that require little or no maintenance through the systematic and direct translation of systematically derived, provably correct algorithms to an imperative programming language.<br\/><br\/>The proposed work will lay the foundation for such automated systems by concentrating on developing the systematic approaches mentioned above, without yet venturing into automation. In addition, prototype libraries, coded using the latest software engineering techniques, will be developed to demonstrate the potential of the approaches. In particular, the ability to overcome the apparent cost of the abstractions that drive the systematic approaches by using C++ techniques like template meta-programming and expression templates will be central to the study. Success will be measured by the degree to which the systematic approaches will enable automation, by the new algorithms that will be uncovered using the methodology, and by the<br\/>performance that can be demonstrated (on sequential and parallel architectures) by the resulting prototype libraries. Automated methods currently used by other projects are not deemed to be competitive, in terms of performance and flexibility, with the proposed libraries.","title":"Collaborative Research: A Systematic Approach to the Derivation, Representation, Analysis, and Correctness of Dense and Banded Linear Algebra Algorithms for HPC Architectures","awardID":"0350463","effectiveDate":"2003-08-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["527384"],"PO":["565272"]},"82996":{"abstract":"Jacome<br\/><br\/>High-Performance Computer Architecture in the Nanoelectronics Era: Overcoming the Reliability Challenge<br\/><br\/>Abstract<br\/><br\/>The formidable increase in device densities promised by nanoscale integration will be accompanied by a substantial rise in the numbers of faulty devices. This increase in both hard and soft faults poses a major `reliability challenge,' demanding a rethinking of fundamental microarchitectural techniques and components. Indeed, performance will be inextricably tied to reliability. Thus, it is important to investigate how effective reliability-performance tradeoffs can be realized at the microarchitecture level. The proposal includes research on several novel techniques including: reliability driven speculation, adaptive validation via incremental recomputing of speculated values, and exploiting reliability-aware functional units and self-checking capabilities. In addition the research includes devising novel design methodologies aimed at achieving the necessary reliability for microarchitectural components, and models capturing the scaling of delay versus reliability for concrete component designs. Key quality metrics (performance, reliability and yield) will be evaluated through analysis and simulation.<br\/><br\/>The timeliness, strategic importance and huge potential payoff of advances in nanotechnologies are widely recognized. The ability to engineer these technologies into new products will create tremendous opportunities for economic expansion and improved quality of life. Taking these technologies into production environments requires addressing the reliability challenges identified in this proposal. The outcomes of this project are likely to impact the design of future nanocomputing systems.","title":"High-Performance Computer Architecture in the Nanoelectronics Era: Overcoming the Reliability Challenge","awardID":"0310119","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["560221","293070"],"PO":["325495"]},"85911":{"abstract":"This project seeks to answer the questions of network proximity estimation, other than direct measurement, by exploring a new analysis approach, combined with large-scale network measurement. Currently, there are very few methods for estimating network proximity, which can add significant overhead to both application and network in terms of delays and additional traffic. Newly emerging Internet applications, e.g. content delivery networks, peer-to-peer networks, multiuser games, overlay routing networks, and applications employing dynamic server selection, depend for its optimal configuration on accurate measures of network proximity. Recent effort in network proximity estimation has suggested that a promising approach may be to model network distances using coordinate systems; that is, via an embedding of network distances into Euclidean space. This approach has many appealing properties, but many fundamental questions remain unanswered: Is a Euclidean embedding effective in general? What is the appropriate dimension to use, and what is the best method for mapping distance measurements into a Euclidean space? How scalable are the resulting schemes? For what sorts of distance metrics are such schemes appropriate? The new analytic approaches proposed here are based on linear algebraic techniques, in particular the application of Principal Component Analysis to the problem of constructing good coordinate systems for the Internet. This project will collect and analyze a large set of network measurements to assess coordinate schemes on truly representative data and develop new algorithms for constructing coordinate schemes that are accurate and yet scalable to thousands of nodes, made available in the form of freely distributed tools.","title":"Coordinate Systems for the Internet","awardID":"0322990","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["486062"],"PO":["565090"]},"83503":{"abstract":"This research deals with improving the computational efficiency of existing power<br\/>control algorithms for wireless systems, as well as developing new computationally<br\/>efficient algorithms. Power control helps minimize transmitted power, and is<br\/>important as it enhances battery life for mobile terminals and extends the life<br\/>of the wireless network. In a multiuser environment power control contributes also<br\/>to minimizing interference and increasing system capacity. <br\/><br\/>The investigators study the use of iterative methods for improving the computational<br\/>efficiency of existing power control algorithms, with emphasis on game theoretic<br\/>approaches. At the physical layer power control is combined with codeword adaptation<br\/>and new algorithms for joint codeword optimization and power control are developed<br\/>in which target signal-to-interference ratios (SIRs) are achieved with minimum<br\/>transmitted power by decreasing effective interference through codeword adaptation.<br\/>Codeword adaptation is based on greedy interference avoidance methods which are also<br\/>investigated from a game theoretic perspective.","title":"ITR: Computationally Efficient Methods for Power Control in Wireless Systems","awardID":"0312323","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[217710,217711],"PO":["499399"]},"83646":{"abstract":"Understanding arbitrary natural language sentences is widely regarded as very challenging. Yet understanding questions such as ``What is the capital of Italy?'' or ``What Chinese restaurants are open on Sunday in Seattle?'' seems straightforward even for a machine. While natural language sentences have the potential to be subtle, complex, and rife with ambiguity, they can also be simple, straight forward, and clear. This project formalizes this intuition by identifying classes of questions that are ``easy to understand'' in a well defined sense. <br\/><br\/>People are unwilling to trade reliable and predictable user interfaces for intelligent but unreliable ones. To satisfy users, Natural Language Interfaces (NLIs) should not be allowed to misinterpret their questions often, if at all. Consequently, this research project has three components. First, it introduces a theoretical framework for analyzing the reliability of an NLI by formally defining the properties of soundness and completeness and identifying a class of semantically tractable natural language questions for which sound and complete NLIs can be built. Second, it is shown that the theory has practical import by measuring the prevalence of semantically tractable questions and by measuring the performance of a sound and complete NLI in practice. Finally, the project extends the framework to dialog systems and to increasingly broad classes of natural language sentences.<br\/><br\/>The research has the potential to reinvigorate basic research on NLIs, and to have the broader societal impact of making powerful information resources more readily available to ordinary people regardless of their knowledge of Computer Science.","title":"ITR: Semantically Tractable Questions: Theory and Implementation","awardID":"0312988","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["365925"],"PO":["565215"]},"83305":{"abstract":"Stochastic processes are a very powerful tool for analyzing the performance of computer systems. However there are still some very fundamental computer systems problems which remain largely intractable. One example is the simple cycle stealing problem, where one server can steal another server's idle cycles under a switching cost overhead. Cycle stealing pervades applications ranging from Webserver farms, to networks of workstations, to disk arrays, to databaseserver clusters, and yet very simple questions like quantifying the benefit of cycle stealing, or understanding under what conditions cycle stealing is profitable are not yet understood. Another example is the long standing open problem of finding and analyzing the optimal policy for task assignment in a server farm. Interestingly, these problems and other open fundamental computer systems problems are difficult for the same reason: they all have a Markov chain representation which grows infinitely in two or more dimensions (2D). While a one-dimensional (1D) infinite Markov chain with repeating structure can be solved via computational approaches, these 2D infinite chains can not.<br\/><br\/>This project proposes a new approach for attacking problems such as those above, resulting in a 2D infinite Markov chain. The idea is to transform the 2D infinite chain into a 1D infinite chain which can be analyzed, without removing the relevant problem information. This is achieved by using Markov chain transitions to denote the durations of various types of busy periods. The project will entail a mathematical exploration of the general applicability of this technique, the application of the technique to specific problems, and the implementation of the analytical solutions within real systems.<br\/><br\/>Broader impacts resulting from the proposed activity include: a workshop on scheduling in server farms; online availability of all source code generated from the work along with documentation; a highly-accessible set of lecture notes on queueing theory applications which evolves yearly to reflect the current research aims of the author; collaborations with the Pittsburgh Supercomputer Center to implement ideas in this proposal; and undergraduate research opportunities in scheduling. The project involves 1 faculty member (1summer month only) and 0.5 graduate students over the course of 3years.","title":"Analysis of Cycle Stealing and Other Multi-Server Problems via New Dimensionality Reduction Approach","awardID":"0311383","effectiveDate":"2003-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["555524"],"PO":["499399"]},"83206":{"abstract":"CCR-0310877<br\/><br\/>Computer Security: A Quantitative Approach<br\/><br\/>Michael D. Smith, Harvard University<br\/><br\/>The proposed project will improve in a quantifiable manner the computing industry's ability to model, analyze, predict, and ultimately increase the security of large composite information systems (i.e., those built from myriad hardware and software components). The approach uses existing economic methods and tools to quantify the threat posed by malicious individuals; decades of research in economics provide a wealth of quantitative techniques for modelling and measuring the effects individuals have on larger systems. In particular, the proposed work measures system security (or robustness) against modes of failure using economic units (dollars). The proposed model is based on a measure, colloquially known as the cost to break, that represents the market price to find and demonstrate a single, previously unknown flaw. The proposed work will extend this measure to support analysis of real systems, which may contain multiple flaws. The resulting model will yield a means for creating security strategies that correctly reflect the wide range of adversaries and the security priorities of the defense. The project will also produce quantitative threat models, based on economic theory, that provide better insights into the motivation and means of attack available to adversaries. These new models will help the defense estimate the level of security required to successfully deter existing threats, reason about new threats, and quantify the shortcomings of existing security systems.","title":"Computer Security: A Quantitative Approach","awardID":"0310877","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["255915"],"PO":["521752"]},"83327":{"abstract":"This project is focused on efficient algorithms for performing trusted<br\/>computations in a networked environment, with applications to<br\/>cyber-security.<br\/><br\/>Intellectual Merit.<br\/><br\/>The following topics will be investigated:<br\/><br\/>- Authenticated data structures and algorithms. We will study methods<br\/> for authenticating the results of data structures and algorithms,<br\/> even when those computations are performed by an untrusted third<br\/> party on behalf of a trusted source.<br\/><br\/>- Audited algorithms. Bringing together recent research on program<br\/> checking and space-efficient computations for streaming data, the<br\/> project will explore a new computational framework in which<br\/> computations are performed by a community of untrusted users and are<br\/> checked by an external auditor with limited computational resources.<br\/><br\/>Broader Impacts.<br\/><br\/>The proposal is directed at a subject area of critical importance to<br\/>society -- methods for efficiently maintaining the security of<br\/>computations and computational resources, including the networks that<br\/>communicate vital data.","title":"Collaborative Research: An Algorithmic Approach to Cyber-Security","awardID":"0311510","effectiveDate":"2003-08-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["521367"],"PO":["499399"]},"83338":{"abstract":"As users and companies begin to rely heavily on the Internet for day-to-day operations, issues such as security and privacy become ever more important in the areas of computer communications and<br\/>networking. Secure group communications (SGC) refers to a setting in which a group of participants can send and receive messages in a way that outsiders are unable to glean any information even when they are<br\/>able to intercept the messages. <br\/><br\/>Group key management (GKM) is the most important issue in SGC. This project will focus on SGC GKM in wired networks as well as in wireless environments. In particular, new, scalable, fault-tolerant, block-free, and burst-efficient GKM protocols will be designed and tested. Theoretical analysis of complexities (time, space, and communication) and experimental simulations for GKM protocols will be performed. Prototype SGC systems and SGC Application Programming Interfaces (APIs) which can be used by industry and SGC application developers will be implemented. The multi-disciplinary research conducted in this project will have a broad impact on graduate and undergraduate education in the areas of information security, cryptography, computational complexity theory, computer networking and<br\/>telecommunications. The research results from this project will be integrated into regular Computer Science and Engineering (CSE) and Information Technology (IT) curricula and findings and software<br\/>resulting from this project will be disseminated.","title":"Secure Group Communications (SGC) over Wired and Wireless Networks","awardID":"0311577","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[217277,"559287","409525"],"PO":["521752"]},"82018":{"abstract":"Increased awareness of power concerns and recent approaches to improve<br\/>energy efficiency and heat dissipation in computer systems have not<br\/>immediately translated into rich, adaptable, power-aware applications.<br\/>This lack of effectiveness is particularly evident in power-aware<br\/>real-time computing, where efforts to bridge the gap between hardware<br\/>and software have generally been limited to developing new schedulers<br\/>that operate by modulating a relatively high-level hardware control<br\/>such as voltage scaling and frequency scaling. The problem with this<br\/>approach is that the hardware controls operate at too gross a level to<br\/>be effective in dynamic, poorly-modeled application scenarios.<br\/><br\/>This project develops a feedback-based, control-theoretic approach to<br\/>optimize and balance, at runtime, power consumption and real-time<br\/>performance. This approach not only integrates hardware-level<br\/>power-management techniques with real-time and quality-of-service<br\/>(QoS) constraints, but also integrates a range of hardware<br\/>power-management techniques at different granularities into a unified<br\/>framework that allows better task-level control of power management.<br\/>This enables finer control of power\/performance tradeoffs by the<br\/>operating system, and permits applications to dynamically adjust the<br\/>system's and chip's power-saving configuration on a per-task basis to<br\/>meet specific performance requirements while reducing power<br\/>consumption. With the new functionality provided by this project, a<br\/>richer class of power-aware applications can be developed to provide<br\/>valuable user experiences in next-generation, real-time environments.<br\/>The project specifically focuses the requirements of web server<br\/>farms where energy and cooling costs are substantial and where the web<br\/>services provide differentiated levels of QoS, thus motivating a<br\/>power-aware framework that balances performance, QoS requirements, and<br\/>energy costs.","title":"Feedback Techniques for Integrating Power Management and Quality of Service in Servers","awardID":"0306404","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["489873","553633"],"PO":["543507"]},"83349":{"abstract":"Abstract<br\/><br\/>Embedded hybrid systems are ubiquitous throughout society: industrial machines, automobiles, medical equipment, household appliances, airplanes, power grids, and environmental monitoring systems all fall under their rubric. The mission-critical nature of the applications in which embedded hybrid systems are used demands high levels of efficiency, performance, reliability, safety, and security. Furthermore, there is an increasingly critical need for the tight integration of multiple applications developed using diverse design paradigms such as periodic feedback control, human interfaces, information processing, and intelligent autonomy to reduce system size, weight, and power consumption.<br\/><br\/>The safety and security of information differs vastly from the safety and security of control. Most industrial control systems used to operate utilities and factories are linked to the Internet, and have wireless sensor networks that can be compromised with a laptop, wireless card, and directional antennae. In an information technology system, security measures are designed around protecting critical core servers, while security of individual remote terminals is not prioritized. However, in the control of an actual physical hybrid system, remote programmable logic controllers (PLCs), which remotely control a facility's sensors and actuators via wireless means, play a key role: If the supervisory control system is compromised, the threat is not as great as if a PLC is attacked. Simply encrypting transmissions and passwords does not provide the solution, and often compromises safety. Hence, an entirely different architecture for designing, implementing, and verifying security in hybrid control systems is necessary.<br\/><br\/>To address these challenges, a tightly integrated design, analysis, verification, and implementation environment for real-time, safe, and security-critical embedded hybrid systems is being created. It includes a formalism-independent method for embedded hybrid system architectural specification with attributes and semantics for verification and validation of properties such as security and safety, along with mechanisms that allow for the composition of models specified in different hybrid modeling languages in a secure and safe manner. More specifically, an abstract functional interface will be created to enhance modularity of the developed solution techniques and reward structures will be used to perform directed searches of a state space to mitigate the state explosion problem. In addition, backwards reachability techniques will be used in order to find escape paths from hazardous states, thereby mitigating the number of states that need to be explored, rendering the problem of verification and validation more tractable. Meshing these two approaches promises to yield groundbreaking results in the scale and complexity of hybrid systems that can be modeled, analyzed, and verified.<br\/><br\/>The broader goal of the project is to produce an industrial-strength tool for the modeling, analysis, and verification of hybrid systems for initial distribution to research institutions, and, upon refinement, to interested industrial partners, such as utilities and airlines. The project will also help create a multidisciplinary base of students (both graduate and undergraduate) from diverse fields such as computer science, operations management, and systems engineering who are competent in the modeling, analysis, and verification of large, complex systems. The result will be an enhanced safety and security culture in academia and industry, which will create overt awareness of the field in the students who will be tomorrow's engineers. It will thus lead to a revolution in the way that complex systems are designed.","title":"Creating An Integrated Modular Environment for the Modelling, Analysis and Verification of Embedded Hybrid Systems","awardID":"0311616","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["542482","383893"],"PO":["561889"]},"83129":{"abstract":"Title: Embedded Software for Domain-Specialized Platforms<br\/>PI: Ingrid Verbauwhede, UCLA<br\/><br\/><br\/>This project develops design methods for embedded software in the context of portable, <br\/>integrated and secure platforms. An example of such a platform is a key-chain <br\/>or a next-generation smart-card with integrated electronics and embedded<br\/>fingerprint sensor. The key-chain allows to use biometrics as a personal key in <br\/>electronic payments or access control. The software for this platform is complex and <br\/>draws from multiple application domains, including signal processing, <br\/>cryptography, and protocol transaction processing. <br\/>Moreover, this software must integrate encryption and fingerprint signal <br\/>co-processors. Thus, the design method for such software must allow for<br\/>multiple design paradigms to coexist, and at the same time must also make<br\/>optimal use of the constrained, embedded form factor to which it is confined.<br\/><br\/>The design method is based on two principles. The first principle is the<br\/>use of virtual machine specializations. A virtual machine allows for a<br\/>smooth, write-once run-everywhere development concept, while the<br\/>specializations allow native support of domain-specific co-processors. The<br\/>second principle is that of flexible interconnect, which allows to shape<br\/>the target architecture to the application at hand. Both of these methods<br\/>are genuine innovations in embedded software design context.<br\/><br\/>On a broader scale, these design techniques are applicable to a wide range <br\/>of portable, embedded devices that provide a tighter coupling of secure<br\/>information infrastructure with the real world. For example, currently<br\/>digital identities are insufficiently coupled to physical identities, <br\/>resulting in identity theft becoming a large-scale problem. Software is a<br\/>key enabler to combat this problem, and the design techniques from this<br\/>project will have broad impact by allowing this software to migrate <br\/>to the embedded context where it is required.","title":"Embedded Software for Domain-Specialized Platforms","awardID":"0310527","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["293104"],"PO":["561889"]},"78938":{"abstract":"In this project, various radio resource allocation problems that arise in multi-hop wireless communication networks are proposed, where the main focus is on broadband wireless infrastructure networks. The aim is to help facilitate the realization of such networks by developing system level approaches to reducing cost and maximizing performance. The resource allocation problems considered include transmission scheduling, routing, power control, and topology configuration, including node placement, and node density planning. In this project, rigorous mathematical analysis techniques will be developed that have not previously been applied to the design of wireless infrastructure networks. These techniques will be combined with practical engineering approaches to yield novel network architectures and improved insight into the design space for multi-hop wireless networks. The results of the project could help to enable low cost, ubiquitous wireless networks that support very high data rates. Development of resource allocation technology underlying broadband wireless infrastructure networks, as presented here, may enable other related applications, including high bandwidth sensor networks and ad-hoc networks. For example, cost effective high bandwidth wireless infrastructure network technology may lead to \"grass root\" development of highly robust communications infrastructures whose control and ownership is distributed among end-users. The improvement of the efficiency of wireless information transport may enable large-scale video surveillance networks.","title":"Radio Resource Allocation in Wireless Communication Networks","awardID":"0240067","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["235820"],"PO":["565090"]},"83701":{"abstract":"Many domains of human activity are characterized by directed graphs:<br\/>interactions in social networks, citation networks, hyperlinked<br\/>domains like the web, trade relations between companies, patterns of<br\/>air travel. Clustering is a general technique to discover global<br\/>structure in such networks of local interactions. Presently, networks<br\/>with asymmetric relations are first symmetrized then clustered by<br\/>methods applicable to undirected graphs. This proposal shows that<br\/>symmetrization often loses the information about structure and propose<br\/>to develop a theoretical framework and algorithms for clustering of<br\/>directed networks. I will approach the task using the random walks<br\/>view that I developed and which has proved successful at clustering in<br\/>undirected graphs.","title":"Clustering Link Data - Theory and Algortithms","awardID":"0313339","effectiveDate":"2003-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V145","name":"CIA-KNOWLEDGE DISCOVERY & DISS"}}],"PIcoPI":["478990"],"PO":["563751"]},"83602":{"abstract":"This research project proposes to develop a transaction management technique for a mobile multidatabase management system that takes energy restriction, transaction real-time constraints, and ad-hoc networks into consideration. This technique is aimed at reducing the overall energy consumption and providing a balance in individual mobile host (MH) energy consumption, while at the same time reducing the number of transactions that must be aborted due to deadline violations. It considers both firm real-time and soft real-time transactions, and three modes that an MH can be in: active, doze, and sleep. It treats time as the most important factor in handling firm transactions while energy as the most important factor in handling soft transactions. It uses this principle to locate MHs, schedule transactions, and commit\/abort transactions. It handles disconnection and migration by introducing a suspended state into global transactions to ensure that transactions of mobile users whose status is unknown will not be aborted until they obstruct the execution of other transactions. A prototype will be developed to evaluate the performance of the proposed technique for real-life applications and to provide guidelines to assist both users and designers.","title":"A Power-Aware Technique to Manage Real-Time Database Transactions in Mobile Ad-Hoc Networks","awardID":"0312746","effectiveDate":"2003-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["432786",217954,"562677","346051"],"PO":["563751"]},"81424":{"abstract":"NIRT: Bottom Up Assembly of Metal and Semiconductor Nanowires: Fundamental Forces to Electronic Circuits<br\/><br\/>Abstract<br\/><br\/>This proposal was received in response to Nanoscale Science and Engineering initiative, NSF 02-148, category NIRT. The technical goal of this project is to enable bottom-up assembly of nanoparticles by controlling fundamental forces. Compared with top-down nanoparticle assembly, bottom-up assembly provides an inexpensive route to making bulk quantities of nanomaterials, including high-density nanoelectronics. Promising methods have been developed by one of the investigators to produce nanoassemblies using bead templating assembly and DNA-directed bead templating assembly. By engineering the fundamental forces (e.g., van der Waals, solvation, depletion), this proposal seeks to minimize undesired aggregation and control either nondeterministic or deterministic assembly. The principles of fundamental nanoparticle forces learned in this research will be tested in the construction of a functional logic circuit based on quantum mechanical ideas, and the same principles will provide a basis for scaling up production quantities of this circuit.<br\/><br\/>The logic circuit to be built consists of hexagonal or square arrays of semiconductor nanowires (e.g., silicon, gallium arsenide), with metal (e.g., gold, platinum) gate wires. This project has five objectives. 1) Simple versions of the device will be built with larger wires at the Penn State Nanofab Facility, using electrofluidic techniques. This will enable development of circuit testing procedures required for later tests with the circuit built using directed assembly. 2) A non-deterministic bead templating technique will exploit physical forces (e.g., electrostatics, steric, solvation) to assemble from the bottom up various types of functional nanowires. Essential to this work is the screening of co-solvent\/particle systems that aggregate uncontrollably, and this will benefit greatly from phase diagrams simulated with molecular level simulations. 3) Unique sphere-rod interparticle force measurements will synergize with molecular dynamics simulations to produce predictive models and heuristics that will be broadly applicable in stabilizing nanoparticle dispersions, for instance by minimizing van der Waals forces and maximizing the stabilizing solvation forces. 4) Bead templating with DNA-directed assembly will be combined with the heuristics from the third objective to guide assembly while preventing undesired particle interactions as the DNA links the nanowires in the desired configuration. The undesired aggregation has been a critical barrier to otherwise very promising techniques. In both subprojects 2 and 4, the circuits will contain chemical specificity that enables, for instance, metal-semiconductor junctions, facilitating objective 1, because the nanocircuits will need to connect to instrumentation large enough to take useful measurements.<br\/><br\/>The broader impact resulting from this project will be improved public ability to make \"nano\" decisions through hands on experience. Nanotechnology has many new capabilities, some, which will be unfamiliar to even the technologically, educated public. It is imperative that the public have sufficient experience with nanotechnology to make ethical and voting decisions. In order that the public gain \"hands on\" experience with nanotechnology, we will conduct semi-annual workshop booths at the \"Central Pennsylvania Festival of the Arts\" in State College, Pennsylvania. This event attracts approximately 200 000 participants annually, providing an extremely public forum. The hypothesis to be tested is that as the public participates, their comfort in accepting the technology and voting on decisions will be enhanced.<br\/><br\/>Another important activity will be to \"teach teachers to teach nano\", building the knowledge of State College Pennsylvania k-12 teachers using \"research experience for teachers\"-type programs to leverage our own expertise into local students and their parents. For this part of the course, summer lab work with local k-12 instructors will enable the development of interactive modules for use in the classroom.","title":"NIRT: Bottom Up Assembly of Metal and Semiconductor Nanowires: Fundamental Forces to Nanoelectronic Circuits","awardID":"0303976","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"1385","name":"SPECIAL STUDIES AND ANALYSES"}}],"PIcoPI":["529764","545158","445751","564843"],"PO":["562984"]},"83515":{"abstract":"Privacy concerns can prevent constructing a centralized data warehouse to support data mining. For example, the Centers for Disease Control (CDC) may want to mine insurance companies' data to identify trends and patterns in disease outbreaks, such as understanding and predicting the progression of a flu epidemic. Gathering all patient data into a single warehouse increases opportunities for privacy breaches and misuse. We propose an alternative: secure collaborative computing between the parties holding the data that produce the desired data mining results, while provably preventing disclosure of private data.<br\/><br\/>This project will enable knowledge discovery under the following assumptions:<br\/>1. data are distributed across multiple sources, with security\/privacy concerns that limit data sharing, and<br\/>2. if data were gathered into a centralized warehouse, data mining tools could identify patterns or relationships that give beneficial knowledge.<br\/>Developed techniques will replicate or approximate the results of centralized data mining, with quantifiable limits on the disclosure of data from each site. The goal is to develop a toolkit of privacy-preserving distributed computation techniques that can be assembled to solve specific real-world problems. By simplifying component assembly so it becomes development rather than research, widespread use of privacy-preserving distributed data mining will become feasible.","title":"Collaborative Research: ITR: Distributed Data Mining to Protect Information Privacy","awardID":"0312366","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["550133"],"PO":["469867"]},"81359":{"abstract":"EEC-0303674<br\/>Cornell University<br\/>Mukherjee<br\/><br\/>The objectives of this three-year project entitled: Dynamical Response of Carbon Nanotubes,\" are: (1) dynamic response modeling of ~1-2nm diameter size carbon nanotubes using a hierarchical approach of standard continuum mechanics, enriched continuum mechanics, molecular dynamics, and ab initio electronic calculations: (2) experimental research utilizing the remarkable mechanical, thermal, and electrical properties of carbon nanotubes to create nanometer-scale electromechanical devices (NEMs); and (3) investigate the unique properties of carbon nanotubes for the innovation of a series of novel devices. The research plan includes five tasks: (1) simulations using continuum mechanics; (2) simulations using enriched continuum mechanics; (3) calculations of first principles; (4) experiments of nanotubes for device applications; and (5) comparison of theory and experiments. Three faculty members including the principal investigator from three departments will form the research team.<br\/><br\/>This award is made under the Nanoscale Science and Engineering Initiative NSF 02-148.","title":"Dynamical Response of Carbon Nanotubes - Modeling, Simulations and Experiments","awardID":"0303674","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1480","name":"ENGINEERING RESEARCH CENTERS"}}],"PIcoPI":["276145","419167",212003],"PO":["431774"]},"83559":{"abstract":"Information Technology is making great progress in the operating room. In the practice of minimally invasive surgery, three-dimensional modeling techniques are enabling preoperative planning, new image acquisition and display techniques, and superior dexterity through teleoperated robotic systems. However, one sensory channel is presently ignored in these technological improvements: touch. In manual surgeries, haptic feedback is crucial for palpation, suture manipulation, and detection of puncture events. Sensation of forces is particularly important for invasive tool-tissue interaction tasks such as grasping, cutting, dissection, and percutaneous (GCDP) therapy. Lack of haptic information overloads the visual sensing required of the surgeon, requiring a demanding level attention. For information technology to truly enhance the practice of surgery, multiple sensory channels must be utilized. <br\/> <br\/>We propose to develop instrumentation and algorithms for modeling the haptic aspect of tool-tissue interaction in four common surgical tasks, namely: grasping, cutting, dissection, and percutaneous therapy. This system will significantly enhance information display in three ways. First, data acquired in real time will be used to provide feedback to the surgeon during model-based teleoperated procedures, increasing the transparency. of the robot-assisted surgical system. Second, real-time modeling techniques will enable model-based teleoperation, removing the strict constraints imposed by time delays in traditional, direct teleoperation. Third, realistic surgical simulations will improve training, increasing surgeon competence and patient safety. The instrumentation and modeling algorithms will be used to determine parameter values for different tissue types, particularly liver, prostate, spleen, and kidney. Ex-vivo tissues and phantom hydrogel tissues will be used in these experiments. Once the instrumentation and modeling techniques are developed, we will proceed to extensive validation of the three applications of enhanced information display. Performance experiments will verify improvements in accuracy and precision for direct and model-based teleoperation, and a computer vision\/force sensing system will determine the realism of force and deformation models developed for surgical simulation. This proposal addresses the ITR challenge for developing an information-enhanced display with computational, simulation, and data analysis methods for modeling common surgical GCDP tasks for which currently there is no systematic model. <br\/> <br\/>Intellectual merit: The specific goal of this project is to significantly improve the information-enhanced operating room through the sensing and acquisition of models representing haptic information during tool-tissue interactions in minimally invasive surgery. This research will significantly impact: (a) tool-tissue interaction models that reflect the actual forces and deformation occurring during surgery, (b) haptic feedback to the surgeon during direct or modelbased teleoperation, thereby improving surgical outcomes, c) the development of realistic simulations for training current and future health care professionals, and d) the development of instrumented smart tools for both traditional minimally invasive and robot-assisted surgeries. <br\/> <br\/>Broader Impacts: The PIs from both institutions have an excellent history of involving undergraduate students (both men and women) in research projects through Research Experience for Undergraduates (REU). Additionally, the Drexel Research Experience for Teachers (RET) site proposal recommended for funding by NSF, along with an established RET program at Johns Hopkins, will involve high-school math and science teachers from high schools to participate in summer research projects related to this proposal. These activities will enhance participation of underrepresented groups from inner-city schools and lead to broader dissemination of scientific and technological education of the students and teachers. <br\/>For graduate students, the interdisciplinary nature of this research offers new opportunities in education, broadening the interaction of mechanical engineers and medical professionals. Finally, the proposed research will lead to improvements in surgical outcomes, benefiting the patient and the society at large. <br\/> <br\/>Due to the diverse areas of research required by this project, the proposed research will benefit from the collaboration of PIs from Drexel and JHU. Drexel has expertise in haptics, FEM modeling, grasping\/dissection tasks, and phantom tissues while JHU has expertise in reality-based modeling for cutting\/percutaneous therapies, haptics, and validation experiments for human-machine systems. The unique facilities and collaborations at both institutions, along with strong ties to medical professionals, make this work appropriate as a collaborative research project.","title":"ITR: Collaborative Research: Modeling and Display of Haptic Information for Enhanced Performance of Computer-Integrated Surgery","awardID":"0312551","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["520895"],"PO":["521045"]},"83119":{"abstract":"CCR-0310493<br\/><br\/>A Layered Approach to Securing Network File Systems<br\/><br\/>Erez Zadok<br\/><br\/>File systems protect important data, but existing file systems are not secure enough for today's needs. Moreover, file system development is difficult. This project investigates and develops an infrastructure for easy development of highly-secure and efficient file systems, using an incremental, layered approach, with a focus on network-based file systems. The main technique used is called \"stacking\": a method for one file system to pass through the operations and data to one or more other file systems. With stacking it is possible to intercept file system operations and then control them as needed. Examples of file systems that are being developed include strong transparent encryption, transparent checksumming for integrity, versioning, transparent virus detection, load-balancing, replication, sand-boxing, hooks for Intrusion Detection Systems (IDSs), and more.<br\/><br\/>Stackable file systems placement is investigated for three different locations along the data path. (1) on clients, offering end-to-end assurances; (2) on servers, enabling powerful IDS capabilities; and (3) on intermediate proxies, transparently controlling file servers with minimal site impact.<br\/><br\/>The significance of this work is that it creates OS infrastructure that will allow future developers to build highly-secure and efficient file systems easily; several working file system examples are developed; and enhancements are investigated for general OS support for secure file systems. This research and teaching will usher a new era of secure file system development.","title":"A Layered Approach to Securing Network File Systems","awardID":"0310493","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["543574"],"PO":["521752"]},"86408":{"abstract":"Information available for security threat detection\/assessment is often generated from distributed heterogeneous sources. Although it may possess a significant qualitative component and lack sufficient time synchrony, this data may provide potentially critical information. This work describes a framework for effective knowledge discovery in such environments via the following tasks: refinement and generalization of the Dempster-Shafer belief theoretic framework; development of the data mining methods of association rule mining and classification; and development of methods enabling the use of timing information in the fusion process to improve threat detection\/assessment tasks. The proposed notions will be validated via the development of an experimental platform consisting of a small-scale fusion and decision-making network located at each of the participating institutions. It will possess various sensing capabilities and will mimic the security zones plus gateways structure that characterizes a typical threat detection\/assessment environment.<br\/> The work significantly advances the state-of-the-art in distributed information fusion environments that forms the basis for numerous other application scenarios. The research results and experimental platforms developed will be integrated into courses that already exist and those to be newly developed; various other outreach activities will also be undertaken.","title":"ITR: Collaborative Research: Distributed Information Fusion Networks for Threat Detection and Assessment","awardID":"0325252","effectiveDate":"2003-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["526929"],"PO":["563727"]},"81733":{"abstract":"Erich Kaltofen is studying the connection of the bit cost of arithmetic on the numeric coefficients to the overall efficiency of symbolic computation algorithms. He designs and implements new algorithms for fundamental problems in exact polynomial and linear algebra and such polynomial resultants that achieve speedup through controlling the lengths of the intermediately computed rational numbers. Faster arithmetic cost is also achieved by fixed or variable precision floating point operations, and such approximate input and output data is the subject of our investigations into hybrid symbolic\/numeric algorithms for polynomial factorization and structured system solving. Randomized algorithms for sparse interpolation problems are being executed as good heuristics with a limited number of coin flips in order to keep intermediate coefficients small. The algorithms in the LinBox program library for sparse, structured and black box matrices through its generic, reusable design are compiled with arithmetic that is specialized, for example, for particularly efficient finite field operations.<br\/><br\/>The overarching goal of the field of symbolic computation is doing mathematics with the aid of a computer. Programs such as Mathematica by Wolfram Research Inc. and Maple by Maplesoft have already reached millions of users, who use them to automatically and error-free perform the mechanics of mathematical manipulation. Thus, the users can concentrate on the interpretation of the mathematical results and, equally important, manipulate large mathematical models that are closer to reality. Kaltofen's research contributes to the infrastructure of the underlying mathematics engine on the computer. The investigated speedups make the execution significantly faster, thus allowing even better models and providing mathematics servers to even more users ranging from practicing scientists to high school students. Kaltofen under the umbrella of the LinBox group (www.linalg.org) is making the developed software freely available. Users can download and run the algorithms and experts in the discipline can scrutinize the fine points.","title":"Fast Bit Complexity in Symbolic Computation Algorithms","awardID":"0305314","effectiveDate":"2003-08-15","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["485433"],"PO":["321058"]},"91545":{"abstract":"People working collaboratively must establish and maintain awareness of one another's intentions, actions, and results. Understanding the role of awareness in computer-supported collaborative work (CSCW) and developing effective software tools to support awareness are keys to the future success of CSCW systems. This project will develop and evaluate a suite of awareness tools to support coordinated planning, action, and outcome analysis in collaborative science learning. Classroom-based field studies will be coordinated with a series of laboratory investigations, to benefit from both the scope and ecological validity of a field study and the analytical focus and control of laboratory studies. Laboratory studies will adapt task simulation methods, including the use of confederate participants, from the social psychology of communication. A key scientific objective is to investigate and develop the notion of activity awareness, the awareness of project work that supports group performance in complex and long-term tasks. Activity awareness builds upon prior research on social awareness (of the presence of one's collaborators) and action awareness (of what collaborators are doing or what they have recently done). Developing a concept of activity awareness can further integrate awareness research and tool support.","title":"ITR\/PE(IIS): Activity Awareness in Computer-Supported Collaboration","awardID":"0353075","effectiveDate":"2003-08-15","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["549541"],"PO":["495796"]},"93514":{"abstract":"Summary:<br\/><br\/>The use of randomness affects computations in dramatic and not yet fully understood ways: in algorithm design it yields simpler and more efficient ways to solve computational problems; in complexity theory it suggests new concepts and models that lead sometimes to unexpected (and far-reaching) results. This career development project involves a collection of research and educational activities related to computational randomness.<br\/><br\/>The research component of this project deals with two main themes. One goal is the development of general tools that can be used to make randomized algorithms more robust, so that they can work even if they are implemented using biased, and limited, sources of randomness. Such tools are randomness extractors, procedures that convert biased distributions into almost uniform ones, and pseudorandom generators, procedures that stretch a short random input into a much longer output that has the property of being indistinguishable (a term that is given a precise technical meaning) from the uniform<br\/>distribution. <br\/><br\/>The other theme of the research component is the study of probabilistically checkable proofs (PCP), a model of computation that gives a surprising characterization of NP in terms of efficient randomized proof-checking. The PCP model is the best known tool to prove results about the complexity of finding approximate solutions for NP-hard combinatorial optimization problems. The goal of this project is to look for stronger characterizations of NP in the PCP model, for more applications to the study of the approximability of optimization problems and, with special emphasis, for a simplified proof of the PCP characterization of NP, a result that currently has an exceedingly complicated proof.<br\/>The educational component of this project will integrate material on randomized algorithms, pseudorandomness, and probabilistic proof-systems into existing courses on algorithms and complexity and into a new course on cryptography that the principal investigator is developing. A main goal of the educational component is to give elementary presentations of some results that have so far been confined to research-oriented graduate courses. This is unfortunate because they are relevant and entertaining, not particularly hard to explain, and can have a strong motivational influence. An extensive set of lecture notes will be developed on this material.","title":"CAREER: Randomized Computations and Probabilistically Checkable Proofs","awardID":"0406156","effectiveDate":"2003-08-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["517279"],"PO":["543507"]},"81459":{"abstract":"NIRT: Molecular Assembly for Hybrid Electronics<br\/>Abstract<br\/><br\/>This proposal was received in response to Nanoscale Science and Engineering initiative, NSF 02-148, category NIRT. The extension of integrated circuits into sub-10-nm range promises enormous benefits for computing, networking, and signal processing. However, fabrication of such devices using current paradigms based on CMOS and current VLSI technology are not possible. We believe that this crisis may only be resolved by a radical paradigm shift, which would simultaneously change the approach to fabrication of electron devices and to VLSI circuit architecture. Our approach is to use a biologically inspired approach called \"Self-Evolving Neuromorphic Networks\". This approach is based on artificial models of the neocortex and is structured to have a high degree of parallelism and intrinsic redundancy. In this approach molecular circuit elements, \"self-assembled\" by molecular chemistry, can be allowed to grow randomly, forming circuit elements (molecular transistors), which connect lithographically patterned metal grids. However, the random aspect of molecular self-assembly has to be carefully understood and controlled. At present, there is no detailed understanding of this process. It is this crucial gap that we address in this proposal. The devices that we are proposing need molecular wires that can switch into and out of a conductive state. The molecules bridge the metal wires with inherent randomness. Our aims are to predict and control the bridging and switching, through deterministic chemistry of the molecule-metal interaction, as well as through a statistical analysis of the assembly process. To accomplish these aims, we have a diverse team, which will interact strongly across the engineering\/chemistry\/physics boundaries. As part of the outreach of this project we plan to use the NIRT as a forum in which we will provide new types of educational settings for students (undergraduate and graduate) and high school teachers, and adopt a flexible program of research guided by feedback between theory and experiment, chemistry and physics and engineering. <br\/><br\/>Tremendous technological advances in miniaturization have enabled more and more transistors to be packed onto a silicon chip. However, the reduction of feature size on chips is limited not just by the resolution of the fabrication process, but also by the problem of quantum and classical fluctuations. Consequently, below a limiting dimension that we have nearly reached, a new paradigm that goes beyond conventional solid state electronics has to be developed for the next generation of electronics devices. In this project, we propose a new paradigm that is based on an artificial model of the neocortex: In which molecular circuits are assembled in a manner similar to the synaptic connections present in the brain. Our paradigm if realized offers the possibility of the design of the next generation of computational devices, with speeds that, in theory, could be 10 orders of magnitude faster than the fastest existing parallel supercomputer.","title":"NIRT- Molecular Assembly for Hybrid Electronics","awardID":"0304122","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":[212339,"268760","560758","495984","380954"],"PO":["550859"]},"86827":{"abstract":"Abstract<br\/><br\/>Proposal : IIS-0327371<br\/>Institution: University of Illinois<br\/>PI: John Downie<br\/>Title: SGER: Creating a Music Information Retrieval (MIR) Development<br\/>and Testing Environment<br\/><br\/><br\/>Music Information Retrieval (MIR) is a rapidly emerging research area requiring new expertise and approaches. The amount of digital music information being created and often avaialble via the internet has been increasing at exponential rates and has prompted new approaches within the field of information retrieival to deal with this unique content. This project will construct the world's first, experimental, internationally-accessible testing and development database environment, for music information. The PI has worked closely with rights-holders in the recording industry to incorportate a rich set of content into the testing environment. The corpus of material will exceed, potentially multi-terabytes of mixed-media content ensuring that the testing environment reflects \"real-world\" situations. The principal work involves research exploring important issues related to systems design and development to support unique functionalities required in building, searching and preserving music infomration, while simultaneously ensuring the unique requirements of rights-holders.<br\/><br\/><br\/><br\/><br\/><br\/><br\/><br\/><br\/><br\/><br\/><br\/><br\/><br\/><br\/><br\/>Abstract<br\/><br\/><br\/>Proposal : IIS-0340597<br\/>Institution: University of Illinois<br\/>PI: John Downie<br\/>Title: Workshop on the Evaluation of Music Information Retrieval<br\/><br\/><br\/>This proposal is to convene a workshop as part of the 26th Annual International ACM SIGIR Conference to be held in Toronto this summer. Music Information Retrieval (MIR) is a rapidly emerging research area requiring new expertise and approaches. The amount of digital music information being created and often available via the internet has been increasing at exponential rates and has prompted new approaches within the field of information retrieival to deal with this unique content. The SIGIR Conference is a major meeting on information retrieval and affords many the opportunity to participate in the workshop who might otherwise not be able to attend. Two earlier meetings in July 2002 (JCDL) and October 2002 (ISMIR) have provided valuable background for this workshop and demonstrated the intense and growing interest in imusic information retrieval.","title":"SGER: Creating a Music Information Retrieval (MIR) Development and Testing Environment","awardID":"0327371","effectiveDate":"2003-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["559417"],"PO":["433760"]},"82119":{"abstract":"A common problem in digital government is the significant gap between research results and government IT practitioners, both policy and technical. On the academic side, it is difficult and risky, especially for a young researcher, to publish cross-disciplinary work, which is what most digital government work is. On the government side, it is difficult to find a journal or magazine which can effectively convey research findings. This grant will examine the existing field of journals and magazines which may be relative to digital government, conduct a survey of researchers and government staff as to their needs for a journal, and characterize such a journal in terms of format, audience, peer review, and sustainability (business model).","title":"A National Partnership for Information Strategy and Technology on Public Service","awardID":"0306813","effectiveDate":"2003-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["548263","433032"],"PO":["371077"]},"81987":{"abstract":"Special Abstract for 0306283 (Dobkin and Chazelle, Princeton U,<br\/><br\/><br\/><br\/>Title: New Directions in Geometric Algorithm Design<br\/><br\/><br\/><br\/>This project pursues a number of objectives<br\/><br\/>that have been at the heart of important<br\/><br\/>new developments in computational geometry.<br\/><br\/>Chief among them is the issue of<br\/><br\/>algorithm design for large datasets:<br\/><br\/>how to deal with high dimensionality,<br\/><br\/>uncertainty; how to optimize functions<br\/><br\/>approximately in sublinear time; how to simplify and<br\/><br\/>visualize complex data;<br\/><br\/>how to customize data structures to speed up search.<br\/><br\/>The effort is to involve a mix of theoretical<br\/><br\/>and experimental investigations, with targeted<br\/><br\/>applications to surface simplification,<br\/><br\/>3D shape matching, massive dataset visualization,<br\/><br\/>and protein structure prediction.<br\/><br\/>The theoretical issues involve<br\/><br\/>combinatorial geometry, algorithm design<br\/><br\/>and basic complexity theory.<br\/><br\/><br\/><br\/>This effort is aimed at deriving new<br\/><br\/>computational methods for solving<br\/><br\/>problems of a geometric or biological nature<br\/><br\/>that have resisted past investigations<br\/><br\/>because of one two reasons: either the input<br\/><br\/>data is too massive to be processed directly<br\/><br\/>and it can only be \"sampled\" cleverly or<br\/><br\/>the number of variables is itself so high<br\/><br\/>that standard methods suffer from an exponential blowup<br\/><br\/>in the time it takes to run them. New<br\/><br\/>dimension reduction techniques are needed<br\/><br\/>to resolve this bottleneck.<br\/><br\/>etric Algorithm Design<br\/><br\/><br\/><br\/><br\/><br\/>This project pursues a number of objectives<br\/><br\/>that have been at the heart of important<br\/><br\/>new developments in computational geometry.<br\/><br\/>Chief among them is the issue of<br\/><br\/>algorithm design for large datasets:<br\/><br\/>how to deal with high dimensionality,<br\/><br\/>uncertainty; how to optimize functions<br\/><br\/>approximately in sublinear time; how to simplify and<br\/><br\/>visualize complex data;<br\/><br\/>how to customize data structures to speed up search.<br\/><br\/>The effort is to involve a mix of theoretical<br\/><br\/>and experimental investigations, with targeted<br\/><br\/>applications to surface simplification,<br\/><br\/>3D shape matching, massive dataset visualization,<br\/><br\/>and protein structure prediction.<br\/><br\/>The theoretical issues involve<br\/><br\/>combinatorial geometry, algorithm design<br\/><br\/>and basic complexity theory.<br\/><br\/><br\/><br\/>This effort is aimed at deriving new<br\/><br\/>computational methods for solving<br\/><br\/>problems of a geometric or biological nature<br\/><br\/>that have resisted past investigations<br\/><br\/>because of one two reasons: either the input<br\/><br\/>data is too massive to be processed directly<br\/><br\/>and it can only be \"sampled\" cleverly or<br\/><br\/>the number of variables is itself so high<br\/><br\/>that standard methods suffer from an exponential blowup<br\/><br\/>in the time it takes to run them. New<br\/><br\/>dimension reduction techniques are needed<br\/><br\/>to resolve this bottleneck.<br\/><br\/><br\/><br\/><br\/><br\/>The proposal is a careful outline of research work that may greatly aid in geometric data","title":"New Directions in Geometric Algorithm Design","awardID":"0306283","effectiveDate":"2003-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["450650",213809],"PO":["321058"]},"81536":{"abstract":"INTELLECTUAL MERITS<br\/>The purpose of this proposal is to develop nano-scale resolution of sensing and actuation between silicon <br\/>CMOS devices and molecules in fluids. We will investigate the implementation of this interface by nonvolatile charges stored in lithography-pattern floating gates, self-assembled metal nanocrystals embedded in SiO2, or surface traps with scan-based direct charging. The nonvolatile charge will interact with the silicon devices in the Flash memory manner as in the commercial technology of the scan disk in digital camera and camcorders. The positive and negative nonvolatile charge will serve as attractive or repulsive receptors like remote cation and anionic ends to the molecules in fluids. We will investigate the force magnitude and resolution by different implementation strategies. We will design and conduct realistic test cases including single molecule trapping\/actuation of fluorescence labeled DNA fragments, and protein recognition based on surface charge distribution instead of global properties such as size and isoelectric point. We will also investigate the influence from microfluidic device integration and autonomous operations, though a complete system design is out of our scope. We will formulate predictive modeling and simulation tool suites for equilibrium molecular structures and their movement toward a surface charge sheet in an environment mediated by the ambient ion charges in fluids. From our preceding NER work (ECS-0210743), we have preliminary experimental evidence that the goals we propose in this NIRT are practically achievable.<br\/><br\/>MAJOR APPLICATIONS<br\/>In addition to the intellectual studies on the interface of silicon devices and molecules, successful implementation of this new interface concept can potentially revolutionize the biological measurements, biomedical microscopy, and pharmaceutical practices. By functionally mimicking the sensory, digestive and immune systems in biological systems with electronic receptors, new systems for molecule actuation, artificial ion channels without applying bias to fluids directly, protein recognition, and eventually biomedical treatments for cell-level diseases can be envisioned. The tight integration with present silicon technology enables affordable production in large volumes.<br\/><br\/>BROADER IMPACTS<br\/>Nanotechnology has caused major transformation in our society. Successful interface between silicon devices and biological molecules will not only be intellectually interesting and commercially valuable, but will also have many social and legal implications. The technology developers and the general public need more overall awareness on these impacts. In addition to our existing outreach channels to penetrate nanotechnology development to K-12 and undergraduate education for broader awareness and diversified perspectives, we have formulated a realistic plan to include law school expertise to study the legal and social implications. In the beginning, the technology developers need to be educated on reasons for government regulation and the nature of risk. Test cases will then be designed collaboratively for course discussions. These materials will be assessed from pragmatic evaluations, proliferated according to the level of understanding, and then promoted to various audiences including engineering, non-engineering and high school curriculum. We will also initiate a new outreach program to Wells College (a womens college 30 miles away from Cornell main campus) in the form of exchange seminars, short intern period for general awareness, and assessment of test cases from an independent group.","title":"NIRT: Molecular Sensing and Actuation by CMOS Nonvolatile Charges with Independently Addressed Nanoscale Resolution","awardID":"0304483","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["380182",212614,"519714","564654","459243",212618],"PO":["564900"]},"81899":{"abstract":"0305954<br\/>Kenneth Goldman<br\/>Washington University<br\/>An Interactive Learning Environment for Introductory Computer Science<br\/>$499,996<br\/>This is a unique, possibly risky, proposal based on outcomes of research into a new software system development paradigm. The scope of the project is to develop a system that supports a novel programming environment for introductory programming courses that treats software development as an application domain rather than a text-centric encoding activity. The project is in keeping with research outcomes in software development that address the next step after current Object-Oriented approaches. As an improvement to Integrated Development Environments (IDEs), the programming environment transferred into the undergraduate classroom by this project is based on a fresh approach to supporting the programming process and several related research innovations. The approach is to raise the level of abstraction by treating the programming process as an application domain. This elevates the unit of discourse for software construction by providing direct manipulation of semantic elements, so that programming abstractions become the primitives of expression. In turn, this enables a transition from loosely-coupled umbrella IDEs to tightly integrated development environments (TIDEs), in which awareness of program structure creates opportunities for ensuring program consistency and supporting truly live software development. The thrust of this project's research is to treat programming as an application domain, amenable to the same human-computer interface design principles that have been applied successfully to other types of applications. Central to these principles is direct manipulation of domain-specific entities. Research in visual languages has produced systems supporting direct manipulation of program entities, but the emphasis of that research has been on finding new ways to think about computation that are particularly well-suited for visual expression. In contrast, the goal of this project is to provide application-level support for already widely accepted programming practices. Rather than create new languages, this project aims to leverage years of evolution in programming language design by applying human-computer interface design principles to the problem of providing domain-specific support for programming in existing high-level languages. Computer science departments in colleges and universities are continually faced with difficulties in effectively communicating deep intellectual content in introductory courses, recruiting a diverse population into the field, and reaching out to students in other disciplines who could benefit from computer science background. The educational impact of this proposal will be to address these difficulties by introducing into the undergraduate classroom a new learning environment that makes software development more tangible.","title":"An Interactive Learning Environment for Introductory Computer Science","awardID":"0305954","effectiveDate":"2003-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["427427","343516"],"PO":["551712"]},"83604":{"abstract":"Proposal: CCR-0312760<br\/><br\/>TITLE: Algorithms for the Technology of Trust<br\/><br\/>PI: Michael T. Goodrich<br\/><br\/>The project is directed at a subject area of critical importance to society--methods for efficiently maintaining the security of computations and computational resources, including the networks that communicate vital data. In addition, the work involves an important educational mission to integrate cyber-security algorithms into the undergraduate computer science curriculum.<br\/><br\/>The research focuses on developing efficient algorithms for performing trusted computations in a networked environment. Themes to be investigated include:<br\/><br\/>* Authenticated data structures and algorithms: The project places special emphasis on methods for authenticating the results of data structures and algorithms, even when those computations are performed by an untrusted third party on behalf of a trusted source.<br\/><br\/>* Audited algorithms: The project will explore a new computational framework in which computations are performed by a community of untrusted users, but this computation is checked by an external auditor with limited computational resources.<br\/><br\/>* Democratic Trust Assurance: The project is also directed at infrastructures for a community of peers who want to establish trust within their group. Specific interest is in solutions that are practical and potentially applicable to grid computing, while allowing for multiple clients and servers.","title":"ITR: Algorithms for the Technology of Trust","awardID":"0312760","effectiveDate":"2003-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["521484"],"PO":["521752"]}}