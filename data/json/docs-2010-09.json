{"175890":{"abstract":"This high-risk, high-reward project is concerned with environmental-impact modeling for infrastructure-network decision-support. The intellectual merit of the research lies in the introduction of an entirely new modeling framework which broadly captures environmental impact in infrastructures by meshing computing and controls concepts, and in the development of a suite of analysis and design tools for this framework. The proposed modeling framework draws on the influence model, a structured representation of interacting Markov chains that can capture the intricate spatio-temporal patterns that are observed in environmental impact, and yet admits rapid computation of local statistics due to its moment-linearity characteristic. By building on the influence-modeling construct, the PIs expect to develop a hybrid model for environmental-impact evolution. A second key task is to develop a suite of tools that allow the use of the environmental-impact model in decision support, with a particular focus on inference and analysis tools.<br\/><br\/>The broader impact of the proposed research is twofold. First, the research has the potential to impact computation and communication technologies in numerous widely-used infrastructures. Second, we the research is envisioned to enact a paradigm shift in modeling for large-scale computation, toward models that incorporate control-theoretic constructs to permit analysis and design of network (and multi-network) dynamics. Education and research-dissemination activities are planned to foster both the societal and computer-science-related impacts of the work. Highlights include multi-disciplinary course-development efforts, and industry-interface and research-experience provisions for undergraduates.","title":"EAGER: Collaborative Research: Stochastic Environmental-Impact Modeling for Automated Decision-Making in Infrastructure Networks: A Multi-Disciplinary Approach","awardID":"1058124","effectiveDate":"2010-09-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[471407],"PO":["565303"]},"175780":{"abstract":"Building on the successes of ATE?s IT Across Careers (ITAC) Project and extensive experience developing national and regional voluntary industry skill standards, EDC and a technical committee of computer scientists and thought leaders in computational thinking (CT) from the University of Washington, Massachusetts Institute of Technology, Williams College, Santa Fe Institute, and Raytheon Corporation will develop and validate a common core of CT skill sets used by scientists, technicians\/technologists, engineers, and mathematicians in America?s STEM (Science, Technology, Engineering, Mathematics) workplaces. The project employs a skill standards development methodology used in European social partnerships to identify a ?learning occupation? and conduct an occupational analysis of that occupation?creating new language and a framework to describe work duties, tasks, skills, knowledge, and attributes of U.S. STEM professional and technical workers empowered with CT. The project will conduct a national online validation of the resulting CT duties, responsibilities, and associated skills, knowledge, and attributes. With expert STEM workers, the project team will develop written and visual examples of how STEM workers use CT skills in routine work to solve problems commonly found in STEM workplaces. Traditional and innovative dissemination strategies will be used to share findings with the national community of CT stakeholders to inform and advance ongoing efforts to define CT, and to integrate CT into K?20 education programs aimed at building the next generation of STEM innovators. <br\/><br\/>Intellectual Merit: The project builds on existing efforts to define CT. It addresses the urgent need to ground the many emerging definitions of Computational Thinking in validated skills, knowledge, and experiences of working scientists, technicians, and technologists who use CT on a daily basis. Engaging expert computational thinkers from laboratories and industry, modifying the DACUM (Developing A CUrriculuM) process to describe CT, and using the ?learning occupation? as a mechanism to surface and promote dialogue across disciplines and work sectors are each radically different from current approaches used by computer scientists to describe and clarify CT. The concept of a learning occupation is a proven way of defining new occupations for emerging industries and occupations that have undergone substantive changes in worker responsibilities. The occupational analysis DACUM methodology has been widely validated and used internationally to identify the skills needed by front-line workers. The proposed activities meet an important need within the CT community and build on prior NSF and National Skill Standards development work. The technical committee connecting the project to national computer science and CT networks are experts who are influential in their fields and highly regarded contributors to evolving definitions of CT. The PI for this project is a seasoned NSF PI who has led NSF projects and a large NSF center successfully serving the needs of NSF projects that develop pathways to STEM careers. <br\/><br\/>Broader Impacts: The occupational analysis methodology provides a new language and structure that can potentially transform dialogue among thought leaders shaping the emerging definitions of computational thinking. The technical committee will ensure that the work finds a prominent place in the national discussion on CT. Demystifying difficult CT concepts will contribute to the public understanding of CT as a foundational skill set for STEM workers and attract new students into STEM. The articulated skill sets and examples will provide learning guideposts for students seeking to become the STEM innovators of the future. Moreover, they will help educators design and develop relevant programs of study, career pathways, and curricula leading students to STEM careers. Examples of CT skills ?in action? in the workplace will be used by counselors and educators to help broaden participation in STEM learning and careers, and lead to the construction of learning experiences that engage underrepresented groups and grow their talent. The processes established within this project will advance understanding of what it takes to articulate new and emerging occupations in STEM and surface important new questions to pursue.","title":"EAGER: Computational Thinking in Action in America's STEM Workplaces","awardID":"1057672","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7492","name":"CCLI-Type 2 (Expansion)"}}],"PIcoPI":["558308"],"PO":["519302"]},"174350":{"abstract":"In ill-defined domains such as engineering design and ethics, mathematical discovery, and law, problems often have more than one 'right' answer. In such situations decision-makers propose rules or hypotheses about how to decide the problem in light of past cases and underlying principles and policies; through this process of interpretive argument decision-makers may then pose hypothetical examples in order to draw out and test the normative, logical, or empirical consequences of the hypothesis. <br\/><br\/>In integrating decision rules, case analogies, hypothetical examples, underlying principles, and policies, interpretive argument is a paradigm of robust reasoning. Although the problems are ill-defined, interpretive argument has an underlying logic, which this project is modeling computationally. By working in successively more complex argument microworlds, families of cases, rules, concepts, principles and policies drawn from realistic legal domains, the project is developing an ontology and implementing inference control mechanisms and argument schema with which a computer program will engage in interpretive argument. Empirical evaluation of the computational model is comparing arguments by the computer and by human arguers.<br\/><br\/>The work contributes to the fields of AI, argumentation theory, AI and Law, and case-based reasoning, and it aims in the longer term to contribute to intelligent tutoring systems that will prepare students for making effective, supportable and otherwise rational arguments, and to design artificial agents as proxies and advocates for humans engaged in disputes.","title":"EAGER: Modeling Interpretive Argument with Case Analogies and Rules in Ill-Defined Domains","awardID":"1049414","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["488662"],"PO":["565215"]},"174240":{"abstract":"Deformability and discriminability are often two \"conflicting\" factors in computer vision problems such as shape matching and object recognition. For example, it has been observed that strong deformation invariant descriptors often suffer from low discriminative powers for category recognition. This EAGER project explores a new framework for balancing deformability and discriminability for computer vision tasks. The framework uniformly embeds an object, which can be a 2D shape, a point set, an image, a 3D volume or a surface, in a high dimensional space named aspect space. The embedding parameter is then used to control the degree of deformation insensitivity. Both the theoretic and application sides of the proposed framework are investigated. Based on the framework, the project aims to develop three additional research goals: robust shape matching methods by selecting deformability adaptively, robust point set registration methods by dealing with articulation in the framework, and robust image matching by extracting features in the embedded aspect space. These goals are planned to be evaluated on real applications including silhouette-based foliage data retrieval, 3D marker matching in computer-based physical therapy, and image-based disease screening. <br\/>The project aims to bridge the two main problems, handling deformation and improving discriminability, which relate to many subfields inside and outside computer vision. The interdisciplinary applications are expected to generate significant contributions to various fields including biodiversity studies, biomedical study, etc. The research results, including code and data, are made public available through the project website.","title":"EAGER: A New Framework for Balancing Deformability and Discriminability in Computer Vision","awardID":"1049032","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["562889"],"PO":["564316"]},"175692":{"abstract":"This workshop brings together government research program managers, experienced researchers, and some new researchers in fields covered by the Trustworthy Computing program to create a set of publicly available materials an presentations that will help broaden the pool of researchers capable of proposing to the program. The program and its predecessors, the Trusted Computing and Cyber Trust programs, now fund more than 400 Principal Investigators. New researchers entering the field need to understand the research areas these programs cover, how they relate to other NSF programs, and how they relate to programs funded by other U.S. government research funding agencies.","title":"Workshop on Trustworthy Computing Program","awardID":"1057312","effectiveDate":"2010-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["547471","501279"],"PO":["565327"]},"172062":{"abstract":"The \"Republic of Letters\" - a term used between ca. 1500-1800 to describe scholarly communities and networks of knowledge - has been described as a lost continent, a country without borders. Enmeshed in trading, diplomatic, and missionary networks, it emerged in the early decades of the printing press, came to full fruition in the era which created learned societies and scholarly journals, and declined when the full-scale professionalization of scholarly life and the rise of the modern nation-state made this transnational scholarly utopia a dream of the past. Organized around individuals, institutions, and projects, the Republic of Letters was the primary means by which knowledge traveled in this earlier era. While its origins were British and European, the Republic of Letters traveled where Europeans traveled, colonized, and settled, including the colonial Americas.<br\/><br\/>The Republic of Letters expresses a wide range of correlations over time and space such that, on a large scale, it can be viewed as a loose affiliation of individuals based on principles, methods of communication, and philosophical ideals over a period spanning hundreds of years. At the other extreme, it is expressed in closely affiliated clusters of individuals sharing ideas either directly in correspondence, in salons, or indirectly through publications and via intermediaries. In every case, there are many conditions and constraints influencing network processes including language, location, social circles, political events, intrigue, religious affiliation, and gender. Much of this data has been captured and will allow us to map the physical and virtual topology of the network. Combining the implications of geographic data, historical events, and social data, this is an excellent case study for how the spread of ideas at the global scale relates to the dynamical processes that operate at the local scale.<br\/><br\/>Dr. Christopher Weaver and colleagues will create techniques to visualize and analyze multi-dimensional, multi-scale, and uncertain heterogeneous data extracted from historical text documents. Further, they will develop interactive designs that enable individual and collaborating scholars to dissect, revisit, share, explore, and analyze these past networks of knowledge. The new visualization methods will be combined with existing techniques to create accessible and functional tools for direct integration in and application to the ongoing study of the Republic of Letters by social science and humanities scholars.<br\/><br\/>This project will contribute to computer science, social sciences, and the humanities. The contributions to computer science include data visualization and interaction techniques in support of open-ended data exploration and analysis methodologies. The contributions to the social sciences and humanities will include elucidation of the Republic of Letters through an exploration of empirical data gleaned from correspondences, publications, and travel records, combined with the interpretive expertise of geographers, historians, and literary scholars.","title":"RAPID: Digging Into the Enlightenment: Mapping the Republic of Letters","awardID":"1036331","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1352","name":"GEOGRAPHY AND SPATIAL SCIENCES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[460937],"PO":["503982"]},"172183":{"abstract":"Since 2006, the annual workshop for Women in Machine Learning (WiML) has brought together female<br\/>researchers in industry and academia, postdoctoral fellows, and graduate students from the machine<br\/>learning community to exchange research ideas and build mentoring and networking relationships. The<br\/>one-day workshop has been especially beneficial for junior graduate students, giving them a supportive<br\/>environment in which to present their research (in many cases, for the first time) and enabling them to<br\/>meet peers and more senior researchers in the field of machine learning. The networking opportunities<br\/>provided by the workshop have also helped senior graduate students find jobs following graduation.<br\/>Intellectual Merit: This workshop will advance machine learning knowledge and foster collaboration<br\/>within the machine learning community. As invited speakers, established researchers at top universities<br\/>and research labs will teach workshop participants about cutting-edge ideas from diverse areas of<br\/>machine learning. Students will present their own research and receive valuable feedback from both<br\/>senior researchers and their peers. By enabling women at all stages of their careers in machine learning to<br\/>exchange research ideas and form new relationships, we expect that new connections and research<br\/>collaborations will be established, thereby advancing the state-of-the-art of the field.<br\/>Broader Impact: This workshop will provide a forum for female graduate students, postdoctoral fellows,<br\/>junior and senior faculty, and industry and government research scientists to exchange research ideas and<br\/>establish networking and mentoring relationships. Undergraduates, particularly those who are interested<br\/>in pursuing graduate school or industry positions in machine learning, are also welcome to attend.<br\/>Bringing together women from different stages of their careers gives established researchers the<br\/>opportunity to act as mentors, and enables junior women to find female role models working in the field<br\/>of machine learning. The workshop will also benefit the wider machine learning community: Firstly, the<br\/>WiML website, which lists all previous workshop presenters, serves as a useful resource for organizations<br\/>looking for female invited speakers. Secondly, co-locating with a major machine learning conference<br\/>enhances the visibility of female researchers among the wider machine learning community. Thirdly,<br\/>travel funding provided to workshop participants also facilitates their travel to the co-located conference,<br\/>which for some participants would otherwise not be possible. Finally, all workshop materials (slides,<br\/>abstracts, etc.) will be made available on the workshop website in order to ensure broad dissemination.","title":"Collaborative Research: Workshop for Women in Machine Learning","awardID":"1037002","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550753"],"PO":["562760"]},"174372":{"abstract":"This award will help to help support student attendance at the IEEE Annual Symposium on the Foundations of Computer Science (FOCS) in Las Vegas, Nevada, October 23 through October 26, 2010, as well as attendance by qualified postdoctoral fellows who do not have other sources of travel funding. FOCS and its sister conference, the ACM STOC meeting, are the premier broad-based conferences on the Theory of Computing. In recent years the attendance at FOCS has been roughly 250 plus or minus 25. 40% or more of the attendees have been students, for whom the conference serves as a valuable educational experience, both in terms of the technical content of the talks and the opportunities for networking that it provides. This award will provide partial support to twenty or more student attendees, covering shared hotel rooms and travel. (Student registration will be supported by other means.)","title":"Travel Support for the Symposium on Foundations of Computer Science (FOCS 2010)","awardID":"1049485","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["517581"],"PO":["565157"]},"174493":{"abstract":"EAGER: Graph-based Theoretical Models and Mining Algorithms for Bioinformatics Data Analysis <br\/><br\/> Project Summary<br\/><br\/>Graphs show up in a surprisingly diverse set of disciplines, ranging from computer networks to sociology, biology, ecology and many more. In recent years, huge amounts of data are generated and ultimately represented in graph format in the bioinformatics applications. Some are stored as a single large graph such as a protein-protein interaction network, while others are stored as a set of graph objects in a graph database such as chemical compounds in drug design and protein 2D\/3D structures in bioinformatics. The main goal of this proposal is to develop novel graph-based theoretical models and algorithms to analyze bioinformatics data sets represented as either a single large graph or a graph database, focusing on the (1) development of efficient structure pattern discovery methods in graph databases based on graph decomposition and compression, and (2) development of mining algorithms for large scale-free network graphs, focusing on developing mixture model and statistical inference of hierarchical structure and missing link prediction in complex network. These algorithms will be validated by analyzing data sets arising in bioinformatics research. The proposed research will advance the understanding of bioinformatics and data mining algorithm research and development in graph data sets. It will also expand the application scope and push new frontiers for graph theory, bioinformatics and data mining. This research work is considered ?high risk high payoff? because it needs to develop novel theoretical graph-model and algorithms, radically different from the dominant random graph theory models and algorithms<br\/><br\/>Intellectual merit: The techniques and methods to be developed in this proposal build on state-of-the-art methods in bioinformatics, graph theory, data mining and database management. The research will result in improved understanding of the issues involved in designing efficient graph-based models, algorithms and methods in scientific data sets. The proposed project will design and develop a wide-range of novel data analysis algorithms and methods including structure pattern matching and discovery, and mining large scale-free network graphs. <br\/><br\/>Broader impacts: The proposal will address a broad range of problems in the data analysis of scientific application domains such as bioinformatics, drug design, molecular biology, etc. Both the graph-based models and algorithms developed from this research are central to the computer science, and are generalizable and will be made publicly available for use in other domains, including personal or social contacts in sociology and epidemiology, author-co-citations in information science, the Internet and the World Wide Web in computer science and information technology. Research outcomes from this proposal can lead to more efficient and effective modeling and simulation mechanism of the biological network and advanced mathematical capabilities that are applicable through other science and engineering domain. The PI and Co-PI have a strong commitment to the integration of research and education, promotion of diversity, strong industrial partnership and broad dissemination of research results. The proposed research area lends itself to raising the scientific curiosity of students at many levels. Students will obtain significant exposure to the latest research. <br\/><br\/>Both the research and education plans of the proposal are highly interdisciplinary, engaging students and faculty from various research areas and drawing from work on numerous fields of study. In particular, the plans serve to highlight the benefits of synthesizing bioinformatics, graph theory and data mining in creating the next generation of graph-based models, algorithms and tools for bioinformatics research. Armed with these models, algorithms and tools, bioinformatics researchers will discover more meaningful and pertinent knowledge\/patterns and enable them to have a better understanding and interpretation of the data sets collected in their investigation. Students will gain an appreciation for the ability to understand, analyze and mine the growing range of bioinformatics data sets.","title":"EAGER: Graph-Based Theoretical Models and Mining Algorithms for Bioinformatics Data Analysis","awardID":"1049864","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["554592","381214"],"PO":["565223"]},"174394":{"abstract":"Abstract<br\/><br\/>This proposed EAGER project focuses on a new, robust and efficient technique to transcribe arbitrary sounds. It also extends in a novel and transformative fashion earlier work that developed a music search engine based on identifying aesthetic similarities. Automated transcription of musical sounds is still an open research area and one of exceptional importance. While some limited transcription techniques are available, they lack critical abilities, such as inability to transcribe polyphonic compositions or difficulties in distinguishing sounds produced by different sources. In addition, the frequency ranges are limited, thereby excluding a vast number of musical works. The approach proposed in this project involves an innovative audio-to-MIDI transcription algorithm, which handles polyphonic compositions, captures harmonic, vocal and percussive instrumentation, is very efficient and works with sounds beyond human produced musical compositions, such as bird songs and sub\/ultrasonic animal vocalizations.","title":"EAGER: An Efficient Algorithm for Automated Transcription of Music, Vocalizations, and Arbitrary Sound Recordings","awardID":"1049554","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["552414"],"PO":["564456"]},"176220":{"abstract":"In many areas of human professional and social life, people tend to form more or less clearly defined communities. The main problem of these hidden or latent communities is that they are really hard to discover since the borders of these communities cut through various professional and organizational borders. The modern social Web, however, provides a huge volume of alternative data sources for discovering latent communities. The goal of this proposal is to explore a range of promising approaches that can be used to elicit latent communities from various kinds of data about individuals available in the modern social Web and deliver the results for human thinking and interactive exploration through interactive visualizations. The visualization provided will allow humans explore and manipulate the results delivered by the new algorithms. This will deliver results that are produced by the joint power of human and artificial intelligence. In the course of the project, the team will build several data sets combining data of several social Web systems and use these data sets to develop, evaluate, and compare several elicitation and visualization approaches. The work will advance the research on latent communities, community and user modeling, and interactive social visualization. At the same time, the work will constitute one of the first attempts to use a variety of social Web data and a variety of approaches for community modeling. To increase the broader impact of the project, the researcher will apply the latent community knowledge to several practical tasks, such as identifying proper academic mentors and forming coherent collaboration groups. They will also engage a number of students in the research advancing their training into this emerging field.","title":"EAGER: Modeling and Visualization of Latent Communities","awardID":"1059577","effectiveDate":"2010-09-15","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J394","name":"National Security Agency"}}],"PIcoPI":["496622"],"PO":["565136"]},"175010":{"abstract":"This project explores a multimodal corpus for vision-based meeting analysis. The research team is working on: (1) extracting the data from tapes and organizing them into multimedia databases; (2) developing a database visualization and analysis tool to support model development; and (3) developing an agent-based algorithm to extract hand and head tracking information so that higher level models may be built onto the data. <br\/><br\/>The project provides datasets that are organized into a usable corpus with many unique properties, such as the ground truth at the psycholinguistic\/psycho-social level of the social roles status, purpose of each meeting, and at the video level in the form of motion tracking data collected co-temporally with the video, for developing and testing new algorithms. The developed tools improve the access to the multimedia database of multi-view group human behavior. The agent-based approach provides a novel way in video annotation. The developed tools and algorithms from this project can be applied to many other applications. For example, the tools may be applied to analyze classroom behavior and in learning scenarios. The project provides research opportunities for undergraduate and graduate students including women and individuals from underrepresented populations. The project outreaches to the user communities through publications, presentations, web presence, and broader collaborative interactions.","title":"EAGER: Multimodal Corpus for Vision-Based Meeting Analysis","awardID":"1053039","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["486496"],"PO":["564316"]},"174284":{"abstract":"This project uses the capabilities of wearable sensors for two inquiries into creativity. The first inquiry investigates the potential for analysis and visualization tools to help users generate novel mental models from wearable sensor data and explore the implications of such models on their lifestyle and wellbeing. The ability to monitor internal state and relate it to behavior and environment can be transformational, because it allows users to develop insights and provides them with hard data with which to monitor their own progress. By focusing on minimally-invasive and inexpensive sensors the developments will have broad appeal for the general public. Prior research in wearable sensors has mainly focused on predicting psychological state (e.g., affect) from physiological signals, and characterizing the users? environment (e.g., from accelerometers, audiovisual sensors). However, relatively little research has been devoted to exploring the relationship between the internal (i.e. physiological) state of users and their environments; unfortunately, one cannot be understood without the other. Study of this relationship is an area where we believe visual workspaces can have a significant impact. <br\/><br\/>The second inquiry seeks to explore how wearable sensors may support research in creativity outside of controlled laboratory settings. Experimental methods for creative cognition in laboratory settings have been very successful in identifying a number of cognitive processes and general principles of creativity that apply across a number of domains, from engineering design to the visual arts. However, these studies do not inform us about how creative processes take place in the real world, when users must deal with the demands of their lives and distractions in their environments. Wearable sensors provide an opportunity for the researcher (and the user) to develop an understanding of how physiological variables and real-world environments affect the creative processes. Studies of creative cognition in natural settings, correlating cognitive and behavioral metrics with data from wearable sensors, can validate and greatly extend our scientific understanding of creative thinking in the real world. Whereas retrospective reports of one?s creative ideas are limited by participants? memories and by their subjective introspection, probing people in real-world settings, as proposed in our experiments, requires neither introspection nor retrospection. Thus, validated metrics of creative ideation can be applied in natural contexts without the reactivity that results from laboratory and field experiments.","title":"EAGER: Creativity in the Wild: Insight and Discovery with Wearable Sensors","awardID":"1049217","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["557686",467562,467563],"PO":["565227"]},"176231":{"abstract":"Location-specific data is the enabling component of a new class of applications that can access near real-time and recent historical data about a specific location, driving applications such as vehicle route planning, real-time fuel efficiency and location-based data sharing. The focus on location-centric applications points towards caching of data in the geographic area where it was generated. Since the cache is location-sensitive and vehicles are constantly on the move, traditional caching and content Web-centric prefetching architectures not apply. Additionally, the large volumes of data these devices will generate cannot be supported by existing centralized approaches. Instead, we have designed Locus, a decentralized data overlay that runs on top of the mobile devices themselves.<br\/><br\/>To keep data from a specific location near that location, Locus introduces the novel concept of \"bubbles of knowledge\", where the sensed data is actually stored in the network by the nodes in the surrounding geographic area, essentially providing localized memory in the network about the sensed data. By using such location information, Locus can achieve more efficient data storage and improve data look-up rates. As more users join the network, the benefits of Locus will be amplified due to the increasing density of the network, increasing both the performance and value of the overlay as the system grows. By maintaining content locally in the vehicular network, Locus reduces the reliance on and cost of infrastructure access, benefiting individuals with mobile data plans that limit total downloads or regions where the cellular data networks are overloaded.","title":"Locus: A Vehicular-based Content Management Network for Location-centric Applications","awardID":"1059628","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["561785"],"PO":["557315"]},"176594":{"abstract":"Proposal #: 10-61621<br\/>PI(s): Halem, Milton; Brown, Sheldon; Conte, Thomas M; Yesha, Yelena<br\/>Institution: University of Maryland Baltimore County<br\/>Title: RAPID: Collaborative Research: An Interactive \"Human Sensor Situation Network\" for Improved Model Predictions of the Dispersion of the Deepwater Horizon Gulf Oil Spill<br\/>Project Proposed:<br\/>This project, proposing research activities related to Gnome model predictions of the Gulf oil spill (within the CHMPR I\/UCRC, to be located at UMBC, UCSD, and GaTech), aims to develop an instrument that acquires servers to collect, extract, locate, and process Gulf oil spill data from the existing social media sources such as Flickr, You Tube, Twitter and integrates them into a cloud. The data is collected from mobile devices and satellite sensors. As a result, the project provides instantaneous spatial distributions and temporal frequencies of oil slicks, tar balls, distressed and dead animals, along the complete coastline of Gulf Border States. The instrument is used to perform a 2-D VAR data assimilation using the Gnome oil spill forecast model as a first guess and the social media data as boundary conditions. The project will present the forecast oil slick dispersion products on the very large LCD tiled wall at UCSD for broadcast to thousands of viewers. System delivery is expected within 15 days. Improvement upon the NOAA operational Gnome model predictions of the Gulf is also expected. Moreover, the \"human sensor web\" data is likely to lead to more accurate operational oil dispersion forecasts for dissemination to decision makers through the 2-D VAR data assimilation;<br\/>Broader Impacts: <br\/>The work prototypes what in the future should become part of the responses to future event situations, either natural or anthropogenic. The \"human sensor web\" data is likely to lead to more accurate operational oil dispersion forecasts for dissemination to decision makers through the 2-D VAR data assimilation; hence the social aspects are strongly evident. This project involves students, especially minorities (at UMBC). Similar outreach activities are planned at Georgia Tech. Furthermore, UCSD will organize an internship program at a middle and high school.","title":"RAPID: An Interactive \"Human Sensor Web\" for Improved Model Predictions of the Dispersion of the Deepwater Horizon Gulf Oil Spill","awardID":"1061621","effectiveDate":"2010-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["558176","517778","537136","537138"],"PO":["557609"]},"168740":{"abstract":"The right to privacy has long been regarded as one of the basic universal human rights. The combination of ubiquitous sensors, wireless connectivity, and powerful recognition algorithms makes it easier than ever to monitor every aspect of our daily lives. From the use of sophisticated video surveillance systems to the theft of biometric signals, people are increasingly wary about the privacy of their multimedia data. To mitigate public concern over privacy violation, it is imperative to make privacy protection a priority in developing the next-generation multimedia processing algorithms. Due to the high dimensionality, high data-rates and stringent real-time requirements of multimedia systems, developing provably-secure privacy protection schemes for multimedia often leads to a blowup in complexity and remains impractical for most applications.<br\/><br\/>This research breaks this \"efficiency barrier\" of the classical cryptographical approach by investigating a new computational framework to combine distributed multimedia processing and homomorphic encryption. Building on recent results of the PI, this work develops efficient encrypted-domain processing through optimal computational procedures, parallel computation in cipher-text, small-field manipulation and encrypted data compression. In addition, by exploiting the interplay between privacy and the perceptual nature of multimedia, this work develops a provably-secure tradeoff scheme between privacy and complexity to significantly reduce the complexity and bandwidth requirements of encrypted-domain processing. The PI demonstrates the usability of this new framework through novel applications in biometric matching, object detection, speech analysis and computational photography. <br\/>This work also incorporates outreach programs for high school students in rural areas, summer undergraduate research experiences, interdisciplinary postgraduate education and community outreach via television documentaries on research discovery.","title":"CIF: Small: Privacy Protection of Multimedia Processing","awardID":"1018241","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["525604"],"PO":["564898"]},"168861":{"abstract":"Adoption of each new generation of nano-scale technology is accompanied by lower yields, stagnant performance or increasing chip-to-chip performance variability, and decreasing robustness to environmental stress. The objective of this research is to identify new avenues for design, analysis, and testing to help compensate for these trends. This research takes a global view of the role of a module in the overall system architecture. This research will focus on two specific issues, namely (1) the impact of a fault in a module on the overall system operation and performance, and (2) the ability to reconfigure one module to compensate for a fault in another module by preventing it from affecting the correct operation of any system or user task. Additional case studies will be conducted to further demonstrate that both these aspects of a global view significantly improve system yield and performance. A systematic approach will be developed to exploit such a global view to dramatically improve yield, performance, and robustness. A completely new framework ? models, information, analysis, and algorithms ? for assembling systems using faulty (and fault-free) components ? will also be developed. <br\/><br\/><br\/>The utilitarian gains to society of this project are likely to be substantial. First, without changing any existing design, the proposed analysis and test approaches will provide significant improvements in yield, performance, and robustness to soft-errors. Second, the proposed analysis, design, test, and global compensation techniques will also help improve yields. Since the types of systems where this research is directly applicable include high-performance processors, the benefits provided will be amplified by the high price such processors fetch and the high volumes in which they are manufactured. Furthermore, since this research is orthogonal to much of the on-going research for improving yield and performance, improvements it provides can be combined with those provided by other approaches. Finally, this project will provide unique educational and training opportunities, for USC students as well as working professionals in the field.","title":"SHF: Small: A Digital System Paradigm for Yield and Robustness Enhancement via Global Analysis and Compensation","awardID":"1018869","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["535238",451942],"PO":["562984"]},"164274":{"abstract":"With support from this International Research Experience for Students (IRES) grant, engineering students from California Polytechnic State University will travel to Malta and Italy to collaborate with Maltese archaeologists to investigate previously unexplored underwater archaeological sites, including the mapping of coastal shipwrecks and ancient cisterns located beneath fortresses, private homes, and churches. Using sonar-equipped Remotely Operated Vehicles (ROV), students will develop (1) Simultaneous Localization and Mapping (SLAM) algorithms to construct 3D maps, and (2) new 3D visualization techniques for underwater robotics applications. In parallel with the research activities, students will participate in a Global Engineering course that explores the historical, archaeological and cultural aspects of research, education and collaboration through multiple national contexts.<br\/><br\/>The research activities bring together an international team of archaeologists, robotics and visualization experts and has a range of broader impacts. For example, by systematically surveying cisterns, investigators are better able to understand the development of Malta's ancient water storage systems and subsequently inform current water management strategy and policy. The robotics and visualization technology developed will also be relevant to applications in oceanography, biology, homeland security and defense. Throughout the project, student investigators will communicate their results to multiple audiences, including bilingual English and Spanish students at Pacheco Elementary School in San Luis Obispo, CA.","title":"International: Underwater Archeology via Robotic Systems","awardID":"0966608","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7727","name":"IRES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["536000","536000","558834","440030",440030],"PO":["558962"]},"167563":{"abstract":"Despite revolutionary advances in how images are recorded, manipulated, and reproduced, our ability to re-create the visual experience remains remarkably limited. Few realistic computer models exist for the characteristic appearance of natural materials such as marble, wood, coral, or skin, or man-made ones such as color-shifting automotive paints. Digitizing and creating realistic images of these substances involves reproducing their interaction with light: the way light is reflected from surfaces, or scattered and absorbed within the materials. Full reproducibility also involves \"printing\" a material as a real, physical object that modulates the light around us. However, it is currently impossible to output complex appearance the way we print color on a paper with fixed gloss, or create shapes using a 3D printer. This project encompasses a comprehensive, collaborative research agenda in computer graphics and related areas, to develop an end-to-end framework for acquiring, representing, and fabricating complex appearance, as well as to understand how it is perceived by the human visual system.<br\/><br\/>The enabling technical idea of the project is to treat materials as thin three-dimensional volumes populated with general scattering sites. This is a radical departure from the hitherto standard approach in computer graphics, which has studied materials purely as surfaces. The volumetric representation subsumes and generalizes the diverse set of conventional representations that currently exist in graphics, including surface-based notions such as bidirectional reflectance (BRDF), spatially varying BRDF, and subsurface scattering distributions (BSSRDF). Moreover, it enables fundamentally improved approaches to efficient yet general acquisition, fast and realistic rendering, and fabrication of objects exhibiting phenomena beyond simple surface reflectance and spatially homogeneous subsurface scattering.","title":"HCC: Large: Collaborative Research: Beyond Flat Images: Acquiring, Processing and Fabricating Visually Rich Material Appearance","awardID":"1012454","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["515747"],"PO":["565227"]},"174097":{"abstract":"Abstract<br\/><br\/>This EAGER aims to provide practical evidence of feasibility for a larger project called instance-optimal sampling. The instance-optimal sampling is a foundational framework for optimal representation of extreme-scale (scattered, unstructured, and structured) datasets. Using the dense polytope packing algorithms, the instance-optimal sampling framework develops strategies for sampling a given dataset at the optimally minimal sampling rate. The instance-optimal representation is derived based on the multidimensional notion of Nyquist frequencies; therefore, this approach is best complemented with the compressive sampling (CS) methods that exploit the sparsity of a dataset to reduce the sampling rate significantly below the Nyquist rate with no loss of information.<br\/><br\/>The main motivation in this research is that the synergy of compressive sampling and instance-optimal sampling would potentially allow the reduction of an extreme-scale dataset to sizes that are logarithmically proportional to number of samples in that dataset and linearly proportional to its sparsity. The research addresses the computational efficiency issue of sparse reconstruction for volumetric and time-varying datasets, which can lay the basis for applying CS to computer graphics problems. The main challenge is the computational cost of the reconstruction algorithm for 3-D or time-varying data. This research examines the feasibility of adopting a tensor-product approach to compressive sampling.","title":"EAGER: Exploring Compressive Sampling for Extreme-Scale Data Visualization","awardID":"1048508","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[466995],"PO":["532791"]},"168421":{"abstract":"Quantum computers could solve a number of problems substantially faster than their conventional counterparts. However, all known quantum algorithms exhibiting speedups use one of a small number of techniques that are responsible for their success. <br\/><br\/>This project pursues novel quantum methods for problem solving, particularly for optimization and simulation of quantum systems. The methods for optimization will include linear transformations in signal analysis and filter design that generalize the Fourier transform, which is key in quantum computing. Special interest will be given to the fractional Fourier transform and wavelet transforms, and to their applications in quantum black-box algorithms that compute specific properties of a function. Efficient quantum circuits that implement these transformations will be developed and their impact in quantum-algorithmic design will be analyzed. <br\/><br\/>The methods for the simulation of quantum systems will use adiabatic state transformation, which is a key tool for accessing energy states in physics via slow evolution. Adiabatic quantum algorithms to compute finite-temperature properties will be designed, and their computational cost will be compared to that of conventional Monte Carlo methods. Complexity lower bounds will also be obtained. In addition, the impact of the devised quantum methods in other areas of quantum information, especially in quantum metrology and parameter estimation, will be explored.","title":"AF: Small: Alternative Models of Quantum Computing for Optimization and Simulation of Quantum Systems","awardID":"1016689","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7928","name":"QUANTUM COMPUTING"}}],"PIcoPI":[450883],"PO":["565157"]},"168674":{"abstract":"Modern search engines, especially those designed for the World Wide Web, commonly analyze and combine hundreds of features extracted from the submitted query and underlying documents (e.g., web pages) in order to assess the relative relevance of a document to a given query and thus rank the underlying collection. The sheer size of this problem has led to the development of learning-to-rank algorithms that can automate the construction of such ranking functions: Given a training set of (feature vector, relevance) pairs, a machine learning procedure learns how to combine the query and document features in such a way so as to effectively assess the relevance of any document to any query and thus rank a collection in response to a user input. Much thought and research has been placed on feature extraction and the development of sophisticated learning-to-rank algorithms. However, relatively little research has been conducted on the choice of documents and queries for learning-to-rank data sets nor on the effect of these choices on the ability of a learning-to-rank algorithm to \"learn\", effectively and efficiently.<br\/><br\/>The proposed work investigates the effect of query, document, and feature selection on the ability of learning-to-rank algorithms to efficiently and effectively learn ranking functions. In preliminary results on document selection, a pilot study has already determined that training sets whose sizes are as small as 2 to 5% of those typically used are just as effective for learning-to-rank purposes. Thus, one can train more efficiently over a much smaller (though effectively equivalent) data set, or, at an equal cost, one can train over a far \"larger\" and more representative data set. In addition to formally characterizing this phenomenon for document selection, the proposed work investigate this phenomenon for query and feature selection as well, with the end goals of (1) understanding the effect of document, query, and feature selection on learning-to-rank algorithms and (2) developing collection construction methodologies that are efficient and effective for learning-to-rank purposes.<br\/><br\/>In addition to characterizing and developing collection construction methodologies, the project plan includes development and release of new, efficient, and effective learning-to-rank data sets for use by academia and industry. In fostering this effort, the project team has close ties with the National Institute of Standards and Technology (NIST) and Microsoft Research, two of the premier organizations that develop and release Information Retrieval data sets. All research results and data sets developed as part of this project will be made available at the project website (http:\/\/www.ccs.neu.edu\/home\/jaa\/IIS-1017903\/). The project provides an educational and training experience for students.","title":"III: Small: Collection Construction Methodologies for Learning-to-Rank","awardID":"1017903","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["535376"],"PO":["563751"]},"168795":{"abstract":"Quantum computing offers more efficient ways to solve certain computational tasks by taking advantage of quantum mechanical principles in its computational operations. However, successful quantum information processing requires mechanisms that make the basic operations reliable. This project will extend the theory of subsystem codes, a class of quantum error-correcting codes that have rich structure and the potential to realize fault-tolerant operations more efficiently. The goal of this project is to generalize the theory of subsystem codes from finite fields to more general arithmetic structures. The objective is use this theory to derive better means to protect quantum information and obtain a wider class of efficient fault-tolerant quantum operations.<br\/><br\/>An outreach component directed towards K-12 students tries to wet the appetite for theoretical computer science.","title":"AF: Small: Fault-Tolerance with Subsystem Codes","awardID":"1018500","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7928","name":"QUANTUM COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7948","name":"QUANTUM COMMUNICATION"}}],"PIcoPI":[451778],"PO":["565157"]},"168685":{"abstract":"The overall goal of this project is the development of the computational theory and algorithms for equilibria and fixed points. Many models from a wide variety of areas involve the computation of an equilibrium or fixed point of some kind. Examples include the computation of Nash equilibria of games; price equilibria in markets; computation of optimal strategies and values of competitive, dynamic games (e.g., stochastic games); analysis of basic stochastic models for evolution like branching processes, and for language like stochastic context-free grammars; and models that incorporate the fundamental primitives of probability and recursion like recursive Markov chains. These models have been studied for a long time by different communities, leading to the development of rich theories. However, basic algorithmic questions have remained open. Recent work has discovered common threads that run through several of these problems, and has identified common algorithmic principles that underlie some of these problems, formalized through appropriate complexity classes and completeness results.<br\/><br\/>The project will develop the computational theory of fixed points and equilibria along several directions. On the one hand the project will advance the general theory by unifying problems and identifying paradigms that are not adequately captured by the current classes, and by investigating the relationships between the different classes and paradigms. On the other hand, the project will investigate particular models and problems (e.g., computation of market equilibria, dynamic market adjustment schemes, stochastic games, and probabilistic recursive models) seeking to develop efficient solutions or to identify the intrinsic obstacles that prevent such solutions. The intellectual merit and goal of this project is to discover new unifying principles and methods that apply to central problems from different fields. It will leverage the computational way of thinking to establish connections and advance greatly our knowledge on a number of important challenging problems.<br\/><br\/>The project is expected to have broader impact on a variety of fields. The concepts and models under investigation are fundamental in various disciplines (including economics, game theory, biology, and various areas of computer science), and they have been studied and are used extensively. Identifying the common computational principles and connections between the different problems facilitates the cross-fertilization of ideas and methods among the different areas. Providing efficient algorithms for their solution, whenever possible, will be greatly beneficial to the relevant areas. The project will include the training of a graduate student, and the preparation of expository survey articles that synthesize the knowledge in the field and which will be useful for teaching and training. The results will be broadly disseminated with presentations at conferences and universities, and with scholarly publications.","title":"AF: Small: Research on Equilibria, Fixed Points, and Approximation","awardID":"1017955","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["550946"],"PO":["565251"]},"167475":{"abstract":"As one of the most promising emerging concepts in Information Technology, outsourced computation (also known as cloud computing) is transforming our perception of how IT is consumed and managed, yielding improved cost efficiencies and delivering flexible, on-demand scalability. Cloud computing reduces IT resources and services to commodities acquired and paid-for on-demand through a fast-growing set of infrastructure, platform, and service providers.<br\/><br\/>Despite the relatively fast growth and increased adoption of clouds, our understanding of aspects related to their security, privacy, and economic value proposition -- and hence our ability to trust them -- is lacking. This project addresses this challenge by (a) extending cloud service-level agreements to govern aspects such as integrity of outsourced services, information leakage control, and fair market pricing; (b) developing mechanisms that allow providers to guarantee and users to verify that such trust-enhancing service-level agreements are being followed; and (c) exposing trustworthiness guarantees and tradeoffs to cloud customers and system integrators in ways that are both practical and usable.<br\/><br\/>The research work pursued in this project is timely as it addresses the issues of cloud trustworthiness early enough to avoid having the conflicts among its various stakeholders develop unchecked -- as was the case with the Internet decades ago. Doing so has the potential of improving the utility and hardness of our cyber-infrastructure, with significant benefit to our economy and society. <br\/><br\/>The project will ultimately lead to a better marketplace for computing resources, in which users are assured that the services they acquire satisfy their performance, security, and privacy expectations.","title":"TC: Large: Collaborative Research: Towards Trustworthy Interactions in the Cloud","awardID":"1012060","effectiveDate":"2010-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["521367",448713,"550830"],"PO":["562974"]},"168575":{"abstract":"Three-dimensional stacked integrated circuits (3D SICs) promise to overcome barriers in interconnect scaling, thereby offering an opportunity to get higher performance using CMOS technology. This collaborative project between Duke University and Pennsylvania State University is focused on test and design-for-testability (DFT) solutions for 3D SICs. Topics being investigated include: (i) fault modeling and test generation, where the goal is to develop new fault models and test generation methods that can effectively target defects unique to 3D SICs; (ii) DFT infrastructure, optimization techniques for test access, and test scheduling methods for pre-bond test and post-bond test; (iii) Test economics and a cost-analysis framework, where test cost is being incorporated into cost models for 3D IC design and fabrication. <br\/><br\/>This project will facilitate further advances in 3D integration and wider adoption of this emerging technology by the semiconductor industry. Innovations in test methods, DFT, and cost modeling will therefore have a transformative impact on the way in which semiconductor chips are designed and fabricated. Undergraduate and graduate students involved in this research will be trained for the next-generation semiconductor industry workforce. Tools and techniques developed in this research will be used in teaching existing courses and developing new courses. A virtual classroom through web delivery will facilitate collaborative lectures originating from Duke and Penn State. The PIs will make tools available through the web for use by other educators, researchers, and industry practitioners. At Duke, the PI will mentor undergraduate students in collaboration with the Associate Dean for Education and Outreach Programs in the Pratt School of Engineering, and generate excitement among high-school students at the North Carolina School of Science and Mathematics.","title":"SHF: Small: Collaborative Research: Testing and Design-for-Testability Solutions for 3D Stacked Integrated Circuits","awardID":"1017391","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["506171"],"PO":["562984"]},"177056":{"abstract":"Most websites use javascript to provide personalized content to the users. At the same time, more and more attackers are using the web to deliver their attacks, especially with malicious javascript. Malicious javascript detection needs to be fast enough so that it does not interfere with users' normal activities (non-invasive), and yet effective enough to protect them from the majority of attacks. Rule-based or signature-based detection mechanisms often fail to detect obfuscated and malicious javascript. Behavior-based detection mechanisms are more robust against obfuscation, and have been effective in identifying variants of known attacks. However, monitoring behavior during execution usually is rather invasive, as it requires too much time and resources to be used in web browsers while users are interacting with websites. <br\/><br\/>This project investigates non-invasive detection of malicious javascript using classifiers (data mining techniques) trained on malicious scripts, including obfuscated scripts. Preliminary results show that it is possible to detect the vast majority of malicious scripts without full-blown de-obfuscation, while labeling very few benign scripts as malicious. As the detection mechanism correctly identifies most benign scripts, resource-intensive detection mechanisms can use this method to filter most benign scripts and focus on the remainder only. <br\/><br\/>Key elements of the envisioned solutions are: (a) automatic collection of malicious javascript; (b) partial de-obfuscator that will extract features for classifiers; (c) classifiers that assess the maliciousness of scripts; (d) redirection graphs that chronicle the connections between websites hosting known malicious scripts; (e) feedback mechanism to assist javascript collection and classifier re-training.","title":"CSR: Small: Non-Invasive Detection of Malicious Javascript at Web Browsers","awardID":"1063745","effectiveDate":"2010-09-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[474671,474672],"PO":["565255"]},"168355":{"abstract":"Intellectual merit<br\/>One of the major goals of the emerging field of synthetic biology is to design synthetic genetic 'circuits' in living cells to program artificial functions. Such programmed cells may serve as efficient cell factories for valuable drugs, chemicals, and biofuels, or intelligent biosensors or therapeutic vehicles that can be implanted in patients. Today, genetic programmers assemble synthetic genetic circuits in a manner similar to how engineers design and build electronic circuits, by connecting a number of 'parts' into a complex ?circuit? synthesized in the form that the cells can interpret (i.e. DNA). However, just as there are many different circuits that can function as a radio, there are many overall circuit designs to achieve a certain cellular function. The main goal of the proposed research is to ask: what is the best strategy to arrive at better (if not the best) circuit designs in the biological context? This is not a trivial question because genetic circuits must function in the complex biological environment. Cells grow, adapt, die, and even mutate while the synthetic circuits run inside them. Ideally, engineered genetic circuits should function robustly in such dynamic and rather unpredictable environment. We propose to adapt the strategy that nature has been using to 'design' its own circuits: evolution. First, we will generate a large number (millions) of different circuits in bacteria through genetic manipulation. The circuits are then subjected to the laboratory evolution process that involves selection and mutation in the controlled environment. We expect that the best circuit designs that robustly function in the living cells emerge from the laboratory evolution process. We will also study how the evolving circuit populations acquire new functions, which is also an important aspect of evolution. These studies are expected to enhance our ability to program living cells with complex and useful functions, as well as to deepen our understanding of how evolution shapes the complex genetic circuits observed in nature.<br\/><br\/>Broader impacts<br\/>The tools and insights gained through the proposed research should advance our ability to program living cells for the future practical applications. Genetic parts that are developed through the proposed project will be made available to the research community. Furthermore, the proposed research will actively engage domestic and international undergraduate students as research interns and summer researchers. High school students will also participate in the research through a summer program administered at UC Davis. The proposed project will foster interactions among the young students with diverse backgrounds through cutting-edge research activities.","title":"SHF: Small: Evolvability and Robustness of Synthetic Gene Circuits in Bacteria","awardID":"1016357","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["524275"],"PO":["565223"]},"168476":{"abstract":"This project is a collaborative effort between the University of Delaware and Millersville University. Information graphics (non-pictorial graphics such as bar charts and line graphs) occur frequently in popular media such as newspapers and magazines. Not only is the knowledge conveyed by these graphics very often not included in the article's text, but (in contrast with scientific documents) the article's text most often does not even explicitly refer to the graphics. Information retrieval research has focused on the text of documents, and their information graphics have largely been ignored. Yet, the graphic designer considered the graphic's message important enough to warrant designing a graphic to convey it. This project's goal is a novel methodology for retrieving relevant information graphics from a digital library in response to user queries.<br\/><br\/>Information graphics in popular media generally have a communicative goal or message that they are intended to convey. This message encapsulates the high-level knowledge contained in the graphic. The approach of the project is a language model that treats the relevance of a graphic to a query as a mixture of three components: a graphic's intended message, other textual components of the graphic such as its caption and additional textual description augmenting the caption, and the text of the document containing the graphic. Challenges that are being addressed include identifying the portion of the article that is relevant to the graphic, associating query terms with the intended messages of graphics in the document library, expanding the abbreviated captions and additional textual descriptions of graphics to more fully capture their content, and appropriately weighting the contribution of individual components of the mixture model. In addition, some kinds of graphics, such as grouped bar charts, have both a primary intended message and a secondary message. The impact of the secondary message on retrieval when an ideal graphic is unavailable is also being addressed. Evaluation of the graph retrieval methodology consists of experiments in which human subjects rate the relevance of retrieved graphics to user queries.<br\/><br\/>The goal of this project is to produce a system for retrieving relevant information graphics, thereby expanding the utility of digital libraries. Together with the SIGHT system, which conveys the content of information graphics via speech, the project will extend the information resources available to individuals with sight-impairments. The project will also produce a corpus of information graphics and their XML representations that can be used by other researchers. Corpora and research results will be disseminated on the project web site (http:\/\/www.cis.udel.edu\/~carberry\/Graph-Retrieval). In addition to significantly increasing the resources accessible from a digital library, the research will lay the foundation for expanding research on question-answering to take into account information graphics. The project will contribute to the development of future scientists by educating graduate students, providing research opportunities for undergraduates at a predominantly undergraduate institution, and enhancing the mentoring skills of graduate students as they work on a team that includes undergraduates.","title":"III: Small: Collaborative Research: Exploiting Information Graphics in a Digital Library","awardID":"1016916","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[451009],"PO":["563751"]},"168597":{"abstract":"Benchmarking file and storage systems is challenging. The Wisconsin Next Generation Benchmarks (WiNG) project aims to provide tools and techniques to simplify the benchmarking of file and storage systems, particularly at large scales and storage capacities. The WiNG project solves three current problems in benchmarking file systems.<br\/><br\/>First, the performance of file systems can be extremely sensitive to the initial allocation of files on disk. Our Impressions framework helps evaluators to easily and quickly create representative, reproducible file system images to initialize the system under test.<br\/><br\/>Second, evaluators want to understand how file systems perform on large data sets; unfortunately, it can be costly to acquire the necessary storage capacity and time consuming to run the workloads. Compressions helps with scale: it enables users to benchmark extremely large data sets using significantly smaller storage systems and for some scenarios reduces benchmark running time by orders of magnitude.<br\/><br\/>Third, evaluators rarely have the expertise to set up and run an interesting range of representative applications. Insight enables users to easily create and run synthetic workloads representative of more complex applications.<br\/><br\/>In summary, WiNG enables developers to evaluate file systems on applications that real users care about. WiNG is developing benchmarking infrastructure and source code that can and will be used by the file system community. WiNG gives graduate students hands-on training with cutting-edge systems technology. Finally, for outreach to the wider community, WiNG enables an undergraduate to work with elementary-school children in the Scratch programming environment.","title":"CSR: Small: Wisconsin Next Generation benchmarks (WiNG)","awardID":"1017518","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550389","550390"],"PO":["565255"]},"168267":{"abstract":"Boosting is a machine-learning method based on combining many<br\/>carefully trained weak prediction rules into a single, highly accurate<br\/>classifier. Boosting has both a rich theory and a record of empirical<br\/>success, for instance, to face detection and spoken-dialogue systems.<br\/><br\/>The theory of boosting is broadly connected to other research fields,<br\/>but has only been fully developed for the simplest learning problems.<br\/>Nevertheless, in practice, boosting is commonly applied in settings<br\/>where the theory lags well behind. We do not know if such practical<br\/>methods are truly best possible; even for binary classification, it is<br\/>not clear how to best exploit what is known about how boosting<br\/>operates. New challenges will demand an even greater widening of the<br\/>foundations of boosting.<br\/><br\/>The goal of this project is to develop broad theoretical insights and<br\/>versatile algorithmic principles. The aim is to study<br\/>game-theoretically how to design the most efficient and effective<br\/>boosting algorithms possible.<br\/><br\/>Research on boosting is spread over many years. across multiple<br\/>publications and disciplines. To organize this body of work, a<br\/>significant activity of this project is the completion of a book on<br\/>boosting which will provide a valuable resource for students and<br\/>researchers of diverse backgrounds and interests.<br\/><br\/>Boosting has historically had a major impact on areas outside machine<br\/>learning, such as statistics, computer vision, and speech and language<br\/>processing. Thus, there is a strong potential for work at its<br\/>foundations to have a broad impact on these other research and<br\/>application areas as well.","title":"RI: Small: Boosting, Optimality and Game Theory","awardID":"1016029","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[450503],"PO":["562760"]},"168388":{"abstract":"Network coding is touted as the foundation on which several applications related to the robust operation of both wired and wireless networks can be built. This promising technique has been missing a simple framework that can allow explaining its evolution in an arbitrary wireless network. Given an arbitrary wireless network and a network coding strategy, a question that remains to be answered is how the rank or state of the nodes in the network evolves over time. Further, if there are changes in the underlying wireless network either through changes in the PHY layer, MAC layer or due to other factors such as mobility or traffic, how does this impact the evolution of network coding over this arbitrary network? This research involves answering such questions that are of paramount importance for network practitioners. <br\/><br\/>A systematic framework called DEDI, that is based on differential equations (DE) and differential inclusions (DI) which is a generalization of DEs with discontinuous right-hand sides, is developed to study the dynamics of network coding. Using both analytical methods and numerical software for solving differential equations and inclusions, the DEDI framework is used as a tool for the crosslayer design and analysis of network coding. Numerical DE and DI solvers are used to develop an open source software utility that allows analytical insights without having to resort to time consuming simulations, there by aiding the design of practical network coding. The use of DEs and DIs along with associated numerical software also offers an educational opportunity to involve both graduate students and undergraduate students by developing simple yet illustrative modules for studying the evolution of network coding.","title":"CIF: Small: DEDI: A New Framework for the Practice of Wireless Network Coding","awardID":"1016551","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["475434"],"PO":["564924"]},"168399":{"abstract":"Future communication networks will incorporate capabilities for routing encoded data to its destination along multiple simultaneous paths, in order to increase security, data rate, and reliability. A significant fraction of the data traversing these future networks will be associated with delay sensitive applications. Such applications include streaming video, video and teleconferencing, and remote control over a network, all of which will be required for other important future applications such as telepresence and telemedicine. There is a significant hurdle, however, in routing data for delay sensitive applications over several paths due to randomly varying delays, and packets of information arriving out of order at the destination. This research solves the important problem of matching delay intolerant applications to best effort multi-path routed and coded networks all the way from a fundamental perspective to implementation and testing on a network testbed to human interaction testing. The public awareness of live streaming technology and the work being performed will be enhanced through live streaming Philadelphia Orchestral concerts at Drexel University.<br\/>The problem of matching delay sensitive applications to best effort multipath routed network architectures involves a clear fundamental tradeoff: the redundancy required to guarantee a decoding delay in spite of network packet reordering, delay, and loss comes at the cost of a reduced application data rate. This project investigates this fundamental tradeoff over all end-to-end coding schemes using information theory. The developed models and delay mitigating code transport protocol will be evaluated on a network tested, and the perceptual performance provided by applications running over the developed transport protocol are measured via an educational interactive web tool.","title":"NetSE: Small: Connections Over Multiple Network Paths via Delay Mitigating Codes","awardID":"1016588","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["533238","520246","503250","539473"],"PO":["564898"]},"174560":{"abstract":"Source controlled routing, where the edges of the network have some control over the paths taken by their packets, is a promising technique to improve network reliability and path quality. However, past studies of source-controlled routing algorithms have been based on overlay networks rather than via direct control of switches or routers---despite the performance-sensitive nature of these systems.<br\/><br\/>This EAGER project is studying adaptive multipath, source-routing algorithms to improve performance for real-time applications. The experiments use GENI Alpha, which provides a unique combination of coexistence with real traffic and deep programmability, which are essential to obtain accurate results in these experiments. Thus, the results of this project will develop novel, practical and experimentally-grounded techniques to improve reliability and path quality, and it will quantitatively demonstrate the value of experimenting on GENI infrastructure by comparing with overlay-based experiments. Results will be disseminated through publications, presentations, and demos of the software.","title":"EAGER: Adaptive Source Routing on GENI","awardID":"1050146","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["508065"],"PO":["564993"]},"174571":{"abstract":"This project proposes a comprehensive load-balancing solution to minimize client response time and reduce system costs for services hosted in wide-area networks. The system, called Aster*x, uses the global state of server load and network congestion, and dynamically routes the requests over appropriate (server and path) pairs, calculated using the load-balancing algorithms developed by project staff. <br\/><br\/>The GENI network infrastructure will be used for extensive deployment, evaluation, and demonstration of Aster*x. Aster*x exploits OpenFlow?s logically centralized controller to obtain the global network state and route flows of various granularities. It will use the PlanetLab and ProtoGENI-based computation substrate to host the replicated web service and to generate client requests from multiple locations. The project will provide an opportunity for students across four universities to collaborate and build a relatively large experimental system on GENI.","title":"Collaborative: Aster*x: Load-Balancing Web Traffic over Wide-Area Networks","awardID":"1050182","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["553786"],"PO":["564993"]},"174461":{"abstract":"Voting is the most fundamental act of participation in our democracy, yet voting technology has suffered diverse failures and crises. Voting is a remarkably hard, interdisciplinary problem, with seemingly conflicting goals of verifying ballots while maintaining secret ballots to safeguard against bribery and coercion. This project is producing innovative and fundamental computer security technologies supporting remote and kiosk voting scenarios, i.e. high assurance applications on un-trusted hardware\/software.<br\/><br\/>This research is designing and developing a secure execution partition (SEP) prototype based on an un-trusted hardware and software base. The research leverages the trusted components, e.g. Trusted Platform Module (TPM) and vPro chipsets, currently available on production motherboards, and programming language constructs producing a prototype that enables easy formal verification by third parties.<br\/><br\/>The execution of high assurance software on un-trusted components has been a research problem for decades. While specifically addressing the remote voting problem in this effort, results will also significantly impact health care privacy, remote financial transactions, and remote authentication.<br\/><br\/>The findings and experience from this research will be incorporated into UMD?s system's programming\/architecture, operating systems, and information security courses at the graduate and under graduate level. Exceptional undergraduate students will be active solicited for participation in the research. Finally, the results of this research will impact society through improvements in future operating systems.","title":"Secure Execution Partition (SEP) for Remote Voting","awardID":"1049750","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[467998],"PO":["565264"]},"174582":{"abstract":"This project proposes a comprehensive load-balancing solution to minimize client response time and reduce system costs for services hosted in wide-area networks. The system, called Aster*x, uses the global state of server load and network congestion, and dynamically routes the requests over appropriate (server and path) pairs, calculated using the load-balancing algorithms developed by project staff. <br\/><br\/>The GENI network infrastructure will be used for extensive deployment, evaluation, and demonstration of Aster*x. Aster*x exploits OpenFlow?s logically centralized controller to obtain the global network state and route flows of various granularities. It will use the PlanetLab and ProtoGENI-based computation substrate to host the replicated web service and to generate client requests from multiple locations. The project will provide an opportunity for students across four universities to collaborate and build a relatively large experimental system on GENI.","title":"EAGER: Collaborative: Aster*x: Load-Balancing Web Traffic over Wide-Area Networks","awardID":"1050234","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564992","561756"],"PO":["564993"]},"174351":{"abstract":"Research in Human-Computer Interaction (HCI) on sustainability has recently exploded. The goal of this project is to guide further development of sustainable HCI by informing research in the area with an understanding of contemporary interventionist eco-art practices. By \"interventionist eco-art practices\" we are referring to a set of artists and projects that combine public and institutional engagement with a commitment to sustainability, to produce artifacts and systems that intervene in environmental issues to raise awareness and provide models for social change. Through such activities, artists push the boundaries of how we use and think about technology and its relationship to the environment. These interventionist eco-art artists and projects suggest new themes and work practices that could usefully inform sustainable HCI. But because they are born from far outside of the traditional sciences, arts-based approaches run into challenges in being taken up and taken seriously as part of HCI. On the one hand, methods and outcomes deriving from the arts are most easily incorporated into HCI by retro-fitting them to existing understandings of HCI as a scientific discipline in ways that blunt their potential to truly add new perspectives. On the other hand, methods and outcomes that remain true to an arts sensibility can suffer marginal status as \"artsy HCI\" such arts-based approaches are more likely to be considered acceptable for fringework or one-off systems than to be thought of as appropriate or essential for the core research of HCI. In either case, the \"edge\" of arts-based approaches, that could provide transformative potential for innovation, is dulled.<br\/><br\/>In this project, groundwork for transdisciplinary engagement between sustainable HCI and interventionist eco-art practices will be laid through an ethnographic case study of interventionist eco-arts practices at the 2010 01 SJ Biennial in San Jose, California to be held September 16 to 19, 2010. The 01SJ Biennial is one of the major international media arts festivals. It attracts tens of thousands of visitors; over 60 artists, designers and collectives are scheduled to participate in the 2010. The theme of 2010 is \"Build Your Own World\" and the majority of participating projects share a common theme of developing alternative, collaborative and Do-It-Yourself (DIY) approaches social and environmental conditions. As such, it provides a unique opportunity for ethnographic study of a range of projects and practices within a bounded space and timeframe. This research will engage in the following activities (1) observation and analysis of eco-arts projects presented at the 2010 01SJ Biennial; (2) participant-observation in the Biennial as a commissioned art\/design collective (3) a project workshop to integrate the results of the first two activities and develop a set of key themes for sustainable HCI (4) follow-on interviews with artists from and the curator of the Biennial.","title":"EAGER: Collaborative Research: Transformative Innovation for Sustainable HCI through Interventionist Eco-Arts","awardID":"1049415","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["517929"],"PO":["565227"]},"174472":{"abstract":"The proposed EAGER project will research issues and conduct GENI experiments related to the following two topics: (1) how to effectively ?glue? multiple virtual machines (VMs) distributed across different geographical locations into one seamless machine with Single System Image (SSI); (2) how to make it easier for ordinary people to use and enjoy the benefits of cloud computing when they might be reluctant due to concerns over privacy and security of their data or how to change\/customize applications and migrate between VMs. <br\/><br\/>The second part of the project will integrate existing social networking services, such as authentication and ?friends lists,? into the GENI control framework, and allow GENI users to share their resources under the VLAN-based SSI framework with their friends. <br\/><br\/>Intellectual Merit and Broader Impacts: The work on SSI will also contribute to the understanding and advancement of cloud computing over a virtual<br\/>data center or multiple data centers. Furthermore, socially-aware SSI represents a departure from conventional resource-sharing approaches and peer-to-peer file sharing approaches. The proposed work will make it easier and more comfortable for mass users to contribute their own resources to GENI and use others? resources made available through GENI. It may become a catalyst for personal and wireless cloud computing that could change the way we do computing and transform the IT landscape.","title":"EAGER: Create a Socially-aware Single System Image (S3I) in GENI","awardID":"1049775","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["511691"],"PO":["564993"]},"174593":{"abstract":"This project proposes a comprehensive load-balancing solution to minimize client response time and reduce system costs for services hosted in wide-area networks. The system, called Aster*x, uses the global state of server load and network congestion, and dynamically routes the requests over appropriate (server and path) pairs, calculated using the load-balancing algorithms developed by project staff. <br\/><br\/>The GENI network infrastructure will be used for extensive deployment, evaluation, and demonstration of Aster*x. Aster*x exploits OpenFlow?s logically centralized controller to obtain the global network state and route flows of various granularities. It will use the PlanetLab and ProtoGENI-based computation substrate to host the replicated web service and to generate client requests from multiple locations. The project will provide an opportunity for students across four universities to collaborate and build a relatively large experimental system on GENI.","title":"EAGER: Collaborative: Aster*x: Load-Balancing Web Traffic Over Wide-Area Networks","awardID":"1050266","effectiveDate":"2010-09-01","expirationDate":"2013-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["549890"],"PO":["564993"]},"174120":{"abstract":"Abstract<br\/><br\/>Fundamental changes in the underlying algorithms of physical simulation are needed to bring about the orders of magnitude improvement in performance required to bring physical simulation to resource-constrained applications such as real-time games or surgical training. This research is investigating three issues: frame-rate simulation, asynchronous evolution, and multilevel solvers. The approach to frame-rate simulation consists of ensuring stability by careful energy management principles to address both stability and damping. Paying special attention to the amount of artificial damping in the system enables one to avoid excessively damped simulations, a problem that limits the time step size possible with existing techniques. Such a frame-rate simulator enables the next step: developing an asynchronous evolution scheme that allows small time steps to be taken in regions of high-frequency motion and large time steps to be taken elsewhere. Other attempts at developing asynchronous schemes have difficulty with excessive damping when taking large time-steps. This research is investigating an asynchronous method around the proposed frame-rate simulator in order to alleviate this problem, as the amount of damping can be explicitly controlled. Finally, to reduce the cost of a single time step, we are using multilevel methods to reduce the time spent solving large linear systems typical of physical simulation. <br\/><br\/>Multilevel methods have a long history, but they are new to the physical simulation community. Finding suitable coarsening and refinement operators are key to multilevel methods and, although difficult to formulate, have the potential to create asymptotic improvements in the convergence rates of solving these systems. The methods being investigated represent a radically different approach from current techniques and this exploratory research is seeking to demonstrate the feasibility of this potentially transformative change.","title":"EAGER: IIS (G&V):Scalable High-Fidelity Solids Simulation","awardID":"1048573","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[467067],"PO":["532791"]},"173163":{"abstract":"This proposal requests funding for a two-day workshop on cross-disciplinary investigations in imaging and image analysis. This workshop will bring together representatives from US and foreign academic institutions representing a variety of disciplines engaged in imaging and imaging analyses. The workshop envisions large-group keynote presentations by prominent researchers and break-out sessions on specific topical areas. One goal of the meeting is to facilitate education, training and informational exchange among multiple scientific disciplines including humanities, arts, social science, science, and computational researchers to address related research challenges for which image and imaging analysis is both a means and end (visualization, virtual spaces, et al.) The organizations planning the event include the National Center for Supercomputing Applications (NCSA), the University of Illinois School of Art and Design, and the Institute for Computing in Humanities, Arts, and Social Science (I-CHASS) as well as individual stakeholders in the broader community.","title":"Workshop: Cross-Disciplinary Investigations in Imaging and Image Analyses","awardID":"1043036","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["506710","473994",464453],"PO":["564456"]},"175000":{"abstract":"This award will provide support for a special workshop titled ?Facets of Coding Theory: from Algorithms to Networks? and dedicated to the work of Ralf Koetter. The workshop will take place at the Allerton House, in Monticello, Illinois, from Sunday, September 26, until Tuesday, September 28, 2010, immediately prior to the Forty-Eighth Annual Allerton Conference on Communication, Control, and Computing. While Ralf Koetter lost his battle with cancer a year ago February, this workshop is not only to honor his memory, but also to celebrate and explore the tremendous wealth of opportunities in research that his work in communications, information theory, coding theory and signal processing brought to light.","title":"Facets of Coding Theory: From Algorithms to Networks: A Tribute to the Work of Ralf Koetter","awardID":"1052995","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["551642"],"PO":["564898"]},"175121":{"abstract":"This proposal is for travel support for the participation of two United States Scientists\/Artists, Victoria Vesna and Leah Buechley, in the 2010 ACM Multimedia Conference Interactive Art Program Exhibition \"An Interactive Renaissance of Color\" to be held in Florence, Italy. Dr. Vesna's work is characterized by her utilization of scientific practice as source material. The result is to educate the public to understand new discoveries, and provoke thought about their impact on society. Dr. Buechley describes her work as high-low tech, because it is part of the do-it-yourself movement of citizen science and engineering. Both of these Scientists\/Artists inspire to broaden participation in computing. Vesna's impact is pronounced particularly through her collaborations with life scientists and physicists. She develops a functional model, harnessing artistic practice as a means for communicating about science, and scientific practice as grist for art. Buechley provocatively combines circuitry, fashion, and design, challenging gender stereotypes about geeks, and thus inviting the participation of a new generation of young women into STEM.<br\/><br\/>The scientific tracks of the ACM Multimedia conference focus on algorithmic techniques and scientific measurements, emphasizing content recognition and streaming media. The Interactive Art track develops creative and expressive innovative use contexts that stretch our imagination of what is possible for multimedia science and technology. This track serves to advance the dialog of artists and scientists in order to advance the principles and uses of computing. These connections, in the historically rich environment of Florence, Italy where art and science where strong collaborators, will be used as a springboard to catalyze new ideas that will inspire the future of multimedia computing as an example of how artistic and scientific research can be combined in the most innovative, dynamic, thought-provoking ways imaginable.","title":"U.S. Participation in ACM Multimedia Interactive Art Exhibition: An Interactive Renaissance of Color","awardID":"1053538","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["531380"],"PO":["565227"]},"174274":{"abstract":"The objective of this Early-Concept Grant for Exploratory Research (EAGER) project is to develop a novel concept for patterning single protein with ultrahigh resolution (below 10 nm). The approach is based on self-assembly and self-recognition and originates in the intracellular environment that is too crowded to allow diffusion to be an efficient mechanism for the movement of materials within the cytoplasm. Specifically, in situ polymerized microtubule (cytoskeletal filaments) affixed vertically to the tip of an atomic force microscope serves as track for purified kinesin molecular motors; under the chemical energy derived from adenosine triphosphate hydrolysis kinesin is deposited from the microtubule tip onto a glass surface situated in close proximity leading to nanoarrays of single protein. <br\/><br\/>This EAGER-developed technology benefits society in areas as: drug delivery, screening, nanoelectronics, and nanosensors. Beyond recognizing the value of this technology through the proof of principle that biological molecules can be used for printing nanoarrays with ultrahigh resolution, this research also provides solutions to patterning individual nanomaterial (both organic and inorganic). The inherent interdisciplinary nature offers tremendous opportunities for enticing and integrating students with educational experience across diverse disciplines (two graduates will be employed by this program). The advances in the field of biomimetic-based nanomanufacturing will be incorporated in two courses Cellular machines at WVU and Processing of Biomaterials at RPI. Lastly, the PI will use Society for Biological Engineers at WVU to popularize bionanotechnology by generating inexpensive posters highlighting the advances and thus contributing to public education in nanotechnology and outreach to underrepresented populations, (i.e., women, rural communities).","title":"EAGER\/Collaborative Research: Large Scale Microtubule-Based Nanomanufacturing of Single Kinesin Patterns with Ultrahigh Resolution","awardID":"1049150","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1788","name":"NANOMANUFACTURING"}}],"PIcoPI":["541120"],"PO":["564949"]},"168851":{"abstract":"Pattern matching is a key function in many data intensive computing applications ranging from deep packet inspection, text processing, to genomic research. The explosive growth of digital information in the form of webpages, XML documents, network traffic and scientific data has put an enormous pressure on the performance requirements of large-scale pattern matching. This research will study the use of innovative algorithms and architectures on ASIC\/FPGA and multi-core platforms to accelerate large-scale pattern matching for network security, data mining and filtering applications. Various types of pattern matching will be considered, including regular expression matching, dictionary-based string matching, and extended regular expression matching. The intellectual merit of this proposal includes the innovation in algorithms and architectures for matching large pattern sets against high bandwidth data input. <br\/><br\/>The proposed research will be conducted from two perspectives: (1) Novel algorithms and data structures for large-scale pattern matching; such as finite automata, dynamic search tree, formal language and graph theory. (2) Practical optimization techniques for pipelining, partitioning, scalable and modular designs on parallel architectures with ASICs\/FPGAs, multi-core processors and general-purpose graphics processors (GPGPUs). Instead of producing heuristics specific to a particular input or pattern set, the proposed research aims to improve the fundamental understanding of large-scale pattern matching, and apply the understanding to both algorithmic and architectural innovations. This allows exploration of the design limits and tradeoffs in using practical optimizations on state-of-the-art computing platforms. The designs will be mapped onto parallel architectures based on both FPGA and multi-core technologies, including CPU-FPGA and CPU-GPU heterogeneous architectures.","title":"DC: Small: Accelerating Large-Scale Pattern Matching for Data Intensive Applications","awardID":"1018801","effectiveDate":"2010-09-15","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["563658"],"PO":["565272"]},"176353":{"abstract":"This project aims to leverage GENI's deeply programmable core and wireless edge networks to implement and evaluate recently proposed approaches for delivering predictable end-to-end performance to mobile devices. These approaches involve techniques such as inter-flow and intra-flow network coding, multipath routing, available bandwidth estimation, and spare bandwidth exploitation. While these techniques have been studied using simulations, it has never been possible to validate their models and their limits on an operational network without GENI's fine-grained measurement and control capabilities. <br\/><br\/>True ubiquitous broadband networking cannot be realized without overcoming the bandwidth bottleneck and mobility overheads of future Internet, both at the core and at the wireless edge. Early wireless access deployments in many instances resulted in only marginal improvements in end-to-end data rates to mobile users. Outcomes from this research may influence the ongoing broadband initiatives in the United States.","title":"EAGER: GENI Experiments on Mobile Gigabit Wireless Access with Core-to-Edge Network Coding","awardID":"1060344","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["553458"],"PO":["564993"]},"174065":{"abstract":"This project explores a radical new theoretical and computational model for creativity, casting it as a rational pursuit of curiosity, and in particular develops a model of expressive artifact creation as a knowledge seeking effort. A discovery agent engages in the rational pursuit of curiosity when, given an experimental situation and a set of discovery actions, the agent takes the action it predicts will result in the maximum knowledge gain. This is a key feature of our proposed model of transformational creativity: creative agents in a design domain are creative precisely because they seek to increase their design knowledge in the domain. This new discovery system approach will be built on the foundations of the Co-PI's earlier contributions in formalizing the domain of game mechanics and generating a wide variety of human-playable games through logical reasoning. In doing so, the project will bridge a gap in the creativity literature? recasting the creation of aesthetic artifacts as a knowledge building process, rather than the product of a limited grammar or the knowledge-free exploration of a generative space. We call this approach expressive discovery.<br\/><br\/>The proposed game design system will be focused in the creation of the underlying models of the mechanics that drive game play with the goal of providing a new game development platform. This area of computational creativity will support game design that moves beyond the production of static outputs (e.g., musical compositions or fictional stories) toward the creation of artifacts that are inherently self-reflective and interactive. This project consists of three core activities: 1) creating the first formalization that captures a large design space for interactive artifacts in a computational creative system; 2) develop a new model for discovery systems that embodies the Co-PI's model of transformational creativity as the rational pursuit of curiosity.; and 3) preliminary evaluations of the game design model formalization and the larger creative process it supports to inform future work in the area.","title":"EAGER: Creative Synthesis of Interactive Artifacts through Computational Knowledge Building","awardID":"1048385","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["536597","536598"],"PO":["564456"]},"168631":{"abstract":"For most applications in which optimization algorithms are used in industry, and in particular problems from logistics, supply-chain management, routing, and network design, the computational problems are intractable -- there are severe restrictions on the size of input data that can be quickly and reliably solved to optimality. We will focus on the development of new algorithmic techniques in the design of algorithms to produce good solutions for these critical problems. The theoretical foundation of these algorithms is that they possess a performance guarantee that assures that the solutions computed are nearly optimal; for example, the project aims to devise efficient algorithms to find solutions for which the cost is no more than a specified percentage more than the minimum possible. The project also considers stochastic optimization problems, where the input consists of a probability distribution over inputs, thereby giving rise to even more difficult problems than if the input is known with certainty. We will focus on problem formulations and approaches that allow us to model the requisite probability distributions using historical data archives.<br\/><br\/>This project aims to provide algorithms with strong guarantees for a number of theoretical models including the capacitated facility location problem, which arises in many industrial contexts from the positioning of warehouses in a distribution network to the choice of hub placements in high-bandwidth networks; the generalized assignment problem, which has a range of workload-balancing applications in heterogeneous environments; the bottleneck asymmetric traveling salesman problem (TSP), which arises in scheduling of chemical processing plants (known technically as a no-wait flowshop scheduling environment), as well as the more often studied minimum-sum variant; and several stochastic optimization models including one arising from the adaptive routing of medical transport planes.<br\/><br\/>Finding good approaches to gain new efficiencies in logistical planning is an issue that is important for the overall US economy, and this is a long-term goal of this project. Our viewpoint is that the study of simplified models will yield algorithmic paradigms that can be applied to realistic settings with industry-scale data and complexities. The insight needed to prove strong theorems about the quality of the solutions found translates into algorithmic principles, which in turn leads to algorithms that work well on the problems that industry needs to solve. By training graduate students in this area, this project will also contribute to the important effort to ensure that the US workforce has sufficient expertise to meet the technological challenges of the coming century in the area of logistics support.","title":"AF: Small: AAdvances in the Design of Approximation Algorithms for Optimization Problems","awardID":"1017688","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["562312"],"PO":["565251"]},"168752":{"abstract":"Inferring the true evolutionary history for a group of organisms, taxa, is a difficult problem. For a given set of taxa, there is an exponential number of ways to depict their family tree. Hence, an exhaustive exploration of all possible trees is infeasible. As a result, the most popular techniques sample tree space in order to obtain an estimate of the true evolutionary tree. The challenge is to know when a an estimate of an evolutionary tree for a group of taxa has converged, which is important because non-convergence leads to inaccurate estimation of the true evolutionary tree.<br\/>The team will develop a suite of convergence detection algorithms for large-scale Markov Chain Monte Carlo phylogenetic analyses, one of the most popular techniques for reconstructing large-scale evolutionary trees that can handle hundreds of thousands of trees on hundreds to thousands of taxa. Convergence detection changes the framework for how these evolutionary trees are reconstructed. For example, analyses that have not yet converged, rather than be terminated based on some arbitrary specification (e.g., elapsed time), could be allowed to continue as long as progress toward convergence is detected. If progress is still not made, the phylogenetic analysis would be terminated saving significant time and computational resources. The approach arms life scientists with information for why their analysis did not converge. <br\/><br\/>The team will develop convergence detection techniques that are based on the topological structure (i.e., the evolutionary relationships contained in a tree) of the underlying phylogenetic tree instead of relying solely on its score. To address the above issues, the novel integrated framework consists of: (i) designing and analyzing new algorithms for convergence detection, (ii) identifying the causes for non-convergence in a phylogenetic analysis, (iii) performing real-time convergence analysis, and (iv) developing new visualization tools that provide informative views of convergence data.<br\/><br\/>There are many benefits that exist between the collaboration of a research university and an undergraduate liberal arts college. Both undergraduate and graduate students in both biology and computer science have an opportunity to design and implement algorithms and run computational experiments on large data sets that would otherwise be unavailable to them. The large trees that can be considered have applications in improving global agriculture and protecting ecosystems from invasive species. The results of this work will be presented and disseminated at scientific conferences, workshops, and journals. Tools and software developed will be made publicly available.","title":"III: Small: Collaborative: Novel Techniques for Understanding Convergence in Large-Scale Markov Chain Monte Carlo Phylogenetic Analyses","awardID":"1018311","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560696"],"PO":["565136"]},"168873":{"abstract":"High cost differentials are causing many steps of IC manufacturing to increasingly move overseas. This project considers the problem of evaluating trustworthiness of digital ICs fabricated by untrusted vendors who may insert hardware Trojans. The proposed EDICT framework (Evaluation and Design of IC's for Trustworthiness) tackles two main challenges, namely the unavailability of a gold-standard chip combined with high process variations, and the fact that Trojans are introduced by intelligent adversaries. EDICT exploits the key difference between the impact on circuit parameters of Trojans and process variations - universal shift vs. random - to detect Trojans, including those causing deviations smaller than process variations. In particular, this project is developing new techniques to identify effective measurements - sequences of values applied at IC inputs and parameters measured - for evaluation of chip's trustworthiness.<br\/> This project represents a radical extension of techniques for generating vectors for high-volume-manufacturing testing by focusing on new targets that capture all possible Trojans, developing the first suite of techniques to characterize and identify Trojans in a non-destructive manner, and developing the first methods to identify additional unauthorized functionality. <br\/> By providing the technical infrastructure to evaluate trustworthiness of ICs, this project enables defense and civilian sectors to exploit global semiconductor industry at reduced risk. Trustworthy digital systems bring many benefits to society. They improve many essential services - health, security, education, etc. - and bring lower costs. Finally, this project trains graduate students in developing, and defense and industry experts in using, new approaches and tools for evaluating IC trustworthiness.","title":"TC:Small:EDICT: Evaluation and Design of IC's for Trustworthiness","awardID":"1018937","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["535238","518663"],"PO":["565264"]},"176133":{"abstract":"This project is developing techniques for secured real-time services for cyber-physical systems. In particular, the research is incorporating real-time traffic modeling techniques into the security service, consequently enhancing both system security and real-time capabilities in an adverse environment. While this proposed methodology has not yet been fully tested, it is potentially transformative. <br\/><br\/>To defend against traffic analysis attacks, the research is developing algorithms that can effectively mask the actual operational modes of cyber-physical applications without compromising the guaranteed quality of service. This is achieved by using the traffic modeling theory, developed by the PIs, to precisely manage the network traffic at the right time and the right place. This traffic modeling theory can also help in develop efficient attack detection and suppression methods that can identify and restrain an attack in real-time.<br\/><br\/>The proposed methods are expected to be more effective, efficient, and scalable than traditional methods.","title":"A Study of Security Countermeasures for Cyber-Physical Systems","awardID":"1059127","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[472011],"PO":["565239"]},"165485":{"abstract":"Educators at all levels have begun to exploit children's attraction to games. However, until recently, especially at the K12 level, it has been assumed that learners were consumers of games and not their producers. The goal of the Pedagogical Game project is to develop and evaluate a secondary school curriculum for learning standards-based content via collaborative game-making. The proposed work will test the hypothesis that creating computer games (game-making) can engage students in learning standards-based content and significantly impact achievement and retention and that collaborative game design can be a powerful tool for encouraging open negotiation and argumentation, a core element in promoting creativity. The interdisciplinary and project-based approach to learning will encourage art\/theater and math\/science students to work together in a collaborative setting and promote differentiation of learning tasks and student-centered learning. Research being undertaken includes (a) developing collaborative game making curriculum where standard based math content is effectively integrated; (b) identifying scaffolding opportunities, such as promoting student collaboration and reflection through online discussions and wiki-based journaling; (c) developing instructional assessment tools based on discourse analysis and course topic ontology that will monitor student progress over time according to the game making project goals.<br\/><br\/>The proposed work will strengthen and evaluate a fledgling game-building curriculum that was created to address the educational needs of at-risk high school students in underperforming schools in the Los Angeles Unified School District (LAUSD). The program has a large potential to positively impact the education and lives of our at-risk student population. The intellectual merit of the project includes a game-making curriculum with embedded standards and new ways to promote and evaluate collaboration in a game-making context. The results of the project will have broad societal impact by enhancing the ability of students from traditionally under-represented groups to participate in STEM fields of study while learning 21st century career skills. The project will also contribute to the knowledge base through careful empirical evaluation of the benefits of creative new instructional strategies (game-making, project-based learning) that support learning styles and strategies preferred by students who have had difficulty excelling in mathematics learning. With the support of LAUD teachers and staff, we are poised to develop and integrate the program into the curriculum and scale its adoption. Its success has the potential to transform learning strategies for at risk students.","title":"Major: Creative Secondary STEM Learning Through Collaborative Game Building (PedGames)","awardID":"1002901","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["446978","472308","446979","519748"],"PO":["562669"]},"168642":{"abstract":"Search engines and various data-mining applications commonly rely on web crawlers to navigate the web, discover valuable content, and keep it fresh. However, the enormous volume of available information and sophisticated spam techniques commonly used to deceive search engines present significant challenges in web crawling, especially in non-commercial applications such as research. The first part of this project designs efficient real-time graph-manipulation algorithms and builds a high-performance distributed web-crawler architecture that seamlessly couples the various components of Internet-scale networking, information retrieval, and graph theory. The second part creates probabilistic techniques for quick estimation of domain reputation and explores various ranking techniques to achieve better robustness against spam. The third part designs advanced budgeting mechanisms to control the crawl rate of different parts of the web at multiple levels of granularity. The project is expected to engage students at Texas A&M in research-intensive education in cross-disciplinary fields (such as data-intensive computing, networking, graph theory, distributed systems, parallel architectures, and modeling), broaden integration of web research into classroom teaching, attract undergraduate students to REU, extend participation of minority groups in engineering, stimulate collaboration among students and sharing of ideas, and permit web-related research at other institutions through publicly shared outcomes of our work.","title":"CSR: Small: Large-Scale Web Crawling and Spam Avoidance in Search-Engine Applications","awardID":"1017766","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550669"],"PO":["565255"]},"168763":{"abstract":"This project aims to systematically investigate the analysis, design, and management of environmentally powered micro-scale systems. The project will comprise of three research thrusts, namely: (a) Techniques for efficient power extraction from micro-scale energy transducers. Specific research artifacts include new power converter designs and maximum power point tracking schemes that are specifically optimized for use with micro-scale energy transducers, (b) Techniques for efficient storage and consumption of harvested power. As part of this thrust, new ways of synergistically combining heterogeneous energy buffer elements (e.g., thin film batteries and ultra-capacitors) to minimize losses during energy storage will be explored. New harvesting-aware power management techniques will also be developed to help realize the goal of self-sustained operation (i.e., net-zero energy operation), and (c) Simulation models of various system components (e.g., energy transducers, power converters) will be developed to enable systematic design space exploration of micro-scale energy harvesting systems. These models will be used to build simulation tools that allow designers to evaluate the impact of various design choices and understand the numerous design trade-offs while architecting highly efficient micro-scale energy harvesting systems.<br\/><br\/><br\/>In terms of broader impact, the techniques developed as part of this project have the potential to greatly reduce the need for battery replacement in emerging application domains such as biomedical implants and networks of smart dust sensors. This will not only remove one of the biggest showstoppers to their large-scale adoption, but also decrease the large number of batteries that are discarded every year and cause significant heavy metal contamination in landfills and ground water sources. From an educational perspective, the research results developed as part of this project will be incorporated into undergraduate and graduate courses at Purdue, specifically, Embedded Systems (ECE 568), System-on-Chip Design (ECE 695R), and Advanced VLSI Design (ECE 695KR). Beyond the classroom, the systems developed as part of this project will directly impact the broader community through unique programs at Purdue such as the Engineering Projects In Community Service, which supports teams of faculty and students that work together on practical projects of relevance to the local community.","title":"SHF: Small: Design and Management of Micro-Scale Energy Harvesting Systems","awardID":"1018358","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[451692],"PO":["562984"]},"168532":{"abstract":"In contrast with most existing dynamic spectrum access (DSA) paradigms which impose a `foe' relationship between primary users (PUs) and secondary users (SUs), this project investigates a new DSA paradigm which encourages PUs and SUs to help each other by trading spectrum ownership for improved overall performance. Specifically, this project designs two different schemes: (1) Give-And-Take (GAT) and (2) Network Coding + Secondary User Relay (NC+SR). The former does not need to change the radio or the protocol stack of PUs, while the latter assumes that PUs and SUs are capable of performing network coding. In GAT, SUs help deliver the traffic of PUs and in return are allowed to access licensed spectrum in a manner disruptive to PUs. The help constitutes the `give' part, and the disruptive spectrum accesses constitute the `take' part. In NC+SR, SUs help relay PU traffic between PUs. When relaying PU packets, SU relay nodes may encode SU packets onto PU packets via network coding, so that SU packets get a `free ride' on PU packets. Both GAT and NC+SR promise the improved performance of PUs as well as SUs. The project studies the issues of protocol design and performance optimization of the two schemes. Results from this project are expected to encourage incumbent licensed users to embrace DSA to further improve the capacity of wireless network. The project sustains a collaborative research team, and involves both graduate and undergraduate students, particularly the underrepresented minority students,<br\/>in research.","title":"NeTS: Small: Collaborative Research: Learning to help: Trading spectrum ownership for performance","awardID":"1017172","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["565184"],"PO":["565303"]},"167443":{"abstract":"Cooperation and Learning over Cognitive Networks<br\/>Studies on herding and self-organization in economics and the social and biological sciences have observed that coordination among multiple agents leads to regular patterns of behavior and swarm intelligence, even when each group member shows limited behavioral complexity. In ant colonies, for example, individual ants cannot capture rich spatial information from their environment because of their limited sensing ability. Nevertheless, when the ants coordinate their activities within a colony, the group ends up exhibiting better sensing abilities. Using signal processing and communications techniques, the research studies how and why such manifestations of rational and organized behavior arise at the group level from local interactions among agents with limited abilities, what communication topologies enable such behavior, and what type of signal processing enables such formations. <br\/><br\/>This research seeks to understand and reverse-engineer the distributed intelligence encountered in socio-economic-biological networks, by investigating relations with learning and rationality over cognitive networks. The latter are adaptive networks that avoid centralized information processing and perform in-network inference and control decisions. Cognitive networks contrast with networks that rely on centralized and parallel information fusion, which are not scalable, are hard to adapt to changing topologies, and suffer from points of vulnerability and information bottlenecks. The research considers large scale networks of agents and studies how global (rational or irrational) patterns of behavior emerge, including herds, contagions and bubbles in economics. An understanding of how the biotic environment influences collective behavior in animal societies provides a real world guide to good cognitive networks, which can be used in turn to design engineered systems. Cognitive networks have applications in areas ranging from precision agriculture, to environmental monitoring, disaster relief management, and smart spaces.","title":"CIF: Large: Collaborative Research: Cooperation and Learning Over Cognitive Networks","awardID":"1011918","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":[448637],"PO":["564898"]},"174098":{"abstract":"This proposal applies for NSF support for the 43rd International Symposium on Microarchitecture (MICRO-43). The MICRO Symposium is a top-tier conference on microprocessor related research and has enjoyed a rich history of success. The research results presented at MICRO conferences have shown strong impacts in this research field and are highly regarded in the computer architecture community.<br\/><br\/>By providing this support to students, postdoctoral researchers, and junior faculty members, the PI expect to extend the range of attendance. We also anticipate that the research results presented at the conference, as well as the emphasis on interaction between academic researchers and industrial designers, will be carried back by attendees to their home institutions resulting in heightened awareness and interests in advanced.<br\/><br\/><br\/>The requested funds will be used solely to provide travel support for students, postdoctoral researchers, and junior faculty members in order to defray the costs of attending and participating in MICRO-43. Priority will be given to those students who will present their research at MICRO-43 or its joint workshops. To broaden the participation, the PI will strongly encourage women and members of other under-represented minority groups to apply for the<br\/>travel grant.","title":"Support for the 43rd International Symposium on Microarchitecture","awardID":"1048509","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["550974"],"PO":["562984"]},"168785":{"abstract":"Spectral Graph Theory or Algebraic Graph Theory, as it is also known, is the study of the relationship between the eigenvalues and eigenvectors of graphs and their combinatorial properties. The project will focus on furthering our understanding of this relationship and exploit this understanding to design new and efficient algorithms. Included in this list of algorithmic problems will be fast and reliable linear system solvers and graph partitioners. These new algorithms will in turn be used to find better and more efficient algorithms for problems in image processing, medical imaging, machine learning, and linear and non-linear optimizations. Enabling technology will include linear-work or O(m log m)-work algorithms for computing extreme eigenvalues of symmetric diagonally dominate systems. The project will uses ideas and techniques from graph theory such as graph sparsifiers, graph cuts, and Steiner trees. These graph theoretic ideas will be combined with numerical methods such as Krylov subspaces methods, interior point methods, and preconditioning methods to design and analyze these new algorithms. When possible, code for the basic algorithms and their applications will be made available over the web to researchers.<br\/><br\/>The use of Spectral Graph Theory in computer science applications has become increasingly important and popular. A notable application is the algorithm patented by Google to rank order web pages. Other applications include image processing, in particular, medical image segmentation and denoising. This project will further contribute to the design of better algorithms for these problem domains by combining the best ideas from numerical analysis and graph theory. The goal is to design algorithms with very strong guarantees for both run time and robustness so that these algorithms will be appropriate for critical applications such as real-time image processing in a clinician's office. Dissemination will not only include journal and conference publications, but also giving a biannual spectral graph theory class and spectral graph theory lectures in both undergraduate and graduate algorithm classes.","title":"AF: Small: Algorithm Design Using Spectral Graph Theory","awardID":"1018463","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[451749,"475261","501921"],"PO":["565251"]},"176166":{"abstract":"A workshop titled \"Pervasive Computing and Smart Environments with Applications\" is being proposed, to be held in the Fall of 2010. The goals of the workshop are to foster the continued emergence of smart environment design; to define challenging and beneficial applications of pervasive computing and smart environment; and to identify key research areas in pervasive computing and smart environment design that will support and challenge this growing field. <br\/><br\/>The workshop will consist of four long and approximately thirty short invited talks, three panel \/ discussion sessions, and two breakout sessions. Invited talks will provide perspectives on the field from funding agencies, from industry, and from leading academic research labs. Attendees will use the breakout sessions to discuss issues and brainstorm ideas related to embedded devices, new networking and middleware paradigms, interfaces and modes of interactions, and application of technology to smart grids, social networking, health care, and beyond. An outcome of the workshop will be a set of steps to recommend that NSF take to nurture the maturing and transformation of this field. Following the meeting a report will be prepared that summarizes the workshop and details the recommendations. This report will be provided to NSF and posted on the NSF web site.","title":"NeTS: NSF Workshop Proposal on Pervasive Computing and Smart Environments with Applications","awardID":"1059280","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["547675","529645"],"PO":["557315"]},"168433":{"abstract":"Current AI systems still lack the knowledge and reasoning <br\/>abilities needed to handle the semantic subtleties of language <br\/>and the thematic breadth of human discourse and thinking.<br\/>This project is developing a basic repertoire of lexical and<br\/>other general knowledge for use in a powerful inference engine <br\/>(EPILOG) designed expressly to support unrestricted language <br\/>understanding and reasoning.<br\/><br\/>The methods being employed exploit the insights into language-based<br\/>inference gained in recent years in the area of \"natural Logic\",<br\/>which makes systematic use of word-level and structural entailment<br\/>properties of language. These are easily modeled in EPILOG, which<br\/>uses a language-like meaning representation (Episodic Logic). Some<br\/>very general semantic properties are being manually encoded, and in <br\/>addition, large numbers of knowledge items are being extracted<br\/>computationally from lexical resources such as WordNet and VerbNet,<br\/>and from word similarity or paraphrase clusters derived from large <br\/>text corpora.<br\/><br\/>The expected result is a knowledge base of fundamental lexical and<br\/>other commonsense knowledge that will allow demonstration of many<br\/>previously infeasible language-based inferences, including both <br\/>forward and backward reasoning and many multi-premise entailment <br\/>inferences in existing test suites. This will significantly <br\/>advance the state of the art in basic language understanding and <br\/>in mechanizing \"obvious inferences\", with potential applications <br\/>to intelligent dialogue-based agents (for question answering, <br\/>tutoring, personal assistance, etc.), and to knowledge bootstrapping <br\/>through machine reading. The results will be disseminated both <br\/>through papers at conferences and in journals, and through web sites <br\/>making available EPILOG and the newly developed knowledge bases.","title":"RI: Small: Adapting a Natural Logic Reasoning Platform to the Task of Entailment Inference","awardID":"1016735","effectiveDate":"2010-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[450916],"PO":["565215"]},"168554":{"abstract":"Voice-processing systems that perform speaker verification, keyword spotting, speech recognition, etc. need complete access to the speech signal, albeit in parameterized form. These data could potentially be logged for future playback, analysis or even malicious activities and represent a threat to the privacy and security of users. This project aims to develop techniques that enable some key voice processing tasks, namely speaker identification or verification and keyword spotting, while preserving the privacy of the speaker?s voice. The techniques will perform their operations without observing any intelligible form of the speech signal from which one could glean any information about the speaker or what they said; yet at the end of the computation the results, which will only be delivered to an authorized party, will be indistinguishable from those that would be obtained if the system were not secured in this manner.<br\/><br\/>The proposed work draws upon approaches from cryptography and secure multiparty computation. It is explained how these techniques can be used to devise privacy-preserving algorithms for voice processing, and the development of such algorithms for the three problems mentioned, speaker identification and verification and keyword spotting, has been proposed.<br\/><br\/>For further information see http:\/\/mlsp.cs.cmu.edu\/projects\/secureaudio","title":"III: Small: Privacy Preserving Techniques for Speech Processing","awardID":"1017256","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[451194],"PO":["562974"]},"168466":{"abstract":"Algorithmic game theory is a field that uses and extends tools from economics and game theory to reason about fundamental computer science problems and applications. The PI will pursue a broad research agenda across three central subfields of algorithmic game theory. The first set of goals is to develop general analysis frameworks that can identify robust guarantees on the worst-case inefficiency of equilibria, and to consider measures of inefficiency other than the quality of a worst-case Nash equilibrium. The second set of goals concern developing novel worst-case analysis frameworks to inform the design of incentive-compatible auctions for revenue-maximization problems. The final goal is to apply computational complexity theory to explain rigorously certain barriers in economics and game theory, in particular in optimal mechanism design and in equilibrium computation.","title":"AF: Small: Frontiers in Algorithmic Game Theory","awardID":"1016885","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["516879"],"PO":["565251"]},"168587":{"abstract":"Abstract<br\/><br\/>Sensor networks are interactive collections of distributed devices that interface the virtual and physical worlds. Among the tasks needed to implement these interfaces is the inference of properties of the physical world using observations collected by the network. Inference tasks cover a vast range, particular examples being estimation of rainfall in an orchard, or tracking the surface salinity of the ocean. <br\/>This project develops an integrated framework for distributed statistical inference of dynamic processes using sensor networks. The ultimate goal is to impact on the numerous activities that stand to benefit from the development of sensor networks, including economic sectors like manufacture, agriculture, and environmental management. <br\/>Further impact is expected from the incorporation of research results in undergraduate classes.<br\/><br\/>This project advances the use of prices to mediate the incorporation of global knowledge into local estimates. Many problems in dynamic statistical inference require solution of optimization problems, prompting formulations whereby estimates are viewed as economic outputs to be maximized. The global optimization that would result from the action of a centralized agent is regarded as a social resource optimization problem. Local estimates computed by individual sensors are the result of selfish actions of market agents. Prices are introduced to align social and agents? interest. While these ideas have been successfully pursued in static environments, this project pursues them in dynamic settings. The research cuts horizontally across different dynamic statistical inference problems and is vertically organized into: <br\/>(i) Determination of convergence properties of price mediation algorithms. (ii) Resolution of memory growth problems through manipulation of price structures. (iii) Practical considerations including robustness, convergence speed, and communication effects (iv) Integration with learning algorithms for problems with incomplete model information.","title":"CIF: SMALL: Distributed Statistical Inference of Dynamic Systems with Sensor Networks","awardID":"1017454","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":["541883"],"PO":["564898"]},"168598":{"abstract":"Online social networks now provide a view of social interactions that is unmatched in scale, granularity and - equally important - amenability to automated analysis. However, only a small fraction of our social capital is spent online; moreover, online networks are typically only a re&#64258;ection of richer, causative networks that govern our everyday interactions - relationships typically &#64257;rst develop of&#64258;ine. The aim of this proposal is to bring the full power of automated data-driven understanding to bear on the - arguably more important - social networks in the real world. The research will develop a scalable sensor-tag based infrastructure that measures co-locations of participants by dynamically pairing participants with tags and extract genuine interactions from mere colocations via theory of structure learning in Markov Random Fields. The research will characterize network properties (like subgroups, clustering and small worlds), and node properties (like centrality and in&#64258;uence) and capture the natural evolution of participant interactions via the theory of compressed sensing with sequential observations. <br\/><br\/>The techniques pioneered in this proposal will significantly advance our ability to obtain a meaningful data-driven understanding of social networks in the real world. Industry interaction will inform this research from the beginning, via established industry partnerships at UT Austin. Student involvement, both undergraduate and graduate, lies at the core of this research, providing a natural venue to introduce under-represented groups to networking research. Social networks provide a naturally engaging subject to introduce high-school students to engineering and networks, which the PIs will do via talks in area schools.","title":"NetSE: Small: Social Networks in the Real World: From Sensing to Structure Analysis","awardID":"1017525","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["560222","550745"],"PO":["565136"]},"168488":{"abstract":"In large-scale computer systems, component failures are no longer rare events. As the scale of the systems continues to increase, their reliability and service availability become an increasingly critical concern. Recent IT expenditure analyses also show that the worldwide spending in server management and administration has surpassed the cost of new server acquisition. Conventional reactive trouble-shooting measures and conservative check-pointing approaches are often counter-productive or may cause a long time service disruption. The goal of this FEMA project is to develop modeling and analytical methodologies and tools to characterize the systems failure dynamics for proactive failure management in highly dependable systems.<br\/><br\/>This FEMA project is carried out in three aspects. First is the development of an aggregated spherical covariance model that characterizes the failure dynamics quantitatively. The model centers on a failure signature concept that correlates a group of OS-level performance parameters and operation-level job allocation information to different types of fault events in both space and time domains. Second is an innovative application of statistical learning methods for failure prediction. Different failures types in different system scopes have different failure dynamics and different amount of history data for training; different prediction metrics pose different requirements for prediction granularity. Various supervised, unsupervised, and reinforcement learning algorithms find their applications in different scenarios. Third is the development of system reliability traces for offline evaluation and a methodology for online prediction in production systems. The trace not only contains a log of failure events, but also their corresponding operational contexts that are necessary for attaining high prediction accuracy.","title":"SHF: Small: Failure Events Modeling and Analysis for Proactive Management in Highly Dependable Systems","awardID":"1016966","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[451038],"PO":["565272"]},"168279":{"abstract":"This project is investigating the following three research problems concerning knowledge extraction and data mining from real-time stream systems:<br\/><br\/>Novel Framework for Stream Mining Systems: <br\/>The project is studying how to formalize the problem of large scale distributed knowledge extraction from high volume streams by defining appropriate local and end-to-end objective functions, along with resource and delay constraints that will guide the different optimization and adaptation algorithms. <br\/><br\/>Topology construction: <br\/>The project is studying methods to organize classifiers into a connected topology mapped onto a distributed infrastructure. The research starts by studying linear chains of classifiers and then seeks to extend the work to multiple chains working in parallel, and to classifier trees.<br\/><br\/>Decentralized Solutions based on Interactive Multi-Agent Learning: <br\/>For large scale stream mining systems, where the classifiers are distributed across multiple nodes, the project is developing a decentralized decision framework and distributed algorithms for joint topology construction and local classifier configuration. In such distributed scenarios, optimizing the end-to-end performance requires interactive, multi-agent solutions to be deployed at each site in order to determine the effect of each classifier's decisions on the other classifiers.","title":"CSR: Small: Dynamic Construction and Configuration of Classifier Topologies for Real-time Stream Mining Systems","awardID":"1016081","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558132"],"PO":["565255"]},"172690":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040689","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["495285","466565","502829","438934"],"PO":["565090"]},"170084":{"abstract":"In this project, the investigators study the fundamental aspects of<br\/>incorporating uncertainty with sensitivity analysis in the visual<br\/>analytics process. They also aim to develop novel and scalable<br\/>visual representations of sensitivity, from the visualization of the<br\/>raw sensitivity coefficients to visual summaries of multivariate<br\/>derivatives obtained from the analysis. Uncertainty-aware visual<br\/>analytics helps enhance analysts' confidence levels on the insight<br\/>gained from the analysis. Furthermore, it gives toolmakers a<br\/>methodology for measuring and comparing the robustness of<br\/>data and visual transformations. Sensitivity coefficients of data and<br\/>visual transformations are useful for discovering the factors that mostly<br\/>contribute to output variability, identifying stability regions of the<br\/>different transformations within the original data space, and<br\/>telling the analyst what the interaction is between variables,<br\/>outputs and transformations.<br\/><br\/>Uncertainty is introduced throughout the process of data generation,<br\/>transformation, and analysis in most real-world applications. The ability to<br\/>incorporate uncertainty into visual analysis is therefore critically important<br\/>for insightful reasoning and key decision making. This project will have a<br\/>wide-reaching impact on those areas relying on the ability to reason<br\/>about large amounts of data. On one hand, it suggests to provide a variational<br\/>view of the visual analytics process, which opens up new directions and<br\/>paradigms for visual data analysis and mining. On the other hand,<br\/>the improved understanding of the visual analytics process will help<br\/>establish the field as a scientific discipline.","title":"Modeling the Uncertainty Due to Data\/Visual Transformations Using Sensitivity Analysis","awardID":"1025269","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["552243",455232],"PO":["562984"]},"174330":{"abstract":"Systems in which people and computers work together in a socially intelligent manner represent a new form of computing that brings together the challenges of traditional computing (e.g., algorithms, information representation, information acquisition, data quality) with those of human interaction (e.g., cognition, social interaction, culture, learning) and indeed a whole host of new challenges related to the combination of humans and computers (e.g., computer reasoning about human knowledge and abilities, socially-intelligent human-computer interaction, social computing). <br\/><br\/>This award supports a Doctoral Symposium (DS), June 9, 2011 for graduate students who are developing SoCS related research topics. Doctoral students pursing SoCS research face numerous challenges, including defining research that spans computing and human elements, but also identifying meaningful evaluation for their research (often in the absence of close precedents) and positioning their research to fulfill the requirements of disciplinary dissertation committees. The doctoral symposium will help students hone their dissertation projects so that they can make better contributions to the solution of these intellectual challenges, and also help them build a social network of fellow doctoral students and more senior researchers to support their careers.<br\/><br\/>There are both short and long-term benefits from this work. In the short term, the DS will provide significant feedback to the students selected to participate in the DS. In the long-term, we expect that students who participate in the DS will help establish critical research trajectories for SoCS and SoCS related topics. Students who participate in the DS will be well positioned to provide feedback to their peers who may also be interested in SoCS topics.","title":"WORKSHOP: Social-Computational Systems (SoCS) Doctoral Symposium","awardID":"1049379","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["550380"],"PO":["564456"]},"163693":{"abstract":"This research involves design and building of a three-dimensional (3D) microarray device, with position-controlled microspheres, to perform simultaneous, efficient, and accurate screening of complementary DNAs, RNAs, and protein receptors on a single platform. This new device is portable, self-contained, automatic, and cost effective. Applications of this device include medical screening, drug discovery, and gene sequencing. In particular, it performs inexpensive disease diagnosis and provide insight into the molecular basis in different patients. <br\/><br\/>In existing 3D microarrays, microspheres are placed randomly within a substrate. This random placement of the microspheres makes their packing inefficient and their data processing complex. To overcome these drawbacks, the investigators design and build new microarrays with position-controlled microspheres. They analyze the statistical accuracy in estimating the target concentrations by computing performance bounds, and apply the results to select the minimal distance between the microspheres and the best operating temperature, while ensuring desired optimal estimation accuracy. The minimal microsphere distance enables high packing, and the optimal temperature reduces the cost. The investigators implement the position-controlled microarray using a microfluidic approach; particularly, they emplace the microspheres using a hydrodynamic trapping mechanism and using on-chip microvalves and pumps. The long-term goal is to integrate this device with image sensors, electronics, and optofluidic imaging to build a complete lab-on-a-chip system.","title":"CIF: IHCS: Medium: Collaborative Research: Design and Implementation of Position-Encoded 3D Microarrays","awardID":"0963717","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[438201,438202],"PO":["564898"]},"172163":{"abstract":"Intellectual Merit This travel grant supports approximately fifteen graduate students from United States institutions to attend the premier network protocol conference, the IEEE International Conference on Network Protocols (ICNP) 2010 which will be held in Kyoto Japan from October 5 through October 8, 2010. The objective of the award is to widen the audience attending ICNP and, as a result, raise the level of interactions among attendees, and increase the potential for new collaboration, new investigations, and higher quality research.<br\/><br\/>Broader Impacts. Conference attendance is a crucial part of the life of a researcher. By creating new opportunities for graduate students to attend this high-quality conference, this project will benefit the research community in several ways. The students benefit from the opportunity to meet and interact with many other researchers in a favorable setting, and from seeing research presented that may be related to what they are working on, or may inspire them to try a new direction. The research community benefits from the improvement of the students in the pipeline, and the introduction of new researcher perspectives. All attendees benefit from increased diversity of participants attending the conference, through discussions and other interactions.","title":"Student Travel Support for the 18th IEEE International Conference on Nework Protocols (ICNP), Kyoto, Japan - October 5-8, 2010","awardID":"1036856","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550639"],"PO":["565090"]},"174000":{"abstract":"This award is part of the Software Infrastructure for Sustained Innovation. The Office of Cyberinfrastructure, the Division of Computer and Network Systems, and the Division of Materials Research contribute funds to this award. <br\/><br\/>Developing large computational codes such as those used to perform simulations in quantum mechanics to calculate properties of materials, or to predict the aerodynamics forces around airplanes, still typically require several human-years. However the pace of research and industrial product development demands much more rapid software tool development to make progress and to remain competitive. This award contributes to developing the capability to rapidly create high performance large scale codes. <br\/><br\/>The PIs will augment a computer programming language with a very high level language that is interactive in the sense that the developer will enter language commands and get instantaneous interpreted answers, instead of processing the whole code. This approach of creating an interactive extensible language framework will provide a way to help speed development of large scale computer software. Efforts will be specifically targeted at software for materials science applications. This will enable progress in large scale computational research that aims to predict properties of materials starting from a knowledge of the constituent atoms and the way they are arranged in the material. <br\/><br\/>This award contributes to the education of knowledgeable specialists capable of developing large and complex computational codes. The PIs will design new graduate level courses outside of the current curriculum to increase the number of students who receive training in effective development of software for materials research and scientific computing in general. <br\/><br\/>This award also supports the research team's efforts to broaden participation of underrepresented groups through the existing Alice in Wonderland Program, which aims to recruit members of underrepresented groups at the high school level, and to attract female high school students to science and engineering by involving them in research over the summer before they make decisions about colleges. They will also revive the Summer Undergraduate Interns program to recruit undergraduate students interested in high performance computing for summer internships.","title":"SI2-SSE: Collaborative: Extensible Languages for Sustainable Development of High Performance Software in Materials Science","awardID":"1047961","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1712","name":"DMR SHORT TERM SUPPORT"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550000","544438"],"PO":["141355"]},"173032":{"abstract":"The University of North Carolina at Charlotte, in collaboration with Loyola College, proposes to engage diverse stakeholders to develop an Association of Computing Machinery Special Interest Group in Broadening Participation (ACM SIGBP) charter, submit a proposal to the ACM to establish a SIGBP, and support startup efforts of the SIGBP community. The SIG will provide a well-recognized, well-established, international community to support and strengthen the diverse array of initiatives for Broadening Participation in Computing (BPC). Broadening participation in computing requires multiple levels of inter-disciplinary collaboration among researchers, practitioners, educators and policy-makers from academia, industry, government, K-12 schools, and the non-profit sector within a variety of interests, including computing, psychology, sociology, ethnic and gender studies, education, and human resources. A plethora of BPC organizations, programs and initiatives exist. Although BPC communities are starting to coalesce, as with the NSF BPC alliances, a majority of initiatives are relatively isolated. The BPC research literature is scattered among journals and conferences within computing education, general education, and the social sciences. What is needed is an overarching BPC community to support and highlight the many existing BPC initiatives, and to drive the national BPC agenda by speaking for the community with one voice. This will provide opportunities for students seeking to participate, practices for practitioners to adopt, and a community for researchers seeking to collaborate. The ACM is the flagship international professional and scientific organization for computing. The ACM Special Interest Groups (SIGs) represent the major areas of computing. Each SIG forms a community that includes conferences, publications, and regional and global activities intended to advance knowledge and foster collaboration within computing areas. We seek to leverage the ACM SIG community structure to support an international BPC Community. The goal of the proposed ACM SIGBP Project is to strengthen, scale, and sustain efforts to broaden participation in computing by establishing an ACM SIGBP. Project outcomes include a) establishing an ACM SIGBP, b) increasing participation in existing BPC activities and organizations, c) increasing awareness among computing students of BPC opportunities, and d) increasing collaboration among existing BPC efforts nationally and internationally.","title":"Collaborative Research: BPC-LSA: ACM SIGBP: Forming an ACM Special Interest Group to Scale the Impact of BPC Activities","awardID":"1042372","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["464128"],"PO":["560704"]},"174363":{"abstract":"Systems in which people and computers work together in a socially intelligent manner represent a new form of computing that brings together the challenges of traditional computing (e.g., algorithms, information representation, information acquisition, data quality) with those of human interaction (e.g., cognition, social interaction, culture, learning) and indeed a whole host of new challenges related to the combination of humans and computers (e.g., computer reasoning about human knowledge and abilities, socially-intelligent human-computer interaction, social computing). <br\/><br\/>This award supports a workshop for researchers from the wide range of SoCS related disciplines. This SoCS community meeting (June 9-11, 2011) will provide the opportunity for researchers who are not currently involved in the SoCS program, but who are doing SoCS related research to engaged in critical cross-fertilizing discussions. This workshop is designed to build on and leverage two other SoCS related workshops that will be temporally and physically co-located.","title":"WORKSHOP: Social-Computational Systems (SoCS) Community Meeting","awardID":"1049455","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["518491"],"PO":["565342"]},"174374":{"abstract":"The security of the national computing infrastructure is critical for consumer confidence, protection of privacy, protection of valuable intellectual property, and even national security. Logic-based approaches to security have been gaining popularity, in part because they provide a precise way to describe and reason about the kinds of complexity found in real systems. Perhaps even more importantly, automated reasoning techniques can be used to assist users in navigating this complexity. Despite the promise of automated reasoning, its use in practical applications is still limited. One of the primary reasons for this is that for many problems, automated reasoning methods are not fast enough, especially for use in interactive environments (such as browser plug-ins in desktop computing, or mobile applications running on smart phones and PDAs). This project aims to address the performance weakness of automated reasoning by investigating novel designs and algorithms with the unifying theme of exploiting parallelism. The project will focus on three main areas of automated deduction: Boolean satisfiability, first-order reasoning, and satisfiability modulo theories.","title":"TC: EAGER: Collaborative Research: Parallel Automated Reasoning","awardID":"1049495","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550906"],"PO":["497499"]},"164463":{"abstract":"Volunteer Computing (VC) uses the computational resources of volunteers with Internet-connected PCs to address fundamental problems in science. Unfortunately, the largely white-male volunteers are not representative of the general population, and their involvement typically consists of nothing more than contributing idle computing resources. The demonstrated benefits to scientific discovery and the opportunity to engage a broad population motivate this project?s radical transformation of VC systems.<br\/><br\/>This work will build ExSciTecH, an interactive, easy-to-use VC system to Explore Science, Technology, and Health. The system will motivate and facilitate diverse volunteers to donate their intellectual and computational resources to VC projects. As a result, ExSciTecH will aid scientific discovery even as it develops a more scientifically informed and engaged citizenry. Supported by technologies such as the Nintendo Wii Remote controller and casual gaming, ExSciTecH will help volunteers discover how rewarding and exciting science can be.<br\/><br\/>Intellectual Merit: This project aims to increase the interest and participation of diverse populations in computer science in general and VC projects in particular, to build inclusive communities of diverse volunteers, and to increase the science delivered to scientists by Docking@Home, a VC project targeting the design of new drugs for breast cancer and HIV.<br\/><br\/>Broader Impact: ExSciTecH will be distributed through an established network of undergraduate computing programs that are dedicated to diversity in information technology. The National Center for Women and IT (NCWIT) has experience and resources for promoting and distributing practices that recruit and retain diverse populations.","title":"Collaborative Research: SoCS - ExSciTecH: An Interactive, Easy-to-Use Volunteer Computing System to Explore Science, Technology, and Health","awardID":"0968350","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["549918"],"PO":["565342"]},"177542":{"abstract":"CAREER: Novel Sampling Approaches for Protein Modeling Applications<br\/><br\/>Yaohang Li<br\/>North Carolina A&T State University<br\/><br\/>Accurately modeling protein or protein complex structure is considered a significant grand challenge that has broad economic and scientific impact. One of the key obstacles is the absence of a reliable sampling method that can efficiently explore the tremendously large protein conformation space. This CAREER project investigates efficient sampling approaches that can lead to prediction of high resolution protein structures with accuracy and reliability currently not achievable in computational protein modeling. The rationale is to integrate various physics- and knowledge-based scoring functions via multi-scoring functions sampling to explore the complex protein conformation space. The research work includes 1) establishing computational models for multi-scoring functions sampling in protein structure modeling with theoretically and mathematically rigorous justification; 2) designing novel sampling algorithms to efficiently explore large protein conformation space; 3) applying the sampling algorithms to important protein modeling applications including ab initio protein folding and protein-protein docking; and 4) developing a resource-efficient protein modeling programming paradigm.<br\/><br\/>The efficient sampling approaches developed in this research can be applied to a variety of important computational biology applications, which will provide a critical stepping stone toward reliable resolution improvement in protein models for practical use. Success of high resolution protein modeling will have significant impact on genomic study, disease research, bio-energy development, and the drug-design industry. In addition to its research impact, the educational goal of this CAREER project is to attract excellent students, particularly the minorities, to participate in computational biology research and pursue computational science career.","title":"CAREER: Novel Sampling Approaches for Protein Modeling Applications","awardID":"1066471","effectiveDate":"2010-09-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":["482837"],"PO":["565223"]},"175122":{"abstract":"The grant supports student travel for about twelve students to attend the 2010 ACM conference on Foundations of Software Engineering (FSE 2010), to be held November 7-11, 2010, in Santa Fe, New Mexico. Funds are requested to support the travel, meals, and lodging for student volunteers. The students will attend portions of the conference and serve as student volunteers. Attention will be paid to financial needs and under-represented groups. The opportunity to attend one of the premier conferences in Software Engineering is intended to provide experiences that may encourage students to pursue higher degrees in computer science research.","title":"CCF: Student Volunteer Scholarship: Broadening Participation through Student Volunteers at FSE","awardID":"1053540","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["548131"],"PO":["564388"]},"174154":{"abstract":"Parallel and Distributed Computing (PDC) now permeates most computing activities. The penetration of this technology in the daily lives has resulted in common users relying on its effectiveness and reliability. The mass marketing of multicores and general-purpose graphics processing units in home and office PCs and laptops has a potential for empowering even common users to become technology contributors. Certainly, it is no longer sufficient for even basic programmers to acquire only the conventional programming skills. All these phenomena point to the need for imparting a broad-based skill set in parallel and distributed computing at various levels, impacting Computer Science (CS) and Computer Engineering (CE) programs and related computational disciplines. However, the rapid change in computing hardware platforms and devices, languages, and supporting programming environments, and the research advances, more than ever challenges the educators in deciding what to teach in any given semester. Students and their future employers face similar challenges on what constitutes basic expertise.<br\/><br\/>Our vision is bringing all stakeholder experts working together and periodically providing guidance on restructuring standard curriculum across various courses and modules related to parallel and distributed computing. Immediate benefit would be providing CS\/CE students and their instructors with periodic guidelines on which aspects to cover in which courses. New programs at colleges (nationally and internationally) will receive guidance in setting up courses and\/or integrating parallelism in the Computer Science or Engineering or Computational Science curriculum. Employers would have well defined expectations from students on PDC skills. This will similarly help in retraining and certifications of existing professionals. As background preparation, a planning workshop was held in Feb 2010 to explore the state of curriculum in parallel and distributed education, assess the needs, provide action plans and recommend mechanisms for how best to address the curricular needs in both the short and long terms. The planning workshop and its related set of activities have drawn experts from various stakeholders.<br\/><br\/>The primary task is to propose a set of core topics in parallel and distributed computing for undergraduate curriculum for CS\/CE students. For various topics in the three sub-areas of Programming, Algorithms, and Architecture, the expected deliverables are (i) learning outcomes, (ii) level of coverage (Bloom's classification), and (iii) examples of how to teach each topic. In summer 2010, we aim to carry out a public release of preliminary curriculum, collect feedback from various stakeholders, and identify and recruit colleagues who will try out aspects the proposed curriculum during fall 2010 and spring 2011. Following these, during these two semesters, the activities will include monitoring and supporting the courses and feedback collection from instructors and students.<br\/><br\/>Our larger goal is to enable students to be fully prepared for their future careers in light of the technological shifts and mass marketing of multicores and GPUs and to make real impact on all the stakeholders including employers, authors, and educators. This curricular guidance and its trajectory, along with periodic feedback and other evaluation data on adoption and use, will also help steer companies hiring students and interns, hardware and software vendors, and, of course, the authors and researchers.","title":"A Curriculum Initiative on Parallel and Distributed Computing - Toward Core Topics for Undergraduates","awardID":"1048711","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7934","name":"PARAL\/DISTRIBUTED ALGORITHMS"}}],"PIcoPI":["526127"],"PO":["565251"]},"168720":{"abstract":"It is widely recognized that language impairment can have a negative effect on literacy skills, and that children suffering language impairment are at a higher risk of academic under-achievement and lower overall social development. Hence, early and accurate language assessment for children is critical, especially for those with non-mainstream linguistic backgrounds. Spontaneous language samples are commonly used in communication disorders to measure the speaker's competence across a range of complementary language skills. These elicitation tasks allow clinicians and clinical researchers to analyze speech fluency by looking at the patterns of disfluencies and other speech disruptions. Language productivity can be gauged by computing mean length of utterance, along with measures of vocabulary and total utterances produced. Morpho-syntactic skills can also be analyzed from these data, by manually coding for specific grammatical constructions that are known to signal developmental milestones. At present, use of the information contained in these language samples is restricted to the capacity of human experts to manually analyze the data, since little has been done to use computational models for this task In this collaborative effort by PIs in the University of Alabama at Birmingham and the University of Texas at Dallas, the objective is to address this problem by developing computational approaches for scoring samples from children along different language dimensions, including speech fluency, syntactic structure, content, and coherence, with the long term goal of building robust computational linguistic approaches for identifying language impairments in children. With these ends in mind, the PIs will investigate a number of core research questions, including measuring syntactic complexity in children's language, evaluating content in story retelling and play sessions, and detecting disfluencies in children's transcripts. Moreover, this research will focus on analyzing samples from children with three different language backgrounds: English monolinguals, Spanish monolinguals, and Spanish-English bilinguals of Mexican descent (the latter representing the fastest growing minority in this country). Since their models will be data driven, the PIs expect to be able to evaluate empirically the differences in developmental patterns of speech in children across these linguistic diversities. Addressing the bilingual population involves modeling code-switching behavior; thus, additional core research questions include measuring syntactic complexity in code-switched data, and identification and categorization of code-switching patterns in bilingual children. <br\/><br\/>Broader Impacts: This research will contribute to developing more accurate and practical tools for assessing language development in children, a field to which little attention has been paid to date. Addressing the challenges involved in the automated analysis of children's speech will also advance the field of Natural Language Processing (NLP) in general. Moreover, since the project involves children with three different linguistic backgrounds, the new technology will have low language dependency and so should be easily portable to other languages and domains. In the field of communication disorders, applying corpus-based approaches to language assessment is still in its infancy; project outcomes will have a direct impact on this field, by providing new metrics for scoring spontaneous language samples of children that can complement the battery of assessment tools currently used.","title":"HCC: Small: Collaborative Research: Analysis of Language Samples for Detecting Language Impairment in Monolingual and Bilingual Children","awardID":"1018124","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["562856"],"PO":["565227"]},"168841":{"abstract":"Many physical and logical networks, including the Internet, World Wide Web, and future ubiquitous wireless networks, have enormous size that can be regarded practically infinite. For example, the World Wide Web is estimated to have over 50 billion web pages. The huge networks are also extremely heterogeneous, both physically and in their technical\/social usage. They are expected to eventually merge into a complex, global socio-technical infrastructure.<br\/><br\/>To understand and reason about the enormous socio-technical networks, including methods for designing\/optimizing them, the traditional network analysis and modeling approaches are insufficient, due to their limited scalability. Simulation is only feasible up to a limited network size. Conventional analysis methods, such as teletraffic theory, queuing network analysis etc., also quickly lose scalability in huge networks. At the same time, modeling and analysis is still indispensable, since one may not be able to experiment with various new solutions via large scale practical deployment, due to prohibitive cost.<br\/><br\/>This situation, in which one deals with networks of practically infinite size, has naturally led to the emergence of novel analysis and modeling approaches. They can generally be characterized as having a more abstract, \"bird's eye\" view of the network and often relying on asymptotic analysis on the mathematical side. This project focuses on network models that describe and analyze the network using the mathematical methodology of random graph models. A large and diverse set of such models have been proposed and analyzed, but there is a lack of unified methodology. This methodological gap is what primarily motivates this work.<br\/><br\/>Intellectual Merit<br\/>The project will fill the above described methodological gap and will develop general methods that can usefully apply to many different network models. Specifically, the project will pursue the following directions:<br\/><br\/>-Exploring connections and implications among model properties that are valid for large classes of network models, not just for a single model. <br\/><br\/>-Finding methods that provide useful model-independent bounds and approximations for various properties within large model classes.<br\/><br\/>Broader Impact <br\/>The project will strengthen the cross-fertilizing effect between networking and graph theory, in particular, the theory of random graph models, potentially impacting both fields. The PI has experience in both areas, which provides an ideal position to generate meaningful interaction to overcome current limitations. The educational side of the project also has a non-conventional component: beyond integrating the subject into graduate courses, the project will include student competitions to motivate students for developing creative new modeling ideas.","title":"NetSE: Small: Analysis and Modeling of Very Large Networks","awardID":"1018760","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":[451890],"PO":["564993"]},"175133":{"abstract":"The research plan of this project consists of two main tasks:<br\/><br\/>In the first task, the PIs are developing a formal proof-theoretic framework to ensure that the partition management protocols (which results in the elasticity of cloud computing systems) are correct. The PIs will then use this framework to analyze the partition management functionalities of two representative systems: BigTable (equivalently HBase) and Yahoo?s PNUTS. The PIs will also validate the functionality of the storage subsystem in Google GFS and Hadoop HDFS to ensure that the read and write operations at the file system level indeed satisfy the stated invariants. The PIs will then extend this study to ensure that the atomicity of operations on a single key-value pair indeed are atomic and durable irrespective to the size of the value attribute.<br\/><br\/>In the second task, the PIs will investigate more stringent levels of data and object consistency in cloud computing systems. In particular, the PIs will develop a distributed implementation of snapshot isolation and evaluate its effectiveness in cloud computing environments primarily with respect to elasticity and scalability. Also, the PIs will put all the pieces together (with their associated invariants) and evaluate if the overall system thus formed is correct. Moreover, the PIs will formalize the characteristics of different replica management protocols to identify the limit of data availability in various cloud computing environments.","title":"NSF EAGER: From a Virtualized Computing Nucleus to a Cloud Computing Universe","awardID":"1053594","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["536696","500153"],"PO":["565255"]},"164485":{"abstract":"The NSF-funded project conducted by Kevin Crowston at Syracuse University will investigate the capabilities and potential of social-computational support systems in the context of citizen science, defined as \"partnerships between volunteers and scientists that answer real-world questions\". The research will examine nature of the computational systems currently used in a number of citizen science projects and will use these insights to improve computational support for different kinds of citizen science projects. The project will focus on the following three goals: (1) developing a practical understanding of the conditions under which social computation can enhance science and education; (2) generating new research models of social-computational systems that support large-scale public participation in scientific research; and (3) developing and testing social-computational systems that incorporate explicit knowledge about human cognitive and social abilities.<br\/><br\/>The project will produce societal benefits by investigating how involving the public in scientific research can advance scientific goals while contributing to the science education of the volunteer participants, determining the conditions under which citizen science can prove beneficial for large-scale data collection and analysis, and providing guidelines for improving the design and implementation of computational support systems for citizen science projects.","title":"SOCS: Socially Intelligent Computing to Support Citizen Science","awardID":"0968470","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["464413","565342"],"PO":["565215"]},"168610":{"abstract":"Combinatorial Algorithms and Structure in Phylogeny: A Chordal Graph Approach <br\/>NSF:CCF 1017580<br\/>PI: Dan Gusfield, UC Davis<br\/> The evolutionary history of a set of organisms is described by a tree called an evolutionary, or phylogenetic tree. Such trees display fundamental, evolutionary relationships between organisms, and are also used to display information and relationships outside of the field of evolution. as well. The Multi-State Perfect Phylogeny (MPP) problem is a computational and mathematical problem arising from the construction of such evolutionary trees. The MPP problem addresses the need to represent rich, multi-state properties of data in phylogenetic trees, rather than properties that only have two states (for example, present or absent). The MPP problem was initially defined in a 1974 paper that established a deep mathematical relationship between it and a subfield of the mathematical field called ``graph theory''. Graph theory is the study of collections of points and lines; the subfield of graph theory that is related to the MPP problem is called Chordal Graph Theory. Although the connection between the MPP problem and chordal graph theory has been known since 1974, that connection has not been widely used in the development of algorithms for the computational solution of the MPP problem and extensions of the MPP problem. <br\/>This project focuses on exploiting and extending recent advances in chordal graph theory to develop practical computational methods to solve Multi-State Perfect Phylogeny problems and extensions of those problems. Building on recent work in the literature on chordal graph theory, the project will obtain new graph theoretic results for the MPP problem, and will use those mathematical results to obtain practical algorithms for MPP problems. This is a rare situation where a deep, elegant mathematical and algorithmic framework is available and appropriate for the study of an applied algorithmic problem. The project combines research in computer science algorithms, graph theory, and discrete optimization theory to produce effective means for reconstructing evolutionary histories, and for understanding the underlying mathematical structure of such histories. This theoretical work will be accompanied by the development of a suite of software tools that will be made available for other researchers interested in studying chordal graphs, MPP problems, treewidth problems, and related problems.","title":"AF: Small: Combinatorial Algorithms and Structure in Phylogeny: A Chordal Graph Approach","awardID":"1017580","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":["518691"],"PO":["565223"]},"168731":{"abstract":"Traditional information theory investigates transmission problems from a physical layer perspective. Information theory aims to determine largest achievable communication rates between transmitters and receivers for a given physical communication channel. In the simplified source-channel-destination model, information-theoretic approaches assume the availability of an infinite number of bits at the transmitters before the transmission starts. The burstiness of the arrivals and the associated issue of delay are mostly ignored. In contrast, network theory gives sophisticated analysis of network layer issues, such as random arrivals and network delay. However, in network-theoretic approaches, the underlying physical layer model is usually very simplified, e.g., in most approaches simultaneous transmissions are not allowed, and even when they are allowed, a collision channel model is used, which is far too simplistic to capture what can be achieved in the physical layer from an information-theoretic perspective.<br\/>This project aims to develop a fundamental understanding for the issue of delay in networks, and design transmission methods and scheduling algorithms to minimize delay in network communications. Towards this goal, this project combines techniques from information theory, network theory, queueing theory and optimization theory. The investigators use information-theoretic techniques to improve the underlying information carrying rates, together with queueing- and network-theoretic tools to allocate these rates to network users considering external arrival rates and current queue sizes. Further, the investigators incorporate physical layer phenomena such as fading (enabling opportunistic transmissions) and overheard information (enabling cooperation) into this development. In addition, in networking applications where nodes are able to harvest energy from nature, the investigators consider the interactions between the random packet arrivals and the random energy arrivals (through harvesting) to nodes, in designing the transmission and scheduling mechanisms.","title":"NetSE: Small: Delay Minimization in Wireless Networks","awardID":"1018185","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["548269"],"PO":["564924"]},"168621":{"abstract":"Joint source-channel coding and decoding techniques are rapidly emerging as important design tools for the complexity- and latency-constrained transmission systems that underlie the multimedia revolution. In such scenarios these techniques have the potential to offer the same performance with less complexity or delay compared with systems which completely separate the source and channel coding functions. The investigators develop theoretical insights and practical approaches into the construction of joint source-channel codes by addressing certain classes of optimal variable-length error correcting codes and their application to networks. The insights gained by these studies facilitates new advanced coding strategies as well as a fundamental theory that guides the design of future wireless and multimedia systems. <br\/><br\/>One approach to joint source-channel coding is to consider prefix condition codes which have an inherent source compression property and are in addition able to detect or correct errors resulting from noise on the communication channel. Thus, these codes typically require a smaller amount of redundancy than classical channel codes to achieve the same amount of error resilience. However, the current understanding of these codes remains rather limited which has led researchers to focus on heuristics. The investigators address these issues by tackling research problems in three interrelated directions. In particular, we (1) develop new minimum-redundancy variable-length codes with inherent error resilience properties and investigate issues related to their design and compression performance; (2) study the application of this family of codes to sensor and ad hoc networks and gain insight into their repercussions for higher communication layers; (3) investigate the construction of reversible variable-length codes including those with special error-correcting properties.","title":"CIF: Small: Collaborative Research: New Approaches to the Design of Joint Source-Channel Codes","awardID":"1017632","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["551001"],"PO":["564924"]},"168742":{"abstract":"The Environmental Protection Agency (EPA) estimates that energy consumption at data centers could grow to 100 billion KWhr, contributing to 2.9% of the total US electricity needs, by the year 2011. This project investigates fundamentally new techniques for building energy proportional storage systems that consume energy in proportion to the I\/O workload intensity. It takes the view that a carefully constructed data replication based approach (instead of data migration) combined with background data synchronization for consistency provide more effective mechanisms for enabling dynamic storage consolidation. Contributions of this project include:<br\/><br\/>(1) Energy proportional designs for both virtualized SAN (VSAN) and the replicated distributed file\/object system (DFS) storage architectures, <br\/><br\/>(2) Formal models of the energy proportionality problem for VSAN and DFS architectures and the development of algorithmic foundations for various sub-problems within this framework, and <br\/><br\/>(3) Novel techniques to control the I\/O performance impact during dynamic working set shifts and unexpected I\/O bursts under consolidation, scheduling strategies for background replica synchronization, and new models for estimating the performance of a given workload or a set of consolidated workloads on a specific storage system.<br\/><br\/>Given that servers within data centers operate at well below peak levels and that today's storage systems are composed of inherently non energy proportional disk devices, this project develops a key enabling technology for operating data centers more energy-efficiently. The creation and distribution of open source systems software will aid technology transfer.","title":"CSR: Small: Energy Proportional Storage Systems","awardID":"1018262","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[451640,"550842"],"PO":["565255"]},"165233":{"abstract":"The PI proposes algorithmic versions of the recent hypergraph regularity methods of Rodl, Schacht, Skokan and the PI, and of Gowers. For graphs, Szemeredi's Regularity Lemma was made algorithmic by Alon, Duke, Lefmann, Rodl and Yuster. For 3-uniform hypergraphs, Haxell, Rodl and the PI established an algorithmic hypergraph regularity lemma (compatible with a counting lemma). Using this work, Poerschke, Rodl, Schacht and the PI derived algorithmic 3-uniform versions of Gowers' regularity lemma and that of Frankl and Rodl. The PI proposes algorithmic k-uniform versions of each of these regularity lemmas. Moreover, the PI proposes that the three concepts of regularity considered by these sets of authors are all equivalent, which plays an important role in the development of the desired algorithm. It also plays an important role in the applications of such algorithmic regularity lemmas, since then it follows that all three regularity lemmas admit a corresponding counting lemma. The PI then proposes work on several algorithmic hypergraph problems. <br\/><br\/>Hypergraph regularity methods have lead to important solutions to quite a few problems across the areas of extremal combinatorics, theoretical computer science, number theory and discrete geometry. These methods have, in a strong sense, provided a general infrastructure for solving certain problems. An algorithmic version of the hypergraph regularity method would expand that infrastructure to constructive procedures for solving algorithmic hypergraph problems.","title":"Hypergraph regularity algorithms and applications","awardID":"1001781","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[442647],"PO":["565280"]},"176002":{"abstract":"This workshop is the third in a series of bi-lateral workshops focused on cooperation, collaboration and federation between GENI, a suite of network research infrastructure supported by NSF, and FIRE, a networking researchers' initiative supported by the European Commission. The first workshop was held in Madrid; the second one was held in Seattle. This one will take place in Brussels the 30 September and 1 October at the EU premises. The EC project FIREWorks is facilitating the event. Serge Fdida (EU) and Joe Evans (US) are serving as co-chairs. This proposal will support the travel costs of about 18 US researchers and developers to travel to Brussels to participate in the workshop.<br\/><br\/>The focus of the workshop will be on bilateral discussions between FIRE and GENI projects working in the same domains. Different themes are being identified for this bilateral dialogue in order to achieve in-depth technical exchanges and to define possible collaborations. These themes will include, for example, sensors, clouds, service architectures, smart cities, social networking, security, and network infrastructure. Ideally, these bilateral discussions will move collaborative efforts forward by identifying bilateral teams that will plan and develop cross-Atlantic experiments that utilize both GENI and FIRE infrastructure capabilities. The workshop will have impact in a number of ways. By building on complementary strengths, the collaborations envisioned here will enable both communities to accelerate and expand the horizons of networking and future Internet research. The workshop and the collaborations that come out of it provide for specific research and education opportunities in an international context.","title":"GENI-FIRE Workshop","awardID":"1058521","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["250082"],"PO":["564993"]},"168511":{"abstract":"Dynamic random access memory (DRAM) has been used as the main memory in computer systems for decades. However, DRAM technologies are facing both scalability and power issues. With the superior scalability, phase-change memory (PCM) has become an attractive DRAM alternative to implement high-capacity, ultra-dense main memory systems. Recent advances in nano-scale material engineering have also enabled fabricating phase change memory using nano-scale structures (e.g. nano-wire), which exhibit ultra-low programming power than the conventional thin-film based substrates. Although technology scaling and advanced material engineering provide smaller and denser devices, they make architecting reliable, power-efficient and high-performance phase change memory systems increasingly challenging. If left unattended, these challenges will soon become showstoppers of future phase change memory systems by either preventing them from scaling down to smaller feature sizes or resulting in the inefficient operation of these systems. This collaborative research project aims to improve the efficiency of phase change memory systems as the underlying processing technology scaling continues, including: (1) Cross-layer process variation characterization, modeling and mitigation for phase change memory (2) Nano-wire based PCM design exploration and (3) Resistance drift resilient phase change memory system. In addition, this project will develop a comprehensive full-system simulation infrastructure that consists of PCM device\/array\/architecture multi-scale models and architecture\/OS techniques that will allow the computer architecture design community to study the trade offs and optimizations of employing emerging phase change based memory systems in light of advanced process technology and material engineering. This collaborative research project will facilitate ultra-density, low-power and reliable phase change based non-volatile memory systems to most effectively leverage emerging nano-scale material and fabrication technologies to tackle the grand \"Memory Wall\" challenge faced in today's computer design community. It can greatly contribute to enabling high-performance computing to stay on track with its historic scaling as the number of CPU cores increases and workloads become more memory intensive, and hence benefit numerous real-life applications running from high-end servers to low-end embedded systems. This collaborative research project will also contribute to society through engaging under-represented groups, research infrastructure dissemination for education and training, and outreach to non-volatile memory design industries.","title":"SHF: Small: Collaborative Research: Architecting Technology Enabled Phase Change Memory Systems","awardID":"1017068","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["551083"],"PO":["565157"]},"168632":{"abstract":"Over the past two decades, Human-Computer Interaction (HCI) research has generated a broad range of interaction styles that move beyond the desktop into new physical and social contexts. Key areas of innovation in this respect are tabletop, tangible, and embodied user interfaces. These interaction styles leverage users' existing knowledge and skills of interaction with the real non-digital world, thus we refer to them as reality-based interfaces (RBI). RBIs offer a natural, intuitive, and often collaborative form of interaction that reduces the mental effort required to learn and operate a computational system. While these advances in HCI have been successfully applied to a broad range of application domains, little research has been devoted to investigating reality-based interaction in the context of scientific discovery. However, it is particularly important to study reality-based interaction in this context where reducing users' mental workload and supporting collaborative work could lead to new scientific discoveries. The goals of this research are to design, develop, and evaluate the benefits of a tabletop reality-based interface for collaborative exploration of heterogeneous genomic information. The investigation will focus on how tabletop reality-based interaction can support collaborative research and facilitate new discoveries. Specifically, the investigator will address two questions: What is the key computational functionality required to enable an effective use of a tabletop reality-based interface for genomic research? And, can reality-based interface improve users? work flow and facilitate the development of new biological insights?<br\/><br\/>This research program addresses a number of broader impacts. First, successful results of this project will foster collaboration and improve work flow in genomic research, thus, may lead to new scientific discoveries. This investigation will contribute a design, implementation and validation of a tabletop reality-based interface that supports collaborative genomic research, and a set of design requirements for supporting collaborative scientific discovery in areas where vast amounts of heterogeneous information is explored. Second, this project will train undergraduate female researchers, making them an integral part of the research team. Finally, the project will have a significant impact on three computing and science courses in a women?s college.","title":"RUI: IIS: HCC: Small Projects: Enhancing Genomic Exploration through Reality-Based Interaction","awardID":"1017693","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["534174"],"PO":["565227"]},"168874":{"abstract":"This project is developing and integrating statistical and symbolic methods of Artificial Intelligence in an agent architecture and evaluating the agent in a competitive domain, notably the real-time strategy game StarCraft. Real-time strategy (RTS) games provide several interesting research challenges including real-time decision making, enormous state spaces and imperfect information. StarCraft is a popular commercial RTS game that has several professional gaming leagues, and therefore ideal for evaluating the performance of AI agents. Professional StarCraft players reason about and react to strategic decisions at multiple levels of abstraction, sometimes executing over 300 game actions per minute, so developing competition-level StarCraft agents presents extraordinary challenges. <br\/><br\/>More specifically, the project is using novel supervised and unsupervised learning algorithms to automatically learn domain knowledge from collections of professional gameplay traces; the agent is being implemented within the reactive planning architecture ABL (A Behavior Language). The ABL reactive planner provides the glue for integrating multiple, heterogeneous reasoners within a real-time execution environment. <br\/><br\/>This work is expected to make significant contributions to the understanding of decision making processes in a complex, real-time domain. This understanding will contribute to the development of robust, intelligent systems that can be deployed within real-world environments. This work will motivate AI researchers to build integrated agent architectures. As a well-known game with very high-level professional play, research in StarCraft AI has the potential to attract significant attention to AI research. The StarCraft competition being hosted by our lab has attracted significant interest both within and outside academia, and at the high-school, undergraduate and graduate level. Thus, this work has the potential to raise general public awareness in research in human-level AI, and will encourage high-school students to pursue careers in computer science and game design.","title":"RI: Small: A Human-Level, Real-Time, Integrated Agent","awardID":"1018954","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["536596","536597"],"PO":["565035"]},"175287":{"abstract":"In a denial of service attack on a wireless sensor network, an attacker can cause the network nodes to perform useless work until they fully discharge their batteries. To defend against such attacks, each node in a wireless sensor network needs to view its action executions as moves in a game whose ultimate objective is two-fold: <br\/><br\/>First, the node needs to execute enough actions so that its reputation as a reliable node remains high between its neighboring nodes.<br\/><br\/>Second, the node needs to refrain from executing some actions in order to ensure that the lifetime of its battery remains long.<br\/><br\/>The PIs are working on constructing a utility function for this game and analyzing various ways in which the game can reach an equilibrium state, where the minimum battery discharges in the network are minimized and the node reputations remain high.","title":"EAGER: Incentivizing Cooperation in Wireless Sensor Networks for Prevention of DoS Attack using Minimum Battery Discharge: A Game Theoretic Approach","awardID":"1054492","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[470059,470060],"PO":["565255"]},"174198":{"abstract":"Abstract<br\/><br\/>Considerable work in computer graphics has gone into the realistic modeling and rendering of flames. Modeling and rendering the underlying wood combustion process has received some attention recently, but prior work has not incorporated effects of internal wood properties such as density variation (i.e. ?grain?) and pre-combustion processes such as drying. A concept called ?fiber bundles? is proposed that can realistically represent the structure of fibrous materials such as wood. Fiber bundles consist of an arbitrarily large number of almost-parallel, never-intersecting curves. Model properties at any point in space depend on (a) the curve that comes closest to that point and (b) the distance to that curve. Space is partitioned by the Voronoi volume of these curves. This is a new concept in graphical modeling and, if viable, would be transformative in the representation of both natural and synthetic fibrous materials, allowing for physically correct simulation. Significant issues arise in computing these fiber bundles and this research is designed to show that mathematical algorithms for processing fiber bundles can be developed and implemented in ways that are computationally viable in terms of both time and space efficiency.<br\/><br\/>If successful, the research can lead to improved new representation of fibrous materials. This will be applicable not only for wood combustion, but also wherever plants, plant materials, or synthetic fibers are modeled. The impact goes beyond the entertainment industry. It would, for example, provide essential predictive capabilities to design systems for fire engineering as well as for disaster planning and management.","title":"IIS (G&V) EAGER: Modeling and Rendering a Fibre Bundle","awardID":"1048873","effectiveDate":"2010-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[467324],"PO":["532791"]},"168643":{"abstract":"As the Web is playing a more and more important role in our lives,<br\/>it has become criminals' preferred targets. <br\/>Web-based vulnerabilities now outnumber traditional computer security <br\/>concerns. We believe that the root cause of many of these attacks<br\/>is the Web's current access control models: they are<br\/>fundamentally inadequate to satisfy the protection needs of today's web.<br\/><br\/>The objective of this project is to re-design the access control models<br\/>for the Web to fix the security problems at the fundamental level. <br\/>We target two essential components of the Web infrastructure: browser and database. <br\/>We have designed a generic access control model for web browsers<br\/>to enforce the browser-side access control needs of web<br\/>applications. The model replaces the web's current Same Origin Policy (SOP) model,<br\/>which is the culprit of many of the security problems. The success of this task <br\/>will help significantly reduce the number of security problems at the browser side.<br\/>We have also designed DAC-DB, a Discretionary <br\/>Access Control (DAC) model for database to automate the enforcement of DAC in<br\/>web applications. With this model, web application developers can be liberated <br\/>from implementing the complicated and error-prone security enforcement logics. <br\/>Both access control models are designed based on the well-established security principles.<br\/>To help disseminate our results, we will implement our designs <br\/>for open-source web browsers and databases, and persuade the web<br\/>community to adopt our models. The outcome of this research will also<br\/>be converted to hands-on labs to enhance students' learning in<br\/>system security.","title":"TC: Small: To Configure or to Implement, That is the Access Control Question for Web Applications","awardID":"1017771","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550133"],"PO":["562974"]},"168764":{"abstract":"The proposal aims at studying authorship flows in information diffusion in social media. The proposal takes an individual level approach to understanding diffusion and authorship flow as compared to existing macro level approaches. The proposed approach is to study the impact of factors such as the type of media format, the type of topics diffused and the valence of the information in information diffusion and authorship flow. An initial taxonomy will be used to classify the type of media format that may evolve with the study. Three models will be combined in the research. The dataset to be used large-scale blogs and tweets. If successful, the project can help to establish a theoretical foundation for understanding the diffusion and authority in digital media.","title":"HCC: III: Small: Diffusion and Ranking in Social Media: A Computational Examination of the Role of Influence and Authority","awardID":"1018361","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[451694,451695,"543580"],"PO":["564456"]},"167444":{"abstract":"Despite revolutionary advances in how images are recorded, manipulated, and reproduced, our ability to re-create the visual experience remains remarkably limited. Few realistic computer models exist for the characteristic appearance of natural materials such as marble, wood, coral, or skin, or man-made ones such as color-shifting automotive paints. Digitizing and creating realistic images of these substances involves reproducing their interaction with light: the way light is reflected from surfaces, or scattered and absorbed within the materials. Full reproducibility also involves \"printing\" a material as a real, physical object that modulates the light around us. However, it is currently impossible to output complex appearance the way we print color on a paper with fixed gloss, or create shapes using a 3D printer. This project encompasses a comprehensive, collaborative research agenda in computer graphics and related areas, to develop an end-to-end framework for acquiring, representing, and fabricating complex appearance, as well as to understand how it is perceived by the human visual system.<br\/><br\/>The enabling technical idea of the project is to treat materials as thin three-dimensional volumes populated with general scattering sites. This is a radical departure from the hitherto standard approach in computer graphics, which has studied materials purely as surfaces. The volumetric representation subsumes and generalizes the diverse set of conventional representations that currently exist in graphics, including surface-based notions such as bidirectional reflectance (BRDF), spatially varying BRDF, and subsurface scattering distributions (BSSRDF). Moreover, it enables fundamentally improved approaches to efficient yet general acquisition, fast and realistic rendering, and fabrication of objects exhibiting phenomena beyond simple surface reflectance and spatially homogeneous subsurface scattering.","title":"HCC: Large: Collaborative Research: Beyond Flat Images: Acquiring, Processing and Fabricating Visually Rich Material Appearance","awardID":"1011919","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[448639,"508159"],"PO":["565227"]},"168775":{"abstract":"This project investigates effective and resource efficient establishment of connectivity among disjoint wireless sensor network (WSN) segments. The segments can belong to a structurally damaged network caused by the failure of multiple sensor nodes. In addition, the segments can simply be standalone WSNs that are normally operated by different agencies and are to be federated to serve a common application. The objectives of this project are to develop novel solutions for various aspects and contexts of the federation problems, to create a prototype for validation and to share the results\/experience with application designers. <br\/><br\/>The technical approaches consider the availability of resources such as mobile sensors, mobile and static gateways and their count. Both optimal and heuristic solutions for repositioning of mobile sensors and placement of mobile gateways are studied to establish connectivity as well as achieving some desired performance (i.e., QoS). Finally, the results are validated via a real test-bed consisting of sensors and mobile robots. <br\/>This project will boost the effectiveness of many civil and scientific applications. Example of such applications include crisis management, where existing WSNs may suffer an extensive loss of nodes due to fire, flooding, debris, etc., or when the services of networks owned or controlled by different parties or agencies need to be aggregated to assess in search-and-rescue. The results are made available in various forms including archival publications, tutorials and web-based resources. The project is enriching the curricula at UMBC and SIUC through hands-on projects and attracting K-12 students via prototype demonstrations.","title":"NeTS: Small: Collaborative Research: Federating Disjoint Wireless Sensor Networks","awardID":"1018404","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550252"],"PO":["565303"]},"168423":{"abstract":"This project endeavors to develop novel computational representations for appearance modeling of physical materials for realistic computer graphics and machine vision applications by investigating spherical moments for modeling material appearance. Beyond the development of a novel theoretical framework for appearance modeling, the project involves evaluation of the generalization of the proposed appearance representation in various settings using software simulations as well using ground truth data available from various measurements. The project identifies three fundamental goals for such an appearance representation: application to general forward (reflectance modeling) and inverse (reflectance estimation) problems, appearance modeling in uncontrolled (lighting and viewpoint) settings, and validation and appearance classification for scene analysis applications. In particular, the analysis of higher order statistics for novel compact representations for forward simulation and inverse rendering problems are investigated. Additionally, appearance modeling from sparse input data acquired under general conditions of semi-controlled or uncontrolled lighting is investigated within this framework. Also investigated is the classification of material appearance from sparse measurements based on such spherical statistics. <br\/>This research has far-reaching impact beyond computer graphics in many fields such as architecture, engineering, science, fine art and entertainment. Besides providing new insights into appearance modeling, the developed theory allows rapid measurements with greater ease, making the results more accessible to other researchers and practitioners in the field. Besides mentoring a graduate student, the findings of the research are planned to be integrated into a graduate level computer science course offering and through the creation of internship opportunities for undergraduate students.","title":"RI: Small: Higher Order Statistics for Appearance","awardID":"1016703","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[450887,450888,"562850"],"PO":["564316"]},"168665":{"abstract":"This project seeks to develop tactile sensing technology that emulates many qualities of human skin. The goal is a sensor that can determine the texture and shape of objects that it touches, as well as the forces distributed across the surface. The new sensor is made of a block of clear elastomer, with a compliance similar to that of the human fingertip, covered with a flexible reflective skin. A small light source and a camera are embedded in the device. When an object contacts the skin, the surface is distorted, leading to a change in the reflected light pattern. Machine vision techniques convert the patterns into estimates of the forces on the skin. The project is testing a number of optical and mechanical designs, and is developing the corresponding image analysis techniques, in order to characterize and optimize the performance. Because the sensor is compliant, it can be built into a human-like robotic finger, providing gripping surfaces that are mechanically stable as well as highly sensitive. The new technology may also be useful in medical applications such as minimally invasive surgery, where it is important for the surgeon to sense the mechanical properties of the tissues that are being explored.","title":"RI: Small: High Resolution Tactile Sensing.","awardID":"1017862","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["508175",451454],"PO":["564316"]},"168786":{"abstract":"Wireless ad hoc networking has become a critical technology for nodes to communicate with each other in the absence of infrastructures such as base stations. It will be used in a variety of applications including wireless sensor networks, disaster recovery, and military on-the-field communications.<br\/>Significant advances have been made in the area of wireless ad hoc networking at all levels of the protocol stack, MAC, routing, congestion control, etc., with an eye toward configuring networks so as to optimize metrics such as capacity, connectivity, delay, etc. However, there remain numerous issues that have not been satisfactorily dealt with, ranging from identifying network configurations to optimize emerging security metrics, to how to effect various desirable network configurations: namely, how does an ad hoc network bootstrap itself to realize the promised performance and security? We address this question in our research. Specifically we focus on the following:<br\/><br\/>? Wireless network security: Characterize the tradeoff between performance and security in opportunistic wireless networks where eavesdroppers and\/or jammers are present, and develop algorithms for providing secure communication in such environments.<br\/><br\/>? Wireless Network configuration: Configure networks at the time of deployment, paying particular attention to facilitating the selection of \"friendly jammers\" and opportunistic relays as needed to enhance security.<br\/><br\/>The outcome of this research will constitute a significant advance in the development of theoretical foundations, practical algorithms, and network architecture for configuring and securing wireless networks.","title":"NeTS: Small: Design and Initialization of Secure Wireless Networks: Foundations and Practice","awardID":"1018464","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["545655","545656"],"PO":["557315"]},"168313":{"abstract":"Users rely on computers to save valuable data, with the expectation that the data will be available and accessible at any time. Consequently, storage and server systems have to provide stringent reliability guarantees. Many techniques - redundant data copies, multiple servers, and backup hardware - are employed in modern data centers to prevent data loss due to failures. However, these techniques consume more energy either to sustain additional hardware or to perform additional software tasks that keep disks busy longer. This poses trade-offs between using energy management and data reliability improvement - both of which are critical technologies that will direct the future of computer systems development. Thus, this project investigates the combined impact of energy efficiency and data reliability on storage systems. The utilization of a novel metric for capturing the energy-reliability interactions allows for designing optimization techniques that provide integrated reliability and energy management for modern storage systems. The results from this project are expected to lead to a better understanding of the interactions of energy management and reliability improvement techniques in storage systems, and to novel energy-efficient and reliable storage system organizations and designs that balance reliability and energy efficiency. The developed mechanisms will also enable further research in energy efficient and reliable systems at scale. Moreover, the project employs an integrated research and education approach for training both undergraduate and graduate researchers, especially from underrepresented groups. The training will instill critical system development skills and provide valuable learning opportunities in designing energy-efficient and reliable computer systems.","title":"DC: Small: Collaborative Research: Exploring Energy-Reliability Trade-offs in Data Storage Systems","awardID":"1016198","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["475180"],"PO":["564778"]},"167466":{"abstract":"Cooperation and Learning over Cognitive Networks<br\/>Studies on herding and self-organization in economics and the social and biological sciences have observed that coordination among multiple agents leads to regular patterns of behavior and swarm intelligence, even when each group member shows limited behavioral complexity. In ant colonies, for example, individual ants cannot capture rich spatial information from their environment because of their limited sensing ability. Nevertheless, when the ants coordinate their activities within a colony, the group ends up exhibiting better sensing abilities. Using signal processing and communications techniques, the research studies how and why such manifestations of rational and organized behavior arise at the group level from local interactions among agents with limited abilities, what communication topologies enable such behavior, and what type of signal processing enables such formations. <br\/><br\/>This research seeks to understand and reverse-engineer the distributed intelligence encountered in socio-economic-biological networks, by investigating relations with learning and rationality over cognitive networks. The latter are adaptive networks that avoid centralized information processing and perform in-network inference and control decisions. Cognitive networks contrast with networks that rely on centralized and parallel information fusion, which are not scalable, are hard to adapt to changing topologies, and suffer from points of vulnerability and information bottlenecks. The research considers large scale networks of agents and studies how global (rational or irrational) patterns of behavior emerge, including herds, contagions and bubbles in economics. An understanding of how the biotic environment influences collective behavior in animal societies provides a real world guide to good cognitive networks, which can be used in turn to design engineered systems. Cognitive networks have applications in areas ranging from precision agriculture, to environmental monitoring, disaster relief management, and smart spaces.","title":"CIF: Large: Collaborative Research: Cooperation and Learning Over Cognitive Networks","awardID":"1012029","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":[448690],"PO":["564898"]},"168797":{"abstract":"Despite sophisticated monitoring tools for runtime detection of intruders and techniques designed to protect computing systems from a wide range of attacks, attackers continually penetrate even well-protected systems. Attack data from real, large-scale production environments (National Center for Supercomputing Applications (NCSA) at Illinois, in this work) are used as a basis for characterizing and modeling attacker behavior and for uncovering deficiencies of the monitoring infrastructure. Increased understanding of attacks arising from these analysis and modeling activities significantly contributes to improvements in secure systems analysis and design. The analyses uncover new and realistic attack scenarios that can guide the design of enhancements to improve system protection against malicious activities at every level. Understanding real attack patterns and classes through detailed forensics pinpoints the open holes in a network\/system and characterizes attacker behavior. In-depth study of the data allows investigating actions and intentions of the attacker, and creates a foundation for the design of an automated tool to assist in data collection, analysis, and response. The size and variety of the data enable a flexible framework to be developed that can incorporate insights gained from attacks yet unseen.<br\/><br\/>This research produces sound methods for automated (semi-automated) analysis of large populations of data on security attacks and develops tools to facilitate the analysis and detection. The goals are to understand the attack patterns, establish comprehensive models to capture attacker behavior, and use the models to enable development of techniques for rapid detection of malicious tampering with the system.","title":"TC: Small: Data Driven Analysis of Security Attacks in Large Scale Systems","awardID":"1018503","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["557160",451783],"PO":["564223"]},"168698":{"abstract":"The behavior of a communications network depends on the configuration<br\/>of hundreds to thousands of switches, routers, firewalls, and other<br\/>devices. For example, a campus network may have as many as 2,000<br\/>inter-operating network devices and about one million lines of<br\/>configuration; whether the network operates correctly depends for the<br\/>most part on the configuration of these devices. Human configuration<br\/>errors are the single biggest contributor to network downtime. This<br\/>project seeks to develop techniques to make networks easier to manage<br\/>by improving both configuration testing and synthesis. Testing takes<br\/>as input an existing network configuration and determines whether the<br\/>configuration is operating correctly. Synthesis generates<br\/>configurations automatically. The project draws on two testing<br\/>techniques to make network configurations easier to test: differential<br\/>testing and dynamic testing. Differential testing generates test<br\/>cases to characterize the run-time behavior of two different programs;<br\/>analyzing differences in network-wide configurations can help testing<br\/>by allowing test cases to focus on the smaller subset of<br\/>configurations that change more frequently. Differential analysis may<br\/>make testing more tractable by reducing the amount of configuration to<br\/>test. Dynamic testing checks the correctness of a program by<br\/>executing it; this execution can be performed in a parallel \"shadow\"<br\/>network, for example. The expected results from this project include<br\/>tools for network operators to test and automatically generate<br\/>network-wide configurations for both enterprise and ISP networks. The<br\/>tools will also be useful in graduate-level courses.","title":"NeTS-Small: Collaborative Research: Network-Wide Configuration Testing and Synthesis","awardID":"1018021","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["561756"],"PO":["564993"]},"168346":{"abstract":"Current technologies have made it possible for submarines to evade standard sonar detection. Finding solutions to detect intruding submarines therefore becomes important and timely. A viable approach is to deploy magnetic or acoustic sensors in close proximity of possible underwater pathways intruders may pass through. This project seeks to develop a comprehensive theoretical and practical solution to construct undersea sensor networks for intrusion detection. When sensors are randomly deployed, spatial barriers are unlikely to exist, allowing intruders to pass through the bounded 3D space undetected. This motivates the use of mobile sensors to dynamically form sensor barriers. How to minimize the energy consumed by the movement of underwater sensors is a challenging issue. This project tackles the problem via three thrusts: (1) Develop an energy-efficient approach to using mobile sensors to construct a spatial barrier in 3D space; (2) Devise near-optimal practical solutions to reduce computation and communication costs, and develop these algorithms into practical protocols; and (3) Develop simulation modules and test-beds to evaluate the proposed solutions with realistic undersea environment parameters. The project integrates concepts and techniques in auction algorithms, geometry, combinatorial optimization, underwater acoustic communications and networking, software and system development to construct analytical models and practical solutions. The research results are expected to have a substantial impact on the understanding of constructing sensing barriers in underwater environments, and will be integrated into graduate and undergraduate teaching and outreach activities. Efforts will be also proactively pursued to recruit students from under-represented groups to participate in the project.","title":"NeTS: Small: Collaborative Research: Undersea Sensor Networks for Intrusion Detection: Foundations and Practice","awardID":"1016320","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[450698],"PO":["565303"]},"168599":{"abstract":"Social-networking sites (e.g., Facebook, MySpace, LinkedIn, etc.) and other online collaborative tools have emerged as places where people can post and share information. This information-sharing has many benefits, ranging from practical (e.g., sharing a business document) to purely social (e.g., communicating with distant friends). At the same time, information sharing inevitably poses significant threats to user privacy. In social-networking sites, for example, documented threats range from identity theft to digital stalking and personalized spam. As a result, a growing number of such sites allow individual users to specify fine-grained policies that indicate who can access their data, and to what extent. However, studies have consistently shown that most end-users find the task of specifying access-control policies for their own data overwhelming; as a result, users often skip the process altogether.<br\/><br\/><br\/>The goal of this project is to help collaborative and social-media users gain control of their data. To that end, the project will include three main components: assisted specification, feedback, and refinement recommendations. To assist users in initially specifying access-control policies for their data, the project will develop a \"privacy wizard,\" which employs data mining and machine learning methods, including active learning, to construct an accurate policy, with minimal input from the user. To provide feedback regarding existing privacy settings, the project will pursue two approaches: aggregate scores and visualizations. For example, an aggregate score can be used to concisely explain to the user how her settings differ from those of other users. Preliminary work found that Item Response Theory (IRT) can be used effectively for this purpose. Finally, the project will consider how aggregate scores and visual feedback can be enriched with recommendations for refinements to help the user achieve an expressed level of social exposure.<br\/><br\/>Online collaborative tools and social media offer great promise in a number of arenas. In addition to communicating with friends via social networking sites, collaborative tools are now used in fields as diverse as business, medicine and education. However, the absence of usable privacy and access control prevents such tools from realizing their full potential. Results of this project will be disseminated via prototype implementations, as well as research publications. New undergraduate and graduate curriculum modules will also increase awareness of the importance of policy-specification and emerging research in this area.","title":"TC: Small: Collaborative Research: User-centric Privacy Control for Collaborative Social Media","awardID":"1017529","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550882"],"PO":["565136"]},"168489":{"abstract":"For the past 20 years, CD-ROMs have been the primary media for distributing key economic, scientifi c, environmental, and societal data as well as educational and scholarly work. More than 150,000 titles have been published including thousands distributed by the United States and other governments. Yet no viable strategy has been developed to ensure that these materials will be accessible to future generations of scholars. In the short term, these materials are subject to physical degradation which will make them ultimately unreadable and, in the long-term, technological obsolescence will make their contents unusable. This project will develop practical techniques using off-the-shelf emulators with virtualization software to ensure long-term viability of CD-ROM materials. Although emulation has been widely discussed as a preservation strategy, it suffers from a fundamental flaw, since future users are unlikely to be familiar with legacy software environments and will find such software increasingly difficult to use. Furthermore the user communities of many such materials are sparse and distributed, thus any necessary technical knowledge is unlikely to be available to library patrons. The key objective of this project is to develop the technology and processes necessary to mitigate these flaws and to enable large-scale deployment of emulation by libraries and archives.<br\/><br\/>This project will develop automation technologies to capture the technical knowledge necessary to install and perform common actions with legacy CD-ROM materials in the form of scripts for performing on-the-fly customization of \\generic\" emulation environments. The long-term vision is to support a distributed CD-ROM collection, developed by a community of libraries, which enables client workstations to access preserved CD-ROM images through customized emulation environments. The project will explore the costs of developing the scripts necessary to automate the use of specific CD-ROMs and the technologies necessary to enable libraries to pool their resources to create a distributed network preserved CD-ROM materials.<br\/><br\/>The project is structured as a two-year pilot study that will develop automation tools, apply these tools to a large (several thousand representative set of CD-ROM materials, evaluate the performance of this approach in a distributed environment, disseminate the tools and scripts as software artifacts, and provide statistics for planning the large-scale preservation of CD-ROM materials. The research performed in this proposal will enable libraries and archives to solve a growing problem while reducing the resources required to maintain their collections of removable media. This project provides a foundation for libraries and archives to pool their intellectual resources by providing access to virtual media collections accessed through shared emulators using community generated scripts. The materials whose preservation will be enabled by this project include key scientific and societal data published by United States and other governments as well as cultural and educational materials from many sources. This project will have a significant impact on undergraduate science education by direct mentoring of undergraduate research assistants and providing the opportunity for their involvement in writing and presenting scholarly works.","title":"III: Small: Assisted Emulation for Digital Preservation","awardID":"1016967","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["565319","565242"],"PO":["565136"]},"172680":{"abstract":"While the Internet has far exceeded expectations, it has also stretched initial assumptions, often creating tussles that challenge its underlying communication model. Users and applications operate in terms of content, making it increasingly limiting and difficult to conform to IP's requirement to communicate by discovering and specifying location. To carry the Internet into the future, a conceptually simple yet transformational architectural shift is required, from today's focus on where ? addresses and hosts ? to what ? the content that users and applications care about.<br\/>This project investigates a potential new Internet architecture called Named Data Networking (NDN). NDN capitalizes on strengths ? and addresses weaknesses ? of the Internet's current host-based, point-to-point communication architecture in order to naturally accommodate emerging patterns of communication. By naming data instead of their location, NDN transforms data into a first-class entity. The current Internet secures the data container. NDN secures the contents, a design choice that decouples trust in data from trust in hosts, enabling several radically scalable communication mechanisms such as automatic caching to optimize bandwidth. The project studies the technical challenges that must be addressed to validate NDN as a future Internet architecture: routing scalability, fast forwarding, trust models, network security, content protection and privacy, and fundamental communication theory. The project uses end-to-end testbed deployments, simulation, and theoretical analysis to evaluate the proposed architecture, and is developing specifications and prototype implementations of NDN protocols and applications.","title":"FIA: Collaborative Research: Named Data Networking (NDN)","awardID":"1040643","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["522382"],"PO":["565090"]},"172581":{"abstract":"While the Internet has far exceeded expectations, it has also stretched initial assumptions, often creating tussles that challenge its underlying communication model. Users and applications operate in terms of content, making it increasingly limiting and difficult to conform to IP's requirement to communicate by discovering and specifying location. To carry the Internet into the future, a conceptually simple yet transformational architectural shift is required, from today's focus on where ? addresses and hosts ? to what ? the content that users and applications care about.<br\/>This project investigates a potential new Internet architecture called Named Data Networking (NDN). NDN capitalizes on strengths ? and addresses weaknesses ? of the Internet's current host-based, point-to-point communication architecture in order to naturally accommodate emerging patterns of communication. By naming data instead of their location, NDN transforms data into a first-class entity. The current Internet secures the data container. NDN secures the contents, a design choice that decouples trust in data from trust in hosts, enabling several radically scalable communication mechanisms such as automatic caching to optimize bandwidth. The project studies the technical challenges that must be addressed to validate NDN as a future Internet architecture: routing scalability, fast forwarding, trust models, network security, content protection and privacy, and fundamental communication theory. The project uses end-to-end testbed deployments, simulation, and theoretical analysis to evaluate the proposed architecture, and is developing specifications and prototype implementations of NDN protocols and applications.","title":"FIA: Collaborative Research: Named Data Networking (NDN)","awardID":"1040036","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["545336"],"PO":["565090"]},"173220":{"abstract":"Abstract <br\/><br\/>Careers in experimental science allow some researchers to push these frontiers of human knowledge to remote phenomena, from the formation of structure at cosmological scales to the self-assembly of protein enzymes. Non-experts have few channels to deeply experience these revelations due to several barriers: the time required to master technical details, the spatial distance to experts and educators, and the financial expense of careful experimentation. This research is creating a system that removes these barriers to scientific exploration for non-experts, in a frontier field that has attracted wide scientific and public interest: the engineering of nanoscale molecules into complex shapes. <br\/><br\/>An internet-scale gaming infrastructure is being created that will enable hundreds of thousands of game players to jointly explore the conformational space of ribonucleic acid (RNA) designs. As players explore a simulated RNA design space, their efforts produce a prioritized list of candidate designs which are synthesized immediately in the PI?s biochemistry lab. Experimental results then feed back into the game?s incentive structure. The players? collective efforts thus move beyond simulation into real biochemical experimentation. Also, it is currently unknown how to maximally exploit the ?network effect? of cooperation in multiplayer search games. Successful designs must both reward individual exploration and incentivize knowledge sharing. To unite these goals, the PIs are experimenting with several advances in collaborative scoring. Thus, within the new field of nano-engineering, the system will enhance the toolkit of RNA sequences that self-assemble into complex three-dimensional shapes from the ?bottom-up?: knots, polyhedra, and additional novel shapes never before seen with RNA. The project is producing advances in the nascent field of socially intelligent computing.","title":"EAGER: Collaborative Research: G&V: Evolving Social Computation in an RNA World","awardID":"1043251","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[464610],"PO":["532791"]},"171295":{"abstract":"All mobile organisms spend much of their lives searching for something, be it food, water, shelter, or others of their kind. Searching uses perception, memory, cognition, and action. It can occur over vast landscapes and periods of time, as in whale migration behaviors. It can occur in under a second on the basis of fleeting bits of sensory evidence, as in frogs searching their visual fields for flies. And it occurs on all scales in between, across organisms but also across different behaviors of a given organism. Human search is especially diverse in this regard because human searches range from subatomic to human to cosmic scales of exploration.<br\/><br\/>With support from the National Science Foundation, Dr. Christopher Kello is leading a team of researchers at the University of California, Merced, in the study of human search behaviors in three very different but complementary domains: Foraging over large virtual spaces, visual searches over scenes and movies, and memory searches over words and concepts. The generality and evolutionary importance of search suggests that search functions may share common principles across scales and domains. Evidence for this conjecture has been found in \"Levy distributions\" that describe the frequencies with which segments of different lengths occur in search paths. These frequencies are observed to obey a common scaling law across a wide range of different search behaviors but current evidence is not sufficient to determine the meaning of this law.<br\/><br\/>With mentorship from three faculty members in Cognitive and Information Sciences, undergraduate and graduate students and a postdoctoral fellow will collaborate on experiments and computational models in each of the three domains of interest, in a unique and highly interdisciplinary education and research experience.","title":"Levy Distributions in Foraging Games, Scene Perception, and Semantic Memory","awardID":"1031903","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["294423",458613,"543484"],"PO":["563458"]},"175420":{"abstract":"Recently, there has been a growing disparity between processor and memory speeds; this disparity is called the ?memory wall? problem. Memory performance has a dominating effect on overall system performance, especially for the data-dominated applications. Also, memory usually occupies half of the surface of the integrated chip of the multi-core system; the total amount of memory required is also a main contributor of the manufacturing cost and the chip size of the multi-core CPU. Memory also dictates the power consumption, since memories and buses consume large quantities of energy. The ?memory wall? problem becomes even more serious when throughput in the processor part is propelled by multi-core architectures.<br\/><br\/>In this proposal, the PI is carrying out research to address the ?memory wall? problem and to develop potentially transformative approaches for memory hierarchy design and configuration in multi-core systems. Different memory architectures can lead to different solutions with different costs and with different performances. Memory size, memory configuration, and memory architecture will be optimized simultaneously for multi-core architectures in order to effectively and efficiently achieve higher performance.","title":"EAGER: The Exploration of Memory Hierarchy Design and Optimization for Multi-core Systems","awardID":"1055290","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[470338],"PO":["565255"]},"174452":{"abstract":"This research investigates the usability of a number of remote voting platforms that are among the most viable candidates for fielding as states begin to consider the implementation of remote voting. The main focus of these usability studies is on the use of impoverished-display handheld mobile computers (i.e. smartphones) and traditional landline telephony interfaces delivered using interactive voice response systems, although vote-by-mail, kiosk, personal PC and hybrid systems are also being studied. Usability is being measured using the usability metrics outlined in ISO 9241-11 (effectiveness, efficiency, satisfaction) in order to establish usability baselines for these kinds of remote voting technologies and allow for direct comparisons to usability metrics that have been established for current precinct-based voting systems. This investigation is also aimed at gaining an understanding of the human factors issues that might impact the ability of voters to accurately and successfully cast their ballots with these potential new platforms. Results from these studies will play an important role in helping voting officials make better informed decisions about the kinds of technologies to consider and the attendant human factors issues as states begin to legislate the adoption of remote voting.","title":"Usability of Voting Systems","awardID":"1049723","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[467978],"PO":["499958"]},"175200":{"abstract":"The award is to support the series of workshops on security in emerging areas that are affiliated with the 2010 ACM Conference on Computer and Communications Security (CCS), and will be held on October 4 to 8, 2010 in Chicago, IL. <br\/><br\/>The annual ACM Computer and Communications Security Conference is a leading international forum for information security researchers, practitioners, developers, and users to explore cutting-edge ideas and results, and to exchange techniques, tools and experiences. Since year 2001, CCS started accommodating series of workshops to explore security issues in a variety of emerging areas. CCS workshops quickly become active forums for researchers to form focus groups, discuss and collaborate on emerging and critical security problems, and disseminate fresh, revolutionary (and sometimes even controversial) ideas. These workshops also serve as natural venues to bring together researchers from multiple disciplines to address security issues in specific domains, such as health care, cloud computing and national critical infrastructures.","title":"CCS Workshops Organization Supplement","awardID":"1054001","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548254"],"PO":["565327"]},"173022":{"abstract":"The University of North Carolina at Charlotte, in collaboration with Loyola College, proposes to engage diverse stakeholders to develop an Association of Computing Machinery Special Interest Group in Broadening Participation (ACM SIGBP) charter, submit a proposal to the ACM to establish a SIGBP, and support startup efforts of the SIGBP community. The SIG will provide a well-recognized, well-established, international community to support and strengthen the diverse array of initiatives for Broadening Participation in Computing (BPC). Broadening participation in computing requires multiple levels of inter-disciplinary collaboration among researchers, practitioners, educators and policy-makers from academia, industry, government, K-12 schools, and the non-profit sector within a variety of interests, including computing, psychology, sociology, ethnic and gender studies, education, and human resources. A plethora of BPC organizations, programs and initiatives exist. Although BPC communities are starting to coalesce, as with the NSF BPC alliances, a majority of initiatives are relatively isolated. The BPC research literature is scattered among journals and conferences within computing education, general education, and the social sciences. What is needed is an overarching BPC community to support and highlight the many existing BPC initiatives, and to drive the national BPC agenda by speaking for the community with one voice. This will provide opportunities for students seeking to participate, practices for practitioners to adopt, and a community for researchers seeking to collaborate. The ACM is the flagship international professional and scientific organization for computing. The ACM Special Interest Groups (SIGs) represent the major areas of computing. Each SIG forms a community that includes conferences, publications, and regional and global activities intended to advance knowledge and foster collaboration within computing areas. We seek to leverage the ACM SIG community structure to support an international BPC Community. The goal of the proposed ACM SIGBP Project is to strengthen, scale, and sustain efforts to broaden participation in computing by establishing an ACM SIGBP. Project outcomes include a) establishing an ACM SIGBP, b) increasing participation in existing BPC activities and organizations, c) increasing awareness among computing students of BPC opportunities, and d) increasing collaboration among existing BPC efforts nationally and internationally.","title":"Collaborative Research: BPC-LSA: ACM SIGBP: Forming an ACM Special Interest Group to Scale the Impact of BPC Activities","awardID":"1042337","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":[464068],"PO":["560704"]},"174001":{"abstract":"Scripting languages are lightweight, dynamic computer programming languages designed to maximize productivity by offering high-level abstractions and reducing syntactic overhead. Scripting languages strive to optimize programmer time, rather than machine time, which is desirable early in the software life cycle. However, they lose their appeal when requirements stabilize and projects enter their deployment phase. The compromises made to reduce development time make it hard to scale to large data sets or to get the needed speed to perform computationally intensive tasks. This is certainly the case for the R scripting language and its development environment. R is an extremely powerful tool for Biostatistics practitioners. Over the years, it has grown to become a mainstay for statistical computing in the life sciences. This project's goal is to build an execution environment for the R programming language, which we call ReactoR, with particular emphasis on improving scalability for real-world applications in the life sciences. The proposed work will yield an implementation of R which delivers performance comparable to compiled native code and lets developers write code without having to resort to low-level intrinsics. This virtual machine will include a trace-based compiler for generating native code for the most frequently executed routines and a concurrent garbage collector to decrease footprint.","title":"SI2-SSE: A Tracing Virtual Machine for Statistical Computing","awardID":"1047962","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7552","name":"COFFES"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["549800","536497"],"PO":["564388"]},"168820":{"abstract":"The design processes used to convert algorithms to hardware implementations have obeyed the axiom that the specification and implementation need to be equivalent in a Boolean or numerical sense. However, algorithms from several interesting application domains exhibit the property of ?inherent resilience?, thereby offering entirely new avenues for performance and power optimization by relaxing the requirement of an exact equivalent implementation.<br\/><br\/>We explore scalable effort hardware design as an approach to tap the reservoir of inherent resilience and translate it into highly efficient hardware implementations. We identify mechanisms at each level of design abstraction (circuit, micro-architecture and algorithm) that can be used to vary the computational effort expended towards generation of the correct (exact) result, and expose them as control knobs in the implementation to achieve improved energy efficiency. Fully exploiting the potential of algorithmic resilience requires synergistic cross-layer optimization of scaling mechanisms at different levels of design abstraction. We investigate the nature of the tradeoffs that are possible through cross-layer optimization of scaling mechanisms, and develop techniques to determine the optimal operating point (in terms of the different scaling mechanisms) that maximizes performance or energy efficiency for any given level of output quality.<br\/><br\/>The proposed research will develop new design approaches that can enable unprecedented levels of performance and energy efficiency in hardware implementations of emerging applications such as recognition and mining. We will disseminate our results through publications, release of open source designs, integration into VLSI Design and System-on-Chip course material, and through Purdue?s nanoHub.","title":"CSR: Small: Scalable Effort Design: Exploiting Algorithmic Resilience for Energy Efficiency","awardID":"1018621","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["551012","551013"],"PO":["565255"]},"174265":{"abstract":"Future networks will be heterogeneous and they will need to be scalable, highly controllable, and secure. These future heterogeneous networks will have multiple modalities (wired, wireless, satellite) and range from low (100?s of b\/s) to ultra-high user data rates (over 100 Gb\/s). Major challenges facing the deployment of such networks include; the coordination of the widely different data rates offered by different subnets to the users, efficient support of heterogeneous voice, video and data services with several orders spread in transaction sizes and rates, and the development of a common set of protocols that works across disparate networks with very different physical layer attributes. This workshop brings together investigators to discuss the research and development activities needed to enable the end-to-end, scalable, highly controllable, secure heterogeneous networks of the future. This activity is of interest to the Large Scale Networking Coordinating Group (LSN) of the Networking and Information Technology Research and Development (NITRD) interagency community.","title":"NSF Workshop on: Highly Controllable Dynamic Heterogeneous Networking","awardID":"1049123","effectiveDate":"2010-09-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["483597"],"PO":["564993"]},"174386":{"abstract":"This travel support enables U.S.-based students to attend the 18th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (SIGSPATIAL), held in San Jose, California, USA, November 2-5, 2010 (http:\/\/acmgis2010.cs.ucsb.edu\/). <br\/><br\/>The ACM SIGSPATIAL GIS conference has established itself as the world?s premier conference to foster research in the areas of Spatial Data and Analysis and Geographic Information Systems (GIS). The conference provides a forum for original research contributions covering all conceptual, design, and implementation aspects of GIS ranging from applications, user interfaces, and visualization to storage management and indexing issues. It brings together researchers, developers, users, and practitioners carrying out research and development in novel systems based on geo-spatial data and knowledge, and fostering interdisciplinary discussions and research in all aspects of GIS. It is the premier annual event of the ACM Special Interest Group on Spatial Information (ACM SIGSPATIAL). The conference seeks to continuously advance the state of-the-art in spatial data management and spatial data analysis and broaden its impact. <br\/><br\/>This grant provides partial travel support and conference registration for 20-25 qualified U.S. based graduate and promising undergraduate student participants. The students will greatly benefit from attending this conference, as they will be able to partake in the current state-of-the-art in the area of geo-spatial systems and applications, present their work, and potentially make connections for research collaborations and research mentoring. The total number of ACM SIGSPATIAL GIS participants in the past has been in excess of 250 participants, with a majority of the participants from the U.S., followed by Europe and Asia. The conference participation has shown a steady increase in the past few years due to the growing importance of geographic information. A strong representation of U.S.-based graduate students at ACM SIGSPATIAL GIS is useful in maintaining U.S. competitiveness in the important research areas crucial for U.S. infrastructures and applications that critically depend on geo-referenced information.","title":"US-Based Students Support to Attend the ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems 2010 (ACM SIGSPATIAL GIS 2010)","awardID":"1049534","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["536696"],"PO":["563751"]},"168710":{"abstract":"Embedded systems of collaborating agents that are capable of interacting with their environments are becoming ubiquitous. These systems must be able to adapt to the dynamic and uncertain characteristics of an open environment based on the priority of tasks, availability of resources, and availability of alternative ways of satisfying these tasks, as well as tasks expected in the future. The project is developing a framework and supporting algorithms for multi-agent meta-level control, which will determine when adaptation should be done and how much effort should be invested in adaptation as opposed to continuing with the current action plan. In particular, the meta-level framework will support coordinating decentralized Markov Decision Processes and views this coordination as a global optimization problem that bootstraps from individual agent learning and vice-versa. The framework will be demonstrated in a real-world multi-agent tornado tracking application called NetRads.","title":"RI: Small: A Hybrid Approach For Meta-Level Control Across Agent Boundaries","awardID":"1018067","effectiveDate":"2010-09-15","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["545120"],"PO":["564316"]},"168831":{"abstract":"Controlling Uncertainty: On the Sequential Refinement of Belief<br\/>This research focuses on a variety of information acquisition and sensing applications in which a<br\/>decision maker, by carefully controlling a sequence of actions with uncertain outcomes,<br\/>dynamically refines his belief about a phenomenon of interest in a speedy, accurate, and efficient<br\/>manner. The model includes a class of applications in communications, design of experiments,<br\/>cognitive science, and sensor management. In particular, the following three problems are<br\/>tackled.<br\/>? Active Sequential Hypothesis Testing: There are a set of hypotheses, one of which is true. A<br\/>decision maker is asked to identify the correct hypothesis by sequentially employing either one<br\/>of available sensing actions. Actions costs differently and produce statistically distinct<br\/>observations. Given a penalty for error in declaration, the work investigates the optimal<br\/>selection of sensing actions.<br\/>? Feedback Schemes for Joint Source-Channel Coding with Bandwidth Expansion: A message is<br\/>to be conveyed to a receiver over a noisy memoryless channel with feedback. The expected<br\/>distortion between the message and the receiver?s construction is sought to be minimized over<br\/>the choice of causal encoding functions as well as the decoding function.<br\/>? Joint Source-Channel Coding over a Multiple Access Channel with Feedback: Multiple<br\/>transmitters convey messages to a common receiver over a noisy memoryless multiple access<br\/>channel with perfect output feedback.<br\/>These problems boil down to the sequential control of a dynamical system whose system is the<br\/>conditional distribution of the unknown (true hypothesis, message, etc) and whose dynamics is<br\/>dictated by the Bayes? rule. In particular, the optimal choice of actions, i.e. refinement in the<br\/>conditional distribution and reduction of uncertainty, is investigated.","title":"CIF: Small: Controlling Uncertainty: On the Sequential Refinement of Belief","awardID":"1018722","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":["553607"],"PO":["564898"]},"176212":{"abstract":"Distributed applications require coordination between multiple nodes in a network, and they need to continue to operate correctly despite node failures. Implementation of such applications benefits from the availability of distributed primitives for commonly used distributed operations, such as clock synchronization or consensus. While most of the past distributed applications have traditionally used wired networks, there is an emerging trend towards the use of wireless networks for distributed applications.<br\/><br\/>The focus of this interdisciplinary project is on design, analysis and implementation of distributed primitives for wireless networks. In wireless networks, the network capacity is often quite limited. This project explores the design of efficient algorithms for distributed primitives under network capacity constraints, while exploiting wireless network capabilities such as local broadcast and physical layer adaptation. The scope of the project includes network-constrained distributed primitives for synchronization, consensus and function computation. Expected results from the project include theoretical bounds on performance of distributed primitives under network capacity constraints, design of efficient algorithms for the primitives, and practical implementations based on insights gained from the theory. Outcomes from the project are expected to allow efficient implementation of future distributed applications in resource-constrained wireless networks. The project brings together networking and distributed systems viewpoints, and is expected to yield fundamental new insights of interest to both areas. The research outcomes from this project will be disseminated via publications in technical conferences and journals, and incorporated into distributed computing and wireless networking courses.","title":"EAGER: Network-Constrained Distributed Primitives","awardID":"1059540","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["553537"],"PO":["557315"]},"168600":{"abstract":"This project proposes an efficient solution to parallel event-driven simulation of digital designs described in a hardware description language (HDL). It is based on a novel concept of spatial parallelism using accurate prediction of input and output signals of individual modules, derived from a model at a higher abstraction level. Using the predicted rather than actual signal values makes it possible to eliminate the need for communication and synchronization between the simulators. The simulation process consists of two phases: 1) Each local simulation is executed using the predicted input, so that no communication and synchronization cost is incurred for exchanging data with other local simulations. Each local simulation stores the results at periodic checkpoints and compares the computed output with the predicted output, to make the correction later, if necessary. 2) If the comparison fails, each local simulation rolls back to the nearest checkpoint to be executed with the actual inputs coming from other modules. This requires exchanging data with other simulations and introduces undesired communication and synchronization overhead. Each local simulation compares the actual input with the predicted input, and if the number of matches exceeds the predetermined threshold, the simulation is switched back to the prediction phase 1. The proposed method is applicable to massively parallel computing platforms and can work with any commercial event-driven HDL simulator.<br\/><br\/><br\/>Successful implementation of the proposed method for parallel event-driven HDL simulation will have profound effect on the way dynamic, simulation-based verification is carried out in academia and in industry. It will benefit researchers and all sectors of industry that deal with the design of systems on chip (SoC). It will significantly increase designer productivity in developing and testing complex SoCs, shorten the time to market, lower design development cost and consumer prices. It will fuel the development of other areas of technology, such as multi-core platforms, parallel processors, etc. It will also affect EDA industry developing verification tools ? with new innovative verification tool, automated verification flow and methodology.","title":"SHF: Small: Advances in Distributed Spatial-Parallel Event-Driven HDL Simulation","awardID":"1017530","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["550433"],"PO":["562984"]},"168721":{"abstract":"There are various instances of problems where correlated sources need to be transmitted from remote sources to a set of terminals, e.g., large scale sensor networks and distributed data storage systems. The field of distributed source coding considers coding strategies that leverage the correlation between the sources in a distributed manner while allowing the information to be communicated at a bitrate as low as possible to the terminals. This research studies practical coding schemes for the general distributed source coding problem.<br\/><br\/>The vast majority of prior work in this area considers the case of two binary sources, or a higher number of sources with small alphabets and restrictive correlation structures. This research investigates novel constructions of distributed source codes based on Reed Solomon (RS) codes. Consecutive realizations of the nonbinary sources are viewed as coefficients of polynomials over a finite field. Each source encoder transmits evaluations of this polynomial at certain points from the field. Source recovery at the terminal is performed by multivariate polynomial interpolation with carefully chosen root multiplicities, followed by factorization. The multiplicity matrices allow us to capture the joint likelihood of the different source sequences in the decoding process, while ensuring that the decoding is tractable. The scheme is designed for multiple nonbinary sources. Corner points of the rate region for sources with arbitrary correlation are expected to be achieved in this manner. For general rate points, the approach will be extended for a large class of correlation structures that generalizes the set of structures that can be handled by current state of the art techniques.<br\/><br\/>The research is integrated into the graduate\/undergraduate curriculum and into senior-design at appropriate levels.","title":"CIF: Small: An Algebraic Approach to Distributed Source Coding","awardID":"1018148","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["550838"],"PO":["564924"]},"168611":{"abstract":"Application protocol parsing, the translation of raw packet flows into higher level flows of semantic content, is the foundation and enabler of a wide variety of current and future networking services such as network security, application-aware load balancing, content-aware networking, and vulnerability based signature checking. A key feature of application protocol parsing is the controlled extraction of specific data within such a high level flow for further processing. <br\/>A fundamentally new framework for application protocol parsing and field extraction, FlowSifter is under development. To achieve practical application protocol parsing and efficient field extraction suitable for high speed networking devices that process millions of concurrent flows, FlowSifter performs automated selective stackless approximate parsing. <br\/>The new formal language theory models such as counting automata are applied to achieve the research goals. Specifically, FlowSifter allows a user to specify application protocols as well as the desired fields to be extracted using a modified regular grammar. FlowSifter turns the modified regular grammar into a counting automata to perform the approximate, selective, and approximate field extraction with controlled error bounds. <br\/>Expected results of this project include the new formal language theory models and the comprehensive FlowSifter framework. Research results are broadly disseminated through publications, open source software releases, freely available course modules, and industry interaction. The development of FlowSifter benefits society by enabling the future deployment of potentially transformative security and networking services such as vulnerability based signature checking for detecting polymorphic worms in network intrusion detection\/prevention systems (IDSes\/IPSes) and content-aware networking.","title":"NeTS: Small: Grammar Aware High-Speed Application Protocol Parsing for Deep Flow Inspection","awardID":"1017588","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562295","562296"],"PO":["564993"]},"167522":{"abstract":"Across many fields of science, engineering, and business, massive data sets are being generated at unprecedented rate by high-bandwidth sensors and cameras, large-scale simulations, or web-enabled large scale data collection. Much of this data has a geometric character, either directly or indirectly. For example, second generation LiDARs can map the earth's surface at 15-20 cm resolution; the Large Synoptic Telescope is set to produce about 30 terabytes of data each night; thirteen hours of video are uploaded to YouTube every minute; Facebook manages over 40 billion photos requiring more than one petabyte of data.<br\/><br\/>These data sets provide tremendous opportunities to enable novel capabilities that were unimaginable a few years ago. Capitalizing on these opportunities, however, and transforming these massive amounts of heterogeneous data into useful information for vastly different types of applications and users requires solving challenging algorithmic problems. An effective way of addressing this challenge is by designing efficient methods for producing informative yet succinct summaries of such geometric data sets. These summaries must work at multiple scales, and allow a wide variety of queries to be answered approximately but efficiently. The goal of this project is to study the theoretical underpinnings of compact representations and efficient algorithms for organizing, summarizing, cross-correlating, interlinking, and querying large distributed geometric data sets.<br\/><br\/>This project will design methods for computing summaries of many kinds of flavors, all with provable properties. Summaries can be combinatorial and metric (core sets and kernels), algebraic (linear sketches), topological (persistence diagrams), feature-based, and structural (encoding self-similarities in the data). The properties they aim to capture extend from low-level metric attributes, such as the diameter or width of a point set, to higher-level attributes revealing the internal structure of the data, as in the detection of symmetries and repeated patterns. This processing must be done in the presence of uncertainty in data coming from sensors, and optimize multiple performance measures, including communication cost for data distributed across multiple locations in a network. Another key aspect of this project is that it aims to understand not individual data sets in isolation but rather the inter-relationships and correspondences among different data sets, and to do so by communicating only summary information, without even having all the data in one place. <br\/><br\/>This work touches upon many topics in theoretical computer science and applied mathematics including low-distortion embeddings, compressive sensing, transportation metrics, spectral graph theory or harmonic analysis, machine learning, and computational topology.","title":"AF: Large: Collaborative Research: Compact Representations and Efficient Algorithms for Distributed Geometric Data","awardID":"1012254","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":["554177"],"PO":["565157"]},"168501":{"abstract":"Network coding brings the promise of increased wireless network capacity by decreasing the overall number of<br\/>transmissions. In practice however, many challenges remain in realizing the gains from network coding. In particular<br\/>the interactions between network coding and transmission rate control have not been carefully studied to date.<br\/>While transmission at higher rates favor a capacity increase, they can diminish overhearing possibilities, a key requirement<br\/>of network coding.<br\/>This proposal considers the problem of transmission rate control and network coding in a holistic<br\/>way. A framework that examines the interdependencies between the use of network coding and multiple transmission<br\/>rates with respect to various functions spanning the link and routing layers, is developed.<br\/><br\/><br\/>The following tasks are being undertaken: (i) Design a network-coding aware transmission rate control module<br\/>that allows nodes to transmit at the high bit rates while at the same time facilitating network coding.<br\/>(ii) Design a set of functions at the link and routing layers that provide the best trade-offs between applying<br\/>network coding and controlling interference and network congestion<br\/>(iii) Implement and extensively evaluate a unified framework combining all of our functional modules on wireless testbeds.<br\/><br\/>The proposed research is tightly knit with new education programs by establishing wireless teaching<br\/>laboratories and introduce cross-disciplinary courses that bridge the physical and higher layers.","title":"NeTS: Small : Collaborative Research: Harnessing Network Coding Gains in Multi-Rate Wireless Networks","awardID":"1017012","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550738"],"PO":["557315"]},"168864":{"abstract":"Performing network security applications such as malware detection, rule-based network intrusion detection, and covert channel detection at very high network line rates (10 Gbps now and soon scaling up to 40 to 100 Gbps) is critical to safeguarding enterprise networks. In this research project, we are investigating the applicability of MPPA (Massively Parallel Processing Array) architectures to scale packet processing and analysis tasks to meet the security challenges presented by next generation high-speed networks. Building upon our preliminary work, we are investigating parallel implementations of algorithms that are required in many different network security applications. These include 1) the K-means clustering algorithm used in traffic classification, 2) the entropy computation algorithm used in anomaly detection, 3) pattern matching used in rule-based network intrusion detection, and 4) encryption and decryption acceleration engines. We are investigate how these algorithms can be parallelized in a MPPA architecture with a large number of processors with limited memory and how the programmable processor interconnect can be leveraged to optimize the parallel implementation of algorithms. We are pursuing an experimental approach by building a testbed system to support both network traffic based and trace driven analyses. Through our research we expect to quantify the ability of MPPA architectures to scale data intensive computations for higher and higher line rates. The parallel algorithms and the implementation of the network security applications will be made available to other researchers. It is expected that graduate and undergraduate students involved in this project will obtain training in areas intersecting computer networks security, signal processing, and parallel processing.","title":"DC: Small: Scaling the Performance of Network Security Applications Using Massively Parallel Processing Array (MPPA) Architectures","awardID":"1018886","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["541428","485983"],"PO":["535244"]},"167775":{"abstract":"The research objective of this award is realization of Networked Mobile Assistive Systems (NMASs) that allow people to receive physical assistance and rehabilitation treatments anywhere, at any time with feedback regarding adequacy and appropriateness of training. The approach taken will consist of two major elements: a body-sensor network and a highly reliable wireless network. Most of the data acquired from a body-sensor network and the algorithms for the control of mobile power assistive devices will be stored on a host server, and users will access the system with any portable computer while receiving appropriate assistance and rehabilitation treatment. The networked systems will also allow doctors to observe the stored information without compromising the important, sensitive personal interactions between the provider and the patient.<br\/><br\/>If successful, the benefits of this research will contribute to the improved quality of life for physically impaired people (young or old) who have problems with community mobility and specific gait limitations. It will also provide a powerful tool to physical therapists in the treatment of patients. The project team consists of two PI's from Mechanical Engineering and Computer Science and a consultant from Physical Therapy. This team uniquely links engineering with clinical applications. The interdisciplinary research opportunities will be made available to engineering students and students in physical therapy. The Center for Information Technology Research in the Interest of Society (CITRIS) at the University of California, Berkeley provides a unique environment and opportunity to the team to interact and share research findings with other researchers and students.<br\/><br\/>The project is an Interdisciplinary Research (IDR) Project jointly funded by ENG\/CMMI and CISE\/CNS.","title":"IDR\/Collaborative Research: Monitoring and Mobility Assistance with Wireless Body Sensor Network and Mechatronic Actuation","awardID":"1013657","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1639","name":"SENSORS AND SENSING SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7951","name":"ENG INTERDISC RES (IDR)"}}],"PIcoPI":["496112"],"PO":["564949"]},"168633":{"abstract":"In the past two years we have observed an explosion in the use of online message streams. With an abundance of information comes information overload and a scarcity of attention: Active message stream users now face thousands of unread messages every day in their personal streams. To date, we are aware of little academic research dedicated to this stream consumption problem, despite the enormous interest among users and businesses.<br\/><br\/>This research will establish scientific foundations for our understanding of the consumption of message streams, and engineer, deploy, and evaluate new tools for users built on those foundations. This research has two principle aims. First, construct computational models that characterize the individual preferences of stream readers and predict for each reader the value provided by specific messages, and, in aggregate, specific stream contributors. The second aim is to design novel, personalized and intelligent user interfaces that facilitate better digestion and management of online message streams, and evaluate those designs in large-scale field studies on the popular platforms Twitter, Facebook and Google Reader. The proposed research is among the first to examine online message streams broadly and to characterize message streams from the perspective of consumption. Our modeling will give insights into the nature of online message stream consumption and provide a theoretical framework for further investigation.<br\/><br\/>Hundreds of millions of users worldwide are ?voting with their fingers? to spend time creating, commenting on, communing over, and consuming tweets, wall posts, status updates, and blog posts. The research proposed here promises to deepen our understanding of the purpose, value, and social mechanisms underlying message streams, and to create new computational resources for modeling the contributors, their contributions, and the process of consumption. Based on these computational models, innovative visualizations, recommendations, and interfaces will be developed to reshape the user experience, and inform the design of future message stream services.","title":"HCC: Small: Net Fishing: Pulling Valuable Tweets, Feeds, and Blogs from the Online Message Stream","awardID":"1017697","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["550380","483488"],"PO":["564456"]},"168754":{"abstract":"Many text search engines use probabilistic reasoning to determine how well a word represents a person?s information need. The probability that a term appears in relevant documents ? documents that satisfy the information need ? is a fundamental quantity in the theory of probabilistic information retrieval, however prior research provided few clues about how to estimate it reliably. This project uses exploratory data analysis to identify common reasons that user-specified query terms fail to match relevant documents, develops features correlated with each reason, and integrates them into a model that can be trained from data. The resulting term necessity predictions can be used in state-of-the-art retrieval models to improve retrieval accuracy substantially.<br\/><br\/>Term necessity predictions are based on a two-stage approach to text retrieval. A feature-based analysis of an initial retrieval develops evidence that can be linked to a variety of common reasons that a term might not match relevant documents, for example, centrality, synonymy, and abstractness. This model-based approach can be trained from available data, making it easy to incorporate new features that test new hypotheses, or to train a corpus-specific predictive model. It also has the advantage that probability predictions are query-specific, and linked to features that can guide automatic term weighting as well as interactive or automatic query refinement. The project develops several focused interventions for interactive, automatic query expansion, and relevance feedback refinement of queries.<br\/><br\/>This project makes an impact on the scientific community by providing new approaches to a central problem that affects probabilistic retrieval models, and the diagnosis and correction of problems in query formation. Improvements in search engine accuracy also affect a broad population of everyday users. The proposed research improves search accuracy for ?ordinary people? using unstructured keyword queries, as well as professional searchers who often use sophisticated structured queries to search structured documents.<br\/><br\/>Research results will be disseminated in research papers and via project web site (http:\/\/www.cs.cmu.edu\/~callan\/Projects\/IIS-1018317\/). New techniques will be implemented and disseminated in periodic releases of the Lemur Project?s Indri search engine (http:\/\/www.lemurproject.org\/indri\/). Indri is used by a broad international research community, thus this form of dissemination makes it more likely that other researchers will study and extend the proposed research.","title":"III: Small: Modeling and Predicting Term Mismatch for Full-Text Retrieval","awardID":"1018317","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["541869"],"PO":["563751"]},"168875":{"abstract":"AJAX programming enables superior performance and interface quality that is comparable to desktop applications, despite the fact that the users? browsers interact with a remote server on the cloud. The challenge is that AJAX programs are hard to write since they are essentially distributed programs combining three different languages: browser-side Javascript, a server side programming language (e.g., Java, PHP, etc) and database access with SQL. <br\/><br\/>The proposal develops a framework for the rapid creation of fully-fledged AJAX-based web application pages from declarative, data-driven, SQL-based specifications. The proposal delivers an architecture and SQL-based page specification language that is sufficiently abstract and declarative to enable rapid development, while it is also (a) performant and (b) enables the same class of data-driven web applications with what can be manually coded. Novel incremental view maintenance, distributed query processing and concurrency control techniques enable performance, while the component-based structuring of pages blends the data aspects of the language with front-end mechanisms for creating rich interfaces.<br\/><br\/>Declarative specifications lead to rapid programming, fewer bugs and easy application maintenance and evolution, while the framework solves performance optimization and correctness problems and provides functionalities that otherwise the developer would need to take care of with tedious custom AJAX code. The results are carried over besides Ajax to Adobe's Flash, the recent Microsoft's Silverlight and the emerging mobile application platforms. Furthermore, they contribute to UCSD?s web application development curriculum by providing a principled method of architecting and implementing interactive data-driven applications. The information about the project can be found at http:\/\/db.ucsd.edu\/NSF10FWD\/","title":"III: Small: Database-driven Ajax applications","awardID":"1018961","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["525612"],"PO":["563727"]},"168644":{"abstract":"Growing interest in sensor networks and other wireless communication network infrastructure for a host of applications presents important engineering challenges. In particular, there is a need to deliver data quickly and reliably in harsh environments, using often very scarce energy and bandwidth resources. Compared with traditional networks, a distinguishing feature of communication in many emerging applications is the inherent sparseness of communication---that is,communication between participating nodes is highly intermittent. For example, a sensor node may send a few hundred bits of information every few days. In such cases, there is not only uncertainty due to noise to contend with, but timing uncertainty as well. Such transmission profiles create unique challenges, due to the requirement to synchronize with the receiver each time. As a result, for short transmissions, traditional synchronization approaches can consume a disproportionate share of the available resources.<br\/><br\/>This research develops and analyzes models for asynchronous communication suitable for such applications, starting with basic single-user channels and proceeding to broader multiuser and network scenarios. The investigation studies fundamental limits and trade-offs associated with such models, and pursues architectures,protocols, and practical codes for resource-efficient communication in such settings. Because such models explicitly incorporate the lack of prior synchronization in the communication, the associated coding schemes of interest ensure reliable communication in the presence of such timing uncertainty. The research uses such models to assess the relative value of different candidate sparse communication architectures, including quantifying the inefficiency of traditional architectures in which synchronization and communication subsystems are separate, over an approach in which synchronization and communication are combined.","title":"CIF: Small: Theory and Codes for Intermittent and Sparse Communication","awardID":"1017772","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["550597"],"PO":["564924"]},"168413":{"abstract":"Computer storage systems are exploding in size and are vulnerable to an ever-increasing variety of failures. Without measures to anticipate these failures, the systems will lose data, an outcome with dire and tragic consequences. Protecting the storage systems of today and the next decade from failures that can lead to lost data is of paramount importance.<br\/><br\/>Erasure codes are mathematical entitities that protect computer storage systems from losing data when they fail. With an erasure code, one computes and stores extra information from the data that is already stored, so that when disks fail or become corrupted, the original data may be recalculated from the survivors. Optimal erasure codes are well-known for small storage systems. However, larger systems exist today and will be more prevalent in the future, and the current erasure codes that protect them are suboptimal. This project attacks the unknown to develop, evaluate and implement improved erasure codes for large-scale storage installations.<br\/><br\/>The project begins at the threshold of what is currently known and explores codes for larger and more complex systems. The exploration is multi-pronged, addressing the mathematical framework, structural properties and implementational features of the codes. The result will be new codes that perform better and are safer than current ones. Besides formal presentations of the codes, the project will implement and disseminate them as open-source software libraries, so that the practitioners that need them can leverage the work without having to master the complex math that underlies them.","title":"CSR: Small: Developing and Implementing High Performance Erasure Codes to Tolerate Storage Failures","awardID":"1016636","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[450864],"PO":["565255"]},"168534":{"abstract":"The emerging field of sentiment analysis employs algorithmic methods to identify and summarize opinions expressed in text. Both machine learning and ad-hoc approaches lie at the foundations of contemporary sentiment analysis systems, but progress on improving both precision and recall has been slowed by the expense and complexity of obtaining sufficiently broad, general sentiment training\/validation data.<br\/><br\/>Recent work has established that fundamental economic variables can successfully be forecast by applying sentiment analysis methods to news-oriented text streams. This project turns this relation on its head, using such forecasting approaches to improve both the precision and recall of general entity-oriented sentiment analysis methods. In particular, this project provides a three-pronged research effort into entity-level sentiment analysis, focusing on improved assessment and algorithms, with applications to the social sciences and forecasting. In particular: <br\/>(1) Developing a complete entity-level, text and language-independent sentiment evaluation environment, both to further the development of the Lydia system and for release to the international sentiment analysis community.<br\/>(2) Building on this environment, to develop improved sentiment-detection methods for English news, foreign language news streams, social media such as blogs and Twitter, and historical text corpora.<br\/>(3) Finally, applying improved sentiment analysis to a variety of challenges in the social sciences. <br\/><br\/>This research promises to substantially improve both the precision and recall of sentiment detection methods, by focusing on the weakest link: rigorous yet domain-, source-, and language-independent assessment of sentiment. Beyond improvements in natural language processing (NLP), this includes other issues in opinion mining, including article clustering and duplicate detection, entity-domain context, and combining opinions from large numbers of distinct sources.<br\/><br\/>The sentiment analysis methods and data developed under this research project are expected to have a broad impact, as the results will be directly applicable in a broad range of social sciences, including sociology, economics, political science, and media and communication studies. The techniques will serve as both an educational and scholarly resource in these fields, empowering students and researchers to conduct their own primary studies on historical trends and social forces. Results will be disseminated to the community through the project website (http:\/\/www.textmap.org\/III).","title":"III: Small: Better Sentiment Analysis through Forecasting","awardID":"1017181","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["472850"],"PO":["563751"]},"168424":{"abstract":"Communications systems often transfer digital data because digital systems are reliable, programmable, and testable. The digital data are converted to analog form by a digital-to-analog converter (DAC), which produces the input to a channel that makes a physical connection between the transmitter and receiver. Channel nonidealities cause the raw received signals to be continuously variable (analog). In practice, each location has a transmitter and a receiver operating together. Therefore, the raw received signal at any location consists of an analog signal related to the remote digital data plus a filtered copy of the local transmitter signal (an \"echo\"). An analog-to-digital converter (ADC) converts this combined signal into digital form. An echo canceler adaptively removes the echo but usually cannot remove noise or distortion. Therefore, ADCs and DACs used in digital communication systems must have high resolution (for low noise) and high linearity (for low distortion). Inside the ADCs and DACs, unintentional mismatch between elements causes distortion, which is commonly reduced by calibration. However, calibration is often done in the foreground, which means that it interrupts the conversion and reduces the communications rate. To overcome this problem, background calibration can be used. Background calibration operates during normal conversion and has been much less thoroughly studied in DACs than in ADCs. <br\/><br\/>This project involves investigating the digital background calibration of high-speed, high-linearity DACs used for data-communication systems. Unlike in previously reported work, the calibration architecture considered here senses and corrects for signal-dependent output resistance effects. Also, it can improve not only the static (or low output frequency) DAC performance, but also the dynamic (or high output frequency) performance, which is the main limitation in state-of-the art DACs.","title":"CIF: Small: Digital Background Calibration of Digital-to-Analog Converters in CMOS Technologies","awardID":"1016704","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[450891,450892],"PO":["564898"]},"168545":{"abstract":"The Semantic Web is based on describing the meaning ? or<br\/>semantics ? of data on the Web by means of metadata ? data describing<br\/>other data ? in the form of ontologies. The World Wide Web Consortium<br\/>(W3C) has made several recommended standards for ontology languages<br\/>which differ in expressivity and ease of use. Central to these<br\/>languages is that they come with a formal semantics, expressed in<br\/>model-theoretic terms, which enables access to implicit knowledge by<br\/>automated reasoning.<br\/><br\/>Progress in the adoption of reasoning for ontology languages in<br\/>practice is currently being made, but several obstacles remain to be<br\/>overcome for wide adoption on the Web. Two of the central technical<br\/>issues are scalability of reasoning algorithms, and dealing with<br\/>inconsistency of the ontological knowledge bases. These two issues<br\/>are being addressed in this project.<br\/><br\/>The scalability issue has its origin in the fact that the expression<br\/>of complex knowledge requires sophisticated ontology languages, like<br\/>the Web Ontology Language OWL, which are inherently difficult to<br\/>reason with ? as witnessed by high computational complexities, usually<br\/>ExpTime or beyond. This project builds on recent new developments in <br\/>polynomial time languages around OWL in order to remedy this. <br\/>In particular, in this project efficient algorithmizations and tools are <br\/>developed for the largest currently known polynomial-time ontology language, <br\/>called ELP. Reasoning with knowledge bases with expressivity beyond ELP is<br\/>enabled through approximating these knowledge bases within ELP.<br\/><br\/>The inconsistency issue has its origin in the fact that large knowledge<br\/>bases, in particular on the web, are usually not centrally engineered,<br\/>but arise out of the merging of different knowledge bases with<br\/>different underlying perspectives and rationales. <br\/>In this project tools are developed for efficient, i.e., <br\/>polynomial-time reasoning with inconsistent ontologies.<br\/><br\/>The concrete outcome of the project is an open source reasoning<br\/>system which is able to reason efficiently with (possibly)<br\/>inconsistent knowledge bases around OWL, in at least an approximate<br\/>manner. <br\/><br\/>For further information see the project web page at <br\/>http:\/\/knoesis.wright.edu\/faculty\/pascal\/projects\/tron.html","title":"III: Small: TROn - Tractable Reasoning with Ontologies","awardID":"1017225","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563585"],"PO":["563727"]},"168666":{"abstract":"The objective of this research is to analyze and verify VLSI systems and to demonstrate vastly improved scalability in order to raise the quality and scope of predictive circuit modeling. VLSI circuit simulation has become critical due to interconnect dominance of advanced fabrication technologies. Functional modules are integrated through substrates and connected by wires with parasitics. A simulation of the whole system will empower designers with a full grasp of the transient behavior of the circuits. <br\/>The intellectual merit of this proposal lies in the algorithm and software package for full chip simulation. Circuit simulation is one of the main bottlenecks in VLSI design in industry. The complexity of full chip simulations chip is prohibitive for state-of-the-art designs. The project could significantly improve the turnaround time and capacity of whole circuit simulations, enabling the VLSI industry to be more competitive during a time of technological disruption and hence rapid design evolution. The run time software techniques developed by the investigation should apply to a wide range of applications beyond the simulator that could benefit from latency tolerant formulation. New platforms that employ hardware acceleration, e.g. GPUs, will also benefit, since they place a premium on communication.<br\/><br\/><br\/>The broader impacts include the following educational and outreach components. (1) The research will be conducted in collaboration with electronic design automation companies and design houses and the findings will be directly transferred to industry for 3D IC designs. (2) Seminars and new courses will be offered to educate undergraduate and graduate students. A new graduate-level course on circuit simulation using parallel processing will be developed and taught at UCSD as well as at industrial partner sites. (3) Advanced technology books and class handouts will be released through publishers and web-sites. For wider educational outreach, webinars will be presented. (4) The research team is highly integrated and consists of two investigators and a senior researcher from different backgrounds at UCSD and Lawrence Berkeley National Research Laboratory. Education of graduate students involved in the project will be enhanced by participation in an interdisciplinary collaborative research. To disseminate our excitement with the ideas outlined here, and to stimulate the scientific imagination of future scientists, the team will give demonstrations and lectures for minority and disadvantaged students.","title":"SHF: Small: VLSI Circuit Simulation Using Parallel Processing","awardID":"1017864","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[451456,"544334"],"PO":["562984"]},"168787":{"abstract":"Data-center-level energy management techniques have recently shown a lot of promise in improving data center energy efficiency. One challenge in developing such techniques is to support important types of workload. Current approaches, however, only consider managing compute-intensive applications. How to execute data-intensive parallel computations energy-efficiently remains a difficult open problem. World data is growing exponentially, doubling its size every three years. To facilitate large-scale data analysis and processing, a growing number of data centers start to support workloads that are managed with MapReduce-style frameworks. To support this increasingly popular workload energy-efficiently becomes very important.<br\/><br\/>This project develops an energy management software system for heterogeneous MapReduce data centers. It is novel in several ways. First, it considers both computing energy and cooling energy and jointly minimizes their sum. Second, it develops feedback control algorithms to achieve energy-efficient utilization of multiple resources in heterogeneous data centers. Third, it develops aggressive consolidation techniques, matching the number of active nodes to the current needs of the workload. Novel consolidation-aware data management techniques are developed to make data placement and replication cooperative with server consolidation, saving energy while ensuring applications data availability and performance. If successful, this project will have significant impact on the society, by greatly conserving data center energy expenditures and corresponding carbon emissions footprint. Besides the technological impact, via outreach activities, curriculum development and matching minority students with this research, this project informs and educates the broader society and provides students hands-on experience in building energy-efficient computing systems.","title":"CSR: Small: Energy Management for Heterogeneous MapReduce Data Centers","awardID":"1018467","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["77700","559285"],"PO":["565255"]},"168798":{"abstract":"This research considers large scale sparsely networked systems as they arise in large critical infrastructures, e.g., the power grid, or a large transportation system, or when monitoring large physical spaces instrumented with ad-hoc networks of sensors, as in environmental applications. The research will develop a completely novel distributed estimator to process the measurements collected by the networked sensors. A significant problem is the intermittent availability of the measurements because the underlying communication infrastructure among the sensors may exhibit random failures (e.g., due to packet loss in switched networks) or may communicate through a random protocol (gossip or variations.) Due to this intermittency, the estimator equations are random and the filter equations switch at random times between two modes of behaviors; in particular, the filter Riccati equation switches randomly between a linear algebraic matrix equation (Lyapounov) and a quadratic algebraic matrix equation. This research develops an appropriate distributed estimation algorithm, establishes under what structural conditions and for what rates of measurement collection does the filtering error stay bounded, and aims at determining the probability of the filtering error growing unbounded. To study these issues, this work develops new, potentially transformative, powerful methodologies that draw from the theory of random dynamical systems and (moderate) large deviations principle. The work will define appropriate conditions under which the sequences of the filter random covariances converge, determine their limiting invariant distributions, define appropriate rare events, and develop a moderate deviations principle that determines appropriate best rates at which the probability of rare events vanishes.","title":"CIF: Small: Gossiping, Intermittency, and Kalman Filtering","awardID":"1018509","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[451785],"PO":["564898"]},"168688":{"abstract":"Recently, Gentry and others have established the feasibility of constructing fully homomorphic encryption schemes. Briefly, a fully homomorphic encryption (FHE) scheme is one that allows a third-party who has ciphertexts of several messages to construct---without knowing the decryption key---a new ciphertext that corresponds to an arbitrary efficiently computable function applied to the original messages. Fully homomorphic encryption has the potential to allow disparate organizations to compute basic functions on their pooled data-sets without revealing such data to each other. It is thus an ultimate solution for implementing ``need-to-know'' privacy.<br\/><br\/>Until Gentry's discovery, few researchers believed that FHE could be constructed. As a result, the concept has not been well-studied despite its clear potential to solve important tasks in a privacy-preserving manner. In particular, the basic relationship between FHE and traditional public-key cryptography remains unclear. The goals of this research project are to formalize this relationship, to build notions of FHE that satisfy stronger security guarantees such as security even when the adversary has access to a restricted decryption oracle, and to potentially use these stronger security guarantees to apply FHE in secure and privacy preserving computation.<br\/><br\/>To ensure the broader impact of the research, this project includes mentoring of students at all levels from undergraduate to post-doctoral and outreach activities to traditionally under-represented students and K-12 students. Research from this project will be disseminated through presentations and publications in conferences, journals and on the Internet.","title":"TC: Small: Collaborative Research: Implications of Fully Homomorphic Encryption","awardID":"1017979","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["483444"],"PO":["565239"]},"168699":{"abstract":"The project is developing a new, powerful paradigm for declarative programming, capable of solving computational problems that require a large amount of diverse knowledge and use of different reasoning methods. Such problems frequently occur in practice but cannot be solved by more traditional methods of declarative (or procedural) programming. The research includes the development of a language for representing various types of knowledge, algorithms and systems for reasoning about this knowledge, and a methodology of using the language and the systems for solving a large variety of computational problems. Our approach to declarative programming will integrate the ideas from Answer Set Programming (ASP), Constraint Programming (CP), programming methods based on Boolean Satisfiability (SAT) and Satisfiability Modulo Theory (SMT), and with a longer-term goal of including abductive and probabilistic reasoning as well. The approach will be tested on problems in challenging application domains such as a decision support system for space shuttle controllers, secure software systems with complex authorization and obligation policies, and systems capable of planning and scheduling based on non-trivial domain knowledge.","title":"RI: Small: Integrating Logic Based Declarative Programming Paradigms","awardID":"1018031","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["562056",451538],"PO":["565035"]},"168105":{"abstract":"Despite all the progress made in other areas of networking over the past few decades, the management of production networks has remained primitive. However, over the past five years a radically new approach to network management has emerged. This new approach uses a ?network operating system? to hide all the complexity of networking details from management applications while providing powerful primitives for programmatically observing and controlling the network. This project is focusing on three main areas of investigation: Building a next-generation network operating system: sophisticated management requires a network operating system that is scalable, reliable, and secure while also providing network operators with the appropriate set of primitives for controlling their networks; Applying this network operating system to a wide variety of contexts and requirements: a network operating system should support management in enterprise networks, home networks, wide-area networks, and datacenter networks, and should address issues ranging from access control to traffic engineering; Leveraging this approach to gain deeper understanding of networks: network operating systems should support higher-level abstractions ? such as policy languages, event reconstructions, and logical networks ? that allow operators to focus on management goals not implementation details. Addressing these topics will enable the deployment of more secure, reliable, cost-effective, and scalable networks. Moreover, the software from this project will be open-sourced, allowing these benefits to be realized by all.","title":"NeTS: Small: The Design and Use of a Network Operating System","awardID":"1015459","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[450158,"560562"],"PO":["564993"]},"168347":{"abstract":"The availability of digital cameras, improved networking, and the diminishing cost of memory has made it easy to capture, share, and store large image collections. With dense sampling, there are many connections and correlations among these captured images, as they effectively record the same or visually similar objects. This project aims to build such networks of linked images on a large scale, store the inter-image relationships in the form of a graph or simplicial complexes called Image Webs, study the properties of these networks, and exploit them for a variety of applications.<br\/><br\/>Establishing links between parts of images based on image content analysis, and doing so on the scale of millions of images, is a computationally demanding task. Since it is impractical to do this for all image pairs, techniques are developed for attempting to establish links only between pairs for which (1) a link is likely to exist and, (2) the link adds substantially to what is already known about the connectivity of a particular Web. A deeper understanding of the global structure of image webs as topological complexes can aid this link prediction process. Methods are developed for effectively navigating these large structures and for constructing useful maps over them. Integration with more symbolic information associated with images is possible by transferring information around in this vast network.<br\/><br\/>The project is of a highly interdisciplinary nature, combining techniques from continuous applied mathematics, traditionally used in signal processing and image analysis, with methods from discrete mathematics and network theory.","title":"RI: III: Small: IInterlinking Image Collections","awardID":"1016324","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["521232"],"PO":["564316"]},"168259":{"abstract":"Biocomputing systems are being researched for multi-stage information processing in applications ranging from novel biosensors, to signaling and fast decision making in cases of trauma\/injury, implantable devices, biofuel cells, and ultimately, interfacing of living organisms with Si electronics. This research program aims at advancing experimental design and theoretical modeling\/optimization of primarily enzyme-based logic gates, as well as developing a toolbox of non-Boolean and bio-inspired network elements. Approaches will be developed for realizing interconnected networks, as well as for interfacing biochemical logic with bioelectronic systems. Models will be devised for improving the performance of biochemical logic networks in terms of noise reduction, robustness, fault-tolerance, and scalability, for information processing applications. <br\/><br\/>Thus, the present project will advance the basic science of scaling up information processing with biomolecules, primarily, with enzymes, beyond single gates to multi-element networks. The research plan involves both experimental investigations of enzyme-based biochemical gates and their networking as well as theoretical analysis of the concepts and results. Experimental aspects of the work will include the selection and networking of enzymatic systems performing logic processing of biochemical signals at various levels of complexity. The theoretical part will encompass optimization and computer simulation of the biocomputing systems to ensure their stable and fault-tolerant operation. We will specifically address noise reduction and robustness of biomolecular information processing systems.<br\/><br\/>Biocomputing elements of even moderate complexity will allow effective interfacing between complex physiological systems and nanostructured materials and\/or electronic devices. Thus, the broader impacts of this research will include the advancement of a new emerging technological paradigm: Networking of information processing stages that involve biochemical processes. We aim at taking out the wires and batteries, and reducing the overall need for electrical power supplies at those stages of information processing that are carried out on-site in implantable devices and other biotechnology applications, as well as contributing to the advancement of novel biosensor concepts. Significant educational impact will be achieved by training of postdocs and educating Ph.D. students, offering undergraduate research projects, K-12 outreach, and developing new coursework.","title":"SHF: Small: Experimental and Theoretical Development of Error Correction and Digitalization Concepts for Multi-Enzyme Biomolecular Computing Networks","awardID":"1015983","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["475949","545613"],"PO":["565223"]},"163870":{"abstract":"A clinical data warehouse (CDW) is a repository that aggregates medical patient data from many different sources: billing records, electronic medical records including structured data (e.g., codes for diagnoses, procedures, vital signs, etc.), semi-structured reports and free-text dictations. A key benefit of maintaining a CDW lies in its ability to provide the raw data that are needed for large-scale study of real-world health care -- for example, finding a previously unknown association between a pain killer (e.g., Vioxx) and heart disease. Unfortunately, CDWs are riddled with systematic errors that make it difficult to answer even the simplest questions (such as \"What fraction of female outpatients have breast cancer?\") with any accuracy.<br\/><br\/>This project focuses on statistical models and learning algorithms for quantifying and correcting errors in CDW records. For example, the project is developing semi-supervised learning methods that use the structured data present in electronic medical records (patient age, weight, medications, billing codes, etc.) in order to quantify the likelihood of error that is associated with the diagnosis codes present in the record (for example, being able to state \"There is a 0.2 probability that the correct code was migraine instead of the listed headache\"). The project will also develop methods that attempt to control for confounding variables present in the records, in order to remove systematic biases from the data.<br\/><br\/>These models and learning algorithms will allow CDW users to manage and monitor the uncertainty and error in the data. This in turn will allow fundamentally new types of analysis to be undertaken, which will result in the discovery of actionable medical knowledge that saves both lives and money. To make the models and algorithms accessible to medical professionals who may lack computational or statistical background, they will be added to an open-source release of the widely-used I2B2 CDW software.<br\/><br\/>The project is a collaboration between the Computer Science Department at Rice University and the School of Biomedical informatics at the University of Texas Health Science Center at Houston. All project results will be made available online (http:\/\/www.cs.rice.edu\/~cmj4\/CDW.htm).","title":"III: Medium: Collaborative Research: Data Mining and Cleaning for Medical Data Warehouses","awardID":"0964526","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543599"],"PO":["563751"]},"163760":{"abstract":"The advent of multicore processors has introduced new opportunities for achieving<br\/>increased software performance, reliability, security, and availability. However,<br\/>powerful dynamic execution monitoring capabilities are required to realize these<br\/>opportunities. This project addresses the challenges of developing a Dynamic<br\/>Binary Translation based monitoring framework for parallel applications running on<br\/>multicore systems. The programmability of the framework will enable realization of <br\/>benefits in achieving enhanced performance, reliability, security, and availability.<br\/><br\/> Some of the instrumentation code required in context of parallel applications <br\/>must be executed by a core in response to events that involve other cores. In particular, <br\/>events relevant to many performance, reliability, and security related tasks correspond <br\/>to the manifestation of interprocessor data dependences due to updates of shared <br\/>memory locations by multiple cores. Based upon this observation programmable <br\/>architectural mechanisms will be provided that not only enable the detection of <br\/>interprocessor dependence events but also enable the triggering of the execution of <br\/>application specific monitoring code. This project will then employ these mechanisms <br\/>for improving performance via speculative parallelism, enabling debugging via a<br\/>novel strategy of execution suppression, improving reliability via an approach that<br\/>allows applications to automatically recover from failures, providing security via<br\/>dynamic detection of mutating viruses, and software availability via dynamic updates.","title":"SHF: Medium: Programmable Monitoring Framework for Multicore Systems","awardID":"0963996","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["553364","549718"],"PO":["564388"]},"163892":{"abstract":"With technology scaling and increasing integration density in the nanometer technology regime, design considerations for yield and reliability have become critical. The objective of this collaborative research is to explore low-overhead formal design methodology with distributed micro-scale sensor network and systematic feedback control to achieve auto-curing of digital, analog and mixed-signal electronic systems under large process and temporal variations. Such auto-curing approaches will play a key role in preventing yield loss for nanoscale designs, while ensuring reliability of operation and low power dissipation. The research investigates self-curing concepts\/techniques for logic circuits, digital signal processing (DSP) units, embedded memory and analog components using appropriate variation sensing and compensation techniques to achieve high yield with optimal power\/die-area overhead. It also explores system-level self-curing approaches using global parameter sensor and global controller to determine optimal compensation of mixed-signal cores under power constraint. To realize the curing methodologies in an automatic synthesis environment, the research will aim at developing appropriate Computer-Aided Design tools and a library of self-correcting mixed-signal cores. <br\/><br\/>If successful, it will help the semiconductor industry deliver complex nanoelectronic systems with high reliability, low power and high yield. The proposed research will integrate education and training through course development, summer research program for undergraduates, and senior project design.","title":"SHF: Medium: Collaborative Research: System Level Self Correction Using On-Chip Micro Sensor Network and Autonomous Feedback Control","awardID":"0964634","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["451621","551012"],"PO":["366560"]},"175883":{"abstract":"This high-risk, high-reward project is concerned with environmental-impact modeling for infrastructure-network decision-support. The intellectual merit of the research lies in the introduction of an entirely new modeling framework which broadly captures environmental impact in infrastructures by meshing computing and controls concepts, and in the development of a suite of analysis and design tools for this framework. The proposed modeling framework draws on the influence model, a structured representation of interacting Markov chains that can capture the intricate spatio-temporal patterns that are observed in environmental impact, and yet admits rapid computation of local statistics due to its moment-linearity characteristic. By building on the influence-modeling construct, the PIs expect to develop a hybrid model for environmental-impact evolution. A second key task is to develop a suite of tools that allow the use of the environmental-impact model in decision support, with a particular focus on inference and analysis tools.<br\/><br\/>The broader impact of the proposed research is twofold. First, the research has the potential to impact computation and communication technologies in numerous widely-used infrastructures. Second, we the research is envisioned to enact a paradigm shift in modeling for large-scale computation, toward models that incorporate control-theoretic constructs to permit analysis and design of network (and multi-network) dynamics. Education and research-dissemination activities are planned to foster both the societal and computer-science-related impacts of the work. Highlights include multi-disciplinary course-development efforts, and industry-interface and research-experience provisions for undergraduates.","title":"EAGER: Collaborative Research: Stochastic Environmental-Impact Modeling for Automated Decision-Making in Infrastructure Networks: A Multi-Disciplinary Approach","awardID":"1058110","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["559671"],"PO":["565303"]},"174343":{"abstract":"Research in Human-Computer Interaction (HCI) on sustainability has recently exploded. The goal of this project is to guide further development of sustainable HCI by informing research in the area with an understanding of contemporary interventionist eco-art practices. By \"interventionist eco-art practices\" we are referring to a set of artists and projects that combine public and institutional engagement with a commitment to sustainability, to produce artifacts and systems that intervene in environmental issues to raise awareness and provide models for social change. Through such activities, artists push the boundaries of how we use and think about technology and its relationship to the environment. These interventionist eco-art artists and projects suggest new themes and work practices that could usefully inform sustainable HCI. But because they are born from far outside of the traditional sciences, arts-based approaches run into challenges in being taken up and taken seriously as part of HCI. On the one hand, methods and outcomes deriving from the arts are most easily incorporated into HCI by retro-fitting them to existing understandings of HCI as a scientific discipline in ways that blunt their potential to truly add new perspectives. On the other hand, methods and outcomes that remain true to an arts sensibility can suffer marginal status as \"artsy HCI\" such arts-based approaches are more likely to be considered acceptable for fringework or one-off systems than to be thought of as appropriate or essential for the core research of HCI. In either case, the \"edge\" of arts-based approaches, that could provide transformative potential for innovation, is dulled.<br\/><br\/>In this project, groundwork for transdisciplinary engagement between sustainable HCI and interventionist eco-art practices will be laid through an ethnographic case study of interventionist eco-arts practices at the 2010 01 SJ Biennial in San Jose, California to be held September 16 to 19, 2010. The 01SJ Biennial is one of the major international media arts festivals. It attracts tens of thousands of visitors; over 60 artists, designers and collectives are scheduled to participate in the 2010. The theme of 2010 is \"Build Your Own World\" and the majority of participating projects share a common theme of developing alternative, collaborative and Do-It-Yourself (DIY) approaches social and environmental conditions. As such, it provides a unique opportunity for ethnographic study of a range of projects and practices within a bounded space and timeframe. This research will engage in the following activities (1) observation and analysis of eco-arts projects presented at the 2010 01SJ Biennial; (2) participant-observation in the Biennial as a commissioned art\/design collective (3) a project workshop to integrate the results of the first two activities and develop a set of key themes for sustainable HCI (4) follow-on interviews with artists from and the curator of the Biennial.","title":"EAGER: Collaborative Research: Transformative Innovation for Sustainable HCI through Interventionist Eco-Arts","awardID":"1049405","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[467718],"PO":["564456"]},"163695":{"abstract":"Error correcting codes are an integral part of modern day communications, computer and data storage systems and play a vital role in ensuring the integrity of data. At the heart of modern coding theory is the fact that the low-density parity check codes can be efficiently decoded by the algorithm known as belief propagation (BP). The BP is an iterative algorithm which operates on a graphical representation of a code by sending coded bit likelihoods - beliefs. The project establishes a new paradigm and develops tools for the design and analysis of decoding algorithms which are much simpler yet better than belief propagation. This novel paradigm provides a new angle in addressing a fundamental coding theory questions and a methodology for designing a class of decoding algorithms with provable performance and large flexibility in controlling complexity and speed.<br\/><br\/>Unlike BP decoders, these decoders do not propagate beliefs but a rather different kind of messages that reflect the local structure of the code graph. The methodology for designing such decoders involves identifying graphical structures on which traditional decoders fail, and deriving message passing rules that can correct a majority of these structures with minimal number of bits used in the messages. New and successively better decoding algorithms are built by adding more bits to the messages passed in a simpler decoder. The project develops a comprehensive framework to study decoders that achieve the best possible trade-off between the complexity and performance in the low noise region. Also by increasing the number of bits to represent the input alphabet successively better approximations of the behavior of the decoders for continuous channels are obtained.","title":"CIF: Medium: Iterative Decoding Beyond Belief Propagation","awardID":"0963726","effectiveDate":"2010-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["548044"],"PO":["564924"]},"172165":{"abstract":"This project provides travel support for students to attend the 7th IEEE International Conference on Mobile Ad-hoc and Sensor Systems (MASS) to be held during the first week of November 2010. MASS has become a premier international technical venue in a very short period of time (6 years) and has been featuring work of excellent quality attracting attendees from all over the world. The conference has already gained its prominence in providing a superb forum for information exchange. In 2010, the seventh edition of MASS will take place in San Francisco, California, USA during the first week of November. By being located fairly close to the Silicon Valley, MASS 2010 promises to attract record participation from academia and industry. For all its previous venues, MASS has been able to provide student travel grants thanks to NSF's support. Making travel grants available has been very effective in accomplishing the goal of encouraging student participation in technical meetings, especially in the case of under-privileged student populations. Besides the main conference, several workshops and a demo\/poster session will take place as part of MASS 2010. Student participation in such events is a critical part of their education and training no matter what career path they plan to take.","title":"IEEE MASS 2010 Student Travel Support","awardID":"1036861","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551159"],"PO":["557315"]},"174354":{"abstract":"This proposal requests support for a research colloquium of doctoral students and research faculty to be held in conjunction with the 2011 iConference hosted by the University of Washington. The iConference is the annual meeting of the iSchools Project, a consortium of 27 schools, at this time, with programs that focus on the relationships among information, technology, and people. The iSchools are interdisciplinary, including the fields of information science, library science, computer science, education, history, philosophy, sociology, and management. iSchools are global in their reach. The iConference brings together faculty, students, research staff, and industry researchers who share an interest in supporting and augmenting human engagement with information and technology. This will be the sixth iConference. The goals of the 2011 colloquium include helping to advance and enrich the dialog between students and faculty in the iSchools and exploring career opportunities available in the academic research community and other public and private sector areas.","title":"Workshop: 2011 iConference Doctoral Research Colloquium","awardID":"1049425","effectiveDate":"2010-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[467745,467746],"PO":["564456"]},"168810":{"abstract":"This project is devoted to building a large multilingual semantic network<br\/>through the application of novel techniques for semantic analysis<br\/>specifically targeted at the Wikipedia corpus. The driving hypothesis of<br\/>the project is that the structure of Wikipedia can be effectively used to<br\/>create a highly structured graph of world knowledge in which nodes<br\/>correspond to entities and concepts described in Wikipedia, while edges<br\/>capture ontological relations such as hypernymy and meronymy. Special<br\/>emphasis is given to exploiting the multilingual information available in<br\/>Wikipedia in order to improve the performance of each semantic analysis<br\/>tool. Significant research effort is therefore aimed at developing tools<br\/>for word sense disambiguation, reference resolution and the extraction of<br\/>ontological relations that use multilingual reinforcement and the<br\/>consistent structure and focused content of Wikipedia to solve these tasks<br\/>accurately. An additional research challenge is the effective integration<br\/>of inherently noisy evidence from multiple Wikipedia articles in order to<br\/>increase the reliability of the overall knowledge encoded in the global<br\/>Wikipedia graph. Computing probabilistic confidence values for every piece<br\/>of structural information added to the network is an important step in<br\/>this integration, and it is also meant to provide increased utility for<br\/>downstream applications. The proposed highly structured semantic network<br\/>complements existing semantic resources and is expected to have a broad<br\/>impact on a wide range of natural language processing applications in need<br\/>of large scale world knowledge.<br\/><br\/>For further information, please see the project website:<br\/>http:\/\/lit.csci.unt.edu\/index.php\/Mu.Se.Net","title":"III: Small: Collaborative Research: Building a Large Multilingual Semantic Network for Text Processing Applications","awardID":"1018590","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["486301"],"PO":["565136"]},"169910":{"abstract":"Directorates\/offices across the National Science Foundation (NSF) will host twenty (20) K-12 science and mathematics teachers as Fellows of the Albert Einstein Distinguished Educator Fellowship (AEDEF) program. The AEDEF program is a Congressionally-mandated program under the auspices of the U. S. Department of Energy (DOE). NSF participates in AEDEF through a grant to the Triangle Coalition that manages the program for DOE. <br\/><br\/>The objectives of the program are to: (1) provide outstanding STEM teachers the opportunity to bring to Congress and appropriate branches of the Federal government the insights, extensive knowledge, and practical experience of classroom teachers; (2) increase the understanding, communication, and cooperation between Congress and Federal agencies; (3) increase the understanding, communication and cooperation between the Federal government and the science, technology and mathematics education community; and (4) gain insights and an understanding of national educational issues which can then be transferred back to the classroom. While at NSF, each Fellow has a sponsor who will oversee all activities and experiences.<br\/><br\/>The Fellows will engage in a wealth of STEM activities within their respective directorates\/offices such as regular meetings and discussions about research, discoveries, and practices; directorate-wide advisory meetings; seminars; briefings; brown bags; and distinguished lectures of national and international prominence. Externally, the Fellows will interact with their respective members of Congress and their staffs; visit the Goddard Space Flight Center, the National Institutes of Health, the Library of Congress, and the National Academy of Sciences. <br\/><br\/>AEDEF offers a wealth of rich experiences that will likely advance the STEM knowledge of participating teachers personally and professionally. Individually and as a group, Fellows present at national, state, and local workshops and conferences to disseminate information about their experiences and to help recruit potential candidates for the program. <br\/><br\/>Teachers will serve their fellowship in the Biological Sciences, Computer and Information Science and Engineering, Education and Human Resources, and Geosciences directorates at NSF. They will also be hosted by the Division of Industrial Innovation and Partnerships, the National Science Board, Office of Cyberinfrastructure, International Science and Engineering, Office of Legislative and Public Affairs, and the Polar Programs. The teachers represent Arizona, California, Colorado, Connecticut, Hawaii, Idaho, Illinois, Maryland, Massachusetts, New Jersey, New York, Pennsylvania, Washington, Washington, DC, and Wisconsin. Other agencies participating in the program include NASA, NOAA, and DOE.","title":"Albert Einstein Distinguished Educator Fellowship Program","awardID":"1024415","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"129P","name":"Einstein Fellow (OLPA)"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"7957","name":"COMMUNICATING SCIENCE BROADLY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0600","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"1733","name":"GEOSCIENCE EDUCATION"}},{"dir":{"id":"10","name":"Office of OFFICE OF BUDGET, FINANCE, & AWARD MANAG","abbr":"BFA"},"div":{"id":"1005","name":"Division of INSTITUTION & AWARD SUPPORT","abbr":"DIAS"},"pgm":{"id":"0626","name":"MISCELLANEOUS SERVICES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1793","name":"MSP-OTHER AWARDS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1795","name":"ROBERT NOYCE SCHOLARSHIP PGM"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1544","name":"RES ON GENDER IN SCI & ENGINE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7179","name":"GRAD TEACHING FELLOWS IN K-12"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7259","name":"INFORMAL SCIENCE EDUCATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7645","name":"DISCOVERY RESEARCH K-12"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1401","name":"Division of ARCTIC SCIENCES DIVISION","abbr":"ARC"},"pgm":{"id":"5208","name":"ARCTIC RESEARCH AND EDUCATION"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1403","name":"Division of ANTARCTIC SCIENCES DIVISION","abbr":"ANT"},"pgm":{"id":"5294","name":"Antarctic Education"}}],"PIcoPI":["529017","529018"],"PO":["562491"]},"168700":{"abstract":"Although P2P has proven itself as a viable architectural paradigm for distributed applications, the success of future P2P applications ultimately depends on convincing users to volunteer these resources. In this project, two inter-related P2P incentive paradigms are under investigation. In the first paradigm, called Networked Asynchronous Bilateral Trading (NABT), each user has a set of online friends. Users can trade asynchronously with direct friends using local currency and a debt limits. NABT also allows trades to pass through intermediaries. For file sharing, NABT is almost as efficient as a perfect economy, where all users can trade directly with each other. Research is also aimed at extending NABT, developing designs and theories for heterogeneous P2P resource markets. The second paradigm, called Closed P2P Communities, uses a lightweight centralized banking infrastructure. Here the focus is on designing and analyzing a new class of powerful, but lightweight currency-based incentive schemes. Game theory is being applied to design incentive mechanisms that optimize deal throughput for diverse P2P markets and pricing theory is used to study the pricing dynamics in closed P2P communities. Novel approaches for detecting and evicting colluders are also under development. Prototypes for both incentive paradigms will be constructed. The project will provide a framework for a new P2P computing paradigm. It will involve undergraduate and graduate students, especially minority students. Interactions with industry will be facilitated through the CATT center at NYU-Poly. Educational material will be developed and disseminated for undergraduate and graduate level networking courses taught by the PIs at NYU-Poly.","title":"NeTs: Small: Economic Incentives for P2P: Theory and Design","awardID":"1018032","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["312698","550020"],"PO":["564993"]},"168821":{"abstract":"The Web promises unprecedented access to the perspectives of an<br\/>enormous number of people on a wide range of issues. Turning that<br\/>still untamed cacophony into meaningful insights requires dealing with<br\/>the linguistic diversity and scale of the Web. Most current research<br\/>focuses on specialized tasks such as tracking consumer opinions, and<br\/>virtually all current research treats the Web as both monolithic and<br\/>monolingual, ignoring the variety of languages represented and the<br\/>rich interplay between topics and issues under discussion.<br\/><br\/>This project moves the state of the art forward by focusing on two key<br\/>challenges. First, highly-scalable MapReduce algorithms for<br\/>linguistic modeling within a Bayesian framework, making use of<br\/>variational inference to achieve a high degree of parallelization on<br\/>Web-scale datasets. Second, novel Bayesian models that learn<br\/>consistent interpretations of text across languages and a wide range<br\/>of response variables of interest (for example, views on an issue,<br\/>strength of emotion relative to an event, and focus of attention).<br\/><br\/>The techniques developed in this project will be demonstrated on large<br\/>crawls of Web pages and blogs. Potential applications for these<br\/>technologies include helping a schoolchild learn that people in<br\/>different countries may view some issues very differently, helping a<br\/>politician understand how constituents are reacting to proposed<br\/>legislation, or helping an intelligence analyst understand how public<br\/>opinion is evolving in a hostile country.<br\/><br\/>For further information see the project Web page:<br\/>http:\/\/www.umiacs.umd.edu\/~jimmylin\/cloud-computing","title":"DC: Small: Cross-Language Bayesian Models for Web-Scale Text Analysis Using MapReduce","awardID":"1018625","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["514912","518100","550879"],"PO":["563751"]},"168832":{"abstract":"This proposal aims to enable scalable and adaptable information integration over unstructured data at a large scale. There is a need to be able to do structured queries with unstructured data, for example in executing SQL queries over Web pages. This project will develop a new approach of \"query push-down,\" distinctive from the conventional \"data pull-up\" techniques, as a promising direction for accomplishing agility in integration. The technical objectives will be driven by two application domains: Army land planning and the Illinois digital library. <br\/>The team will develop query translation techniques that \"pushes down\" queries to a format that can be executed over unstructured document and feature indexes. This approach will eliminate expensive, inflexible, and often fragile extraction of unstructured data, enabling scalable and adaptable information integration through \"best effort\" semantics. In the query push-down approach, queries are no longer executed by the SQL-like Boolean semantics, but would rather take a maximum likelihood interpretation-- i.e., what are the most likely answers, by properly translating a given query, under the presence of uncertainty and lack of preciseness in data? The team will study the formalism that governs the principles of such probabilistic query execution, for achieving \"best effort\" with probabilities as a formal quality metric. Researchers will build the Data-oriented Content Query System , which will support users of Web data not only keywords but also data types to query for relevant values of their desired data in the contents of the corpus, by specifying flexible patterns and customizing scoring functions. Structured queries will be translated for executing in the system to access and integrate the unstructured contents in the corpus.<br\/><br\/>The successful results in this proposed research will have significant impacts in two areas. The research community has observed the scalability limitation of the current integration schemes. These observations highlight the urgency of the proposed study for developing large-scale, agile integration techniques. This will formally advance the understanding of large-scale best-effort integration and develop a set of general techniques. Second, the development of the query system engine will provide access to the data-rich Web, with practical deployment at the Illinois Gateway of the UIUC digital library, which will improve students and faculty?s access to online scholarly and open information. Students will be directly involved in the research effort and new curricula are planned.","title":"III: Small: Towards Agile Information Integration for Large Scale-- Data Aware Indexing and Search over Unstructured Data","awardID":"1018723","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["465856",451869],"PO":["565136"]},"178754":{"abstract":"Description<br\/><br\/>Advances in remote sensing techniques have made available large datasets of topographic measurements pertaining to terrestrial and planetary land surfaces. However, the scientific utilization of these datasets is hampered by a lack of tools for effective automated analysis. This project seeks to develop a system for fast, objective and transparent conversion of topographic data into knowledge about land surfaces. The project has two complementary goals: 1) to develop a tool that autonomously produces geomorphic maps mimicking traditional, manually derived maps in their appearance and content, and 2) to develop a tool that classifies entire topographic scenes into characteristic landscape categories. The mapping tool is based on the object-oriented supervised classification principle. A number of novel solutions, including semi-supervised learning, meta-learning, and a wrapping technique coupling classification and segmentation, are proposed to address challenges posed by the specificity of topographic data. The scene classification tool is based on information-theoretic metrics and incorporates novel solutions to problems posed by the raster character of topographic datasets.<br\/><br\/>Intellectual Merit<br\/><br\/>The project employs a novel fusion of machine learning and computer vision techniques to open new possibilities. In the process of constructing the mapping and classifying tools, novel machine learning methodologies will be developed and tested. The products of this research will enable a qualitatively new type of analysis of land surface topography: the large scale statistical comparison of spatial distribution of landforms.<br\/><br\/>Broad Impact<br\/><br\/>Successful mapping and classifying tools will have impact beyond the analysis of natural landscapes; they can be also be applied to the study of surface metrology (the numerical characterization of industrial surfaces). The nature of this project will attract interest and collaboration with specialists from diverse disciplines, such as computer science, remote sensing, geomorphology and hydrology. Such links will broaden the base of expertise for each discipline, as well as enrich participants from contributing domains.","title":"III-CXT-Small: Collaborative Research: Automatic Geomorphic Mapping and Analysis of Land Surfaces Using Pattern Recognition","awardID":"1103684","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["501341"],"PO":["563751"]},"176213":{"abstract":"This proposal seeks travel support for US-based student participants to the 12th International Symposium on Stabilization, Safety, and Security (SSS 2010) to be held in New York City during September 20-22, 2010. With the rapid growth of large-scale networks, the issues of stabilization, safety and security have assumed critical importance in dynamic distributed systems. To foster the growth of research in these areas and to maintain global leadership in the future, it is vital for US-based students to participate in this symposium, meet the leaders in these disciplines, and update themselves on the state-of-the-art. <br\/><br\/>While stabilization helps distributed systems spontaneously recover from the effects of failures and environmental perturbation like user demands and node mobility, safety and security are of critical significance in a world where physical and cyber security are under constant threat. Atendance to the SSS conference will enable US-based students gain first-hand knowledge in the key areas of stabilization, safety and security in networks and distributed systems, and bring back the knowledge to their home institutions for the enrichment of their research. The broader impact of this proposal is that US-based students will be better prepared to maintain global leadership in a competitive world. The travel support will be used to specifically encourage the participation of women and minority students, so that these underrepresented communities become motivated towards advanced computer science education and research.","title":"Student Travel Support for the Symposium on Stabilization, Safety and Security (SSS 2010), New York City, September 20-22, 2010","awardID":"1059550","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[472231],"PO":["557315"]},"169932":{"abstract":"The central objective of this project is to accelerate the pace of the revolution in the state-of-the-art of integer programming that took place over the last 15 years. Until the early 1990's, integer programming, a universal tool for modeling real-world situations characterized by the absence of convexity, smoothness, continuity, could only solve very small problem instances. Over the last 15 years, due partly to the successful adaptation of new convexification procedures, the reach of integer programming has been vastly extended so that today it can cope with problems involving thousands of variables and constraints. This project is aimed at developing new and more efficient convexification techniques in the form of improved lift-and-project cuts derived directly from the simplex tableau, intersection cuts from multiple rows or multiple term disjunctions, cuts obtained by iterative disjunctive modularization, pure integer cuts generated lexicographically, and others.<br\/>The techniques to be developed promise to yield cuts that are not only deeper, but more diverse and stable, thereby tightening the linear relaxation of the mixed integer programs at hand, and reducing the size of the search tree generated in the process. This is expected to increase by an order of magnitude the size of the instances solvable in useful time and thereby to extend the sphere of solvable problems to new types of mixed integer programs that arise in supply chain management, industrial scheduling and other real-world environments.","title":"Integer and Combinatorial Optimization: Intersection Cuts from Multiple Rows","awardID":"1024554","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":["539128","539129"],"PO":["565139"]},"168722":{"abstract":"Abstract<br\/>This research develops a novel framework for interpolation and approximation of multivariate data.<br\/>The research introduces a method for construction of non-separable multivariate splines that are geometrically<br\/>tailored for general sampling lattices with emphasis on sphere packing and covering lattices<br\/>in multidimensions. These multivariate splines lead to the design of multidimensional signal processing<br\/>tools, that have proven degree of continuity and approximation order for sampling lattices.<br\/>The splines under investigation, called Voronoi splines, are B-spline-like elements that inherit the<br\/>geometry of any sampling lattice from its Voronoi cell and form basis for reconstruction. Furthermore,<br\/>the relationship of the proposed splines with the well-known multivariate box splines are investigated<br\/>and used for evaluation purposes. Compared to other polyhedral splines, Voronoi splines form shiftinvariant<br\/>spaces for approximation. This property makes them uniquely suitable for multidimensional<br\/>signal processing.","title":"CIF: Small: Multidimensional Signal Processing With Box Splines","awardID":"1018149","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["466995"],"PO":["564898"]},"164487":{"abstract":"Health support groups, including those on the internet, can substantially benefit participants, but the social processes responsible for these benefits are unclear. A team of researchers led by Robert Kraut at Carnegie-Mellon University will explore how the conversational dynamics of online cancer support groups influence group functioning and participant quality of life and will develop computational tools that can be used to analyze online conversations and improve their effectiveness. The research project has four specific goals. (1) To understand how conversational episodes in online support groups facilitate social support. For example, what must a person say to get others to respond empathically? (2) To understand how support in these groups influences group commitment and affects health outcomes. (3) To develop computational tools to make the analysis of large datasets of health conversations tractable. (4) To use these tools to improve the training of support group facilitators.<br\/><br\/>Online health support groups are popular, being used by about 58% of American adults. Identifying the role of communication in online cancer support groups will provide valuable information to users and facilitators of these groups and will enhance their training. Moreover, a tool for analyzing large corpora of conversational data will facilitate the work of researchers who are interested in conversational behavior in other kinds of online groups","title":"SoCS: Collaborative Research: Conversational Dynamics in Online Support Groups","awardID":"0968480","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[440640],"PO":["563458"]},"168854":{"abstract":"This research addresses a fundamental computer systems challenge presented by the rise of datacenter computing as the dominant platform for ``cloud computing.'' Today, datacenters host mission-critical services for IT, health, and financial institutions using complex systems consisting of large ensembles of machines spread across multiple physical networks and geographic regions. These sophisticated services must meet stringent design and performance requirements such as horizontal scalability, fault tolerance, self adaptation, and security while leveraging low-cost commodity hardware. A key challenge is to quantify the impact of hardware changes, software designs, and energy management policies. Critically, such evaluations require the real code, workloads, component interactions, heterogeneous hardware, and high-load conditions to accurately predict performance. <br\/><br\/>This proposal investigates techniques and architectures for building a high-fidelity datacenter emulation platform to transform datacenter network and service design from a black art into a rigorous, accurate, and repeatable (scientific) process. Such a facility allows researchers and architects to develop the principles and best practices for next-generation datacenter design. By accurately emulating realistic datacenter scales (10,000+ machines, 100+switches, multiple cooperating services) with a modest cluster of a few hundred machines, the proposed work aims to place datacenter experimentation within the reach of students, academics, and businesses without the financial reach of large IT firms.","title":"CSR: Small: High-Fidelity Datacenter Emulation","awardID":"1018808","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485593","518658"],"PO":["565255"]},"164498":{"abstract":"Volunteer Computing (VC) uses the computational resources of volunteers with Internet-connected PCs to address fundamental problems in science. Unfortunately, the largely white-male volunteers are not representative of the general population, and their involvement typically consists of nothing more than contributing idle computing resources. The demonstrated benefits to scientific discovery and the opportunity to engage a broad population motivate this project?s radical transformation of VC systems. <br\/><br\/>This work will build ExSciTecH, an interactive, easy-to-use VC system to Explore Science, Technology, and Health. The system will motivate and facilitate diverse volunteers to donate their intellectual and computational resources to VC projects. As a result, ExSciTecH will aid scientific discovery even as it develops a more scientifically informed and engaged citizenry. Supported by technologies such as the Nintendo Wii Remote controller and casual gaming, ExSciTecH will help volunteers discover how rewarding and exciting science can be. <br\/><br\/>Intellectual Merit: This project aims to increase the interest and participation of diverse populations in computer science in general and VC projects in particular, to build inclusive communities of diverse volunteers, and to increase the science delivered to scientists by Docking@Home, a VC project targeting the design of new drugs for breast cancer and HIV. <br\/><br\/>Broader Impact: ExSciTecH will be distributed through an established network of undergraduate computing programs that are dedicated to diversity in information technology. The National Center for Women and IT (NCWIT) has experience and resources for promoting and distributing practices that recruit and retain diverse populations.","title":"Collaborative Research: SoCS - ExSciTecH: An Interactive, Easy-to-Use Volunteer Computing System to Explore Science, Technology and Health","awardID":"0968503","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["513746"],"PO":["565342"]},"168623":{"abstract":"The growing power of supercomputers provides significant advancements to the scientists' capability to simulate more complex problems at greater detail, leading to high-impact scientific and engineering breakthroughs. To fully understand the vast amounts of data, scientists need scalable solutions that can perform complex data analysis at different levels of detail. Over the years, visualization has become an important method to analyze data generated by a variety of computationally intensive applications. The selection of visualization parameters and identification of important features, however, are mostly done in an ad-hoc manner. To enable the user to explore the data systematically and effectively, in this collaborative research effort involving the Ohio State University and the Michigan Technological University, the PIs explore an information-theoretical framework to evaluate the quality of visualization and guide the selection of algorithm parameters.<br\/><br\/>The research team plans to develop a four-tier analysis framework based on information theory. The bottom tier of the framework consists of the components of information measures where data are modeled as probability distributions. Based on the information measurement components, in the tier two of the framework the most common visualization algorithms including isosurface extraction and flowline generation are evaluated and optimized to effectively reveal the most amount of information in the data. The PIs also investigate issues related to information measurement in image space and optimize the direct volume rendering results. The tier three of the framework is focused on the analysis of time-varying and multivariate data sets. Methods for identifying important spatio-temporal regions in time-varying data sets and to measure the information flow in multivariate data sets to identify the causal relationship among different variables will be developed. In the fourth tier of the framework, the information theory is used to assess the quality of different levels of detail in multi-resolution volumes and images, and to select the level of detail to optimize the visualization quality while satisfying the underlying performance constraints.<br\/><br\/>The key accomplishment of this project will be the development of a rigorous information theory based solution to assist scientists in comprehending the vast amounts of data generated by large-scale simulations and effective visualizations. To target the research at real world applications, the PIs are collaborating with the combustion scientists at Sandia National Laboratories who are at the forefront of their field to employ extreme-scale computing to solve the most challenging problems. The four-tier information-theoretic framework will be implemented using the Visualization Toolkit (VTK), which is to be released to general users. New algorithms and techniques developed in the project will be disseminated through the project web site (http:\/\/www.cse.ohio-state.edu\/~hwshen\/Research\/NSF_GV2010), presentations at the annual visualization and application-specific conferences that the PIs have been actively participating in. Dissemination plan will also includes reaching general audiences through news, stories, and presentations to enhance their understanding and appreciation of the value of visualization. This project provides training to graduate, undergraduate, and underrepresented students in the area of computational science and large-scale data analysis and visualization.","title":"GV: Small: Collaborative Research: An Information-Theoretic Framework for Large-Scale Data Analysis and Visualization","awardID":"1017635","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["533228"],"PO":["563751"]},"168744":{"abstract":"The widespread deployment of wireless communication systems creates unprecedented opportunities to impact our daily lives. Regardless of whether wireless infrastructures are used just for communication or as the basis for actual responses, large-scale wireless data provide increasing opportunities for detecting environmental changes caused by moving objects. Indeed, it is expected to develop the ability to make use of existing wireless infrastructure and sensing data to track moving objects which do not carry radio devices and may not even being aware of being tracked. However, these wireless data are dynamic and have complex data characteristics, such as multi-scale, multi-source and multi-modal. As these data become large and more detailed, new challenges are emerging for intrusion learning.<br\/><br\/>This project aims to develop effective and scalable multi-modal passive intrusion learning techniques that have the capability to detect and track device-free moving objects in pervasive wireless environments through adaptive learning in a collaborative way. In contrast to traditional techniques, which require pre-deployment of specialized hardware, and thus not easily deployed for unscheduled tasks and may not be scalable, this project leads to new insights into intrusion learning by mining on wireless environmental data, as well as leading to new approaches to device-free wireless localization, which can be used to assist a broad array of applications (e.g., identification of people trapped in a fire building during emergency evacuation). Project results are expected to open a new venue for integrating learning capabilities into emerging pervasive wireless fields. The educational component seeks to equip students with the necessary background and practical skills needed to contribute to information technology and have a practical impact on a large set of cross-section domains.","title":"NeTSE:Small:Collaborative Research: MILAN: Multi-Modal Passive Intrusion Learning in Pervasive Wireless Environments","awardID":"1018270","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["550063"],"PO":["564924"]},"168865":{"abstract":"This project is developing underwater acoustic tracking strategies for locating and tracking particular species of tagged sharks that have long distance migratory paths. A unique aspect of this project is that receivers will be onboard a team of Autonomous Underwater Vehicles (AUV), enabling them to cooperatively estimate the shark position, thereby allowing the AUVs to track and follow the shark for sustained periods of time. The AUV team's mobility and ability to modify its own path in response to shark movement allows it to obtain in-situ measurements that cannot be obtained from static receiver systems typically used for monitoring shark behavior.<br\/><br\/>Due to its interdisciplinary nature, this project will make contributions in both Engineering (AUV autonomy and control) and Biological Sciences (shark behavior characterization, life history, and habitat utilization). New approaches to state estimation are being developed. A key to creating a successful estimator for this application will be incorporating kinematic and dynamic models of shark locomotion. Novel control strategies are also necessary given the difficulty of tracking sharks that can travel at high speed. Tracking controllers don't typically consider the additional constraint of maintaining a separation distance to ensure the AUV doesn't affect shark behavior. The end goal of conducting shark tracking experiments will be the first of its kind. Additionally, much merit will be derived from the actual data the experiments yield. Specifically, the engineering within this project is driven by the goal of determining the relationships between local ocean environment variables (e.g. temperatures, current velocities) and shark behavior (e.g. migration path choices, habitat use). While there is considerable knowledge of shark physiology and behavior, there are no fine scale time studies of shark motion and its associated energy use within different behaviors.<br\/><br\/>This work includes developing new AUV sampling technologies that can be generalized and applied to studying various forms of marine life, and in addition to the ecological contributions, the research is applicable to other tasks associated with safe marine navigation, homeland security, and the military.","title":"RI: Small: RUI: Shark Tracking with Multiple Autonomous Underwater Vehicles","awardID":"1018894","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["546586","536000"],"PO":["543539"]},"178545":{"abstract":"The objective of this research is to develop techniques that utilize solid-state memory technologies from device, circuit, architecture, and system perspectives across I\/O hierarchy in order to exploit their true potential for improving I\/O stack performance in high-performance computing systems. <br\/>I\/O friendly memory system architectures will be developed to enable hybrid processor-memory 3D integrations with largely reduced off-chip I\/O traffic. Adaptive cache management and hotspot prediction methods will be developed to address the low random write performance of solid-state drives, and data processing techniques will be developed to enable run-time configurable trade-offs among solid-state drive performance characteristics. A comprehensive full-system simulation infrastructure will be developed to evaluate and demonstrate the research under diverse high-performance computing workloads.<br\/>The research will facilitate the high-performance computing systems to most effectively utilize existing\/emerging memory and processing technologies to tackle the grand I\/O stack design challenge. It can greatly contribute to enabling high-performance computing systems to stay on track of their historic scaling, and hence benefit numerous real-life applications such as biology, chemistry, earth science, health care, etc. This project will also contribute to the society through engaging under-represented groups, research infrastructure dissemination for education and training, and outreach to high school students.","title":"Collaborative Research: Cross-Layer Exploration of Non-Volatile Solid-State Memories to Achieve Effective I\/O Stack for High-Performance Computing Systems","awardID":"1102605","effectiveDate":"2010-09-20","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["550809"],"PO":["565272"]},"165477":{"abstract":"The Partnership for 21st Century Skills (P21), a national organization formed in 2002 by the U.S. Department of Education in cooperation with organizations such as Apple Computer, Cisco Systems, and the National Education Association, is a leading catalyst for educational reform in this country. P21 seeks to prepare every child in the United States with the ?21st century knowledge and skills? they need to become competent workers and active citizens. At the top of their list of skills is creativity and innovation, which they say includes not only the ability for individuals to think creatively, but also to work creatively with others and implement innovations into practice. In the spirit of P21?s new focus on creativity and innovation, our research will lead to new insights for STEM education regarding the relationship between creativity and information technology by looking at how young people act when they are given the chance to be technology designers, specifically designers of a mobile game called Re:Activism. This is a game in which game designers challenge players equipped with Global Positioning System (GPS)-enabled devices to visit and learn about areas in their community where significant historical events such as protests, riots, or activist events have occurred. In New York, these sites might include the location of the Triangle Shirtwaist Factory fire, for example. Over the course of the project, 3 groups of youth participants will work in teams to design their own versions of Re:Activism using a design process of prototyping, testing, and refining. <br\/><br\/>Participants will be 11-16 year olds drawn primarily from the after school programs at member institutions of the New Youth City Learning Network (NYCLN). NYCLN is a new initiative sponsored by the MacArthur Foundation and is comprised of a set of cultural institutions in New York that include the New York Hall of Science, the DreamYard project (digital arts program), the New York Public Library, and the Institute of Play (game design program), among others. Through the process of designing their own game, youth participants will learn new ways to link media like photographs to physical locations via geographic and mobile technologies. They will also learn how they can work together to use these tools creatively within the context of game design to craft and share historical stories about their community in a format that can eventually be played by others. In addition to developing new insights for STEM educators, we plan to publish the results of this work in multiple formats and venues within the informal learning community to impact and inform the contemporary dialogue underway within private, public and philanthropic sectors regarding the importance of mobile and geographic technologies in supporting situated and social forms of learning, advancing geospatial understanding, and encouraging community participation and engagement.","title":"Major: Urban Game Design as a Tool for Creativity, Collaboration, and Learning Among Youth","awardID":"1002850","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["561664",443283,443284],"PO":["562669"]},"168513":{"abstract":"One dominant characteristic of today's large-scale computing systems<br\/>is the prevalence of large storage clusters. Storage clusters at the<br\/>scale of hundreds or thousands of commodity machines are<br\/>increasingly being deployed. At companies like Amazon, Google, Yahoo,<br\/>and others, thousands of nodes are managed as a single system.<br\/><br\/>As large clusters have brought many benefits, they also bring a new<br\/>challenge: a growing number and frequency of failures that must be<br\/>managed. Bits, sectors, disks, machines, racks, and many other<br\/>components fail. With millions of servers and hundreds of data<br\/>centers, there are millions of opportunities for these components to<br\/>fail. Failing to deal with failures will directly impact the<br\/>reliability and availability of data and jobs.<br\/><br\/>Unfortunately, we still hear data-loss stories even recently. For<br\/>example, in March 2009, Facebook lost millions of photos due to<br\/>simultaneous disk failures that \"should\" rarely happen at the same<br\/>time (but it happened); in July 2009, a large bank was fined a record<br\/>total of 3 millions pounds after losing data on thousands of its<br\/>customers; more recently, in October 2009, T-Mobile Sidekick, which<br\/>uses Microsoft's cloud service, also lost its customer data. These<br\/>incidents have shown that existing large-scale storage systems are<br\/>still fragile to failures.<br\/><br\/>To address the challenges of large-scale recovery, the goal of this<br\/>project is to: (1) seek the fundamental problems of recovery in<br\/>today's scalable world of computing, (2) improve the reliability,<br\/>performance, and scalability of existing large-scale recovery, and (3)<br\/>explore formally grounded languages to empower rigorous specification<br\/>of recovery properties and behaviors. Our vision is to build systems<br\/>that \"DARE to fail\": systems that deliberately fail themselves,<br\/>exercise recovery routinely, and enable easy and correct deployment of<br\/>new recovery policies.<br\/><br\/>For more information, please visit this website:<br\/>http:\/\/boom.cs.berkeley.edu\/dare\/","title":"DC: Small: Collaborative Research: DARE: Declarative and Scalable Recovery","awardID":"1017073","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["550390"],"PO":["366560"]},"168755":{"abstract":"Inferring searcher intent is a central problem in information retrieval and web search: for effective ranking and result presentation, the search engine must know what the user is looking for. Yet, expressing a searcher information need currently relies on entering the ?right? search keywords, which can require multiple rounds of trial-and-error from the searcher. The goal of this project is to develop effective methods for a search engine to automatically infer searcher intent and information needs from the searcher interactions and behavior data. Specifically, the project addresses two main challenges of search intent inference: developing accurate and robust models of searcher intent and behavior, and exploiting these models to infer search intent for each individual user. This project significantly advances previous efforts on implicit feedback and search modeling, by considering a wide range of user interaction and contextual features, and by developing novel techniques for mining and exploiting these signals to improve web search and information access.<br\/><br\/>To develop robust search intent and behavior models, the project uses machine learning and data mining techniques to model the connection between search actions and result page behavior and the searcher intent. The first stage of the project develops and evaluates these models in controlled lab environments, by combining eye tracking and search interface instrumentation data. The second stage of the project empirically validates the intent inference models through a large-scale collection of search behavior data using a variety of remote user studies with instrumented search interfaces. Finally, the project applies the resulting models and algorithms to improve performance on key information retrieval tasks including result ranking, automatic query expansion, and search result presentation. <br\/><br\/>The techniques developed in this project are expected to make web search and information access more intuitive and effective for millions of users through collaboration with major search engine companies. Additional broader impacts will be achieved through domain-specific applications of the developed techniques, ranging from improved library search to web-based diagnostics of cognitive impairment. All aspects of the project will involve graduate and undergraduate students, and the resulting tools and datasets are to be integrated into undergraduate course instruction and projects, thus broadening participation in computer science research. The resulting publications, software, and datasets will be made publicly available on the project website (http:\/\/ir.mathcs.emory.edu\/intent\/).","title":"III: Small: Modeling and Inferring Searcher Intent by Mining User Interactions","awardID":"1018321","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[451675],"PO":["563751"]},"168645":{"abstract":"Signal processing methods for passive acoustic monitoring of marine mammals<br\/>Eva-Marie Nosal (PI) and Anders Host-Madsen (co-PI)<br\/><br\/>The welfare of the marine environment is of increasing global concern. Underwater acoustics is a promising approach to assess and mitigate human impact on marine mammals, as well as to determine population sizes, monitor behavior and migration patterns, identify critical habitat, and study bioacoustics. The research funded by this award is expected to lead to radically improved methods for passive acoustic monitoring of marine animals by using modern signal processing methods. Passive acoustic monitoring methods are non-invasive, unobtrusive, and can be used in poor weather conditions and lack of daylight. They enable continuous and remote sensing in a cost and time efficient manner. For these reasons, passive acoustic techniques are valuable on their own, and as a complement to existing visual and tagging techniques for studying marine mammals.<br\/><br\/>Many marine mammals are vocal so by processing data collected by hydrophones (underwater microphones), they can be detected, monitored and studied. Due to the complex nature of the marine environment and the vocalizations, advanced signal processing methods are needed. The project will consider the following specific problems 1) Channel estimation and use of this for localization of mammals. 2) Separation of multiple mammals. Signal processing methods for blind source separation can be used to separate the vocalizations of multiple mammals within the range of the hydrophones. 3) Detection of vocalizations. Most of the time sound recordings are pure noise. The project will develop methods for separating noise and signal segments. 4) Analysis of vocalizations. The project will then look into further analyzing the sounds, for example for classification of species, establishing information content in vocalizations, and extracting bioacoustic properties.","title":"CIF: Small: Signal Processing Methods for Passive Acoustic Monitoring of Marine Mammals","awardID":"1017775","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":["451433",451408],"PO":["564898"]},"168535":{"abstract":"The project continues the study of interconnections between group theory and the theory and practice of computation. The major objectives are (1) the design, analysis, and implementation of algorithms for computations with finite groups; (2) the development of mathematical tools required for the design and analysis of such algorithms; (3) the study of current bottlenecks in the graph isomorphism problem, a major open problem in the theory of computing; and (4) the computationally motivated study of discrete structures involving the group concept. The project will build on the PIs recent results of breaking quarter-century old bottlenecks in the areas of matrix group computation and on the graph isomorphism problem. A principal theme of the project is the synergy between the theoretical and practical, benefitting both the field of symbolic algebra and the theory of computing through the design and implementation of algorithms that are both fast in practice and admit rigorous complexity analysis. The project methodology in the area of matrix computations will combine elements of the two existing approaches, the geometric and abstract structural (\"black-box\") frameworks. The project also includes related problems in group theory, combinatorics, and computer science, connected through the algorithmic study of objects involving the group concept. In particular, a combination of such tools will be required for a renewed study of the bottlenecks that have blocked progress on the graph isomorphism problem and the related coset intersection problem in permutation groups. The PIs will also study of parameters of Boolean functions subject to symmetry conditions, including the complexity of property testing; and the Abelian Sandpile Model which connects a number of fields, including statistical mechanics, algebraic graph theory, discrete dynamical systems, algorithms, and complexity in the study of a certain commutative monoid and group.<br\/><br\/>Groups are the mathematical formulation of symmetry, ubiquitous in mathematics and the sciences. Algorithms for finite groups and their associated Cayley graphs have a wide range of applications, from group theory to statistics, network design, the graph isomorphism problem (of relevance to computer science and chemical documentation), cryptography, and the construction of objects with high symmetry. The broader impact of the project is primarily through the implementation of new algorithms in GAP, a leading, open access computer algebra system that provides computing environment for research in group theory, algebra, graph theory, coding theory, and design theory. GAP development also represents a significant contribution to education as there is an increasing demand to use GAP in undergraduate abstract algebra courses.","title":"AF: Small: Collaborative Research: Groups in Computer Science","awardID":"1017182","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[451148,451149],"PO":["565251"]},"168656":{"abstract":"This project is extending the science of automatic programming, using concepts derived from evolutionary biology and software engineering, to permit the evolution of general and robust computational systems with multiple interacting functionalities and interfaces. The project uses the PI's Push programming language as the target language for evolved programs. Push programs are syntactically unconstrained, which facilitates evolution, but they can make use of arbitrary control and data structures; this supports the evolution of complex, modular programs.<br\/><br\/>This project will add new features to the Push language and develop new methods that allow requirements specifications and tests, of the type employed in software engineering practice, to be transformed into fitness functions that drive evolution. The cumulative effect of these extensions will be to support the evolution of significantly more general and robust computational systems.<br\/><br\/>The effectiveness of the technologies developed in this project will be demonstrated in two application areas: the automatic programming of small but complete productivity software applications and the automatic programming of robustly intelligent software agents for complex, time-varying economic games. The project is contributing to long-standing goals in computer science of building robustly intelligent systems and automatic synthesis of useful computer programs.","title":"RI: Small: RUI: Evolution of Robustly Intelligent Computational Systems","awardID":"1017817","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["554244"],"PO":["562760"]},"176037":{"abstract":"This travel grant requests funds to support graduate student travel to the Symposium on Principles of Programming Languages (POPL). This is a top conference in Computer Science for research and education in the core areas of Software and Hardware Foundations program. The funds enables students to hear the latest results in the field, meet established researchers, and build community with the next generation of researchers.","title":"Funding to Support Student Attendees to POPL 2011","awardID":"1058624","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["518195"],"PO":["564388"]},"168546":{"abstract":"With the advent of sensor-rich mobile devices such as smartphones, an increasing number of people are sharing personal \"contextual\" information like location, activity, and health\/fitness information with members of their social network. To enhance privacy for people sharing such information, a large body of research has focused on ways for users to specify who should be authorized to access their information. This research improves end-user privacy by addressing the related question of \"Who is accessing my information and to what extent?\". Providing users with an accurate sense of their \"exposure\" will enable them to better control how their contextual information is shared and will help mitigate emerging privacy risks.<br\/><br\/>This research advances the state of the art in privacy by formalizing the notion of exposure-awareness research, and by investigating metrics that can be used to quantify a person?s exposure, developing usable feedback models and visualizations that leverage these metrics to convey exposure, and creating exposure control extensions to established policy architectures to help users control exposure and refine their data sharing policies over time. The proposed research will thus allow ordinary people to proactively rein in the amount of personal information shared online, and will reduce the privacy risks for the large population of users who are increasingly using social-networking applications to share personal contextual information.","title":"TC: Small: Collaborative Research: Improved Privacy though Exposure Control","awardID":"1017229","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["534206"],"PO":["565264"]},"168667":{"abstract":"Traditionally, there has been an isolation of responsibilities of<br\/>physical layer (PHY) and higher layers of the network stack leading to<br\/>severe inefficiencies in bandwidth-limited wireless<br\/>networks. Remedying these inefficiencies requires rethinking and<br\/>redesigning wireless protocols such that higher layers and PHY work in<br\/>synergy. This project explores three schemes under the PHY-Informed<br\/>Networking (PHY-IN) framework. 1) Carrier Sense Multiple Access with<br\/>Collision Notification (CSMA\/CN) mechanism detects and aborts<br\/>collisions, breaking away from the existing collision avoidance<br\/>(CSMA\/CA) based schemes such as 802.11. 2) Constellation BAsed Rate<br\/>(CBAR) adaptation scheme jumps to the best feasible rate suitable for<br\/>a varying channel. 3) Remap scheme permutes bit-to-subcarrier<br\/>assignment for a retransmission to improve the chances of its success.<br\/>The PHY-IN framework has the potential to impact the landscape of<br\/>future wireless networking protocols. Apart from mentoring both<br\/>undergraduate and graduate students into independent researchers, this<br\/>project, involving an EPSCoR university and a research lab, will also<br\/>help broaden the participation and industry collaboration.","title":"NeTS: Small: Collaborative: PHY-Informed Networking (PHY-IN): Rethinking Wireless Protocol Design with the Knowledge of PHY","awardID":"1017871","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518400"],"PO":["557315"]},"176169":{"abstract":"Future multicore processor systems will have a growing amount of system-wide shared resources. However, shared resources will present significant undesirable asymmetry. For example, the capabilities of processor cores, cache access latency, and memory access cost will differ depending on the time and the location of their usage. If such asymmetry is not properly managed, the full potential of the multicore computing paradigm will not be achieved. This exploratory research will investigate a novel predictive resource management framework called MAESTRO. The proposed framework automatically learns asymmetry in the system and useful application behavior; the learned knowledge is accumulated and refined; and resource management decisions, such as cache capacity allocation, are made in a predictive manner by exploiting the accumulated knowledge. It is expected that MAESTRO's predictive strategies with detailed system and application knowledge will be a more effective solution to new multicore resource management problems than conventional reactive strategies with limited knowledge. The PI will validate this expectation with solid system prototyping and by studying two target resource management problems.<br\/><br\/>The project has the potential to impact the way future computer systems are designed and managed. It is inter-disciplinary by nature and requires understating of applications, computer architecture, OS and machine learning. Students working on this project will receive rigorous inter-disciplinary training.","title":"EAGER: Foundations for Predictive Resource Management in Next-Generation Multicore Processor Systems","awardID":"1059283","effectiveDate":"2010-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["475186"],"PO":["366560"]},"168436":{"abstract":"Network coding brings the promise of increased wireless network capacity by decreasing the overall number of<br\/>transmissions. In practice however, many challenges remain in realizing the gains from network coding. In particular<br\/>the interactions between network coding and transmission rate control have not been carefully studied to date.<br\/>While transmission at higher rates favor a capacity increase, they can diminish overhearing possibilities, a key requirement<br\/>of network coding.<br\/>This proposal considers the problem of transmission rate control and network coding in a holistic<br\/>way. A framework that examines the interdependencies between the use of network coding and multiple transmission<br\/>rates with respect to various functions spanning the link and routing layers, is developed.<br\/><br\/><br\/>The following tasks are being undertaken: (i) Design a network-coding aware transmission rate control module<br\/>that allows nodes to transmit at the high bit rates while at the same time facilitating network coding.<br\/>(ii) Design a set of functions at the link and routing layers that provide the best trade-offs between applying<br\/>network coding and controlling interference and network congestion<br\/>(iii) Implement and extensively evaluate a unified framework combining all of our functional modules on wireless testbeds.<br\/><br\/>The proposed research is tightly knit with new education programs by establishing wireless teaching<br\/>laboratories and introduce cross-disciplinary courses that bridge the physical and higher layers.","title":"NeTS: Small: Collaborative Research: Harnessing Network Coding Gains in Multi-Rate Wireless Networks","awardID":"1016748","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518380"],"PO":["557315"]},"168678":{"abstract":"This project contributes to the exciting field of geo-stream processing. <br\/>Specifically, an integrated real-time geo-stream processing and monitoring <br\/>system called AegisDB will be built and the research environment and results <br\/>will be leveraged to stimulate learning at the K-12, undergraduate, and <br\/>graduate levels. <br\/><br\/>The AegisDB system includes a Geo-Stream Algebra which uses a data-type-<br\/>based approach as opposed to a traditional tuple-based approach for <br\/>representing and querying geo-streams. The STREAM data types of the <br\/>algebra unify static data, traditional streams, geo-streams from fixed <br\/>locations, and geo-streams that move. The proposed Aggregate Algebra <br\/>generalizes the operator GROUP BY to generalized aggregations (GAs) <br\/>and bridges the fundamental gap between point observations from sensors <br\/>and spatio-temporally continuous phenomena. Several novel <br\/>spatial-centric operator optimization techniques are proposed, <br\/>which include a velocity-based filtering that utilizes the physical <br\/>limitations of most moving objects and a spatial-coverage-based query <br\/>combination that combines geo-stream queries based on <br\/>their intended spatial coverage.<br\/><br\/>The proposed AegisDB system will transform the ways to define and monitor <br\/>more sophisticated spatio-temporal events for alerting purposes. The result is <br\/>the significantly improved realtime access to important spatio-temporal events <br\/>related to our lives by professionals and the general public. The system will <br\/>be critical for important domains including transportation, environmental <br\/>science, hazard monitoring, and emergency responses. <br\/><br\/>This project has strong education and outreach components. Environmental <br\/>models for K-12 teachers and students using real-time environmental datasets <br\/>will be designed. An informal session on how to collect, store, and distribute <br\/>environmental data will be presented through the Family Fun Science <br\/>Saturday events of the Elm Fork Education Center of UNT. A course module <br\/>on geo-stream processing will be developed. Women and minorities will be <br\/>recruited into the research project. Undergraduate students looking for <br\/>research opportunities will be mentored. <br\/><br\/>For further information concerning this project see the project web page: <br\/>URL: http:\/\/www.cse.unt.edu\/~huangyan\/AegisDB\/","title":"III: Small: AegisDB: Integrated Real-Time Geo-Stream Processing and Monitoring System: A Data-Type-Based Approach","awardID":"1017926","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[451487],"PO":["565136"]},"167468":{"abstract":"Across many fields of science, engineering, and business, massive data sets are being generated at unprecedented rate by high-bandwidth sensors and cameras, large-scale simulations, or web-enabled large scale data collection. Much of this data has a geometric character, either directly or indirectly. For example, second generation LiDARs can map the earth's surface at 15-20 cm resolution; the Large Synoptic Telescope is set to produce about 30 terabytes of data each night; thirteen hours of video are uploaded to YouTube every minute; Facebook manages over 40 billion photos requiring more than one petabyte of data.<br\/><br\/>These data sets provide tremendous opportunities to enable novel capabilities that were unimaginable a few years ago. Capitalizing on these opportunities, however, and transforming these massive amounts of heterogeneous data into useful information for vastly different types of applications and users requires solving challenging algorithmic problems. An effective way of addressing this challenge is by designing efficient methods for producing informative yet succinct summaries of such geometric data sets. These summaries must work at multiple scales, and allow a wide variety of queries to be answered approximately but efficiently. The goal of this project is to study the theoretical underpinnings of compact representations and efficient algorithms for organizing, summarizing, cross-correlating, interlinking, and querying large distributed geometric data sets.<br\/><br\/>This project will design methods for computing summaries of many kinds of flavors, all with provable properties. Summaries can be combinatorial and metric (core sets and kernels), algebraic (linear sketches), topological (persistence diagrams), feature-based, and structural (encoding self-similarities in the data). The properties they aim to capture extend from low-level metric attributes, such as the diameter or width of a point set, to higher-level attributes revealing the internal structure of the data, as in the detection of symmetries and repeated patterns. This processing must be done in the presence of uncertainty in data coming from sensors, and optimize multiple performance measures, including communication cost for data distributed across multiple locations in a network. Another key aspect of this project is that it aims to understand not individual data sets in isolation but rather the inter-relationships and correspondences among different data sets, and to do so by communicating only summary information, without even having all the data in one place. <br\/><br\/>This work touches upon many topics in theoretical computer science and applied mathematics including low-distortion embeddings, compressive sensing, transportation metrics, spectral graph theory or harmonic analysis, machine learning, and computational topology.","title":"AF: Large: Collaborative Research: Compact Representations and Efficient Algorithms for Distributed Geometric Data","awardID":"1012042","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":["560190"],"PO":["565157"]},"168326":{"abstract":"This award seeks progress in new areas of computational geometry: specifically, collective behavior, sublinearity, hereditary structures, and low-entropy geometric algorithms. Recent work on multiagent agreement systems has revealed the great potential of a geometric approach to the subject. A new generating function, the \"total s-energy\", shows considerable promise for the study of consensus. A thorough investigation of this new device is the starting point of this project. <br\/><br\/>Geometric data tends to capture a vast amount of coherence and hence little entropy. The second part of this project looks at four instances of this phenomenon: Markov sources, hereditary complexity, sublinear computing, and self-improving geometric algorithms. In the first case, the data is generated by a Markov chain; in the second, it is presented within a larger structure that is given explicitly; in the third, the data is only accessible in limited amounts through random sampling; in the fourth, it comes from an unknown memoryless low-entropy distribution. In all cases, the objective is the same: to go beyond worst-case analysis and make room for a more realistic analytical framework.","title":"AF: Small: New Directions in Computational Geometry","awardID":"1016250","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":[450650],"PO":["565157"]},"168689":{"abstract":"The telecommunications industry is on the verge of major structural change. Historically, the industry's regulator has allocated licenses for the utilization of well-defined bands within the available spectrum. Unlike other commodities, no secondary market for the spectrum has ever developed. Technological limitations as well as legal and regulatory constraints may have contributed to this fact. Today the evidence clearly points to a situation of relative under-utilization of the spectrum. A \"cognitive radio network\" (CRN) is a new paradigm for wireless communications aimed at enabling a more efficient use of the spectrum. This research project focuses on two significant technical and regulatory issues which must be resolved to ensure successful deployment of cognitive radio networks. <br\/><br\/>The first issue relates to the network?s ability to manage interference in a distributed fashion without cooperation from the primary users. Here, the research tasks include the analysis, from a signal processing and algorithmic point of view, of various price-based schemes for dynamic spectrum allocation in a broad range of CRN scenarios under a variety of regulatory restrictions. The second relevant issue pertains to the design of a secondary market for the spectrum. The research investigates the analysis of various design choices taking into account specific spectrum sharing techniques and the associated behavior of sellers (i.e. primary users\/primary network service providers (NSP)) and buyers (i.e. cognitive users).<br\/><br\/>The proposed work targets new models to (i) facilitate distributed spectrum sharing and spectrum decision in a broad range of CRN, and to (ii) provide additional insights into the operation of a secondary spectrum market which could prove useful for regulatory design.","title":"CIF: Small: Dynamic Pricing of Interference in Cognitive Radio Networks","awardID":"1017982","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["556971","540771"],"PO":["564924"]},"167479":{"abstract":"Data Protection laws that exempt data that is not individually<br\/>identifiable have led to an explosion in anonymization research.<br\/>Unfortunately, how well current de-identification and anonymization<br\/>techniques control risks to privacy and confidentiality is not well<br\/>understood. Neither is the usefulness of anonymized data for real-world<br\/>applications. The project addresses anonymization on three fronts:<br\/><br\/>1) Textual data, even when explicit identifiers are removed (names,<br\/>dates, locations), can contain highly identifiable information. For<br\/>example, a sample of chief complaint fields from the Indiana Network<br\/>for Patient Care (INPC) found several instances of \"phantom limb<br\/>pain\". Amputees can be visually identifiable, but the HIPAA Safe<br\/>Harbor rules do not list this as \"identifying information\". Any<br\/>policy explicitly listing all types of identifying data is likely to<br\/>fail. Through a joint effort with computer science and linguistics,<br\/>the project is developing new methods to remove specific details from<br\/>text while preserving meaning, eliminating such highly identifiable<br\/>information without a priori knowledge of what would be identifying.<br\/><br\/>2) Current anonymization research is based on unproven measures of<br\/>identifiability. Through a re-identification challenge on synthetic<br\/>data (but based on real healthcare data), the project is evaluating<br\/>the efficacy of these measures. Interdisciplinary teams of students<br\/>are given challenge problems - anonymized data with hypothetical<br\/>healthcare data - and asked to make (hypothetical) inferences about<br\/>health information of individuals. The results can be used to<br\/>calibrate the effectiveness of different anonymization measures.<br\/><br\/>3) The utility of anonymized data has been a concern among research:<br\/>Does anonymized data provide credible research results? By partnering<br\/>with healthcare studies at the Kinsey Institute and Purdue University<br\/>School of Nursing, the project is comparing analyses on original data<br\/>with analyses on anonymized data, and evaluating the impact of types<br\/>of anonymization on research results. A related issue is determining<br\/>the impact on data collection: Are individuals more candid in their<br\/>responses if they know data will be anonymized? Outcomes are broadening<br\/>the scope of research that can be performed on anonymized data, while<br\/>ensuring that researchers know when access to individually identifiable<br\/>data (with attendant restrictions and safeguards) is needed.<br\/><br\/>Through these tasks, the project is advancing our ability to utilize<br\/>the wealth of data we now collect for the benefit of society, while<br\/>ensuring individual privacy is protected.<br\/><br\/>For further information see the project web site at the URL:<br\/>http:\/\/projects.cerias.purdue.edu\/TextAnon","title":"TC:Large:Collaborative Research:Anonymizing Textual Data and its Impact on Utility","awardID":"1012081","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[448728,448729],"PO":["565136"]},"166148":{"abstract":"Computing Groebner bases and finding primary decomposition of polynomial ideals are two closely related topics that are fundamental in computational algebraic geometry. Groebner bases provide an essential tool for computation in algebra, especially in solving systems of multivariate polynomials. The primary decomposition theorem was proved by the late chess Master Emanuel Lasker in 1905 for polynomial rings and Emmy Noether in early 1920s for general Noetherian rings. Primary decomposition is a crucial step in computerizing schemes in algebraic geometry, yet it is still a big challenge to provide efficient algorithms for reasonable sized systems of polynomials. The major bottleneck is in computing Groebner bases for systems of polynomials that appear in the process of computing primary decomposition. The main goal of the project is to develop new efficient algorithms for computing Groebner bases and for finding primary decomposition.<br\/><br\/><br\/>Solving polynomial systems is ubiquitous in sciences and engineerings. <br\/>Its applications include, but not limited to, computer vision, computer-aided designs, coding theory, cryptography, robot kinematics, computational biology, etc. Work in this project would benefit major computer algebra systems and their users in education and industry. It also bears direct applications in reliable and secure communications from Internet commercial to military combats and from cell phones to outer space explorations.","title":"Topics on Computational Algebra","awardID":"1005369","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[445138],"PO":["565286"]},"168458":{"abstract":"In contrast with most existing dynamic spectrum access (DSA) paradigms which impose a `foe' relationship between primary users (PUs) and secondary users (SUs), this project investigates a new DSA paradigm which encourages PUs and SUs to help each other by trading spectrum ownership for improved overall performance. Specifically, this project designs two different schemes: (1) Give-And-Take (GAT) and (2) Network Coding + Secondary User Relay (NC+SR). The former does not need to change the radio or the protocol stack of PUs, while the latter assumes that PUs and SUs are capable of performing network coding. In GAT, SUs help deliver the traffic of PUs and in return are allowed to access licensed spectrum in a manner disruptive to PUs. The help constitutes the `give' part, and the disruptive spectrum accesses constitute the `take' part. In NC+SR, SUs help relay PU traffic between PUs. When relaying PU packets, SU relay nodes may encode SU packets onto PU packets via network coding, so that SU packets get a `free ride' on PU packets. Both GAT and NC+SR promise the improved performance of PUs as well as SUs. The project studies the issues of protocol design and performance optimization of the two schemes. Results from this project are expected to encourage incumbent licensed users to embrace DSA to further improve the capacity of wireless network. The project sustains a collaborative research team, and involves both graduate and undergraduate students, particularly the underrepresented minority students,<br\/>in research.","title":"NeTS: Small: Collaborative Research: Learning to help: Trading spectrum ownership for performance","awardID":"1016841","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["528443"],"PO":["565303"]},"167138":{"abstract":"Experiments in which subjects reach from one point to another are one of the workhorses of movement science. Many questions ranging from basic neuroscience (How do neurons represent movement?) to clinical (How do patients with Parkinson's Disease move differently from healthy controls?) to behavioral (How does loud noise lead to movement errors?) are studied using this paradigm. Moreover, many models have been constructed to describe reaching, and these models have strong links to robotics and computer science. This project will develop a database that contains both experimental results as well as models of reaching movement. The database will make it easier for experiments to falsify models and for models to be designed so that they overcome the limitations of previous models. <br\/><br\/>The objective of the joint database design is that multiple models should be able to make predictions for a given experimental dataset, and likewise, multiple experimental datasets can be used to constrain a given model. The project will start with a relatively narrow set of experiments and models, widening the scope gradually over the course of the project. Research on reaching spans a broad set of questions and a broad set of experimental methods; however, many experimental approaches share significant aspects. The objective of the project is to enable inclusion of the results of a broad set of communities while keeping the database sufficiently coherent to be useful. <br\/><br\/>To enable the inclusion of a broad set of participants who will share models and data the proposed project will include summer schools, workshops and competitions where participants can compare models. Access to the database will be free and open, and this possibility of access to high quality data promises to allow scientists from any movement related discipline to productively interact with movement data and models.","title":"CRCNS: Data Sharing: A Joint Database of Experiments and Models of Reaching Movement","awardID":"1010336","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[447672,447673,"549464","529059"],"PO":["564318"]},"168359":{"abstract":"The goal of this research is to examine how the incorporation of culturally specific values into health-related ICTs might increase the likelihood of their adoption, as well as how those culturally specific values bear on their practical use. This research sits at the intersection of two research thrusts that are gaining momentum within Human Centered Computing, and contribute to the intellectual development of both. First, this proposed research contributes to the human-centered health ICT research domain by explicitly accounting for culturally specific values in the design of applications. Medical evidence in the U.S. shows that health interventions will likely not succeed unless they are culturally relevant. And yet, little research to date has attempted to explicitly incorporate culturally specific values into design, or has evaluated value-sensitive systems in use. Results of this research will show how different values can be designed into health ICTs, and how that affects their usage. It will also surface the values implicit in current health ICTs. Second, there is a body of research (largely in Human Computer Interaction for Development (HCI4D)) that argues that culture must be explicitly taken into account in the design of ICTs for them to succeed. When it is accounted for, significant innovations can result. This literature makes a compelling case for explicitly accounting for cultures outside the United States, but simultaneously points to a surprising omission: knowledge about the ICT implications of cultural diversity within the United States. This research addresses that gap by showing how explicit attention to cultural values can lead to transformative socio-technical systems for health and wellness. Further, as has been reported within the HCI4D literature, focus on culturally specific values also provides opportunities to reflect on assumptions embedded within the methods, frameworks and systems that guide human-centered research. <br\/><br\/>The project will focus on three areas, each answering different research questions. 1) Impact of value discovery and the design and evaluation of ICTs that incorporate those values. The idea that systems have values is an established research finding within HCC. Value Sensitive Design (VSD) explicitly argues for accounting for values in the design of systems. The proposed work will bring research on values in design into the health domain by empirically identifying values and designing them into ICTs that provide culturally relevant health information. Evaluations of each intervention will focus on adoption and rejection patterns with particular focus on use (or not) as related to the values designed into the system. 2) Impact of culturally distinct patterns of collaboration. Collaboration is an essential component of health; support of friends and family complements an individual?s health management. However, public health researchers find that collaboration, particularly cooperation, extends beyond the family to the community in various sub-cultures. These results suggest that opportunities exist to refine our understanding of collaboration, by asking questions about the nature and patterns of interactions surrounding health practices. Questions focus on what is being shared, who is communicating with whom and how, and where ICTs have the most promise for supporting existing modes of collaboration as well as developing entirely new ones.3) How infrastructure differences present an opportunity for transformative solutions. Public health research suggests that culturally tailored health innovations are particularly important in low-income minority communities. But reports suggest that ICT adoption is increasing among these communities, and also that different types of systems are being appropriated because of the differences in infrastructure.","title":"HCC: Small: Culture,Technology and Wellness: Approaches to Improving the Health and Wellness of US Americans","awardID":"1016394","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[450731],"PO":["564456"]},"172682":{"abstract":"This project is aimed at the design and experimental validation of a comprehensive clean-slate future Internet architecture. The proposed MobilityFirst architecture is motivated by the ongoing paradigm shift of Internet usage from today?s fixed PC\/host (client)?server model to emerging mobile data services and pervasive computing applications. The major design goals of the architecture are: mobility as the norm with dynamic host and network mobility at scale; robustness with respect to intrinsic properties of the wireless medium; trustworthiness in the form of enhanced security and privacy; usability features such as support for context-aware services, evolvability, manageability and economic viability. The key components of the MobilityFirst network design are: (1) separation of naming and addressing, implemented via a fast global dynamic name resolution service; (2) self-certifying public key network addresses to support strong authentication and security; (3) generalized delay-tolerant routing with in-network storage for packets in transit; (4) flat-label internetwork routing with public key addresses; (5) hop-by-hop transport protocols operating over segments rather than an end-to-end path; (6) a separate network management plane that provides enhanced visibility; (7) optional privacy features for user and location data; and (8) an integrated computing and storage layer to support programmability. The project?s scope includes architectural design, validation of key protocol components, testbed prototyping of the MobilityFirst architecture as a whole, and real-world protocol deployment on the GENI experimental infrastructure. The results of this project will provide architectural guidance for cellular-Internet convergence, and are expected to influence future technical standards in the networking industry.","title":"FIA: Collaborative Research: MobilityFirst: A Robust and Trustworthy Mobility-Centric Architecture for the Future Internet","awardID":"1040648","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["560207"],"PO":["565090"]},"172693":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040708","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["533300"],"PO":["565090"]},"171483":{"abstract":"This is funding to support the development of Gaming Against Plagiarism (GAP), an online, self-directed, interactive game that provides a role-playing environment in which Science, Technology, Engineering, and Mathematics (STEM) graduate students learn to recognize and avoid plagiarism. The goal is to train STEM graduate students in U.S. institutions of higher learning to function effectively and ethically as authors within multi-national research teams. Given the substantial documentation of significant differences in cultural attitudes towards plagiarism, cutting-edge 21st century science will require a common ground for preparing and publishing results in the scientific literature. GAP will provide this common ground. To this end, GAP will employ strategies to affect behaviors that influence students' ethical choices, including peer behavior, institutional norms, and differing cultural practices. It will be collaboratively designed, tested, and evaluated by means of an iterative development process by an interdisciplinary team of experts in graduate science education, gaming, academic integrity, intellectual property rights, and educational digital media production. Six NSF Engineering Education awardee institutions (Purdue University, Virginia Commonwealth University, University of Houston, Loyola Marymount University, Oakland University, and Rowan University), along with the College of Sciences at the University of Central Florida, have agreed to assist the PI in the testing and iterative refinement of the GAP intervention. The GAP project will be open source and freely available to these institutions and others, in order to create the broadest possible national impact.<br\/><br\/>Broader Impacts: GAP will be tested during development to ensure that it is both adaptable and scalable across a wide spectrum of American higher education settings. The game's open source platform will enable universities across the nation to download the software and to incorporate modifications to serve the needs of the particular institution (e.g., to integrate their own code of conduct, relevant policies, and branding) while maintaining a common focus on what constitutes responsible conduct of research. Although the initial game will emphasize plagiarism, the platform will be specifically designed so as to accommodate additional game development on other ethical issues (such as the falsification of data).","title":"Gaming Against Plagiarism","awardID":"1033002","effectiveDate":"2010-09-01","expirationDate":"2012-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":[459102,459103,459104,459105,459106,"564596"],"PO":["565227"]},"171494":{"abstract":"This award supports the Third IFIP Working Conference on \"Verified Software: Theories, Tools, and Experiments (VSTTE 2010)\", August 16-19, 2010, hosted by Heriot-Watt University, Edinburgh Scotland. The construction of reliable software poses one of the most significant scientific and engineering challenges of the 21st century. Professor Tony Hoare of Microsoft Research has proposed the creation of a program verifier as a grand challenge for computer science and outlined an international program of research combining many disciplines such as the theory and implementation of programming languages, formal methods, program analysis, and automated theorem proving. The VSTTE conference series was established by the research community in response to this challenge. The VSTTE 2010 program includes two workshops focusing on the areas of: (1) theories, and (2) tools and experiments. This award is enabled through support provided by the NITRD High Confidence Software and Systems (HCSS) interagency Coordinating Group.","title":"CPS: The Third Working Conference on Verified Software","awardID":"1033105","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["555363"],"PO":["565274"]},"163871":{"abstract":"The success of the future Internet will not be measured by performance alone, but by its social and societal effects that alter our quality of life. The next-generation Internet must connect not only machines but also users: families and friends, representatives and rights advocates. There are immense technical challenges in facilitating communication while protecting user privacy and guarding their security. We address three key challenges. First, we apply user-focused research into developing practical secure communication between friends, laying the groundwork for social messaging without trusting centralized authorities to provide identities. Second, we develop advanced cryptographic techniques for processing private data without divulging it to application providers, placing private social applications on a solid theoretical foundation. Finally, we propose to fundamentally change how cooperation is encouraged and misbehavior is punished in distributed applications by embedding social network data into the design of applications.<br\/><br\/>This work has important broader impacts. Social networking is incredibly popular and maintaining privacy is a significant problem within these systems. The desire for privacy prevents individuals from participating fully and makes those who do participate vulnerable to various problems including potential identity theft. Because of the importance of the problem and problem domain, the results of our research will have significant public impact. Graduate and undergraduate students working on this proposal will gain experience with social applications, evaluating cryptographic protocols, and building systems that combine social data. We have actively involved undergraduate students in our research, and expect to continue.","title":"NetSE: Medium: Collaborative Research: Privacy Preserving Social Systems","awardID":"0964541","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["548322","519626",438680],"PO":["565136"]},"164510":{"abstract":"Peers are powerful socializing agents in the lives of adolescents, that is, youth between the ages of 11 to 17 years. Decades of sociological, psychological, and criminological literature have found that youth aggression (e.g., bullying, fighting) and delinquency (e.g., truancy, vandalism, alcohol and drug use) are predominately determined by the behaviors of youth in one's primary friendship. Computer involvement in adolescent networks is growing in recent years, giving rise to new group dynamics and new opportunities to study group interactions and individual preferences.<br\/><br\/>The work proposed here will develop algorithms and methodologies for inferring adolescent network structure from partial observations about individuals. It will take information collected from small middle schools to infer information about larger groups of students. The PIs will create a set of games for use in the classroom that would collect data for this research while also providing information about class dynamics. The data sets collected through those games will be compared with previous approaches.<br\/><br\/>This research has potential impact on a wide range of disciplines. Innovations in identifying adolescent network structures will allow better estimation of the role of peers in the rising rates of risky adolescent behaviors. The intellectual partnership between an expert in computer science and one in psychology represents an important step in bringing innovative computational thinking to better understand issues of real-world significance such as youth aggression and delinquency.","title":"SoCS: Analyzing Partially Observable Computer-Adolescent Networks","awardID":"0968552","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[440709,440710],"PO":["565342"]},"174432":{"abstract":"The security of the national computing infrastructure is critical for consumer confidence, protection of privacy, protection of valuable intellectual property, and even national security. Logic-based approaches to security have been gaining popularity, in part because they provide a precise way to describe and reason about the kinds of complexity found in real systems. Perhaps even more importantly, automated reasoning techniques can be used to assist users in navigating this complexity. Despite the promise of automated reasoning, its use in practical applications is still limited. One of the primary reasons for this is that for many problems, automated reasoning methods are not fast enough, especially for use in interactive environments (such as browser plug-ins in desktop computing, or mobile applications running on smart phones and PDAs). This project aims to address the performance weakness of automated reasoning by investigating novel designs and algorithms with the unifying theme of exploiting parallelism. The project will focus on three main areas of automated deduction: Boolean satisfiability, first-order reasoning, and satisfiability modulo theories.","title":"TC: EAGER: Collaborative Research: Parallel Automated Reasoning","awardID":"1049674","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521573"],"PO":["565264"]},"174564":{"abstract":"Popular applications such as email, image\/video galleries, and file storage are increasingly being supported by \"cloud\" platforms in residential, academia and industry communities. The next frontier for these user communities will be to transition \"traditional desktops\" that have dedicated hardware and software configurations into \"virtual desktop clouds\" that are accessible via thin clients. The project aim is to develop optimal resource allocation frameworks and performance benchmarking tools that can enable building and managing thin-client based virtual desktop clouds at Internet-scale. Virtual desktop cloud experiments will be conducted under realistic user and system loads by leveraging multiple kinds of GENI resources such as aggregates, user opt-in mechanisms, measurement services and experimenter workflow tools. Project outcomes will help in minimizing costly cloud resource over-commitment, and in avoiding thin client protocol configuration guesswork, while delivering optimum user experience. Further, they will positively impact computer desktop user communities, GENI-like testbeds, and equipment vendors.","title":"EAGER: Enabling Mobile Services through In-network Storage and Computation--Evaluation using the GENI Infrastructure","awardID":"1050157","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["549845"],"PO":["564993"]},"174685":{"abstract":"Navigating in online virtual worlds is similar to searching the Web prior to the development of the first search engine. Users can find regions of interest to them through serendipity, by browsing or word of mouth, but they can only search the specific world they are on. This exploratory project investigates an enabling mobile crawler technology that can collect information across multiple worlds, and allows virtual worlds to grow in a distributed, multi-server, multi-platform manner. Of particular interest is content in 3D environments that is interconnected with the traditional flat Web. In this research explores strategies for gathering content from 3D environments and, using that content, gain a better understanding of how users are utilizing 3D environments and how they might benefit from more accessible, cross-platform search services. Crawling in 3D environments has many similarities with flat Web crawling but has additional constraints that may constrain how much content can reasonably be collected. The gathered data will further be explored, e.g., how frequently content changes in 3D environments and how users utilize linking in virtual worlds as compared to the linkage structures on the Web. In addition, this project investigates how traffic patterns in 3D environments are related to links, recommendations, and groups. <br\/><br\/>The research challenges in this project are: <br\/>(1) Gathering content from distributed 3D environments. This includes approaches for navigating around the 3D environment for information collection are explored, mapping the 3D environment space, analysis of the impact of additional information that can only be collected via interaction, and characterization of the additional information that is available through internal and external links.<br\/>(2) Gaining a better understanding of user behavior. Research focuses on investigating ways in which user linkage patterns are similar to, and different from, user linkages on the flat Web and whether or not avatar traffic can be used to identify sites of broader user interest that can be exploited by the search process.<br\/>(3) Supporting search across multiple platforms. The aim is to develop a 3D 3D object ontologies and a schema, similar to RSS, that will enable virtual world servers to more easily support sharing of their data with an external search service.<br\/><br\/>As 3D environments become both more prevalent and more diverse, the need for a cross-platform search service will continue to grow. By increasing the visibility of content across platforms and servers, this project will allow content creators to focus on creating higher quality 3D environment by providing effective search mechanism for finding the desired content in a large, distributed, virtual world.<br\/><br\/>The expected results are expected to provide foundations for exploring questions of how to discover and rank a wide range of content in virtual reality, mirror world, and augmented reality environments. By creating an open platform, this project will provide opportunities for more researchers to work in 3D environments. The database of regions, traffic, and linkages will be made available for downloading and analysis by other researchers. Research results, gathered data and the crawler will be made available as freeware via the project Web site (http:\/\/virtualworldsearch.uark.edu).","title":"III: EAGER: Mapping Three-Dimensional Virtual Worlds","awardID":"1050801","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[468586,468587,468588],"PO":["563751"]},"173002":{"abstract":"The University of Washington (UW) proposes an extension for the Alliance for Access to Computing Careers (AccessComputing). AccessComputing engages individuals with disabilities as well as those who support, serve, guide, educate, and employ them in transformational efforts to make the computing disciplines more welcoming and accessible to individuals with disabilities, including post-9\/11 veterans. AccessComputing, a combined effort of UW's Department of Computer Science and Engineering and DO-IT (Disabilities, Opportunities, Internetworking, and Technology) Center, in partnership with diverse set of postsecondary institutions, BPC Alliances, and computing organizations. The Alliance aims to (1) increase the capacity of postsecondary institutions, precollege educators, BPC Alliances, and industry to fully include individuals with disabilities in computing fields; (2) provide direct services to individuals using evidence-based practices that support those individuals as they move through critical junctures on the way to computing careers; (3) build synergistic and lasting relationships among stakeholders to promote systemic changes toward inclusiveness in computing education and careers; and (4) expand an online resource center to share research and successful practices worldwide. Applying methods grounded in knowledge management, collaboration, and social network theory and practice, this extension to the AccessComputing award will formalize earlier and new relationships into a multitier organizational structure of partners, collaborators, and affiliates. Outcomes for individuals with disabilities will be documented by tracking the progress of student participants as well as institutional enrollment and graduation data; and results will be compared to local, regional, and national data with respect to the academic and career success of people with disabilities.","title":"BPC-AE: AccessComputing Second Extension","awardID":"1042260","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["485574",464009],"PO":["560704"]},"174575":{"abstract":"The Global Environment for Network Innovations (GENI) is a novel suite of infrastructure now being designed and prototyped to support experimental research in network science and engineering. This new infrastructure challenges us to understand and rethink networks broadly and at several layers of abstraction; from the physical substrates through the architecture and protocols to the networks of people, organizations and societies. GENI experimental research will range from network and distributed system design to the theoretical underpinnings of network science, network policy and economics, societal values and the dynamic interactions of the physical, social and virtual spheres in communication networks. Such research holds great promise for new knowledge about the structure, behavior, and dynamics of our most complex systems ? networks of networks ? with potentially huge social and economic impact.<br\/><br\/>While planning has been ongoing for a number of years, a meso-scale national deployment has just begun. One critical, immediate goal is to GENI-enable a number of college and university campuses across the US. These campus-wide GENI deployments are still in the very earliest stages of exploration. Yet, there is high utility in opening up these campuses for experimentation now. A recent workshop at Princeton resulted in about a dozen research teams ready to deploy their experiments on GENI. This EAGER will allow five campuses ? Georgia Institute of Technology, Indiana University, Rutgers University, University of Massachusetts, Amherst, and University of Wisconsin, Madison ? to introduce and debug OpenFlow and WiMAX campus infrastructure so that experimentation can be carried out this fall and winter. The plan is for GENI-enabled campuses to be operated by campus IT staff under the overall direction of the GENI Project Office. This funding will allow for about 2 person-months of staff support per campus. All of the campuses have developed schematics for their campus build-out, have obtained support from the campus CIO, and are ready to deploy. <br\/><br\/>Experimental research into untested and novel ideas at this scale could have very substantial potential pay-offs in terms of opening up a new frontier in computer science research, and might well drive rapid and innovative advances in those research fields that begin to employ the GENI suite of infrastructure.","title":"EAGER: Exploring the Transformative Potential of \"GENI-enabled\" Campuses","awardID":"1050190","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["521729"],"PO":["564993"]},"164301":{"abstract":"Virtual learning environments are proliferating, yet the social interactions between learners in these contexts remain challenging. Cues (such as gestures) that facilitate reading other people in face-to-face contexts are absent in many virtual environments. However, these contexts can endow participants with communicative capabilities that are not possible face-to-face. Because social interactions and relationships are pivotal to an array of outcomes, we need to facilitate interpersonal communication in these contexts.<br\/><br\/>This research will conduct four experiments to capitalize on the affordances of computer mediated learning environments to improve the relationships participants from within them. These experiments will examine undergraduate and middle-school learners who are learning about complex causality within ecosystems. In each study, relationships between learners will be improved through transformed social interactions, an approach in which participants are endowed with capabilities for navigating their social world that humans do not normally possess. Specifically, participants will be able to take the perspective of other participants and to increase their similarity to other participants.<br\/><br\/>Intellectual Merit. This study makes important intellectual contributions through experimentally testing ways to improve learners' relationships, examining the impact of these interventions on learning and motivation (and affective outcomes), and advancing the state of the art in non-verbal signals in computer-mediated communication.<br\/><br\/>Potential Broader Impacts. Because of the proliferation of online learning communities, the capacity for these environments to involve a diverse cross-section of students, and the novel, widely-replicable, computational approach, these studies may have broad impact across the fields of education, communications, and computer science.","title":"SoCS: Enhancing Immersive Social Perspective Taking and Perceived Virtual Similarity to Enable Intelligent Social Relationships","awardID":"0966838","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["519305","553205","451500",440104],"PO":["563324"]},"173024":{"abstract":"The University of Texas, El Paso proposes to extend the work of the Computing Alliance of Hispanic-Serving Institutions (CAHSI) in collaboration with their partners: California State University-Dominguez Hills, California State University-San Marcos, Dade College, Florida International University, New Mexico State University, Texas A&M University-Corpus Christi, University of Houston Downtown, University of Puerto Rico Mayaguez, and the University of Texas Pan American. Together these Hispanic-Serving institutions will work to adapt proven strategies that have positive impact on (1) the number of Hispanic students who enter the workforce with computing degrees; (2) the retention and advancement of Hispanic students and faculty in computing, and (3) the development of sustainable, competitive education and research programs. To accomplish this, CAHSI has already implemented a number of programs, including Peer-Led Team Learning (PLTL) that creates an active learning experience for students and leadership experiences for undergraduates serving as peer leaders, the Affinity Research Group (ARG) model that emphasizes the deliberate and intentional development of technical, team and professional skills and knowledge required for research, and Mentor-Grad that engages undergraduates in experiences and activities that prepare them for graduate studies and the professoriate. CAHSI has a strong record of success: recent bachelor's graduation rates of Hispanics in computer science increased by nearly 25% within their member institution, while over the same time period, the national trend showed a 39% decline. This extension will add two new goals to its agenda (1) institute a sustainable infrastructure that supports CAHSI's continued impact and (2) become recognized as an organization that affects decision-making and cultural change at the local, regional, and national levels. To achieve these goals CAHSI will establish the cyber infrastructure to support collaborations and dissemination of CAHSI practices, establish collaborations beyond the Alliance with organizations and institutions sharing common goals, and promote multicultural awareness in administrators, faculty, and students.","title":"BPC-AE: Computing Alliance of Hispanic-Serving Institutions","awardID":"1042341","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["558105","479700","559621","561141","528389"],"PO":["560704"]},"174355":{"abstract":"This EAGER proposal seeks to develop new, improved approaches, based on single- and multi-objective differential evolution, to the following important problems:<br\/>(i) QoS-based multicast routing in mobile networks; (ii) Energy-efficient routing in hierarchical (two-tiered) wireless sensor networks; (iii) Stability-aware clustering in mobile ad hoc networks with special consideration of group mobility; and (iv) Cross-layer optimization in wireless sensor networks by joint routing and link scheduling in the presence of energy constraints, link interference and noise.<br\/><br\/>The goal is to achieve higher energy saving, better network performance and extended network lifetimes.<br\/><br\/>The novelty of this proposal is that it brings the power of differential evolution, a cutting-edge strategy in present-day computational intelligence research, to a group of outstanding, NP-hard problems in computer networks. It presents novel schemes for encoding of trial solutions and also for designing the differential operator for these problems. This research cuts across conventional subject lines ? it embodies an interdisciplinary and transformative application of ideas from electrical engineering, computer communications, computational intelligence, and statistical machine learning. This has the potential to open up a radically new direction in networking research.<br\/><br\/>The broader impact of this research is far-reaching in this era of ubiquitous and pervasive computing. The efficiency, flexibility, and controllability provided in the proposed methods can be used to save costs and improve the quality of the final products in the industry. The proposal also includes well-thought out plans for integrating research and education. The PI will use this project to involve high-school students, women, and undergraduate\/graduate students in computer science research.","title":"EAGER: Optimization in Wireless Mobile and Sensor Networks: A Novel Paradigm Based on Differential Evolution","awardID":"1049427","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["485221"],"PO":["565303"]},"168800":{"abstract":"This proposal seeks to answer a growing engineering need: the development of robust computationally efficient methods to analyze transient radiation and scattering from electrically large multiscale objects. The proposed work can be categorized into two interrelated areas: (i) building parallel transient potential evaluators for computing interactions between random non-uniform source\/observer pairs wherein separation between two points ranges from a millionth to a thousand of the minimum wavelength; (ii) development of parallel time domain higher-order integral equation solvers that include these potential integrators. The four-fold objectives of this proposal are as follows: (i) rigorous methods that can be integrated with the plane wave time domain (PWTD) algorithm to extend its applicability to the quasi-static regime; (ii) windowed operators that will morph PWTD with beams; (iii) parallel, multiscale, fast potential evaluators that include the above developments; and (iv) integration of these into time domain integral equation solvers. To realize these objectives, advances will be made on two fronts: (i) numerical methods to effect these operations with a proper understanding of error bounds and the means to control them; and (ii) parallel algorithms that are provably scalable. <br\/><br\/>The design and analysis of realistic devices is the holy grail of any computational endeavor. The same is true of Maxwell solvers. As Maxwell's equations form the foundation to a wide array of modern technology, methods developed to efficiently and accurately solve these equations can have wide ranging impact. To date, simulation tools have been complementary to, but have not supplanted experiments. The principal challenge has been bottlenecks posed by complex structural topologies with fine features, embedded in electrically large structures. Our goal-to enable the analysis of field deployable systems-will be realized by making advances in both the underlying numerics and parallel algorithms. These, in turn, will enable transition of this technology from tens of processors to thousands and tens of thousands of processors. Methods developed will yield a robust, accurate, and adaptable code that can be widely adopted in multiple domains in electromagnetics, acoustics, plasma dynamics, etc. To ensure dissemination, the PIs will work with practitioners in industry as well as with the Michigan Center for Industrial and Applied Mathematics. Existing channels in recruitment at MSU and ISU will be utilized to encourage participation by women and minorities. Undergraduate students will be involved through senior design projects and potentially through REU supplements. Additionally, a post-doctoral scholar will be mentored in all aspects necessary to be a successful academic.","title":"AF: :Small: Parallel Transient Solvers for Multiscale Electromagnetics Simulation","awardID":"1018516","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["532976"],"PO":["565251"]},"168701":{"abstract":"Identifying bugs in software continues to be a challenging, but essential problem to solve. One particularly difficult task is ensuring the integrity of large-scale data structures stored in memory. Existing bug-finding techniques, such as static analysis of the code, have not been effective on this problem, especially for complex and highly dynamic software, such as web applications.<br\/><br\/>This project explores a new technique for checking data structures dynamically as the program executes. Dynamic checking is effective and precise, but must be efficient in order to avoid significantly slowing program execution. The key idea in this work is to piggyback checking on the garbage collector, which already periodically visits all data structures in the program. An efficient and precise tool for detecting data structure errors could be widely deployed to improve the reliability of critical software infrastructure.<br\/><br\/>The project consists of three specific avenues of research. The first involves developing a declarative language for expressing dynamic data structure properties, building on existing techniques from static analysis and verification. The second investigates the class of properties that can be checked during a single pass of the garbage collector. The third builds on the machinery of concurrent garbage collection, allowing heap checks to proceed concurrently with the application on available extra CPU cores.","title":"SHF: Small: Dynamic Detection of Heap-Based Bugs","awardID":"1018038","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["553399"],"PO":["564388"]},"174025":{"abstract":"This collaborative project is focused on GIS vector-based spatial data overlay processing through cloud computing. Vector-based processing is considerably more complicated than raster data processing because raster data is based on regular grid-based fixed-size pixels, while vector features have irregular geometric shapes represented by a list of large number of vertices. GIS data files can be very large-scale huge and as such, computational requirements are significant. Cloud platforms such as Azure are appropriate for large-scale computing and storage capabilities. These capabilities combined with accessibility on-demand and other features have made cloud processing very desirable for GIS applications. This exploratory research will attempt to discover distributed algorithms and test their scalable implementations for GIS overlay processing on the Azure platform.","title":"CiC: EAGER: CCollaborative: GIS Vector Data Overlay Processing on Azure Platform","awardID":"1048200","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8010","name":"Computing in the Cloud"}}],"PIcoPI":["526127"],"PO":["565136"]},"168712":{"abstract":"Improving energy efficiency of embedded and mobile systems is a major design challenge. Such systems involve complex algorithms for audiovisual processing, recognition, and communication that heavily utilize digital signal processing (DSP) architectures. This proposal advances a systematic strategy to reduce energy consumption of DSP sub-systems and thereby make major strides towards a new generation of low-energy embedded applications. The main premise behind the proposal is that signal processing algorithms may accept, in a finely controlled manner, some amount of timing errors in return for significant energy savings. Signal processing algorithms have an intrinsic quality floor, set by quantization and roundoff noise. A traditional design paradigm of worst-case margining is highly suboptimal, and by accepting a small amount of low-probability timing errors, significant energy savings of more than 50% are possible.<br\/><br\/>Research under this proposal will result in the development of a formal analysis and synthesis framework for integration into a hardware synthesis flow that supports systematic design of ultra low-energy error-permissive DSP systems. A flow for controlled acceptance of timing errors must fundamentally be based on a new formal notion of quality-energy (Q-E) tradeoff, which is unique to error-permissive signal processing, and which will allow treatment of other Q-E techniques, such as approximate signal processing, consistently within the same framework. To this end, the goals of this project are two-fold: (i) to formally develop models and analysis techniques for controlled timing-error acceptance under given input statistics and quality-energy budgets, and (ii) to develop a comprehensive synthesis flow that allows multiple Q-E techniques to be applied to the co-optimization of quality, energy, area and performance objectives for a large class of algorithms that can generally tolerate a small amount of errors. Results of this work will enable automatic exploration of joint algorithm and architecture tradeoffs for implementation of general quality- and energy-tuned error-permissive systems. The new controlled timing error paradigm will facilitate sustained improvement in the energy efficiency of integrated circuits and digital systems, where ultra low-energy operation will enable use of hitherto infeasible portable, implantable, wireless and autonomous systems.","title":"SHF: Small: Formal Synthesis of Low-Energy Signal Processing Systems Relying on Controlled Timing-Error Acceptance","awardID":"1018075","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["535118","556802"],"PO":["562984"]},"168833":{"abstract":"The trend towards multicore processors and graphic processing units is increasing the need for software that can take advantage of parallelism and concurrency. Unfortunately, concurrent programs have proven to be much more difficult to write and debug than sequential software. This is because concurrent programs often exhibit incorrect behaviors due to unintended interference among multiple threads. Such concurrency bugs are often difficult to find because they typically happen under very specific thread interleavings.<br\/><br\/>Testing and debugging are important phases of the software development process that help to improve software quality, reliability, and safety. For sequential software, software developers effectively use testing and debugging techniques in practice. Unfortunately, testing and debugging become notoriously difficult for concurrent programs compared to their sequential counterparts. This project investigates automated testing and debugging techniques that can not only find bugs in concurrent programs automatically and quickly, but also help to simplify and pinpoint the cause of bugs. The proposed techniques will combine practical methods, such as testing, and mathematically rigorous techniques, such as model checking and program analysis. The project will immediately benefit the software industry, where testing and bug fixing consume more than half of the total software development cost.","title":"SHF: Small: Directed Testing and Debugging of Concurrent Programs","awardID":"1018729","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["451873"],"PO":["565264"]},"167623":{"abstract":"The CORAM (Connected-RAM) project endeavors to completely rethink the reconfigurable computing fabric from scratch to create a new generation of FPGAs as first-class computing devices. From a computing perspective, a major deficiency in today?s FPGAs is the lack of a native memory architecture. The goal of the CORAM project is to develop a consistent and hardware-friendly memory architecture for FPGAs. The CORAM project will develop (1) convenient memory interface abstractions to support the application developers in accessing on- and off-chip memory and (2) the associated mechanisms, from the architecture-level down to the circuit-level, to efficiently support those memory abstractions. The CORAM project will study the abstractions and mechanisms using a combination of FPGA-based prototypes and a test-chip prototype.<br\/><br\/><br\/>The CORAM project is motivated by the renewed interest in FPGA-based computing, driven by the need for greater computing performance and at the same time greater energy efficiency. Reconfigurable computing is one of the key technology candidates to extend the exponential performance scaling efficiently beyond the current commercial multicore processor technology horizon. The CORAM project is central to fully exploring the potential of the reconfigurable computing paradigm.","title":"SHF: Large: Rethinking the Architecture of FPGAs as First-Class Computing Devices","awardID":"1012851","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["548336","550978"],"PO":["562984"]},"164477":{"abstract":"This PIRE renewal award supports the expansion of a unique interdisciplinary U.S.-Japan research and education partnership focused on terahertz (THz) dynamics in nanostructures. The 0.1 to 10 THz frequency range of the electromagnetic spectrum is where electrical transport and optical transitions merge, thus offering exciting opportunities to study a variety of novel physical phenomena. By combining THz technology and nanotechnology, we can advance our understanding of THz physics while improving and developing THz devices. Nanotechnology is the study of nanostructures (between 1 to 100 nanometers long) and how they can be controlled, fabricated, or manipulated. New discoveries provide insight into the possibilities for novel electronic, photonic, mechanical, and magnetic devices that have huge potential for future technological applications including medicine, computation, and communications.<br\/><br\/>This PIRE project will (a) advance our quantitative understanding of THz dynamics in nanostructures, (b) fabricate novel nanostructures for THz study and applications, (c) advance cutting-edge experimental techniques in THz spectroscopy and imaging, and (d) provide new knowledge useful for developing novel THz devices. The projects explore THz dynamics in carbon nanomaterials, namely, nanotubes and graphene.<br\/><br\/>The U.S. and Japan are global leaders in both THz research and nanotechnology, and stimulating cooperation is critical to further advance THz science and develop commercial products from new ideas in the lab. However, obstacles exist for international collaboration - primarily linguistic and cultural barriers - and this PIRE project aims to continue breaking down these barriers. The project will also leverage large investments by both countries to achieve long-term scientific and societal impact by providing future generations of researchers with a better understanding of both the culture and the state-of-the-art technology in each country.<br\/><br\/>The strong educational portfolio of this project focuses on cultivating interest in nanotechnology among young U.S. undergraduate students, especially those from underrepresented groups, and encouraging such students to pursue graduate study and academic research in the physical sciences. This renewed funding will expand and strengthen the award-winning international research experience program for undergraduates called the NanoJapan Program. Recognized as a model for international education programs for science and engineering students, this program will provide U.S. undergraduates with structured research opportunities in Japanese university laboratories with Japanese mentors. This program includes a three-week orientation program with language and culture training as well as extensive use of information technologies as learning and community-building tools. U.S. graduate students, early career scientists, researchers and alumni will benefit from direct involvement in the PIRE research as well as from related follow-on educational projects at home institutions and in local communities. Other programs such as undergraduate and graduate research assistantships and the NanoAsia Graduate International Research Experience (IRE) are additional venues for international collaboration for U.S. students. The original PIRE had particular success with recruitment of females and African-American students; these recruitment efforts will continue and will be expanded to include first-generation college-attending students. This broad portfolio of PIRE educational activities should produce a diverse cadre of students with rich skill sets that span nanoscience specialties, international cultural awareness, and the intersection of culture, language, science, and technology.<br\/><br\/>Institutional impacts of this award include strengthening Rice University's leadership position in international research and education in THz science, materials science, and nanoscience. It places Rice at the hub of an exciting domestic and international collaborative network of researchers and educators, while leveraging the University of Tulsa's exceptional strength in international education, especially its expertise in developing international education programs for science and engineering students. An Introduction to Nanotechnology & Nanoscience Online Seminar will be developed within this PIRE and will be webcast live and archived online, enabling live or asynchronous participation of all U.S. and Japanese participants, thus enhancing the international curriculum at all institutions. In addition, the project will further strengthen and internationalize connections within and among campuses established through the original PIRE award, including those with international offices, IT units, and curriculum and assessment specialists. The project is also an innovative model that enables the participating universities to foster multi-disciplinary international collaboration among scholars ","title":"PIRE: U.S.-Japan Cooperative Research and Education on Terahertz Dynamics in Nanostructures","awardID":"0968405","effectiveDate":"2010-09-15","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7742","name":"PIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["546987","465012","507370","545910","553159"],"PO":["399099"]},"174036":{"abstract":"The proposed funds are for a meeting in Washington, DC to be held in November\/December 2010 to identify and establish research priorities and to help construct a framework that will support and sustain collaboration among institutions working toward creating a digital library and related digital resources for North Africa. The project builds on the results of two earlier events: the \"A Digital Library of the Middle East\" workshop held at the Bibliotheca Alexandrina in Alexandria, Egypt, January 15-17, 2006, and the January 25-29, 2007 \"US-Maghreb Workshop on Digital Libraries for Education, Culture and Science\" held in Rabat, Morocco. Both of these activities were funded in part by NSF. The proposed meeting will stimulate dialog and provide information that can improve efforts toward creating a new generation of digital resources for the Maghreb region of North Africa enabled by advanced computing and networking capabilities. Findings from the meetings are expected to inform grant-making agencies, private foundations and potential funders in other countries of new opportunities for research and infrastructure building efforts to broaden and sustain scientific collaboration with the research communities in Maghreb countries. This project is jointly funded by the Division of Information and Intelligent Systems and the Office of International Science and Engineering.","title":"WORKSHOP: The Science Community and a Digital Library for North Africa","awardID":"1048272","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["537297"],"PO":["564456"]},"168723":{"abstract":"The widespread deployment of wireless communication systems creates unprecedented opportunities to impact our daily lives. Regardless of whether wireless infrastructures are used just for communication or as the basis for actual responses, large-scale wireless data provide increasing opportunities for detecting environmental changes caused by moving objects. Indeed, it is expected to develop the ability to make use of existing wireless infrastructure and sensing data to track moving objects which do not carry radio devices and may not even being aware of being tracked. However, these wireless data are dynamic and have complex data characteristics, such as multi-scale, multi-source and multi-modal. As these data become large and more detailed, new challenges are emerging for intrusion learning. <br\/><br\/>This project aims to develop effective and scalable multi-modal passive intrusion learning techniques that have the capability to detect and track device-free moving objects in pervasive wireless environments through adaptive learning in a collaborative way. In contrast to traditional techniques, which require pre-deployment of specialized hardware, and thus not easily deployed for unscheduled tasks and may not be scalable, this project leads to new insights into intrusion learning by mining on wireless environmental data, as well as leading to new approaches to device-free wireless localization, which can be used to assist a broad array of applications (e.g., identification of people trapped in a fire building during emergency evacuation). Project results are expected to open a new venue for integrating learning capabilities into emerging pervasive wireless fields. The educational component seeks to equip students with the necessary background and practical skills needed to contribute to information technology and have a practical impact on a large set of cross-section domains.","title":"NeTSE:Small:Collaborative Research: MILAN: Multi-Modal Passive Intrusion Learning in Pervasive Wireless Environments","awardID":"1018151","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["535281"],"PO":["564924"]},"168844":{"abstract":"The project develops a mathematical and algorithmic foundation for the field of network computing. The project ties together ideas from network coding with computational problems. While some special cases of network computing have been recently studied, this project carries out a unified study of the field of network computing. The project exploits the promise of improved performance using non-linear codes over traditional network routing and linear coding techniques. Emphasis is placed on computing in networks that allow coding in addition to routing. Applications of network computing include sensor networks and wireless networks. The broad fields studied are: (1) theory and algorithms, and (2) alternative network computing models.<br\/><br\/>The main objectives of the project are to achieve a deep mathematical understanding of network computing capacity and solvability and to develop practical algorithms that can be used effectively to improve performance in real applications. The investigation involves mathematical analysis, algorithm design, and computer simulation. The main topic areas investigated are: (1) Capacity computability and alphabet size, (2) Iterative design of network computing algorithms, (3) Limiting the number of network nodes that can perform coding, (4) Average computation rate in network coding, (5) Bi-directional and broadcast-mode network computing.","title":"CIF: Small: Network Computing","awardID":"1018777","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["517054"],"PO":["564924"]},"168734":{"abstract":"Over the past few decades, the semiconductor industry has been primarily driven by increasing performance and transistor counts. The increase in system design complexity increases the importance and complexity of test and verification. The need for on-line testing of complex CMOS systems and to reduce the off-line test cost, mandate a systematic and standardized test and verification methodology. The future test and verification methodology will use a modular architecture, a programmable topology to address time varying test requirements, and a centralized control scheme for simple access and reconfiguration by operating software. The proposed test and verification architecture will utilize low-cost low temperature poly-Si (LTPS) thin film transistor (TFT) circuits on glass or plastic substrate stacked on top of a silicon substrate. An on-line test control module transmits test vectors to multiple TFT test circuits on glass\/plastic substrate through RF wireless inductive links. The wireless link allows both parallel (broadcasting) and series transmissions. Power and timing (clock) signals can be wirelessly transmitted along with the test vectors, if required. The TFT test circuits evaluate and monitor the underlying silicon CMOS circuits through flip-chip bump contacts and transmit the collected response data back to the test control module. The proposed architecture is: (1) low-cost, (2) modular, (3) can apply programmable test vectors for time varying on-line tests, and (4) allows easy access and control by operating software. The TFTs on which the proposed test circuits would reside, should have reasonable performance and work with CMOS-compatible supply voltages. The proposed research will also investigate and develop optimized TFT structures and passives for CMOS-compatible operations and suitable for 3D integration with standard CMOS systems.<br\/><br\/><br\/>The need for low-cost low-power high-performance electronics is rapidly growing. It is possible to optimize TFT devices on flexible substrates to achieve reasonable performance with low-power dissipation, with CMOS compatible supply voltage. Traditionally, TFTs have been used in high voltage display applications where speed is not important. This research is therefore, a novel way of optimizing and using TFTs for higher performance and lower-power, opening up a plethora of applications such as low-power DSPs and sensors based on the TFT-CMOS hybrid architecture in addition to the low-cost test\/verification application. The ability to implement ?higher-performance? TFTs on flexible substrate with a low-cost process also helps in embedding such electronics\/sensors on materials such as clothes, automobiles, planes, etc. Given the possibilities with such approaches, there is a pressing need to develop such devices and corresponding models and simulation tools to harness the unique characteristics of these devices to achieve high-yield, reliable performance and low-power dissipation. This will enhance our understanding of flexible electronics from device, circuit, and architecture perspectives and open the door for ?more than Moore? applications.","title":"SHF: Small: Standardized On-line Test and Verification Architecture Using TFTs on Glass and Inductive Wireless Links","awardID":"1018205","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[451621,"551012"],"PO":["562984"]},"168624":{"abstract":"Security of many computer systems relies on the basic assumption that data theft through unauthorized physical tampering with a computer system is hard and easily detected. Unfortunately, the ongoing transition to a knowledge economy results in increasing motivation for attackers and results in increasingly sophisticated attacks. Potential EM side-channel attacks, which use radio and microwave signals that are unintentionally produced by computer hardware as it operates, are especially worrisome because they can be carried out without actual contact with the computer, and because they are virtually undetectable by the user of the system. Unfortunately, there is very limited understanding of how much information is possibly being leaked from modern computer systems, from which distance can this information be received, and how to design processors and systems in a way that systematically minimizes this data leakage.<br\/><br\/>This research proposes to carry out preliminary investigation and characterization of the EM side channel data leakage, and gain useful insights that will pave the way toward approaches that minimize this leakage. To this end, the PIs will create a basic experimental testbed to receive and analyze EM emanations from modern systems, and then use this testbed to identify EM emanations that leak data and estimate how the amount of EM data leakage changes with the distance from the system.","title":"SHF: Small: Understanding and Mitigation of Electromagnetic Data Leakage from Modern Computer Processors and Systems","awardID":"1017638","effectiveDate":"2010-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["550974","550165"],"PO":["366560"]},"168404":{"abstract":"With the advent of sensor-rich mobile devices such as smartphones, an increasing number of people are sharing personal \"contextual\" information like location, activity, and health\/fitness information with members of their social network. To enhance privacy for people sharing such information, a large body of research has focused on ways for users to specify who should be authorized to access their information. This research improves end-user privacy by addressing the related question of \"Who is accessing my information and to what extent?\". Providing users with an accurate sense of their \"exposure\" will enable them to better control how their contextual information is shared and will help mitigate emerging privacy risks.<br\/><br\/>This research advances the state of the art in privacy by formalizing the notion of exposure-awareness research, and by investigating metrics that can be used to quantify a person?s exposure, developing usable feedback models and visualizations that leverage these metrics to convey exposure, and creating exposure control extensions to established policy architectures to help users control exposure and refine their data sharing policies over time. The proposed research will thus allow ordinary people to proactively rein in the amount of personal information shared online, and will reduce the privacy risks for the large population of users who are increasingly using social-networking applications to share personal contextual information.","title":"TC: Small: Collaborative Research: Improved Privacy though Exposure Control","awardID":"1016603","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["534031"],"PO":["565264"]},"168525":{"abstract":"As integrated circuits (ICs) shrink to the nanometer range, unpredictable physical phenomena such as temperature changes and radiation-induced soft errors are starting to affect the accuracy and reliability of computers. To address this problem, this project will investigate physically adaptive computing (PAC), a new way to enable an IC to sense internal physical changes on-line and automatically reconfigure its structure to mitigate the negative effects of these changes. The work will exploit the flexibility of IC types like field-programmable gate arrays (FPGAs) and nanoPLAs. It will also build on recent research at Michigan into FPGA applications, as well as fast methods to analyze probabilistic circuit behavior. A major goal is to obtain a deep understanding of PAC and its role in nanoscale computer design. The project will study virtual sensing techniques that use on-chip sensors to detect and infer a wide range of physical parameters. It will seek more cost-effective ways to exploit reprogrammable circuit types to implement fast, on-the-fly adaption schemes. Finally, it will investigate analytic methods to characterize fundamental trade-offs between computational accuracy and key physical parameters, especially energy usage. The theoretical research will be complemented and validated by software simulations and hardware experiments using FPGA-based equipment. <br\/><br\/><br\/>The expected results should be of broad interest to computer engineers and scientists in academe, as well as circuit designers and design tool developers in the U.S. microelectronics industry and in the emerging nanotechnology field. A key goal of the project is to support the training of graduate students, who will participate directly in the research as part of their M.S. and Ph.D. programs at the University of Michigan. Recent graduate students of the PI have included women and minorities, and a special effort will be made to attract more such students to this emerging research area.","title":"SHF: Small: Physically Adaptive Computing and its Applications","awardID":"1017142","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["549712"],"PO":["562984"]},"168646":{"abstract":"Modern integrated circuit design involves multibillion-transistor CMOS circuits, built using miniscule nanometer-scale transistors and wires. Such technologies are plagued by significant variations due to process uncertainties, supply voltage degradation, temperature changes, and aging phenomena, all of which are projected to grow more critical in the coming years. With variability steadily eating into design margins and yield, mainstream current-day methodologies will be unsustainable in the future and new approaches will be necessary. Such variations can be reduced by design optimization at the presilicon stage, before manufacturing, as well as at the postsilicon stage, after manufacturing. The focus of this work is to build design-for-adaptability techniques at the presilicon stage that enable postsilicon adjustments that allow circuits to recover from variational effects. The methods to be pursued will seek to inject formalism into the process of building a practical framework for designing resilient systems. A key ingredient is the development of new sensors and incorporates them into schemes that are capable of providing runtime adaptation, based on a sensing\/mitigation strategy that forms a feedback loop, and ?cures? a ?sick? die. <br\/><br\/>Solutions from this research will facilitate the design of next-generation integrated systems for computing and communication applications, and has the potential to impact applications in the consumer, computing, and healthcare spaces. The technology developed in this project will be transferred to industry through research discussions as well as publications. The key accomplishments will be distributed through the PI?s research webpage. The project will actively recruit underrepresented minorities to the research project, and will contribute to education through the development of new course materials.","title":"SHF: Small: Enabling Resiliency in Nanometer-Scale CMOS Circuits","awardID":"1017778","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["508418"],"PO":["562984"]},"168415":{"abstract":"A common characteristic of the emerging generation of wireless networks is their heterogeneity: these networks consist of devices with very different capabilities and requirements sharing overlapping spectrum. Intelligent home networks consisting of HD streaming, gaming consoles, wireless routers, and energy monitoring devices is one example; cognitive networks (utilizing white spaces), and femtocell networks being two more. Somewhat surprisingly, nearly all engineering design, analysis, and knowledge is based entirely on the assumption of node homogeneity Our research involves obtaining fundamental new laws and limits for the connectivity and capacity of heterogeneous wireless networks. The nature of such limits is expected to provide a roadmap for better design principles.<br\/><br\/>The novelty of this research is based on a new application of marked point processes, where the points model the node locations and marks characterize essential traits of the node, like their bandwidth and power. To calculate the desired statistical properties of the network, we introduce and advance new mathematical tools such as Tauberian theory, series of random functions, Stein approximation theory, and sub-ergodic theory. In addition to the basic research aspect of this project, we are pursuing an energetic program of technology transfer with several leading companies developing heterogeneous networks and planning standards contributions and other intellectual property development. This is consistent with the PI's past track record.","title":"Heterogeneous Network Connectivity and Capacity","awardID":"1016649","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["522873",450870],"PO":["564924"]},"168536":{"abstract":"The AfterBurner project looks at improving single-thread performance on<br\/>both simple and high-performance out-of-order cores in an energy efficient way. Aside from explicit parallelism, this is the primary challenge of multi-core architectures going forward. The most energy-efficient way to improve single-thread performance is to accelerate low-performing program regions. This approach yields the greatest benefit. It also has a low cost because it doesnot require high-bandwidth execution, making it applicable to both simple<br\/>and high-performance cores. Low single-thread performance is caused by squashes due to control and data mis-speculations and by long latency loads and stores which clog the pipeline. AfterBurner unifies two recently proposed techniques---speculative retirement which can efficiently buffer large numbers of completed instructions and selective re-execution which can re-execute dynamically generated program subgraphs to back-patch program state---and uses them to tolerate all four classes of low-performance events. AfterBurner's multi-purpose infrastructure approach to performance reduces cost, simplifies design, and expands applicability to code that suffers from different low-performance events simulatenously.<br\/><br\/>In addition to education and student tarining, the AfterBurner project marks the beginning of a systems research collaboration between Uniersity of Pennsylvania and Drexel computer science departments.","title":"SHF: Small: AfterBurner: Efficient Performance Scaling via Post-Retirement Processing","awardID":"1017184","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["556655",451152],"PO":["366560"]},"168657":{"abstract":"This project aims to answer a fundamental question in wireless networking: what is the energy needed to transmit one bit of information over a wireless network? And the related question: how can practical networks be designed to come close to this limit? The motivation is to save energy. It is evident that there is a strong current interest in energy conservation. Currently it is estimated that consumer electronics account for 11% of total residential electricity consumption in the US. While this is not all used on communications, as most devices have wireless capability, wireless communications could account for a significant part of this energy consumption. Clearly, if this energy consumption can be cut in half, the saving is significant. In fact, preliminary results show that by optimizing the signaling, energy consumption in wireless communications can be reduced much more than 50%.<br\/><br\/>As is well known, there are few networks where the exact Shannon capacity has been found. The research therefore approaches the theoretical part of this problem in different ways. For some networks, the minimum energy per bit can be found even if the exact capacity cannot be found. When the exact minimum energy per bit cannot be found, approximations to the minimum energy per bit are sought in the form of a figure within a certain number of dB that is universal over a certain class of networks. A key part of the research will be to look at networks with correlated information and distortion. Joint source-channel coding can reduce the energy consumption beyond what a separate approach can provide. The theoretical approach will be combined with practical coding methods.","title":"CIF:Small:Collaborative Research:Minimum Energy Communications in Wireless Networks","awardID":"1017823","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}}],"PIcoPI":[451433],"PO":["564924"]},"168778":{"abstract":"Current technologies have made it possible for submarines to evade standard sonar detection. Finding solutions to detect intruding submarines therefore becomes important and timely. A viable approach is to deploy magnetic or acoustic sensors in close proximity of possible underwater pathways intruders may pass through. This project seeks to develop a comprehensive theoretical and practical solution to construct undersea sensor networks for intrusion detection. When sensors are randomly deployed, spatial barriers are unlikely to exist, allowing intruders to pass through the bounded 3D space undetected. This motivates the use of mobile sensors to dynamically form sensor barriers. How to minimize the energy consumed by the movement of underwater sensors is a challenging issue. This project tackles the problem via three thrusts: (1) Develop an energy-efficient approach to using mobile sensors to construct a spatial barrier in 3D space; (2) Devise near-optimal practical solutions to reduce computation and communication costs, and develop these algorithms into practical protocols; and (3) Develop simulation modules and test-beds to evaluate the proposed solutions with realistic undersea environment parameters. The project integrates concepts and techniques in auction algorithms, geometry, combinatorial optimization, underwater acoustic communications and networking, software and system development to construct analytical models and practical solutions. The research results are expected to have a substantial impact on the understanding of constructing sensing barriers in underwater environments, and will be integrated into graduate and undergraduate teaching and outreach activities. Efforts will be also proactively pursued to recruit students from under-represented groups to participate in the project.","title":"NeTS: Small: Collaborative Research: Undersea Sensor Networks for Intrusion Detection: Foundations and Practice","awardID":"1018422","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["526410"],"PO":["565303"]},"168547":{"abstract":"In developing variants of natural proteins with improved properties and activities, protein engineers are confronted with large, complex design spaces. The degrees of freedom for producing variants mirror nature but can be specifically targeted experimentally, choosing parent proteins, replacements for some amino acids (site-directed mutation), and locations for crossing over between parents (site-directed recombination). A set of choices, constituting a design, can be evaluated by multiple disparate criteria, including consistency with evolutionary information, energetic favorability with respect to a three-dimensional structure, and incorporation of specific characteristics distinguishing functional subclasses. Unfortunately, the different evaluation metrics may be complementary or even contradictory, and the prior information on which they are based is incomplete, so that the metrics are only more or less accurate in predicting the real-life quality of the designs.<br\/><br\/>The overall goal of this project is to develop efficient methods to characterize complex protein design spaces and optimize high-quality designs for experimental evaluation. A combinatorial protein engineering approach will be pursued, experimentally constructing a library of related variants and assaying them for properties of interest. Potential scores will evaluate a possible library (without explicitly enumerating its members) with respect to prior information from sequence, structure, and functional subclass. To account for disparate evaluation metrics, design algorithms will focus on the<br\/>identification of Pareto optimal designs, those for which no other design is as good or better with respect to all desired criteria. To account for incomplete prior information, design algorithms will trade off between exploitation of the prior information and broader exploration of the design space, seeking to identify a diverse set of designs, each with a diverse set of variants. Markov Chain Monte Carlo sampling algorithms will characterize the overall design space by generating choices for the degrees of freedom and evaluating the designs with the potential scores, using the scores and diversity metrics to appropriately explore the space. Exact algorithms will more precisely focus on regions of interest, dividing and conquering the design space and employing combinatorial optimization algorithms to identify Pareto optimal designs.<br\/><br\/>The design space approach provides a powerful new mechanism to address protein engineering applications, enabling the engineer to explicitly evaluate and optimize for trade-offs among important criteria and considerations. Interactive tools will help engineers navigate through the regions of interest, visualize designs and perform \"what-if\" analyses, and compare and contrast Pareto optimal designs. A design space repository will enable sharing of analyses and underlying data. The tools and repository will support protein engineering for a range of activities in the national interest, including biosensors, production of novel biological therapeutics and novel enzymes for green chemical synthesis, energy extraction, and bioremediation. As part of the project, the mechanism will be put to use in the engineering of soluble and robust cytochrome P450s that employ the inexpensive and non-toxic hydrogen peroxide to hydroxylate steroids and multi-ring compounds that mimic estrogenic (feminizing) steroids in the environment without the need for living cells or protein cofactors. Such enzymes would be valuable as tools for chemical synthesis, waste treatment, and bioremediation.<br\/><br\/>This project provides an ideal venue to impart cross-disciplinary training to students by illustrating how computational techniques can be fruitfully integrated with experimentation in answering important biological questions. Aspects of the project will be used in both undergraduate and graduate courses, from an introductory biology course to an advanced bioinformatics course. The project itself will provide the opportunity for inter-disciplinary research training for graduates and undergraduates, including those from underrepresented groups.","title":"III: Small: Collaborative Research: Analysis of Multi-Dimensional Protein Design Spaces with Pareto Optimization of Experimental Designs","awardID":"1017231","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["511584"],"PO":["565136"]},"168789":{"abstract":"Abstract<br\/>What physical, chemical, or biological configuration produced the measurements one has made or the images one has formed? This is a question of inverting an image for the field that produced it, and it arises in almost all fields of science and engineering. The emerging methodology of compressed sensing has opened up many applications in imaging science, signal processing, and networking. However, its applicability to high-resolution image inversion is as yet unproven. The objective of this research is to provide a comprehensive analysis of the performance of compressed sensing as an image inversion principle. The program is interdisciplinary, with signal processing forming the bridge between imaging science and mathematics.<br\/><br\/>The theory of compressed sensing suggests that sub-sampling of an image of a physical field has manageable consequences for image inversion, provided that the image is sparse in a known basis. But in reality, no physical field is sparse in a known basis and therefore any presumed basis for sparsity is always mismatched to the actual sparsity basis chosen by the physics of the problem. This is called model mismatch. This research establishes bounds on the sensitivities to model mismatch of compressed sensing and compares its performance to more established principles of image inversion. The goal of the research is to establish quantitative trade-offs between basis over-fitting, compressed sampling rate, and robustness to mismatch. The research develops principles for compressed sensing that preserve the fidelity of inversions, even under conditions of mismatch. It extends the theory of compressed sensing from a first-order theory of modeling to a second-order theory for sparse covariance and frequency-wave-number spectrum estimation.","title":"CIF: Small: Collaborative Research: Compressed Sensing for High-Resolution Image Inversion","awardID":"1018472","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["523725",451762],"PO":["564898"]},"168558":{"abstract":"Traditionally, there has been an isolation of responsibilities of<br\/>physical layer (PHY) and higher layers of the network stack leading to<br\/>severe inefficiencies in bandwidth-limited wireless<br\/>networks. Remedying these inefficiencies requires rethinking and<br\/>redesigning wireless protocols such that higher layers and PHY work in<br\/>synergy. This project explores three schemes under the PHY-Informed<br\/>Networking (PHY-IN) framework. 1) Carrier Sense Multiple Access with<br\/>Collision Notification (CSMA\/CN) mechanism detects and aborts<br\/>collisions, breaking away from the existing collision avoidance<br\/>(CSMA\/CA) based schemes such as 802.11. 2) Constellation BAsed Rate<br\/>(CBAR) adaptation scheme jumps to the best feasible rate suitable for<br\/>a varying channel. 3) Remap scheme permutes bit-to-subcarrier<br\/>assignment for a retransmission to improve the chances of its success.<br\/>The PHY-IN framework has the potential to impact the landscape of<br\/>future wireless networking protocols. Apart from mentoring both<br\/>undergraduate and graduate students into independent researchers, this<br\/>project, involving an EPSCoR university and a research lab, will also<br\/>help broaden the participation and industry collaboration.","title":"NeTS: Small: Collaborative: PHY-Informed Networking (PHY-IN): Rethinking Wireless Protocol Design with the Knowledge of PHY","awardID":"1017276","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[451202],"PO":["557315"]},"168679":{"abstract":"NetSE: Small: Collaborative Research:<br\/>Dynamic Flow Equilibria in Vehicular Traffic and Data Communication Networks<br\/><br\/>Project Summary<br\/><br\/>This project will develop a new methodology, algorithms, and models for dynamic flow equilibria in networked systems, with emphasis on two specific real-world networking applications ? vehicular traffic network modeling and efficiency analysis, and routing and flow control in data communication networks. The first research goal of this project involves appropriate modeling of dynamic flow problems in networks with self-interested agents, and understanding the properties of the equilibria for these problems. The other major research goal is to specifically study the application of dynamic flows to vehicular traffic networks and data communication networks. The research goals of this project will be achieved by an interdisciplinary but closely-integrated effort bringing together techniques from game theory, algorithm design, optimization, and real-world network simulation.<br\/>Intellectual Merit: The novelty of this project is that it provides a holistic understanding of the theoretical, algorithmic, and implementation issues of dynamic flow equilibria in networked systems, particularly in the context of vehicular traffic and data communication networks. This research explicitly takes into account the non-negligible travel time of flows in a network, and its variation as a function of the time-varying congestion in the network ? this results in new notions of flow equilibria that are fundamentally different and significantly more complex than those for non time-varying flows. The models used in the project are based on emerging concepts in game theory, optimization theory, and vehicular traffic modeling, and the project is expected to result in the development of a new algorithmic framework for studying dynamic flow equilibria in networks. In addition, this research will contribute techniques for dynamic flow equilibria study to many interested research communities, including transportation, algorithmic game theory, economics, sociology, and multi-agent systems, and facilitate the transfer of techniques between disciplines.<br\/>Broader Impact: This project will facilitate better network engineering, particularly in the context of transportation and communication networks. The implementation of the models developed by this research in specific disciplines (vehicular transportation and data communication networks) will have significant societal impacts, such as (i) enabling more efficient analysis and provisioning of transportation networks, leading to lower travel delays, and (ii) faster Internet access and download speeds due to more efficient routing and flow control protocols. This research will help rethink and possibly redesign important core components of the Internet through better flow control and routing choices. The findings of this research will be integrated into several different courses, and in Interactive Learning Modules aimed at attracting undergraduate and high-school students to research careers. Special efforts will be made to encourage participation of undergraduate and minority students.","title":"NetSE: Small: Collaborative Research: Dynamic Flow Equilibria in Vehicular Traffic and Data Communication Networks","awardID":"1017932","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["518263","531799"],"PO":["565090"]},"168327":{"abstract":"Jamming resistance is crucial for applications where reliable wireless communication is required, such as rescue missions and military operations. Spread spectrum technologies such as Frequency Hopping (FH) and Direct Sequence Spread Spectrum (DSSS) have been used as countermeasures against jamming attacks. However, these anti-jamming techniques require that senders and receivers share a secret key in order to communicate with each other. In situations where the adversary can compromise a legitimate communication device and learn the secret key, she can effectively defeat FH or DSSS wireless communication and thus disrupt normal network operations. In general, traditional anti-jamming techniques such as FH and DSSS are vulnerable to insider attacks where the adversary has access to the secret key used for anti-jamming wireless communication. This project develops novel and efficient insider-jamming-resistant techniques for both DSSS and FH-based wireless communication systems. This research consists of two thrusts: The first thrust develops novel spreading\/despreading techniques to enhance DSSS-based wireless communication to defend against insider jamming threats, while the second thrust develops a new approach to enable FH-based wireless communication to be resistant against insider jammers. A key property of these new approaches is that they do not depend on any secret shared by the sender and receivers. This project will significantly enhance the resilience of future wireless communication systems, especially those for mission-critical applications that may face potential adversaries (e.g., rescue missions and military operations). The results obtained in this project will be disseminated through publications, graduate-level courses, and public release of software packages.","title":"TC: Small: Defending against Insider Jammers in DSSS- and FH-Based Wireless Communication Systems","awardID":"1016260","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["553865","553866","544836"],"PO":["564223"]},"168448":{"abstract":"Computing devices have transformed person-to-person communication, dramatically altering how we present ourselves to the world. As the use of computer character animation rapidly expands into 3D digital media in mobile devices, social networking, and massively multiplayer online games, the demand for distinctive personalized digital avatars is beyond the capacity of key-frame animation, beyond the range of motion capture, and beyond the expressive capability of rule-based animation. The PI's goal in this project is to define a new framework that transforms biological locomotion into a content form, classified by identity-rich features which can be synthesized for use in animating animals, whether real or imagined. The research focuses on how species, age, and weight are perceived by people viewing real animals, with the intention of making virtual animals, or humans representing themselves as animal avatars, more expressive. Project outcomes will include a technique for procedural generation of animation for novel digital creatures that is capable of movement patterns signifying a specific animal species, age as young or old, and weight as heavy or light. The PI argues that to develop this new way of creating and managing expressive animation, we need a better understanding of how we perceive motion itself. To this end, the PI and his team will borrow from biological motion studies to determine what level of detail of motion information is required for recognition. He will use eye tracking to determine where the information is found in animal motion, and will employ linear analysis to decompose the motion and re-inject the identity-laden elements into novel animal forms. Thus, the work will combine three areas of research - perception of biological motion, eye tracking, and synthesis of gait patterns - to develop the foundation for a generative system for animal avatar animation. <br\/><br\/>Broader Impacts: This project combines the use of computational systems to both analyze how we perceive motion and to synthesize new, novel motion. The research will contribute to our understanding of human perception of biological motion, and expand the performance range and emotional impact of synthesized animation. Techniques for isolating the spatio-temporal information that leads to recognition of identifiable traits will expand beyond the perception of humans and into the domain of animal motion, thereby opening the door to creating animal avatars that are expressive through motion in a variety of ways that communicate personality. Project outcomes will thus be of interest to creators of digital content for games, immersive virtual worlds, and cinema. The PI expects this work will lead to expansion of both the range of traits that can be procedurally applied to animation and the sophistication of novel gait generation methods.","title":"HCC-GV: Small: Generating Animal Avatar Animation with Specific Identifiable Traits Based Upon Viewer Perception of Real Animals","awardID":"1016795","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["534310",450949],"PO":["565227"]},"166149":{"abstract":"Superconducting qubits are manufactured solid-state artificial atoms. Their potential for lithographic scalability, compatibility with microwave control, and operability at nanosecond time scales make superconducting qubits a promising candidate for quantum information science and technology applications. To realize their full potential, present limitations to superconducting qubit coherence and lifetimes must be understood and mitigated, and that is the focus of this work. The control of Nuclear Magnetic Resonance systems is remarkably advanced, and one draws on this knowledge to characterize and mitigate noise sources in superconducting qubits. In doing so, one not only brings superconducting qubits closer to application, but addresses fundamental scientific questions regarding the nature of quantum coherence and the degree to which humankind can build, control, and ultimately exploit macroscopic quantum systems.<br\/><br\/>Quantum information science is driving an information processing revolution, enabling technologies and capabilities that simply cannot be achieved through conventional means. A unique educational feature of this work is the access and participation by students in academic, corporate and government research environments in the U.S., Japan, and Canada. Through this coordinated research effort, including student internships at these facilities, this work will further build the scientific foundations of quantum information science while also advancing a research culture that fosters future scientists with a global perspective, capable of developing and leading interdisciplinary teams across institutional and international boundaries.","title":"Noise Characterization And Dynamic Decoupling In Superconducting Qubits","awardID":"1005373","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7281","name":"QUATM INFO & REVOLUTIONARY COM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}}],"PIcoPI":[445140,445141],"PO":["564326"]},"168459":{"abstract":"This project investigates computability, algorithmics, and complexity in distributed settings with large numbers of machines cooperating on solving computation problems in the presence of dynamic changes in the computing medium. The computation problems are modeled as collections of tasks, such as the problems frequently occurring in the Internet supercomputing. This research has the potential to impact massive cooperative computing in dynamic settings through the use of rigorously developed algorithms with formally proved efficiency and fault-tolerance guarantees. In the longer term this research will also have impact on the development of broader classes of adaptive distributed systems. <br\/><br\/>This research develops advanced algorithms enabling efficient and fault-tolerant cooperative computing in dynamic distributed settings. The basic problem is formulated in terms of a collection of processors that need to perform a set of tasks, where the tasks must be executed using either at-least-once or at-most-once semantics. The research considers dynamic settings that are representative of situations in Internet supercomputing. The models of cooperation include: (a) oracle model, where a central authority provides information to the participants. (b) master-worker model, where a single master coordinates the workers in performing the tasks, a typical setting in Internet supercomputing. (c) peer-to-peer mode, where fully-distributed solutions will be investigated, enabling much more dynamic and fault-tolerant solutions. The investigation includes the associated resource discovery problem of identifying the nodes in the distributed system that are willing and able to cooperate; here the investigation focuses on more realistic settings than previously considered. This research also studies supporting services that can provide effective implementations of communication and shared-memory primitives in target dynamic platforms. The quality of algorithms is evaluated using corresponding lower bounds and impossibility results.","title":"AF: Small: Collaborative Research: Principles of Robust Cooperative Computing in Dynamic Distributed Systems","awardID":"1016847","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7934","name":"PARAL\/DISTRIBUTED ALGORITHMS"}}],"PIcoPI":[450972],"PO":["565251"]},"168349":{"abstract":"This project will develop fast numerical methods for fourth and higher order partial differential equations using the interior penalty approach. The interior penalty approach has advantages over the classical approaches that use conforming, nonconforming or mixed finite elements in terms of the computational complexity, the existence of natuaral hierarchies of elements, the preservation of the symetric positive definiteness of the continuous problem, and the ease of deriving convergent schemes for complicated problems. Another significant advantage of interior penalty methods for higher order problems is due to the fact that discontinuous finite elements for higher order problems are also suitable for lower order problems. Therefore multigrid algorithms for interior penalty methods can be developed recursively through the hierarchy of elliptic problems. Namely, multigrid algorithms for second order problems can be embedded naturally in multigrid algorithms for fourth order problems, which can then be embedded naturally in multigrid algorithms for sixth order problems, and so on. The performance of these multigrid methods for higher order problems is comparable to the performance of multigrid methods for second order problems. This project will initiate a comprehensive study of interior penalty methods for higher order problems together with multigrid, domain decomposition and adaptive algorithms that will provide fast solvers for the resulting discrete problems. The results of this project will make it feasible to solve problems of order six and higher on general domains. Applications of these methods to strain gradient elasticity, plate buckling, the Monge-Ampere equations and the Cahn-Hilliard equations will also be investigated.<br\/><br\/>The fast algorithms developed in this project will make it practical for scientists and engineers to model complex phenomena by higher order partial differential equations. These algorithms will enhance the performance of numerical simulations in diverse areas such as structural mechanics, fluid mechanics, image processing, nanoscience, geometric optics, meteorology, optimal transport, differential geometry, and crystal growth, among many others.","title":"Fast Interior Penalty Methods","awardID":"1016332","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550294","550295"],"PO":["565027"]},"170670":{"abstract":"The goal of this project is to develop a new inference-based information processing structure that performs probabilistic computing using radically new nanoscale devices. This approach exploits the analog, time-dependent properties of such devices, and their massive parallelism. By doing so, such a computing structure will be more efficient and scalable than by using more traditional digital hardware. This approach is one of the first to include time-dependent circuit elements to build analog associative memories that approximate Bayesian inference, and which are, in turn, assembled into complex networks that capture higher order structure in streams of data. The ultimate goal is to use these circuits to develop hybrid CMOS \/ molecular scale implementations of a Field Adaptable Bayesian Array (FABA), which has the potential to be a key component for Cyber-Enabled discovery.<br\/><br\/><br\/>Cyber-Enabled discovery is addressed in this research in two ways. The first concerns the design of analog circuits based on complex nano and molecular scale devices with time-varying properties. And the second concerns the creation of a new family of semiconductor components that will significantly enhance Cyber-Enabled discovery applications across a wide range of data and applications.<br\/><br\/><br\/>Designing analog nano-electronic circuits that perform inference through space and time and which consist of dynamic components (such as mem-resistance and mem-capacitance) is extraordinarily difficult. This is particularly true when one considers the wide range of complex devices that are being developed in laboratories around the world for nano and molecular scale electronics. For this effort we have defined an Exploration Methodology that combines multiple levels of abstraction and evolvable computation.<br\/><br\/><br\/>Two key developments then are a design exploration methodology for such devices, and a massively parallel architecture for data capture and inference. This research will explore a new paradigm for using nanoscale electronics for emerging applications by starting with the \"top-down\" system requirements rather than by finding applications for new device concepts (\"bottom-up\").<br\/><br\/><br\/>As the semiconductor industry struggles with where to go next, the work proposed here may provide insight into radical new approaches to architecture, circuits and devices. This research will ultimately benefit society by enhancing human cognition and generating new knowledge from the wealth of heterogeneous digital data society has to deal with.","title":"CDI-Type II: Inference at the Nanoscale","awardID":"1028378","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[456863,"456865",456865],"PO":["562984"]},"170120":{"abstract":"Virtual organizations have experienced an exponential growth due to their flexibility, cost effectiveness, efficiency, and ability to overcome geographic constraints. This project investigates how two scientific virtual organization breeding environments (online communities of practice) in the life sciences use social networking site technology to understand the potential of this cyberinfrastructure to foster trust and social cohesion among potential virtual organizations team members and lead to virtual organization formation and success. The research uses ethnographic and case study data (including visual maps of two virtual organization breeding environments and their interactions) to build theory and hypotheses about whether the use of social networking site technology in virtual organization breeding environments promotes virtual organization development and innovation (and, if it does, how). Quantitative data will be derived from monitoring and coding patterns of communication among participants from both VBEs. The research will also develop and extend Actor-Network-Theory and Social Network Analysis to virtual organization breeding environments improving our understanding of them as sociotechnical communities in which associations can be traced and analyzed.<br\/><br\/>The formation of virtual organizations is an important issue in many fields of science and engineering, as well as in industry. This research focuses explicitly on understanding the role of women in science and attracting women (an under-represented group) into the sciences. It will improve our understanding of the role of Web 2.0 technologies in interactions between scientists and of virtual organization development. Addressing the central question of whether social network systems meaningfully facilitate the social interactions that are required for a successful virtual organization, this project will provide a rich understanding of the formation, evolution and success of virtual organizations to guide the development of cyberinfrastructure. Results will be disseminated through a Facebook group, Twitter page, project website, and a public workshop.","title":"RUI: VOSS: The Potential for Social Networking Cyberinfrastructure to Facilitate Virtual Organization Breeding Grounds","awardID":"1025428","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[455325],"PO":["565342"]},"174971":{"abstract":"This project develops techniques to eliminate partial-duplicates in image search from a large scale database. The research team explores spatial representation schemes for partial-duplicate image retrieval in efficient ways. Images are represented by the Bag-of-Visual-Features model, in the similar way to text document represented by a set of text words. A novel scheme, spatial coding, is designed to encode the spatial relationships among local features in an image. Based on the spatial codes of images, verification of the initial matching of local features between images is performed. And those false matches are identified and removed effectively and efficiently. As a result, the similarity between images based on local feature matching is determined more accurately. Consequently, the retrieval performance is greatly improved. The approach enjoys the merit of scalability. It is an initial step towards billion-scale partial-duplicate image retrieval. The project is developing a real time partial-duplicate image search system with sound recall on 10 million web image database. <br\/><br\/>The research of spatial coding addresses critical problems in multimedia visual information retrieval. The proposed spatial coding approaches have broad impact in various research fields and applications, such as image retrieval, image categorization and object recognition. Finally, research and education are integrated by providing research opportunity for graduate and undergraduate students to selecttheir research topics and senior projects.","title":"EAGER: Large Scale Partial-duplicate Image Search by Post Verification of Local Feature Matching","awardID":"1052851","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["496425"],"PO":["564316"]},"172683":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040663","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[463055,"549890"],"PO":["565090"]},"173541":{"abstract":"This proposal seeks NSF support for OSDI'10 student travel scholarships. The PIs are requesting $20,000 to support between 20 and 40 students to attend the conference.<br\/>The ninth international USENIX Symposium on Operating Systems Design and Implementation (OSDI'10) will be held in Vancouver, BC, Canada, October 4-6, 2010. The ninth OSDI seeks to present innovative, exciting research in computer systems. OSDI brings together professionals from academic and industrial backgrounds in what has become a premier forum for discussing the design, implementation, and implications of systems software. <br\/>This award is to make travel scholarships available to students and universities not typically represented at OSDI in order to improve the conferences impact and outreach.","title":"NSF-CCF: Support for Student Travel for Operating Systems Design and Implementation (OSDI) 2010","awardID":"1044961","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["550389"],"PO":["565272"]},"175851":{"abstract":"Over the last decade, wireless networks have achieved major successes and emerged as the key technology for enabling ubiquitous access to information. However, several challenges remain, energy-efficiency being one of the most notable. At the same time, bio-organisms are well known for energy efficiency. From the brain that performs outstandingly complex tasks with only few tens of watts, to the ear that carries the equivalent of billion floating-point operations per second, biological systems are orders of magnitude more efficient than state of the art wireless systems. A natural, although challenging, question is if we can build biologically enabled wireless networks. <br\/><br\/>Several research communities have been working on new biologically enabled computation and communication paradigms, the biophysics and biomedical communities have been exploring ways to remotely interact with biological organisms. However, these communities rarely interact with each other. This workshop?s goal is to bring them together, articulate a vision for biologically-enabled wireless networks, and define a clear set of challenges to be solved and recommendations for future inter-disciplinary collaborations in this emerging area. Experts from several communities will present the state of the art in (1) enabling mechanisms for bio-networks, such as electromagnetic energy harvesting and transduction into biological signals, and magnetic control of biological systems, (2) molecular computation and communication networks considering both the fundamental information and computation theoretic issues and system design, and (3) synthetic biology as a way to engineer biologically enabled wireless devices but also how biologically enabled devices can be made less sensitive to their environment.","title":"NSF Workshop on Biologically Enabled Wireless Networks","awardID":"1057955","effectiveDate":"2010-09-15","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518182",471308],"PO":["557315"]},"170186":{"abstract":"Increasingly, team projects involve geographically distributed participants. The current project builds on our earlier research identifying success factors in distance work. A preliminary Theory of Remote Collaboration has been developed, and a major goal of the current project is to both verify and extend this theory. A prototype online Collaboration Success Wizard will be developed for those engaged in collaboration or planning to collaborate to assess their strengths and weaknesses. The Wizard steps through questions about important collaboration factors, informs the participants about their strengths and suggests improvements. This project will allow development and refinement of the Collaboration Success Wizard while testing and extending the Theory of Remote Scientific Collaboration. Participation in the Wizard will be followed up with selected interviews and site visits to assess its accuracy, completeness, and predictive capabilities. In addition, the database of collaboratories in science will be updated, including scholarly collaborations beyond science and engineering. <br\/><br\/>Distributed collaborative teams are increasingly common in science, engineering, government and industry. Deepening our understanding of what differentiates successful from unsuccessful distributed collaborations will aid both those engaged in collaboration and those developing or funding this new form of science and engineering work. A verified theory of remote collaboration and widely disseminated assessment Wizard will help organizations assess their strengths and vulnerabilities for distance collaboration. The Wizard will function as a tool for data-collection and for theory-validation, but will also provide its users with an instant report on the strengths and vulnerabilities of the collaboration and suggested steps for strengthening it.","title":"VOSS: Next Steps in Articulating Success Factors for Distributed Collaborations","awardID":"1025769","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":["551830","551829"],"PO":["565342"]},"163796":{"abstract":"Wireless telecommunications are undergoing substantial policy reforms in pursuit of better spectral efficiency. A key element in these reforms entails granting full property rights to spectrum license holders, thereby paving the way to secondary spectrum markets. Spectrum markets hold a remarkable potential to increase spectrum utilization by making it available to a larger fraction of public at lower cost. Yet, although a favorable regulatory framework has been in effect in the last few years, liquidity of spectrum markets is inhibited due to uncertainties perceived by spectrum license holders. These uncertainties stem from complex relationships between effects of electromagnetic interference and economic considerations. This research involves a constructive study of viability of spectrum markets by establishing methods and algorithms that render such markets profitable for their participants. <br\/><br\/>The investigators focus on analytical study of profitability of spectrum markets, and its empirical verification. Main thrusts of the research program are: (i) fundamental elements of pricing and interference externalities for efficient and economically viable use of spectrum; (ii) algorithms for spot market use and real-time measurement-based pricing policies; (iii) empirical techniques for testing demand model specification, and formative models of demand-price relationships via experimental studies. This research is interdisciplinary and it is based on identifying incarnations of both novel and classical notions in economics in the specific context of wireless communications and spectrum markets. <br\/><br\/>The research impacts legal and economic policies for the future wireless industry and provides a tool for assessing potentials of the secondary spectrum market.","title":"NetSE: Medium: Collaborative Research: Promoting Secondary Spectrum Markets via Profitability-Driven Methods and Algorithms","awardID":"0964170","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["500058"],"PO":["564924"]},"172167":{"abstract":"Since 2006, the annual workshop for Women in Machine Learning (WiML) has brought together female<br\/>researchers in industry and academia, postdoctoral fellows, and graduate students from the machine<br\/>learning community to exchange research ideas and build mentoring and networking relationships. The<br\/>one-day workshop has been especially beneficial for junior graduate students, giving them a supportive<br\/>environment in which to present their research (in many cases, for the first time) and enabling them to<br\/>meet peers and more senior researchers in the field of machine learning. The networking opportunities<br\/>provided by the workshop have also helped senior graduate students find jobs following graduation.<br\/>Intellectual Merit: This workshop will advance machine learning knowledge and foster collaboration<br\/>within the machine learning community. As invited speakers, established researchers at top universities<br\/>and research labs will teach workshop participants about cutting-edge ideas from diverse areas of<br\/>machine learning. Students will present their own research and receive valuable feedback from both<br\/>senior researchers and their peers. By enabling women at all stages of their careers in machine learning to<br\/>exchange research ideas and form new relationships, we expect that new connections and research<br\/>collaborations will be established, thereby advancing the state-of-the-art of the field.<br\/>Broader Impact: This workshop will provide a forum for female graduate students, postdoctoral fellows,<br\/>junior and senior faculty, and industry and government research scientists to exchange research ideas and<br\/>establish networking and mentoring relationships. Undergraduates, particularly those who are interested<br\/>in pursuing graduate school or industry positions in machine learning, are also welcome to attend.<br\/>Bringing together women from different stages of their careers gives established researchers the<br\/>opportunity to act as mentors, and enables junior women to find female role models working in the field<br\/>of machine learning. The workshop will also benefit the wider machine learning community: Firstly, the<br\/>WiML website, which lists all previous workshop presenters, serves as a useful resource for organizations<br\/>looking for female invited speakers. Secondly, co-locating with a major machine learning conference<br\/>enhances the visibility of female researchers among the wider machine learning community. Thirdly,<br\/>travel funding provided to workshop participants also facilitates their travel to the co-located conference,<br\/>which for some participants would otherwise not be possible. Finally, all workshop materials (slides,<br\/>abstracts, etc.) will be made available on the workshop website in order to ensure broad dissemination.","title":"Collaborative Research: Workshop for Women in Machine Learning","awardID":"1036868","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["470197"],"PO":["562760"]},"173498":{"abstract":"The human ability to use language flexibly is a hallmark of robust intelligence. In interactive dialog, utterances are dynamically tailored to the common ground or specific context with specific partners. However, interaction with spoken dialog systems is highly constrained and constraining, allowing speakers very little flexibility in what they can say while the system presents pre-determined messages. To make interactive dialog technology broadly useful, this exploratory interdisciplinary project collects a corpus of dialogs exhibiting some important sources of variation, analyzes the corpus, and uses the resulting analyses to develop models and prototype implementations of dynamic dialog strategies. The ultimate goal of this effort is to support the synthesis of entirely new, flexible, and robust spoken dialog systems that are capable of adapting on-line. <br\/><br\/>The Walking-Around corpus consists of 40 human-human dialog interactions where a remotely located person gives directions to a pedestrian walking around in an urban or campus environment. The experimental paradigm varies the friendship relationship of the dialog partners, whether the director can see what the pedestrian sees, and the familiarity of both the director and the pedestrian with the environment. No other existing direction-giving corpora model dialog interaction in an outdoor real-time environment where the physical context grounds the dialog context. The resulting corpus is used to test hypotheses about, and develop models of, the evolution of local and global dialog adaptation strategies. Key to our effort is determining which adaptations are actually functional, that is, beneficial for a particular task or context in spoken dialog systems.","title":"EAGER: Collaborative Research: Modeling Distinctive Partners in Adaptive Spoken Dialog","awardID":"1044693","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["542063"],"PO":["565215"]},"174114":{"abstract":"NSF is providing partial financial support for a Student Research Workshop <br\/>at the AMTA-2010 conference in Denver, Colorado. The Association for Machine <br\/>Translation in the Americas (AMTA) is a non-profit professional organization <br\/>in the area of Machine Translation (MT) in the US and the American continent. <br\/>The main mission of AMTA is to facilitate and promote the exchange of <br\/>knowledge and information between the communities of researchers, developers <br\/>and users of Machine Translation and related translation technologies. In its <br\/>effort to foster the professional growth of the next generation of MT <br\/>researchers, AMTA-2010 is featuring a Student Research Workshop, embedded <br\/>as an integral part of the research program at the conference. Students at <br\/>all levels of study (undergraduate, graduate and post-graduate) are invited to <br\/>submit papers describing their research work. NSF is providing funding to <br\/>subsidize travel, conference and accommodation expenses for up to 10 students <br\/>that have been selected to present their research work at the workshop. <br\/><br\/>The AMTA-2010 Student Research Workshop will greatly facilitate professional <br\/>growth for the brightest young researchers in the field of MT, in the early <br\/>stages of their professional career. The workshop will contribute to the <br\/>professional development of a skilled and diverse workforce in the area of <br\/>Machine Translation and computational processing of natural language. MT and <br\/>other language processing applications are becoming vital technologies in the <br\/>global information age. Strength in these areas is crucial to American <br\/>competitiveness in the global economy of the 21st century.","title":"Workshop Proposal: Student Research Workshop at AMTA-2010","awardID":"1048559","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[467050],"PO":["565215"]},"168801":{"abstract":"Future microprocessors will contain many processing cores. This future presents a unique opportunity to increase performance and decrease power consumption by providing different core types, each optimized for different instruction-level behavior within and across applications. The questions of how many core types, how many of each type, and what should each type look like, are perplexing in the face of arbitrary run-time scenarios. This is because (1) Instruction-level behavior is infinitely diverse whereas the number of core designs that can be practically included is limited; (2) Parallel applications tend to favor homogeneous cores for their uniform tasks. Yet, the optimal homogeneous multi-core processor differs for different parallel applications, which are not static; (3) Multiprogrammed workloads tend to favor heterogeneous cores to match their diverse tasks. Yet, the optimal heterogeneous multi-core processor depends on the mixture of tasks and their arrival rates to the system, factors which vary over time; and (4) Even if we consider a fixed run-time scenario, the optimal configuration of core designs depends on latency, throughput, and power preferences. All of these factors vary over time. Thus, while the multi-core era makes it possible and desirable to provide many core types, it is nearly impossible to determine which ones and how many of each. <br\/><br\/>This project proposes AnyCore, a comprehensively reconfigurable superscalar processing core. AnyCore has a unique and ambitious objective: each one of its hundreds of configurations, called \"virtually fabricated cores\", should achieve the same frequency, cycle-level performance, and power as explicitly designing and fabricating just that core. A novel multi-core architecture comprised of many replicated AnyCores can be configured into arbitrary heterogeneous and homogeneous multi-core designs, each having the performance and power of a fixed design. This will enable achieving optimal latency, throughput, and power targets for arbitrary workload types and arbitrary instruction-level behavior within their constituent tasks. The research could have potentially significant impact on the design process of future commercial processors, as well as on education and research as a rapid simulation platform.","title":"SHF: Small: AnyCore: A Universal Superscalar Core","awardID":"1018517","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["518384"],"PO":["366560"]},"174488":{"abstract":"New wireless technologies promise mobile users easy access to real-time data and the ability to stay connected with business partners, colleagues and friends any where, any time. While emerging mobile applications are designed to be data-centric, existing IP-oriented communication paradigms are not flexible enough to support these new functionalities. Additionally, serious security and privacy concerns have been raised. To fully support emerging mobile applications, we are developing a next-generation mobile network, SECON, that supports mobile content centric networking features.<br\/><br\/>This project will demonstrate new mobile internet features via prototyping and large scale experimentations using GENI testbeds. Key features include (i) intra and inter-domain intentional-named message dissemination, (ii) efficient mobile content centric networking protocol design, and (iii) data-centric security with search capability. The proposed educational component will equip both graduate and undergraduate students with both design and implementation experience of innovative mobile Internet features. The PI also plans to organize outreach activities for minority students.","title":"EAGER: Secure Efficient Content Centric Mobile Network (SECON) Design","awardID":"1049845","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517746"],"PO":["564993"]},"174378":{"abstract":"Computations rarely run in deterministic isolation. They interact with users and adversaries, with random events called by algorithms or generated by the context, with delays and glitches from the system, hardware, and distributed infrastructure, etc. Some of these interactions are hard to model, but even those with straightforward mathematical models are often very hard to analyze.<br\/><br\/>Randomness and non-determinism are two basic \"freedoms\" branching out of the concept of deterministic computation which play a crucial role in computing theory. Yet our understanding of their role and power is minimal. Even a gradual progress in understanding these phenomena and their relationship to each other and to other concepts would be important.<br\/><br\/>An example of achievements in this direction is the discovery of generic relationship between one-way functions and deterministic generation of randomness. Another is the concept of transparent (also called holographic, or PCP) proofs and computations.<br\/><br\/>A number of interesting techniques useful for quite different results in these areas have been accumulated: low-degree polynomials and Fourier transforms over low-periodic groups, related to classical results on error-correcting codes and hashing, expander graphs, hierarchic structures, etc. The research is to continue PI's investigation of such concepts and of the power of these and other related techniques.<br\/><br\/>Symmetry is one of the central phenomena in many fields. In computations it can simplify analysis, provide uniformity and redundancy useful, e.g., for error-correction. On the other hand, it can cause indecisiveness, deadlocks and complicate initialization and organization of computing processes. Breaking symmetries is as essential a task as maintaining them. A study of a number of mathematical and algorithmic tools useful for symmetry breaking is planned. Examples include Thue sequences, aperiodic tilings, extensions of the concept of flat connections from manifolds to graphs, and others.<br\/><br\/>In prior work, the P.I. has made major contributions to our understanding of randomness, nondeterminism, complexity, and symmetry breaking. This project will advance our understanding of those areas.","title":"AF:EAGER: Randomness, Non-determinism, and Symmetry Breaking","awardID":"1049505","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":[467800],"PO":["565157"]},"164467":{"abstract":"Volunteer Computing (VC) uses the computational resources of volunteers with Internet-connected PCs to address fundamental problems in science. Unfortunately, the largely white-male volunteers are not representative of the general population, and their involvement typically consists of nothing more than contributing idle computing resources. The demonstrated benefits to scientific discovery and the opportunity to engage a broad population motivate this project?s radical transformation of VC systems. <br\/><br\/>This work will build ExSciTecH, an interactive, easy-to-use VC system to Explore Science, Technology, and Health. The system will motivate and facilitate diverse volunteers to donate their intellectual and computational resources to VC projects. As a result, ExSciTecH will aid scientific discovery even as it develops a more scientifically informed and engaged citizenry. Supported by technologies such as the Nintendo Wii Remote controller and casual gaming, ExSciTecH will help volunteers discover how rewarding and exciting science can be. <br\/><br\/>Intellectual Merit: This project aims to increase the interest and participation of diverse populations in computer science in general and VC projects in particular, to build inclusive communities of diverse volunteers, and to increase the science delivered to scientists by Docking@Home, a VC project targeting the design of new drugs for breast cancer and HIV. <br\/><br\/>Broader Impact: ExSciTecH will be distributed through an established network of undergraduate computing programs that are dedicated to diversity in information technology. The National Center for Women and IT (NCWIT) has experience and resources for promoting and distributing practices that recruit and retain diverse populations.","title":"Collaborative Research: SoCS - ExSciTecH: An Interactive, Easy-to-Use Volunteer Computing System to Explore Science, Technology, and Health","awardID":"0968368","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[440567],"PO":["564456"]},"174389":{"abstract":"While it has been shown theoretically that stochastic network<br\/>optimization techniques utilizing queue backpressure can result in<br\/>high performance cross-layer protocols, there has been limited prior<br\/>work on translating them into practice. In this exploratory research<br\/>project, we develop and demonstrate a novel cross-layer backpressure<br\/>protocol stack for wireless sensor networks, building on our<br\/>implementation of the backpressure collection protocol (BCP). The<br\/>possible gains of this highly agile approach to cross-layer wireless<br\/>networking are substantial and include increased throughput even in<br\/>the presence of mobility, handling of bursty external interference<br\/>events with reduced losses, and reduced protocol implementation<br\/>complexity. We incorporate techniques for MAC-layer backoff<br\/>prioritization, transport layer utility optimization, mechanisms to<br\/>handle various kinds of network dynamics, and interoperability with<br\/>asynchronous low power sleep schedules. Protocol implementation code<br\/>developed in the project will be released publicly as open-source. It<br\/>is expected that the successful completion of this project will<br\/>provide an important proof-of-concept that stochastic optimization<br\/>theory-driven protocols can be successful in practice.","title":"EAGER: Towards an Open Source Backpressure Protocol Stack for Wireless Networks","awardID":"1049541","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[467823,"531832"],"PO":["565303"]},"165204":{"abstract":"The objective of this project is to explore several problems and directions in Combinatorial Geometry and Ramsey Theory and their interconnections. One research direction is centered around the problem of geometric incidences between points and curves and their connections with problems involving distances, areas, and other measures. The project also deals with geometric questions in Ramsey theory, applications of Van der Waerden's theorem on arithmetic progressions and new results of this type, and others that fit in the broader category of monotone paths in line arrangements. Of particular interest are techniques that permit reformulations of geometric problems in a purely combinatorial setting, such as the technique of allowable sequences introduced by Goodman and Pollack. The last category comprises problems of estimating the size of sets that appear in the theory of set addition and multiplication. Ramsey type problems and Erdos-type extremal discrete geometry problems have attracted continued attention in the combinatorics and computational geometry communities, due to their relevance for computational problems (in range counting, pattern matching, motion planning, and others) and the rich techniques developed for improving extremal bounds (such as the epsilon-net theory, the Crossing Lemma, quasi-planar graphs, etc.), which proved to be instrumental in many areas of computational geometry.<br\/><br\/>A key objective of this project is to explore and identify new techniques for dealing with incidence and distance problems, and other problems in Ramsey theory and number theory that seem to require attacks from several directions. An important feature of the proposed research is advancing the integration of techniques from different areas---geometric graph theory, number theory, topology, linear programming, computer experiments, theory of algorithms---in finding solutions for problems in combinatorial geometry and Ramsey theory. Progress on some of the combinatorial questions presented here are likely to have applications in the design and analysis of geometric algorithms, approximation algorithms, etc, and consequently have impact in the real word over time.","title":"Problems at the interface between Ramsey Theory and Combinatorial Geometry","awardID":"1001667","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7970","name":"Combinatorics"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":[442582],"PO":["565280"]},"163389":{"abstract":"PI: Barrett, Steven F.<br\/>Proposal Number: 0962380<br\/><br\/>As part of the University of Wyoming, College of Engineering and Applied Science (CE&AS) engineering curriculum, students are required to complete a meaningful undergraduate design experience. On the other hand, there are over 73,000 individuals with disabilities in the state of Wyoming with diverse needs. This program will provide a vital link between the University's talented students and individuals with assistive technology (AT) needs. Students will create and provide prototype, custom designed assistive devices which will enhance the quality of life for the individual. Also, this program will educate new design engineers on the special needs of community members with disabilities. Furthermore, we believe this program will continue to attract additional female engineering students.<br\/>We will launch the following new initiatives in the next increment of the program:<br\/>- Establish a review panel of assistive technology professionals, engineers, and project users to insure project meets the user?s needs. The panel will meet several times during project development.<br\/>-Expand the project base regionally to include project requests from adjoining states.<br\/>- Assess engineering students grasp of concepts after the AT instructional module.<br\/>- Provide a web-based project submission site to ease the project request process.<br\/>- Advertise program via websites, WIND publications, and presentations to appropriate groups.<br\/>- Expand project technologies to enhance recipients' independence (e.g. personal area networks, web-based safety monitoring, autonomous wheelchairs, etc.).<br\/>- Develop measurable set of program metrics to assess program success annually.<br\/>To accomplish program objectives the College of Engineering and Applied Science has partnered with the Wyoming INstitute for Disabilities (WIND). The PI Dr. Steven Barrett, Ph.D., P.E. will serve as the coordinator for the College of Engineering and Applied Science to identify the appropriate student expertise to accomplish a specific project. WIND has been a part of the University of Wyoming (UW), College of Health Sciences since 1994. As a member of the national network of University Centers of Excellence in Developmental Disabilities Education, Research and Service (UCEDD), WIND provides teaching, research, information, and community services to both the University and Wyoming at large. WIND Associate Director, Sandy Root-Elledge, M.A., will serve to identify specific AT projects for undergraduate engineering students to design, build, test, and deliver to individuals with disabilities as well as provide assistive technology and disability awareness training to all engineering students.<br\/>Intellectual Merit of the Proposed Activity:<br\/>- The proposed activities will allow the continued construction of projects for individuals with disabilities in the area of developmental disabilities through the Research to Aid Persons with Disabilities (RAPD) program at the NSF. This project has a dramatic need throughout the state and the region.<br\/>- These projects will allow students to complete the required two-semester senior design project in an interdisciplinary team approach. The team includes mechanical and electrical engineering students, assistive technology professionals, caregivers, and the intended users and family members where appropriate. This is highly encouraged by the ABET, Inc. accreditation body.<br\/>- The proposed projects will educate new engineers on the special needs of community members with disabilities early in their careers including those not participating in the NSF sponsored projects.<br\/>Broader Impacts of the Proposed Activity:<br\/>- The proposed design projects should contribute to the quality of life for disabled individuals. Special emphasis will be placed on independent living technologies.<br\/>- Encourage students toward graduate school and employment in AT related fields.<br\/>- Encourage more participation by under-represented student groups (e.g. women in engineering).<br\/>- Provide engineering students with awareness about disabilities and assistive technology.","title":"Undergraduate Design Projects to Aid Persons with Disabilities","awardID":"0962380","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I435","name":"Defense Intelligence Agency"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"5342","name":"Gen & Age Rel Disabilities Eng"}}],"PIcoPI":[437046],"PO":["565049"]},"168603":{"abstract":"The behavior of a communications network depends on the configuration<br\/>of hundreds to thousands of switches, routers, firewalls, and other<br\/>devices. For example, a campus network may have as many as 2,000<br\/>inter-operating network devices and about one million lines of<br\/>configuration; whether the network operates correctly depends for the<br\/>most part on the configuration of these devices. Human configuration<br\/>errors are the single biggest contributor to network downtime. This<br\/>project seeks to develop techniques to make networks easier to manage<br\/>by improving both configuration testing and synthesis. Testing takes<br\/>as input an existing network configuration and determines whether the<br\/>configuration is operating correctly. Synthesis generates<br\/>configurations automatically. The project draws on two testing<br\/>techniques to make network configurations easier to test: differential<br\/>testing and dynamic testing. Differential testing generates test<br\/>cases to characterize the run-time behavior of two different programs;<br\/>analyzing differences in network-wide configurations can help testing<br\/>by allowing test cases to focus on the smaller subset of<br\/>configurations that change more frequently. Differential analysis may<br\/>make testing more tractable by reducing the amount of configuration to<br\/>test. Dynamic testing checks the correctness of a program by<br\/>executing it; this execution can be performed in a parallel \"shadow\"<br\/>network, for example. The expected results from this project include<br\/>tools for network operators to test and automatically generate<br\/>network-wide configurations for both enterprise and ISP networks. The<br\/>tools will also be useful in graduate-level courses.","title":"NeTS-Small: Collaborative Research: Network-Wide Configuration Testing and Synthesis","awardID":"1017545","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["553786"],"PO":["564993"]},"167514":{"abstract":"Data Protection laws that exempt data that is not individually<br\/>identifiable have led to an explosion in anonymization research.<br\/>Unfortunately, how well current de-identification and anonymization<br\/>techniques control risks to privacy and confidentiality is not well<br\/>understood. Neither is the usefulness of anonymized data for real-world<br\/>applications. The project addresses anonymization on three fronts:<br\/><br\/>1) Textual data, even when explicit identifiers are removed (names,<br\/>dates, locations), can contain highly identifiable information. For<br\/>example, a sample of chief complaint fields from the Indiana Network<br\/>for Patient Care (INPC) found several instances of \"phantom limb<br\/>pain\". Amputees can be visually identifiable, but the HIPAA Safe<br\/>Harbor rules do not list this as \"identifying information\". Any<br\/>policy explicitly listing all types of identifying data is likely to<br\/>fail. Through a joint effort with computer science and linguistics,<br\/>the project is developing new methods to remove specific details from<br\/>text while preserving meaning, eliminating such highly identifiable<br\/>information without a priori knowledge of what would be identifying.<br\/><br\/>2) Current anonymization research is based on unproven measures of<br\/>identifiability. Through a re-identification challenge on synthetic<br\/>data (but based on real healthcare data), the project is evaluating<br\/>the efficacy of these measures. Interdisciplinary teams of students<br\/>are given challenge problems - anonymized data with hypothetical<br\/>healthcare data - and asked to make (hypothetical) inferences about<br\/>health information of individuals. The results can be used to<br\/>calibrate the effectiveness of different anonymization measures.<br\/><br\/>3) The utility of anonymized data has been a concern among research:<br\/>Does anonymized data provide credible research results? By partnering<br\/>with healthcare studies at the Kinsey Institute and Purdue University<br\/>School of Nursing, the project is comparing analyses on original data<br\/>with analyses on anonymized data, and evaluating the impact of types<br\/>of anonymization on research results. A related issue is determining<br\/>the impact on data collection: Are individuals more candid in their<br\/>responses if they know data will be anonymized? Outcomes are broadening<br\/>the scope of research that can be performed on anonymized data, while<br\/>ensuring that researchers know when access to individually identifiable<br\/>data (with attendant restrictions and safeguards) is needed.<br\/><br\/>Through these tasks, the project is advancing our ability to utilize<br\/>the wealth of data we now collect for the benefit of society, while<br\/>ensuring individual privacy is protected.<br\/><br\/>For further information see the project web site at the URL:<br\/>http:\/\/projects.cerias.purdue.edu\/TextAnon","title":"TC:Large:Collaborative Research:Anonymizing Textual Data and its Impact on Utility","awardID":"1012208","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["527912",448807,"548255","548255","562974","527911"],"PO":["565136"]},"168845":{"abstract":"Inferring the true evolutionary history for a group of organisms, taxa, is a difficult problem. For a given set of taxa, there is an exponential number of ways to depict their family tree. Hence, an exhaustive exploration of all possible trees is infeasible. As a result, the most popular techniques sample tree space in order to obtain an estimate of the true evolutionary tree. The challenge is to know when a an estimate of an evolutionary tree for a group of taxa has converged, which is important because non-convergence leads to inaccurate estimation of the true evolutionary tree.<br\/><br\/>The team will develop a suite of convergence detection algorithms for large-scale Markov Chain Monte Carlo phylogenetic analyses, one of the most popular techniques for reconstructing large-scale evolutionary trees that can handle hundreds of thousands of trees on hundreds to thousands of taxa. Convergence detection changes the framework for how these evolutionary trees are reconstructed. For example, analyses that have not yet converged, rather than be terminated based on some arbitrary specification (e.g., elapsed time), could be allowed to continue as long as progress toward convergence is detected. If progress is still not made, the phylogenetic analysis would be terminated saving significant time and computational resources. The approach arms life scientists with information for why their analysis did not converge. <br\/><br\/>The team will develop convergence detection techniques that are based on the topological structure (i.e., the evolutionary relationships contained in a tree) of the underlying phylogenetic tree instead of relying solely on its score. To address the above issues, the novel integrated framework consists of: (i) designing and analyzing new algorithms for convergence detection, (ii) identifying the causes for non-convergence in a phylogenetic analysis, (iii) performing real-time convergence analysis, and (iv) developing new visualization tools that provide informative views of convergence data.<br\/><br\/>There are many benefits that exist between the collaboration of a research university and an undergraduate liberal arts college. Both undergraduate and graduate students in both biology and computer science have an opportunity to design and implement algorithms and run computational experiments on large data sets that would otherwise be unavailable to them. The large trees that can be considered have applications in improving global agriculture and protecting ecosystems from invasive species. The results of this work will be presented and disseminated at scientific conferences, workshops, and journals. Tools and software developed will be made publicly available.","title":"III: Small: Collaborative: Novel Techniques for Understanding Convergence in Large-Scale Markov Chain Monte Carlo Phylogenetic Analyses","awardID":"1018785","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["513229"],"PO":["565136"]},"164489":{"abstract":"Social production communities can be powerful engines for harnessing the efforts of many individuals to produce valuable artifacts and knowledge. However, their success critically depends on members' ability to effectively contribute. As the size and complexity of the community grows, so do challenges to members' understanding of the content and collaboration. These challenges decrease the ability of the team to work together, and the quality of the work product.<br\/><br\/>The researchers propose partnering humans with intelligent interfaces that improve contribution effectiveness. They will create intelligent algorithms and interfaces that go beyond supporting people simply foraging for information to information farming, in which members of the community work together to plant the seeds of the information the community needs, nurture the growth of those seeds into valuable information, and weed out the information that detracts from the value of the farm.<br\/><br\/>The research is based on theories of human information processing, and will extend those theories to environments in which people are producing information. The researchers will explore new algorithms and interfaces based on the extended theories, and will carry out studies to understand how the theories work in practice.<br\/><br\/>Social production communities are economically and socially important. Open source software runs large parts of our economy; Wikipedia is revolutionizing knowledge production and consumption, providing free access to one of the largest bodies of knowledge gathered in human history. The proposed research will directly improve Wikipedia, and will contribute to understanding how social production communities work.","title":"SoCS: Collaborative Research: Information Farming: Intelligent Interfaces for an Online Production Community","awardID":"0968483","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["518491","483488"],"PO":["564456"]},"168735":{"abstract":"Today's computing environments are characterized by an ongoing dramatic increase in connectivity and data sharing. A critical concern in this setting is access control---the ability to easily and quickly allow access to authorized users or devices, while preventing misuse, unauthorized access, and violations of privacy. Two common pitfalls in many approaches to access control are (1) their inability to support highly flexible access-control policies while avoiding unintended side effects and (2) difficulty in usefully differentiating between all the authority that a user might need and the minimal authority that she requires to perform a specific task. Both these shortcomings prevent systems from enforcing exactly the policies that users desire and thereby increase the danger of misuse and the costs of compromise.<br\/><br\/>This award supports the design and implementation of mechanisms that make it possible to specify and enforce security policies that more precisely limit the amount of authority that is conveyed to users or devices. More specifically, new mechanisms will be developed to enable restricting the circumstances under which the authority to access a resource can be used, and to allow administrators to specify these restrictions as constraints on policies. At the same time, new methods will be developed to distinguish between the total authority that is conveyed to a user and the subset of that authority that she may exercise at a specific moment. These improvements will be carried out in the context of logic-based access control, an approach that offers significant benefits in terms of flexibility and assurance of correctness.","title":"TC: Small: Towards precise specification of logic-based acces-control policies","awardID":"1018211","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550854","563508"],"PO":["565264"]},"168856":{"abstract":"Internet users can now use https:\/\/www.google.com instead of http:\/\/www.google.com, protecting their text searches against espionage and sabotage by network attackers. However, Google still does not support encryption for high-volume data such as images and maps.<br\/><br\/>Other sites encrypt even less. More than 99% of Internet web pages and Internet mail messages remain unencrypted. Furthermore, most encryption used on the Internet is at a surprisingly low security level. For example, in June 2010, https:\/\/paypal.com was still using 1024-bit RSA, a key size easily breakable by the Conficker botnet. Government recommendations to move to at least 2048-bit RSA have triggered widespread objections.<br\/><br\/>The underlying problem is that cryptography is too slow. Even when the necessary cryptographic software has been written and installed, users are often forced to disable or limit the software, or compromise security, so that their computers are not overloaded.<br\/><br\/>This project directly addresses this problem by making cryptography faster---without compromising security. The research has a broad vertical scope spanning high-speed engineering of high-speed software, CPU-specific optimization, algorithm analysis and design, analysis and design of cryptographic functions, and optimization of cryptographic Internet protocols.","title":"TC: Small: Higher-Speed Cryptography","awardID":"1018836","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548359"],"PO":["565264"]},"168504":{"abstract":"Traditional models of information retrieval assume documents are independently relevant. However, users often want to see the retrieved documents cover several subtopics, or different possible interpretations, or nuggets of relevant information for a query. In these cases, modeling documents as independently relevant does not provide the optimal user experience. This research project attempts to remedy this with new models of document interdependence and new evaluation measures. There are three threads running through this work: (1) the models of diversity, novelty, and redundancy that will be needed to implement ranking algorithms; (2) measurements of diversity, novelty, and redundancy in a ranking of documents; and (3) optimizing model structures and parameters to the measures.<br\/><br\/>The main challenges addressed in this project include: how to model relevance along with interdependencies among search results for different tasks and domains; how to predict the degree of diversity; and how to evaluate the new models. The new models include set-based and pattern-based retrieval models, and the new measures include set-based labeling, list-based preference etc. The models will be evaluated with the existing measures as well as the new measures, and the new measures will be evaluated with in-depth statistical analysis. The result of this project includes a suite of models and measures that combine novelty and diversity with relevance for different domains, including biomedical search, legal search and Web search.<br\/><br\/>The far-reaching potential impact of this project is an improvement in search engine utility across the board. The project addresses specific applications to biomedical search, legal or patent search, and web search reflect major domains in which search engines are important and in which improved models for novelty and diversity would directly improve the user experience. Project results, including publications and evaluation datasets, will be disseminated via the project website (http:\/\/ir.cis.udel.edu\/monads).","title":"III: Small: Models and Measures for Novel and Diverse Search Results","awardID":"1017026","effectiveDate":"2010-09-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[451075,451076],"PO":["563751"]},"168625":{"abstract":"As the de facto global information infrastructure that underpins much of today's commercial, social, political and cultural activities, the Internet now provides a convenient, speedy (near instant), and sometimes anonymous means to connect and communicate, and more broadly speaking, to ``social-network'' with other people, breaking the geographical, cultural, socio-economic, and other barriers. These ``social networks?? reflect the social interactions, behaviors and interests of human users, and influence what information is accessed and what services are used. On the other hand, the Internet and its constituent network and service infrastructures -- the underlying ``technical networks'' which connect human users, the end devices they use for communications and information access, and various servers hosting Internet services -- determine how information and services are accessed and delivered. Hence, the interplay and interactions of the socio-technical networks drive innovation, adoption and spread of both Internet applications and the technologies that enable them. As the research community contemplates ``clean-state'' re-designs of a future Internet architecture, it is therefore both important and imperative to understand and account for such interplay and interactions. <br\/><br\/>Intellectual Merit. This research project explores and studies the interplay and interactions of socio-technical networks through network traffic. Telecommunications networks exist to carry and deliver traffic generated by various applications and services to enable communications, information access and sharing, and social interactions among users. Hence network traffic and its spatial and temporal dynamics implicitly reflect user behaviors, social communities, and emergent trends. The researchers advance the novel notion of network traffic activity graphs (TAGs) to capture the spatial and temporal traffic dynamics, and to uncover and extract significant communication patters and structural dynamics therein. The researchers employ TAGs as a main tool to study the interplay and interactions of socio-technical networks by addressing two broad sets of inter-related questions: i) how to extract network-wide, spatial and temporal communication patterns and other structural dynamics inherent in network traffic, and use them to help reveal the social interactions, community structures and user behaviors? and ii) how to meaningfully analyze and quantify the effects of the interplay and interactions of socio-technical networks, and account for them to better operate, manage, secure and evolve the (technical) networks and the services running on top of them? <br\/><br\/>Broader Impact. Understanding the interplay and interactions of socio-technical networks will help improve the operations, management and security of today's IP networks as well as emerging services. Such understanding will also provide valuable insight to the design of future networks, so as to better meet the demands and requirements of new Internet services, many of which are too futuristic to have yet been contemplated. All these will bring significant benefits to users, service providers and the society at large. The research project will also provide both undergraduate and graduate students with hands-on experiences in learning large-scale data analytics and network designs. The researchers will actively involve undergraduate students -- especially female students and underrepresented minorities -- in the research project. The researchers plan to disseminate the research outcomes through publications and outreach activities. Through participation in future Internet design forums (e.g., NetSE\/GENI) and collaboration with industrial partners, the researchers will seek to impact the development of future Internet technologies and services by explicitly accounting for the interplay and interactions of socio-technical networks.","title":"NeTSE: Small: Spatio-Temporal Network Traffic Dynamics and Interactions of Social-Technical Networks","awardID":"1017647","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["543509","557452"],"PO":["565090"]},"168746":{"abstract":"Wireless technology has become indispensible in today?s world. However, jamming attacks are a prominent problem, resulting in loss of network availability, increased latency and reduced throughput due to significant deterioration of link quality. The interplay between users and jammers is a natural fit for game-theoretic analysis which provides strategic solutions to the jamming problem and allows us to study the extent to which jammers affect the stability and welfare of the wireless network. <br\/><br\/>This project models the impact of local jammers on higher level network functions such as traffic flows and congestion. The PIs provide formulations and solve zero-sum and other games at physical and network layers that reflect appropriate utility\/cost functions, jammer and transceiver resource constraints and common knowledge (e.g. side information about channel conditions). Leveraging metrics from algorithmic game theory, such as the price of stability\/anarchy, novel metrics and analytical techniques will be developed that measure the impact of jamming such as the Price of Jamming, which measures how much worse equilibria can get when jammers are involved. The PIs also examine the existence of networks, games and utility functions which lead to paradoxical situations (Paradox of Jamming), where jammers may actually improve the welfare of the system. Thus, this work will provide broad insights into determining the extent of jamming damage in wireless networks and also to design appropriate anti-jamming mechanisms. The outcomes of this research will be disseminated through publications, talks, and courses. Traditionally underrepresented minority students in the PIs research groups will actively participate in this research.","title":"NeTS: Small: Modeling and Analysis of Multilayer Jamming Games in Wireless Networks","awardID":"1018273","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[451649,"551019","550884"],"PO":["557315"]},"168867":{"abstract":"Indexes impact crucially the performance of a database system, and hence creating the right indexes for a workload, also known as index tuning, is an important task in database administration. Automated index tuning techniques have thus become an indispensable tool for administrators. However, existing techniques target the simplified scenario of a single database hosted on a single machine, which does not match the more complex system architectures observed in practice, e.g., multi-tenant systems with virtualized databases, or shared-nothing parallel databases. This mismatch results in suboptimal tuning that underutilizes the available system resources. Moreover, the majority of techniques require the administrator to have detailed knowledge of the anticipated database workload, which is not feasible when the workload has unpredictable characteristics (e.g., workload in ad-hoc data analysis). An alternative is techniques that analyze the workload online, but such techniques assume total control of index-maintenance decisions and essentially sidestep the administrator. The proposed project develops novel index tuning techniques that address the aforementioned shortcomings. The first contribution is a new tuning paradigm that couples online workload analysis with feedback and interaction from the administrator, thus combining the best features of previous approaches. The theoretical foundation is a novel extension of previous results from the field of online optimization. Subsequently, the paradigm is specialized for databases on compute clusters and virtualized databases, two practical architectures that are not covered by previous techniques. The project will impact the education of Computer Science students in database systems and will lead to more effective tools for database administration. For further information see the project page at http:\/\/www.cs.ucsc.edu\/~alkis\/tuning.","title":"III: Small: Novel Paradigms for Automated Index Tuning","awardID":"1018914","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["542080"],"PO":["563727"]},"178547":{"abstract":"Extending virtualization technology into high-performance, cluster platforms generates exciting new possibilities. However, I\/O efficiency in virtualized environments, specifically with respect to disk I\/O, remains little understood and hardly tested. The objective of this research is to investigate fundamental techniques for virtual clusters that not only facilitate rigorous performance studies, but also identify places where performance is suffering and then optimize the system to lessen the impact of such bottlenecks. <br\/>This research will greatly contribute to understanding virtualized I\/O, identifying I\/O bottlenecks and optimizing I\/O, and thus facilitate the cluster systems to most effectively utilize virtualization technology. This project will also contribute to the society through promoting research and engaging under-represented groups that leads students to advancing their careers in science and engineering.","title":"RUI: Automatic Identification of I\/O Bottleneck and Run-time Optimization for Cluster Virtualization","awardID":"1102624","effectiveDate":"2010-09-03","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["550809"],"PO":["565272"]},"168515":{"abstract":"The objective of this project is to design autonomous planning algorithms for robots that move obstacles out of the way. The research is motivated by future robots that will save humans from disasters such as floods and earthquakes by solving Navigation Among Movable Obstacles (NAMO). Traditional motion planning algorithms search for collision-free paths from a start to a goal. However, when flood waters have caused furniture to float and collapse, there is no path to the victims. Instead, robots must decide which obstacles can be moved and how to move them.<br\/><br\/>The practical robot algorithms developed in this project manipulate the environment and create accurate environment models. To handle uncertainty about the environment, new algorithms merge tools from decision theory with motion planning. Markov Decision Processes represent robot uncertainty about environment interactions. Process structure encodes the existence and mobility of objects. Computational techniques optimize decisions to achieve both goal-directed and information gathering actions by updating the decision process structure.<br\/><br\/>Results from this work advance the understanding of decision theory to motion planning for robot systems with numerous degrees of freedom. Potential applications include solutions to rescue challenges and broader domains where uncertain outcomes of numerous possible actions require online modeling of environments. Outreach activities focus on workshops that combine decision theory with motion planning and course curriculum that introduces students to research in algorithms that simultaneously learn about the world and make effective decisions.","title":"RI: Small: Planning Navigation Among Movable Obstacles","awardID":"1017076","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["500707"],"PO":["543539"]},"167426":{"abstract":"Despite revolutionary advances in how images are recorded, manipulated, and reproduced, our ability to re-create the visual experience remains remarkably limited. Few realistic computer models exist for the characteristic appearance of natural materials such as marble, wood, coral, or skin, or man-made ones such as color-shifting automotive paints. Digitizing and creating realistic images of these substances involves reproducing their interaction with light: the way light is reflected from surfaces, or scattered and absorbed within the materials. Full reproducibility also involves \"printing\" a material as a real, physical object that modulates the light around us. However, it is currently impossible to output complex appearance the way we print color on a paper with fixed gloss, or create shapes using a 3D printer. This project encompasses a comprehensive, collaborative research agenda in computer graphics and related areas, to develop an end-to-end framework for acquiring, representing, and fabricating complex appearance, as well as to understand how it is perceived by the human visual system.<br\/><br\/>The enabling technical idea of the project is to treat materials as thin three-dimensional volumes populated with general scattering sites. This is a radical departure from the hitherto standard approach in computer graphics, which has studied materials purely as surfaces. The volumetric representation subsumes and generalizes the diverse set of conventional representations that currently exist in graphics, including surface-based notions such as bidirectional reflectance (BRDF), spatially varying BRDF, and subsurface scattering distributions (BSSRDF). Moreover, it enables fundamentally improved approaches to efficient yet general acquisition, fast and realistic rendering, and fabrication of objects exhibiting phenomena beyond simple surface reflectance and spatially homogeneous subsurface scattering.","title":"HCC: Large: Collaborative Research: Beyond Flat Images: Acquiring, Processing, and Fabricating Visually Rich Material Appearance","awardID":"1011832","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["485160"],"PO":["565227"]},"168878":{"abstract":"Seamless understanding of the meaning of visual images is a key property of human cognition that is far beyond the abilities of current computer vision programs. The purpose of this project is to build a computational system that captures the dynamical and interactive aspects of human vision by integrating higher-level concepts with lower-level visual perception. If successful, this system will be able to interpret visual scenes in a way that scales well with the complexity of the scene. Current computer vision systems typically rely on relatively low-level visual information (e.g., color, texture, shape) to classify objects or determine the overall category of a scene. Such categorization is typically done in a \"bottom-up\" fashion, in which the vision system extracts lower-level features from all parts of the scene, and subsequently analyzes the extracted features to determine which parts of the scene contain objects of interest and how those objects should be categorized. Such systems lack the abilities to scale to large numbers of visual categories and to identify more complex visual concepts that involve spatial and abstract relationships among object categories. Visual perception by humans is known to be a temporal process with feedback, in which lower-level visual features serve to activate higher-level concepts (or knowledge). These active concepts, in turn, guide the perception of and attention given to lower-level visual features. Moreover, activated concepts can spread activation to semantically related concepts (e.g., \"wheels\" might activate \"car\" or \"bicycle\"; \"bicycle\" might activate \"road\" or \"rider\"). In this way there is a continual interaction between the lower and higher levels of vision, which allows the viewer to focus on and connect important aspects of a complex scene in order to perceive its meaning, without having to pay equal attention to every detail of the scene. The system proposed here will model these aspects of human visual perception. <br\/><br\/>The proposed system, called Petacat, will integrate and build on two existing projects: the HMAX model of object recognition originally developed by Riesenhuber and Poggio, and the Copycat model of high-level perception and analogy-making, developed by Hofstadter and Mitchell. HMAX models the \"what\" pathway of mammalian visual cortex via a feed-forward network that extracts increasingly complex textural and shape features from an image. (HMAX has been reimplemented, as the \"Petascale Artificial Neural Network\" or PANN, by the Synthetic Vision Group at Los Alamos to allow for high-performance computing on large numbers of neurons.) Copycat implements a process of interaction between high-level concepts and lower-level perception, and has been used to model focus of attention, conceptual slippage, and analogy-making in several non-visual domains. This project will marry the feature extraction abilities of HMAX\/PANN with the higher-level interactive perceptual abilities of Copycat to build the Petacat architecture. The image interpretation abilities of Petacat will be evaluated on families of related semantic visual recognition tasks (e.g., recognizing, in a flexible, human-like way, instances of \"walking a dog\"). The evaluation part of the project will involve the creation of image databases for benchmarking semantic image-understanding systems. The Petacat source code and benchmarking databases will be made publically available via the web.","title":"RI: Small: Collaborative Research: A Scalable Architecture for Image Interpretation","awardID":"1018967","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[451985],"PO":["564318"]},"168526":{"abstract":"The purpose of the award is to develop a new nano-circuit architecture, novel circuit realization using quantum-electronic devices, and a comprehensive, vertically integrated design methodology for real-time electronic vision applications. The architecture integrates nano-optical sensors and active quantum dot processing elements into hybrid, ultra efficient, distributed intelligence systems with meta-level decision making agents. This is in contrast with conventional electronic vision systems where all decision related processing is done by an algorithmic agent only after digitization of the input from nanowire sensors. The approach employs a smooth analog-to-digital processing transition to allow en-route, hierarchical transformation of the input into simpler, digital representations of multidimensional, abstract input characteristics while the signal is on its way to the central decision making agent. A more rapid decision-making can be achieved because the agent can now directly correlate just the key features without first identifying and extracting these features or filtering out extraneous details. Such close-to-source processing also includes all other desirable benefits like high energy-efficiency, low signal degradation and small area requirement for chip implementation, in addition to high speed. Specifically, fanning-out the input to a cellular-neural-network-like architecture of active quantum-electronic analog functional units will extract and encode the key features that can then be fanned in to one or more decision agents. These units include spatio-temporal filters, velocity estimators, and image processing elements. <br\/><br\/>The intellectual merits of this research include the construction of nanoscale quantum dots based cellular logic arrays capable of performing neuromorphic computation like spatiotemporal signal processing, video and image processing; and the design of a new CAD tool for optimizing the 3D nanostructures of quantum tunneling devices while performing the system-level optimization in an augmented circuit simulator developed by the principal investigator's research group. The broader impacts include development of pedagogical interdisciplinary training to the next generation of circuit engineers and supplementary didactic material---two new, definitive textbooks on nanoelectronics.","title":"SHF: Small: Fusion of Quantum Dot\/Nanowire Based Sensors and Processors in Ultra-low-energy, Distributed-Intelligence Sensing Network","awardID":"1017143","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["521045","434309"],"PO":["565157"]},"168647":{"abstract":"The project continues the study of interconnections between group theory and the theory and practice of computation. The major objectives are (1) the design, analysis, and implementation of algorithms for computations with finite groups; (2) the development of mathematical tools required for the design and analysis of such algorithms; (3) the study of current bottlenecks in the graph isomorphism problem, a major open problem in the theory of computing; and (4) the computationally motivated study of discrete structures involving the group concept. The project will build on the PIs recent results of breaking quarter-century old bottlenecks in the areas of matrix group computation and on the graph isomorphism problem. A principal theme of the project is the synergy between the theoretical and practical, benefitting both the field of symbolic algebra and the theory of computing through the design and implementation of algorithms that are both fast in practice and admit rigorous complexity analysis. The project methodology in the area of matrix computations will combine elements of the two existing approaches, the geometric and abstract structural (\"black-box\") frameworks. The project also includes related problems in group theory, combinatorics, and computer science, connected through the algorithmic study of objects involving the group concept. In particular, a combination of such tools will be required for a renewed study of the bottlenecks that have blocked progress on the graph isomorphism problem and the related coset intersection problem in permutation groups. The PIs will also study of parameters of Boolean functions subject to symmetry conditions, including the complexity of property testing; and the Abelian Sandpile Model which connects a number of fields, including statistical mechanics, algebraic graph theory, discrete dynamical systems, algorithms, and complexity in the study of a certain commutative monoid and group.<br\/><br\/>Groups are the mathematical formulation of symmetry, ubiquitous in mathematics and the sciences. Algorithms for finite groups and their associated Cayley graphs have a wide range of applications, from group theory to statistics, network design, the graph isomorphism problem (of relevance to computer science and chemical documentation), cryptography, and the construction of objects with high symmetry. The broader impact of the project is primarily through the implementation of new algorithms in GAP, a leading, open access computer algebra system that provides computing environment for research in group theory, algebra, graph theory, coding theory, and design theory. GAP development also represents a significant contribution to education as there is an increasing demand to use GAP in undergraduate abstract algebra courses.","title":"AF: Small: Collaborative Research: Groups in Computer Science","awardID":"1017781","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[451412],"PO":["565157"]},"168658":{"abstract":"Movement is a basic feature of human existence and is intimately connected to our quality of life. Movement training can prevent injury, improve athletic performance, delay musculoskeletal disease and accelerate rehabilitation. Until now, training has been limited in scope to specialized training facilities and limited in effectiveness to the verbal recommendations of physical trainers. In this project, the PI's goal is to expand the scope and effectiveness of human movement training in order to extend health and lifestyle benefits to the general public. The primary outcome of this research at the intersection of robotics, biomechanics and human-computer interaction will be gait modeling software that integrates sensor data in real time to compute kinematics, kinetics and joint\/tendon forces to predict adjustments to motion parameters to achieve an end goal. The PI's hypothesis is that wearable computation can fundamentally change the way people move. The miniaturization of computational hardware, as well as advances in movement analysis algorithms, wearable sensors and feedback devices, all serve as catalysts for a new level of human interaction. The work will focus on everyday repetitive dynamic activities like walking, running and jumping, whose nature is that information gathered and analyzed during one cycle can be applied to subsequent cycles to achieve gradual improvement. Feedback that builds upon advances in robotics, motion tracking and biomechanical modeling (that have led to efficient monitoring and simulation of complex multi-degree of freedom systems) will be provided in real time and will be adaptive, robust with respect to cycle-to-cycle variations, and user specific. For maximum impact, movement training will be accessible to the average citizen instead of confined to the laboratory or clinic. To this end, the PI will create a system that could be used while walking around the house, hiking outdoors or running in a gymnasium. Preliminary experiments in motion tracking, dynamic analysis and wearable feedback for gait retraining to reduce knee loading associated with injury and arthritis will be extended to evaluate which types of sensing and feedback, in combination with algorithms to detect and analyze motion anomalies, are effective outside of the laboratory. The PI will conduct a series of experiments to validate the portable solution, comparing it with results obtained in a fully instrumented laboratory setting and assessing how the effects of training are retained over time. <br\/><br\/>Broader Impacts: The PI argues that with wearable retraining devices middle-aged women could be taught to walk in a way that slows or prevents osteoarthritis as well as injury at the hips, ankles, etc., college athletes could be trained to jump and land while playing volleyball so as to prevent ACL and other common sports-related injuries (while perhaps improving performance as well), and victims of stroke and other neurological disorders could be rehabilitated at home instead of at the clinic. This project will focus initially on walking and knee joint loading, a problem of immediate importance for the aging U.S. population. The PI will provide open source software (e.g., for monitoring sensors and predicting target gait parameters) and wearable hardware licensing to promote adaptation of project outcomes to other applications.","title":"HCC: SMALL: Wearable computation and feedback for real-time movement training","awardID":"1017826","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["508165",451436],"PO":["565227"]},"168427":{"abstract":"Crowd-sourcing is a recent framework in which human intelligence tasks are outsourced to a crowd of unknown people as an open request for services. Requesters use crowd-sourcing for a wide variety of jobs like dictation-transcription, content screening, linguistic tasks, user-studies, etc. These requesters often use complex workflows to subdivide a large task into bite-sized pieces (including the management of these tasks), each of which is independently crowd-sourced. These workflows are paramount to the success of crowd-sourcing, still, there has been little attention paid to methods for dynamically optimizing the throughput of a workflow. Controlling and optimizing such a workflow is an excellent application for AI research for two reasons. First, it is challenging in that the agent has to understand the dynamics of an uncertain, real-time environment and reason about distinct choices for a decision. More importantly, the domain has significant economic value -- progress can potentially impact hundreds of thousands of people and spur economic development in a fast growing sector.<br\/><br\/>This project is investigating complex workflows using a decision-theoretic framework that optimizes for a quality\/price trade-off, with aims of (1) building statistical models of worker behavior derived from a large corpus of online behavior, (2) defining a declarative representation language to describe a wide range of workflows, and (3) developing an automated scheme that optimizes a general workflow resulting in an automated controller for making informed decisions at various stages of the process and for monitoring worker accuracies and computing corrections based on them. In the longer term, perhaps beyond the scope of this project, is (4) development of an interface optimizer that automatically learns the best user interface for a task based on user behavior increasing throughput of the workflow, and (5) integrating these ideas in an open-source, software toolkit to directly benefit the various requesters in managing their tasks.","title":"RI: Small: Decision-Theoretic Control of Crowd-Sourced Workflows","awardID":"1016713","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[450899,450900],"PO":["562760"]},"168548":{"abstract":"This project investigates computability, algorithmics, and complexity in distributed settings with large numbers of machines cooperating on solving computation problems in the presence of dynamic changes in the computing medium. The computation problems are modeled as collections of tasks, such as the problems frequently occurring in the Internet supercomputing. This research has the potential to impact massive cooperative computing in dynamic settings through the use of rigorously developed algorithms with formally proved efficiency and fault-tolerance guarantees. In the longer term this research will also have impact on the development of broader classes of adaptive distributed systems.<br\/><br\/>This research develops advanced algorithms enabling efficient and fault-tolerant cooperative computing in dynamic distributed settings. The basic problem is formulated in terms of a collection of processors that need to perform a set of tasks, where the tasks must be executed using either at-least-once or at-most-once semantics. The research considers dynamic settings that are representative of situations in Internet supercomputing. The models of cooperation include: (a) oracle model, where a central authority provides information to the participants. (b) master-worker model, where a single master coordinates the workers in performing the tasks, a typical setting in Internet supercomputing. (c) peer-to-peer mode, where fully-distributed solutions will be investigated, enabling much more dynamic and fault-tolerant solutions. The investigation includes the associated resource discovery problem of identifying the nodes in the distributed system that are willing and able to cooperate; here the investigation focuses on more realistic settings than previously considered. This research also studies supporting services that can provide effective implementations of communication and shared-memory primitives in target dynamic platforms. The quality of algorithms is evaluated using corresponding lower bounds and impossibility results.","title":"AF: Small: Collaborative Research: Principles of Robust Cooperative Computing in Dynamic Distributed Systems","awardID":"1017232","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7934","name":"PARAL\/DISTRIBUTED ALGORITHMS"}}],"PIcoPI":[451177],"PO":["565251"]},"168669":{"abstract":"Differential equations have numerous applications in science and engineering. In this project, new algorithms will be developed to compute exact solutions of linear differential equations. The project consists of two components, a top-down approach and a bottom-up approach. The bottom-up approach is to develop an algorithm for each particular type of solutions. In contrast, the top-down algorithms are not specific to any particular type of solution, instead, the top-down algorithms aim to reduce an equation to one that is easier to solve. This complements the bottom-up approach in several ways. By reducing to an easier equation, the top-down approach can drastically reduce the computation time it takes to solve the equation. Moreover, the top-down approach also reduces the number of algorithms need to be developed and implemented in the bottom-up approach; only equations that can not be reduced any further need to be treated.","title":"AF: Small: Solving Linear Differential in Terms of Special Functions","awardID":"1017880","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["550445"],"PO":["565251"]},"167459":{"abstract":"Data Protection laws that exempt data that is not individually <br\/>identifiable have led to an explosion in anonymization research. <br\/>Unfortunately, how well current de-identification and anonymization <br\/>techniques control risks to privacy and confidentiality is not well <br\/>understood. Neither is the usefulness of anonymized data for real-world <br\/>applications. The project addresses anonymization on three fronts: <br\/><br\/>1) Textual data, even when explicit identifiers are removed (names, <br\/>dates, locations), can contain highly identifiable information. For <br\/>example, a sample of chief complaint fields from the Indiana Network <br\/>for Patient Care (INPC) found several instances of \"phantom limb <br\/>pain\". Amputees can be visually identifiable, but the HIPAA Safe <br\/>Harbor rules do not list this as \"identifying information\". Any <br\/>policy explicitly listing all types of identifying data is likely to <br\/>fail. Through a joint effort with computer science and linguistics, <br\/>the project is developing new methods to remove specific details from <br\/>text while preserving meaning, eliminating such highly identifiable <br\/>information without a priori knowledge of what would be identifying. <br\/><br\/>2) Current anonymization research is based on unproven measures of <br\/>identifiability. Through a re-identification challenge on synthetic <br\/>data (but based on real healthcare data), the project is evaluating <br\/>the efficacy of these measures. Interdisciplinary teams of students <br\/>are given challenge problems - anonymized data with hypothetical <br\/>healthcare data - and asked to make (hypothetical) inferences about <br\/>health information of individuals. The results can be used to <br\/>calibrate the effectiveness of different anonymization measures. <br\/><br\/>3) The utility of anonymized data has been a concern among research: <br\/>Does anonymized data provide credible research results? By partnering <br\/>with healthcare studies at the Kinsey Institute and Purdue University <br\/>School of Nursing, the project is comparing analyses on original data <br\/>with analyses on anonymized data, and evaluating the impact of types <br\/>of anonymization on research results. A related issue is determining <br\/>the impact on data collection: Are individuals more candid in their <br\/>responses if they know data will be anonymized? Outcomes are broadening <br\/>the scope of research that can be performed on anonymized data, while <br\/>ensuring that researchers know when access to individually identifiable <br\/>data (with attendant restrictions and safeguards) is needed. <br\/><br\/>Through these tasks, the project is advancing our ability to utilize <br\/>the wealth of data we now collect for the benefit of society, while <br\/>ensuring individual privacy is protected. <br\/><br\/>For further information see the project web site at the URL: <br\/>http:\/\/projects.cerias.purdue.edu\/TextAnon","title":"TC:Large:Collaborative Research:Anonymizing Textual Data and its Impact on Utility","awardID":"1011984","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[448675],"PO":["565136"]},"168317":{"abstract":"Database management systems (DBMSes) are now an essential component of a vibrant information technology industry. Despite research and development efforts over several decades, DBMSes are not well understood. There is surprisingly little known about quite basic questions such as, how often does the optimizer pick the wrong plan for a query? does adding a physical operator for an algebraic operation always improve the effectiveness of query optimization, or is there a limit to the number of operators that can be practically accommodated? how do throughput and disk utilization depend on multiprogramming level? or when does thrashing occur?<br\/><br\/>This project extends an existing laboratory information management system to develop and thoroughly test predictive models of centralized DBMSes. These models concern the role of schema complexity, effective operator set, and cardinality estimation errors on the plan chosen by the optimizer, the structure of the optimizer search space, and the interaction of multiprogramming level on throughput, disk utilization, and response time in predicting thrashing. These models predict important characteristics of DBMSes that share a common architecture, quantify the relative contributions of identified causal factors, and determine fundamental limits of that architecture.<br\/><br\/>These models can be used to further improve DBMSes through engineering efforts that benefit from the fundamental understanding that this perspective can provide. Additionally, this novel research infrastructure, being made available to the community and to students via a web portal, encourages a culture of empirical generalization and the sharing of experimental results: http:\/\/www.cs.arizona.edu\/projects\/soc\/sodb\/","title":"III: Small: Using Empirical Generalization to Develop Predictive Models of DBMS Processing","awardID":"1016205","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560601"],"PO":["563727"]},"168438":{"abstract":"This project is pursuing a novel strategy for the analysis of temporal structure in video through the exploitation of statistical tests of temporal causality. The motivation is the need for unsupervised video analysis methods which do not require a pre-defined set of video categories or a large corpus of labeled examples. The starting point is the classical formulation of Granger causality, which provides a principled statistical test for directed influence between two time series. Modifying the classical pair-wise Granger test leads to a method which is suitable for video events, which are represented as multiple point processes. Using this representation, methods are being developed for grouping visual words into sets based on their interaction over time. This results in a novel bottom-up segmentation approach which can identify interactions between visual words without supervision. A further goal is the development of an integrated approach to modeling visual events and identifying causal relations. Additional efforts are aimed at developing novel features constructed from causal relations with the goal of improved performance on categorization and retrieval tasks. <br\/><br\/>In summary, the project is developing new unsupervised methods for representing and segmenting video based on temporal causal analysis. The resulting algorithms yield improved performance in video retrieval and categorization tasks, and provide new approaches to organizing and searching unstructured content such as YouTube videos. Novel datasets for video segmentation and categorization are being developed along with a library of analysis software to facilitate adoption by the research community.","title":"RI: Small: Temporal Causality For Video Event Analysis","awardID":"1016772","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550806"],"PO":["564316"]},"168559":{"abstract":"Three-dimensional stacked integrated circuits (3D SICs) promise to overcome barriers in interconnect scaling, thereby offering an opportunity to get higher performance using CMOS technology. This collaborative project between Duke University and Pennsylvania State University is focused on test and design-for-testability (DFT) solutions for 3D SICs. Topics being investigated include: (i) fault modeling and test generation, where the goal is to develop new fault models and test generation methods that can effectively target defects unique to 3D SICs; (ii) DFT infrastructure, optimization techniques for test access, and test scheduling methods for pre-bond test and post-bond test; (iii) Test economics and a cost-analysis framework, where test cost is being incorporated into cost models for 3D IC design and fabrication. <br\/><br\/>This project will facilitate further advances in 3D integration and wider adoption of this emerging technology by the semiconductor industry. Innovations in test methods, DFT, and cost modeling will therefore have a transformative impact on the way in which semiconductor chips are designed and fabricated. Undergraduate and graduate students involved in this research will be trained for the next-generation semiconductor industry workforce. Tools and techniques developed in this research will be used in teaching existing courses and developing new courses. A virtual classroom through web delivery will facilitate collaborative lectures originating from Duke and Penn State. The PIs will make tools available through the web for use by other educators, researchers, and industry practitioners. At Duke, the PI will mentor undergraduate students in collaboration with the Associate Dean for Education and Outreach Programs in the Pratt School of Engineering, and generate excitement among high-school students at the North Carolina School of Science and Mathematics.","title":"SHF: Small: Collaborative Research: Testing and Design-for-Testability Solutions for 3D Stacked Integrated Circuits","awardID":"1017277","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["518504","528208"],"PO":["562984"]},"168328":{"abstract":"Power efficiency has become the most critical design constraint for both high-performance and low-power processors. To minimize power consumption of such processors, voltage scaling has been widely used as one of the most powerful techniques. However, technology scaling increases process variability. This, in turn, increases the failure probability of on-chip memory elements at low voltages and limits voltage scaling of processors to a minimum operating voltage. In this project, synergistic solutions combining circuit and architecture techniques with information theory will be explored to provide reliable, ultra-low voltage on-chip caches for future processors. The novelty of the proposed approaches lies in designing cost- and performance-effective on-chip cache circuits and architectures by exploiting 1) the strong dependence between size and failure probability of SRAM cells; 2) the effectiveness of existing and new schemes using the redundancy in hardware and information for repairing defective cells; and 3) the characteristics of processor memory systems at low operating voltage and frequency points. <br\/><br\/>The proposed research will have a specific and significant impact on the computer architecture, circuit, and information theory communities since it requires analysis of interesting and representative workloads; realization of state-of-the-art architecture, circuit, information theory techniques; and invention of powerful and useful evaluation methodologies. Since most of the development and research work will be conducted by graduate students, both industry and academia will benefit from well-educated and trained employees, as well as direct technology transfer when students graduate and begin employment elsewhere. Finally, the success of this research will clearly have a major societal impact on economic, education and social benefits, and play an important role to assure the America's leading position.","title":"SHF: Small: Architecture-Circuit Codesign of Ultra-Low Voltage On-Chip Caches","awardID":"1016262","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["517586"],"PO":["366560"]},"167118":{"abstract":"Understanding how memory is encoded and maintained in our brain is paramount to understanding cognitive functions. Unlike in a computer, human memories are continuously consolidated, reconsolidated, and integrated within the context of what has already been learned. This process is thought to involve exchanges of information between the cortex and the hippocampus during sleep. The investigators will study the ability of small groups of cells in the rodent hippocampus and medial prefrontal cortex (mPFC) to become transiently co-active during sleep periods occurring many hours after learning has taken place. Rats will be engaged in learning tasks aimed at selectively activating one or both of these areas. It is expected that the activity recorded during post-task sleep will be correlated with the activity of the same cells during the task in a manner compatible with the nature of the task and the specifics of the learning. This type of reactivation is considered to be a basic mechanism for memory consolidation.<br\/><br\/>The investigators have developed new analytical tools based on fuzzy clustering and information geometry. Preliminary data show that short episodes of reactivation occur with different time courses in these two structures, as is often proposed on theoretical grounds. In this project, the investigators will study how this reactivation is coordinated across two connected brain areas (CA3-CA1, CA1-mPFC) on very long time scales, and how single neurons contribute to single reactivating episodes.<br\/><br\/>These studies will yield insights into the long-term temporal and spatial dynamics of reactivation in the adult rodent. They will also contribute to a better understanding of the neural basis of memory consolidation and reconsolidation in cortex and hippocampus, and the relationship between memory consolidation and sleep.","title":"CRCNS: Long Term Reactivations in Cortex and Hippocampus","awardID":"1010172","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[447609,"486270"],"PO":["564318"]},"168449":{"abstract":"This research is focused on general area of approximation and online algorithms. Many commonly studied optimization problems are intractable, and it is natural to approximate the optimum instead. While there has been much progress on such problems in the past two decades, there is much work to be done. This research investigates some long-standing open problems of interest, it also extends the techniques beyond what is currently known, and the research also investigates richer models and problems that attempt to capture the complexity and diversity of optimization problems that arise in practice. Along the problems considered in this research is that of formulating and solving optimization problems in the presence of partial information, which is often a requirement in practice. Another class of problems concerns the algorithmic theory of finite metric spaces, and this research further investigates the embeddability of graph metrics into normed spaces.<br\/><br\/>This research broadens the scope of understanding of approximation algorithms for optimization problems by developing models and problem formulations inspired by the aspects of practicality, and by developing algorithms and algorithmic techniques which will be relevant in broader contexts. Research progress is propagated into the curriculum via specialized courses presenting the theoretical advances in the context of their applications, as well as basic courses teaching the fundamental ideas and techniques behind these research advances.","title":"AF: Small: Future Directions in Approximation Algorithms Research","awardID":"1016799","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["550590"],"PO":["565251"]},"168229":{"abstract":"Non-volatile memories such as flash memory, Phase Change Memory and Magnetic Memory have the characteristics of low-cost, non-volatility, shock-resistivity and power-economy. Because non-volatile memory consumes less idle power than DRAM by orders of magnitude, achieves fast start-up time and can be twice as dense as DRAM, it is desirable for the computing system industry to use these memories not only as non-volatile storage, but also as main memory. In order to make it possible, however, we need answers to two challenges: The first one is the issue of lifetime and the second is the slowness of write activities.<br\/><br\/>The objective of this project is to develop solutions to these problems by reducing write activities on non-volatile memory through software optimization and hardware support, which lead to the practical adoption of non-volatile main memory in mobile and embedded systems.<br\/><br\/>This project, consisting of 3 groups of tasks, considers various types of platforms with single core or multiple cores. The type of cache on each platform can be either a hardware controlled cache or a software controlled one. Best cache consistency protocol is studied so that the required write activities to main memory are minimized. This project develops techniques including Write-Aware Scheduling, Recomputation, and Data Migration. These techniques will be combined to yield the best results on various platforms.<br\/><br\/>Broader impact: The engineers need to learn how to design the new-generation of embedded systems with non-volatile memory. This project will provide effective tools and solutions to the general engineers.","title":"CSR: Small: Towards Solutions of Maximizing Performance and Lifetime for Non-Volatile Main Memory Systems","awardID":"1015802","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["456490"],"PO":["565255"]},"171870":{"abstract":"The objective of the research is to develop tools for comprehensive design and optimization of air traffic flow management capabilities at multiple spatial and temporal resolutions: a national airspace-wide scale and one-day time horizon (strategic time-frame); and at a regional scale (of one or a few Centers) and a two-hour time horizon (tactical time-frame). The approach is to develop a suite of tools for designing complex multi-scale dynamical networks, and in turn to use these tools to comprehensively address the strategic-to-tactical traffic flow management problem. <br\/><br\/>The two directions in tool development include 1) the meshed modeling\/design of flow- and queueing-networks under network topology variation for cyber- and physical- resource allocation, and 2) large-scale network simulation and numerical analysis. This research will yield aggregate modeling, management design, and validation tools for multi-scale dynamical infrastructure networks, and comprehensive solutions for national-wide strategic-to-tactical traffic flow management using these tools. <br\/><br\/>The broader impact of the research lies in the significant improvement in cost and equity that may be achieved by the National Airspace System customers, and in the introduction of systematic tools for infrastructure-network design that will have impact not only in transportation but in fields such as electric power network control and health-infrastructure design. The development of an Infrastructure Network Ideas Cluster will enhance inter-disciplinary collaboration on the project topics and discussion of their potential societal impact. Activities of the cluster include cross-university undergraduate research training, seminars on technological and societal-impact aspects of the project, and new course development.","title":"CPS: Small: Collaborative Research: Dynamical-Network Evaluation and Design Tools for Strategic-to-Tactical Air Traffic Flow Management","awardID":"1035386","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559671"],"PO":["565274"]},"174950":{"abstract":"This project explores a novel principled framework for learning generic models of collective activities. Examples of collective activities are: people talking; a group of zebras escaping from a lion. Such models are used, in turn, for detecting, classifying, and segmenting activities as well as indentifying activities that differ from the collective behavior from videos sequences. Research developed in this project is distinctly different from previous research on action classification wherein activities are analyzed by considering individuals in isolation. Furthermore, unlike many current contributions, the aim is to work under unrestrictive conditions such as dynamic cluttered background, moving, monocular and un-calibrated cameras.<br\/><br\/>Key intellectual contributions of this project are: i) a learning scheme based on Random Forest that is able to adaptively characterize the coherent behavior of individuals, thus enabling discriminative classification of collective activities. This learning scheme is also relevant to other visual recognition tasks using context (e.g., scene and object recognition); ii) a methodology based on Relational Dependency Networks for segmenting different collective activities and discovering anomalous ones. <br\/><br\/>This project can provides critical building blocks toward addressing high level visual problems such as modeling the interaction between humans\/animals and objects, constructing an ontology of human\/animal activities, modeling complex human\/animal behaviors. This research has a potential to play a transformative role in strategic areas such as robotics and navigation. It also provides a crucial tool for analyzing and studying typical spatial-temporal collective behaviors in biology (insects, animals) or biomedicine (cells).","title":"EAGER: Modeling and Recognizing Collective Activities","awardID":"1052762","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["507875"],"PO":["564316"]},"171463":{"abstract":"The Web10Gig Project enables ordinary users, from the broadest range of fields and technical abilities, to effectively use the network to its full capacity. The research associated with the Web10Gig project builds upon the very successful Web100 project, whose prototype software is still heavily used six years beyond the end of the project funding. Under Web10Gig, the investigators produce a produce a production quality implementation of standard TCP instrumentation, based on the existing Web100 prototype, and groom it for inclusion in the Linux main line. It eliminates barriers to development associated with the original Web100 software suite, addresses a number of weaknesses in the Web100 prototype implementation and migrates the non-kernel code to a public open source code development site where anyone can contribute future additions and improvements.<br\/><br\/><br\/>As the Web10 Gig code propagates out to all Linux users it enables network measurement and diagnosis underneath all types of Internet applications. Like the autotuning software developed before it, it will be replicated in other operating systems, such that everybody, Linux user or not will reap to the benefits of having standard TCP instrumentation. Once incorporated into the Linux main line, the TCP instrumentation passes beyond the control of the Web10Gig investigators where maintained by the commercial world through production implementations and the researchers and developers actually using the code.","title":"Collaborative Research: SDCI Net Improvement: Web10Gig - Taking TCP instrumentation to the Next Level","awardID":"1032813","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7683","name":"SOFTWARE DEVELOPEMENT FOR CI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7369","name":"INTERNATIONAL RES NET CONNECT"}}],"PIcoPI":["560044",459054],"PO":["564246"]},"174730":{"abstract":"Facial expression is central to human experience. Its efficient and valid measurement is a challenge that automated facial image analysis seeks to address. Currently, few publically available, annotated databases exist. Those that do are limited to 2D static images or video of posed facial behavior. Further development is stymied by lack of adequate training data. Because posed and un-posed (aka ?spontaneous?) facial expressions differ along several dimensions including complexity, well annotated video of un-posed facial behavior is needed. Moreover, because the face is a three-dimensional deformable object, 2D video is insufficient. A 3D video archive is needed. <br\/><br\/>This project develops a 3D video corpus of spontaneous facial and vocal expression in a diverse group of young adults. Well-validated emotion inductions elicit expressions of emotion and paralinguistic communication. Sequence-level ground truth is obtained via participant self-report. Frame-level ground-truth is obtained via facial action unit coding using the Facial Action Coding System. The project promotes the exploration of 3D spatiotemporal features in subtle facial expression, better understanding of the relation between pose and motion dynamics in facial action units, and deeper understanding of naturally occurring facial action. <br\/><br\/>The project promotes research on next-generation affective computing with applications in security, law-enforcement, biomedicine, behavior science, entertainment and education. The multimodal 3D video database and its metadata are for the research community for new algorithm development, assessment, comparison, and evaluation.","title":"EAGER: Spontaneous 4D-Facial Expression Corpus for Automated Facial Image Analysis","awardID":"1051169","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["511335"],"PO":["564316"]},"175830":{"abstract":"The pervasiveness and mobility of network-enabled devices has changed the way people interact with applications and it has also changed the way we interact with each other. Mobile devices and applications have the potential to provide users with a multitude of context-specific resources, collect a wealth of information about users and their environments, and enable users to become information sources. These systems have great potential to play an increased role in socially relevant domains, but a deeper understanding of the interactions between users, environments, applications and networks, is necessary to realize the potential to address large-scale problems. As we move forward it is critical to consider the entire system including the users. <br\/>The goal of this research is to advance the understanding of network-based socio-technical systems by creating, modeling and analyzing a specific system based at the Chicago Zoological Society?s Brookfield Zoo. The Zoo can be viewed as a rich social system including staff, animals and a diverse group of over two million visitors per year. This project creates a socio-technical system to study by introducing technology with the purpose of enticing visitors to become citizen scientists by observing and reporting animal behavior, and allowing anyone to interact with the animal observation data collected by researchers. Social networking applications will be used to share animal observations and to explicitly make the animals part of the online social network. <br\/>The Intellectual Merit of this project involves the interdisciplinary study of networks as an enabling technology and as a model for understanding the relationships between stakeholders at the Zoo. By creating a unified socio-technical framework to consider and model the relationships between the stakeholders and technology, one can explore many research issues. The research will aid in gaining a deeper understanding of the factors that influence information transfer across social networks. It will allow consideration of the types of information that are likely to stimulate network activity and facilitate a cognitive system that adapts to environment to optimize user outcomes. We will be able to ascertain how information from various sources (e.g. scientists, guests, educators) influences activity of the network and transmission of specific messages through the network. This work will also provide a demonstration of how individuals with fundamentally different roles in the network (animals, application designers, and application users) influence network outcomes. <br\/>The Broader Impact of this project includes the software application introduced at the zoo, the research outcomes and the students exposed to the project. People of varied socio-economic backgrounds as well as many school groups and other organizations visit Brookfield Zoo. The National Research Council (NRC 2009) concludes that informal learning environments (e.g. Zoos) can have a significant impact on science learning outcomes for underrepresented groups. The work proposed here will be fundamental in determining a new role for technology in this learning. More immediately, it can also encourage a diverse audience of zoo visitors to pursue interests in the zoo animals and perhaps become a citizen scientist, reporting observations and investigating the data collected. Increased understanding of the connections between design and engineering of technology and social outcomes can empower us to best utilize technology to solve important social problems. This work will serve as a model for optimizing resource distribution when there is the potential to utilize comprehensive integrated information (social and technical) and the goal is to increase message transfer and understanding. Additionally, a diverse group of students will be involved and trained through this project. The PIs have a track record of working with underrepresented groups and will use this project as a platform to involve even more women and minorities.","title":"Collaborative Research: EAGER: Zoo-based Network Science Experimentation and Modeling","awardID":"1057879","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560175",471258],"PO":["565090"]},"173311":{"abstract":"Abstract<br\/><br\/>Careers in experimental science allow some researchers to push these frontiers of human knowledge to remote phenomena, from the formation of structure at cosmological scales to the self-assembly of protein enzymes. Non-experts have few channels to deeply experience these revelations due to several barriers: the time required to master technical details, the spatial distance to experts and educators, and the financial expense of careful experimentation. This research is creating a system that removes these barriers to scientific exploration for non-experts, in a frontier field that has attracted wide scientific and public interest: the engineering of nanoscale molecules into complex shapes. <br\/><br\/>An internet-scale gaming infrastructure is being created that will enable hundreds of thousands of game players to jointly explore the conformational space of ribonucleic acid (RNA) designs. As players explore a simulated RNA design space, their efforts produce a prioritized list of candidate designs which are synthesized immediately in the PI?s biochemistry lab. Experimental results then feed back into the game?s incentive structure. The players? collective efforts thus move beyond simulation into real biochemical experimentation. Also, it is currently unknown how to maximally exploit the ?network effect? of cooperation in multiplayer search games. Successful designs must both reward individual exploration and incentivize knowledge sharing. To unite these goals, the PIs are experimenting with several advances in collaborative scoring. Thus, within the new field of nano-engineering, the system will enhance the toolkit of RNA sequences that self-assemble into complex three-dimensional shapes from the ?bottom-up?: knots, polyhedra, and additional novel shapes never before seen with RNA. The project is producing advances in the nascent field of socially intelligent computing.","title":"EAGER: Collaborative Research: G&V: Evolving Social Computation in an RNA World","awardID":"1043650","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["491767"],"PO":["532791"]},"173553":{"abstract":"Abstract<br\/><br\/>The simulation of realistic physical phenomena, such as fluid interactions and deformable bodies, has become an indispensable part of both computational physics and computer animation. Such simulations produce stunning visual effects for the entertainment industry but also lead to new discoveries in diverse fields, such as astrophysics, energy production, or understanding the global climate. However, prior to running these simulations on a computer, the mathematical representation of the domain must be discretized in order to minimize computational errors (i.e., to obtain accurate physical results). The increased resolution of modern simulations is making this an increasingly important issue, especially for simulations requiring periodic remeshing or necessitating a fully automated approach.<br\/><br\/>Current practice in the coupling of discretization and computation has significant weaknesses. The computational tools often demand specific element shapes, e.g. hexahedra, over-constraining the discretization. On the other hand, meshing quality is generally measured by geometric quantities that provide only a limited connection to overall simulation performance. This research is demonstrating a new approach. Theoretical mathematics is used to develop, for the first time, a discretization scheme that is explicitly dependent on the structure of scalar fields generated by the simulation. The key insight is that a topological structure, the Morse-Smale (MS) complex, acts as a natural quadrilateral decomposition of a domain based on a given scalar field, called a background function. The background function behaves as a mechanism for encoding key information from a simulation. The MS complex then acts as a coarse mesh that coincides geometrically with the input domain while aligning itself with simulation properties. Finally, through optimization and subdivision, fine-grained meshes are generated that adapt locally to the resolution needed. This produces a discretization that more accurately follows the target simulations using fewer elements.","title":"EAGER (G&V): Exploring Morse Theoretic Tools for Automatic Mesh Generation and Simulation on Surfaces","awardID":"1045032","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["548348","548347"],"PO":["532791"]},"161464":{"abstract":"he goal of this CAREER project is to develop novel mechanisms that use<br\/>transactions to improve software assurance. This project is developing<br\/>Transactional Memory Introspection---or TMI, which is an approach to <br\/>building software security mechanisms by leveraging recent advances in <br\/>hardware and software transactional memory. Security mechanisms based <br\/>on TMI build upon the same machinery that transactional memory systems <br\/>use to ensure performance and functionality. TMI therefore promises to <br\/>make security mechanisms efficient and easy to integrate with software.<br\/><br\/>TMI-based security mechanisms being researched in this project include:<br\/>(1) TxAuth: a reference monitor architecture to better ensure complete<br\/>mediation of security-sensitive operations and allow easier integration <br\/>with legacy systems;<br\/>(2) TxInt: a data structure integrity monitor to protect extensible <br\/>software systems, such as operating systems and browsers, from untrusted <br\/>extensions; and<br\/>(3) TMWatch: a data watchpoint framework that equips malware analysis <br\/>tools and debuggers with new capabilities to reverse-engineer malware <br\/>behavior.<br\/><br\/>More broadly, this project seeks to demonstrate that concurrency control<br\/>machinery implemented in transactional memory systems can also be used to <br\/>improve software assurance. These additional benefits may lead to more <br\/>research on transactions and their ultimate adoption by hardware and <br\/>software vendors. The results from this project are being disseminated <br\/>via the development of new course material that will expose students and <br\/>software vendors to the dos and don'ts of secure programming. Suitable <br\/>course material developed in this project is also being included in <br\/>courses targeted towards K-12 and undergraduate students to attract<br\/>them to computer science programs.","title":"CAREER: Improving Software Assurance Using Transactions","awardID":"0952128","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["486426"],"PO":["565264"]},"175753":{"abstract":"Workshop on Usable Verification<br\/><br\/>Formal verification technology has made significant advances in the last two decades. Techniques like model checking and theorem proving are now used in both the hardware and software industries. Current research is focused on increasing the scale and expressiveness of this technology. The biggest challenge facing this technology is in making it more accessible to a wider audience. This requires powerful automation, more integration, better user interfaces, and deeper embedding into design tools. To address these challenges, a two-day workshop on Usable Verification will be held at Microsoft Research in Redmond during November 15 and 16, 2010. This will be the first of a series of workshops aimed at building a community that is focused on usability issues in verification technology.","title":"CISE\/SHF:Workshop on Usable Verification","awardID":"1057567","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["555363"],"PO":["565264"]},"164523":{"abstract":"As information technologies become unremarkable elements of everyday life, opportunities arise to employ them to help introduce and reinforce lifestyle and behavioral changes in which people are invested, in areas such as health and wellness, or environmental sustainability. Most previous research in this area has taken the individual user as its primary focus, asking, first, how interactive technology might make people more aware of their own behavioral patterns, and, second, how interactive technology might provide people with incentives and rewards for changing those behaviors. The challenge - especially for topics such as environmental sustainability - is how to scale up from individual actions to the sorts of large-scale, societal change that makes for long-term impact.<br\/><br\/>This research examines an alternative approach to technologically-based behavior change with a focus on questions of scale. We draw on two main sources. The first comprises sociological investigations of social movements and the processes through which they are formed. The second is the contemporary interest in social networking and social media. Our goal is to be able to link people together into larger socio-computational systems that align with and motivate civic engagement and social responsibility. We will develop, deploy, and evaluate online tools on both traditional and mobile platforms that foster the creation of social movements through the alignment of individual actions to collectivities. These systems will be built around our fundamental principle that social groups are a more intelligible and more compelling way to understand environmental actions than arbitrary scales or abstract scientific measures such as CO2 tonnage.<br\/><br\/>This research will provide new understandings of the processes of social movement formation, with an emphasis on the role of online tools and the potential for social networking technologies. We will operationalize these understandings through a focus on design practice. Our research provides insight into the potential for information technologies to help people connect with local communities, increase civic engagement, and achieve personally desirable behavior change.","title":"SoCS: Scaling Social Networks to Social Movements","awardID":"0968608","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["464219","550622"],"PO":["564456"]},"174324":{"abstract":"While information technologies (IT) promise to liberate us of hard labor and save us time by offering efficiency and productivity, improving our quality of life, at the same time they raise the standards of what we should accomplish and increase the amount of information we need to deal with and foster a sense of increased pace and accessibility. As such, the value of busyness may be implicitly embedded in IT design. This award funds a research workshop to create a research agenda on the design of future IT to account for the culture of busyness. The workshop participants will address two question: (1) What are the roles of IT in coping with and\/or promoting a culture of busyness?, and (2) To what extent is it possible to intervene in the culture of busyness by altering the design of IT or its use practices? Through these initial questions the participants will identify theoretical and empirical gaps in understanding sociotechnical aspects of busyness at the individual, organizational, and societal level and will identify both technical and social opportunities and challenges in the design and application of IT interventions for this purpose. <br\/><br\/>Workshop participants will be recruited and selected in three ways: (1) specific scholars who have done research related to this topic will be individually invited; (2) a general solicitation to submit position papers will be sent out through relevant mailing lists; and (3) local graduate students with interest in this topic will be invited to take part. <br\/><br\/>The outcome of this workshop will be to develop a research agenda for better understanding and addressing the value of busyness embedded in IT. Specifically, we plan to submit an article to a general audience journal to describe this research agenda. Further, as we identify specific research being done, we plan to propose a special issue at a major journal in order to group together results about this topic.","title":"Workshop: Rethinking the Value of Busyness in IT","awardID":"1049359","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["517929"],"PO":["564456"]},"174456":{"abstract":"A fundamental tension exists between transparency and privacy in electronic voting. Electoral transparency requires access to primary voter records, so observers can be sure that the election was run appropriately. Ballot privacy---keeping ballot contents separate from information that can identify the voter---is required to prevent coercion and vote-selling. If we discard either transparency or privacy, voting becomes much simpler: without transparency, ballots can be perfectly private; with no privacy requirement, elections can be perfectly transparent. The project aims to reconcile transparency with ballot privacy in electronic voting systems.<br\/><br\/>The project has several goals. The project is identifying legal and technical barriers to increased privacy, both in terms of fundamental limits and limits imposed by technology. The project is also identifying vulnerabilities enabled by the movement for increased electoral transparency, for example the practical risks of identifying ballots using voter marks and paper-fingerprinting. This enables research to design privacy-preserving methods for publishing artifacts of transparency, such as scanned ballot images. The project is examining the loss of ballot privacy intrinsic to various models of post-election audits, where the trend has been toward greater disclosure of records, which may implicate issues of ballot privacy. The project is creating process models of post-election audits to identify and compare ballot privacy leakage and developing methods to better determine how many ballots are truly in an audit batch, a crucial but overlooked element of the mathematics in post-election audits.","title":"Reconciling Post-Election Auditing with the Secret Ballot","awardID":"1049730","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[467986],"PO":["497499"]},"174236":{"abstract":"This complex proposal is a pioneering effort aimed at exploring novel methods to counter boredom associated with repetitive tasks. The approach, based on a pilot study, is to design appropriate interactive options in the form of computer games and other activities requiring imaginative thinking. The premise taken is that multiplexing an interesting task in a background monitoring task can lead to improved engagement and, indirectly, improved performance. The concept has been successfully tested in a pilot study and it is proposed to build new application designs suitable for effective dual tasking.","title":"EAGER: Improving Human Performance in Routine Activities Using Interactive Role Playing Games","awardID":"1049004","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["532471"],"PO":["564456"]},"175688":{"abstract":"This CISE EAGER project supports the development of a resource model that allows educators to effectively find and leverage existing curricular materials, particularly computer science and computational thinking curricular materials. While many previous efforts have attempted to build repositories of course materials, these efforts have been hampered by factors such as a lack of efficient search facilities, a dearth of available\/stored materials, an inability to find quality materials, or the user perception of commercial interest in the repository. The overall goal is to create a framework to address four critical issues that have hampered the utility of such repositories thus far: a better search interface, easily usable by computing teachers (especially K-12 teachers), a critical mass of materials, a rating mechanism by teachers, and a system that will appeal to teachers. This project seeks to address the shortcomings of existing repositories by providing the appropriate affordances for search and user feedback\/ratings. Moreover, by proactively seeking an initial set of content, this project can help to break the lack-of-content\/ lack-of-usage cycle that plagues most existing systems. This Eager project proposes to develop a prototype along these lines with enough content to be a proof-of-concept for such a system. Based on initial results and usage profiles, this project can lay a foundation for how to best proceed in making such a system more broadly used by the computing educational community.<br\/><br\/>The intellectual merits of this project lies in the strong team and vision for improvement in the field of resources for computing educators. This project should provide a model for development of a digital resource system that is valued and used by educators, particularly K-12 educators. This represents a significant contribution as an enhancement over the current situation in computer science where the existing digital libraries are not widely used. By providing an alternative approach towards searching for high quality computing curricular materials, this project plans to allow high quality computing curricular materials to be accessed and used by a much wider segment of computing teachers. The team is strong, including computer science faculty, K-12 computing educators, educational specialists, and researchers with academic and industry experience with the development of searchable resources.<br\/><br\/>The broader impacts of this project lie in the potential for long-term benefit to the computing community and to computing educators. If this project is successful, the computing disciplines will have a portal that can be comparable in usability to the successful portals in other STEM disciplines. It will provide an effective dissemination vehicle for high quality curricular materials, developed as through funded and non-funded sources. This project has the potential to improve the teaching of a wide variety of computing topics and courses by becoming a single source computing teachers go to when needing to find high quality curricular materials.","title":"Addressing the Shortcomings of Digital Libraries of Educational Materials","awardID":"1057270","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[470900,"351237","562668"],"PO":["564181"]},"174599":{"abstract":"This project proposes a comprehensive load-balancing solution to minimize client response time and reduce system costs for services hosted in wide-area networks. The system, called Aster*x, uses the global state of server load and network congestion, and dynamically routes the requests over appropriate (server and path) pairs, calculated using the load-balancing algorithms developed by project staff. <br\/><br\/>The GENI network infrastructure will be used for extensive deployment, evaluation, and demonstration of Aster*x. Aster*x exploits OpenFlow?s logically centralized controller to obtain the global network state and route flows of various granularities. It will use the PlanetLab and ProtoGENI-based computation substrate to host the replicated web service and to generate client requests from multiple locations. The project will provide an opportunity for students across four universities to collaborate and build a relatively large experimental system on GENI.","title":"EAGER: Collaborative: Aster*x: Load-Balancing Web Traffic over Wide-Area Networks","awardID":"1050290","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560546"],"PO":["564993"]},"168802":{"abstract":"Recently, Gentry and others have established the feasibility of constructing fully homomorphic encryption schemes. Briefly, a fully homomorphic encryption (FHE) scheme is one that allows a third-party who has ciphertexts of several messages to construct---without knowing the decryption key---a new ciphertext that corresponds to an arbitrary efficiently computable function applied to the original messages. Fully homomorphic encryption has the potential to allow disparate organizations to compute basic functions on their pooled data-sets without revealing such data to each other. It is thus an ultimate solution for implementing ``need-to-know'' privacy. <br\/><br\/>Until Gentry's discovery, few researchers believed that FHE could be constructed. As a result, the concept has not been well-studied despite its clear potential to solve important tasks in a privacy-preserving manner. In particular, the basic relationship between FHE and traditional public-key cryptography remains unclear. The goals of this research project are to formalize this relationship, to build notions of FHE that satisfy stronger security guarantees such as security even when the adversary has access to a restricted decryption oracle, and to potentially use these stronger security guarantees to apply FHE in secure and privacy preserving computation. <br\/><br\/>To ensure the broader impact of the research, this project includes mentoring of students at all levels from undergraduate to post-doctoral and outreach activities to traditionally under-represented students and K-12 students. Research from this project will be disseminated through presentations and publications in conferences, journals and on the Internet.","title":"TC: Small: Collaborative Research: Implications of Fully Homomorphic Encryption","awardID":"1018543","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486395"],"PO":["565239"]},"174005":{"abstract":"This award is part of the Software Infrastructure for Sustained Innovation. The Office of Cyberinfrastructure, the Division of Computer and Network Systems, and the Division of Materials Research contribute funds to this award. <br\/><br\/>Developing large computational codes such as those used to perform simulations in quantum mechanics to calculate properties of materials, or to predict the aerodynamics forces around airplanes, still typically require several human-years. However the pace of research and industrial product development demands much more rapid software tool development to make progress and to remain competitive. This award contributes to developing the capability to rapidly create high performance large scale codes. <br\/><br\/>The PIs will augment a computer programming language with a very high level language that is interactive in the sense that the developer will enter language commands and get instantaneous interpreted answers, instead of processing the whole code. This approach of creating an interactive extensible language framework will provide a way to help speed development of large scale computer software. Efforts will be specifically targeted at software for materials science applications. This will enable progress in large scale computational research that aims to predict properties of materials starting from a knowledge of the constituent atoms and the way they are arranged in the material. <br\/><br\/>This award contributes to the education of knowledgeable specialists capable of developing large and complex computational codes. The PIs will design new graduate level courses outside of the current curriculum to increase the number of students who receive training in effective development of software for materials research and scientific computing in general. <br\/><br\/>This award also supports the research team's efforts to broaden participation of underrepresented groups through the existing Alice in Wonderland Program, which aims to recruit members of underrepresented groups at the high school level, and to attract female high school students to science and engineering by involving them in research over the summer before they make decisions about colleges. They will also revive the Summer Undergraduate Interns program to recruit undergraduate students interested in high performance computing for summer internships.","title":"Collaborative: Extensible Languages for Sustainable Development of High Performance Software in Materials Science","awardID":"1047997","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1712","name":"DMR SHORT TERM SUPPORT"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[466762],"PO":["141355"]},"174126":{"abstract":"Digital photography and the Internet are enabling ordinary people to take and save photographs at negligible variable cost. As a result amateurs often accumulate large volumes of images. They are then confronted with the tedious chore of sorting through their massive collections to select the most aesthetically pleasing pictures. The onerous nature of this task is exacerbated by the sense of many people that articulating and quantifying aesthetic attributes is esoteric. Automated evaluation of photographs based on user-defined criteria is in a nascent stage, lacking the flexibility to provide a personalized experience tailored to the individual user. Current systems develop a set of classifiers based on an image dataset, but this approach impedes adaptation to user preferences and inhibits the flexibility needed to develop new heuristics for aesthetics. In this exploratory project the PI aims to raise the overall aesthetic quality of amateur photography by creating software to automatically sort and filter a collection of images using a set of analytically-constructed aesthetic principles, in a manner analogous to what is done by a professional photographer. The approach is based upon the concept of a hierarchal modular classifier that can be customized for different individuals, so that each user can have a classifier that characterizes his or her preferences. Since the classifier is a simple arrangement of modules, one can imagine that even a single user could design multiple classifiers that cater to his or her every preference; for example, the user could have a classifier to help select the best landscape photographs s\/he has taken, and another to select the best portraits. <br\/><br\/>Broader Impacts: Comparison of data taken from different demographics will enhance our understanding of how cultural, social, or other background factors influence individual preferences in aesthetics. The ability to tune image searches so as to return images that are more aesthetically pleasing according to specific criteria will have commercial implications (e.g., when companies endeavor to create designs, products, or services that are tailored to different audiences). The work has social networking applications as well, since the algorithms developed could enable people to find others with similar preferences. The PI's system will teach amateur photographers how to improve their picture-taking skills, by showing them specific possible modifications that could be applied to enhance their photographs. Project outcomes will lay the foundation for technology that can automatically post-process images so as to improve their aesthetic quality. Thus, this research ultimately will improve the overall quality of the images that are available on the Web.","title":"EAGER: Aesthetically Empowering Novice Photographers","awardID":"1048599","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["518667"],"PO":["565227"]},"174368":{"abstract":"This project provides partial travel fellowships to students enrolled in U.S. <br\/>universities in order to facilitate their attending the 2010 International <br\/>Semantic Web Conference (ISWC) held November 7-11, 2010 in Shanghai, China. ISWC <br\/>is a major international forum where visionary and state-of-the-art research on <br\/>all aspects of the Semantic Web is presented. Priority will be given to students<br\/> selected to participate in the doctoral consortium, followed by students who are <br\/>first author on a paper accepted at the conference, followed by students who have <br\/>other authorship on a conference or related workshop paper. The purpose of this <br\/>project is to allow students to share their research ideas, receive constructive <br\/>feedback, and develop connections that will enhance their research careers. The <br\/>project is expected to support between 10 and 15 students. <br\/><br\/>Further information can be found at the web page:<br\/>http:\/\/iswc2010.semanticweb.org\/travel-awards","title":"III: Travel Fellowships for Students from US Universities to Attend ISWC 2010","awardID":"1049469","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[467778],"PO":["560586"]},"184169":{"abstract":"Abstract<br\/><br\/>This research encompasses novel attempts in several research topics on flapping flight in insects and birds. The goal of this research is to a) quantitatively study the flight trajectory feasibility and stability observed in insects and birds; b) investigate the underlying principles that cause their flight stability and performance differences in order to develop a methodology and guideline for designing flapping wing micro-aerial vehicles; and c) design and fabricate flapping wing micro-aerial vehicles capable of stable and maneuverable flight with biomimetic sensors. Our previous study on the theory of nonlinear systems including harmonic balance and bifurcation methods will be utilized to conduct theoretical and mathematical modeling of flapping flight. We will verify our analysis using the free-flight measurements on the fruit fly and the experimental data from the current generation of fabricated Micromechanical Flying Insects (MFIs). Based on our analysis, we will develop guidelines to aid the design and fabrication of future MFIs and flapping wing micro-aerial vehicle in general, with the capability to ensure the flight feasibility and stability of the vehicle.<br\/><br\/>The theories developed from this research will provide new understanding of the inherent flight stability and maneuverability present in insects and birds, and hopefully will lead to developing a new theory describing the underlying principles of the different flight phenomena observed in nature.<br\/><br\/>The educational activities include incorporating research materials into graduate and undergraduate curricula, and the developed research and educational activities will be outreached to the K-12 students and teachers as well as underrepresented and women groups in Delaware through the University of Delaware's Design and Discovery summer camp for girls. Another broader impact of this program will be to create an Internet-based flapping flight gait simulator accessible to students and researchers to simulate and visualize realistic flight patterns of different insects and birds, given their morphological data.","title":"CAREER: Theory and Practices of Flapping Flight: From Biological to Robotic Insects","awardID":"1132240","effectiveDate":"2010-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["524924"],"PO":["543539"]},"176568":{"abstract":"Proposal #: 10-61489<br\/>PI(s): Papanikolopoulos, Nikolaos;Hondzo, Miki; Morellas, Vassilios; Anaraki, Siavash Pourmakamali; Voyles, Richard M.<br\/>Institution: University of Minnesota <br\/>Title: MRI RAPID: Collaborative Research: Swarms of Robotic Aquapods to Assess Impact of Oil Spills on Marshlands<br\/>Project Proposed:<br\/>The project, testing the adequateness of underwater robots to swiftly and repeatedly sample large areas of Golf Oil Spill, aims to determine the spatial heterogeneity of the impacts on the shoreline, revealing \"hot spots.\" These are areas of high oil concentration that constitute a challenge since hot-spots move due to shoreline morphology, wind patterns, and water circulation. To this end, small robots called \"Aquapods\" will be deployed. Aquapods are miniature robots with a high mobility-to-size ratio. As a form of locomotion, they are based on tumbling which allows them to locomote on the water, under the water, and on sandy and marshy shoreline. A recent version of the Aquapod (developed as part of the IUCRC on Safety, Security, and Rescue) can be completely submerged in water to operate on a lake or stream floor. Additionally, this robot is equipped with a buoyancy control unit that allows the robot to either sink or float in water, thus offering many unique applications in both environmental monitoring and surveillance. The work develops a more advanced system than the first generation radio controlled design, incorporating functionalities more appropriate to monitor oil spill effects.<br\/>Broader Impacts: <br\/>As the proposed research can drastically improve oil spill cleanup efforts, the potential broader impacts are large. The project exhibits the ability to assess the environmental impact on areas not easily accessible by humans. The PIs have a solid plan to involve middle-schoolers from underrepresented groups in the proposed project. Moreover, the developed instrument will be free for use to the interested groups of scientists. Planned are solid dissemination and education efforts both at the University of Minnesota and the University of Denver.","title":"MRI RAPID: Swarms of Robotic Aquapods to Assess Impact of Oil Spills on Marshlands","awardID":"1061489","effectiveDate":"2010-09-15","expirationDate":"2012-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["557449",473345,"543539","561114","523124"],"PO":["557609"]},"168714":{"abstract":"Query-Driven Visualization (QDV) is a knowledge discovery strategy that combines state-of-the-art methods from scientific data management with modern visualization approaches to support rapid data analysis. By restricting computational and cognitive workload in visualization and interpretation to records defined to be significant by a scientist, fast visualization responses can answer intuitive questions about the data. Thus, query-driven techniques are ideal tools for data exploration and hypothesis testing. However, uncertainty in data and query can strongly and negatively influence a visualization result and hence the insight obtained from it. This research project explores a novel framework that generalizes QDV and is aimed at addressing deficiencies in existing methods. <br\/><br\/>The approach to providing robust visualization techniques that incorporate the uncertain nature of the analysis process into the visualization result, thus enabling tools that will allow users to factor uncertainty into the conclusions drawn from data sets are based on modeling uncertainty at all levels of the query-driven process. The methods developed leverage multi-resolution data representations incorporating uncertainty information; and this results in improved efficiency and parallel computation in answering queries over very large, high-dimensional data sets. New visualization techniques are derived by taking advantage of the improved flexibility, generality and efficiency of the provided framework, to address specifically the needs of comparative visualization of an ensemble of data sets pertaining to a common science problem. <br\/><br\/>The resulting robust query-driven visualization techniques that incorporate the uncertain nature of the analysis in the knowledge discovery process will allow users to factor uncertainty into the conclusions drawn from complex, large-scale, high-dimensional data sets. In order to increase the impact of the research, results will be accessible via the project Web site (http:\/\/idav.ucdavis.edu\/~joy\/NSF-IIS-1018097.html), and incorporated into an open-source visualization package. Project provides research experience to students.","title":"III\/G&V: Small: Enhanced Query-Driven Techniques for Uncertainty and Comparative Visualization","awardID":"1018097","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[451576,451577],"PO":["563751"]},"175369":{"abstract":"Mobile phones and other similar portable systems are essentially embedded systems designed using analog\/mixed-signal system-on-chips. These systems consist of several heterogeneous components including digital circuits, analog\/mixed-signal circuits, power management systems, and software. The goal of International Symposium on Electronic System Design (ISED) is to bring experts from these fields together for the efficient design of such portable systems. The next issue that arises is how to train the next generation engineers to acquire the needed expertise. Thus, ISED has an integrated Workshop for Engineering Scholars (WES) and an Expo on Electronic Systems (EES). Overall, ISED creates a venue for researchers, educators, students, and industry personnel for close interaction for the advancement of research, education, and international collaboration in electronic system design. ISED is being held for the first time in Bhubaneswar, India, and this proposal seeks funding for supporting the travel and registration expenses of a few selected US students and keynote speakers to attend the conference in India. This should help in increasing the Indo-US collaboration in the area of electronic design.","title":"International Symposium on Electronic System Design (ISED)","awardID":"1054975","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[470229],"PO":["559883"]},"168604":{"abstract":"The anticipated opening up of white space by the FCC for unlicensed<br\/>use has created exciting new opportunities. It also presents unique<br\/>challenges: (i) it requires accurate wide-band spectrum sensing<br\/>technique to avoid interfering with primary users, and (ii) it needs<br\/>dynamic spectrum sharing in heterogeneous setting both within networks<br\/>and across networks.<br\/><br\/>This project develops a holistic approach for spectrum sensing to<br\/>address spatio-temporal variability and spectrum sharing among<br\/>multiple secondary users and networks in white space. In particular,<br\/>it first develops efficient and accurate spectrum sensing techniques<br\/>that simultaneously exploit time- and frequency-domain features,<br\/>sparsity in active transmitters, and temporal and spatial locality in<br\/>the transmissions. Second, it studies the cost and benefits of sharing<br\/>network state in a heterogeneous network where different nodes have<br\/>different information views. Third, it studies spectrum sharing across<br\/>networks (e.g., CSMA\/MaxWeight, TDMA\/CSMA co-located networks). It<br\/>develops algorithms and studies performance and fairness both with<br\/>implicit sharing (i.e., no state-exchange) and with explicit sharing<br\/>of information across networks. Fourth, it proposes a ground-up design<br\/>for white space that leverages random CDMA-like codes for spectrum<br\/>sharing with an OFDM physical layer that leads to a new efficient<br\/>architecture for sharing across users and networks in white space.<br\/><br\/>The algorithms, techniques, and software resulting from this research<br\/>will help enable effective communication in white space, create new<br\/>wireless network technologies, and deepen our understanding of<br\/>wireless networks. The research results will be incorporated into<br\/>networking courses and widely disseminated through conference\/journal<br\/>publications and software distribution.","title":"NeTS: Small: From Sensing To Sharing Across Networks In White Space","awardID":"1017549","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560222","560223"],"PO":["557315"]},"165458":{"abstract":"This project will explore approaches to artificial intelligence that can support creative digital filmmaking, an extremely rich new form of expression and communication. The most accessible variant of digital filmmaking is \"machinima\" - cinematic movies created by manipulating avatars in 3D computer game worlds. Due to the allure of cheap, quick, and easy movie making, and the accessibility of high-fidelity graphics through video games technologies, machinima has grown into a mainstream form of creative expression and sharing. However, machinima has a high threshold of entry. This is due only partly to technical tools, which are cheap and easily acquired; digital filmmaking also has a high threshold of skill requirements. In general, creativity is collaborative, with creators often seeking feedback and critique from others. Intelligent systems can also participate in the feedback loop of creative practice by suggesting, autonomously creating, and critiquing digital media.<br\/><br\/>The goal of this research is to reduce the technological and skill barriers to complex, but rich forms of digital expression such as filmmaking, thereby increasing the creative productivity of amateur creators. Its approach is to develop digital media production tools that are instilled with computational models of creative practice and intuitive interfaces informed by empirical studies. The anticipated result is a greater understanding of creative processes involving feedback and critique, models of cognitive and emotive processes in human recipients of creative artifacts, and understanding about the tradeoffs of interface modalities involving intelligent participatory systems. The project is organized around two major, interrelated thrusts: (1) develop cognitive and computational models of feedback and critique as a means toward intelligent systems that participate in creative endeavors; (2) study how the creative abilities of amateur and expert digital filmmakers are affected by production interfaces along dimensions of (a) degree of constraint in cinematic control and (b) modes of intelligent participatory support.<br\/><br\/>It is anticipated that the resultant models and implementations will serve as next-generation creativity support tools to be adopted by the amateur digital filmmaking and machinima communities. By achieving its research goals, this project will demonstrate a technique for lowing the threshold of entry to a form of digital media creation. Lowering the threshold of machinima production, in particular, will open the practice to populations of users historically underrepresented in computing such as women, who are attracted to storytelling but often discouraged by highly technical \"hacker\" skills. As an expressive form, digital filmmaking is a powerful medium for communication, can be used as a draw to computing, and can be integrated into a wide repertoire of activities including entertainment and education. Resultant models and implementations may also impact the growing practice of previsualization in the movie and television industries. The approach will result in a model for incorporating intelligent creative assistance into other forms of expressive digital media.","title":"MAJOR: Assistive Artificial Intelligence to Support Creative Filmmaking in Computer Animation","awardID":"1002748","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["550869",443231],"PO":["564456"]},"175017":{"abstract":"Computer vision started with the goal of building machines that can see like humans. Nowadays, computer vision has expended to numerous applications such as image database search in the world wide web, computational photography, reconstruction of three-dimensional scenes, surveillance, assistive systems, vision for graphics and nanotechnology, etc. More domains and applications keep arising as computer vision technology develops. <br\/><br\/> The goal of the workshop in Frontiers in Computer Vision is to bring together national and international experts, from academia and industry, to identify the future impact of computer vision on the economic, social, educational and security needs of the nation and outline the scientific and technological challenges to address the issues: how can computer vision build on the success and enthusiasm of its growing participants? how can the academic community make connections to industry? how to better foster scholarship and improve communication both within computer vision itself and to related disciplines and application areas? How can computer vision best interact with related fields? how can the importance and promise of computer vision be communicated to the general public? <br\/><br\/>The deliverables of the event include, among others, videos of the presentations available on the Frontiers in Computer Vision website, together with a roadmap to outline the scientific and technological challenges to address.","title":"WORKSHOP: Froniers in Computer Vision","awardID":"1053105","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["509344"],"PO":["564316"]},"168736":{"abstract":"Through-Silicon-Via (TSV) provides the possibility of arranging heterogeneous components across multiple dies at a fine level of granularity in 3D ICs. This can result in significant decrease in the overall wire length, delay, power, and form factor. Primarily due to their large size compared with other layout objects, however, TSVs cause significant non-uniform density distribution in various layers. This density issue is expected to cause trouble during chemical mechanical polishing (CMP) and require TSV-aware solutions. In addition, the CTE (coefficient of thermal expansion) mismatch between TSV copper and silicon causes significant thermal mechanical stress to the devices nearby during TSV manufacturing and circuit operation. This in turn affects the timing and power characteristics of the devices. The mechanical reliability of the substrate and devices are also affected by TSVs. However, little is known on what design tool and methodology changes are required to improve the manufacturability of TSV-based 3D ICs. This project would investigate three key DFM\/DFR areas specific to 3D IC integration, namely, TSV-induced stress effect and its impact to the overall circuit timing and power, TSV impact to CMP and lithography, and TSV-induced reliability. Successful completion of the project would help us to gain in-depth understanding of manufacturability and reliability issues with 3D ICs and TSV technology and develop effective physical design solutions to overcome these issues. The proposal calls for a very strong collaboration between the researchers from the manufacturability and reliability modeling, simulation, and validation area and the researchers from circuit and physical design area for 3D ICs.","title":"SHF: Small: Collaborative Research: Design for Manufacturability of 3D ICs with Through Silicon Vias","awardID":"1018216","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["422053"],"PO":["562984"]},"168857":{"abstract":"Today, inexpensive computer systems based on commodity, off-the-shelf components can support hundreds of gigabytes of memory. Traditionally, the demand for large-memory systems came predominantly from the operators of databases for applications such as high-volume transaction processing. Today, however, a much wider variety of applications drive the demand for such large-memory systems, ranging from server consolidation using virtualization to infrastructure for Web 2.0 applications. At a scale of 100GB or more, for many of these applications, virtual memory access becomes a bottleneck. Specifically, the overhead of address translation increases dramatically. Large pages can mitigate this problem by significantly increasing translation look-aside buffer (TLB) coverage. However, all too often these applications exhibit poor temporal and\/or spatial locality of reference. Thus, even with large pages, the TLB hit rate is very low.<br\/><br\/>This research will develop novel architectural mechanisms and operating systems support to mitigate the cost of address translation. Effective approaches to this problem include caching internal levels of the page table in dedicated hardware, providing hardware support to exploit physically contiguous memory reservations within the operating system, and re-examining page table organizations for large address spaces. This research will explore all of these techniques and carefully consider the interactions between memory allocation and management in the operating system and address translation overhead in the hardware.<br\/><br\/>This research will transform the way in which address translation is performed on future systems, enabling the effective use of hundreds of gigabytes of memory. Currently, large memory machines suffer from address translation bottlenecks, limiting overall performance. As these machines consume significant amounts of power, this leads to poor power efficiency, wasting both energy and money. More efficient address translation will lead to significant improvements, especially in datacenters with numerous large memory machines.","title":"CSR: Small: Breaking the Address Translation Barrier in Large Memory Systems","awardID":"1018840","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["551076","551027"],"PO":["565255"]},"168505":{"abstract":"Software errors frequently arise because a component of the program does<br\/>not correctly follow a well-defined protocol for accessing some stateful<br\/>resource. Common examples include programs that misuse resource handles<br\/>provided by the operating system, incorrectly deallocate the same memory<br\/>or other resource multiple times, or fail to properly sequence calls to<br\/>a complex program module. Such protocol violations lead to software<br\/>crashes or unintended behavior, potentially with disastrous<br\/>consequences.<br\/><br\/>The project objective is to develop programming language technology to<br\/>allows software developers to conveniently describe protocols over<br\/>stateful resources. This technology will uncover such bugs at design<br\/>time by statically checking whether the program is appropriately<br\/>following the desired protocols, thereby ruling out the wide class of<br\/>software flaws. The new language mechanisms will be general purpose,<br\/>practical, and suitable for use in a wide variety of applications<br\/>ranging from memory management to traditional protocol implementation.<br\/>The researchers will create a compiler infrastructure prototype and<br\/>establish the correctness of the approach by a machine-checked proof of<br\/>type soundness. The primary broader impact of the project is the<br\/>development of technology to help eliminate such programming errors<br\/>early in the software-design life cycle to decrease the cost of building<br\/>correct, reliable software.","title":"SHF: SMALL: Practical Linear Types for Safe Protocols","awardID":"1017027","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["556654"],"PO":["564588"]},"168868":{"abstract":"This project tackles the development of new tools for the semantic <br\/>analysis of temporal signals, in particular (but not restricted to) <br\/>video sequences. While most of the emphasis in video analysis so far has <br\/>been at the low-level, the investigators plan to explore the use of <br\/>Causal Analysis to perform inference and decisions to analyze video <br\/>signals. The challenge in this project is to bridge the gap between <br\/>basic descriptor at the signal level and Causal Calculus, that acts on <br\/>semantically meaningful representations. In particular, long-range <br\/>prediction, not just short-range continuous extrapolation, requires the <br\/>development of new tools that allow \"interventions\" into the model. How <br\/>would the state \"X\" evolve if event \"Y\" were to occur? To attain the <br\/>goals set forth in the proposal, the investigators must tackle <br\/>fundamental problems in the analysis of time series, both at the <br\/>low\/mid-level (defining a proper notion of ``distance'' between time <br\/>series that respects their intrinsic dynamics), at the mid-level <br\/>(defining clustering schemes for action segments), and at the high-level <br\/>(develop action semantics in an abductive framework). <br\/><br\/>During this pilot one-year project, the investigators plan to explore the <br\/>feasibility of using causal analysis for performing long-range temporal <br\/>prediction of events and actions from visual data. Sample applications <br\/>that are impacted in case of success are broad ranging from <br\/>surveillance to environmental monitoring to driver assistance in <br\/>transportation, with significant societal impact in reducing traffic <br\/>accidents.","title":"RI: Small: Modeling and Parsing Time Series for Causal Analysis with Application to Action Interpretation in Video of Natural and Man-made Environments","awardID":"1018922","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["541989","461021"],"PO":["564316"]},"178548":{"abstract":"The availability and robustness of the I\/O system is crucial to large-scale applications that generate and analyze terabytes of data. Storage systems are vulnerable to numerous hardware failures (I\/O and metadata server crashes) and contribute to as much as 25% of all system failures. Actually, highly available data storage for high end computing is becoming increasingly more critical as high-end computing systems scale up in size. To achieve high availability storage systems, a challenging issue is to characterize the availability metric in addition to performance of these systems.<br\/><br\/>This research investigates high-availability data and I\/O services and benchmarking. The investigators take an organized approach to developing a benchmarking framework to measure the storage performance in consideration of availability under various faulty conditions. The research involves four tasks: 1) develop faults\/errors model and design fault injection schemes for storage systems; 2) develop an innovative benchmarking framework for high availability distributed storage systems under different faulty conditions; 3) implement an Availability and Performance Evaluation Toolset (APET) to integrate the fault injection and stress testing libraries and capture raw performance of storage systems at block level under various faults; 4) validate the benchmarking framework using APET for block-level storage systems.<br\/><br\/>This research has direct contributions to understanding highly available data and I\/O services for HEC systems, establishing a general benchmarking framework for characterizing storage systems under faulty conditions, and thus benefiting the society by guiding develop high-availability oriented distributed storage systems which are crucial to many applications.","title":"CSR---PDOS: A Benchmarking Framework for High-Availability Distributed Storage Systems","awardID":"1102629","effectiveDate":"2010-09-09","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550809"],"PO":["535244"]},"168406":{"abstract":"If we pull on a string and something immediately moves, we infer a causal relation between our action and the result. Toss a stick into a bush and if something runs out we assume we caused that too. The acts of grabbing, hitting, pressing or squeezing all result in direct, contingent, visual changes in the state of the world. It is through such temporal contingencies that infants gain a basic understanding of the state of the world, and cognitive scientists argue that such experiences form the conceptual substrate on which even very abstract concepts are built. Causal linkages are ubiquitous and fundamental to our understanding of many diverse phenomena, including how people influence one another, how ecosystems function, and how physical systems function. Understanding causal linkages is, in many cases, the whole purpose of exploratory data analysis. Yet, currently, we do not have good general purpose interactive methods for exploring causal linkages. At present such linkages are generally expressed with static diagrams using simple arrows; on some occasions these arrows are labeled. Such diagrams are both difficult to understand and incapable of expressing the different kinds of phenomena that exist in an intuitive way. The PI's goal in this project is to develop visually compelling and easy to learn interactive representations of causal linkages. These will be built on simple physics-based visual metaphors that theory suggests form the substrate of our ability to cognitively model causal relationships. The interactive notation will be capable of expressing causal phenomena including negative causation, causal damping, causal amplification, causal blocking, as well as simple positive causation. In prior work, the PI has begun to develop a system of visual thinking design patterns that capture simple, effective interactive techniques, as well as basic perceptual and cognitive processes, in order to support the design processes of building tools for visual thinking. The current project will help further develop this theory, in addition to providing practical solutions to the problem of representing causal networks. Research activities will include design, design implementation, and evaluation studies of interactive causal diagramming notations. A multi-touch screen will provide the interface.<br\/><br\/>Broader Impacts: Modern theories of cognition have only just begun to take into account the fact that most real-world thinking occurs by people using interactive thinking tools, such as spreadsheets or computer aided design programs. Interactive diagrams have been shown to be extremely effective in data analysis. Techniques such as brushing, dynamic queries, and topological range highlighting provide powerful analytic tools, and multi-touch interaction is becoming increasingly available due to the widespread adoption of devices such as the iPhone. There is a need for interactive diagrams that effectively express different kinds of causal linkages in a way that can be easily understood. Such diagrams will find application in a wide variety of knowledge domains, including educational media and the interfaces that scientists and engineers use to explore causal networks.","title":"HCC: Small: Interactive Causal Networks","awardID":"1016607","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[450848],"PO":["565227"]},"168527":{"abstract":"This project is building tools and developing methods that identify the root cause of software configuration problems and suggest potential corrective actions. Our work is motivated by the increasing complexity of modern software, which makes computer systems difficult to configure and manage correctly. Users and administrators currently spend considerable time and effort troubleshooting software configuration problems. For instance, technical support is estimated to contribute 17% of the total cost of ownership for desktop computers and 60-80% for information systems.<br\/><br\/>We are demonstrating how system support for causality tracking can substantially reduce the time and human effort needed to troubleshoot software. We are focusing on configuration problems, in which the application code is correct, but the software has been installed, configured, or updated incorrectly so that it does not behave as desired. We are developing methods and tools that automate troubleshooting, thereby reducing the time to recover from errors and requiring less manual effort. Our tools track causality within software binaries by using dynamic instrumentation to monitor information flow at byte granularity. They propagate this information among files, processes, and multiple computers to troubleshoot complex distributed systems. Multi-level causality tracking helps determine the set of configuration values and other inputs that are most likely to have influenced the control flow of misconfigured software programs. We expect that the tools developed during this project will make complex computer systems easier to manage; this has the potential to dramatically reduce administrative support costs for our nation's computer infrastructure.","title":"CSR: Small: System Support for Causality-Driven Automated Troubleshooting","awardID":"1017148","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["521047"],"PO":["565255"]},"168648":{"abstract":"With software-as-a-service (SaaS) rapidly becoming mainstream, web applications increasingly substitute for desktop software. A web application is a two-part program, with its components deployed both in the browser and in the web server. The interactions between these two components inevitably reveal the program's internal states to any observer of the communication stream, simply through the pattern of packet lengths and the timing of interactions, even if stream is entirely encrypted. This research reveals that these \"side-channel\" information leaks are both fundamental and common: a number of popular web applications are found to disclose highly sensitive user data such as one's family income, health profile, investments and more. This research will develop an in-depth understanding of web applications' side channel vulnerabilities, particularly the design features and domain knowledge that lead to side-channel leaks. Based upon this understanding, new technologies are developed to facilitate the detection and mitigation of the side-channel threats during the development and operation of web applications. These technologies will be made available to users so they can assess their vulnerabilities and to developers so they can reduce the vulnerabilities in the applications they build. The outcomes of the project will contribute to the improvement of privacy protection in the SaaS infrastructure and cloud computing.","title":"TC: Small: Reining in Side-Channel Information Leaks in the Software-as-a-Service Era","awardID":"1017782","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486098"],"PO":["565327"]},"168417":{"abstract":"Information technology and electronic communications have been rapidly applied to every sphere of human activity, including commerce, medicine and social networking. The concomitant emergence of myriad large centralized searchable data repositories has made \"leakage\" of private information via data correlation (inadvertently or by malicious design) an important and urgent societal problem. Maintaining the usefulness of these data sources while also providing necessary privacy guarantees is an important unsolved problem. This problem drives the need for an overarching analytic framework that can tell us unequivocally how safe private data can be (privacy) while still providing useful benefit (utility) to multiple legitimate information consumers.<br\/><br\/>This research develops a unified framework to study the utility-privacy tradeoff irrespective of the type of data source or method of perturbation. Techniques and results from rate-distortion theory are used to model data sources, develop application independent utility and privacy metrics, and develop a side-information model for dealing with questions of external knowledge. The framework, applicable for single query data source models, is extended to study the utility-privacy tradeoffs for multiple-query models. Also studied is a successive disclosure problem which draws on classic results in successive refinement to develop the conditions under which multiple queries result in no additional information loss. The universal framework developed includes tools and techniques to bridge the gap between the information-theoretic model and current approaches and the dominant theoretical framework in computer science.","title":"CIF: Small: Privacy and Utility of Databases: An Information-Theoretic Approach","awardID":"1016671","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["562947","560130"],"PO":["564924"]},"168538":{"abstract":"It is widely recognized that language impairment can have a negative effect on literacy skills, and that children suffering language impairment are at a higher risk of academic under-achievement and lower overall social development. Hence, early and accurate language assessment for children is critical, especially for those with non-mainstream linguistic backgrounds. Spontaneous language samples are commonly used in communication disorders to measure the speaker's competence across a range of complementary language skills. These elicitation tasks allow clinicians and clinical researchers to analyze speech fluency by looking at the patterns of disfluencies and other speech disruptions. Language productivity can be gauged by computing mean length of utterance, along with measures of vocabulary and total utterances produced. Morpho-syntactic skills can also be analyzed from these data, by manually coding for specific grammatical constructions that are known to signal developmental milestones. At present, use of the information contained in these language samples is restricted to the capacity of human experts to manually analyze the data, since little has been done to use computational models for this task In this collaborative effort by PIs in the University of Alabama at Birmingham and the University of Texas at Dallas, the objective is to address this problem by developing computational approaches for scoring samples from children along different language dimensions, including speech fluency, syntactic structure, content, and coherence, with the long term goal of building robust computational linguistic approaches for identifying language impairments in children. With these ends in mind, the PIs will investigate a number of core research questions, including measuring syntactic complexity in children's language, evaluating content in story retelling and play sessions, and detecting disfluencies in children's transcripts. Moreover, this research will focus on analyzing samples from children with three different language backgrounds: English monolinguals, Spanish monolinguals, and Spanish-English bilinguals of Mexican descent (the latter representing the fastest growing minority in this country). Since their models will be data driven, the PIs expect to be able to evaluate empirically the differences in developmental patterns of speech in children across these linguistic diversities. Addressing the bilingual population involves modeling code-switching behavior; thus, additional core research questions include measuring syntactic complexity in code-switched data, and identification and categorization of code-switching patterns in bilingual children. <br\/><br\/>Broader Impacts: This research will contribute to developing more accurate and practical tools for assessing language development in children, a field to which little attention has been paid to date. Addressing the challenges involved in the automated analysis of children's speech will also advance the field of Natural Language Processing (NLP) in general. Moreover, since the project involves children with three different linguistic backgrounds, the new technology will have low language dependency and so should be easily portable to other languages and domains. In the field of communication disorders, applying corpus-based approaches to language assessment is still in its infancy; project outcomes will have a direct impact on this field, by providing new metrics for scoring spontaneous language samples of children that can complement the battery of assessment tools currently used.","title":"HCC: Small: Collaborative Research: Analysis of Language Samples for Detecting Language Impairment in Monolingual and Bilingual Children","awardID":"1017190","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["563325"],"PO":["565227"]},"168659":{"abstract":"It is well-observed that the whole world is full of data that are highly related and of diverse data object types such as people, organizations, and events. In many applications, it is intended to discover the hidden structures through such relationships involving different types of data objects in the world, in addition to \"clusters\" of the same type of data objects. On the other hand, relational data learning typically involves a large collection of data objects and thus algorithms for relational data learning are computation-intensive as well as data intensive. This calls for massively parallel solutions in order to make the algorithms scalable to large collections of data. This project addresses a three year integrated research and education program focusing on engaging in-depth research in developing novel parallel frameworks for a wide spectrum of state-of-the-art solutions to a series of fundamental problems in relational data learning. This research promotes the revolutionized understanding of relational data learning in the context of distributed computation environment. The project addresses fundamental problems in the literature of relational data learning as well as the expected breakthrough in the interdisciplinary and multidisciplinary research communities including parallel computation and scheduling, data mining and machine learning, and pattern analysis. The technologies generated from the research can be immediately deployed in important applications such as social network analysis, biological information discovery, financial and economic development analysis and prediction, natural disaster prediction, as well as military intelligence analysis.<br\/><br\/>Project url:<br\/><br\/>http:\/\/www.fortune.binghamton.edu\/nsf-iis-1017828.htm","title":"DC:Small: Collaborative Research: Data Intensive Computing for General Relational Data Learning","awardID":"1017828","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":[451438],"PO":["564316"]},"168549":{"abstract":"Several studies including those by the PIs have inferred the presence of considerable amounts of redundancy in Internet traffic content (ranging up to 99%). These studies clearly establish the tremendous scope for enhancing communication performance through appropriate exploitation of the redundancies. In this research, the investigators study and develop a network memory solution for the future Internet. Network memory, in its simplest form, involves a memory at every network element that allows store\/retrieve operations. The store operation is used when a particular data flows through the element for the first time. The retrieve operation is used when the same data needs to be retrieved from that element at a later point. The primary goal of using such a network memory is to minimize or eliminate any redundant traffic when delivering any content from its server to any client, and hence, reducing the bandwidth requirements. <br\/><br\/>Intellectual Merit: The underlying fabric of the Internet consisting of the content Servers, routers, and clients perform very little, if any, memorization and hence re-use of the memorized content. The focus of this research is to rethink this aspect of the Internet for the design of the future Internet architecture. The investigators introduce network memory as a new layer 3.5 for the future Internet, residing beneath the transport layer and above the network layer. The overall benefits of using network memory are better network delivery performance and higher network utilization levels through the exploitation of redundancies. Previous techniques such as web-caching, CDNs, and P2P applications, while in principle try to leverage redundancy, either do not harness the redundancy available or are too narrow in their scope to even attempt leveraging redundancies along the various (temporal and spatial) dimensions. A subset of the questions that the investigators plan to address through the work includes: 1. What is the granularity at which data should be memorized in the network memory? Should it be sub-packet, packet-level, or even super-packet level granularity? 2. Who are the participants in the network memory? Is it the clients, content-servers, or routers, or perhaps all of them? 3. How does the network memory work? How is the memory location determined for any given data? How is addressing of the network memory performed? 4. Should the network memory support sophisticated operations beyond just store and retrieve? The investigators will also explore fundamental issues with the network memory such as the nature of traffic redundancies and the concept of network compression. Finally, the research will address several key systems issues pertaining to the network memory including overheads of realization, protocol and header formats, and impact on other Internet protocols. <br\/><br\/>Broader Impact: In addition to graduate and undergraduate training opportunities, the research will be aimed at the standardization and technology transfer for the network-memory-layer solutions. The broader impact also includes: (a) Undergraduate curriculum development through senior undergraduate classes taught by the PIs, (b) Graduate curriculum development through two graduate-level classes on networking and information theory taught by the PIs, (c) Support for minority students.","title":"NetSE: Small: Network Memory for the Future Internet","awardID":"1017234","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["485126","560261"],"PO":["565090"]},"168318":{"abstract":"The objective of this project is to develop a new class of real-time motion planning and control algorithms, enabling mobile cyber-physical systems such as autonomous cars, aircraft, or mobile robots to behave in a provably safe, reliable and efficient fashion, in dynamically-changing, uncertain environments, shared with humans and other independent agents. Safe interaction of such systems with humans, human-controlled systems, or other automated systems will require the ability to behave according to accepted protocols and rules stated in high-level \"human-like\" languages, such as those arising from the rules of the road, ethical and privacy concerns, as well as rules of engagement in military or security applications. The core of the project is a new approach to the synthesis of real-time planning and control algorithms for mobile cyber-physical systems, combining incremental sampling algorithms for trajectory generation with efficient local model checking techniques. The proposed approach is intended to provide, in addition to provably correct and safe closed-loop behaviors, both asymptotic optimality guarantees and reactive planning capabilities. As a concrete target application area, autonomous automobiles are considered. In particular, a concept is proposed for autonomy-enabled mobility-on-demand system, which could help reducing traffic congestion in metropolitan areas by providing low-cost, convenient, private, and flexible transportation options to city dwellers.","title":"CSR: Small: Incremental Sampling Methods for Online Reactive Motion Planning with Temporal Logic Specifications","awardID":"1016213","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526913"],"PO":["565255"]},"168439":{"abstract":"We seek a better understanding of the behavior of decentralized systems such as markets (economic and electronic) and traffic networks, through the study of effective resource allocation and price determination for these systems. For network traffic, we seek to understand the impact of selfish network users on system behavior and study methods to control this. For markets where there is an accepted ordering of the desirability of goods (such as ad slots on web pages, quality-of-service customer classes, and network routes with known delays), we seek to design fast algorithms to match buyers and sellers so that all profit from the exchange. For decentralized networked markets, we seek to understand the convergence properties of local price update algorithms. These problems have implications for Internet and transportation networks, networked market economies, and online advertising markets. We will also design and offer new undergraduate courses that introduce both computer science majors and nonmajors to these important issues.","title":"AF: Small: Equilibria, Algorithms, and Mechanism Design for Network Games and Markets","awardID":"1016778","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[450928],"PO":["565251"]},"170870":{"abstract":"Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and <br\/>Communicative Behavior<br\/>Lead PI\/Institution: James M. Rehg, Georgia Institute of Technology<br\/>This Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. <br\/>Human behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions. This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.<br\/>The long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles.","title":"Collaborative Research: Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and Communicative Behavior","awardID":"1029430","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["472054"],"PO":["565227"]},"182442":{"abstract":"Mobile ad hoc networks (MANETs) are finding growing applications in time-critical and mission-critical scenarios such as disaster rescue?C public safety and military operations. The purpose of this project is to investigate two very important but mostly untouched MANET security issues: user unlocatability and communication anonymity. Without solving them, mobile users can be easily tracked or their communication patterns can be easily gathered for user profiling, which would jeopardize the user privacy and make them vulnerable to pinpoint attacks. In this project, a novel overlay-based approach OverUCA, an anonymous network overlay composed of nodes that anonymously communicate with one another atop the underlying MANET substrate, will be investigated to achieve user unlocatability, source anonymity, destination anonymity, source-destination unlinkability, and full compatibility with existing routing and MAC protocols. The success of this research will have a tremendous impact on advancing the deployments of MANETs in security-critical commercial, civilian, and military applications. This research will provide a viable way to fight against pinpoint attacks, advance the state-of-the-art in the wireless security research, and spark new research activities in securing MANETs. Moreover, the results from this research will be disseminated widely through high-quality conference and journal publications and public talks. Furthermore, the research outcome will be integrated into the educational curricula across two institutions. Finally, a couple of minority (female) students will work for their Ph.D. degrees, and hence this project will train the minority professionals for the national work force.","title":"COLLABORATIVE RESEARCH: CT-ISG: Overlay-Based User Unlocatability and Communication Anonymity in Mobile Ad Hoc Networks","awardID":"1122697","effectiveDate":"2010-09-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["551041"],"PO":["497499"]},"174984":{"abstract":"This award supports participant travel, primarily graduate student travel, to the second AAAI Fall Symposium on Complex Adaptive Systems (CAS). The objectives for this symposium are to continue building the nascent community of complex adaptive systems researchers, and to advance understanding basic characteristics of CAS, such as resilience, robustness, and evolvability. The Symposium will address these phenomena in the context of non-trivial, real-life CAS applications, with a focus on human\/social and ecological systems. Study of applications is guided by general domain-independent questions, such as:<br\/><br\/>* What are the best models for studying complex systems?<br\/>* How does the structure of a complex system constrain its emergent behaviors?<br\/>* What are the consequences of evolution and adaptation in complex systems?<br\/>* How do we calibrate complex systems and predict their behavior?<br\/><br\/>Furthermore, communicating the properties of CAS across domains allows researchers to gain insight from fields that they normally may not encounter, to span natural, physical, social, and virtual\/artificial systems.","title":"WORKSHOP: Complex Adaptive Systems: Resilience, Robustness, and Evolvability","awardID":"1052901","effectiveDate":"2010-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[469338,469339],"PO":["491702"]},"163852":{"abstract":"The success of the future Internet will not be measured by performance alone, but by its social and societal effects that alter our quality of life. The next-generation Internet must connect not only machines but also users: families and friends, representatives and rights advocates. There are immense technical challenges in facilitating communication while protecting user privacy and guarding their security. We address three key challenges. First, we apply user-focused research into developing practical secure communication between friends, laying the groundwork for social messaging without trusting centralized authorities to provide identities. Second, we develop advanced cryptographic techniques for processing private data without divulging it to application providers, placing private social applications on a solid theoretical foundation. Finally, we propose to fundamentally change how cooperation is encouraged and misbehavior is punished in distributed applications by embedding social network data into the design of applications.<br\/><br\/>This work has important broader impacts. Social networking is incredibly popular and maintaining privacy is a significant problem within these systems. The desire for privacy prevents individuals from participating fully and makes those who do participate vulnerable to various problems including potential identity theft. Because of the importance of the problem and problem domain, the results of our research will have significant public impact. Graduate and undergraduate students working on this proposal will gain experience with social applications, evaluating cryptographic protocols, and building systems that combine social data. We have actively involved undergraduate students in our research, and expect to continue.","title":"NetSE: Medium: Collaborative Research: Privacy Preserving Social Systems","awardID":"0964465","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["550216"],"PO":["565136"]},"170155":{"abstract":"This research project asks: How does public engagement in collaborative science and engineering projects affect the process of discovery and innovation? Combining approaches and tools from sociology, information studies, anthropology and public policy, we will provide both concrete models and detailed case studies that analyze the effects of organizations' involvement with members of the organized public on the nature of new networked virtual organizations with respect to three domains of variation: structure, outcomes and governance. The models, concepts and modes of analysis will be constructed to be understandable across disciplines, as well as in the scientific and engineering domains under study.<br\/><br\/>To build these models and concepts, we will analyze existing cases in the scholarly and popular literature and create in-depth studies of exemplary cases showing how they work and the struggles they face. Our results will have implications for how we measure, report and reward innovation; how we design policy and distribute resources that encourage public participation; and how we build infrastructures that integrate the work of professional scientists with that of other individuals who have a stake in science and engineering.","title":"Public engagement in networked virtual organizations and its effects on discovery and innovation","awardID":"1025569","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["551819","551820"],"PO":["565342"]},"171486":{"abstract":"At a recent EESE Program PI meeting, educators from across science and engineering expressed frustration with the way in which ethics is perceived by STEM undergraduate and graduate students, who seem to view it as a constraint or punitive, something that stands in the way of creativity and innovation. The PI argues that constraining behavior (don't cheat, don't falsify data) is only one of the roles ethics plays in science and engineering; another is as a creative and generative force that contributes to the development of new knowledge. In this project the PI's goal is to address this seeming contradiction, by building and disseminating new understandings on the role of formal and informal ethical inquiry in science and engineering as an essential catalyst of new discoveries from the industrial revolution through modern times. To this end the PI has assembled a team drawn from the domains of film, theater and television, information studies, and science and technology studies, and which also includes working media artists. They will harness their diverse perspectives to jointly develop a set of case studies centered around original documentary film shorts, which will be gathered in an accessible Web portal. These multimedia educational materials, including interviews, location footage, and motion graphics, will be the first to use professional media to tell stories about the creative power of ethical debate, and will impart a new, positive and generative perspective to undergraduate and graduate STEM ethics training. <br\/><br\/>Broader Impacts: Online and video media are key ways of engaging students. High production values (i.e., careful research, professional screenwriting, and compelling motion graphics) will not only engage the target student audience, but are necessary to convey the complexity of the selected topics. In addition to the curricular materials, the project will contribute methodological experience in the creation of multimedia and video content using ethics-focused approaches, which the PI will document and share in order to encourage educators and STEM researchers to pursue similar studies of ethics as a catalyst for innovation. The PI recognizes that the project format provides an opportunity to highlight the contributions of diverse and traditionally under-represented communities to ethical inquiry in science and engineering in a unique and highly visible way, and he plans to carefully consider questions of representation during selection and production of the case studies.","title":"Courage and Creativity: The Innovation of Ethics in Science and Engineering","awardID":"1033026","effectiveDate":"2010-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":["552479","560926"],"PO":["565227"]},"163742":{"abstract":"Analysts in all areas of human knowledge, from science and engineering<br\/>to economics, social science and journalism are drowning in data. The<br\/>proliferation of digital information requires tools and techniques for<br\/>exploring, analyzing and communicating data in a manner that scales as<br\/>both the data and the organizations analyzing it grow in<br\/>size. Throughout the data life-cycle, sensemaking is often a<br\/>collaborative process. As different analysts each contribute to data<br\/>acquisition, cleaning, analysis, and interpretation they contribute<br\/>contextual knowledge that deepens understanding. Analysts may disagree<br\/>on how to interpret data, but then work together to reach<br\/>consensus. Many data sets are so large that thorough exploration by a<br\/>single person is unlikely. In short, social cognition plays a critical<br\/>role in the process of scalable data analysis. New analysis tools that<br\/>address human cognitive characteristics, social interaction and data<br\/>analytics in an integrated fashion can improve our ability to turn<br\/>data into knowledge.<br\/><br\/>Scalable data analysis requires social interaction and therefore<br\/>social context must be embedded in data analysis tools. The goals of<br\/>this project are (1) to understand how social interaction and social<br\/>context can facilitate successful data analysis, (2) to develop models<br\/>and tools for representing and annotating data transformations,<br\/>visualizations, and social activity (e.g., textual and graphical<br\/>annotations, discussions, links, tags), and (3) to design and test<br\/>visual interfaces that leverage our tools to support collaborative<br\/>analysis practices, including data entry, transformation,<br\/>visualization, and interpretation. Central concerns include (a) a<br\/>focus on enabling social interaction throughout the data life-cycle<br\/>and (b) the use of scalable data transformation routines that can<br\/>return results in a time frame concordant with interactive,<br\/>exploratory data transformation and analysis.<br\/><br\/><br\/>Further information on this project can be found at: <br\/>http:\/\/vis.berkeley.edu\/projects\/scalable_social_data_analysis\/","title":"DC: Medium: Collaborative Research: Data Intensive Computing: Scalable, Social Data Analysis","awardID":"0963922","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["534062","451018"],"PO":["563751"]},"163753":{"abstract":"The probabilistic method is a powerful tool to establish the existence<br\/>of diverse objects of importance in several applications. For example,<br\/>Shannon's famous theorem asserts that a random codebook can be used<br\/>for reliably transmitting information at optimal rates on a noisy<br\/>channel. It is well known that a random graph is typically \"Ramsey\"<br\/>and has no large clique or independent set, and a random sparse graph<br\/>is very likely to be an expander with excellent connectivity. Yet, in<br\/>applications it is important to explicitly construct such an object<br\/>with a certified guarantee of the desired property. Obtaining such<br\/>constructions of comparable strength to what is guaranteed by the<br\/>probabilistic method is typically much harder and often unknown.<br\/><br\/>Pseudorandomness is a broad area that deals with efficiently<br\/>generating objects that exhibit the desirable properties of<br\/>\"random-like\" objects despite being constructed either explicitly or<br\/>with limited randomness. Such pseudorandom constructions are important<br\/>in the study of error-correcting codes, complexity theory,<br\/>combinatorics, cryptography, and high-dimensional geometry. Research<br\/>in recent years has addressed some of these challenges and led to<br\/>powerful constructions of error-correcting codes, expander graphs,<br\/>randomness extractors, Ramsey graphs, compressed sensing matrices,<br\/>etc. Despite the seemingly different definitions and motivations for<br\/>the study of these objects, much of this progress was based on<br\/>insights uncovering intimate connections between them, leading to a<br\/>rich theory with a common pool of broadly useful techniques.<br\/><br\/>This progress notwithstanding, explicit constructions with optimal<br\/>parameters typically remain open, and the area is full of exciting new<br\/>directions motivated by emerging applications. This project will<br\/>involve a comprehensive collection of interconnected research<br\/>activities focusing on the theory of error-correcting codes and<br\/>pseudorandomness. The directions pursued will include strengthening<br\/>the existing connections between various pseudorandom constructs and<br\/>discovering new computational applications thereof, and investigating<br\/>the pseudorandom properties of codes and related objects that have<br\/>important structural characteristics often needed in applications<br\/>(such as linearity or sparsity). Topics in coding theory inspired by<br\/>complexity theory such as list decoding and locally testable codes,<br\/>and codes for poorly understood noise models such as deletion channels<br\/>will be studied. Another important goal of the project is to bridge<br\/>the gap between worst-case and probabilistic noise models via codes<br\/>for channels with natural computational restrictions.<br\/><br\/>The research will use ideas from computer science in setting new<br\/>directions for research in coding theory as well as discovering new<br\/>constructions of codes and decoding algorithms, thereby enhancing the<br\/>connection between the computer science and information theory<br\/>communities. The discovery of new coding schemes has potential direct<br\/>applications in communication and storage of data. Many of the<br\/>questions to be addressed, therefore, have a natural practical<br\/>connection alongside their fundamental theoretical appeal. On the<br\/>education front, the project will engage several graduate students and<br\/>provide a stimulating research environment for them, and help with the<br\/>planned writing of a \"goal-oriented\" textbook on coding theory.","title":"AF: Medium: New Directions in Coding Theory and Pseudorandomness","awardID":"0963975","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["485293"],"PO":["565157"]},"174533":{"abstract":"In situated dialogue, although artificial agents and their human partners are copresent in a shared environment, their knowledge and representation of the shared world are significantly different. When a shared basis of the environment is missing, communication between partners become more challenging. Language alone can be difficult and inefficient for partners to ground objects of interest. Motivated by previous empirical findings on eye gaze in joint attention, in collaboration, and in human language processing, our hypothesis is that eye gaze plays an important role in coordinating the collaborative referring process, especially between partners who have mismatched representations of their shared environment. Based on this hypothesis, the objective of this exploratory project is to examine the role of shared gaze in the collaborative referring process.<br\/><br\/>This EArly Grant for Exploratory Research aims to generate new findings on how shared gaze coordinates the collaborative referring behaviors between partners with mismatched representation of the shared environment. These findings will provide insight to computational approaches and systems that combine gaze modeling with the collaborative discourse to ground references. The collected data will support many in-depth studies on language processing in situated dialogue.","title":"EAGER: Shared Gaze in Collaborative Referring","awardID":"1050004","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["565127"],"PO":["565215"]},"163885":{"abstract":"The manifestation of language in space poses special challenges for computer-based recognition. Prior approaches to sign recognition have not leveraged knowledge of linguistic structures and constraints, in part because of limitations in the computational models employed. In addition, they have focused on the recognition of limited classes of signs. No system exists that can recognize signs of all morphophonological types or that can even discriminate among these in continuous signing. Through integration of several computational approaches, informed by knowledge of linguistic properties of manual signs, and supported by a large existing linguistically annotated corpus, the team will develop a robust, comprehensive framework for sign recognition from video streams of natural, continuous signing. Fundamental differences in the linguistic structure of signs, distinguishing signed languages in 4D, with spatio-temporal dependencies and multiple production channels from spoken languages, are critical to computer-based recognition. This is because finger-spelled items, lexical signs, and classifier constructions, e.g., require different recognition strategies. Linguistic properties will be leveraged here for (i) segmentation and categorization of significantly different types of signs, and then, although this subsequent enterprise will necessarily be limited in scope within the project period, (ii) recognition of the segmented sign sequences. Through the 3D hand pose estimation from a team-developed tracker, w significant tracking accuracy, robustness, and computational efficiency will be attained. This 3D information is expected to greatly improve the recognition results, as compared with recognition schemes using only 2D information. The 3D estimated information from the tracking will be used in the proposed hierarchical Conditional Random Field (CRF) based recognition, to allow for tracking and recognition of signs that are distinct in their linguistic composition. Since other signed languages also rely on a very similar sign typology, this technology will be readily extensible to computer-based recognition of other signed languages.<br\/><br\/>This linguistically-based hierarchical framework for ASL sign recognition?based on techniques with direct applicability to other signed languages, as well?provides, for the first time, a way to model and analyze the discrete and continuous aspects of signing, also enabling appropriate recognition strategies to be applied to signs with linguistically different composition. This approach will also allow the future integration of the discrete and continuous aspects of facial gestures with manual signing, to further improve computer-based modeling and analysis of ASL. The lack of such a framework has held back sign language recognition and generation. Advances in this area will, in turn, have far-ranging benefits for Universal Access and improved communication with the Deaf. Further applications of this technology include automated recognition and analysis by computer of non-verbal communication in general, security applications, human-computer interfaces, and virtual and augmented reality. In fact, these techniques have potential utility for any human-centered applications with continuous and discrete aspects. The proposed approach will offer ways to address similar problems in other domains characterized by multidimensional and complex spatio-temporal data that require the incorporation of domain knowledge. The products of this research, including software, videos, and annotations, will be made publicly available for use in research and education.","title":"III: Medium: Collaborative Research: Linguistically Based ASL Sign Recognition as a Structured Multivariate Learning Problem","awardID":"0964597","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["522465"],"PO":["565136"]},"174302":{"abstract":"Data analysis is a fundamental problem in computational science, ubiquitous in a broad range of application fields, from computer graphics to geographics information system, from sensor networks to social networks, and from economics to biological science. Two complementary fields that have driven modern data analysis are computational geometry and statistical learning. The former focuses on detailed and precise models characterizing low-dimensional geometric phenomena. The latter focuses on robust or predictive inference of models given noisy high-dimensional data. This project aims to initiate a dialog between these two fields with geometry being the central theme. A closer interaction between them will benefit and advance both fields, and can potentially fundamentally change the way we view and perform data analysis. <br\/><br\/>Specifically, on one hand, the type of data common in the learning community poses several challenges for traditional computational geometry methods. The shift of focus to these challenges and the modeling of uncertainty central in statistical learning can broaden the scope of computational geometry, and lead to geometric algorithms and models that are more robust to noise and extend to high-dimensional data analysis. On the other hand, computational geometry has developed many elegant structures that contain often detailed and precise information about the underlying domain. Models parameterized using these structures can lead to statistical learning models and algorithms that are richer and more interpretable but remain robust to noise and are predictive. <br\/><br\/>This project is multi-disciplinary in nature, and will involve fields including computational geometry, algorithms, statistics, differential geometry and topology. Education will be integrated in this project.","title":"AF: EAGER: Collaborative Research: Integration of Computational Geometry and Statistical Learning for Modern Data Analysis","awardID":"1049290","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":["550819"],"PO":["565157"]},"164513":{"abstract":"The NSF-funded research project led by Javier Movellan at the University of California, San Diego will develop a social network (?RubiNet?) for early childhood education. The network will help integrate the activities of children, teachers, parents, and researchers with the goal of improving early childhood education at a national and international level. RubiNet will use low-cost sociable robots to connect children and teachers in different classrooms, from different socioeconomic backgrounds, cultures, and ethnicities. Some of the classrooms will be in different countries. Movellan and his colleagues will investigate the potential of RubiNet as a tool for rapid design and evaluation of low cost early intervention programs. The potential for RubiNet to improve academic skills in young children will be assessed. The researchers will also investigate whether this form of interaction engenders more familiarity and positivity in children's views of those who are different from themselves.<br\/><br\/>An unprecedented number of children in the US start public school with major deficits in basic skills, including social skills, language, and mathematics. Children that experience early failure in school are more likely to later become inattentive, disruptive, or disengaged. These students tend to drop out of school early, and are more likely to depend on public assistance programs for survival. Empirical research suggests that the key to avoiding this vicious cycle is to intervene during the pre-kindergarten years instead of waiting until failures occur in kindergarten or later. Unfortunately, early intervention programs are typically very costly. Thus, another key goal of RubiNet is to significantly lower the cost of intervention in early education. In addition, RubiNet will be of great potential benefit to researchers who study social interaction in young children.","title":"SoCS: An International Social Network for Early Childhood Education","awardID":"0968573","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["463668","523911",440719],"PO":["563458"]},"174325":{"abstract":"We propose to formalize mathematical models of group decision making that take into account expected behaviors, the effects of exogenous events and influences, and the psychological effects of belief modifications, all in the context of probabilistic reasoning. We are interested in building models sufficient to give us insight into both human and computational preference aggregation and voting processes. For instance, we want to leverage the growing political science work on social networks and voting to build models of voting that reflect complex interpersonal influence between voters. We want to explore work on belief changes in the political science, psychology, and decision sciences literature to include in our models the human tendency to revert to earlier-held beliefs.<br\/><br\/>The intellectual merit of this work lies in the mathematical formalization of theories of group decision making and influence in a stochastic setting; the alignment of such models with those from the political science literature; computational complexity analysis of stochastic models of influence in group decision making, and algorithms for influencing and blocking influence in such settings.<br\/><br\/>This work addresses NSF's third broader impacts category: \"Enhance infrastructure for research and education.\" The field of computational social choice is often said to have begun with Bartholdi, Tovey, and Trick's 1989 paper in the journal Social Choice and Welfare. However, computer scientists were very slow to notice it, and it generated little initial attention in political science. Even now, cooperation and even communication between political and computer scientists about \"social choice'\" is limited. We will take on the challenging task of interdisciplinary research, attempting to understand problem statements, goals, and results from both bodies of research. We have seen great success by SIGECOM in supporting interdisciplinary work in algorithmic computer science, complexity theory, and economics. We hope to bring that level of interaction to the social choice research areas.","title":"EAGER: Changing Minds, Changing Probabilities","awardID":"1049360","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["516895"],"PO":["565251"]},"174567":{"abstract":"This exploratory project strives to develop a new approach to support human understanding of the uncertainty that is inherent in the structure and predictions of complex models.Specifically, the focus in the project is on understanding several types of uncertainty that are associated with model predictions.<br\/>Sample uncertainty occurs when regions of the instance space are not well represented in the training data, and predictions are therefore based on sparse information. Model instability occurs when model predictions vary, depending on the training data that was used to construct the model. Prediction variability occurs when a given observation may have noisy attributes, and this input uncertainty leads to uncertainty in the model's predictions. Novel analytical techniques are developed to create meta-models that characterize these three forms of uncertainty. To facilitate user understanding of the nature and distribution of these multiple types of uncertainty across the model space, novel visualization methods represent these meta-models in a display space. Finally, a novel evaluation methodology is used to measure whether, and in what ways, important characteristics of the meta-models are captured in the visualization display space.<br\/><br\/>This work develops novel techniques in the fields of machine learning and data visualization. Contributions in machine learning include more powerful methods for constructing and analyzing meta-models that characterize multiple types of uncertainty associated with predictive models. Data visualization research focuses on new approaches for representing multi-valued, probabilistic, and complex data, enabling the display of the nature and range of model predictions and uncertainty. An interdisciplinary contribution is the development of a novel methodology for evaluating the quality of model visualizations with respect to the preservation of important model and meta-model characteristics.<br\/><br\/>The broader impacts of this project may be grouped into three major clusters: a new model building paradigm; fostering scientific collaboration; and integrating research and education. The results are expected to provide foundations for further research is management of uncertainty in deriving models representing a wide range of phenomena. This project lays a technical groundwork that can contribute to new collaborations between the PIs and application domain experts, facilitating broad interdisciplinary collaborations. Project results will be widely disseminated via the project web site (http:\/\/maple.cs.umbc.edu\/complexmodels\/). Finally, through teaching and training activities, this research project is also well suited to include the introduction of undergraduates to the possibilities of research and the incorporation of project topics into the PIs' courses on visualization and artificial intelligence.","title":"GV: EAGER: Innovative Analysis and Visualization Approaches for Understanding Model Uncertainty","awardID":"1050168","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["558297","507476"],"PO":["563751"]},"173005":{"abstract":"This project will conduct innovative research to demonstrate the potential of book citation analysis in navigating, analyzing and evaluating research progress, direction and impact. A hopeful result will be a comprehensive cartography of the scientific and scholarly research space associated with the content of these documents. The project also will extend the data-intensive inquiry beyond simple reference extraction to other structures and patterns in books. This will be done in collaboration with researchers at Indiana University, Leiden University, Netherlands and L'Universit\u00e9 du Qu\u00e9bec \u00e0 Montr\u00e9al, Canada. In pursuing its goals the project will use novel methods and large-scale data resources to explore prominent shortcomings in the overall structure and flow of scientific knowledge as it now proceeds in the internet-age. The Principal Investigator and his collaborators will leverage and modify work done by a variety of research groups in the course of this project in order to achieve their goals.","title":"EAGER: Creating a Book Citation Index","awardID":"1042276","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["562561"],"PO":["565227"]},"174457":{"abstract":"Election auditing verifies that the systems and procedures work as intended, and that the votes have been counted correctly. If a problem arises, forensic techniques enable auditors to determine what happened and how to compensate if possible. Current audit trails record incomplete information, or unnecessary information, thereby hindering validation of the election results and the correctness of the process, and determination of the causes and effects of problems.<br\/><br\/>Complicating both tasks is that the audit trails enabling analysis of failures may contain information that either exposes the identity of the voter (enabling voter coercion, for example); or that communicates a message to a third party (enabling vote selling). <br\/><br\/>The goal of this project is to determine the information needed to assess whether the election process in general, and e-voting machines in particular, operate with the desired degree of assurance, especially with respect to anonymity and privacy. This project also seeks to describe the requirements that an infrastructure supporting e-voting machines must meet. It reflects a novel approach to discovering, analyzing, and balancing security, auditability, privacy, and anonymity in a real environment. Real election processes in California will be used to test practicality of the approach and dissemination of knowledge. Given the involvement of the election officials, and the analysis of real voting procedures and systems, the anticipated outcome of this project include a better understanding of auditing requirements and processes for elections by voting machine manufacturers, election officials, forensic analysts, and researchers.","title":"Auditing Voting Systems While Preserving Secrecy and Anonymity","awardID":"1049738","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560876","564751"],"PO":["564388"]},"174578":{"abstract":"For many current Internet applications, users experience a crisis of confidence. Is the website really served from the correct server or was it altered in transit? Is the Facebook invitation really originating from the claimed individual or was it created by an impostor? Is the received email from the claimed individual or was it sent by a spammer? The PI's proposed work is based on the observation that individuals often have physical interactions with resources or other individuals they communicate with. Often, people communicate over the Internet after having met in person. Similarly people visit brick-and-mortar stores and later visit their websites. The intellectual merit is that human-understandable trust establishment is a fundamental research challenge. Despite decades of research, easy-to-use and secure mechanisms that individuals can use to establish trust in Internet resources are still elusive. This exploratory work has the potential to have a transformative effect on the research directions of the community, such that the urgent crisis of confidence users are experiencing for their digital communications can be resolved. The broader impacts of the work are that achieving a high confidence for the authenticity of Internet resources is an urgent need for our society. The proposed research could provide new directions on how to address these important challenges.","title":"CNS: EAGER: All Trust is Local: User-Oriented Trust Establishment","awardID":"1050224","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[468291,"496764"],"PO":["565327"]},"174116":{"abstract":"This proposal requests support for travel to preliminary planning meetings, and to attend a workshop at the headquarters of the German Archaeological Institute in Berlin. The workshop will allow US researchers to coordinate efforts with the strategic initiatives of the German Archaeological Institute, one of the largest and most archaeological organizations in the world. The US researchers will be primarily associated with the large and well-established Perseus Digital Library (with a focus on Greco-Roman Antiquity) and the group associated with the Electronic Cultural Atlas Initiative (with particular strength on Asian culture). Both have considerable international collaborations underway. Preliminary meetings will address the challenges of developing interoperable linguistic and geographic resources that are of great value to scholars studying long-term cultural transformations across broad geographical areas.","title":"New Horizons in the Use of Historical Linguistic and Archaeological Data: Workshops in China and Germany","awardID":"1048561","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[467058],"PO":["564456"]},"175447":{"abstract":"This grant supports travel by doctoral students to the Doctoral Symposium at the International Conference on Software Engineering (ICSE). ICSE is the flagship conference for the area of Software Engineering, providing a forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and concerns in the field of Software Engineering. The Doctoral Symposium at ICSE provides a venue for young researchers to access worldwide expertise in Software Engineering. The Symposium provides a forum for Ph.D. students to present and discuss their research goals, methods, and results at an early stage in their research. The Symposium aims to provide useful guidance to the students from a panel of experts, for completion of the dissertation research and initiation of a research career. The opportunity to attend one of the premier conferences in Software Engineering is intended to provide experiences that may encourage students to pursue higher degrees in computer science research.","title":"Student Participant Support for the ICSE 2011 Doctoral Symposium","awardID":"1055425","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["533779"],"PO":["564388"]},"168803":{"abstract":"Data is being generated everywhere in real-time since the scope of sensors has extended to smartphones that continually capture and\/or transmit a varied type of data. A lot of data comes in different semantic forms that needs to be distinguished. For example, tweets and instant messages carry different types of information although both are based on text. Such distributed data carries rich semantics that need to be captured and processed for determining the state of the information in near real time and this poses many challenges. This work proposes a language-based (Java) approach along with a mobile agent based system to capture important properties such as timeliness, currency, incompleteness, consistency, and autonomy of data utilizing the properties of their sources. Moreover, since the data sources are quite autonomous, information flow policies dictate access control of the non-local data. Policies pose constraints on data access and movement and multiple processing possibilities exist in such a scenario. Performing such data fusion in real-time is very challenging and it is envisioned to use Java mobile agents framework. The role of compiler analysis is critical to make the runtime smart to reduce undue overhead to get distributed real time processing needs under control. It is proposed to test this software infrastructure on several applications from the domains such as the transportation, and the navigation systems.","title":"DC: Small: A Programming Model for Distributed Data Fusion","awardID":"1018544","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["550988","458681"],"PO":["565272"]},"164458":{"abstract":"The goals of this project are to develop collaborative tools for helping to solve difficult managerial and societal problems and to test these tools on an important problem confronting the world today: global climate change. Inspired by systems like Wikipedia and Linux, the project will develop a global, on-line forum - called the Climate Collaboratorium - in which thousands of people around the world can create, analyze, and ultimately select detailed plans for what humans can do about global climate change. At the core of the system will be an evolving collection of user-created plans based on computer simulations of the actions humans can take and the predicted impacts of those actions. Users will also be able to debate the pros and cons of different plans and vote for the plans and arguments they find most credible and desirable.<br\/><br\/>Intellectual merit <br\/>The primary intellectual contributions of this work will be lessons about how to design large-scale model-centric collective decision-making tools and the communities to use them. <br\/><br\/>Broader impacts <br\/>At a minimum, this on-line forum can help educate the general public about the real issues involved in global climate change. But more importantly, by constructively engaging a broad range of scientists, policy makers, and ordinary citizens, this forum may help develop plans and policies that are actually better than any that would have otherwise been developed. In short, it could become a combination of a kind of simulation game for climate change, a Wikipedia for controversial topics, and an electronic democracy on steroids.","title":"SoCS: The Climate Collaboratorium: A Tool for Large-Scale Model-Centric Collective Decision-Making","awardID":"0968321","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["551967","551789","499969"],"PO":["565227"]},"168704":{"abstract":"Advances in technology are making it feasible to explore novel approaches to human-computer interaction in a wide variety of devices and settings, in an effort to achieve interaction that feels more natural. While valuable from both a user and commercial perspective, use of new technology is not well understood from a more principled system design or cognitive science perspective. Establishing even the basic elements of a set of design principles would both produce better designs and increase our confidence in using the technology in high-risk\/high-reward domains, such as first responder planning and control. The PI's long-term goal is to develop a set of principles specifying how to design systems that both enable natural human-computer interaction and are informed by an understanding of human factors. Natural interaction refers to the cognitively transparent, effortless multimodal communication that can happen between people; this work aims to make that possible in human-computer interaction. Designs informed by human factors take into account an understanding of human capabilities (e.g., attention, use of multiple information channels, etc.), so that the final system is a good impedance match to human information processing. This research will involve building systems designed in this spirit and articulating principles for their design that, in turn, will facilitate future designs by making explicit both the task conditions under which one or another modality is appropriate (e.g., when to draw, when to talk), and the ways in which multiple modalities can effectively be used simultaneously in human-computer communication. The project is set in the context of a tabletop-based system that assists with planning and coordination in the command center of an urban search and rescue (USAR) operation. The work will proceed by leveraging and combining the team's experience in building novel interaction technologies and in human factors. They will extend the current version of the PI's tabletop system, which permits basic pen-based interaction, so as to give it the ability to handle the kinds of sketching, freehand gestures and speech used in real-world USAR work, thereby providing a far more natural style of interaction. The additional interaction modalities will make the system more powerful, while the real-world, time-pressured character of the task offers a good platform for studying the human factors aspects. This will allow the team to understand how, when and why various modalities are useful, providing the data from which system design principles can be articulated. To help ensure breadth of applicability of project outcomes, the PI will explore the same issues in a second domain, software design with UML diagrams.<br\/><br\/>Intellectual Merit: This research will provide insight into a model of multimodal interaction by producing empirical data about modality selection, and by articulating a widely useful set of principles for interface design that make explicit the conditions for both modality selection and cognitively effective modality combination. Such principles offer the possibility of transformative change to multimodal interface design, changing it from the current largely ad hoc practice to a design process guided by testable principles. Pursuing the research in two task domains will help to ensure a useful degree of generality to the principles derived. The work will provide benefit to society to the extent it can improve the effectiveness of first responder teams. The ability to handle non-traditional interaction modalities (e.g., gesture) will ultimately make computer interaction more accessible to physically disadvantaged users. The PI will take care, to the extent possible, to use and build upon open source tools, so that he can make available to the community all of the research software produced during the course of the project, thereby adding to the supply of next-generation research and education platforms.","title":"HCC: Small: Enabling and Exploring Natural Interaction","awardID":"1018055","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["474452","210681"],"PO":["565227"]},"167615":{"abstract":"As one of the most promising emerging concepts in Information Technology, outsourced computation (also known as cloud computing) is transforming our perception of how IT is consumed and managed, yielding improved cost efficiencies and delivering flexible, on-demand scalability. Cloud computing reduces IT resources and services to commodities acquired and paid-for on-demand through a fast-growing set of infrastructure, platform, and service providers.<br\/><br\/>Despite the relatively fast growth and increased adoption of clouds, our understanding of aspects related to their security, privacy, and economic value proposition -- and hence our ability to trust them -- is lacking. This project addresses this challenge by (a) extending cloud service-level agreements to govern aspects such as integrity of outsourced services, information leakage control, and fair market pricing; (b) developing mechanisms that allow providers to guarantee and users to verify that such trust-enhancing service-level agreements are being followed; and (c) exposing trustworthiness guarantees and tradeoffs to cloud customers and system integrators in ways that are both practical and usable.<br\/><br\/>The research work pursued in this project is timely as it addresses the issues of cloud trustworthiness early enough to avoid having the conflicts among its various stakeholders develop unchecked -- as was the case with the Internet decades ago. Doing so has the potential of improving the utility and hardness of our cyber-infrastructure, with significant benefit to our economy and society. <br\/><br\/>The project will ultimately lead to a better marketplace for computing resources, in which users are assured that the services they acquire satisfy their performance, security, and privacy expectations.","title":"TC:Large:Collaborative Research: Towards Trustworthy Interactions in the Cloud","awardID":"1012798","effectiveDate":"2010-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["562061","449084","562065",449039],"PO":["562974"]},"168616":{"abstract":"Information flow is a central concept in computer security, yet it is still an open problem to tag information in a running system and track how the information flows throughout the system in an accurate manner. We are developing the fundamental concepts in control theory, information theory, and systems to solve this problem using what we call a relaxed static stability approach.<br\/><br\/>In a running system, as information is cut-and-pasted by users or processed, it flows in unexpected ways. Two major challenges are address dependencies and control dependencies. Overtagging these dependencies causes the entire system to quickly become tagged, while undertagging them means that important flows of information are not tracked. Modern fighter jets and stealth aircraft are designed without inherent stability, then advanced digital \"fly-by-wire\" systems are incorporated into the design to create a stable system that can actually fly. By applying this same kind of \"relaxed static stability\" approach, we are designing an accurate dynamic information flow tracking system that makes the right tradeoffs between overtagging and undertagging. This will enable whole new classes of applications based on dynamic information flow tracking, ranging from digital forensics and malware analysis to data provenance. By addressing a fundamental need in security and privacy research, we expect our work to have impact in any field where the flow of information in a computer is important to understand.","title":"Realizing Full-System Dynamic Information Flow Tracking via Relaxed Static Stability","awardID":"1017602","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548106","493492"],"PO":["565327"]},"168858":{"abstract":"The availability of parallelism in single-chip microprocessors has increased exponentially over the last five years, as process technology parameters have led microprocessors designers to transition from single core to multi-core designs. This trend is certain to continue; designs with hundreds and even thousands of cores on a single chip are envisioned in future. These chips, often referred to as manycore processors, offer the opportunity to greatly increase our computational capabilities through continued exploitation of Moore's Law. However, with them the deep and difficult goals of programmability and energy efficiency have emerged as two of the central research challenges in computer engineering today.<br\/><br\/>Recently, issues in programming multi- and many- core chips have led many members of the research community to believe that addressing the multi-core programmability crisis is one of the most critical issues in computer science research today. The goal of making multi-, and many- core architectures more useful calls for new approaches that will greatly reduce the programmer effort and skill required to attain good performance across a wide variety of programs. This research examines a manycore system called Feather, which attacks these programmability issues through a combination of automatic parallelization and novel architectural techniques. Feather focuses on heavily numerical applications, and is programmed using high level languages. Feather combines a tunable compiler, a run-time system, and an architecture into a system that seeks to ease performance brittleness and programmability issues for numerical codes on manycore systems.","title":"SHF: Small: Feather: A High Productivity, Energy-Efficient Manycore System for Numerical Codes","awardID":"1018850","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"6892","name":"CI REUSE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["557941"],"PO":["562984"]},"168506":{"abstract":"As seen by the proliferation of commercial-grade malware, attacking networked applications is a profitable enterprise. There are two advantages malware authors currently have against us. The first advantage is that because users run a diverse set of applications on their systems, anti-virus and anti-malware programs must exhaustively search for specific malware instances across all pieces of software on a system. Malware easily thwarts this through the use of polymorphism, metamorphism, obfuscation, and cryptographic packing, placing a financial burden on anti-malware vendors and a performance burden on their users. The second advantage malware authors enjoy is that while there are a lot of applications to attack, each software target is static across many client machines. As a result, malware authors only need to reverse and exploit a single instance of an application in order to compromise thousands of machines. This project examines two novel approaches for reversing the advantages held by malware authors. The first approach explores a white-listed execution model that extends integrity-checks beyond the operating system and into the running application in an on-line manner. The second approach explores the on-line, run-time transformation of applications in order to force a malware adversary to reverse and exploit a new application for each new client it wishes to compromise. Finally, the project aims to demonstrate the impact these techniques have on the cost of developing malware.","title":"TC: Small: Increasing The Cost of Malware","awardID":"1017034","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[451080],"PO":["564388"]},"168627":{"abstract":"The AfterBurner project looks at improving single-thread performance on both simple and high-performance out-of-order cores in an energy efficient way. Aside from explicit parallelism, this is the primary challenge of multi-core architectures going forward. The most energy-efficient way to improve single-thread performance is to accelerate low-performing program regions. This approach yields the greatest benefit. It also has a low cost because it doesnot require high-bandwidth execution, making it applicable to both simple and high-performance cores. Low single-thread performance is caused by squashes due to control and data mis-speculations and by long latency loads and stores which clog the pipeline. AfterBurner unifies two recently proposed techniques---speculative retirement which can efficiently buffer large numbers of completed instructions and selective re-execution which can re-execute dynamically generated program subgraphs to back-patch program state---and uses them to tolerate all four classes of low-performance events. AfterBurner's multi-purpose infrastructure approach to performance reduces cost, simplifies design, and expands applicability to code that suffers from different low-performance events simulatenously.<br\/><br\/>In addition to education and student tarining, the AfterBurner project marks the beginning of a systems research collaboration between Uniersity of Pennsylvania and Drexel computer science departments.","title":"SHF: Small: AfterBurner: Efficient Performance Scaling via Post-Retirement Processing","awardID":"1017654","effectiveDate":"2010-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["562909"],"PO":["559883"]},"168517":{"abstract":"Parallel computing based on the general purpose Graphic Processing Unit (GPU) provide massive many-core parallelism and can deliver staggering performance improvements over traditional single-core and existing general multi-core computing techniques. The recent introduction of general-purpose GPU (GPGPU) has gained strong interests from the scientific community to tackle many computationally intensive problems. The GPU computing powers, however, have not been fully exploited for many important engineering computing problems in the VLSI design practices. Simulation of massive global interconnects, radio-frequency (RF) and millimeter-wave (MM) integrated circuits (ICs) at very high frequencies remain as difficult problems confronting chip designers. Designing new parallel and scalable computing algorithms, which can unleash the potentials of GPU-based parallel computing techniques, become highly desirable. This research seeks to investigate new parallel simulation approaches to solving massive interconnect circuits and analog\/RF\/MM integrated circuits based on single node general GPU or networked GPUs on a computer (GPU-cluster). First, the PI will investigate new parallel simulation algorithms based on analytic solution for structured interconnect circuits like on-chip power delivery and clock distribution networks on a GPU or GPU-cluster. Second, the PI proposes developing a very efficient numerical parallel simulation algorithm for analyzing general interconnects. The new algorithm will perform circuit complexity reduction to improve the efficiency. The PI?s team will investigate to parallelize the major computing steps in this method. Third, the PI plans to develop new parallel shooting-Newton methods for high-frequency circuits (RF\/MM). The new method will explore structured Krylov-subspace, and GPU-based parallelization to improve efficiency as well as the convergence of RF\/MM integrated circuit simulation. <br\/><br\/>The outcome of this research will add significantly to the core knowledge of parallel numerical analysis of linear and nonlinear dynamic systems on the GPU and GPU-cluster systems. By working with the industry partner, the PI expects to bring immediate impacts on the design community to improve the design productivity for nanometer VLSI systems. The research results will also help the electronic design automation (EDA) community to gain more insight in exploring the current and future general-purpose GPUs for parallelizing entire EDA tools on GPUs and multicore systems. The interdisciplinary nature of proposed research and relevant training will allow students to gain critical skills in the highly competitive high-tech job market. This grant will enable the PI to hire more female and underrepresented minority students to further contribute to the diversity in America?s science and technology workforce.","title":"SHF:Small:GPU-Based Many-Core Parallel Simulation of Interconnect and High-Frequency Circuits","awardID":"1017090","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["535204"],"PO":["562984"]},"167428":{"abstract":"As one of the most promising emerging concepts in Information Technology, outsourced computation (also known as cloud computing) is transforming our perception of how IT is consumed and managed, yielding improved cost efficiencies and delivering flexible, on-demand scalability. Cloud computing reduces IT resources and services to commodities acquired and paid-for on-demand through a fast-growing set of infrastructure, platform, and service providers.<br\/><br\/>Despite the relatively fast growth and increased adoption of clouds, our understanding of aspects related to their security, privacy, and economic value proposition -- and hence our ability to trust them -- is lacking. This project addresses this challenge by (a) extending cloud service-level agreements to govern aspects such as integrity of outsourced services, information leakage control, and fair market pricing; (b) developing mechanisms that allow providers to guarantee and users to verify that such trust-enhancing service-level agreements are being followed; and (c) exposing trustworthiness guarantees and tradeoffs to cloud customers and system integrators in ways that are both practical and usable.<br\/><br\/>The research work pursued in this project is timely as it addresses the issues of cloud trustworthiness early enough to avoid having the conflicts among its various stakeholders develop unchecked -- as was the case with the Internet decades ago. Doing so has the potential of improving the utility and hardness of our cyber-infrastructure, with significant benefit to our economy and society. <br\/><br\/>The project will ultimately lead to a better marketplace for computing resources, in which users are assured that the services they acquire satisfy their performance, security, and privacy expectations.","title":"TC:Large:Collaborative Research: Towards Trustworthy Interactions in the Cloud","awardID":"1011840","effectiveDate":"2010-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["521484"],"PO":["562974"]},"168528":{"abstract":"Social-networking sites (e.g., Facebook, MySpace, LinkedIn, etc.) and other online collaborative tools have emerged as places where people can post and share information. This information-sharing has many benefits, ranging from practical (e.g., sharing a business document) to purely social (e.g., communicating with distant friends). At the same time, information sharing inevitably poses significant threats to user privacy. In social-networking sites, for example, documented threats range from identity theft to digital stalking and personalized spam. As a result, a growing number of such sites allow individual users to specify fine-grained policies that indicate who can access their data, and to what extent. However, studies have consistently shown that most end-users find the task of specifying access-control policies for their own data overwhelming; as a result, users often skip the process altogether.<br\/><br\/><br\/>The goal of this project is to help collaborative and social-media users gain control of their data. To that end, the project will include three main components: assisted specification, feedback, and refinement recommendations. To assist users in initially specifying access-control policies for their data, the project will develop a \"privacy wizard,\" which employs data mining and machine learning methods, including active learning, to construct an accurate policy, with minimal input from the user. To provide feedback regarding existing privacy settings, the project will pursue two approaches: aggregate scores and visualizations. For example, an aggregate score can be used to concisely explain to the user how her settings differ from those of other users. Preliminary work found that Item Response Theory (IRT) can be used effectively for this purpose. Finally, the project will consider how aggregate scores and visual feedback can be enriched with recommendations for refinements to help the user achieve an expressed level of social exposure.<br\/><br\/>Online collaborative tools and social media offer great promise in a number of arenas. In addition to communicating with friends via social networking sites, collaborative tools are now used in fields as diverse as business, medicine and education. However, the absence of usable privacy and access control prevents such tools from realizing their full potential. Results of this project will be disseminated via prototype implementations, as well as research publications. New undergraduate and graduate curriculum modules will also increase awareness of the importance of policy-specification and emerging research in this area.","title":"TC: Small: Collaborative Research: User-Centric Privacy Control for Collaborative Social Media","awardID":"1017149","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[451132,"533266"],"PO":["565136"]},"168649":{"abstract":"Many applications require high reliability and availability. Unfortunately, as software has grown in size and complexity, many software bugs escape from testing into production runs and cause computer failures in real world. When a production run system fails, software engineers are frequently called upon emergency to diagnose and solve the issue within a tight time schedule. Because such errors directly impact customers? business, vendors make diagnosing and fixing them as the highest priority. Since in many cases it is impossible to reproduce production-run failures in house due to various reasons (privacy, execution environments, etc.), the common practice is that customers send back the logs generated by the failed system. Such logs are the sole data source (in addition to source code) for software engineers to troubleshoot the occurred failure. Based on what are in the logs, they manually infer what may have happened to narrow down the root cause.<br\/><br\/>Unfortunately, the above diagnosis process is mostly manual, very often a trial-and-error guess game and therefore is time-consuming, error-prone and also expensive in terms of both labor cost and system down time. Especially because log messages are added in an ad-hoc way, many of them do not provide precise, informative clues to help narrow down the root cause. Furthermore, the rapidly growing size and complexity as well as software aging has greatly affected modern software?s diagnosability.<br\/><br\/>To enable developers to quickly troubleshoot production-rune failures and shorten system downtime, we propose automatic log inference and informative logging to make real-world software more diagnosable. We not only will investigate new diagnosis tools that can analyze logs and source code together to help software engineers narrowing down the possible root causes, but also will explore new ways to automatically enhance software logging to make log messages more effective and efficient for diagnosis. As software has been widely used in our daily life, software reliability is becoming an important issue. Our proposed solutions will allow software engineers to quickly identify root causes and patches to fix the problem, which would significantly reduce the amount of system down time. As such, it benefits both software\/system vendors and computer users, especially those financial companies where an hour of down time can result in multiple millions of dollars loss in business.","title":"CSR: Small: Improving Software Diagnosability via Automatic Log Inferrence and Informative Logging","awardID":"1017784","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["551097"],"PO":["565255"]},"168418":{"abstract":"The likelihood of hidden, subtle bugs increases with growing design sizes, and reaching corner cases in large circuits and systems in order to expose such subtle bugs has become a daunting task. Verifying the correctness of the design is now a tremendous bottleneck in the overall design process. Critical to the effectiveness of stimuli generation is the quality of guidance and feedback provided during the search. The objective of this research is to elicit the swarming power to solve this very difficult problem, which has not been done in the past. Individual knowledge acquired during the search is extracted to benefit collective effort. This is enabled via cultivation of knowledge exchange, accumulation, and utilization. The intelligent partitioning and grouping of the state variables allows for the construction of many effective abstract navigation tracks in large designs, benefiting the swarm platform. <br\/><br\/>The development of new theories and algorithms will be an original contribution that will allow for transformative understanding of semi-formal verification and state space exploration, all in a rigorous framework. The theories and practice that will result from this work will not only enable us for a deeper understanding of collective effort, this project will directly promote the education of the involved students. In regard to outreach to under-represented students, the PI currently advises multiple women Ph.D. students (under-represented in engineering), and this project will continue to encourage aspiring female students to participate in the research endeavor. In addition, the PI will actively recruit summer minority interns from programs within Virginia Tech to take part in this project.","title":"SHF: Small: Exploring Swarm Intelligence for Design Validation","awardID":"1016675","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["494757"],"PO":["562984"]},"170750":{"abstract":"Abstract: The Variability Expedition<br\/>Project: Variability-Aware Software for Efficient Computing with Nanoscale Devices<br\/><br\/>As semiconductor manufacturers build ever smaller components, circuits and chips at the nano scale become less reliable and more expensive to produce ? no longer behaving like precisely chiseled machines with tight tolerances. Modern computing is effectively ignorant of the variability in behavior of underlying system components from device to device, their wear-out over time, or the environment in which the computing system is placed. This makes them expensive, fragile and vulnerable to even the smallest changes in the environment or component failures. We envision a computing world where system components -- led by proactive software -- routinely monitor, predict and adapt to the variability of manufactured systems. Changing the way software interacts with hardware offers the best hope for perpetuating the fundamental gains in computing performance at lower cost of the past 40 years. The Variability Expedition fundamentally rethinks the rigid, deterministic hardware-software interface, to propose a new class of computing machines that are not only adaptive but also highly energy efficient. These machines will be able to discover the nature and extent of variation in hardware, develop abstractions to capture these variations, and drive adaptations in the software stack from compilers, runtime to applications. The resulting computer systems will work and continue working while using components that vary in performance or grow less reliable over time and across technology generations. A fluid software-hardware interface will thus mitigate the variability of manufactured systems and make machines robust, reliable and responsive to the changing operating conditions.<br\/><br\/>The Variability Expedition marshals the resources of researchers at the California Institute for Telecommunications and Information Technology (Calit2) at UC San Diego and UC Irvine, as well as UCLA, University of Michigan, Stanford and University of Illinois at Urbana-Champaign. With expertise in process technology, architecture, and design tools on the hardware side, and in operating systems, compilers and languages on the software side, the team also has the system implementation and applications expertise needed to drive and evaluate the research as well as transition the research accomplishments into practice via application drivers in wireless sensing, software radio and mobile platforms. <br\/><br\/>A successful Expedition will dramatically change the computing landscape. By re-architecting software to work in a world where monitoring and adaptation are the norm, it will achieve more robust, efficient and affordable systems that are able to predict and withstand not only hardware failures, but other kinds of software bugs or even attacks. The new paradigm will apply across the entire spectrum of embedded, mobile, desktop and server-class computing machines, yielding particular gains in sensor information processing, multimedia rendering, software radios, search, medical imaging and other important applications. Transforming the relationship between hardware and software presents valuable opportunities to integrate research and education, and this Expedition will build on established collaborations with educator-partners in formal and informal arenas to promote interdisciplinary teaching, training, learning and research. The team has built strong industrial and community outreach ties to ensure success and reach out to high-school students through a combination of tutoring and summer school programs. The Variability Expedition will engage undergraduate and graduate students in software, hardware and systems research, while promoting participation by underrepresented groups at all levels and broadly disseminating results within academia and industry.","title":"Collaborative Research: Variability-Aware Software for Efficient Computing with Nanoscale Devices","awardID":"1028831","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["559405"],"PO":["562984"]},"172961":{"abstract":"The ways in which scientific knowledge is discovered and communicated openly online have changed dramatically over the last three decades, and especially in the last ten years. Multiple factors have contributed to massive growth in this area. The production of vast amounts of data and literature, coupled with the rapid development and advancement of the processing, storage, and communication technologies have made it both possible and necessary to use more computing technologies and methods in the research process. Computer-mediated discovery processes are being increasingly adopted and used by different scientific communities to explore and study a wide range of domains of knowledge, including all scientific disciplines. Computational scientific knowledge discovery is thus rapidly becoming practiced as a new form of scientific inquiry in the virtual environment, building upon and supplementing the research based on theoretical, experimental, and observational methods that preceded it. At the same time, many new models of open science have been developed that take much greater advantage of the capabilities of digital networks. When integrated together online, various types of open knowledge resources are forming incipient information ?commons? and knowledge environments, which can derive more value from the public investments in research. Of particular interest to this proposed project, such mechanisms can enable more efficient and effective applications of digital scientific knowledge discovery tools and techniques. A deeper understanding of the opportunities and barriers to such processes has the potential to accelerate the progress of scientific research, to support U.S. national competitiveness and increased productivity in information-intensive areas of research and its applications. An improved understanding of these issues also can enable research managers and policy makers to make much more informed decisions about the research enterprise, and to explain more clearly to policymakers and to the general public how the public investment in research and digital technologies advances broader socioeconomic interests.","title":"WORKSHOP: The Future of Scientific Knowledge Discovery in the Open Networked Environment","awardID":"1042078","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":["499569"],"PO":["565136"]},"170783":{"abstract":"Abstract: The Variability Expedition<br\/>Project: Variability-Aware Software for Efficient Computing with Nanoscale Devices<br\/><br\/>As semiconductor manufacturers build ever smaller components, circuits and chips at the nano scale become less reliable and more expensive to produce ? no longer behaving like precisely chiseled machines with tight tolerances. Modern computing is effectively ignorant of the variability in behavior of underlying system components from device to device, their wear-out over time, or the environment in which the computing system is placed. This makes them expensive, fragile and vulnerable to even the smallest changes in the environment or component failures. We envision a computing world where system components -- led by proactive software -- routinely monitor, predict and adapt to the variability of manufactured systems. Changing the way software interacts with hardware offers the best hope for perpetuating the fundamental gains in computing performance at lower cost of the past 40 years. The Variability Expedition fundamentally rethinks the rigid, deterministic hardware-software interface, to propose a new class of computing machines that are not only adaptive but also highly energy efficient. These machines will be able to discover the nature and extent of variation in hardware, develop abstractions to capture these variations, and drive adaptations in the software stack from compilers, runtime to applications. The resulting computer systems will work and continue working while using components that vary in performance or grow less reliable over time and across technology generations. A fluid software-hardware interface will thus mitigate the variability of manufactured systems and make machines robust, reliable and responsive to the changing operating conditions.<br\/><br\/>The Variability Expedition marshals the resources of researchers at the California Institute for Telecommunications and Information Technology (Calit2) at UC San Diego and UC Irvine, as well as UCLA, University of Michigan, Stanford and University of Illinois at Urbana-Champaign. With expertise in process technology, architecture, and design tools on the hardware side, and in operating systems, compilers and languages on the software side, the team also has the system implementation and applications expertise needed to drive and evaluate the research as well as transition the research accomplishments into practice via application drivers in wireless sensing, software radio and mobile platforms. <br\/><br\/>A successful Expedition will dramatically change the computing landscape. By re-architecting software to work in a world where monitoring and adaptation are the norm, it will achieve more robust, efficient and affordable systems that are able to predict and withstand not only hardware failures, but other kinds of software bugs or even attacks. The new paradigm will apply across the entire spectrum of embedded, mobile, desktop and server-class computing machines, yielding particular gains in sensor information processing, multimedia rendering, software radios, search, medical imaging and other important applications. Transforming the relationship between hardware and software presents valuable opportunities to integrate research and education, and this Expedition will build on established collaborations with educator-partners in formal and informal arenas to promote interdisciplinary teaching, training, learning and research. The team has built strong industrial and community outreach ties to ensure success and reach out to high-school students through a combination of tutoring and summer school programs. The Variability Expedition will engage undergraduate and graduate students in software, hardware and systems research, while promoting participation by underrepresented groups at all levels and broadly disseminating results within academia and industry.","title":"Collaborative Research: Variability-Aware Software for Efficient Computing with Nanoscale Devices","awardID":"1029025","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["517834"],"PO":["562984"]},"174952":{"abstract":"This proposal explores in a novel fashion an understudied social phenomenon - the nature and dynamics of short-term professional communities. Modern community-based systems such as social networking and recommender systems have to date been effectively limited in applicability to large, long-term communities. The research goal addressed by this proposal is to maximize information- and people-finding in short-term professional communities. The subject of the investigation is professional research conferences (a specific kind of small short-term community). The project will explore new methods to leverage information about user interests and contacts, which is already available from multiple external sources, and develop cross-cutting techniques for existing social technologies.","title":"EAGER: Personalization and social networking for short-term communities","awardID":"1052768","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[469259,"496622"],"PO":["564456"]},"161642":{"abstract":"As mobile phones become capable of performing increasingly complex and sensitive tasks, the loss, theft or destruction of such devices represents one of the most significant classes of security problems. This research improves the security of data stored on and generated by these devices by breaking the mandatory binding between mobile phones and hardware. In particular, this work limits the damage associated with this class of vulnerabilities not to the value of the data they transport but to the cost of the device itself. In this system, mobile phone users can seamlessly migrate software images of their phone to any device at their disposal, while data present on previously used devices is automatically encrypted or securely deleted. Phone images themselves are efficiently pushed into and pulled from the cloud, which also supports patching and the upgrade of phone images to occur both over the air and within the cloud itself, increasing the speed with which software vulnerabilities can be mitigated. In so doing, this approach allows network providers and users to adopt highly dynamic responses to security incidents.","title":"CAREER: Protecting User Data on Lost, Stolen and Damaged Mobile Phones","awardID":"0952959","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["549758"],"PO":["565327"]},"173984":{"abstract":"The proposed project will develop a new interdisciplinary methodology for both the analysis of user experience in virtual worlds and the design of such worlds. The methodology combines ideas from game design, computer science, information visualization, New Media Art and media theory. The project will combine two research efforts: The Scalable City developed in the Experimental Game Lab directed by Professor Sheldon Brown, and Cultural Analytics developed by the Software Studies Initiative directed by Dr. Lev Manovich. The Scalable City is an interactive artwork that uses custom computer graphics software to create a dynamically changing 3D urban environment. First, satellite imagery of real cities is manipulated through image processing routines to generate new, highly patterned terrains. After spatial analysis, areas are \"zoned\" for development using a variety of eccentric \"real estate development\" schemes - space filling curves, dense grids, mazes, and combinations of these forms. As a critical artwork, the Scalable City has been designed to challenge the existing conventions of 3D narrative environments. It engages the users in a narrative of discovery, not that of a story line, but of interacting with the world in self-reflective ways. Cultural Analytics is a computational method to quantitatively analyze patterns and rhythms in visual media such as photography, design, film, animation, choreography, and music composition. It has been developed specifically for humanities scholars of visual culture and media studies to harness the powers of computational methods to identify patterns of creativity. <br\/><br\/>Using the Cultural Analytics framework, Brown and Manovich propose to develop a new methodology for the analysis of users? activities and visual experiences in a multi-user version of the Scalable City. The Cultural Analytics Framework will be embedded into the Scalable City generative software. This new analytical software layer will enable the transformation of the virtual world in real-time in response to patterns in users? behavior and visual experience. At the same time, by incorporating the new analytics techniques in virtual world generation software, the project aims to advance the current research on how to create interfaces and simulations which analyze user performance and dynamically adapt based on the results of the analysis If successful, this research is likely to have transformative effects in a number of fields. Game designers, HCI researchers, and games and media scholars will be able to analyze, visualize and interpret the dimensions of user experiences with interactive time-based cultural artifacts such as video games, animated interfaces, and interactive artworks which are not captured with current analytics techniques such as network analysis (connectivity, load, and latency), econometrics on virtual economies, and profiling player game play.","title":"EAGER: A Cultural Analytics Framework for Identifying and Integrating Creative Patterns of User Behavior and Experience in the Scalable City Multi-User Virtual World","awardID":"1047812","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":[466693,"537136"],"PO":["565227"]},"163842":{"abstract":"In this project, the PI and his team will develop a new simulation framework to interactively model and visualize socio-economic and geometric characteristics of urban areas. The framework will consist of a synergistic collaboration of three different areas: behavioral urban modeling, probabilistic graphical modeling, and visualization and computer graphics. In machine learning and statistics, the area of probabilistic graphical modeling offers a flexible framework to build, estimate and simulate from models of substantial complexity and scale, with partially observed data. By accounting for uncertainty and interdependencies, including aspects of dynamic equilibrium that arise in modeling the complex spatio-temporal dynamics of urban areas, the PI argues there is significant potential for breakthroughs in modeling large-scale urban systems. Similarly, by integrating behavioral and geometrical dimensions of urban areas, he expects to exploit the power of behavioral simulations more effectively by filling in geometric details that behavioral models are not well suited to manage, and at the same time provide a powerful framework to generate 2D and 3D geometric representations of urban areas that are behaviorally and geometrically consistent. The PI will take advantage of massive datasets available for urban areas, including parcel and building inventories, business establishment inventories, census data, household surveys, and GIS data on physical and political features, and will fuse these data into a coherent and consistent database to support his modeling objectives. This data fusion will address imputation of missing data, accounting for complex spatial and relational connections among the data sources. The PI will evaluate the accuracy and usability of his system through several deployments in diverse contexts. The PI has elicited engagement from the Urban Land Institute, the European Research Council, and the Council for Scientific and Industrial Research. Several organizations in the San Francisco Bay Area in California and the Puget Sound region in Washington will serve as testbeds for the research. Finally, the PI will collaborate with other NSF-funded research projects, such as the Drought Research Initiative Network, in order to investigate correlations between urban development and water\/drought. <br\/><br\/>Broader Impacts: The results of this multidisciplinary project will have a transformative effect on the area of urban simulation, in that they will enable non-professionals as well as the general public to better understand urban phenomena. City planners, researchers, students, and citizens will be able to efficiently simulate urban processes not previously possible, and to visualize the effects of adopting different urban policies on urban livability and sustainability outcomes, and to address local and global concerns regarding equity, infrastructure, and economic development. The framework will provide interactive desktop and web-based interfaces for configuring urban scenario inputs to a simulation that may reach petabytes in data size, and to visualize the simulation results using 2D aerial views, 3D city walkthroughs, and choroplethic maps and tables of indicators portraying the simulated area. Thus, the work will also advance the fields of visualization and computer graphics, through development of new techniques for large-scale urban modeling and rendering. The PI will develop an open-source system to make the results of this research widely available.","title":"III: Medium: Collaborative Research: Integrating Behavioral, Geometrical and Graphical Modeling to Simulate and Visualize Urban Areas","awardID":"0964412","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["497161",438603],"PO":["565227"]},"172686":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040672","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["527253","517980","518109",463068,"475279"],"PO":["565090"]},"174501":{"abstract":"Applications such as traffic monitoring, mobile user management, and sensor networks need to process large volumes of updates while supporting on-line analytic queries. With large amounts of RAM, single machines are potentially able to manage hundreds of millions of items. With multiple hardware threads, as many as 64 on modern commodity multicore chips, many operations can be processed concurrently.<br\/><br\/>Processing queries and updates concurrently can cause interference. Queries need to see a consistent database state, meaning that at least some of the time, updates will need to wait for queries to complete. To address this problem, a variety of solutions are explored in which a RAM-resident snapshot of the database is taken at various points in time. Analytic queries operate over the snapshot, eliminating interference, but allowing answers to be slightly out of date. Several different snapshot creation methods are being developed and studied, with the goal of being able to create snapshots rapidl(e.g., in fractions of a second) while minimizing the overhead on update processing.<br\/><br\/>These problems are studied both for traditional server machines, as well as for multicore mobile devices. By keeping personalized, up to date data on a user's mobile device, a wide range of potential new applications could be supported while avoiding the privacy concerns of widely distributing one's location. The research focus is on how to efficiently utilize the many processing cores available on modern machines, both traditional and mobile devices. A primary goal is to allow performance to scale as additional cores become available in newer generations of hardware.<br\/><br\/>The website for this project can be found at http:\/\/www.cs.columbia.edu\/~kar\/snapshot.html","title":"EAGER: Rapid Updates and Snapshot-Based Queries Using Multicore Processors","awardID":"1049898","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["531167"],"PO":["563727"]},"172697":{"abstract":"This project is aimed at the design and experimental validation of a comprehensive clean-slate future Internet architecture. The proposed MobilityFirst architecture is motivated by the ongoing paradigm shift of Internet usage from today?s fixed PC\/host (client)?server model to emerging mobile data services and pervasive computing applications. The major design goals of the architecture are: mobility as the norm with dynamic host and network mobility at scale; robustness with respect to intrinsic properties of the wireless medium; trustworthiness in the form of enhanced security and privacy; usability features such as support for context-aware services, evolvability, manageability and economic viability. The key components of the MobilityFirst network design are: (1) separation of naming and addressing, implemented via a fast global dynamic name resolution service; (2) self-certifying public key network addresses to support strong authentication and security; (3) generalized delay-tolerant routing with in-network storage for packets in transit; (4) flat-label internetwork routing with public key addresses; (5) hop-by-hop transport protocols operating over segments rather than an end-to-end path; (6) a separate network management plane that provides enhanced visibility; (7) optional privacy features for user and location data; and (8) an integrated computing and storage layer to support programmability. The project?s scope includes architectural design, validation of key protocol components, testbed prototyping of the MobilityFirst architecture as a whole, and real-world protocol deployment on the GENI experimental infrastructure. The results of this project will provide architectural guidance for cellular-Internet convergence, and are expected to influence future technical standards in the networking industry.","title":"FIA: Collaborative Research: MobilityFirst: A Robust and Trustworthy Mobility-Centric Architecture for the Future Internet","awardID":"1040725","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[463098],"PO":["565090"]},"175843":{"abstract":"This project focuses on exploratory research towards the next generation of adaptive socio-technical crisis alerting and warning systems. Alerting systems inform entities affected by crisis ? schools, businesses, hospitals, and the public at large ? about impending dangers, the status of infrastructures, life lines, and available help and actions designed to reduce exposure to natural and human-induced threats ? e.g. evacuate, shelter-in-place etc. The eventual goal is to develop alerting systems that deliver an accurate message to the right targets in the right format and at the right time, however this requires a synergistic exploration of the challenges at multiple levels ? physical\/geographical, network and user levels. This effort is an initial exploratory effort that aims to meaningfully combine the three levels into effective alerting schemes. <br\/><br\/>Intellectual Merit: Specifically, this project offers a new model of geography based alert dissemination that incorporates both the geographical aspects and societal needs. While information needs are strongly correlated to the geographical location in the context of a natural or human induced disaster, this insight has never been fully exploited in the alert dissemination process. The principal investigator (PI) conjectures that societal\/user information in combination with geographical context can be used to improve the alert dissemination process. In particular, the research aims to enhance the structural properties of a network to represent both the societal and physical connectivity. This requires an understanding of which aspects of a social network are useful to map and maintain as the situation evolves. The research addresses the above interdisciplinary research issues via the following 3 steps. The first research task develops mechanisms to create and maintain a geo-aware overlay network, in order to model geographical correlations. In the second step, the geo-aware overlay network is enhanced to capture and represent societal characteristics by using a geo-social mapping process, and the outcome of this process is a geo-social overlay network. The final research task is that of effective utilization of the geo-social overlay network in the alerting process, which is adaptive to the given knowledge of potential failure, in order to support reliable dissemination at the societal scale in the presence of geo-correlated failures. The project includes a prototype implementation to test\/validate the research on a campus testbed.<br\/><br\/>Broader Impact: The research paves the way towards a new generation of socio-technical alerting systems that are far more effective than alerting mechanisms in use today and opens new avenues for interdisciplinary research on technologies for alerting systems. If successful the project will lead to new ways of leveraging the capabilities of existing network infrastructures and quickly repurposing them in emergency situations to provide critical situation awareness and disaster management information to diverse organizations and individuals. The PI has strong ties with entities that have a stake in the outcome of this research, including local governments, emergency management agencies and organizations at the state and federal level, and university- and agency-based researchers. A workshop with stakeholders including academic researchers from multiple disciplines, industry participants and government agencies is part of this project to discuss current processes, systems and challenges in disseminating emergency alerts in public. Outreach efforts will also raise awareness of the upcoming communication models for socio-technical alerting systems; it will help demonstrate the possibility of synergistically combining information about the disaster, infrastructure and the public to achieve the desired level of response.","title":"EAGER: GeoAlerting: An Exploratory Case Study in Socio-Technical Alerting","awardID":"1057928","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["499298"],"PO":["565090"]},"172587":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040083","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["470252"],"PO":["565090"]},"170046":{"abstract":"As the availability and size of digital information repositories continues to burgeon, the problem of extracting deep semantic structure from high-dimensional data becomes more critical. This project addresses the fundamental problem of transfer learning, in particular it investigates methods for aligning multiple heterogeneous data sets to find correspondences and extract shared latent semantic structure. Domains of applicability include automatic machine translation, bioinformatics, cross-lingual information retrieval, perceptual learning, robotic control, and sensor-based activity modeling. The proposed research will investigate a geometric framework for transfer learning based on finding correspondences between data by aligning their projections onto lower dimensional manifolds. The proposed research will investigate a broad spectrum of approaches to manifold alignment, including one-step vs. two-step alignment, instance-based vs. feature-based alignment, semi-supervised vs. unsupervised alignment, and finally one-level vs. multi-scale alignment. Visualization tools that use alignment information will be developed to facilitate interactive learning from data analysis. To aid the processing of large data sets, the parallel computational power of modern graphics processing units (GPUs) will be exploited.<br\/><br\/>Given the rapidly increasing availability of digital data sets from a diverse variety of domains, the scientific question of extracting knowledge from massive unstructured information repositories is becoming ever more critical. The proposed research combines the study of machine learning algorithms for discovering latent correspondences between seemingly disparate data sets, and the development of visualization tools to aid human interpretation of high-dimensional data. Empirical studies on a variety of real-world applications will be carried out, ranging from bioinformatics, Internet web archives, multilingual text, and sequential time-series data sets. The broader impacts of the proposed research include algorithmic advances in the analysis and visualization of high-dimensional data, and empirical studies on a variety of real-world applications. The data sets and software developed in this research will be disseminated through the web. The research will be communicated through a variety of conferences, workshops and seminars in several disciplines ranging from computer science, engineering, mathematics, and statistics. The PIs will make significant efforts to recruit underrepresented groups, including women and other minorities, in this research. New course material on advanced data analysis and visualization will be developed based on the proposed research.","title":"Manifold Alignment of High-Dimensional Data Sets","awardID":"1025120","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}}],"PIcoPI":["544475","521885"],"PO":["565286"]},"174897":{"abstract":"In many practical situations heuristic algorithms reliably give satisfactory solutions to real-life instances of optimization problems, despite evidence from computational complexity theory that the problems are intractable. The central goal of this project is to contribute to an understanding of this seeming contradiction, and to put the construction and evaluation of heuristic algorithms on a firmer footing.<br\/><br\/>The project will develop a general empirical method for selecting an optimal choice of parameters and subroutines within a well-defined heuristic algorithmic strategy. The method is empirical, and assumes the availability of a supply of typical problem instances which can be used to train the algorithmic strategy and evaluate its performance. The search for optimal parameters and subroutines will be treated as an optimization problem in its own right.<br\/><br\/>The project will introduce the concept of an implicit hitting set problem, demonstrate that a broad class of NP-hard combinatorial optimization problems can be framed as implicit hitting set problems, and systematically derive and evaluate heuristic algorithms for three problems in this class: multi-genome alignment, the feedback vertex set problem, and the feedback arc set problem.<br\/><br\/>Further examples of heuristic algorithm design will be drawn from computational molecular biology, where a long-term goal is to extract, from large data sets, information about how proteins work together to carry out life processes at a cellular level. This investigation will focus on protein-protein interaction (PPI) networks, in which the vertices are the proteins within a species and the edges indicate direct interactions between proteins. The goal will be to discover conserved protein modules: richly interacting sets of proteins whose patterns of interaction are conserved across two or more species. Such modules correspond to subgraphs of a PPI network that have many internal edges, relatively few external edges, and a structure that persists from one species to another.There are several existing software packages for finding conserved protein modules, and the algorithms developed in this project will be compared systematically with these packages.<br\/><br\/>This research leads naturally to fundamental abstract problems in computational graph theory, such as the problem of partitioning a graph into vertex-disjoint subgraphs with a high density of edges, or the colorful subgraph problem, in which each vertex of a graph is assigned a color, and the goal is to find a small connected subgraph containing at least one vertex of each color. The project will systematically derive and evaluate heuristic algorithms for these problems.<br\/><br\/>Since heuristic algorithms are an essential tool for the practical solution of NP-hard optimization problems, and since most optimization problems arising in practice are NP-hard, the attempts to systematize the creation, comparison and validation of heuristic algorithms may have repercussions for many application areas beyond those pursued in this proposal.","title":"CCF: AF: EAGER: Systematic Construction of Heuristic Algorithms for Combinatorial Optimization Problems in Biology","awardID":"1052553","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":["561682"],"PO":["565223"]},"164502":{"abstract":"Computationally-mediated civic participation is emerging as a solution to contemporary problems associated with economic and social issues such as healthcare, energy sustainability, education, environmental protection, and disaster response. The NSF-funded research project conducted by Ben Shneiderman, Alan Neustadtl, and Catherine Plaisant at the University of Maryland will study reasons for successes and failures of the community safety system, Nation of Neighbors. The results will enable interventions to shift the balance towards increasing success. One product of the research will be a computer-based Community Analysis Visualization Environment (CAVE) that will enable community managers to use a visual analytic toolkit to take the pulse of their communities by identifying effective and ineffective components of the community participation program, and will enable researchers to compare large numbers of communities to understand the features that distinguish successful from failing community participation programs. The project will test the four-stage Reader-to-Leader Framework -- which assumes that participation moves from reader to contributor to collaborator to leader, with fewer and fewer participants moving into each subsequent stage -- by studying community manager strategies for coping with the practical challenge of increased participation as well as threatening disruptions caused by external events, malicious attacks, harmful rumors, and disaffected members. <br\/><br\/>In addition the results will have general implications for many computationally-mediated civic participation systems such as those designed for coping with natural disasters (earthquakes, toxic waste discharges, etc.), medical outbreaks (food poisoning, flu, pandemics, etc.), and human threats (terrorists, serial killers, bombers, arsonists, etc.). The computational tools developed for the project will also be useful to researchers studying community participation networks. The research may also provide useful insights into the working of other types of social networks and might have implications for organizations where information is shared by large numbers of people, such as hospitals and school districts.","title":"SoCS: Supporting A Nation of Neighbors with Community Analysis Visualization Environment","awardID":"0968521","effectiveDate":"2010-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["527292",440679,"527290"],"PO":["497399"]},"174469":{"abstract":"Botnets are typically used to stage denial of service (DDoS) attacks against commercial sites. DDoS attacks can disable critical infrastructure across the globe. Few effective countermeasures exist. A proposed set of experiments will quantify factors responsible for DDoS vulnerability and will verify solutions for neutralizing those attacks. In addition, repressive nations use network monitoring to identify and prosecute their opponents. Timing vulnerabilities in anonymity systems put dissidents in repressive regimes in potential danger. Flaws in anonymity systems will be quantified and a new approach to safeguarding privacy will be confirmed.<br\/><br\/>The GENI network infrastructure enables security research that has not been possible before due to potential disruption to production networks. This project will carry out a number of security and privacy experiments that include:<br\/><br\/>-WiMAX DDoS analysis with analysis of variance finding vulnerable control parameter settings;<br\/>-Privacy\/Anonymity side-channel Hidden Markov Models (HMMs) will be inferred to break anonymity systems;<br\/>-DDoS traffic measurement to map attack severity vs. network topology;<br\/>-Side-channel vulnerability removal protocol tested at scale; and <br\/>-DDoS countermeasure testing to neutralize DDoS attacks.<br\/><br\/>This research has the ability to change the landscape in regards to network security and privacy. Graduate students will have abundant opportunities to carry out experiments on a network infrastructure that allows them to fully explore these research challenges at scale.","title":"EAGER-GENI Experiments on Network Security and Traffic Analysis","awardID":"1049765","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["474900","561722"],"PO":["564993"]},"168804":{"abstract":"Consumer mobile devices such as smartphones have been proposed for use in a wide range of settings, including citizen journalism, citizen science, and domestic eldercare. Re-purposing consumer devices in these domains is appealing because consumer devices offer a low-cost, highly-scalable platform for mobile sensing that can expand coverage and reduce costs.<br\/><br\/>At the same time, these application scenarios raise new data-integrity and privacy challenges. Organizations currently rely on non-technical economic and legal frameworks to establish trust in sensed data: integrity guidelines specify how data can be gathered and handled, and data sources are held accountable through binding legal agreements. Unfortunately, these frameworks are not anonymous and do not scale to the billions of world-wide mobile-phone users.<br\/><br\/>Trustworthy mobile sensing offers a technical way to ensure data integrity without sacrificing anonymity. This project investigates building a platform for trustworthy mobile sensing using Trusted Platform Module (TPM) hardware. Three trusted software subsystems sit on top of TPM functionality: 1) a trusted path for sensor data from sensing hardware to untrusted applications' address spaces, 2) a trusted runtime for transparently monitoring untrusted applications as they execute, and 3) a trusted post-facto analysis engine for comparing untrusted applications' input sensor data to the digital artifacts they generate. Taken together, this combination of hardware and software provides a strong foundation for reasoning about the trustworthiness of anonymous, user-generated content.","title":"TC: Small: Trustworthy Mobile Sensing","awardID":"1018547","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[451799],"PO":["564223"]},"174007":{"abstract":"Algorithms that find good partitionings of large, sparse, and unstructured graphs represent an important technique for developing effective and computationally efficient approaches for problems that need to process and analyze such graphs. As a result, they have found extensive applications in many diverse areas such as high-performance computing, scientific computing, VLSI design, data mining, pattern recognition, computer graphics, network analysis, database and geographical information systems, operations research, optimization, and scheduling. This project will develop and make available a software infrastructure that provides a broad range of graph partitioning tools for large, sparse, and unstructured graphs. This infrastructure will be built using modern object-oriented software engineering principles that will facilitate their modularity, user-extensibility, maintainability, and community development; and incorporate novel graph partitioning algorithms that can scale to graphs containing billions of nodes and facilitate the partitioning of different types of graphs on different computing architectures. This software infrastructure will enable the efficient execution of scientific numerical simulations on parallel systems containing tens of thousands of processing nodes and billions of mesh elements, the development of divide-and-conquer approaches for synthesizing very large VLSI circuits on different chip architectures, the clustering and analysis of very large graphs and networks, and the solution of a wide-range of partitioning problem instances involving different objectives and constraints.<br\/><br\/>This will positively impact numerous science & engineering disciplines, commercial companies, non-profit organizations, and individuals that benefit from the results of the computations that are enabled and facilitated by the various application domains that rely on graph partitioning. Finally, the project integrates the research with an educational plan focused on undergraduate and graduate education and mentoring through courses, software engineering projects, summer institutes, and research opportunities; and a community development and an outreach plan designed to promote broad adoption of the resulting software infrastructure by providing extensive documentation, online tutorials, and organizing meetings at relevant conferences and workshops.","title":"SI2-SSE: Software Infrastructure For Partitioning Sparse Graphs on Existing and Emerging Computer Architectures","awardID":"1048018","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["531622","536974"],"PO":["564388"]},"174249":{"abstract":"The lack of access to visual information like text labels, icons, and colors frustrates blind people and severely decreases their independence. Current access technology uses fully-automatic approaches to address some problems in this space but is error-prone, limited in scope, and expensive. Blind people who can afford to do so must carry multiple special-purpose portable devices with different audio and tactile interfaces in order to access critical data about their environment such as product information from bar codes and location information via GPS. These devices would likely be used more often if they had greater functionality and failed less often. Providing a fallback by making it easy to consult a human assistant could be part of the solution. The PI's talking VizWiz application for mobile phones is one such prototype that connects blind people to remote human workers who answer general questions about the users' visual environments. VizWiz currently allows blind users to take a picture, speak a question, and receive answers back quickly. Preliminary findings have demonstrated the potential advantages of including humans in the loop to help overcome visual problems that are still too difficult to be solved by automatic approaches alone, but questions remain about the efficacy, privacy, speed, and cost of these approaches. In this project the PI will seek answers to some of these questions, by conducting a longitudinal study of VizWiz with blind people to better understand how the application might fit into their everyday lives. He will endeavor to determine how users' existing social networks might be employed as a source of answers using applications for Facebook and Twitter. And he will seek to define new services with appropriate interfaces that let users mediate between automatic and human-powered remote sources for answers. A mobile accessibility solution using both automated and human Web services represents a significant advance in accessibility but presents challenging user interface questions. Understanding issues such as those enumerated above is necessary for human-powered services to be accepted as part of assistive technology. <br\/><br\/>Broader Impacts: This exploratory research represents a new paradigm in human-computer interaction in which humans are both clients and providers. VizWiz has the potential to improve the independence of blind people, and may be both less expensive and more sustainable than current accessibility solutions. This project will improve our understanding of the types of tools that would be useful for blind people regardless of what is possible today with automatic computer vision, and will help us better understand how to recruit people to answer questions while respecting the asker's values. The research will involve blind people throughout; the resulting interfaces and functionality will be evaluated by blind people in the world going about their everyday lives. The interfaces, applications, and framework created and improved as part of this project will be released as open source so other researchers may build on the PI's results. Project outcomes will be broadly applicable to other problems where automated solutions may occasionally need human intervention.","title":"EAGER: VizWiz - Enabling Blind People to Answer Visual Questions On-the-Go with Remote Automatic and Human-Powered Services","awardID":"1049080","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["557943"],"PO":["565227"]},"173039":{"abstract":"The University of Virginia proposes to leverage and scale the Tapestry Workshops, a successful series of workshops for high school computer science teachers that includes training in both content and in methods for attracting and retaining women and minority students. After participating in this workshop, teachers report success in recruiting more students - particularly girls and minority students - to their classes. With this proposal, the Tapestry workshops will be scaled for national impact with a new workshop, Teachers Attract Girls to high school CS (TAG HSCS) that will train \"trainers\" to organize new Tapestry-type workshops in their own geographic regions. Specifically, the proposed effort will recruit organizers for train-the-trainer workshops to be held in conjunction with SIGCSE, the Grace Hopper Celebration of Women in Computing, and the Regional Hopper Celebrations; it will create community among those organizers for sharing resources; it will replicate the Tapestry workshops around the country; and it will develop and distribute an NCWIT Program-in-a-Box for offering Tapestry-type workshops. The community of organizers will be sustained in part through attendance and sessions at the annual NCWIT meetings. The project will ensure workshop quality by reviewing and consulting on plans, providing tested content, and funding participants for the first implementations. Together these trainers and the teachers who participate in their workshops have the capacity to have a broad impact on the entry and early experiences of underrepresented students in computing.","title":"BPC-LSA: Training High School CS Teachers to Attract More & Diverse Students","awardID":"1042452","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[464116,"513746"],"PO":["561855"]},"168815":{"abstract":"This project in Human-Centered Computing is a study of micro-coordination and interactions with technology of young adults. It examines the emotional, personal, interpersonal and behavioral effects that technology design and use practices have on young adults in the course of solving micro-coordinational problems. The research will explore and evaluate the theory that (a) the fundamental experience of growing up in America today has been altered by what young people have not experienced but which earlier generations did experience, (b) these aspects of interaction are discounted in the public discourse about technology, (c) assumptions in the design of technology that contribute to these problems have not been sufficiently examined, and (d) ultimately the design of technologies can address some of the same problems to which it also contributes.<br\/><br\/>To build a system architecture that accommodates complexity and richness, this research will use technology experimentally to create and solve palpable problems in the micro-coordination of interpersonal interaction. It will explore four themes intimately tied to social negotiation and coordination: (1) exerting social agency, (2) regulating interpersonal attention, (3) managing conflict, and (4) establishing the moral order. Each of these themes represents a kind of interpersonal challenge that children in the past have learned about through playground and street games. That is, children in the playground encounter situations in coordination and social negotiation that allow them to experiment taking agentic stances with respect to others and seeing the results. They witness the consequences of their actions for other people and they see how different stances make them feel about themselves. They may experience pride, shame, alienation, affiliation, comfort, achievement, and hatred. They hit the boundaries between self and other, rules and volition, individual and group, transgression and concession, over and over again. <br\/><br\/>Previous work has shown that young adult populations, deprived of sustained, significant playground and street experiences during childhood, exhibit some unexpected behaviors, such as failing to take charge of creating meaningful coordinative experiences when the computer does not give them guidance. This research will examine changes to technologies that influence such behaviors by making the interactional challenges a direct focus, that is, a \"seam\" in the technology. The result is expected to be a much better picture of human micro-coordination in relationship to challenges in pervasive, distributed computing and the interconnections between behavior and emotional, personal, interpersonal states. Thus, the research will address the societal challenge of maintaining the skills for connectivity in an increasingly distracted, disconnected world.","title":"HCC-Small: Human Micro-Coordination in a World of Pervasive Computing: Understanding Emotional, Personal, Interpersonal and Behavioral Interconnections","awardID":"1018607","effectiveDate":"2010-09-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["563439","563440"],"PO":["564456"]},"174029":{"abstract":"The University of Florida is awarded a grant to implement and evaluate the latest methods for identifying the evolutionary history of gene duplications and losses on the Microsoft Azure cloud computing platform, and will use these methods to reconstruct the history of whole genome duplications in plants. One of the greatest challenges in evolutionary biology is to identify genetic mechanisms responsible for adaptive changes and species diversification. The availability of large-scale genomic data sets from many diverse species provides unprecedented opportunities to identify such important genetic changes. Gene duplication plays a key role in gaining new gene functions and, consequently, adaptive innovations. However, in order to link gene duplications with adaptive changes, it is necessary to determine when in evolutionary history the duplications took place. Recently developed model-based methods enable scientists to map the locations of gene duplications and loss events within a species phylogeny. However, these methods are computationally intensive, and consequently, have only been implemented for small data sets. Cloud computing through the Microsoft Azure platform offers the ideal system in which to extend the implementations of these methods to incorporate full genomic data sets from many organisms and to keep pace with the rapid accumulation of new genome sequences. Education and training in computational biology are a major component of this project. Not only will this work motivate new research into modeling gene evolution and enable enormous analyses to identify potential genomic innovations, it also will provide unique opportunities for cross-disciplinary training for a post-doc and graduate student. Furthermore, educational resources on the uses of cloud computing for large-scale bioinformatics analyses will be developed for the classroom and internet, and a workshop on cloud computing for evolutionary analyses will be held in conjunction with a conference of evolutionary biologists.","title":"CiC: EAGER: Inferring Pattern and Processes of Genome Evolution Through Cloud Computing","awardID":"1048217","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8010","name":"Computing in the Cloud"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":["546284","546265","530024","538607","514664"],"PO":["565272"]},"168716":{"abstract":"In developing variants of natural proteins with improved properties and activities, protein engineers are confronted with large, complex design spaces. The degrees of freedom for producing variants mirror nature but can be specifically targeted experimentally, choosing parent proteins, replacements for some amino acids (site-directed mutation), and locations for crossing over between parents (site-directed recombination). A set of choices, constituting a design, can be evaluated by multiple disparate criteria, including consistency with evolutionary information, energetic favorability with respect to a three-dimensional structure, and incorporation of specific characteristics distinguishing functional subclasses. Unfortunately, the different evaluation metrics may be complementary or even contradictory, and the prior information on which they are based is incomplete, so that the metrics are only more or less accurate in predicting the real-life quality of the designs.<br\/><br\/>The overall goal of this project is to develop efficient methods to characterize complex protein design spaces and optimize high-quality designs for experimental evaluation. A combinatorial protein engineering approach will be pursued, experimentally constructing a library of related variants and assaying them for properties of interest. Potential scores will evaluate a possible library (without explicitly enumerating its members) with respect to prior information from sequence, structure, and functional subclass. To account for disparate evaluation metrics, design algorithms will focus on the<br\/>identification of Pareto optimal designs, those for which no other design is as good or better with respect to all desired criteria. To account for incomplete prior information, design algorithms will trade off between exploitation of the prior information and broader exploration of the design space, seeking to identify a diverse set of designs, each with a diverse set of variants. Markov Chain Monte Carlo sampling algorithms will characterize the overall design space by generating choices for the degrees of freedom and evaluating the designs with the potential scores, using the scores and diversity metrics to appropriately explore the space. Exact algorithms will more precisely focus on regions of interest, dividing and conquering the design space and employing combinatorial optimization algorithms to identify Pareto optimal designs.<br\/><br\/>The design space approach provides a powerful new mechanism to address protein engineering applications, enabling the engineer to explicitly evaluate and optimize for trade-offs among important criteria and considerations. Interactive tools will help engineers navigate through the regions of interest, visualize designs and perform \"what-if\" analyses, and compare and contrast Pareto optimal designs. A design space repository will enable sharing of analyses and underlying data. The tools and repository will support protein engineering for a range of activities in the national interest, including biosensors, production of novel biological therapeutics and novel enzymes for green chemical synthesis, energy extraction, and bioremediation. As part of the project, the mechanism will be put to use in the engineering of soluble and robust cytochrome P450s that employ the inexpensive and non-toxic hydrogen peroxide to hydroxylate steroids and multi-ring compounds that mimic estrogenic (feminizing) steroids in the environment without the need for living cells or protein cofactors. Such enzymes would be valuable as tools for chemical synthesis, waste treatment, and bioremediation.<br\/><br\/>This project provides an ideal venue to impart cross-disciplinary training to students by illustrating how computational techniques can be fruitfully integrated with experimentation in answering important biological questions. Aspects of the project will be used in both undergraduate and graduate courses, from an introductory biology course to an advanced bioinformatics course. The project itself will provide the opportunity for inter-disciplinary research training for graduates and undergraduates, including those from underrepresented groups.","title":"III: Small: Collaborative Research: Analysis of Multi-Dimensional Protein Design Spaces with Pareto Optimization of Experimental Designs","awardID":"1018110","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["461949"],"PO":["565136"]},"168606":{"abstract":"Decentralized architectures for decision-making are coming to the fore as more and more distributed infrastructures are deployed to address current challenges and needs of society, including ?smart grids? for energy distribution, sensor and actuator networks for ecological monitoring and control, sustainable mass transportation systems, etc. The objective is to ensure that local actions at the nodes result in coherent collective behavior of the network. Systems of this type operate in highly uncertain environments that are noisy, unpredictable and possibly subject to adversarial disturbances. The goal of this research project is to develop a comprehensive theoretical and algorithmic framework for real-time adaptive decision-making in such large-scale systems under resource and cost constraints.<br\/><br\/>Online decision-making is concerned with real-time sequential planning in the presence of model uncertainty, nonstationarity, and possibly adversarial disturbances. The investigators study a novel extension of this paradigm to decentralized settings, where the actions have to be taken at the nodes of a large network, and the nodes only have access to noisy local information. The research entails explicit consideration of a temporally varying environment with a priori unknown dynamics; analysis and application in settings with significant model uncertainty, potential unmodeled statistical dependencies in observations either across the network nodes or over time, and possible adversarial contamination of data; and accounting for the influence of the decisions and network actions on the surrounding environment. The theoretical component of the project captures the impact of decentralization on the quality of the decision-making; the algorithmic component is to develop, analyze, and implement algorithms that come as close as possible to the derived theoretical bounds.","title":"CIF: Small: Distributed Online Decision-Making in Large-Scale Networks","awardID":"1017564","effectiveDate":"2010-09-01","expirationDate":"2012-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["550641","541985"],"PO":["564924"]},"168727":{"abstract":"This project investigates effective and resource efficient establishment of connectivity among disjoint wireless sensor network (WSN) segments. The segments can belong to a structurally damaged network caused by the failure of multiple sensor nodes. In addition, the segments can simply be standalone WSNs that are normally operated by different agencies and are to be federated to serve a common application. The objectives of this project are to develop novel solutions for various aspects and contexts of the federation problems, to create a prototype for validation and to share the results\/experience with application designers. <br\/><br\/>The technical approaches consider the availability of resources such as mobile sensors, mobile and static gateways and their count. Both optimal and heuristic solutions for repositioning of mobile sensors and placement of mobile gateways are studied to establish connectivity as well as achieving some desired performance (i.e., QoS). Finally, the results are validated via a real test-bed consisting of sensors and mobile robots. <br\/>This project will boost the effectiveness of many civil and scientific applications. Example of such applications include crisis management, where existing WSNs may suffer an extensive loss of nodes due to fire, flooding, debris, etc., or when the services of networks owned or controlled by different parties or agencies need to be aggregated to assess in search-and-rescue. The results are made available in various forms including archival publications, tutorials and web-based resources. The project is enriching the curricula at UMBC and SIUC through hands-on projects and attracting K-12 students via prototype demonstrations.","title":"NeTS: Small: Collaborative Research: Federating Disjoint Wireless Sensor Networks","awardID":"1018171","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["534304"],"PO":["565303"]},"168617":{"abstract":"Several modern data mining applications involve predictive modeling on large <br\/>amounts of multi-relational data with added structures such as product <br\/>hierarchies or social networks among customers. The broad goal of this proposal <br\/>is to develop a comprehensive framework for predictive modeling on large, <br\/>heterogeneous, multi-relational data based on \"Simultaneous Decomposition and <br\/>Prediction\" (SDaP) approaches that iteratively partition the problem into more <br\/>homogeneous and manageable pieces while concurrently building multiple <br\/>predictive models, one for each piece. Such approaches lead to simpler and more <br\/>accurate solutions. The proposed algorithmic strategies that determine how many <br\/>models to learn and where they should apply, which data to discard and which to <br\/>keep, how to learn multiple related tasks defined on multi-modal data, and how <br\/>to scalably implement the solutions on distributed computers, provide practical <br\/>solutions to certain real-world problems for which current learning and data <br\/>mining techniques are severely lacking. Application domains of ecology, bio-<br\/>informatics, market research and web mining are specifically identified and <br\/>targeted. <br\/><br\/>There are two broad research impacts of the proposed project: (a) it further <br\/>vitalizes the research in data mining towards better algorithms for predictive <br\/>modeling on rich and heterogeneous multi-modal data, and (b) provides and <br\/>promotes the SDaP approach as a fundamental data analysis tool across multiple <br\/>disciplines. The PI will organize a workshop and offer a tutorial at major data <br\/>mining conferences to foster and promote research on various aspects of SDaP <br\/>analysis. Moreover, the curated complex datasets and software developed under <br\/>this project will be shared with the scientific community via a public web site <br\/>as part of the proposed one-of-a-kind multi-relational data benchmarking <br\/>facility. The PI will further develop a novel graduate course on Modeling and <br\/>Analysis of Complex Data. Outreach modules that illustrate data analysis <br\/>concepts and capabilities at levels appropriate for pre-college students will <br\/>also be developed. For further information see the project web site at the URL:<br\/>http:\/\/www.ideal.ece.utexas.edu\/projects\/sdap\/","title":"III: Small: Simultaneous Decomposition and Predictive Modeling on Large Multi-Modal Data","awardID":"1017614","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["485856"],"PO":["565136"]},"168738":{"abstract":"An individual's genetic makeup, inferred by means of DNA sequencing, will help determine the individual's susceptibility to a broad range of chronic and acute diseases or disorders, enable the discovery and clinical testing of new pharmaceutical products, and generally personalize and improve the delivery of health care. Before the promised benefits of personalized medicine come to fruition, DNA sequencing technology must become fast, affordable, and reliable. High cost and labor intensive nature of conventional sequencing technology render it unfit for routine sequencing tasks. Recently developed sequencing-by-synthesis is a novel high-throughput technique addressing these obstacles -- currently, it achieves a cost reduction of two orders of magnitude as compared to the conventional method. However, fidelity and sequence read-lengths of sequencing-by-synthesis are inferior to those of the costly conventional technology, and its overall performance is insufficient for most medical studies.<br\/><br\/>The goal of this research is to develop signal processing techniques which enable accurate and reliable DNA sequence detection in sequencing-by-synthesis systems. The investigator specifically aims to: (1) Develop mathematical models of sequencing-by-synthesis process and derive techniques for inferring parameters of such models. (2) Design computationally efficient algorithms for optimal DNA sequence detection in sequencing-by-synthesis systems. (3) Validate the obtained theoretical results on experimental data. The results of the outlined work are expected to have a major impact on the development and applications of high-performance affordable DNA sequencing.","title":"CIF:Small:Next Generation DNA Sequencing: Signal Processing Perspectives","awardID":"1018235","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["550783"],"PO":["564898"]},"168859":{"abstract":"The goal of the proposed research is to develop and evaluate a new voice<br\/>source model based on physiological observations of the vocal folds of 30 adult speakers. Shortcomings of existing source models can be in part attributed to the way in which they were developed: based on limited data from a few speakers, without direct physiological observations, and without perceptual validation. A larger dataset would help in not only developing a source model that could account for a range of voice qualities within and across speakers, but also result in an understanding of how and which model parameter(s) are speaker and\/or gender specific. Model development will consider the perceptual effects of the model's parameters from the earliest stages.<br\/>A better source model might also improve the performance of speech processing algorithms such as text-to-speech synthesis (TTS). Typically in the development of such algorithms, the emphasis has been on acoustic features related to the speech spectral envelope. The acoustics of the voice source, on the other hand, have received less attention. <br\/>The proposed work involves: 1) recording high-speed images of vocal fold<br\/>vibrations with simultaneous audio recordings from 15 male and 15 female speakers, 2) extracting glottal area functions from the images to parameterize a new voice source model, 3) performing perception experiments to uncover which model parameters are perceptually salient, and 4) using the new voice source model in TTS. <br\/>The project's interdisciplinary team (with expertise in modeling, synthesis, recognition, phonetics, and psycholinguistics) is uniquely qualified to conduct this transformative research.","title":"RI: Small: A New Voice Source Model: From Glottal Areas to Better Speech Synthesis","awardID":"1018863","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[451934,"558131","531681"],"PO":["565215"]},"168628":{"abstract":"Is it possible to delegate the processing of your data to a party you do not completely trust? What if you do not want to give full access to your data to such party? Or what if the computation you delegate is so sensitive that you must make sure the result is correct, but must do so using only very limited computational resources (which is the reason you delegated the computation in the first place)? These questions are at the core of the usual tension between convenience and availability on one hand and security and privacy on the other. These questions are acquiring a particularly urgent importance as we move towards widespread acceptance of cloud computing, a paradigm where businesses buy computing time from a service, rather than purchase and maintain their own computing resources. These issues also arise from the proliferation of mobile devices, such as smart phones and netbooks: computationally weak devices which might outsource computationally intensive operation, e.g., a cryptographic operation or a photo manipulation, they are not able to perform on their own.<br\/><br\/>To put everything on line, \"in the cloud,\" without some security and privacy provisions, is to risk an Orwellian future. That is why, for example, privacy laws might require to encrypt medical records before storing them off-site. But once those records are encrypted, how can we allow an outside provider to process them for say billing, or epidemiologic research? Similar trust issue may come up even when handling data which is not private: if we outsource complex market analysis to a financial firm, how do we verify that the final recommendations reflect the actual market data, and not the financial interests of the firm itself? Because safeguarding the security of outsourced computation can be critical (think of military applications) we need to protect ourselves also from non-malicious behavior such as a bug in the code run by the delegated party.<br\/><br\/>When the Internet evolved from a relatively small network of academic and military nodes into an incredibly large public network, secure protocols like IPSec and SSL (developed through a fruitful research collaboration between academic and industrial centers) enabled us to fully develop its economical and financial potential through e-commerce and e-business. Today we stand at a similar crossroad: the success of the cloud computing paradigm is predicated on our ability to secure it. Security and privacy are not just desirable properties when it comes to outsourcing computation, but they are essential enablers for the paradigm itself. Once again a concerted research effort is needed that can capitalize on the collaboration between academia and industry to design and deploy secure solutions for cloud computing applications.<br\/><br\/>We propose therefore a research program to explore cryptographic techniques, algorithms and protocols needed in the design of secure outsourced computation mechanisms. When it comes to the security and privacy concerns associated with outsourced computation, we can summarize them in the following very important two questions: (a) Is it possible to protect the privacy of the computation input:} in other words, can an outside party compute for us, without learning our private data? (b) Can you trust the result of the computation: in other words, how does one verify that the outside party performed the computation correctly without investing too many computational resources (without, for example, redoing the computation from scratch)? The goal of this project is to analyze these and other security questions related to cloud computing, and propose new cryptographic schemes and protocols that can contribute to their solution. We believe that this research project will require new approaches and new ways of thinking about the problems themselves, and about the mathematical tools at our disposal. It will contribute fundamental advances to our knowledge and understanding of encryption, authentication and the mathematics underlying them.","title":"TC: Small: Cryptographic Algorithms for Security in Cloud Computing Applications","awardID":"1017660","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[451369,"451371",451371],"PO":["565239"]},"168749":{"abstract":"The general objective of this research is to address the challenges of protecting adolescent online safety. This work proposes a set of research activities to investigate three aspects of online safety issues for the adolescent cohort: conceptualization, intervention, and education. The specific goals are to: 1) conceptualize information privacy for the adolescent cohort; 2) assess the effectiveness of parental mediation strategies; and 3) generate design recommendations for effective designs of online safety awareness and training programs. The intellectual merit of this work lies in both the strength of the interdisciplinary project team and the significance of the problem addressed. The team includes a broad range of expertise in the domains of information privacy and security, psychology, human-computer interaction, and family and youth resiliency and policy. This work will offer new insights that can address the issues of protecting children online safety as well as study the human-computer and human-human (parent-child) interactions that are aware of the well-being of families. <br\/><br\/>The findings will have a broader impact in increasing the online safety of adolescents. This work includes significant community outreach and dissemination, involving parents and adolescents from a wide demographic variety in terms of gender, income, ethnicity, and rurality. The proposed intervention approaches will strengthen the trust within parent-child relationship, by enabling parents to show empathy with a child's perspective, and provide choices and options whenever possible. This work will be the first step towards a more ambitious research and intervention project that the team plans to develop in collaboration with national non-profit organizations.","title":"TC: Small: MySpace Generation's Online Safety: Adolescent Attitude and Behavior, Parental Mediation, and Educational Intervention","awardID":"1018302","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[451657,"550223","549540","549541","549541"],"PO":["565136"]},"168518":{"abstract":"Despite its enormous success, today's Internet suffers certain well-known shortcomings, and is increasingly strained to meet the high availability, reliability, mobility, manageability and security demands of modern applications and services. In contrast, Ethernet is largely plug-&-play; however, this traditional layer-2 technology can hardly meet the scale as well as the efficiency and robustness requirements of emerging and future large, dynamic networks such as data centers and cloud-computing services.<br\/><br\/>In this project, the PI is developing VIRO --- a novel and paradigm-shifting approach to network routing and forwarding. VIRO simultaneously addresses the challenges faced by IP networks and Ethernet by decoupling routing from addressing and by integrating and unifying routing and forwarding performed by the traditional layer-2 and layer 3. VIRO introduces a topology-aware, structured virtual identifier (vid) space onto which both physical identifiers and higher layer addresses\/names are mapped. It employs innovative DHT-style routing mechanisms to build end-to-end connectivity from bottom-up, and to route\/forward data packets using vids only. Hence, VIRO is not only highly scalable and robust, but also namespace-independent. <br\/><br\/>This research project has the potential to reduce the complexity and costs of operating and managing future large, dynamic networks, and to foster creation and deployment of new Internet services. The PI plans to disseminate the research outcomes through publications and outreach activities. VIRO prototypes will be implemented and made publicly available. Through participation in future Internet design forums and collaboration with industrial partners, the PI will seek to impact the larger industry behind Internet technologies.","title":"NeTS: Small: VIRO: Highly Scalable, Robust and Namespace Independent Routing for Future Networks","awardID":"1017092","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543509"],"PO":["564993"]},"168408":{"abstract":"Project Abstract<br\/>CSR: Small: Turbo Button: A Semantically-Smart SSD-based RAID System for <br\/>Internet-Scale Applications<br\/><br\/> It is timely and opportunistic to rethink the designs of flash-memory SSD-integrated RAID storage systems for Internet-scale applications. Therefore, how to best utilize the high sequential-I\/O performance and cost-efficient characteristics of HDD to assist the SSD-based RAID systems becomes an important research issue. This project seeks to develop a Semantically-Smart SSD (S4D) framework to explore and exploit the file system and application semantic information to boost the performance and improve the reliability of flash-memory SSDs. <br\/><br\/>In particular, this project qualitatively and quantitatively identifies the critical issues for existing flash-memory SSDs, and conveys the file-system block liveness and correlation information to the underlying S4D with the standard or modified block interface. Secondly, S4D exploits the block liveness information to efficiently supplement the log-block pool with free blocks, and reduce the FTL block mapping table size. Finally, based on S4D, Turbo Button, an SSD-HDD-Hybrid RAID storage system, will be designed and constructed, in order to leverage the advantages of HDD judiciously to address the problems of straightforwardly applying RAID algorithms to SSDs. The broader impact of the project lies in its (1) research development that provides significant performance, reliability, and energy-efficiency improvement for existing and future flash-based and flash-integrated storage systems (specially RAID-structured storage systems) widely deployed in data centers that serve the Internet-scale application community; (2) infrastructure development that enhances research and education at UNL and, through accessibility via public domain, the high performance and data-intensive computing community.","title":"CSR: Small: Turbo Button: A Semantically-Smart SSD-based RAID System for Internet-Scale Applicationsa","awardID":"1016609","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485826","366560","485828"],"PO":["565255"]},"168529":{"abstract":"This project presents a new paradigm-shift approach in fault diagnosis by investigating network problems without requiring any monitoring sensors or active measurements, and assuming little or no knowledge about the network. The goal is to develop accurate, scalable and cost-effective network problem diagnosis that reason about uncertainty in case of incomplete knowledge without intrusive active probing or network monitoring. This project investigates a novel approach that uses evidential reasoning based on user observations to analyze the end-user views as evidence and compute a combined belief for determining the most possible root causes in overlay networks at real-time. The project also investigates techniques to rank the overlay paths based on their quality. The reasoning results can then be fedback into adaptive active monitoring, and dynamic virtual assignment\/reconfiguration systems to optimize problem monitoring and recovery, respectively. <br\/><br\/>Developing techniques and tools that enable sharing and analyzing end-host observations provide powerful diagnosing capabilities to service providers, system developers, and administrators to in problem determination, characterizing network conditions, configuration debugging and troubleshooting. These techniques are applicable on both overlay and traditional networks. This project enables trained workforce in this area through teaching and supervising students.","title":"CSR: Small: Collaborative Research: Towards Collaborative Overlay Problem Diagnosis Using Evidential Reasoning and Adaptive Monitoring","awardID":"1017152","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550428"],"PO":["565255"]},"171950":{"abstract":"The objective of this research is to develop the theoretical foundations of robust <br\/>cyber-physical systems. Robustness is the property ensuring that slight <br\/>perturbations in the cyber, physical, or in the interaction between the cyber and <br\/>the physical components, e.g., noise in sensor measurements, causes only slight <br\/>changes in the system execution. While it is theoretically possible to enumerate <br\/>all possible faults that can occur in a cyber-physical system and to design <br\/>software components that correctly handle all such faults, the resulting <br\/>specifications would be unwieldy and difficult to understand or verify. Instead, this <br\/>project investigates the design of software components that guarantee <br\/>robustness of cyber-physical systems with respect to unmodeled faults. The <br\/>approach consist in abstracting and generalizing several key ideas from robust <br\/>control theory to cyber-physical systems. <br\/><br\/>The project's intellectual merit is divided in two parts. The first part consists in <br\/>defining a notion of robustness for cyber-physical systems relying on finite-state <br\/>abstractions of the physical world retaining metric information about physical <br\/>quantities. The second part consists in developing the methods and tools for <br\/>automatically synthesizing software modules enforcing desired specifications in a <br\/>robust manner. <br\/><br\/>The tools and techniques developed in this project will significantly enhance our <br\/>ability to produce robust cyber-physical systems and thus have a broad impact in <br\/>several application areas transcending computer science and control <br\/>engineering. Moreover, the broader impact of the proposed research is amplified <br\/>by explicitly addressing the lack of robustness in legacy software through the <br\/>development of robustifying software patches. To enhance the transfer of the <br\/>research results to industry, the PIs and the Electrical Engineering Office of <br\/>Industrial Relations will host a workshop for the local industry on robust cyber-<br\/>physical systems.","title":"CPS: Small: Towards robust cyber-physical systems","awardID":"1035916","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["526859",460594],"PO":["564728"]},"170630":{"abstract":"This project will develop algorithms to assist with the early diagnosis of children who are at risk of developing behavioral disorders. Previous research has indicated that two critical areas of behavioral investigation for use in identifying at-risk children have been abnormalities in motor activities and emotional range displays, especially of the face. Motor abnormalities are based on the observation that motor control involves the circuits of the brain associated with dopamine; these are also implicated in behavioral disorders. Many different disorders share the observation of disruption in the emotional range regulation, so facial expressions are included in the study.<br\/><br\/>To date, assessments of motor and emotional range have been done by the experts who view and rate videos of an individual. However, these expert, subjective ratings limit the analysis of behavioral conditions to only a narrow range of behaviors, work only for small populations of individual subjects, and are both costly and dependent on the observer's particular expertise. In order to enable wider population screening, automation is required. Innovative ways of capturing and quantifying the expertise of experts will be accompanied by metrics for assessing the evolution of the behavior. In addition, new computational tools will support evaluation of the effectiveness of interventions.<br\/><br\/>The broader impacts of the proposed work will involve improved mental health levels across the populations by providing a systematic approach for enhancing early detection, prevention, or mitigation of behavioral disorders and likely reduce the long-term costs of missed or late diagnosis. The research results will be blended with the educational process through inclusion of project themes in the curricula at the Institute of Technology, the Medical School, and the College of Education and Human Development at the University of Minnesota and the creation of a program with annual workshops, tutorials, web pages and a wiki on knowledge discovery and behavioral analysis. The team will develop an interactive exhibit for children at the Bakken Museum, and create of new instructional material for student teachers at the Institute of Child Development and similar institutions. Development of a central web repository will insure that the algorithms and the data will be readily available for appropriate research.","title":"CDI-Type II: Computational Tools for Behavioral Analysis, Diagnosis, and Intervention of at Risk Children","awardID":"1028076","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0401","name":"Division of SBE Off of Multidisciplinary A","abbr":"SMA"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0401","name":"Division of SBE Off of Multidisciplinary A","abbr":"SMA"},"pgm":{"id":"1397","name":"CROSS-DIRECTORATE  ACTIV PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1331","name":"SOCIOLOGY"}}],"PIcoPI":["557451","557452","557449","549760"],"PO":["564359"]},"161830":{"abstract":"Fixing software bugs is a difficult and time-consuming process, accounting for up to 90% of the lifetime cost of a typical program. Because the number of defects outstrips the resources available for repairing them, most software is shipped with both known and unknown bugs. This research builds upon a novel, fully-automated method for repairing bugs in existing software, producing trustworthy repairs for real-world programs. The research will be broadly applicable, targeting large legacy applications with many testcases.<br\/><br\/>The technical focus of the work is a scalable and trustworthy technique to automatically repair program bugs. Program variants are evolved, using analogues of biological processes such as mutation, until one is found that both retains required functionality and avoids the defect. Thousands of standard software testcases, program invariants, mined specifications, and \"fuzz\" inputs are used to represent bugs, encode program requirements, and build trusted repairs. Empirical evaluations include an automated hardening scenario: programs and attacks against them are coevolved over time, simulating parts of the security arms race. Significant potential outcomes include: a scalable and trustworthy automated program repair methodology and freely available tools; advances in formal program analyses; significant efforts in outreach and education; and dissemination of the results.","title":"CAREER: Scalable and Trustworthy Automatic Program Repair","awardID":"0954024","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["496766"],"PO":["564388"]},"170663":{"abstract":"The goal of this project is to develop a new inference-based information processing structure that performs probabilistic computing using radically new nanoscale devices. This approach exploits the analog, time-dependent properties of such devices, and their massive parallelism. By doing so, such a computing structure will be more efficient and scalable than by using more traditional digital hardware. This approach is one of the first to include time-dependent circuit elements to build analog associative memories that approximate Bayesian inference, and which are, in turn, assembled into complex networks that capture higher order structure in streams of data. The ultimate goal is to use these circuits to develop hybrid CMOS \/ molecular scale implementations of a Field Adaptable Bayesian Array (FABA), which has the potential to be a key component for Cyber-Enabled discovery.<br\/><br\/><br\/>Cyber-Enabled discovery is addressed in this research in two ways. The first concerns the design of analog circuits based on complex nano and molecular scale devices with time-varying properties. And the second concerns the creation of a new family of semiconductor components that will significantly enhance Cyber-Enabled discovery applications across a wide range of data and applications.<br\/><br\/><br\/>Designing analog nano-electronic circuits that perform inference through space and time and which consist of dynamic components (such as mem-resistance and mem-capacitance) is extraordinarily difficult. This is particularly true when one considers the wide range of complex devices that are being developed in laboratories around the world for nano and molecular scale electronics. For this effort we have defined an Exploration Methodology that combines multiple levels of abstraction and evolvable computation.<br\/><br\/><br\/>Two key developments then are a design exploration methodology for such devices, and a massively parallel architecture for data capture and inference. This research will explore a new paradigm for using nanoscale electronics for emerging applications by starting with the \"top-down\" system requirements rather than by finding applications for new device concepts (\"bottom-up\").<br\/><br\/><br\/>As the semiconductor industry struggles with where to go next, the work proposed here may provide insight into radical new approaches to architecture, circuits and devices. This research will ultimately benefit society by enhancing human cognition and generating new knowledge from the wealth of heterogeneous digital data society has to deal with.","title":"Collaborative Research: CDI: Inference at the Nano-Scale","awardID":"1028336","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[456843],"PO":["562984"]},"172511":{"abstract":"While the Internet has far exceeded expectations, it has also stretched initial assumptions, often creating tussles that challenge its underlying communication model. Users and applications operate in terms of content, making it increasingly limiting and difficult to conform to IP's requirement to communicate by discovering and specifying location. To carry the Internet into the future, a conceptually simple yet transformational architectural shift is required, from today's focus on where ? addresses and hosts ? to what ? the content that users and applications care about.<br\/>This project investigates a potential new Internet architecture called Named Data Networking (NDN). NDN capitalizes on strengths ? and addresses weaknesses ? of the Internet's current host-based, point-to-point communication architecture in order to naturally accommodate emerging patterns of communication. By naming data instead of their location, NDN transforms data into a first-class entity. The current Internet secures the data container. NDN secures the contents, a design choice that decouples trust in data from trust in hosts, enabling several radically scalable communication mechanisms such as automatic caching to optimize bandwidth. The project studies the technical challenges that must be addressed to validate NDN as a future Internet architecture: routing scalability, fast forwarding, trust models, network security, content protection and privacy, and fundamental communication theory. The project uses end-to-end testbed deployments, simulation, and theoretical analysis to evaluate the proposed architecture, and is developing specifications and prototype implementations of NDN protocols and applications.","title":"FIA: Collaborative Research: Named Data Networking (NDN)","awardID":"1039646","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["521741","560811"],"PO":["565090"]},"174953":{"abstract":"For the use of unattended wireless sensor networks (WSNs) in critical situations to be viable, they must be able to operate in hostile environments for extended periods of time. Therefore, protocols for WSNs must be energy-efficient. In addition to the need for energy-efficiency, a WSN deployed in a hostile region should be resilient to attack. The current approach to defending against malicious threats is to develop and deploy a specific defense mechanism for a specific attack. However, this unrealistically assumes that only the attack that the sensor is prepared for will be executed. To truly realize mission critical sensor networks, the WSN must have the capability to defend against all known attacks as well as mechanisms for defending against future attacks (i.e., the WSN must be self-protecting). This proposal addresses the challenges with and feasibility of implementing large-scale self-protecting WSNs. In particular, this proposal seeks to determine if: 1) there are fundamental limitations of current sensor system architectures that prevent the realization of a self-protecting WSN; 2) the current network protocols and database techniques can provide the constraints-based routing and real-time storage \/ retrieval required for self-protecting WSNs; and 3) the proposed architecture of the self-protecting WSN is itself susceptible to attack. Where necessary, algorithms and architectures to overcome the potential limitations of current architectures and protocols are also developed in the project.","title":"EAGER: Evaluating the feasibility of Self-Protecting Heterogeneous Wireless Sensor Networks","awardID":"1052769","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560166","560166","469265",469265],"PO":["565303"]},"174601":{"abstract":"Perhaps the most prevalent scenario in science in general is reconstructing a phenomenon that is not directly observable using the data that can be measured. In biology, for example, this occurs when computing an evolutionary alignment of homologous proteins, predicting the secondary structure of a folded RNA molecule, inferring a phylogeny for a collection of taxa, recovering the regulatory network for a set of genes, or assembling the DNA sequence for a genome. These tasks are almost always modeled as optimization problems, where the optimal solution is intended to correspond to the correct reconstruction. A crucial ingredient in any such model is the objective function, whose role is to select out the correct solution as one that maximizes or minimizes the objective function. This objective function usually comes from a family of parameterized functions, and the correctness of the model can critically depend on the choice of parameter values for the function. In practice, the question of how to determine the right values for a model's parameters is both difficult and ubiquitous: improved models that better reflect the underlying biology have many parameters, but yield worse results unless their parameters are set to correct values, yet painstakingly exploring the high-dimensional parameter space to find a correct setting quickly becomes impossible. The team is looking to implement new finding of an algorithm in the area of inverse parametric optimization that can efficiently learn correct parameter values for any linear problem, such as those biology problems noted. The system readily yields efficient software for inverse shortest paths, inverse spanning trees, maximum flow, maximum matching and maximum branching, all of which have linear objective function can optimized, enabling efficient model learning for a multitude of computer science applications.<br\/><br\/>The proposed work on inverse parametric optimization has extremely broad scientific impact in computer science and computational biology, as our techniques efficiently solve inverse optimization for any problem with a linear objective function. The PI will also create a new combined course that is an integral part of a new interdisciplinary degree program.","title":"EAGER: An Exploratory System for Inverse Parametric Optimization","awardID":"1050293","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560602"],"PO":["565136"]},"174612":{"abstract":"The objective of this EAGER proposal is to develop Adaptive Regression Testing (ART) Strategies: strategies that can guide software test engineers in selecting appropriate regression testing techniques to use on new versions of their software systems as those systems evolve. As an initial approach to creating ART strategies, the research will investigate Analytical Hierarchy Process (AHP) methods while implementing a prototype tool to support the process. Controlled experiment to evaluate the use of their ART strategies will be conducted. The work is advancing knowledge and understanding by providing new strategies for regression testing software systems over their lifetimes, empirical data about those strategies, and empirical approaches that can be used by other researchers to make further progress in this area. For further information see the project web site at URL <br\/>http:\/\/cs.ndsu.edu\/~hdo\/projects\/art-strategy.html","title":"EAGER: Adaptive Regression Testing (ART) Strategies and Empirical Evaluations","awardID":"1050343","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["502044"],"PO":["565264"]},"175943":{"abstract":"This EAGER project contributes to a longstanding goal of factoring societal values into the design and creation of information technologies. It offers a novel model for fostering collaboration between experts in social analysis and in science and engineering. The model is being honed and tested in the context of large Future Internet Architecture (FIA) projects. These projects are ideal test beds because, like the existing Internet, they must aspire not only to meet criteria of technical excellence but to meet societal expectations for the future to promote and embody values such as innovation, productivity, security, human development, openness, broad and equitable access, accountability, privacy, and more. This EAGER model is intended not to replace existing cross-disciplinary collaborative models but to supplement them.<br\/><br\/>Intellectual Merit: From an assembled multi-disciplinary team of 10-15 experts in social analysis of IT and digital media, sub-groups of approximately 3-4 will participate in FIA-PI meetings. At these meetings, team members serve as analysts and consultants. They will help to identify junctures of values-critical technical decision-making, locate design features that differentially call values into play, articulate rich conceptual understandings of relevant values, operationalize values for implementation, consider implications for law and policy, and where possible, to design verification strategies. All of the above, constitute components of a general family of approaches known as Values-in-Design (VID). <br\/><br\/>Broader Impacts: The model holds distinctive promise because it facilitates repeated exposure to complex technical systems-under-development to a rotating cross-section of experts in social analysis. These activities constitute an opportunity rarely, if ever, provided in discipline-oriented institutions. As such, it facilitates more effective matching of expertise and interest with particular problems, at particular phases of design. In the longer term, the goal is to engender ongoing collaborations and, ultimately, systems and mechanisms that reflect and are deeply responsive to societal values.","title":"EAGER: Values in Design in the Future Internet Architecture","awardID":"1058333","effectiveDate":"2010-09-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["563668"],"PO":["565090"]},"172687":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040675","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[463071],"PO":["565090"]},"174623":{"abstract":"Wireless networks often evolve over time: changes of topology can occur if some nodes appear, disappear, or move around. Such dynamics over time domain are often ignored in protocol design or simply modeled by pure randomness such as in the well-known random walk mobility model. However, in real wireless networks, the node mobility and topology evolution depend heavily on both social and temporal characteristics of the network and network participants. In such socio-temporal evolving wireless networks, traditional communication protocols designed for mobile ad hoc networks and delay tolerant networks are inefficient due to time-varying structures, long delays, and the lack of continuous connectivity. To address this problems, this project seeks a new exploratory study of socio-temporal evolving wireless networks and topology control protocols for such networks, specifically, to (1) analyze and model socio-temporal dynamics of evolving wireless networks by using real-life wireless networking tracing data; (2) design efficient topology control protocols based on these socio-temporal models. The expected results include new socio-temporal models and novel topology control protocols, which can support many new civilian and military applications. The success of this project provides a deep understanding of both social and temporal properties of time-evolving wireless networks and enhances the interdisciplinary research between network science and social science. The research results will be incorporated into networking courses and widely disseminated through conference\/journal publications.","title":"EAGER: Topology Design in Socio-Temporal Evolving Wireless Networks","awardID":"1050398","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["251870"],"PO":["557315"]},"173666":{"abstract":"With the recent Deepwater Horizon oil spill in the Gulf of Mexico, the behavior of oil plumes in the natural environment has come become a central question. Experiments performed in the University of North Carolina (UNC) Fluids Laboratory have shown that buoyant plumes can be trapped underwater at regions of strong density stratification. This project will explore the mechanisms leading to underwater trapping of multi-phase plumes like those forming in the ongoing Gulf spill. Specifically, the project will focus on fluid dynamics experiments in the density-stratified flow facility in the UNC Fluids Lab to better quantify the combined roles of turbulent mixing, strong ambient stratifications, plume buoyancy, and use of surfactants (dispersants) in creating under water trapped plumes. Theoretical closure models will be developed to interpret the experiments and guide field studies. Further research will include direct numerical simulations to explore plume behavior under the effects of high temperature, high pressure, internal waves, and shear associated with this current spill. The intellectual merit of this theoretical and experimental research includes developing a benchmarked model for actual oil plume distribution, residence time, and surface versus sub-surface oil fractions. Broader impacts of the research will involve disseminating results with other groups directly working on the Gulf Oil Spill, including those collecting data on the subsurface plume distribution. Additionally, the PIs will make results available to the petroleum industry and regulatory agencies such as EPA to assist in the understanding of current and future spills. The research project will also involve the education of two undergraduate researchers and create new outreach opportunities for high school students to participate in the UNC Fluids Lab.","title":"RAPID: Multi-phase Buoyant Plumes in Stratified Water Study relevant to Oil Spill Implications for the Gulf oil spill distribution","awardID":"1045653","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1443","name":"FLUID DYNAMICS"}}],"PIcoPI":["522313","522314","555803"],"PO":["498493"]},"172698":{"abstract":"This project is aimed at the design and experimental validation of a comprehensive clean-slate future Internet architecture. The proposed MobilityFirst architecture is motivated by the ongoing paradigm shift of Internet usage from today?s fixed PC\/host (client)?server model to emerging mobile data services and pervasive computing applications. The major design goals of the architecture are: mobility as the norm with dynamic host and network mobility at scale; robustness with respect to intrinsic properties of the wireless medium; trustworthiness in the form of enhanced security and privacy; usability features such as support for context-aware services, evolvability, manageability and economic viability. The key components of the MobilityFirst network design are: (1) separation of naming and addressing, implemented via a fast global dynamic name resolution service; (2) self-certifying public key network addresses to support strong authentication and security; (3) generalized delay-tolerant routing with in-network storage for packets in transit; (4) flat-label internetwork routing with public key addresses; (5) hop-by-hop transport protocols operating over segments rather than an end-to-end path; (6) a separate network management plane that provides enhanced visibility; (7) optional privacy features for user and location data; and (8) an integrated computing and storage layer to support programmability. The project?s scope includes architectural design, validation of key protocol components, testbed prototyping of the MobilityFirst architecture as a whole, and real-world protocol deployment on the GENI experimental infrastructure. The results of this project will provide architectural guidance for cellular-Internet convergence, and are expected to influence future technical standards in the networking industry.","title":"FIA: Collaborative Research: MobilityFirst: A Robust and Trustworthy Mobility-Centric Architecture for the Future Internet","awardID":"1040735","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[463100,"559843","564746","531726","553648"],"PO":["565090"]},"174524":{"abstract":"Interactive systems are software systems that incorporate \"human-in-the-loop\" in achieving complex tasks. This proposal introduces Interaction History Management Systems (IHMSs): systems that capture and manage sequences of user interactions that determine the behavior of an interactive system. The interactions managed by an IHMS may be system- and domain-specific and can include SQL queries, search keywords, annotations of results and applied processing algorithms. By managing the histories of such interactions, it becomes possible to optimize and add additional functionality (e.g., versioning, time travel, use analysis) to the underlying interactive system.<br\/><br\/>This project explores the design and optimization of IHMSs to support the formulation of \"systematic reviews\": human-accumulated evidence that provide empirical data for the effectiveness of treatment strategies of a given patient's diagnosed disease or disorder. The project leverages research in several computer science areas such as query and workflow management, query recommendations and query provenance while it explores new interdisciplinary research domains. It also has high impacts in the domain of healthcare: it leads to the next generation of collaborative, streamlined systematic reviewing systems and therefore improves the effectiveness of evidence-based healthcare practice. Computer science students will be trained in healthcare applications and interdisciplinary research. Further information on the project can be found on the project web page: http:\/\/www.cs.brandeis.edu\/~olga\/IHMS.html","title":"EAGER: Interaction History Management Systems and their Application to Evidence-Based Practice of Healthcare","awardID":"1049974","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["483625","518052","483626","534198"],"PO":["563727"]},"163887":{"abstract":"A clinical data warehouse (CDW) is a repository that aggregates medical patient data from many different sources: billing records, electronic medical records including structured data (e.g., codes for diagnoses, procedures, vital signs, etc.), semi-structured reports and free-text dictations. A key benefit of maintaining a CDW lies in its ability to provide the raw data that are needed for large-scale study of real-world health care -- for example, finding a previously unknown association between a pain killer (e.g., Vioxx) and heart disease. Unfortunately, CDWs are riddled with systematic errors that make it difficult to answer even the simplest questions (such as \"What fraction of female outpatients have breast cancer?\") with any accuracy.<br\/><br\/>This project focuses on statistical models and learning algorithms for quantifying and correcting errors in CDW records. For example, the project is developing semi-supervised learning methods that use the structured data present in electronic medical records (patient age, weight, medications, billing codes, etc.) in order to quantify the likelihood of error that is associated with the diagnosis codes present in the record (for example, being able to state \"There is a 0.2 probability that the correct code was migraine instead of the listed headache\"). The project will also develop methods that attempt to control for confounding variables present in the records, in order to remove systematic biases from the data.<br\/><br\/>These models and learning algorithms will allow CDW users to manage and monitor the uncertainty and error in the data. This in turn will allow fundamentally new types of analysis to be undertaken, which will result in the discovery of actionable medical knowledge that saves both lives and money. To make the models and algorithms accessible to medical professionals who may lack computational or statistical background, they will be added to an open-source release of the widely-used I2B2 CDW software.<br\/><br\/>The project is a collaboration between the Computer Science Department at Rice University and the School of Biomedical informatics at the University of Texas Health Science Center at Houston. All project results will be made available online (http:\/\/www.cs.rice.edu\/~cmj4\/CDW.htm).","title":"III: Medium: Collaborative Research: Data Mining and Cleaning for Medical Data Warehouse","awardID":"0964613","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[438729],"PO":["563751"]},"161588":{"abstract":"Today's photonic infrastructure, whose foundations were established several decades ago, gradually extends from global backbone to access networks and beyond. Recent studies indicate that each household in North America should be connected by at least 100 Mb\/s, which cannot be accommodated by the last century's technology. The 100 Gb\/s Ethernet is currently under standardization, and according to industry experts 1 Tb\/s Ethernet should be standardized by the year 2012-2013. Migrating to higher transmission rates comes along with certain challenges such as degradation in the signal quality due to different linear and nonlinear channel impairments and increased installation costs. The limitations of photonics-enabled networks also result from the heterogeneity of the infrastructure and consequential bottlenecks at different boundaries and interfaces. <br\/><br\/>This multidisciplinary research grant studies different approaches to overcome the limitations of heterogeneous optical networks and enable serial 1 Tb\/s optical transport, while employing the components operating at lower speeds. In this approach, modulation, coding and multiplexing are performed in a unified fashion so that, effectively, the transmission, signal processing, detection and decoding are done at much lower symbol rates. At these lower rates, dealing with nonlinear and linear effects is manageable while the aggregate data rate is maintained at 1 Tb\/s and above. The primary research objectives of this grant can be summarized as follows: (i) development of different coded modulation schemes, employing both single-carrier and multicarrier, to enable 1 Tb\/s per wavelength optical transport and for simultaneous mitigation of channel impairments over various types of optical links; (ii) hardware FPGA\/ASIC implementation of coded modulation schemes; and (iii) validation of the proposed methodology through proof-of-concept implementation studies.","title":"CAREER: Enabling Technologies for Beyond 1 Tb\/s per Wavelength Optical Transport","awardID":"0952711","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[432182],"PO":["564924"]},"174425":{"abstract":"Organisms adapt to external perturbations through the optimized structure of their gene regulatory networks (GRNs). In the long-term, the state transition network of a GRN converges to a set of attractors that make the organism resilient to removal or functional impairment of genes. In wireless sensor networks (WSN), such attractors refer to a group of sensors serving as sink nodes for packets sent over multiple hops. This project maps such attractor based genomic robustness onto WSNs to infer optimal topologies and routing strategies that mitigate both sensor failure and a noisy wireless channel. This is being achieved by conducting in silico gene ?knock-down? experiments by simulating the functional removal of a gene from sample GRNs, to understand the dynamics of the attractor state space. This information is next used to design WSN topologies and routing protocols that are resilient to network uncertainty, node breakdown and compromise. <br\/>This project pursues the design of optimal wiring rules between sensors in a robust WSN that guarantees maximum probability of successful packet transmission under a given routing strategy. The guiding principle is to follow nature?s foot-steps in designing simple rules (i.e., routing algorithms) that guarantee maximum efficiency over an optimized WSN topology. It also develops innovative network-science based tools, and provides insights into the interplay of GRNs and WSNs that inspire new designs for engineered systems (i.e. fault-tolerant topologies for WSNs). Validation and testing are accomplished on real life WSN testbeds. Research results will be disseminated through publications, besides allowing for the design of new graduate-level courses.","title":"EAGER: Collaborative Research: Improving the efficiency of Wireless Sensor Networks using principles of Genomic Robustness","awardID":"1049652","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564777","502401"],"PO":["565303"]},"163898":{"abstract":"Wireless telecommunications are undergoing substantial policy reforms in pursuit of better spectral efficiency. A key element in these reforms entails granting full property rights to spectrum license holders, thereby paving the way to secondary spectrum markets. Spectrum markets hold a remarkable potential to increase spectrum utilization by making it available to a larger fraction of public at lower cost. Yet, although a favorable regulatory framework has been in effect in the last few years, liquidity of spectrum markets is inhibited due to uncertainties perceived by spectrum license holders. These uncertainties stem from complex relationships between effects of electromagnetic interference and economic considerations. This research involves a constructive study of viability of spectrum markets by establishing methods and algorithms that render such markets profitable for their participants.<br\/><br\/>The investigators focus on analytical study of profitability of spectrum markets, and its empirical verification. Main thrusts of the research program are: (i) fundamental elements of pricing and interference externalities for efficient and economically viable use of spectrum; (ii) algorithms for spot market use and real-time measurement-based pricing policies; (iii) empirical techniques for testing demand model specification, and formative models of demand-price relationships via experimental studies. This research is interdisciplinary and it is based on identifying incarnations of both novel and classical notions in economics in the specific context of wireless communications and spectrum markets.<br\/><br\/>The research impacts legal and economic policies for the future wireless industry and provides a tool for assessing potentials of the secondary spectrum market.","title":"NetSE: Medium: Collaborative Research: Promoting Secondary Spectrum Markets via Profitability-Driven Methods and Algorithms","awardID":"0964652","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["486132","451601"],"PO":["564924"]},"175526":{"abstract":"The highly-exposed live feed of the oil spill from underwater cameras in the Gulf of Mexico is one of many examples showcasing the importance of multimedia underwater sensor networks in fields such as underwater surveillance, undersea exploration, video-assisted navigation, and environmental monitoring. Multimedia networking, however, requires (i) much higher data rates than what has been available in the past with acoustic technology and (ii) flexible protocol design. Multiple-input-multiple-output (MIMO) is a transmission technique that may increase data rates or reduce link errors by leveraging the spatial diversity offered by the rich scattering structure of underwater acoustic propagation. To-date, little experimental data is available to the research community to assess the potential of MIMO gains in real underwater acoustic links. <br\/><br\/>This project is an early-stage research effort to collect data and experimentally assess the potential of acoustic MIMO networking. A testbed is being built to measure and model the propagation characteristics of underwater MIMO links and understand how the fundamental MIMO multiplexing and diversity tradeoff translates into a tradeoff between achievable transmission rate and link error probability. The project identifies how the capabilities of MIMO links impact the design of higher layer networking protocols. The resulting characterization informs the design of a class of integrated medium access control and signaling techniques that optimally select the transmit power, MIMO transmission mode, and coding strength to improve data rates and reduce bit error rates. All collected data are being made available to the research community through the project website.","title":"EAGER: Networking on Underwater Acoustic MIMO Links","awardID":"1055945","effectiveDate":"2010-09-01","expirationDate":"2013-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["490695","555021","490697","490699"],"PO":["565303"]},"164526":{"abstract":"This project studies the ongoing NASA-ESA-ASI Cassini Mission to Saturn to better understand the issues that envelop complex socio-computation systems, such as the mutual interdependence of humans and machines, to present broader implications for the design of complex human-computer systems more generally. While the robots become famous, robotic space exploration missions also require networked and distant hardware to control spacecraft movement, extensive home-grown software suites that coordinate work activity, and several hundred human scientists and engineers who must negotiate scientific priorities and make decisions that guide the robot.<br\/><br\/>Using ethnography, oral history interviews, and archival work, researchers will probe the practices of sociotechnical organization, distributed operations, data sharing, and community maintenance in an existing, complex, high-stakes and international sociocomputational environment. The research addresses the questions: what constraints does the social place on the technological, and vice versa? Also, how does the political and decision-making structure of a group align or clash with their technical infrastructure, and with what consequences for both social interaction and scientific production?<br\/><br\/>The intellectual merit of the project lies in its melding of five disciplinary areas of investigation - Science & Technology Studies, Computer-Supported Cooperative Work, Organization Sciences, Human-Computer Interaction, and Human-Robot Interaction - to generate a holistic picture of the institutional and workplace realities of large-scale technoscience in a radically distributed context. The broader impacts of this work include design implications for the next generation of socially-intelligent computational systems both within and outside of planetary exploration.","title":"SoCS: Socio-Computational Approaches to Planetary Exploration","awardID":"0968616","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["560634"],"PO":["564456"]},"163679":{"abstract":"This project exploits advances in parallel computing hardware and a neuroscience-informed perspective to design next-generation computer vision algorithms that aim to match a human's ability to recognize objects. The human brain has superlative visual object recognition abilities -- humans can effortlessly identify and categorize tens of thousands of objects with high accuracy in a fraction of a second -- and a stronger connection between neuroscience and computer vision has driven new progress on machine algorithms. However, these models have not yet achieved robust, human-level object recognition in part because the number of possible \"bio-inspired\" model configurations is enormous. Powerful models hidden in this model class have yet to be systematically characterized and the correct biological model is not known.<br\/><br\/>To break through this barrier, this project will leverage newly available computational tools to undertake a systematic exploration of the bio-inspired model class by using a high-throughput approach in which millions of candidate models are generated and screened for desirable object recognition properties (Objective 1). To drive this systematic search, the project will create and employ a suite of benchmark vision tasks and performance \"report cards\" that operationally define what constitutes a good visual image representation for object recognition (Objective 2). The highest performing visual representations harvested from these ongoing high-throughput searches will be used: for applications in other machine vision domains, to generate new experimental predictions, and to determine the underlying computing motifs that enable this high performance (Objective 3). Preliminary results show that this approach already yields algorithms that exceed state-of-the-art performance in object recognition tasks and generalize to other visual tasks.<br\/><br\/>As the scale of available computational power continues to expand, this approach holds great potential to rapidly accelerate progress in computer vision, neuroscience, and cognitive science: it will create a large-scale \"laboratory\" for testing neuroscience ideas within the domain of computer vision; it will generate new, testable computational hypotheses to guide neuroscience experiments; it will produce a new kind of multidimensional image challenge suite that will be a rallying point for computer models, neuronal population studies, and behavioral investigations; and it could unleash a host of new applications.","title":"RI: Medium: Collaborative Research: Unlocking Biologically-Inspired Computer Vision: A High-Throughput Approach","awardID":"0963668","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["438545"],"PO":["564318"]},"175779":{"abstract":"Proposal #: 10-57661<br\/>PI(s): Naphtali D Rishe<br\/>Institution: Florida International University<br\/>Title: RAPID: MRI: Development of Database Appliance Module for Multi-temporal Analysis and Correlation of Gulf Oil Spill Related Geospatial Data<br\/>Project Proposed:<br\/>This project, building an instrument that can analyze and correlate multi-temporal geospatial data, develops a new module working in conjunction with FIU?s TerraFly database appliance, with specific applicability to the study of coastal and near-coastal areas affected by the Gulf Oil Spill. The instrument will provide data analysis, definition, and visualization in combination with efficient algorithms. TerraFly is an FIU project with wide outreach and impact, where users visualize aerial imagery, precise street name overlays, and various other overlays. Users virtually \"fly\" over imagery via a web browser, without any software to install or plug in. Tools include user-friendly geospatial querying, interfaces with real-time data suppliers, demographic analysis, annotation, route dissemination via autopilots, and an application programming interface (API) for web sites (to name a few). Since the instrument can provide quick-response development of the tools, the project develops a unique module in TerraFly that can enable various studies of the coastal communities affected by the Gulf Oil Spill. Application examples range from environmental monitoring (such as analysis of water source availability by the USGS and water management districts) to questions of economic impact, such value of real estate in certain regions.<br\/>The instrument under development enables multi-temporal geospatial data analysis and correlation, with a specific applicability to the study of coastal and near-coastal areas affected by the Gulf Oil Spill. This hardware-software appliance, enables access to algorithms and data that allow a variety of functions to be defined, analyzed and visualized by the instrument?s users. This Instrument, consisting of a module working in conjunction with FIU?s TerraFly database appliance, that enables temporal querying, cross-referencing, visualization, and analysis of geospatial data, including time series multi-temporal aerial imagery, multi-temporal measurement and economic data, and vast existing static geospatial databases. Hence, the instrument provides a platform for analysis of differences in imagery and vectors, to facilitate querying differences per location and to address a range of questions pertaining to the economic impact of the Gulf Oil Spill on coastal communities. <br\/>The hardware aspects of the Instrument involve assembly and interconnection of a database machine from servers, mass storage units, and networking elements. The core of the Instrument is a software system running on the hardware platform. This is a Geospatial Database Management System to highly efficiently and reliably perform the functions enumerated above. The software system and the hardware elements together comprise a database appliance, i.e. a device accepting complex queries as input, rapidly evaluating said queries against massive data stored within the appliance, and emitting output streams for human consumption or for further machine processing. Thus, a smaller part of the work is assembling and interconnecting existing commodity hardware units into a new high-performance platform, while the bigger part of the work is software engineering effort to code, deploy, and calibrate the software system, as implementation of algorithms that have developed under non-MRI funding. <br\/>Broader Impacts: <br\/>Plans include having the data and graphic interface to queries, both user-definable and pre-defined, posted at http:\/\/terrafly.fiu.edu\/r.htm. In addition to research outcomes, this site will provide documentation relative to the project. The project enables and facilitates the access to the database and interfaces for all researchers and general public and also allows system-to-system XML access to all academic researchers to their GeoQuery system for the relevant Gulf Coast data.","title":"RAPID: MRI: Development of Database Appliance Module for Multi-temporal Analysis and Correlation of Gulf Oil Spill Related Geospatial Data","awardID":"1057661","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["558108"],"PO":["557609"]},"174228":{"abstract":"Data analysis is a fundamental problem in computational science, ubiquitous in a broad range of application fields, from computer graphics to geographics information system, from sensor networks to social networks, and from economics to biological science. Two complementary fields that have driven modern data analysis are computational geometry and statistical learning. The former focuses on detailed and precise models characterizing low-dimensional geometric phenomena. The latter focuses on robust or predictive inference of models given noisy high-dimensional data. This project aims to initiate a dialog between these two fields with geometry being the central theme. A closer interaction between them will benefit and advance both fields, and can potentially fundamentally change the way we view and perform data analysis. <br\/><br\/>Specifically, on one hand, the type of data common in the learning community poses several challenges for traditional computational geometry methods. The shift of focus to these challenges and the modeling of uncertainty central in statistical learning can broaden the scope of computational geometry, and lead to geometric algorithms and models that are more robust to noise and extend to high-dimensional data analysis. On the other hand, computational geometry has developed many elegant structures that contain often detailed and precise information about the underlying domain. Models parameterized using these structures can lead to statistical learning models and algorithms that are richer and more interpretable but remain robust to noise and are predictive. <br\/><br\/>This project is multi-disciplinary in nature, and will involve fields including computational geometry, algorithms, statistics, differential geometry and topology. Education will be integrated in this project.","title":"AF: EAGER: Collaborative Research: Integration of Computational Geometry and Statistical Learning for Modern Data Analysis","awardID":"1048983","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":["550392","562318"],"PO":["565157"]},"174349":{"abstract":"Many communication and compression scenarios involve the presence of Side Information (SI) on the state of the channel through which communication is to take place, or on the information source which is to be communicated. The role and potential benefit of such SI is a central theme in information theory.<br\/>In ways that are well understood for various source and channel coding systems, SI can be a valuable resource, resulting in significant performance boosts relative to the case where it is absent. In the problems studied thus far, however, the lack or availability of the SI, and its quality, are a given. This research is geared towards characterizing fundamental limits ?and devising guidelines for the construction of practical schemes? in scenarios involving systems that can take actions affecting the availability, quality, or nature of the SI. A central component of this research is the study of control theoretic notions such as action and actuation from an information theoretic perspective.<br\/>Specifically, we study source coding scenarios involving the presence of side information, when the system can take actions that affect the availability, quality, or nature of the SI. We begin by extending the Wyner-Ziv problem of source coding with decoder side information to the case where the decoder is allowed to choose actions affecting the SI. We consider also settings where actions are taken by the encoder(s). In a parallel vein, we study channels with action-dependent states: Given the messages to be communicated, the transmitter chooses an action sequence that affects the formation of the channel states, and then creates the channel input sequence based on the state sequence. We characterize the capacity of such a channel both for the case where the channel inputs are allowed to depend non-causally on the state sequence and the case where they are restricted to causal dependence. Actions may have costs that are commensurate with the quality of the SI they yield, and an overall per-symbol cost constraint may be imposed. We characterize the achievable tradeoffs between rate, distortion, power and cost in such source and channel coding systems, in both point-to-point and multi-terminal settings. Our models cover various new information processing scenarios ranging from sensing and data acquisition to coding for computer memories with a ?rewrite? option.","title":"EAGER: Action in Information Processing","awardID":"1049413","effectiveDate":"2010-09-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":["551175"],"PO":["564898"]},"168805":{"abstract":"The Semantic Web is an emerging technology that stipulates that the content of<br\/>each Internet web site provide self-describing metadata encoded using standard<br\/>graph representations, (using the OWL and RDF computer languages). In the<br\/>common Internet it is optional for web sites to provide topical descriptions of<br\/>their content. Further, the optional methods that are provided simply allow <br\/>developers to list keywords. The methods do not provide a way to detail the <br\/>meaning of those keywords, i.e. their semantics.<br\/><br\/>The goal of this project is to develop and demonstrate algorithms that <br\/>leverage the new, semantic aspects of the Internet and make it much easier <br\/>to treat multiple web sites and their underlying databases as a single <br\/>unified database. This is distinguished from the existing Internet where <br\/>a browser enables people to view documents and data, in the form of <br\/>documents, from different web sites in a single place. While the use <br\/>of Internet browsers is now endemic and trivially intuitive, creating <br\/>computer applications that process data from multiple web sites remains <br\/>a highly skilled and labor-intensive process.<br\/><br\/>This project comprises two components. The first component helps create <br\/>the Semantic Web by developing methods that automatically map existing <br\/>databases to the Semantic Web graph languages. The methods comprise data <br\/>mining techniques that discover the semantics already present, but not <br\/>explicitly encoded in relational databases and recast those semantics <br\/>in graph-based form. The second component comprises the development of <br\/>a distributed query execution environment for processing graph structured <br\/>queries, expressed in SPARQL.<br\/><br\/>The PI is an invited expert on the W3C working group on standards for <br\/>relational database to RDF translation (RDB2RDF), the subject of this <br\/>research. More information on this project can be found at <br\/>http:\/\/www.cs.utexas.edu\/~miranker\/SemanticWeb.html.","title":"III: Small: Linking Relational Databases with OWL and SPARQL","awardID":"1018554","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[451801],"PO":["565136"]},"174129":{"abstract":"The Computer Science Research and Enrichment Program will provide an opportunity to translate the potential of a few promising students at Rutgers University-Camden and a few students from local high schools into measurable impact. As part of this project we will work very closely with these students over the next couple of years - teaching them advanced topics in discrete mathematics\/algorithms, mentoring them, and working on research projects with them. Making a concerted effort to support and guide these students will enrich them individually, and also permit them to make a greater impact through their academic and professional endeavors. The research projects that we plan to work on are related to covering problems and scheduling problems. Like many other problems, the proposed problems are intractable and no efficient algorithms to solve these problems exactly are known. Our goal is to design efficient algorithms that produce near-optimal solutions for these problems.","title":"EAGER: Computer Science Research and Enrichment Program","awardID":"1048606","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["518387"],"PO":["565251"]},"168816":{"abstract":"This project is devoted to building a large multilingual semantic network<br\/>through the application of novel techniques for semantic analysis<br\/>specifically targeted at the Wikipedia corpus. The driving hypothesis of<br\/>the project is that the structure of Wikipedia can be effectively used to<br\/>create a highly structured graph of world knowledge in which nodes<br\/>correspond to entities and concepts described in Wikipedia, while edges<br\/>capture ontological relations such as hypernymy and meronymy. Special<br\/>emphasis is given to exploiting the multilingual information available in<br\/>Wikipedia in order to improve the performance of each semantic analysis<br\/>tool. Significant research effort is therefore aimed at developing tools<br\/>for word sense disambiguation, reference resolution and the extraction of<br\/>ontological relations that use multilingual reinforcement and the<br\/>consistent structure and focused content of Wikipedia to solve these tasks<br\/>accurately. An additional research challenge is the effective integration<br\/>of inherently noisy evidence from multiple Wikipedia articles in order to<br\/>increase the reliability of the overall knowledge encoded in the global<br\/>Wikipedia graph. Computing probabilistic confidence values for every piece<br\/>of structural information added to the network is an important step in<br\/>this integration, and it is also meant to provide increased utility for<br\/>downstream applications. The proposed highly structured semantic network<br\/>complements existing semantic resources and is expected to have a broad<br\/>impact on a wide range of natural language processing applications in need<br\/>of large scale world knowledge.<br\/><br\/>For further information, please see the project website:<br\/>http:\/\/lit.csci.unt.edu\/index.php\/Mu.Se.Net","title":"III: Small: Collaborative Research: Building a Large Multilingual Semantic Network for Text Processing Applications","awardID":"1018613","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[451827,"564432"],"PO":["565136"]},"174019":{"abstract":"This collaborative project is focused on GIS vector-based spatial data overlay processing through cloud computing. Vector-based processing is considerably more complicated than raster data processing because raster data is based on regular grid-based fixed-size pixels, while vector features have irregular geometric shapes represented by a list of large number of vertices. GIS data files can be very large-scale huge and as such, computational requirements are significant. Cloud platforms such as Azure are appropriate for large-scale computing and storage capabilities. These capabilities combined with accessibility on-demand and other features have made cloud processing very desirable for GIS applications. This exploratory research will attempt to discover distributed algorithms and test their scalable implementations for GIS overlay processing on the Azure platform.","title":"CiC: EAGER: Collaborative: GIS Vector Data Overlay Processing on Azure Platform","awardID":"1048162","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8010","name":"Computing in the Cloud"}}],"PIcoPI":[466797],"PO":["565136"]},"168827":{"abstract":"As computing systems and society at large becomes more data-centric, the importance of being able to access data quickly and efficiently becomes critical. In current systems, hard disk performance limits overall system performance for data-intensive tasks and ultimately limits our ability to efficiently process massive amount of data quickly. A new class of advanced, solid-state non-volatile memories are poised to revolutionize how computer systems store and access persistent data. These memory technologies are 100s to 1000s times faster than conventional disk drives. However, they require a complete re-engineering of numerous system components as well as the interfaces between those components. Without understanding and implementing these changes, we will never realize the full potential of these memories. In this research, the PIs propose to design, implement, and evaluate new system components and abstractions for accessing non-volatile, solid-state memories. They will construct hardware prototype system, simulation systems, and custom-built software systems to reduce the cost of accessing these memories and make them easier for programmers to use safely and reliably.<br\/><br\/>Redefining the interface and abstractions that programs use to access and manipulate persistent state will have significant effects across all aspects of computer system design. It will require thinking hardware, operating system, programming language, and application-level design decisions and enable new models for data-intensive computation. The PIs will incorporate the programming models, prototypes, and applications into the curriculum of the CSE department at UCSD. Finally, the broad and interdisciplinary scope of the rsearch makes it an excellent tool for recruiting groups that are traditionally underrepresented in computing fields.","title":"SHF: Small: Redefining IO Abstractions for Non-Volatile, Solid-State Memories: Languages and System Architectures","awardID":"1018672","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["529115","518615"],"PO":["366560"]},"167859":{"abstract":"The research objective of this award is realization of Networked Mobile Assistive Systems (NMASs) that allow people to receive physical assistance and rehabilitation treatments anywhere, at any time with feedback regarding adequacy and appropriateness of training. The approach taken will consist of two major elements: a body-sensor network and a highly reliable wireless network. Most of the data acquired from a body-sensor network and the algorithms for the control of mobile power assistive devices will be stored on a host server, and users will access the system with any portable computer while receiving appropriate assistance and rehabilitation treatment. The networked systems will also allow doctors to observe the stored information without compromising the important, sensitive personal interactions between the provider and the patient.<br\/><br\/>If successful, the benefits of this research will contribute to the improved quality of life for physically impaired people (young or old) who have problems with community mobility and specific gait limitations. It will also provide a powerful tool to physical therapists in the treatment of patients. The project team consists of two PI?s from Mechanical Engineering and Computer Science and a consultant from Physical Therapy. This team uniquely links engineering with clinical applications. The interdisciplinary research opportunities will be made available to engineering students and students in physical therapy. The Center for Information Technology Research in the Interest of Society (CITRIS) at the University of California, Berkeley provides a unique environment and opportunity to the team to interact and share research findings with other researchers and students.<br\/><br\/>The project is an Interdisciplinary Research (IDR) Project jointly funded by ENG\/CMMI and CISE\/CNS.","title":"IDR\/Collaborative Research: Monitoring and Mobility Assistance with Wireless Body Sensor Network and Mechatronic Actuation","awardID":"1014146","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1639","name":"SENSORS AND SENSING SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7951","name":"ENG INTERDISC RES (IDR)"}}],"PIcoPI":["527002"],"PO":["564949"]},"168717":{"abstract":"Natural emergency and disaster scenarios are unfortunate occurrences with far reaching after effects. In addition to human casualties, natural calamities can destroy the power grid, telephone networks, and mobile phone towers. The result being, there is no alternative for disseminating critical updates such as disease and safety alerts, locations, and directions to survivors. The above problem is an outcome of the lack of network systems that are designed to survive and serve after natural disasters. In order to remedy this problem, this project is designing, implementing, and deploying a solar powered self-sustainable emergency mesh to provide critical communication infrastructure to survivors and rescue personnel. <br\/><br\/>This work employs a mesh architecture that is energy-efficient and self-sustainable. It relies on renewable energy sources such as solar to provide near-perpetual lifetime to mesh nodes while serving critical updates to survivors. Since renewable energy scavenging is notoriously unpredictable, this project uses a clean-slate low power hardware and software systems design for the nodes. Additionally, in the event of node failures due to variability inherent in renewable energy scavenging and extreme environmental conditions during the aftermath of a natural calamity, the mesh automatically redistributes the data on the failed nodes to maintain sufficient redundancy. Finally, the mesh design uses common wireless technology such as Wi-Fi and light weight web-based services for compatibility with off-the-shelf laptops, mobile phones, and PDAs carried by disaster survivors. The culminating goal of this project is to save human lives. With the mesh infrastructure in place, human casualties during post-disaster times can be minimized. Additionally, during non-emergency scenarios, the system can be used to disseminate \\police alerts\" and \\disease alerts\" (e.g. swine-flu) that keep individuals well informed and cautious. In addition to a broad societal impact, this project, through educational courses provides hands-on experience to undergraduates and graduates in building mobile, embedded, and geospatial systems.","title":"CSR: Small: Self-sustainable Solar-powered Emergency Mesh Design","awardID":"1018112","effectiveDate":"2010-09-01","expirationDate":"2013-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[451583,"551314","547994"],"PO":["535244"]},"168607":{"abstract":"Recent explosion in experimental demonstration of various spin based devices, both from academia and industry, show that the promise of spintronic devices to augment or, in some cases, replace conventional CMOS based logic systems may soon become a reality. This necessitates that appropriate design tools are available so that individual device behavior observed in experimental labs can be assessed systematically. However, for spintronic devices no such design software currently exists.<br\/><br\/>This research (RiSSC) will attempt to build a simulation platform for spin devices, that is based on fundamental physics and first principles electronic structure but, at the same time, will exploit the increasing computational capability made available through multi-core architecture and super computing clusters. This work will thus, on one hand, advance the fundamental understanding of spin related phenomena and on the other, will enable innovative designs and optimization by integrating varied spin based devices from a common platform. By severely parallelizing the simulation methodology, it will make possible to analyze spin devices from atomistic detail---a feat that is currently regarded as impossible due to computational complexity. RiSSC will thus provide a novel pathway to explore hybrid devices where traditional CMOS devices and exotic spin devices combine to give new functionality. The project also includes significant outreach program including open source software development and deployment, industrial collaboration and involvement of under represented minorities through UC NERDS.","title":"SHF: Small: Rigorous Simulation for All Spin Computing (RiSSC)","awardID":"1017575","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["502253"],"PO":["565157"]},"168849":{"abstract":"Designing parallel systems that are scalable, low-cost, and power efficient, and yet easily programmable, is arguably one of the biggest challenges facing the computing industry today. This proposal describes DeNovo, a hardware architecture and framework that rethinks shared memory system design from the ground up to take advantage of long term trends in disciplined parallel software. It takes the stance that, if shared memory multicore systems with hundreds of cores are to become widely used, programming languages and environments must evolve to enforce highly disciplined programming practices that greatly simplify the programmer's view of shared memory. Such languages must restrict shared memory interactions, enforcing data-race-freedom and determinism-by-default. Moreover, disciplined programming models communicate extensive information about shared memory access patterns (so the discipline can be enforced). Exploiting the parallelism discipline and the communicated information can enable far simpler and more efficient hardware design than possible today.<br\/><br\/>DeNovo proposes an extensive redesign of the memory hierarchy based on three ideas. First, the coherence protocol can be vastly simplified by taking advantage of the absence of software races to virtually eliminate races from the protocol and greatly reduce the number of hidden protocol states. Second, DeNovo uses application-level data sharing granularity (rather than software-oblivious cache lines) as the organizing principle for addressing, communication, and coherence granularities. Third, DeNovo uses more efficient, point-to-point communication (close to explicit message passing) even for shared memory programs, by minimizing indirections through the directory and exploiting information about sharing granularity for bulk data transfers. These changes will simultaneously simplify the hardware design, reduce power consumption, and improve performance. Such a solution is highly unlikely without a fundamental rethinking of the memory system design, but is required to continue to reap the benefits of Moore's law.","title":"SHF: Small: DeNovo: Rethinking Hardware for Disciplined Parallelism","awardID":"1018796","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["551063","542046"],"PO":["366560"]},"168629":{"abstract":"The major objective of this project is to study the challenges and techniques of applying the emerging Compressive Sensing (CS) theory to various fundamental sensor network problems under typical network settings. The proposed research activities include: i) temporal and spatial compressive sampling to decrease the transmitted data volume while preserve the information level; ii) compressive data gathering to decrease the communication overhead while preserve high-fidelity data recovery; iii) mission-critical sensor network applications such as outlier detection and target counting to illustrate the CS formulations of the problems and the strength of CS as a technical approach; and iv) testbed and field deployment for validation purpose. These research activities are motivated by the observations that a) sensor networks are typically deployed to measure various natural signals that are usually compressible and are temporally and spatially correlated; b) fundamental sensor network problems such as topology control and in-network data aggregation and compression investigate the compressibility and correlation among sensor readings for resource conservation; and c) CS provides an approach to recover the compressible data by acquiring just the important information via non-adaptive random projections. <br\/><br\/>The expected results include novel algorithms that can contribute significantly to both CS theory and sensor networking. Our research could motivate a new wave of exploration via sparse signal recovery on a wide range of fundamental sensor network problems that have been investigated through traditional approaches for many years. Research outcomes will be disseminated through high-quality publications as well as presentations in focused workshops and conferences.","title":"NeTS: Small: Exploring the Signal Sparsity in Sensor Networks Based on Compressive Sampling","awardID":"1017662","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560587"],"PO":["565303"]},"167419":{"abstract":"Cooperation and Learning over Cognitive Networks<br\/>Studies on herding and self-organization in economics and the social and biological sciences have observed that coordination among multiple agents leads to regular patterns of behavior and swarm intelligence, even when each group member shows limited behavioral complexity. In ant colonies, for example, individual ants cannot capture rich spatial information from their environment because of their limited sensing ability. Nevertheless, when the ants coordinate their activities within a colony, the group ends up exhibiting better sensing abilities. Using signal processing and communications techniques, the research studies how and why such manifestations of rational and organized behavior arise at the group level from local interactions among agents with limited abilities, what communication topologies enable such behavior, and what type of signal processing enables such formations. <br\/><br\/>This research seeks to understand and reverse-engineer the distributed intelligence encountered in socio-economic-biological networks, by investigating relations with learning and rationality over cognitive networks. The latter are adaptive networks that avoid centralized information processing and perform in-network inference and control decisions. Cognitive networks contrast with networks that rely on centralized and parallel information fusion, which are not scalable, are hard to adapt to changing topologies, and suffer from points of vulnerability and information bottlenecks. The research considers large scale networks of agents and studies how global (rational or irrational) patterns of behavior emerge, including herds, contagions and bubbles in economics. An understanding of how the biotic environment influences collective behavior in animal societies provides a real world guide to good cognitive networks, which can be used in turn to design engineered systems. Cognitive networks have applications in areas ranging from precision agriculture, to environmental monitoring, disaster relief management, and smart spaces.","title":"CIF: Large: Collaborative Research: Cooperation and Learning Over Cognitive Networks","awardID":"1011811","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":["550699"],"PO":["564898"]},"168519":{"abstract":"When people communicate with each other about spatially oriented tasks, they more often use qualitative spatial references (such as \"behind\" in the spatial description \"Your eyeglasses are behind the lamp.\") rather than precise quantitative terms. Although natural for people, such qualitative references are problematic for robots that \"think\" in terms of mathematical expressions and numbers. Yet, providing robots with the ability to understand and communicate with these spatial references has great potential for creating a more natural interface mechanism for robot users. This would allow users to interact with a robot much as they would with another human, and is especially critical if robots are to provide assistive capabilities in unstructured environments occupied by people. This project will do the following: empirically capture and characterize the key components of spatial descriptions that indicate the location of a target object in a 3D immersive task embedded in an eldercare scenario; develop and refine algorithms that enable the robot to produce and comprehend descriptions containing these empirically determined key components within this scenario; and assess and validate the robot spatial language algorithm in virtual and physical environments. This project will train graduate students in an interdisciplinary setting that encompasses psychology, computer science and engineering), and will directly involve undergraduate students in the robotics work at Missouri and in the human subject experimentation work at Notre Dame. This project will lead to a better understanding of how robots can and should be used for this class of assistive tasks in an eldercare scenario.","title":"HCC: Small: Human-Driven Spatial Language for Human-Robot Interaction","awardID":"1017097","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["547707","561794"],"PO":["565227"]},"171830":{"abstract":"The objective of this research is to improve the ability to track the orbits of space debris and thereby reduce the frequency of collisions. The approach is based on two scientific advances: 1) optimizing the scheduling of data transmission from a future constellation of orbiting Cubesats to ground stations located worldwide, and 2) using satellite data to improve models of the ionosphere and thermosphere, which in turn are used to improve estimates of atmospheric density. <br\/>Intellectual Merit<br\/>Robust capacity-constrained scheduling depends on fundamental research on optimization algorithms for nonlinear problems involving both discrete and continuous variables. This objective depends on advances in optimization theory and computational techniques. Model refinement depends on adaptive control algorithms, and can lead to fundamental advances for automatic control systems. These contributions provide new ideas and techniques that are broadly applicable to diverse areas of science and engineering.<br\/>Broader Impacts<br\/>Improving the ability to predict the trajectories of space debris can render the space environment safer in both the near term---by enhancing astronaut safety and satellite reliability---and the long term---by suppressing cascading collisions that could have a devastating impact on the usage of space. This project will impact real-world practice by developing techniques that are applicable to large-scale modeling and data collection, from weather prediction to Homeland Security. The research results will impact education through graduate and undergraduate research as well as through interdisciplinary modules developed for courses in space science, satellite engineering, optimization, and data-based modeling taught across multiple disciplines.","title":"CPS: Medium: Collaborative Research: Robust Capacity-Constrained Scheduling and Data-Based Model Refinement for Enhanced Collision Avoidance in Low-Earth Orbit","awardID":"1035250","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["529271"],"PO":["564728"]},"171951":{"abstract":"The objective of this research is the design of innovative routing,<br\/>planning and coordination strategies for robot networks, and their<br\/>application to oceanography. The approach is organized in three<br\/>synergistic thrusts: (1) the application of queueing theory and<br\/>combinatorial techniques to networked robots performing sequential tasks,<br\/>(2) the design of novel distributed optimization and coordination schemes<br\/>relying only on asynchronous and asymmetric communication, (3) the design<br\/>of practical routing and coordination algorithms for the USC Networked<br\/>Aquatic Platforms. In collaboration with oceanographers and marine<br\/>biologists, the project aims to design motion, communication and<br\/>interaction protocols that maximize the amount of scientific information<br\/>collected by the platforms.<br\/><br\/>This proposal addresses multi-dimensional problems of relevance in<br\/>Engineering and Computer Science by unifying fundamental concepts from<br\/>multiple cyberphysical domains (robotics, autonomy, combinatorics, and<br\/>network science). Our team has expertise in a broad range of scientific<br\/>disciplines, including control theory and theoretical computer science and<br\/>their applications to multi-agent systems, robotics and sensor networks.<br\/><br\/>The proposed research will have a positive impact on the emerging<br\/>technology of autonomous and reliable robotic networks, performing a broad<br\/>range of environmental monitoring and logistic tasks. Our educational and<br\/>outreach objectives are manifold and focus on (1) integrating the proposed<br\/>research themes into undergraduate education and research, e.g., via the<br\/>existing NSF REU site at the USC Computer Science Department, and (2)<br\/>mounting a vigorous program of outreach activities, e.g., via a<br\/>well-developed collaboration with the UCSB Center for Science and<br\/>Engineering Partnerships.","title":"CPS: Medium: Collaborative Research: Dynamic Routing and Robotic Coordination for Oceanographic Adaptive Sampling","awardID":"1035917","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["536698","495278"],"PO":["564728"]},"170873":{"abstract":"This collaborative research project is concerned with the development of accurate and efficient computational uncertainty propagation techniques for nonlinear stochastic Hamiltonian systems that evolve on Lie group configuration spaces. Uncertainties in a dynamic system arise from multiple sources such as unmodeled dynamics, parametric uncertainty, and uncertainty in initial conditions. As they cannot be completely eliminated from any computational experiment or physical measurement, a careful characterization of the evolution of uncertainties is essential in scientific and engineering problems. This project involves the application of computational geometric mechanics, geometric numerical integration, noncommutative harmonic analysis, and generalized polynomial chaos techniques, and will yield mesh-free, coordinate-free methods for the numerically stable long-time propagation of uncertainty in a Hamiltonian system, while explicitly addressing the underlying stochastic and geometric properties of the system.<br\/><br\/>Most mathematical models have sources of uncertainty that may arise from physical processes that are poorly understood, a lack of precise knowledge of the parameters, or incomplete information about the current state of the system, and it is important to understand how these model uncertainties affect the predictions that arise from the mathematical model. In particular, a computer prediction without some indication of the reliability and confidence in the prediction can be disastrously misleading. This project aims to address the essential task of developing accurate mathematical and numerical methods for characterizing the effects of uncertainty in complex systems, which is a particularly timely and pressing need, since mathematical models of complex systems are increasingly relied upon to inform public policy decisions with long lasting and far reaching consequences. A graduate textbook will be prepared that discusses in parallel the continuous and discrete time approach to geometric mechanics on Lie groups that aims to be accessible to professional programs in computational science, and which will be field tested in the CSME graduate program at UCSD. This textbook includes accompanying code that will facilitate the reuse of the computational infrastructure funded by this project in other applications involving uncertainty propagation on nonlinear spaces.","title":"Collaborative Research: Computational Geometric Uncertainty Propagation for Hamiltonian Systems on a Lie Group","awardID":"1029445","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"6892","name":"CI REUSE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7478","name":"DYNAMICAL SYSTEMS"}}],"PIcoPI":["555714"],"PO":["564266"]},"170785":{"abstract":"Abstract: The Variability Expedition<br\/>Project: Variability-Aware Software for Efficient Computing with Nanoscale Devices<br\/><br\/>As semiconductor manufacturers build ever smaller components, circuits and chips at the nano scale become less reliable and more expensive to produce ? no longer behaving like precisely chiseled machines with tight tolerances. Modern computing is effectively ignorant of the variability in behavior of underlying system components from device to device, their wear-out over time, or the environment in which the computing system is placed. This makes them expensive, fragile and vulnerable to even the smallest changes in the environment or component failures. We envision a computing world where system components -- led by proactive software -- routinely monitor, predict and adapt to the variability of manufactured systems. Changing the way software interacts with hardware offers the best hope for perpetuating the fundamental gains in computing performance at lower cost of the past 40 years. The Variability Expedition fundamentally rethinks the rigid, deterministic hardware-software interface, to propose a new class of computing machines that are not only adaptive but also highly energy efficient. These machines will be able to discover the nature and extent of variation in hardware, develop abstractions to capture these variations, and drive adaptations in the software stack from compilers, runtime to applications. The resulting computer systems will work and continue working while using components that vary in performance or grow less reliable over time and across technology generations. A fluid software-hardware interface will thus mitigate the variability of manufactured systems and make machines robust, reliable and responsive to the changing operating conditions.<br\/><br\/>The Variability Expedition marshals the resources of researchers at the California Institute for Telecommunications and Information Technology (Calit2) at UC San Diego and UC Irvine, as well as UCLA, University of Michigan, Stanford and University of Illinois at Urbana-Champaign. With expertise in process technology, architecture, and design tools on the hardware side, and in operating systems, compilers and languages on the software side, the team also has the system implementation and applications expertise needed to drive and evaluate the research as well as transition the research accomplishments into practice via application drivers in wireless sensing, software radio and mobile platforms. <br\/><br\/>A successful Expedition will dramatically change the computing landscape. By re-architecting software to work in a world where monitoring and adaptation are the norm, it will achieve more robust, efficient and affordable systems that are able to predict and withstand not only hardware failures, but other kinds of software bugs or even attacks. The new paradigm will apply across the entire spectrum of embedded, mobile, desktop and server-class computing machines, yielding particular gains in sensor information processing, multimedia rendering, software radios, search, medical imaging and other important applications. Transforming the relationship between hardware and software presents valuable opportunities to integrate research and education, and this Expedition will build on established collaborations with educator-partners in formal and informal arenas to promote interdisciplinary teaching, training, learning and research. The team has built strong industrial and community outreach ties to ensure success and reach out to high-school students through a combination of tutoring and summer school programs. The Variability Expedition will engage undergraduate and graduate students in software, hardware and systems research, while promoting participation by underrepresented groups at all levels and broadly disseminating results within academia and industry.","title":"Collaborative Research: Variability-Aware Software for Efficient Computing with Nanoscale Devices","awardID":"1029030","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7723","name":"EXPERIMENTAL EXPEDITIONS"}}],"PIcoPI":["515835",457198,"508496"],"PO":["562984"]},"171885":{"abstract":"The objective of this research is to develop algorithms and software for treatment planning in intensity modulated radiation therapy under assumption of tumor and healthy organs motion. The current approach to addressing tumor motion in radiation therapy is to treat it as a problem and not as a therapeutic opportunity. However, it is possible that during tumor and healthy organs motion the tumor is better exposed for treatment, allowing for the prescribed dose treatment of the tumor (target) while reducing the exposure of healthy organs to radiation. The approach is to treat tumor and healthy organs motion as an opportunity to improve the treatment outcome, rather than as an obstacle that needs to be overcome. <br\/>Intellectual Merit: The leading intellectual merit of this proposal is to develop treatment planning and delivery algorithms for motion-optimized intensity modulated radiation therapy that exploit differential organ motion to provide a dose distribution that surpasses the static case. This work will show that the proposed motion-optimized IMRT treatment planning paradigm provides superior dose distributions when compared to current state-of-the art motion management protocols. <br\/>Broader Impact: Successful completion of the project will mark a major step for clinical applications of intensity modulated radiation therapy and will help to improve the quality of life of many cancer patients. The results could be integrated within existing devices and could be used for training of students and practitioners. The visualization software for dose accumulation could be used to train medical students in radiation therapy treatment planning.","title":"CPS: Small: Collaborative Research: Tumor and Organs at Risk Motion: An Opportunity for Better DMLC IMRT Delivery Systems","awardID":"1035460","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["558126"],"PO":["564728"]},"172622":{"abstract":"Proposal #: 10-40254<br\/>PI(s): Chen, Hui<br\/> Damevski, Kostadin; Mullins, Christopher; Rafie, Ahmad R.; Wang, Ju<br\/>Institution: Virginia State University<br\/>Title: MRI\/Acq.: Acq. of Sensing and Computing Equipment for Smart High-Tunnel Greenhouses<br\/>Project Proposed:<br\/>This project from an MSI, principally undergraduate university, acquiring actuating devices, server computers, visualization workstations, etc., to form a Cyber-Physical System (CPS) that converts high-tunnel greenhouses into a ?smart? greenhouse system, aims to detect variations in the environmental conditions (e.g., moisture and temperature) and enable fine-grained control. Enabling the investigation of determining how recent advances in sensing, networking, and computing research can benefit agriculture practice (specifically, high-tunnel greenhouses), the work provides a window to expose practical problems that arise from setting up and operating the smart greenhouse system. Aiming to produce affordable and reliable CPS that can support automation in high-tunnel greenhouses the project looks into:<br\/>- Water management in high-tunnel greenhouses,<br\/>- Random scheduling for sensor networks,<br\/>- Localization of sensor nodes that leverages radio tomographic images,<br\/>- Fault-tolerant agriculture CPS, and<br\/>- High programmer productivity environments for heterogeneous CPS.<br\/>The project might lead to broader acceptance and use of the systems.<br\/>Broader Impacts: <br\/>The research instrument should foster collaboration among computer science and agricultural faculty, providing a field laboratory where students can conduct meaningful research-oriented experiments and thus increase the involvement of minority and women students in science, engineering, computer science, and mathematics. The research should contribute to affordable and robust systems and application in precision agriculture, and lead to sustainable agricultural practices and higher crop yields, indeed, a strong benefit for society at large. Moreover, undergraduate and graduate research and instruction and training should see improvement with the incorporation of more sophisticated real-world motivating examples and experiments.","title":"MRI: Acquisition of Sensing and Computing Equipment for Smart High-Tunnel Greenhouses","awardID":"1040254","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"J405","name":"National Security Agency"}}],"PIcoPI":[462804,462805,"509697","394539","465558"],"PO":["557609"]},"171313":{"abstract":"The DIMACS Project on Computer Science \/ Mathematics in Service to Society provides a national resource for a large community of researchers and educators in computer science and related mathematical and statistical areas as well as their collaborators in fields such as biology, chemistry, physics, engineering, public health, business, and the social sciences. The project enhances and encourages programs that emphasize applications of computer science, mathematics, and statistics to problems of society involving topics such as homeland security, energy, climate change, health care, and the economy. The project also emphasizes development of fundamental methods of computer science and related areas of mathematics and statistics. This award partially supports the DIMACS Center infrastructure required to achieve project goals.<br\/><br\/>Research programs enabled by the infrastructure this project supports are organized around special focus programs consisting of workshops, research workshop groups, tutorials, and a visitor program, on topics including Computational and Mathematical Epidemiology; Algorithmic Foundations of the Internet; Hardness of Approximation; Algorithmic Decision Theory; Cybersecurity; Sharing Information; Computational Problems in Medical Informatics; Algorithms and Energy; and Dynamic Data Analysis. Educational programs similarly enabled integrate research and education across levels from precollege through postdoctoral via activities including an extensive Research Experiences for Undergraduates program; a Reconnect program run at satellite locations around the country for 2-year and 4-year college faculty highlighting recent research topics relevant to the classroom; a year-round program of workshops for middle and high school teachers; development of modular materials at the interface between the biological and mathematical sciences for use in high schools; development of high school classroom modules related to computational thinking and to data analysis and homeland security; and a program of advanced study institutes in bio-mathematics for US and African graduate students.","title":"CMISS: DIMACS Project on CS\/Math in Service to Society","awardID":"1032010","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["540234","540234","264120","264120"],"PO":["565251"]},"163701":{"abstract":"This research involves design and building of a three-dimensional (3D) microarray device, with position-controlled microspheres, to perform simultaneous, efficient, and accurate screening of complementary DNAs, RNAs, and protein receptors on a single platform. This new device is portable, self-contained, automatic, and cost effective. Applications of this device include medical screening, drug discovery, and gene sequencing. In particular, it performs inexpensive disease diagnosis and provide insight into the molecular basis in different patients.<br\/><br\/>In existing 3D microarrays, microspheres are placed randomly within a substrate. This random placement of the microspheres makes their packing inefficient and their data processing complex. To overcome these drawbacks, the investigators design and build new microarrays with position-controlled microspheres. They analyze the statistical accuracy in estimating the target concentrations by computing performance bounds, and apply the results to select the minimal distance between the microspheres and the best operating temperature, while ensuring desired optimal estimation accuracy. The minimal microsphere distance enables high packing, and the optimal temperature reduces the cost. The investigators implement the position-controlled microarray using a microfluidic approach; particularly, they emplace the microspheres using a hydrodynamic trapping mechanism and using on-chip microvalves and pumps. The long-term goal is to integrate this device with image sensors, electronics, and optofluidic imaging to build a complete lab-on-a-chip system.","title":"CIF: IHCS: Medium: Collaborative Research: Design and Implementation of Position-Encoded 3D Microarrays","awardID":"0963742","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["449854",438224],"PO":["564898"]},"174723":{"abstract":"Facial expression is central to human experience. Its efficient and valid measurement is a challenge that automated facial image analysis seeks to address. Currently, few publically available, annotated databases exist. Those that do are limited to 2D static images or video of posed facial behavior. Further development is stymied by lack of adequate training data. Because posed and un-posed (aka ?spontaneous?) facial expressions differ along several dimensions including complexity, well annotated video of un-posed facial behavior is needed. Moreover, because the face is a three-dimensional deformable object, 2D video is insufficient. A 3D video archive is needed.<br\/><br\/>This project develops a 3D video corpus of spontaneous facial and vocal expression in a diverse group of young adults. Well-validated emotion inductions elicit expressions of emotion and paralinguistic communication. Sequence-level ground truth is obtained via participant self-report. Frame-level ground-truth is obtained via facial action unit coding using the Facial Action Coding System. The project promotes the exploration of 3D spatiotemporal features in subtle facial expression, better understanding of the relation between pose and motion dynamics in facial action units, and deeper understanding of naturally occurring facial action.<br\/><br\/>The project promotes research on next-generation affective computing with applications in security, law-enforcement, biomedicine, behavior science, entertainment and education. The multimodal 3D video database and its metadata are for the research community for new algorithm development, assessment, comparison, and evaluation.","title":"EAGER: Spontaneous 4D-Facial Expression Corpus for Automated Facial Image Analysis","awardID":"1051103","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["511701"],"PO":["564316"]},"174976":{"abstract":"Software Engineering research is one of the enablers in societal grand challenges such as Health Care, and Software Engineering researchers need to be involved to attain long-term workable solutions. For example, current efforts to make health data available electronically on a national scale could benefit from research in software architectures and software engineering economics to avoid locking into systems with inherently limited capabilities and evolvability. This project will conduct a case study of health record systems, in collaboration with the School of Medicine, leading to architectural specifications that will be the basis for prototypes and a test bed for interoperable Health Care applications. This will enable software researchers to understand the costs and risks of architectural design decisions in building the Health Care systems of the future. Demonstrations and evaluation will be built on the Eclipse-based IBM Jazz platform. The project will explore what role that the large body of Software Engineering research can play in this societal grand challenge.","title":"EAGER: Software Engineering Research for Societal Grand Challenge Problems","awardID":"1052874","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[469318],"PO":["564388"]},"172677":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040614","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["528445"],"PO":["565090"]},"183567":{"abstract":"Emerging general-purpose high performance computing and storage resources provide great opportunities to tackle grand challenge problems in science and engineering. However, most systems do not have adequate support to meet special requirements of a number of ultra-scale dynamic scientific applications due to lack of application-awareness. These computation and data intensive applications are aimed to model and investigate highly dynamic and sometimes drastically changing phenomena in science and engineering, such as interacting black holes, global and regional high-resolution weather forecasting, combustion and detonation simulation, and many others. Furthermore, it is challenging and time-consuming for scientists\/engineers to develop their large-scale parallel and distributed scientific applications from scratch.<br\/><br\/>This project fills the gap and aims to (1) create an integrated framework of scalable adaptive runtime management algorithms, libraries, and toolkit (called SMART) with friendly programming models so that scientists can write sequential programs to achieve automatic parallelism and high performance and throughput; (2) design a suite of application-aware adaptive algorithms to holistically address various issues in computation, communication, data, and energy management in systems with thousands of processors (such as clusters, grids, and clouds); and (3) enable high-impact real-world large-scale scientific applications with additional tools for simulation and visualization.","title":"CAREER: SMART: Scalable Adaptive Runtime Management Algorithms and Toolkit for Large-Scale Dynamic Scientific Applications","awardID":"1128805","effectiveDate":"2010-09-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1045","name":"CAREER: FACULTY EARLY CAR DEV"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["530695"],"PO":["565272"]},"172578":{"abstract":"This project is aimed at the design and experimental validation of a comprehensive clean-slate future Internet architecture. The proposed MobilityFirst architecture is motivated by the ongoing paradigm shift of Internet usage from today?s fixed PC\/host (client)?server model to emerging mobile data services and pervasive computing applications. The major design goals of the architecture are: mobility as the norm with dynamic host and network mobility at scale; robustness with respect to intrinsic properties of the wireless medium; trustworthiness in the form of enhanced security and privacy; usability features such as support for context-aware services, evolvability, manageability and economic viability. The key components of the MobilityFirst network design are: (1) separation of naming and addressing, implemented via a fast global dynamic name resolution service; (2) self-certifying public key network addresses to support strong authentication and security; (3) generalized delay-tolerant routing with in-network storage for packets in transit; (4) flat-label internetwork routing with public key addresses; (5) hop-by-hop transport protocols operating over segments rather than an end-to-end path; (6) a separate network management plane that provides enhanced visibility; (7) optional privacy features for user and location data; and (8) an integrated computing and storage layer to support programmability. The project?s scope includes architectural design, validation of key protocol components, testbed prototyping of the MobilityFirst architecture as a whole, and real-world protocol deployment on the GENI experimental infrastructure. The results of this project will provide architectural guidance for cellular-Internet convergence, and are expected to influence future technical standards in the networking industry.","title":"FIA: Collaborative Research: MobilityFirst: A Robust and Trustworthy Mobility-Centric Architecture for the Future Internet","awardID":"1040020","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["557855"],"PO":["565090"]},"174514":{"abstract":"This research project is tackling challenges associated with migrating enterprise applications to the cloud, including (i) models to predict the impact on performance; (ii) methodologies for assurable policy reconfiguration; and (iii) architectures for cloud data-centers that can provide quality of service guarantees. This project is exploring how GENI can help validate our research, and will use resources including ProtoGENI, Planetlab, and Openflow.<br\/><br\/>Intellectual Merit: Evaluations using a realistic environment such as GENI will (i) aid in determining models for predicting application performance that make an appropriate trade-off between accuracy and complexity; (ii) enable evaluation of designs for cloud data-center architectures; and (iii) lead to insights on principles for architecting cloud data-centers.<br\/><br\/>Broader Impact: If successful, the project will have a transformative effect on IT organizations by enabling them to migrate to the cloud. The project will train graduate and undergraduate students on the use of GENI.","title":"EAGER: Enabling research on migrating enterprises to the cloud using GENI","awardID":"1049941","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["508447"],"PO":["564993"]},"163866":{"abstract":"With technology scaling and increasing integration density in the nanometer technology regime, design considerations for yield and reliability have become critical. The objective of this collaborative research is to explore low-overhead formal design methodology with distributed micro-scale sensor network and systematic feedback control to achieve auto-curing of digital, analog and mixed-signal electronic systems under large process and temporal variations. Such auto-curing approaches will play a key role in preventing yield loss for nanoscale designs, while ensuring reliability of operation and low power dissipation. The research investigates self-curing concepts\/techniques for logic circuits, digital signal processing (DSP) units, embedded memory and analog components using appropriate variation sensing and compensation techniques to achieve high yield with optimal power\/die-area overhead. It also explores system-level self-curing approaches using global parameter sensor and global controller to determine optimal compensation of mixed-signal cores under power constraint. To realize the curing methodologies in an automatic synthesis environment, the research will aim at developing appropriate Computer-Aided Design tools and a library of self-correcting mixed-signal cores. <br\/><br\/>If successful, it will help the semiconductor industry deliver complex nanoelectronic systems with high reliability, low power and high yield. The proposed research will integrate education and training through course development, summer research program for undergraduates, and senior project design.","title":"SHF: Medium: Collaborative Research: System Level Self Correction Using On-Chip Micro Sensor Network and Autonomous Feedback Control","awardID":"0964514","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["530582"],"PO":["562984"]},"174635":{"abstract":"Very few real-life phenomena are ever as simple as A causes B ? a bivariate relationship. Take for example economic forecasting: it is a function of unemployment, consumer confidence, inflation, interest rates, and many other factors. There is not one single variable that can solely predict the state of the economy in the next few months. Similar is true in the study of global warming, in the derivation of gene interactions, in the analysis of customer recommendation systems, and so on. Multivariate relationships are ubiquitous and they have always existed. However, with the growth in sensor technology, whatever the data collection mechanism might be (electronic media, physical devices, etc.); we now have a wealth of data available to study in many domains, small and large. Currently, automated and unsupervised methods often fail once the number of variables (dimensions) grows beyond a dozen or even less; hence visualization techniques for user-assisted analysis play an important role. Responding to this need, this exploratory project develops a novel framework that makes high-dimensional (multivariate) data visualization more accessible to all. It couples powerful data analysis with an intuitive exploration and way-finding paradigm ? akin to a tourist map ? to help users navigate high-dimensional data spaces with ease. <br\/><br\/>The overall goal of the project is to facilitate intuitive navigation and exploration of high-dimensional data spaces, improving comprehensibility and reducing unnecessary complexity. This is achieved by: (1) unrolling the high-dimensional space into a landscape map; (2) enabling users to navigate the map and local subspaces of the data via an interactive data projection utility controlled by a touchpad interface; (3) allowing users to insert interesting observations (i.e., data projections) into this map; (4) augmenting the map with background overlays depicting informative globally defined data; and (5) conveying the data within a level-of-detail illustrative visualization framework. The system is evaluated and refined via formal user studies, both with domain scientists in interviews and in a crowd-sourced setting over the web.<br\/><br\/>This novel information visualization approach will provide support to both scientists and casual users to explore high dimensional data spaces in an intuitive navigation paradigm. The project webpage (http:\/\/www.cs.sunysb.edu\/~mueller\/TripAdvisorND) will be used for results dissemination, including data analysis capabilities within a web-enabled version of the software and also used to invite to participation in evaluation studies. This exploratory research project provides a rich research and educational experience to students.","title":"GV: EAGER: Navigation, Exploration and Visualization Tools for Knowledge Discovery in High Dimensional Data Spaces","awardID":"1050477","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["486115"],"PO":["563751"]},"173315":{"abstract":"The human ability to use language flexibly is a hallmark of robust intelligence. In interactive dialog, utterances are dynamically tailored to the common ground or specific context with specific partners. However, interaction with spoken dialog systems is highly constrained and constraining, allowing speakers very little flexibility in what they can say while the system presents pre-determined messages. To make interactive dialog technology broadly useful, this exploratory interdisciplinary project collects a corpus of dialogs exhibiting some important sources of variation, analyzes the corpus, and uses the resulting analyses to develop models and prototype implementations of dynamic dialog strategies. The ultimate goal of this effort is to support the synthesis of entirely new, flexible, and robust spoken dialog systems that are capable of adapting on-line. <br\/><br\/>The Walking-Around corpus consists of 40 human-human dialog interactions where a remotely located person gives directions to a pedestrian walking around in an urban or campus environment. The experimental paradigm varies the friendship relationship of the dialog partners, whether the director can see what the pedestrian sees, and the familiarity of both the director and the pedestrian with the environment. No other existing direction-giving corpora model dialog interaction in an outdoor real-time environment where the physical context grounds the dialog context. The resulting corpus is used to test hypotheses about, and develop models of, the evolution of local and global dialog adaptation strategies. Key to our effort is determining which adaptations are actually functional, that is, beneficial for a particular task or context in spoken dialog systems.","title":"EAGER: Collaborative Research: Modeling Distinctive Partners in Adaptive Spoken Dialog","awardID":"1043665","effectiveDate":"2010-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["483394"],"PO":["565215"]},"173557":{"abstract":"The Seattle Children's Hospital is awarded a grant to conduct two workshops that will address the opportunities offered by cloud computing to confront the task of uncovering scientific knowledge from enormous amounts of data generated by biological research. The workshop goals are responsive to the NSF strategic vision on Cyberinfrastructure Framework for 21st Century Science and Engineering, which challenges the community to develop and sustain the necessary cyberinfrastructure capable of enabling science and engineering in the 21st century. Cloud computing offers an unprecedented opportunity to address the challenges of this data bottleneck and open up a new era in Data-Intensive Science (DIS). The two workshops will bring practitioners in biological informatics together to discuss challenges, opportunities and strategies in order to propose short- and long-term strategies to take on these challenges. There is a significant and very timely potential for widespread applicability in that there are many disciplines that now routinely generate data sets that overwhelm storage and analysis infrastructures. The workshops will showcase not only the communities and their challenges, but, more importantly, address how best to meet those challenges. <br\/><br\/>The workshops will connect computational, data analysis, and inter-disciplinary research communities, including researchers, analyzers, developers, educators, community and tribal leaders, scientific administrators, and policymakers. This will enable both high-level (strategic) and specific (operational) discussions and developments of the user requirements, user-based evaluations, and standardized development with broad impact beyond the particular community challenges. <br\/><br\/>Cloud computing can have a major impact at helping four main types of diversity issues and institutions. First, clouds have the potential to allow access to extensive compute resources to research groups from all sizes of institutes, but particularly the small to mid-sized institutes that cannot afford to increase their local compute infrastructure. Similarly, secondly, minority-serving institutes (e.g. Howard University) and, thirdly, gender-serving institutions (e.g. Wellesley College) can take advantage of a common resource to boost their compute capabilities. Fourth, young investigators can have ready access to resources outside of their current support levels while more senior investigators can adapt to the increased need for compute resources in their field. <br\/><br\/>These workshops will be held in September 19-20, 2010 (Seattle, WA; Seattle Children's Research Institute) and March 20-21, 2011 (Washington, D.C.; J. Craig Venter Institute). Further information on the workshops and their outcomes will be available via the PI's lab home page at http:\/\/kolkerlab.proteinspire.org\/.","title":"Data-Intensive Science Workshops, to be held Sept. 19 to 20, 2010, Seattle, WA; and Mar 20 to 21, 2011, Washington DC","awardID":"1045040","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8010","name":"Computing in the Cloud"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":[465668],"PO":["496031"]},"175746":{"abstract":"In the mid-1980s a flurry of ground-breaking papers introduced polynomial-time elliptic-curve point counting, the elliptic-curve method of factoring integers (ECM), primality proving using elliptic curves (ECPP), and elliptic-curve cryptography (ECC). The original papers triggered thousands of followup papers, demonstrating a spectacular series of interactions between mathematics, computer science, and engineering, with a profound impact on applications: for example, the government's current \"Suite B\" security standards recommend switching from RSA to ECC.<br\/><br\/>The \"Workshop on Elliptic Curves and Computation\" will celebrate the 25th anniversary of these papers and the subsequent 25 years of theory and practice of elliptic-curve computations. This workshop will include the 14th annual ECC workshop. The workshop will take place 18-22 October 2010 at the Microsoft campus in Redmond, Washington, with a full week of carefully selected invited lectures, including lectures on the most exciting recent research in the area.","title":"Workshop on Elliptic Curves and Computation","awardID":"1057551","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["548359"],"PO":["565157"]},"173239":{"abstract":"By focusing on a set of the physical-structural foundations of dreaming, this research will investigate: (1) new organizational principles for parallel computation and (2) why dreaming is critical to intelligence. <br\/><br\/>Seemingly against all survival instincts, all intelligent beings must sleep and dream, even if they are under duress, even if it endangers their very lives because they are in a hostile environment. Sleep that includes dreaming is strongly related to efficient mental processes. The thesis of this work is that the need to dream can be inferred from the brain's most striking physical and behavioral characteristics. <br\/><br\/>The computer architecture that will be investigated is the DALI (Dream Architecture for Lateral Intelligence) a true Multiple Instruction, Single Datastream (MISD) architecture in which multiple models process the same input stream in real-time. While awake, some lateral processors are observers while one or more others are active. A dream phase of computation resolves divergence between processors in a competitive feedback phase not dominated by a flow of logic. Reality contains multiple views of the same thing, between different individuals and within the same individual, with incongruence resolved over time. The goal of the DALI is to include multiple, lateral models that process what the system observes, and then to model the competitive process of model resolution during a dream phase so that the system may be more effective for the next day's real-time (awake) response. The initial problem which will be investigated is contextual partitioning for speech recognition in pervasive, portable computing devices.","title":"Computational Dreaming","awardID":"1043341","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[464680],"PO":["565303"]},"175329":{"abstract":"The SDR 10 Technical Conference and Product Exhibition will be held November 30th to December 3rd in Washington D.C. This preeminent technical conference is the primary venue for presenting new research results in the software defined and cognitive radio technologies including multimode\/multiprotocol terminal design, Multimode Terminal and Infrastructure Design, Security Services, Mobile Ad-Hoc and Dynamic Spectrum Access Networking, Standards, Certification and Validation, Testing and Tools. Participants have the opportunity to present their work, attend panel and keynote talk sessions, and interact with many others performing leading-edge research in the field.<br\/><br\/>Attending this conference will provide students with exposure to industry and the real problems they will face when entering the workforce in the design, development, manufacture and deployment of advanced wireless systems. Such exposure will help them to better understand how their course work at university applies in a real world setting, and will accelerate the pace at which they become productive upon graduation. At the conference they will meet and interact the leading researchers and practitioners in this field. <br\/><br\/>This proposal requests funding to support approximately 16 graduate and undergraduate students in the United States to attend this premiere conference. Travel scholarships will be awarded to students based on academic merit and preference will be given to students in NSF under-represented categories including women and minorities.","title":"Student Travel Support for SDR'10","awardID":"1054767","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560088"],"PO":["557315"]},"168707":{"abstract":"Compositional security is a recognized central scientific challenge for trustworthy computing. Contemporary systems are built up from smaller components. However, even if each component is secure in isolation, the composed system may not achieve the desired end-to-end security property: an adversary may exploit complex interactions between components to compromise security. <br\/><br\/>This project addresses this important problem by developing a general model of systems and adversaries and techniques for modular reasoning and design. A central idea is to view a trusted system in terms of the interfaces that the various components expose: larger trusted components are built by combining interface calls in known ways; the adversary is constrained to the interfaces it has access to, but may combine interface calls without restriction. At a technical level, we are developing an expressive concurrent programming language with recursive functions for modeling interfaces and higher-order data for modeling code obtained at run time, and a logic of programs to capture reasoning principles for compositional security. We are using this framework to develop a systematic basis for web security, to formalize attacker models for web browsers proposed in literature and develop new ones, and to build an understanding of relevant security policies, end-to-end security properties, attacks in the wild, and ways to defend and prove web applications secure against these attacks. This study could have impact on security mechanisms and policies used in web applications in practice. The reasoning methods developed in the project will be mechanized in a tool.","title":"TC: Small: Compositional End-to-End Security for Systems","awardID":"1018061","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[451558,"550854","475098"],"PO":["565327"]},"168828":{"abstract":"Seamless understanding of the meaning of visual images is a key property of human cognition that is far beyond the abilities of current computer vision programs. The purpose of this project is to build a computational system that captures the dynamical and interactive aspects of human vision by integrating higher-level concepts with lower-level visual perception. If successful, this system will be able to interpret visual scenes in a way that scales well with the complexity of the scene. Current computer vision systems typically rely on relatively low-level visual information (e.g., color, texture, shape) to classify objects or determine the overall category of a scene. Such categorization is typically done in a \"bottom-up\" fashion, in which the vision system extracts lower-level features from all parts of the scene, and subsequently analyzes the extracted features to determine which parts of the scene contain objects of interest and how those objects should be categorized. Such systems lack the abilities to scale to large numbers of visual categories and to identify more complex visual concepts that involve spatial and abstract relationships among object categories. Visual perception by humans is known to be a temporal process with feedback, in which lower-level visual features serve to activate higher-level concepts (or knowledge). These active concepts, in turn, guide the perception of and attention given to lower-level visual features. Moreover, activated concepts can spread activation to semantically related concepts (e.g., \"wheels\" might activate \"car\" or \"bicycle\"; \"bicycle\" might activate \"road\" or \"rider\"). In this way there is a continual interaction between the lower and higher levels of vision, which allows the viewer to focus on and connect important aspects of a complex scene in order to perceive its meaning, without having to pay equal attention to every detail of the scene. The system proposed here will model these aspects of human visual perception. <br\/><br\/>The proposed system, called Petacat, will integrate and build on two existing projects: the HMAX model of object recognition originally developed by Riesenhuber and Poggio, and the Copycat model of high-level perception and analogy-making, developed by Hofstadter and Mitchell. HMAX models the \"what\" pathway of mammalian visual cortex via a feed-forward network that extracts increasingly complex textural and shape features from an image. (HMAX has been reimplemented, as the \"Petascale Artificial Neural Network\" or PANN, by the Synthetic Vision Group at Los Alamos to allow for high-performance computing on large numbers of neurons.) Copycat implements a process of interaction between high-level concepts and lower-level perception, and has been used to model focus of attention, conceptual slippage, and analogy-making in several non-visual domains. This project will marry the feature extraction abilities of HMAX\/PANN with the higher-level interactive perceptual abilities of Copycat to build the Petacat architecture. The image interpretation abilities of Petacat will be evaluated on families of related semantic visual recognition tasks (e.g., recognizing, in a flexible, human-like way, instances of \"walking a dog\"). The evaluation part of the project will involve the creation of image databases for benchmarking semantic image-understanding systems. The Petacat source code and benchmarking databases will be made publically available via the web.","title":"Collaborative Research: RI: Small: A Scalable Architecture for Image Interpretation","awardID":"1018691","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[451860],"PO":["564318"]},"168718":{"abstract":"It is well-observed that the whole world is full of data that are highly related and of diverse data object types such as people, organizations, and events. In many applications, it is intended to discover the hidden structures through such relationships involving different types of data objects in the world, in addition to \"clusters\" of the same type of data objects. On the other hand, relational data learning typically involves a large collection of data objects and thus algorithms for relational data learning are computation-intensive as well as data intensive. This calls for massively parallel solutions in order to make the algorithms scalable to large collections of data. This project addresses a three year integrated research and education program focusing on engaging in-depth research in developing novel parallel frameworks for a wide spectrum of state-of-the-art solutions to a series of fundamental problems in relational data learning. This research promotes the revolutionized understanding of relational data learning in the context of distributed computation environment. The project addresses fundamental problems in the literature of relational data learning as well as the expected breakthrough in the interdisciplinary and multidisciplinary research communities including parallel computation and scheduling, data mining and machine learning, and pattern analysis. The technologies generated from the research can be immediately deployed in important applications such as social network analysis, biological information discovery, financial and economic development analysis and prediction, natural disaster prediction, as well as military intelligence analysis. <br\/><br\/>Project url: <br\/><br\/>http:\/\/www.fortune.binghamton.edu\/nsf-iis-1017828.htm","title":"DC:Small:Collaborative Research:Data Intensive Computing for General Relational Data Learning","awardID":"1018114","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["564706"],"PO":["564316"]},"168839":{"abstract":"Through-Silicon-Via (TSV) provides the possibility of arranging heterogeneous components across multiple dies at a fine level of granularity in 3D ICs. This can result in significant decrease in the overall wire length, delay, power, and form factor. Primarily due to their large size compared with other layout objects, however, TSVs cause significant non-uniform density distribution in various layers. This density issue is expected to cause trouble during chemical mechanical polishing (CMP) and require TSV-aware solutions. In addition, the CTE (coefficient of thermal expansion) mismatch between TSV copper and silicon causes significant thermal mechanical stress to the devices nearby during TSV manufacturing and circuit operation. This in turn affects the timing and power characteristics of the devices. The mechanical reliability of the substrate and devices are also affected by TSVs. However, little is known on what design tool and methodology changes are required to improve the manufacturability of TSV-based 3D ICs. This project would investigate three key DFM\/DFR areas specific to 3D IC integration, namely, TSV-induced stress effect and its impact to the overall circuit timing and power, TSV impact to CMP and lithography, and TSV-induced reliability. Successful completion of the project would help us to gain in-depth understanding of manufacturability and reliability issues with 3D ICs and TSV technology and develop effective physical design solutions to overcome these issues. The proposal calls for a very strong collaboration between the researchers from the manufacturability and reliability modeling, simulation, and validation area and the researchers from circuit and physical design area for 3D ICs.","title":"SHF: Small: Collaborative Research: Design for Manufacturability for 3D ICs with Through Silicon Vias","awardID":"1018750","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["535167"],"PO":["562984"]},"170610":{"abstract":"This project will advance systems modeling approaches by developing a suite of stochastic modeling approaches, coupled with geostatistical and machine learning techniques. The new system modeling approach will utilize both in situ and satellite remotely sensed data to improve system model parameters and model structure. These novel developments, together with observed data, will advance ecosystem and environmental sciences through computational thinking. The proposed approach will be used to develop a cyber-enabled stochastic carbon-weather system to provide more adequate quantification of regional carbon exchanges, which is critical to better understanding carbon-climate-atmosphere feedbacks and facilitating climate-policy making. <br\/><br\/><br\/>The proposed approach will transform the current system modeling approach by (1) developing a stochastic version of the deterministic differential equation models of ecosystems and environmental systems; (2) developing geospatial statistical techniques to fully exploit multifaceted observational data to improve model parameterization; (3) developing advanced statistical and machine learning techniques to further utilize observational data to improve model structure; and (4) applying the improved model to examine the societal and biogeochemical impacts of land use change. Advantages of the proposed cyber-enabled terrestrial ecosystem model will include: (1) Efficiently quantifying regional net carbon exchanges and associated uncertainty and (2) Improving system model parameters and structure using advanced statistical and machine learning techniques and spatiotemporal data acquired over the U.S. Project deliverables include: (1) An innovative, cyber-enabled carbon-weather system that can quantify net carbon exchanges and associated probabilistic information at high spatial and temporal resolution for the continental U.S. and (2) a suite of transformative advanced mathematical, statistical and system modeling techniques that could be applied to other complex modeling fields (e.g., hydrological modeling). This project will significantly advance ecosystem sciences with computational thinking and will provide a unique opportunity to train a new generation of scientists in a highly interdisciplinary research environment.","title":"CDI-Type II: Collaborative Research: A Paradigm Shift in Ecosystem and Environmental Modeling: An Integrated Stochastic, Deterministic, and Machine Learning Approach","awardID":"1027955","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["496146",456686],"PO":["564318"]},"171941":{"abstract":"The objective of this research is to develop an atomic force microscope based cyber-physical system that can enable automated, robust and efficient assembly of nanoscale components such as nanoparticles, carbon nanotubes, nanowires and DNAs into nanodevices. The proposed approach is based on the premise that automated, robust and efficient nanoassembly can be achieved through tip based pushing in an atomic force microscope with intermittent local scanning of nanoscale components. In particular, in order to resolve temporally and spatially continuous movement of nanoscale components under tip pushing, we propose the combination of intermittent local scanning and interval non-uniform rational B-spline based isogeometric analysis in this research.<br\/><br\/>Successful completion of this research would lead to foundational theories and algorithmic infrastructures for effective integration of physical operations (pushing and scanning) and computation (planning and simulation) for robust, efficient and automated nanoassembly. The resulting theories and algorithms will also be applicable to a broader set of cyber physical systems. <br\/><br\/>If successful, this research will lead to leap progress in nanoscale assembly, from prototype demonstration to large-scale manufacturing. Through its integrated research, education and outreach activities, this project will provide advanced knowledge in cyber-physical systems and nanoassembly for students from high schools to graduate schools and will increase domestic students? interest in science and engineering and therefore strengthen our competitiveness in the global workforce.","title":"CPS: Small: Collaborative Research: Automated and Robust Nano-Assembly with Atomic Force Microscopes","awardID":"1035844","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["508858"],"PO":["565239"]},"172700":{"abstract":"Today's Internet is under enormous pressure: there is a growing diversity of use models, an urgent need for trustworthy communication, and a growing set of stakeholders who must coordinate to provide Internet services.<br\/>The project is developing the eXpressive Internet Architecture (XIA), a potential new network architecture that is built around several key principles. First, XIA represents a single network that offers inherent support for communication between diverse principals including hosts, content, services, and unknown future entities. For each type of principal, XIA defines a narrow waist that dictates the API for communication and the network communication mechanisms. Second, XIA rests upon a foundation of intrinsic security in which the integrity and authenticity of communication is guaranteed using XIA's various self-certifying identifiers. Third, XIA enables flexible context-dependent mechanisms for establishing trust between the communicating principals, bridging the gap between human and intrinsically secure identifiers. Finally, recognizing the Internet's central role in our society, economic, policy, and usability considerations play a major role in XIA's design. The project includes user experiments to evaluate and refine the interface between the network and users, and studies that analyze the relationship between technical design decisions, and economic incentives and public policy.<br\/>The outcome of the project will be knowledge about a potential future network architecture that is inherently trustworthy, supports long-term evolution of network use models and network technology, and provides explicit interfaces for interaction between network actors. The architecture will also enable greater visibility and control for various stakeholders, including users, ISPs, and content owners.","title":"FIA: Collaborative Research: A Content and Service Friendly Architecture with Intrinsic Security and Explicit Trust","awardID":"1040757","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["553786"],"PO":["565090"]},"170643":{"abstract":"This project will advance systems modeling approaches by developing a suite of stochastic modeling approaches, coupled with geostatistical and machine learning techniques. The new system modeling approach will utilize both in situ and satellite remotely sensed data to improve system model parameters and model structure. These novel developments, together with observed data, will advance ecosystem and environmental sciences through computational thinking. The proposed approach will be used to develop a cyber-enabled stochastic carbon-weather system to provide more adequate quantification of regional carbon exchanges, which is critical to better understanding carbon-climate-atmosphere feedbacks and facilitating climate-policy making. <br\/><br\/><br\/>The proposed approach will transform the current system modeling approach by (1) developing a stochastic version of the deterministic differential equation models of ecosystems and environmental systems; (2) developing geospatial statistical techniques to fully exploit multifaceted observational data to improve model parameterization; (3) developing advanced statistical and machine learning techniques to further utilize observational data to improve model structure; and (4) applying the improved model to examine the societal and biogeochemical impacts of land use change. Advantages of the proposed cyber-enabled terrestrial ecosystem model will include: (1) Efficiently quantifying regional net carbon exchanges and associated uncertainty and (2) Improving system model parameters and structure using advanced statistical and machine learning techniques and spatiotemporal data acquired over the U.S. Project deliverables include: (1) An innovative, cyber-enabled carbon-weather system that can quantify net carbon exchanges and associated probabilistic information at high spatial and temporal resolution for the continental U.S. and (2) a suite of transformative advanced mathematical, statistical and system modeling techniques that could be applied to other complex modeling fields (e.g., hydrological modeling). This project will significantly advance ecosystem sciences with computational thinking and will provide a unique opportunity to train a new generation of scientists in a highly interdisciplinary research environment.","title":"CDI-Type II: Collaborative Research: A Paradigm Shift in Ecosystem and Environmental Modeling: An Integrated Stochastic, Deterministic, and Machine Learning Approach","awardID":"1028163","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[456785],"PO":["564318"]},"172711":{"abstract":"While the Internet has far exceeded expectations, it has also stretched initial assumptions, often creating tussles that challenge its underlying communication model. Users and applications operate in terms of content, making it increasingly limiting and difficult to conform to IP's requirement to communicate by discovering and specifying location. To carry the Internet into the future, a conceptually simple yet transformational architectural shift is required, from today's focus on where ? addresses and hosts ? to what ? the content that users and applications care about.<br\/>This project investigates a potential new Internet architecture called Named Data Networking (NDN). NDN capitalizes on strengths ? and addresses weaknesses ? of the Internet's current host-based, point-to-point communication architecture in order to naturally accommodate emerging patterns of communication. By naming data instead of their location, NDN transforms data into a first-class entity. The current Internet secures the data container. NDN secures the contents, a design choice that decouples trust in data from trust in hosts, enabling several radically scalable communication mechanisms such as automatic caching to optimize bandwidth. The project studies the technical challenges that must be addressed to validate NDN as a future Internet architecture: routing scalability, fast forwarding, trust models, network security, content protection and privacy, and fundamental communication theory. The project uses end-to-end testbed deployments, simulation, and theoretical analysis to evaluate the proposed architecture, and is developing specifications and prototype implementations of NDN protocols and applications.","title":"FIA: Collaborative Research: Named Data Networking (NDN)","awardID":"1040868","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7684","name":"STRATEGIC TECHNOLOGIES FOR CI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543560","552479","560926"],"PO":["565090"]},"172612":{"abstract":"Proposal #: 10-40207<br\/>PI(s): Qian, Lijun; Annamalai, Annamalai<br\/>Institution: Prairie View A&M University<br\/>Title: MRI\/Acq.: A Software-Defined Radio-Based Testbed for Next Generation Wireless Network Research<br\/>Project Proposed:<br\/>This project from an MSI, principally undergraduate university, acquiring\/building software-defined radio (SDR) platforms for wireless monitoring and surveillance, aims to test and verify theoretical results for synthetic Multiple-Input-Multiple-Output (MIMO) systems. The work will<br\/>- Enhance PHY and MAC visibility of operational wireless networks by distributed acquisition of RF signals and decodable frames and<br\/>- Facilitate evaluation and repeatable experimentations in ongoing research projects in the area of wireless communications and networking,<br\/>The project involves<br\/>- Development of software tools for trace collection and replay for repeatable experimentation;<br\/>- Collection of extensive wireless traces in campus environments to understand propagation characteristics, device types, and co-existence issues;<br\/>- Construction of device fingerprint database for commonly used wired devices; and<br\/>- Performance of synthetic MIMO experiments in a fully controlled environment.<br\/>Broader Impacts: <br\/>The experimental facility is likely to advance research in wireless monitoring and diagnosis by collecting comprehensive wireless traces and supporting design, analysis, and optimization of distributed space-time processing in both controlled and real-world deployment conditions. Complementing the existing apparatus for telecommunication system design within two centers, it should greatly strengthen and broaden wireless activity. Consequently, it will help students to obtain hands-on experience and expertise in theory and practice of experimental wireless and cognitive radio techniques. Thus it contributes to train highly skilled personnel in a critical area.","title":"MRI:Acquisition: A Software-Defined Radio Based Testbed for Next Generation Wireless Networks Research","awardID":"1040207","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["526765",462762],"PO":["557609"]},"173602":{"abstract":"Sketching in Hardware is a three day workshop to be held July 23 - 25, 2010 at the Encounter Restaurant inside the historic LAX Theme Building at the Los Angeles International Airport. The focus of this annual meeting is on the design, use and teaching of physical computing toolkits. Current electronic hardware is enormously powerful, but much of that power is out of reach of people without a specialized formal education in electrical engineering and computer science. Sketching in Hardware brings together leading international representatives from a variety of fields to discuss digital hardware prototyping for people with little or no engineering background, and to identify how to advance it. The meeting presents new ideas, identifies challenges and opportunities, and introduces people who go on to collaborate on new methods, techniques and technologies. The workshop aims to continuously lower the barrier to entry into working with digital hardware by creating a dialogue between disciplines (such as hardware manufacturing and industrial design education) that rarely interact directly. Its goals are to: 1)Encourage development of new toolkits and expansion of existing ones; 2) Support the interconnection of existing toolkit technologies; 3) Create software that support explorations of electronics hardware exploration by non-specialists through interfacing with familiar software creative tools; 4)Identify common challenges and create opportunities for collaboration in solving those challenges.<br\/><br\/>Sketching in Hardware is the only annual gathering devoted exclusively to the discussion of digital hardware tools for non-specialists. The information shared at the meeting creates opportunities for cross-toolkit functionality that broadens users' access to technologies, shares experiences and techniques for designing with these tools and teaching with them. Toolkit designers and manufacturers use the information they share to build on each other's work, and get direct exposure to educators and users at the leading edge in terms of using their tools. Educators find new tools to work with, guide the development of existing tools, and share techniques and resources for teaching. By creating a discussion among people working in this field, the information shared at the meeting helps keep toolkit makers from reinventing wheels that others have already developed, creates opportunities for cross-toolkit functionality that broadens users' access to technologies and shares experiences and techniques for designing with these tools and teaching with them. The workshop regularly leads to the development and dissemination of new tools for working with electronics and encouraging computational thinking. It regularly leads to the creation of new techniques and the cross-pollination of important information across disciplines.","title":"2010 Sketching in Hardware Workshop","awardID":"1045278","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[465788,"499583"],"PO":["565227"]},"161623":{"abstract":"The last decades of the 20th century witnessed the emergence of networks that have become ever more pervasive and important. At the start of the 21st century developing a scientific understanding of networks remains an unresolved intellectual endeavor. Part of this effort is the understanding of wireless communication networks on a fundamental level pursued in this project. The research formulates optimization problems that model wireless networks in a variety of settings and translates properties of the former into characteristics of the latter. For doing so, the investigators rely on the fact that randomness, in the form of fading, yields seemingly more complex problems that nonetheless have a more tractable structure. This richer structure is studied to: (i) Determine architectural properties of wireless networks. (ii) Design algorithms to find optimal operating points for different types of physical layers. (iii) Develop strategies to learn fading distributions. (iv) Consider tradeoffs associated with acquisition of channel state information.<br\/><br\/>The education agenda revolves around the excitement, challenge and discipline gaps. The excitement gap is about the excitement people feels about science and technology versus the lack of interest to pursue careers in science and technology. The challenge gap refers to the ongoing trend to reduce the complexity of material covered in courses. The discipline gap alludes to the compartmental experience offered to students and the reality of an increasingly hazy separation between disciplines. The education plan contributes to the closing of these gaps through the development of an undergraduate level course on stochastic processes and a graduate level course on optimal design of wireless networks. Both of these courses are designed to be challenging, exciting and multidisciplinary.","title":"CAREER: Towards a Formal Theory of Wireless Networking","awardID":"0952867","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["541883"],"PO":["564924"]},"172513":{"abstract":"This project is aimed at the design and experimental validation of a comprehensive clean-slate future Internet architecture. The proposed MobilityFirst architecture is motivated by the ongoing paradigm shift of Internet usage from today?s fixed PC\/host (client)?server model to emerging mobile data services and pervasive computing applications. The major design goals of the architecture are: mobility as the norm with dynamic host and network mobility at scale; robustness with respect to intrinsic properties of the wireless medium; trustworthiness in the form of enhanced security and privacy; usability features such as support for context-aware services, evolvability, manageability and economic viability. The key components of the MobilityFirst network design are: (1) separation of naming and addressing, implemented via a fast global dynamic name resolution service; (2) self-certifying public key network addresses to support strong authentication and security; (3) generalized delay-tolerant routing with in-network storage for packets in transit; (4) flat-label internetwork routing with public key addresses; (5) hop-by-hop transport protocols operating over segments rather than an end-to-end path; (6) a separate network management plane that provides enhanced visibility; (7) optional privacy features for user and location data; and (8) an integrated computing and storage layer to support programmability. The project?s scope includes architectural design, validation of key protocol components, testbed prototyping of the MobilityFirst architecture as a whole, and real-world protocol deployment on the GENI experimental infrastructure. The results of this project will provide architectural guidance for cellular-Internet convergence, and are expected to influence future technical standards in the networking industry.","title":"FIA: Collaborative Research: MobilityFirst: A Robust and Trustworthy Mobility-Centric Architecture for the Future Internet","awardID":"1039657","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["549845"],"PO":["565090"]},"163801":{"abstract":"A key hurdle in studies of brain function is to be able to measure not only what signals are correlated with one another, but also how they are causally related. Correlation quantifies linear dependence, while causality is capable of distinguishing which brain area is leading the correlated counterparts; causality puts an arrow into correlation. Causality is a difficult problem in data analysis and here a novel measure of conditional statistical dependence to evaluate causality is proposed. The ultimate practical goal is to elucidate the principles of cognitive processing and provide online cognitive feedback to human subjects performing complex tasks. <br\/><br\/>The objective of this project is to use a recently developed paradigm for electroencephalogram (EEG) quantification based on periodic visual stimulation to improve the signal to noise ratio of visual stimulation on a pre-determined EEG frequency band (here around 10 Hz). The goal is to develop advanced signal processing techniques based on instantaneous frequency (Hilbert transform) to quantify the instantaneous amplitude of a visual stimulus in 32 channels over the scalp. <br\/><br\/>A recently developed measure of local statistical dependence in the joint space called correntropy will be utilized to evaluate the dependency among instantaneous amplitude time series collected over the scalp. The maximum value of correntropy is a measure of statistical dependence, which is the first step towards causality. To achieve a causality measure, conditional dependence will be evaluated by extending correntropy to conditional correntropy, first for triplets of variables and them to subspaces of arbitrary dimensions. Correntropy is a nonparametric measure of dependence; hence, the new method will be compared to linear and nonlinear Granger causality methods implemented in reproducing kernel Hilbert spaces.<br\/><br\/>These algorithms will be tested on data collected from human subjects in a study of affective visual perception. The goal is to study and quantify the re-entry hypothesis of emotional perception -- that re-entrant modulation originating from higher-order cortices is responsible for enhanced activation in the occipital cortex when emotionally arousing stimuli are perceived. The signal processing and statistical methods developed here will provide a way to identify dependent EEG channels and causal relationships amongst them during the presentation of the stimulus, effectively tracing the flow of neural activity from the stimulated visual areas to frontal areas and back to the visual cortex.","title":"RI: Medium: Quantifying Causality in Distributed Spatial Temporal Brain Networks","awardID":"0964197","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[438489,438490,438491],"PO":["564318"]},"172645":{"abstract":"Proposal #: CNS 10-40430<br\/>PI(s): Chu, Jul; Ahn, Seokyoung; Cunningham, Mark; Kumar, Sanjeev; Yoon, Jasang <br\/>Institution: University of Texas - Pan American<br\/>Title: MRI: Acquisition of a PC Cluster, High Performance Pan American Cluster (HiPAC)<br\/>Project Proposed:<br\/>This project, building a high-performance parallel computing instrument for numerical and network simulations, aims to support the following research projects:<br\/>- Reducing simulation time for uniprocessor and multiprocessor systems;<br\/>- Parallel sparse matrix solution using multi-core cluster with applications in analogue and digital VLSI systems; <br\/>- Biochemical computations with parallel numerical simulations;<br\/>- Future Internet switch architecture simulations and protocol validations;<br\/>- Investigation of the mixing behavior of the nano-particles in a polymer-based binder system for powder injection molding applications; and <br\/>- Quantum chemistry simulations on biomolecular active sites.<br\/>The proposed cluster, called High Performance Pan American Cluster (HiPAC), will be used by multiple scientists at the University of Texas-Pan American (UTPA), a predominantly a Hispanic institution. <br\/>Broader Impacts:<br\/>The instrument enables research in a minority serving institution that contains an 88% Hispanic and a 63% female population. The project involves student training in multi-core cluster technologies, including software and hardware parallelization. Moreover, student training encourages undergraduates to join graduate studies.","title":"MRI: Acquisition of a PC Cluster, High Performance Pan American Cluster (HiPAC)","awardID":"1040430","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[462901,462902,462903,462904,462905],"PO":["557609"]},"171215":{"abstract":"The statistical physics field is devoted to the macroscopic properties of matter using a variety of prob-abilistic, statistical and combinatorial tools. Recently, however, it became apparent that some of the tools and observations originating from statistical physics, have applications far beyond their intended scope and are found useful in a variety of fields outside of statistical physics, such as coding theory, information theory,statistical inference in Markov Random Field, and more recently in several core areas of operations research,such as combinatorial optimization and game theory. Specifically, it was discovered, partially in PI's prior work,that the so-called correlation decay (long-range independence) property studied in great depth in statistical physics, has far reaching applications for the design and analysis of algorithms. The goal of the present proposal is to develop this promising approach in a systematic way. Specifically, the PI intends to focus on designing fast (polynomial time) algorithms in the following three challenging algorithmic areas: a) computing pure and mixed Nash equilibrium in graphical games; b) designing deterministic approximation algorithms for counting the number of feasible solutions of an integer programming problem and the problem of computing a volume of a polytope; and c) combinatorial optimization\/integer programming problems with stochastic objectives. <br\/>This is an exciting new research agenda, which has not been pursued in the operation research field before. The research will lead to new algorithmic design tools and strengthen a newly emerging connections between the fields of algorithms, combinatorial optimization, game theory on the one hand, and statistical physics on the other hand.","title":"Statistical Physics Methods and Algorithmic Applications in Graphical Games and Combinatorial Optimization","awardID":"1031332","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":["555822"],"PO":["565139"]},"173998":{"abstract":"Current relational database systems (RDBMSs) were engineered for the business data processing market, and not for scientific users (e.g, astronomers, physicists, chemists, oceanographers, or earth scientists). By and large, science users either grumble and use RDBMSs or, more often, \"roll their own\" data management software. Significant projects, such as the Large Hadron Collider (LHC) and the NASA Mission to Planet Earth, have spent millions of dollars on custom software systems, with limited applicability to other projects. As such, after a generation of science applications, there is limited shared data management infrastructure. <br\/><br\/>SciDB is a project focused on building an open-source DBMS focused on the needs of science users. We have developed the requirements of SciDB based on a close collaboration with a number of scientists. Data management features include a nested array data model (rather than the tabular model of RDBMSs) with operations attuned to scientific data, a no-overwrite storage model (allowing interaction with historical results), and support for uncertainty, named versions and provenance information. <br\/><br\/>At this point, there is a distributed team of 17 programmers and scientists working actively on the design and implementation of SciDB, assisted by an advisory committee of 15 scientists. This team is primarily focused on the research issues surrounding the design of SciDB, and most contributors are involved in the project as volunteers or are paid by their individual organizations. <br\/><br\/>A demo of the first working proof-of-concept SciDB prototype was given at the VLDB conference in August 2009, and a first public release of SciDB is planned for September 2010. The purpose of this NSF grant is to enhance SciDB with additional science-oriented features, including time travel, versions, uncertainty and provenance. With NSF?s help, we expect to develop a full-function system by the end of the grant period.","title":"SI2-SSE: SciDB - A Scientific DataManagement System","awardID":"1047955","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["483585","525076"],"PO":["565247"]},"171457":{"abstract":"Science Gateways and portals are Web-based user interface and accessibility tools that provide user-centric views of cyberinfrastructure: they convert computing resources into tools for Web-based science and education. Although numerous production gateways have been developed, problems remain. How can operational gateways sustain themselves as underlying resources and middleware change? How can a gateway leverage modern commercial Web techniques like gadgets and social networking? How can a gateway wrap complicated science applications as robust services and workflows that really work in day-to-day operation? Can startup gateways reuse proven software from mature gateways and avoid reinvention? The research team addresses these problems through the Open Gateways Computing Environments (OGCE) collaboration, an integrated group of software developers and operational gateway providers. Key partner gateways include GridChem, GISolve\/SimpleGrid, the Purdue Scientific Data and CCSM Gateways, UltraScan, and MyOSG. <br\/><br\/>The goal of investigators is to provide high-quality implementations of software tools for Grid and Cloud-based scientific application management, workflow composition and enactment, and social network-capable gadget component management. The assembled team supports the full lifecycle of gateway software, from requirements gathering to operational use. This cycle is directly reflected in the project's structure. Feature requests, enhancements, and changes to the software are managed using the Apache meritocracy model. The team achieves long-term sustainability through participation in the Apache Software Foundation. Software developed by the researchers complies with relevant standards: scientific job management is provided through Web services generated by an application factory service; workflows are executed using open standards for enactment engines, and user interface components are compatible with the Open Social specification. Additionally the team investigates the extension of gadget components to the HUBzero framework.","title":"SDCI NMI Improvement: Open Gateway Computing Environments - Tools for Cyberinfrastructure-Enabled Science and Education","awardID":"1032742","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7683","name":"SOFTWARE DEVELOPEMENT FOR CI"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7476","name":"ETF"}}],"PIcoPI":["538222",459035,"558523","558524","540417"],"PO":["565247"]},"174603":{"abstract":"Compared to early Transaction Processing (TP) systems, today's TP systems have seen dramatic changes in both application requirements and underlying hardware support. As such, existing algorithms and design decisions hardly reflect reality and require revisiting them. However, more importantly, future generation TP systems must also necessarily evolve because of the emergence of energy efficiency as a first order design consideration.<br\/><br\/>This project is an early venture into a very new area, seeking to identify the most appropriate metrics for energy efficiency (QoE) in TP environments, the most appropriate ways to combine these energy efficiency metrics with existing quality of service (QoS) metrics and the most appropriate ways to specify any trade-off between QoE and QoS. Project plans also include the development of new scheduling algorithms and new TP system components that optimize a particular metric under different hardware configurations, as well as the experimental evaluation of the developed algorithms on simulation platforms and on real, state-of-the-art hardware.<br\/><br\/>This exploration potentially has great impacts in the development of new data management technologies. It is expected to advance the knowledge and understanding of the interplay among modern hardware components and facilitate the development of next generation TP systems that exploit new hardware features with the potential to achieve significant energy savings. This understanding could help formulate the foundations of the important area of energy-efficient data management, and thus, contribute to the societal goal of energy conservation and sustainability.<br\/><br\/>More information on the project can be found at http:\/\/www.energy-efficient-data-management.org\/tps.","title":"EAGER: Energy-Efficient Transaction Processing","awardID":"1050301","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["532922","532923"],"PO":["563727"]},"172799":{"abstract":"This award provides funding to the Association for Computing Machinery for core support of the activities of the Computer Science Teacher's Association (CSTA). The award is jointly funded by the CISE Broadening Participation in Computing Program and the CPATH Program. Through collaboration with leaders from all levels of education, government, industry, and partnering non-profit organizations, the CSTA is building a nation-wide coalition to improve K-12 computer science education and teaching and to increase student awareness of computer science as an important career pathway. CSTA provides a voice to K-12 educations involved in computing education. CSTA has launched national programs to conduct research, develop curriculum standards, provide professional development, and create and disseminate new resources for teachers. Through these activities, CSTA is building a community of individuals and organizations who collectively work together to address issues in K-12 computer science education.<br\/><br\/>The intellectual merit lies in the efforts to establish K-12 computer science as an essential academic discipline and to conduct fundamental research to document and support the emergence of K-12 computing education as a viable area of research and study. The CSTA relies on its leaders and volunteers, all recognized experts in the field, to develop and carry out many far-reaching programs and initiatives which solidify the discipline and provide an intellectual basis for core integration of computing into K-12 education. <br\/><br\/>The broader impacts lie in the potential of the CSTA initiatives to impact computing education and thus the nation?s technological workforce in an area of national need. Through multi-level collaboration with key stakeholders, the CSTA supports the implementation of curriculum and teaching certification standards that will ensure the quality and consistency of student learning. CSTA conducts and disseminates research and best practices that can facilitate the flow of knowledge from researchers to the practitioners in the classroom. The CSTA goals and activities support ensuring greater participation of underrepresented groups in the computing workforce. Thus, CSTA offers a broad range of programs and activities that provide a broad spectrum of impact on the nation, K-12 education, and the computer science community.","title":"Supporting Continued Improvements to K-12 Computer Science Education","awardID":"1041322","effectiveDate":"2010-09-15","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[463404],"PO":["565136"]},"163724":{"abstract":"Wireless ad-hoc networks consist solely of cheap, mobile nodes that operate in the absence of expensive fixed infrastructure such as base stations. In order to save energy, increase data rate, or improve robustness, some nodes may act as helper nodes, relaying some or all of the information. In the simplest form of relaying, data packets are forwarded node-by-node in a manner akin to a fire bucket brigade. In more advanced methods, such as those considered in this research, several nodes can cooperate to forward information. The key design questions are two-fold. First is the design of cooperative communication techniques, i.e., physical-layer approaches for relaying information from one set of nodes to the next. Second is routing, i.e., identifying which of the available nodes should participate in the transmission and what system resources (time, energy, bandwidth) should be allocated to each. <br\/><br\/>This research analyzes interconnections between these two key questions, treated separately in most prior work. We consider the routing problem when rateless codes are employed at the physical layer. Such codes allow receiving nodes to accumulate mutual information (instead of just energy) from multiple transmitting nodes. This yields greater network robustness and efficiency. The research investigates the effect of interference, which automatically arises when multiple messages are being transmitted simultaneously. By using stochastic network optimization, optimum resource allocation can be provided without the need for centralized knowledge of all states of nodes and propagation channels. Cooperative transmission techniques based on a hybrid of network-coding and compute-and-forward, their rateless variants, and application to cooperative routing are investigated as well. The concepts are validated through experiments.","title":"CIF: Medium: Collaborative Research: Cooperative Routing in Wireless Ad-Hoc Networks with Advanced PHY Layers: Interference Management, Resource Allocation, and Information Mixing","awardID":"0963834","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}}],"PIcoPI":["517551"],"PO":["564924"]},"174504":{"abstract":"An approach based on combinatorics and probability is proposed to tackle a number of problems in computational biology. This is part of an exploratory research for an EAGER grant that aims at extracting simple and elegant mathematical abstractions rather than focusing on the ?nitty-gritty? details of the biological problem. The rationale is the following: (1) Properties of combinatorial objects lead directly to algorithms for solving the problems that generate them and (2) combinatorial and probabilistic methods provide many analytical tools that can be used for determining the worst-case and expected performance of these algorithms. <br\/>To establish the validity of the approach, the PIs allow some breadth by considering three exemplar problems. This, however, is consistent with their long term goal to develop mathematical models that lead to viable computational algorithms and that can explain biological behavior at an aggregate level.<br\/>RNA interaction: An siRNA-based (small interfering RNA) treatment that may ultimately counteract HIV is now not far fetched. An siRNA is a special example of an RNA molecule that interacts with another RNA (e.g. that of HIV), in this case to knockout the HIV gene. Because of its role in gene regulation mechanisms, RNA interaction has a potential to become a new class of drugs. The PIs will conduct a research based on RNA-RNA interaction graphs to predict RNA complexes resulting from the interaction of two RNAs. While this prediction problem is NP-complete, the PIs have proposed novel and efficient approximation algorithms that predict known and unusual RNA complexes in E. Coli. The PIs will improve the running time\/approximation capability of the algorithms, apply the algorithms to a wide range of RNA complexes, and study the extension of the algorithms to handle multiple RNAs (not just two) using a combination of RNA-RNA interaction graphs and random search.<br\/>Protein interaction sites: Similarly, protein interaction is crucial for determining the function of protein complexes. Interaction graphs, however, do not provide a suitable model here because protein interaction is more complex. Instead, predicting the interaction sites of a protein becomes a central task. The PIs will implement a combinatorial approach based on folding the protein on a torus (closed helix) and geometrically grouping amino acids with certain properties (e.g. hydrophobic) to obtain clusters. The clusters represent potential interaction sites. One motivation for this approach is that hydrophobic helices tend to stay away from the solvent and, hence, to interact. Together with a mathematical model of random tori (that will also be developed), this new approach will potentially eliminate the need to predict the 3D folding of the protein (highly intractable problem) and overcomes the simplicity of methods that, otherwise, are entirely sequences based (ignore the geometry).<br\/>Low complexity sequences LCS: While structure resulting from folding and\/or interaction is an important aspect, the lack of structure in proteins raises an important question about the function of their sequences, especially when those sequences are preserved. The cell wall genes of fungi contain an abundance of LCS that are mostly structure-free. Understanding the function of LCS will help guide any effective medical treatment, for instance against uterine infections, that must target the fungus through its cell wall interface. The PIs believe that LCS evolve using a mechanism similar to DNA replication error, resulting in sequences with large deviations in length (a power law distribution). The PIs propose a probabilistic model of evolution that explicitly accounts for lengths and exhibits a similar distribution. This model will help explain the type of evolution that LCS undergo and will shed light on their function in the cell wall. The model will also provide an alternative to alignment-based methods which, despite many existing efforts, usually fail in the presence of LCS.<br\/>The intellectual merit of the proposal lies in providing essential foundation for a number of combinatorial\/probabilistic problems that require a strong knowledge of various fields of mathematics and algorithms, and provide radical ways to capture different aspects of Biology. Therefore, while the research has roots in combinatorial mathematics and probability, it has simultaneously a broader impact on biological sciences. Despite Biology being the driving force, the formulations are general enough and extend the research beyond its biological significance: RNA interaction introduces an interesting geometric graph problem that avoids intersection of edges. Protein interaction sites lead to an elegant problem on regular graphs. Evolution of LCS is captured by a general random walk that is applicable for many systems that exhibits random elongation and shortening over time, e.g. words in a sentence (linguistics). The proposal has also a broader imp","title":"EAGER: CCF-AF: Combinatorial and Probabilistic Aspects of Biological Problems","awardID":"1049902","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":[468102,468103],"PO":["565223"]},"172579":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040023","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["557855"],"PO":["565090"]},"175846":{"abstract":"As a consequence of the 2009 White House 60-Day Review, it became clear that the academic community working on cyber-security is in dire need of real data. The PREDICT portal is an effort to catalog and house the increasingly available research data, and per NSF's request, the needs of the academia for data have been documented. On the other hand, agencies, companies and organizations that do have data are seeking research innovations in the ?arms race? against cyber-attacks. The ?Cyber-security Data for Experimentation? will bring together people from companies\/organizations, academia, and government agencies to discuss (1) models of engagement that will allow the research community to conduct experiments with real-world data sets, (2) how to share research results, and (3) how funding agencies can facilitate the process. A guiding principle of the workshop is that the resulting models should be feasible with the built-in incentives to all parties involved, and the guarantees against violations of privacy or other regulations. The workshop will be organized around panel discussions of three topics: (1) Data availability and use conditions, (2) Research that can greatly benefit from available data to make much needed progresses in cyber-defense, and (3) Engagement models and related IP issues. This will be a one-day workshop, in the DC metro area, held on August 27th, 2010. The workshop will be broadcast to the community at large and will be open to questions and suggestions from the listeners.","title":"TC: Workshop on Real-World Cybersecurity Data for Research","awardID":"1057936","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["561756"],"PO":["565264"]},"173206":{"abstract":"Support for graduate and post-graduate student attendence of the 2010 North American School of Information Theory is provided. The 2010 school builds on the success of the First and Second Annual Schools of Information Theory held in 2008 at Penn State University and 2009 at Northwestern University. At the 2008 event, 101 students and 13 senior attendees participated; at the 2009 event, we had 141 students and 21 senior attendees participated. For the year 2010 school, 233 applications from 62 institutions were received, which represents a 40% growth in student participants over 2009 and a doubling over 2008. <br\/><br\/>The main motivation for the school is to provide a venue where doctoral and post-doctoral students can meet to discuss research, form friendships and collaborations, and learn how to actively and socially participate in scientific research. The students present themselves and their results in a friendly environment, interact with well-known senior scientists, and exchange ideas.","title":"Third Annual North American School of Information Theory","awardID":"1043196","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[464568],"PO":["564924"]},"174548":{"abstract":"This CISE Special Project provides funds to form an entity called the Computing Education Coordinating Council (CECC). The CECC is envisioned to be inclusive and wide ranging ultimately including all organizations with an interest in computing education. The starting point of the Council will be simple, with a small core of prominent computing education organizations, which will be responsible for laying the foundational for long-term sustainability of the CECC. Once it has achieved a higher level of maturity and acceptance, the CECC will be expanded into a larger and more robust group. This project was developed as a direct result of the NSF-funded Future of Computing Education Summit that took place in June 2009. The CECC project team plans to first develop a draft strategic plan for CECC start up that includes ideas and recommendations concerning CECC formation. Then the team intends to engage the leadership of the core computing education organizations in order to solidify CECC goals and activities, establish a two-three year strategic plan, and to secure their commitment to the CECC plan. <br\/><br\/>Intellectual Merit: The field of computing is somewhat paradoxical. Almost everyone recognizes its vital importance in their daily lives; computing is foundational for many other sciences; budgets for computing products and services continue to expand; and there is currently a high demand for competent computing professionals that extends well into the future. Yet, in the last decade there has been little or no growth in the enrollment in educational computing programs; the populations of computing students, educators, and professionals lack diversity; pre-university computing education has critical weaknesses in funding, teacher preparation and curriculum requirements; and the nature, content, and practices of the various computing professions are not well understood by the public. The alarming lack of women and minorities engaged in computing will have long-term impact on our ability to innovate. This lack of diversity of thought is finally being recognized as reaching crisis level by government and industry. Various computing organizations have worked independently to address these problems; however, working singly or in small groups does not have the same positive effect as a more substantial and universal approach. The purpose of the CECC is to present a unified view of how to address the significant challenges faced by computing education. <br\/><br\/>Broader Impact: The CECC will have a wide ranging and significant influence on the state of computing education. The Council will engage in endeavors that support and promote the following: ongoing research and scholarship in computing education to ensure effectiveness, relevance and currency through developments in pedagogy, curriculum, practice, and technology; improvement in pre-university computing education in the areas of teacher preparation and curriculum requirements; increased diversity in the populations of computing students, educators, and professionals; increased numbers of students pursuing degrees in various fields of computing, including computing education; improvement in the public understanding of the nature, content, and practices of various computing professions; and enhanced understanding about the relationship between computing and other disciplines.","title":"Advancing Computing Education: Formation of a Computing Education Coordinating Council","awardID":"1050075","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["521278","521278","468219",468219,468220,468221],"PO":["564181"]},"174439":{"abstract":"Information retrieval (IR) performance is typically measured in terms of relevancy: every document is known to be either relevant or non-relevant to a particular query. Furthermore, more relevant documents are expected to receive a higher rank than lower less relevant documents. However, determination of relevance and rank by users is not practical. Therefore, it is crucial to develop evaluation metrics and ranking functions that can be derived automatically from judgment data and user behavior data, rather than ad-hoc heuristics. This exploratory project investigates machine learning approaches for constructing evaluation metrics for Web search and information retrieval that consider along important directions other than relevance such as diversity, balance and coverage. <br\/><br\/>The approach is based on fundamentally extending the popular evaluation metric Discounted Cumulated Gains (DCG). Research focuses on developing optimization methods for learning DCG that can incorporate the degree of difference in pair-wise comparison of ranking lists. Machine learning methods that can learn DCG for the more realistic scenarios where the relevance grades are not readily available are explored, and nonlinear utility functions as evaluation metrics that can accurately capture the quality of search result sets in terms of relevance, diversity, coverage, balance and novelty are investigated.<br\/><br\/>The project has a number of broad impacts. Research results are expected to provide foundations for further research in evaluation metrics. Active collaborations with industry leaders in Web search will enable the resulting methods to have real impacts on search engine as well as large IR system performance improvements. Improving the quality of search results will have significant impacts on satisfying people's information needs as well as their quality of life in general. The set of research topics lies at the interface between information retrieval and machine learning applications and it provides an ideal setting for training undergraduate and graduate students in the emerging interdisciplinary field of Web of science and engineering research. The project Web site (http:\/\/www.cc.gatech.edu\/~zha\/metrics.html) will be used for results dissemination.","title":"III: EAGER: Learning Evaluation Metrics for Information Retrieval","awardID":"1049694","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["549456"],"PO":["563751"]},"168818":{"abstract":"In order to enable collaboration between different parties it is necessary that the partners reach an agreement on the policy rules that will govern their interaction. While state-of-the-art mechanisms will allow the parties to reconcile their polices, today's policy reconciliation protocols have two main shortcomings. First, they violate privacy since at least one of the parties is required to discloses all its information during the reconciliation process. Second, they generally lack fairness, i.e., the parties' preferences are not recognized. This research is geared to develop novel techniques that enable both private and fair policy reconciliation.<br\/><br\/>The benefits of this research go far beyond the field of policy reconciliation itself. In fact, policy reconciliation is expected to play an increasingly important role in managing and securing infrastructures and procedures, ranging from day-to-day activities such as scheduling an appointment online, to enhancing interoperation in today's cell phone infrastructure, to the architecture of the Future Internet.","title":"TC: Small: Distributed Privacy-Preserving Policy Reconciliation","awardID":"1018616","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["456465"],"PO":["565264"]},"167619":{"abstract":"Intellectual Merit. This project will develop the world?s first urban polymorphic wireless access network, a network that can radically transform its basic properties on-the-fly. A key step is deployment of infrastructure and client nodes that can access diverse spectral ranges spanning from MHz to GHz. This unique capability in spectrum access enables revisiting the foundations of network assessment, design, and access. This experimental approach capitalizes on an unprecedented opportunity in an urban community within Houston: In Pecan Park, an underserved community, the project team will serve as researchers, the wireless network service provider, the network equipment and protocol designers, and community-technology educators and advocates. In a coordinated effort using this urban testbed, the project addresses the following three inter-related research thrusts:<br\/><br\/>CACTUS: cross sectional assessment of community and technology usage: development of a first-of-its-kind network assessment tool that integrates three new methods with existing network trace collection capabilities: (i) sociological assessment of community-technology wireless access objectives from perspectives of both usage and contribution to a collective good; (ii) in-situ user experience assessment via end-user reporting; and (iii) concurrent in-situ client performance tests instantiated remotely by the network operator.<br\/><br\/>PAWN: polymorphic architecture for wireless networks: employing an urban deployment of nodes that can access spectrum spanning an order of magnitude from 5 GHz to 500 MHz in the Digital TV white spaces range, the project will (i) develop foundations and tools for dynamic network architecture based on assessment of community objectives and usage; (ii) develop foundations and tools for ?green wireless,? energy-efficient architectures which power down low-usage nodes but retain coverage through spectrum adaptation; and (iii) develop foundations and tools for spectrum-driven mobility management, in which highly mobile clients exploit nodes with large spatial footprints (enabled by low spectral ranges) to obtain a performance-velocity profile that was previously impossible.<br\/><br\/>CODA: context-driven network access: exploiting CACTUS and context awareness, the project will (i) develop context-driven quality estimation of current and future association choices to a polymorphic wireless network and devise client-directed policies for a client to optimize efficiency, performance, and mobility of association; and (ii) design and realize a polymorphic aggregate network interface that dynamically aggregates packets from multiple network interfaces of multiple spectral bands. Using this mechanism and context-awareness, we will study interface selection and traffic allocation for a client to obtain its required performance with unprecedented efficiency.<br\/><br\/>Broader Impact. With a strong interdisciplinary nature, this project will develop new research methods and yield foundational findings for areas spanning wireless networking to social sciences. The deployment in a low-income community provides access to information technologies for its residents. It will produce lessons and insights for future deployments of wireless infrastructures in other urban communities, including underserved ones, both nationally and internationally. The unique use of DTV white spaces can guide future FCC policy decisions. The project will provide research opportunities for undergraduate and graduate students from a variety of disciplines. It will also produce educational content that can significantly enrich our curricula in multiple disciplines. The project will continue to produce publicly available data sets that have already been utilized by researchers world-wide. The data sets are unique in that they provide unprecedented access to all system components from the end-user to the network.","title":"NetSE: Large: Urban-Scale Polymorphic Wireless Networks: Community-Driven Assessment, Design, and Access","awardID":"1012831","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["499856","548310","548312","490853"],"PO":["565090"]},"169808":{"abstract":"This goal of this project is to investigate next-generation network attack reconnaissance techniques, and explore the limitation for existing defenses. The result of this investigation offers understanding of potential game-changing in network reconnaissance attacks and how they can evolve in order to enable discovering and navigating the network quickly and safely. The project particularly explores novel scanning techniques to discover firewall security polices remotely via intelligent active probing, and without probing the end-hosts. The outcome of this project, if successful, is expected to offer transformative views to network defense, particularly counter-scanning techniques, beyond traditional intrusion detection\/prevention systems. As this far-forward looking EAGER proposal exhibits high-risk, it also entails high-value that is to be always many steps ahead of attackers.<br\/><br\/>This research arises serious concerns about the privacy of security configuration and the effectiveness of existing counter-measures against future advanced attacks. The proposed research agenda may make researchers<br\/>as well as vendors consider fundamentally new defense concepts beyond the current IDS and IPS.<br\/>This project also stimulates theorizing and predicting next-generation network attacks.","title":"TC: EAGER: Investigations of Next-generation Network Reconnaissance Attack Techniques and Limitations","awardID":"1023868","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["563217"],"PO":["565264"]},"171931":{"abstract":"Abstract for Project 1035733:Addressing Design and Human Factors Challenges in Cyber-Transportation Systems <br\/>This project has two closely related objectives. The first is to design and evaluate new Cyber Transportation Systems (CTS) applications for improved traffic safety and traffic operations. The second is to design and develop an integrated traffic-driving-networking simulator. The project takes a multi-disciplinary approach that combines cyber technologies, transportation engineering and human factors. <br\/><br\/> While transportation serves indispensible functions to society, it does have its own negative impacts in terms of accidents, congestion, pollution, and energy consumption. To improve traffic safety, the project will develop and evaluate novel algorithms and protocols for prioritization, delivery and fusion of various warning messages so as to reduce drivers? response time and workload, prevent conflicting warnings, and minimize false alarms. To improve traffic operations, the project will focus on the design of next generation traffic management and control algorithms for both normal and emergency operations (e.g. during inclement weather and evacuation scenarios). Both human performance modeling methods and human subjects? experimental methods will be used to address the human element in this research. As the design and evaluation of CTS applications requires an effective development and testing platform linking the human, transportation and cyber elements, the project will also design and develop a simulator that combines the main features of a traffic simulator, a networking simulator and a driving simulator. The integrated simulator will allow a human driver to control a subject vehicle in a virtual environment with realistic background traffic, which is capable of communicating with the driver and other vehicles with CTS messages. Background traffic will be controlled by a realistic driver model based on our human factors research that accounts for CTS messages? impact on driver behavior. <br\/><br\/>Intellectual Merits: The project explicitly considers human factors in the design and evaluation of CTS safety and operations applications, a topic which has not received adequate attention. Moreover, the proposed integrated simulator represents a first-of-a-kind simulator with unique features that can reduce the design and evaluation costs of new CTS applications.<br\/><br\/>Broader Impacts: The proposed research can improve the safety, efficiency and environmental-friendless of transportation systems, which serve as the very foundation of modern societies and directly affects the quality of life. The integrated simulator will be used as a tool for teenage and elderly driver education and training, and to inspire minority, middle and high school students to pursue careers in math, science, and computer-related fields","title":"CPS: Medium: Addressing Design and Human Factors Challenges in Cyber Transportation Systems","awardID":"1035733","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}}],"PIcoPI":["511691",460528,460529,460530],"PO":["564728"]},"171942":{"abstract":"The objective of this research is to develop formal verification tools<br\/>for human-computer interfaces to cyber-physical systems. The approach<br\/>is incorporating realistic assumptions about the behavior of humans into<br\/>the verification process through mathematically constructed \"mistake<br\/>models\" for common types of mistakes committed by the operator during<br\/>an interactive task. Exhaustive verification techniques are used to<br\/>expose combinations of human mistakes that can lead to system-wide<br\/>failures. The techniques are evaluated using case studies involving<br\/>medical device interfaces.<br\/><br\/><br\/><br\/>The problem of verifying human-machine interfaces requires new<br\/>approaches that combine rigorous formal verification techniques with<br\/>the empirical human-centered approach to user-interface evaluation.<br\/>The research addresses challenges of integrating empirical user-study<br\/>data into formal game-based models that describe common types of <br\/>operator mistakes. Using these models to detect subtle<br\/>flaws in user-interface design is also a challenge.<br\/><br\/><br\/>It is well-known that a poorly designed interface will enable harmful<br\/>operator errors, which remain a major cause of failures in a wide<br\/>variety of safety-critical cyber-physical systems. This project will<br\/>automate user-interface verification by detecting likely defects,<br\/>early in the design process. Open source verification tools will be<br\/>made freely available to the community at large. The ongoing research<br\/>will be integrated into a set of graduate-level computer science<br\/>courses focused on the theme of \"Safety in Human Computer Interfaces\".<br\/>Results from the project will also be integrated into educational<br\/>materials for the ongoing eCSite GK12 project with the goal of<br\/>promoting awareness of user-interface design issues amongst high<br\/>school students.","title":"CPS: Small: Formal Analysis of Man-Machine Interfaces to Cyber-Physical Systems","awardID":"1035845","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["494943","550702"],"PO":["565274"]},"172932":{"abstract":"This project will apply innovative techniques of automated recognition to digital facsimiles of ancient Greek papyri. The project combines three new technological approaches in attempting to analyze the oldest surviving papyrus texts from the 3rd century BC. The first is the automated, statistical evaluation of letter-forms on ancient texts. The second is advanced automated workflows for high-definition digital imaging that result in registered datasets of multi-spectral 2d images aligned to 3d models of a document. And the third is new capabilities in digital library infrastructure that allow automated discovery and retrieval of digital images in registration with textual transcriptions based on generic queries and at a fine level of granularity. All of these involve high levels of computation combined with innovative methodologies. If successful the work can significantly extend and expand existing research capabilities for recovering content from ancient inscriptions, in cases where text is regularized with discrete characters, and dating of the source-documents is made easier by virtue of archaeological context.","title":"EAGER: New Techniques for Recognition and Visualization of Inscriptions on Papyrological Documents","awardID":"1041949","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[463789],"PO":["564456"]},"172701":{"abstract":"This project is aimed at the design and experimental validation of a comprehensive clean-slate future Internet architecture. The proposed MobilityFirst architecture is motivated by the ongoing paradigm shift of Internet usage from today?s fixed PC\/host (client)?server model to emerging mobile data services and pervasive computing applications. The major design goals of the architecture are: mobility as the norm with dynamic host and network mobility at scale; robustness with respect to intrinsic properties of the wireless medium; trustworthiness in the form of enhanced security and privacy; usability features such as support for context-aware services, evolvability, manageability and economic viability. The key components of the MobilityFirst network design are: (1) separation of naming and addressing, implemented via a fast global dynamic name resolution service; (2) self-certifying public key network addresses to support strong authentication and security; (3) generalized delay-tolerant routing with in-network storage for packets in transit; (4) flat-label internetwork routing with public key addresses; (5) hop-by-hop transport protocols operating over segments rather than an end-to-end path; (6) a separate network management plane that provides enhanced visibility; (7) optional privacy features for user and location data; and (8) an integrated computing and storage layer to support programmability. The project?s scope includes architectural design, validation of key protocol components, testbed prototyping of the MobilityFirst architecture as a whole, and real-world protocol deployment on the GENI experimental infrastructure. The results of this project will provide architectural guidance for cellular-Internet convergence, and are expected to influence future technical standards in the networking industry.","title":"FIA: Collaborative Research: MobilityFirst: A Robust and Trustworthy Mobility-Centric Architecture for the Future Internet","awardID":"1040765","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["559287"],"PO":["565090"]},"170644":{"abstract":"Multicore technology is entering the mobile phone domain, and it is termed mobile multicore computing (MMC) in this project. With MMC, the current mobile phones are no longer the traditional mobile phones with only voice and\/or video phone functionalities. More features, such as multimedia streaming and mobile P2P applications, are integrated into these small devices. The grand challenge in MMC mobile phones is making a good tradeoff between performance and power. Different from existing hardware-oriented approaches, such as clock gating and power gating for high performance and low power design, this research proposes software-oriented approaches such as power-aware parallelization of mobile applications and power-aware task scheduling to meet this challenge.<br\/><br\/>In this 2-year EAGER project, the PI is seeking answers to this foundational performance\/power tradeoff problem. The prposal sets forth four ambitious objectives to do so: 1) To build a performance and power tradeoff model for mobile multicore platforms considering user requirements; 2) To parallelize mobile applications for mobile multicore platforms with memory, timing, and power constraints; 3) To schedule multitasks for multicore platforms with memory, timing, and power constraints; and 4) To develop a prototype mobile system based on mobile multicore computing platforms with high performance and low power consumption. It is expected that the insights and results drawn from this project will benefit researchers, practitioners, users, and students on a large scale.","title":"EAGER: Mobile Multicore Computing","awardID":"1028167","effectiveDate":"2010-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["7594"],"PO":["565272"]},"171865":{"abstract":"The objective of the research is to develop tools for comprehensive design and optimization of air traffic flow management capabilities at multiple spatial and temporal resolutions: a national airspace-wide scale and one-day time horizon (strategic time-frame); and at a regional scale (of one or a few Centers) and a two-hour time horizon (tactical time-frame). The approach is to develop a suite of tools for designing complex multi-scale dynamical networks, and in turn to use these tools to comprehensively address the strategic-to-tactical traffic flow management problem. <br\/><br\/>The two directions in tool development include 1) the meshed modeling\/design of flow- and queueing-networks under network topology variation for cyber- and physical- resource allocation, and 2) large-scale network simulation and numerical analysis. This research will yield aggregate modeling, management design, and validation tools for multi-scale dynamical infrastructure networks, and comprehensive solutions for national-wide strategic-to-tactical traffic flow management using these tools. <br\/><br\/>The broader impact of the research lies in the significant improvement in cost and equity that may be achieved by the National Airspace System customers, and in the introduction of systematic tools for infrastructure-network design that will have impact not only in transportation but in fields such as electric power network control and health-infrastructure design. The development of an Infrastructure Network Ideas Cluster will enhance inter-disciplinary collaboration on the project topics and discussion of their potential societal impact. Activities of the cluster include cross-university undergraduate research training, seminars on technological and societal-impact aspects of the project, and new course development.","title":"CPS: Small: Collaborative Research: Dynamical-Network Evaluation and Design Tools for Strategic-to-Tactical Air Traffic Flow Management","awardID":"1035369","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["471407"],"PO":["565274"]},"170787":{"abstract":"Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and <br\/>Communicative Behavior<br\/>Lead PI\/Institution: James M. Rehg, Georgia Institute of Technology<br\/>This Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. <br\/>Human behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions. This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.<br\/>The long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles.","title":"Collaborative Research: Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and Communicative Behavior","awardID":"1029035","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[457204,457205],"PO":["565227"]},"183624":{"abstract":"EMT\/BSSE: Synthetic Biological Integrated Circuits for Computing<br\/>Abstract<br\/>Synthetic biology promises a new paradigm for information processing. By rewiring gene networks, the molecular biology of the cell can be co-opted to produce all the modules used for computation. Moreover, these modules can be produced in very large numbers inexpensively from a single bacterium literally overnight by designing circuits with built-in antibiotic resistance. But the promise of synthetic biology for information processing won?t be realized until engineered gene networks operating in different cells can be assembled into integrated circuits to reliably express a computing function. The prospects for a biological integrated circuit hinge on solutions to three problems: control over the microenvironment of the cell, which affects signal transmission and timing; the difficulty of cascading elements due to the long response time evident in the synthesized gene circuits; and the stochastic noise that develops from biochemical reactions involving a small number of molecules. <br\/>In this research, the investigators synthesize gene circuits designed for high sensitivity and high signal-to-noise protein production, transform bacteria with them, and then assemble the different bacteria with submicron precision into large arrays using molecular signals to wire them together to express a complex computing function. The researchers sort through a succession of gene circuits using directed evolution in pursuit of sensitivity and stability with respect to noise. To efficiently produce proteins with high signal-to-noise ratio without excessive energy, they leverage a protocol that uses MazF, an mRNA interferase, to produce only the proteins of interest in living E. coli and otherwise arrest cell growth. Once the gene networks are designed and tested, the different bacteria are assembled on a hydrogel scaffold with submicron precision into 3D circuits using optical tweezers.","title":"EMT\/BSSE Synthetic Biological Integrated Circuits for Computing","awardID":"1129098","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["535303"],"PO":["565223"]},"172503":{"abstract":"While the Internet has far exceeded expectations, it has also stretched initial assumptions, often creating tussles that challenge its underlying communication model. Users and applications operate in terms of content, making it increasingly limiting and difficult to conform to IP's requirement to communicate by discovering and specifying location. To carry the Internet into the future, a conceptually simple yet transformational architectural shift is required, from today's focus on where ? addresses and hosts ? to what ? the content that users and applications care about.<br\/>This project investigates a potential new Internet architecture called Named Data Networking (NDN). NDN capitalizes on strengths ? and addresses weaknesses ? of the Internet's current host-based, point-to-point communication architecture in order to naturally accommodate emerging patterns of communication. By naming data instead of their location, NDN transforms data into a first-class entity. The current Internet secures the data container. NDN secures the contents, a design choice that decouples trust in data from trust in hosts, enabling several radically scalable communication mechanisms such as automatic caching to optimize bandwidth. The project studies the technical challenges that must be addressed to validate NDN as a future Internet architecture: routing scalability, fast forwarding, trust models, network security, content protection and privacy, and fundamental communication theory. The project uses end-to-end testbed deployments, simulation, and theoretical analysis to evaluate the proposed architecture, and is developing specifications and prototype implementations of NDN protocols and applications.","title":"FIA: Collaborative Research: Named Data Networking (NDN)","awardID":"1039585","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["559197","559197","559198","559198"],"PO":["565090"]},"163835":{"abstract":"The manifestation of language in space poses special challenges for computer-based recognition. Prior approaches to sign recognition have not leveraged knowledge of linguistic structures and constraints, in part because of limitations in the computational models employed. In addition, they have focused on the recognition of limited classes of signs. No system exists that can recognize signs of all morphophonological types or that can even discriminate among these in continuous signing. Through integration of several computational approaches, informed by knowledge of linguistic properties of manual signs, and supported by a large existing linguistically annotated corpus, the team will develop a robust, comprehensive framework for sign recognition from video streams of natural, continuous signing. Fundamental differences in the linguistic structure of signs, distinguishing signed languages in 4D, with spatio-temporal dependencies and multiple production channels from spoken languages, are critical to computer-based recognition. This is because finger-spelled items, lexical signs, and classifier constructions, e.g., require different recognition strategies. Linguistic properties will be leveraged here for (i) segmentation and categorization of significantly different types of signs, and then, although this subsequent enterprise will necessarily be limited in scope within the project period, (ii) recognition of the segmented sign sequences. Through the 3D hand pose estimation from a team-developed tracker, w significant tracking accuracy, robustness, and computational efficiency will be attained. This 3D information is expected to greatly improve the recognition results, as compared with recognition schemes using only 2D information. The 3D estimated information from the tracking will be used in the proposed hierarchical Conditional Random Field (CRF) based recognition, to allow for tracking and recognition of signs that are distinct in their linguistic composition. Since other signed languages also rely on a very similar sign typology, this technology will be readily extensible to computer-based recognition of other signed languages.<br\/><br\/>This linguistically-based hierarchical framework for ASL sign recognition?based on techniques with direct applicability to other signed languages, as well?provides, for the first time, a way to model and analyze the discrete and continuous aspects of signing, also enabling appropriate recognition strategies to be applied to signs with linguistically different composition. This approach will also allow the future integration of the discrete and continuous aspects of facial gestures with manual signing, to further improve computer-based modeling and analysis of ASL. The lack of such a framework has held back sign language recognition and generation. Advances in this area will, in turn, have far-ranging benefits for Universal Access and improved communication with the Deaf. Further applications of this technology include automated recognition and analysis by computer of non-verbal communication in general, security applications, human-computer interfaces, and virtual and augmented reality. In fact, these techniques have potential utility for any human-centered applications with continuous and discrete aspects. The proposed approach will offer ways to address similar problems in other domains characterized by multidimensional and complex spatio-temporal data that require the incorporation of domain knowledge. The products of this research, including software, videos, and annotations, will be made publicly available for use in research and education.","title":"III: Medium: Collaborative Research: Linguistically Based ASL Sign Recognition as a Structured Multivariate Learning Problem","awardID":"0964385","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["475203"],"PO":["565136"]},"174604":{"abstract":"As the scale of data has grown from the order of megabytes to the order of petabytes, energy and power have become a key consideration in managing (i.e., analyzing, organizing, and storing) such large datasets due to the increasing cost of powering the required data processing resources and cooling equipment. It is expected that the demand for data processing resources, both in the form of servers and mobile computing devices, will continue to increase exponentially. The goal of this two-day workshop is to act as a planning meeting for the development and deployment of energy-efficient data management methods and data-intensive applications which are important from both an economic and a sustainability perspective. The workshop includes invited talks, panels and breakout sessions.<br\/><br\/>The broader impact of the workshop is expected to be in terms of guiding future research which will provide a more sustainable way of managing society's increasing and rapidly growing reliance on large data management systems.<br\/><br\/>More information on the workshop can be found at www.energy-efficient-data-management.org\/workshop.","title":"Workshop on Sustainable Energy-Efficient Data Management","awardID":"1050302","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["532922"],"PO":["563727"]},"172679":{"abstract":"This project is aimed at the design and experimental validation of a comprehensive clean-slate future Internet architecture. The proposed MobilityFirst architecture is motivated by the ongoing paradigm shift of Internet usage from today?s fixed PC\/host (client)?server model to emerging mobile data services and pervasive computing applications. The major design goals of the architecture are: mobility as the norm with dynamic host and network mobility at scale; robustness with respect to intrinsic properties of the wireless medium; trustworthiness in the form of enhanced security and privacy; usability features such as support for context-aware services, evolvability, manageability and economic viability. The key components of the MobilityFirst network design are: (1) separation of naming and addressing, implemented via a fast global dynamic name resolution service; (2) self-certifying public key network addresses to support strong authentication and security; (3) generalized delay-tolerant routing with in-network storage for packets in transit; (4) flat-label internetwork routing with public key addresses; (5) hop-by-hop transport protocols operating over segments rather than an end-to-end path; (6) a separate network management plane that provides enhanced visibility; (7) optional privacy features for user and location data; and (8) an integrated computing and storage layer to support programmability. The project?s scope includes architectural design, validation of key protocol components, testbed prototyping of the MobilityFirst architecture as a whole, and real-world protocol deployment on the GENI experimental infrastructure. The results of this project will provide architectural guidance for cellular-Internet convergence, and are expected to influence future technical standards in the networking industry.","title":"FIA: Collaborative Research: MobilityFirst: A Robust and Trustworthy Mobility-Centric Architecture for the Future Internet","awardID":"1040626","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["553884"],"PO":["565090"]},"170138":{"abstract":"Design methods are rapidly being incorporated into many sectors of the economy and reshaping the ways in which we visualize and understand science and engineering. Focusing on design work at four firms in three countries, this project studies hybrid virtual teams to identify which phases of the design process can be performed virtually and which require face-to-face interaction. In addition, it will build a prototype to aid in collaborative design activities by improving trust, building a social network, and providing visualization tools. Relying on theories from communications, information science and science and technology studies, the research team will use ethnographic observation and qualitative interviews with participants in cross-cultural design collaborations that include design professionals and under-served urban populations addressing issues of social innovation and sustainability. <br\/><br\/>Through this research, we will gain a better understanding of the degree to which culture, context and environment play a key role in the adoption and use of information and communication technologies to facilitate interaction and trust-building in virtual organizations. Understanding the issues underlying media choice and design is of theoretical and practical concern as the variety of media expands to include previously unavailable social media and as advanced features are added to existing media. A well-developed tool to improve collaboration among designers engaged in community development efforts would be of considerable value to this community. In addition, design methods would be useful to the research planning phases in multiple scientific disciplines to uncover new sets of problems, relationships and models. The interdisciplinary and international reach of this project will enhance its broader impact through significant exposure to and input from a wide variety of perspectives and cultures. The research involves undergraduate and graduate students and will result in their further training and education in interdisciplinary research.","title":"VOSS: Design Collaborations as Sociotechnical Systems","awardID":"1025498","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1340","name":"ENGINEERING EDUCATION"}}],"PIcoPI":["560930"],"PO":["565342"]},"175968":{"abstract":"The University of California San Diego (UCSD) proposes a planning grant to<br\/>build the Partnership for Expanding \"Exploring Computer Science\" (PEECS)<br\/>with the goal of increasing the number of underrepresented minority and<br\/>female students from San Diego County that graduate from high school<br\/>interested in and prepared to pursue college majors in computer science and<br\/>related fields. PEECS was inspired by the BPC Alliance, \"Into the Loop,\" which<br\/>introduced a new course, \"Exploring Computer Science\" (ECS), in the Los Angeles<br\/>Unified School District. ECS is an introductory course that could be a<br\/>steppingstone to Computer Science Principles, the proposed new Advanced<br\/>Placement (AP) course. These two courses have the potential to transform<br\/>high school education in computing.<br\/><br\/>The CS Principles course is being piloted at UC San Diego this year. Together<br\/>with the facts that \"Into the Loop\" personnel live in the San Diego region,<br\/>there are close ties between the UCLA and UCSD campuses, UCSD Computer Science<br\/>is already involved in revamping their freshman curriculum, and UCSD's San Diego<br\/>Supercomputer Center (SDSC) has a well-established technology and computational<br\/>science professional development program for pre-college teachers (SDSC<br\/>TeacherTECH), this puts San Diego at the right time and place for a major<br\/>overhaul of its high school computer science programs.<br\/><br\/>PEECS proposes to pave the way for a successful expansion and adaptation of<br\/>ECS into a new region, San Diego County. There, multiple school districting<br\/>structures, policies, processes, and academic community cultures present their<br\/>own new challenges to change. Experiences gained in adapting the ECS program<br\/>to the diverse needs of the San Diego region will provide valuable lessons as<br\/>the wider dissemination of ECS and CS Principles goes forward. This planning<br\/>grant will bring together the important stakeholders to develop the necessary<br\/>partnerships and directions for this effort.","title":"Partnership for Expanding \"Exploring Computer Science\" (PEECS)","awardID":"1058432","effectiveDate":"2010-09-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["496824"],"PO":["561855"]},"164506":{"abstract":"This project will develop and evaluate software to support people engaged in online social deliberation, especially as it relates to dispute resolution and collaborative inquiry. The software will model and monitor deliberative processes skills while people are either in collaboration or involved in settling disputes. Applications will be in three domains that already support online conversations: 1) online dispute resolution (e.g., eBay and the U.S. National Mediation Board); 2) collaborative learning in open-ended inquiry learning environments; and 3) dialog and deliberation on civic and ethical issues. The project will scaffold situations, adding structure or focusing attention on social processes, support improvement of individual skills, and facilitate a. Wisdom of crowds that enables participants to produce improved results. This project involves faculty across five departments: legal studies, psychology, political science, computer science and education.<br\/><br\/>Intellectual Merit. This research advances social issues (collaboration, dispute resolution, and critical thinking) and computation techniques (online dispute resolution, argumentation and collaboration). It furthers research into building social communities, explores issues of coaching and collaboration and develops evaluation tools for measuring the effect of online support.<br\/><br\/>Broader Societal Impact. This project advances the understanding of online human-human communication. It will enable more people to access social deliberative tools, promote interest in discussion among more people and improve the quality of on-line disputes as well as collaborations. The project lays the groundwork for more intelligent communication in online communities, creates new understandings of the complexities of collaboration and produces new modes of synergistic online discussions.","title":"SoCS: The Fourth Party: Improving Computer-Mediated Deliberation through Cognitive, Social and Emotional Support","awardID":"0968536","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["440694",440692,"536735",440694,"536737","552841"],"PO":["563324"]},"168808":{"abstract":"Commercial cellular networks have recently experienced a dramatic increase in demand for data services. Satisfying this demand will require substantial (order-of-magnitude) increases in the spectral efficiency that can be achieved by such networks. This will require much more extensive information exchange and cooperation among nodes in the network than in current systems. This research investigates possible approaches for cooperation among nodes in a cellular network based on practical methods for feedback and information exchange.<br\/><br\/>The main theme of this research is on techniques for exchanging and exploiting limited state information about channels, interference, and quality of service in a wireless network. The focus is on two scenarios: feedback for point-to-point fading links, and information exchange between two cooperative base stations. The first scenario is meant to address limits imposed by fading for mobiles well within a cell, whereas the second scenario addresses limits imposed by interference at a cell boundary. One of the goals is to gain fundamental understanding into the trade-off between channel state feedback and receiver state feedback for fading channels. For the two-cell scenario, cooperative resource allocation and cooperative coding and decoding strategies are investigated. The emphasis is on understanding the benefits of cooperation as a function of the amount of information exchanged, and on associated resource allocation across time, frequency, and space. The investigators also study the combination of cooperative coding\/decoding with adaptive techniques for precoder optimization, which do not rely on the explicit exchange of channel measurements.","title":"CIF: Small: Limited Feedback and Information Exchange for Wireless Systems","awardID":"1018578","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["560216","523548"],"PO":["564924"]},"167609":{"abstract":"This work proposes to design a programmable many-core for Extreme-Scale Computing in mobile platforms (netbooks and smart-phones) of year 2020. This work cuts across the architecture, compiler, operating system, and correctness\/performance tools areas. A key technology explored is that of cores and all of the software continuously operating in Chunks (i.e., atomic blocks) of instructions at a time --- eliminating the need for in-order, single-instruction-at-a-time commit. The PIs will develop a novel chunk-based architecture that supports the high levels of performance, power\/energy efficiency, concurrency, and locality required. They will develop advanced compiler support for chunk generation that delivers high performance at low power, and leverages all the programmability features of the architecture. They will also design an OS that supports and takes advantage of chunks. Finally, they will design a set of novel correctness and performance tools that exploit chunks, signatures, hashes, and all the other features of this architecture.<br\/><br\/>The broader impacts of this work involve the creation of a multidisciplinary research and education center at University of Illinois and Purdue on Programmable Extreme Scale Computing. Faculty of diverse expertise will be devoted to solving the problem of programmable, very-high performance, very power\/energy-efficient many-cores for mobile platforms of year 2020 and beyond. The PIs will broaden the course offerings at University of Illinois and Purdue in the four areas, with multidisciplinary courses at different depth levels. Graduate and undergraduate researchers in ECE and CS will be involved in the research. Overall, the PIs hope to prove that programmable, high-performance, and highly power\/energy-efficient many-cores based on continuous atomic-block operation are attractive.","title":"SHF: Large: Collaborative Research: Designing the Programmable Many-Core for Extreme Scale Computing","awardID":"1012759","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["548692","518574","485665"],"PO":["366560"]},"168709":{"abstract":"Cryptographic protocols lie at the core of sound and trustworthy solutions to protect the integrity and secrecy of data stored in private computers and remote servers; and programs executed on hand held devices and remote host computers. Such protocols are guaranteed to preserve some pre-defined security requirements in the face of malicious attacks.<br\/><br\/>The starting point of this research project is that the nature of these attacks has changed fundamentally in recent years. A fast growing worldwide trend is to view computation as a commodity. Organizations or individuals may pay specialized providers (such as the Amazon EC2) to carry out desired computations for them. This trend (often called ``Cloud Computing'') carries with it great promise in terms of overall computing efficiency, power consumption, and financial flexibility. However, it also opens the door to much more acute security threats than those we have encountered so far. Without additional protection, the client must completely trust the provider to perform the computation correctly, and at the same time keep the secrecy of the clients' most sensitive private data. Putting in protection to reduce this trust is a delicate and complex challenge which requires a paradigm shift. Traditional cryptographic techniques and concepts seem to be insufficient to address these new threats and opportunities<br\/><br\/>In this project, we propose to address several challenges arising due to this new computing reality. These include: (1) Designing techniques for securing remote executable code both to safeguard the underlying algorithms and to enable limited time execution. (2) Designing techniques for achieving security against computational side-channel attacks on programs executed in hostile environments, (3) Diversifying the constructions of homomorphic encryption and further exploring their potential to current applications.<br\/><br\/> Intellectual Merit and Broad Impact: Protecting the electronic information world is paramount to the success and stability of modern society. The main goal of this project is to develop techniques for the security of remotely executed programs and cryptographic primitives. We ask basic questions underlying the development of such techniques: Can we build cryptographic primitives that resist various forms of inadvertent information leakage, such as the ones that occur due to side-channel attacks? can the computational assumptions that we have made thus far withstand the existence of extra auxiliary information about their solutions? Can fully homomorphic encryption schemes be demonstrated that possess other useful properties such as leakage-resilience, circular security and the ability to test the ciphertext for predefined predicates? Progress on any of these questions will significantly enhance our tool kit for the remote storage of data and program execution. We believe that this project addresses the most important area of investigation in cryptography today and will have broad impact on teaching us how to utilize remote computers to run your computations maintaining security. This may have far reaching conclusions for the safe use of cloud computing.","title":"TC: Small: Securing Programs and Data In Remote and Hostile Environments","awardID":"1018064","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["562010"],"PO":["565264"]},"170931":{"abstract":"Understanding Climate Change: A Data Driven Approach<br\/><br\/>Climate change is the defining environmental challenge now facing our planet. Whether it is an increase in the frequency or intensity of hurricanes, rising sea levels, droughts, floods, or extreme temperatures and severe weather, the social, economic, and environmental consequences are great as the resource-stressed planet nears 7 billion inhabitants later this century. Yet there is considerable uncertainty as to the social and environmental impacts because the predictive potential of numerical models of the earth system is limited. These models are incapable of addressing important questions relating to food security, water resources, biodiversity, mortality, and other socio-economic issues over relevant time and spatial scales.<br\/><br\/>Climate model development has contributed small and incremental improvements; however, extensive modeling gains have not been forthcoming. Modeling limitations have hampered efforts at providing information on climate change impacts and adaptation and mitigation strategies. A new and transformative approach is required to improve prediction of the potential impacts on human welfare. Data driven methods that have been highly successful in other facets of the computational sciences are now being used in the environmental sciences with success. This Expedition project will significantly advance key challenges in climate change science developing exciting and innovative new data driven approaches that take advantage of the wealth of climate and ecosystem data now available from satellite and ground-based sensors, the observational record for atmospheric, oceanic, and terrestrial processes, and physics-based climate model simulations.<br\/><br\/>To realize this ambitious goal, novel methodologies appropriate to climate change science will be developed in four broad areas of data-intensive computer science: relationship mining, complex networks, predictive modeling, and high performance computing. Analysis and discovery approaches will be cognizant of climate and ecosystem data characteristics, such as non-stationarity, nonlinear processes, multi-scale nature, low-frequency variability, long-range spatial dependence, and long-memory temporal processes such as teleconnections. These innovative new approaches will be used to better understand the complex nature of the earth system and the mechanisms contributing to such climate change phenomena as hurricane frequency and intensity in the tropical Atlantic, precipitation regime shifts in the ecologically sensitive African Sahel or the Southern Great Plains, and the propensity for extreme weather events that weaken our infrastructure and result in environmental disasters with economic losses in excess of $100 billion per year in the U.S. alone.<br\/><br\/>Assessments of climate change impacts, which are useful for stakeholders and policymakers, depend critically on regional and decadal scale projections of climate extremes. Thus, climate scientists often need to develop qualitative inferences about inadequately predicted climate extremes based on insights from observations (e.g., increase in hurricane intensity) or conceptual understanding (e.g., relation of wildfires to regional warming or drying and hurricanes to sea surface temperatures). These urgent societal priorities offer fertile grounds for knowledge discovery approaches. In particular, qualitative inferences on climate extremes and impacts may be transformed into quantitative predictive insights based on a combination of hypothesis-guided data analysis and relatively hypothesis-free, yet data-guided discovery processes.<br\/><br\/>A primary focus of this Expedition project will be on uncertainty reduction, which can bring the complementary or supplementary skills of physics-based models together with data-guided insights regarding complex climate processes. The systematic evaluation of climate models and their component processes, as well as uncertainty assessments at regional and decadal scales is a fundamental problem that will be addressed. The ability to translate gains in the predictive skills of climate variables to improvements in impact assessments and attributions is a critical requirement for informing policymakers. Novel methodologies will be developed to gain actionable insights from disparate impacts-related datasets as well as for causal attribution or root-cause analysis. <br\/><br\/>This research will be conducted in close collaboration with the climate science community and will complement insights obtained from physics-based climate models. Improved understanding of salient atmospheric processes will be provided to those contributing to the development and improvement of climate models with the goal of improving predictability. The approaches and formalisms developed in this research are expected to be applicable to a broad range of scientific and engineering problems, which use model simulations to an","title":"Collaborative Research: Understanding Climate Change: A Data Driven Approach","awardID":"1029711","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563608","550903",457609,"557452",457611],"PO":["565223"]},"171910":{"abstract":"CPS:Small: Methods and Tools: Robots with vision that find objects<br\/><br\/> The objective of this research is the development of methods and software that will allow robots to detect and localize objects using Active Vision and develop descriptions of their visual appearance in terms of shape primitives. The approach is bio inspired and consists of three novel components. First, the robot will actively search the space of interest using an attention mechanism consisting of filters tuned to the appearance of objects. Second, an anthropomorphic segmentation mechanism will be used. The robot will fixate at a point within the attended area and segment the surface containing the fixation point, using contours and depth information from motion and stereo. Finally, a description of the segmented object, in terms of the contours of its visible surfaces and a qualitative description of their 3D shape will be developed.<br\/> The intellectual merit of the proposed approach comes from the bio-inspired design and the interaction of visual learning with advanced behavior. The availability of filters will allow the triggering of contextual models that work in a top-down fashion meeting at some point the bottom-up low-level processes. Thus, the approach defines, for the first time, the meeting point where perception happens. <br\/> The broader impacts of the proposed effort stem from the general usability of the proposed components. Adding top-down attention and segmentation capabilities to robots that can navigate and manipulate, will enable many technologies, for example household robots or assistive robots for the care of the elders, or robots in manufacturing, space exploration and education.","title":"CPS: Small: Methods and Tools: ROBOTS WITH VISION THAT FIND OBJECTS","awardID":"1035542","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[460460,"531850"],"PO":["565136"]},"170612":{"abstract":"The ability of computers to unify visual information from multiple imaging<br\/>modes into comprehensible illustrations will revolutionize the ability of<br\/>scientists, engineers, and humanities scholars to gain and communicate<br\/>knowledge about the visual world. Achieving this goal, however, will<br\/>require a joint focus on developing novel shape and image analysis methods,<br\/>and designing collaborative user interfaces that allow multiple domain<br\/>experts and illustrators to bring together their expertise. The<br\/>Collaborative Algorithmic Rendering Engine (CARE) will be an open-source tool<br\/>for extracting and merging visual details available only under certain<br\/>lighting conditions, certain wavelengths, or certain imaging modalities. <br\/>By focusing on minimal user effort, cross-site collaborative visualization<br\/>design, and integrated archiving and process history (provenance) tracking,<br\/>the CARE tool is specifically designed to remove existing obstacles to<br\/>widespread adoption of digital tools for visual analysis and communication.<br\/><br\/>As part of the project, investigators are developing novel image analysis<br\/>techniques that build upon existing technologies such as Reflectance<br\/>Transformation Imaging (RTI) and non-photorealistic rendering using images<br\/>with normals (RGBN NPR), which have already received enormous interest<br\/>within the cultural heritage community. The research includes methods for:<br\/>(1) analyzing the collection of images to decompose them into \"maps\" of<br\/>color, orientation, and material at each pixel; (2) performing an arbitrary<br\/>sequence or combination of image-processing operations on some or all of<br\/>the maps separately; and (3) combining several maps into the final<br\/>illustration. The whole process is driven by (4) a user interface designed<br\/>for interactive response and including special features that enable<br\/>collaborative illustration design.<br\/><br\/>The project involves a close collaboration between a university-based research<br\/>group, responsible for development of new technologies, and a non-profit<br\/>company with a demonstrated track record of working with museums and<br\/>archaeological sites to deploy novel imaging and computational photography<br\/>systems. This joint development will ensure that the underlying<br\/>technologies will have immediate high impact in the field: cultural<br\/>heritage scholars and scientists will be able to generate high-quality,<br\/>comprehensible illustrations for scientific papers and textbooks, with control<br\/>over selective emphasis, contrast, attention, and abstraction, at lower<br\/>cost and greater flexibility than generating such figures by hand. The subject<br\/>matter of art history also offers the unique opportunity to stimulate the<br\/>interest of students who would not normally take courses in computer<br\/>science, broadening the class of students exposed to the tools and capabilities<br\/>of computing.","title":"CDI-Type I: Automated Documentation and Illustration of Material Culture through the Collaborative Algorithmic Rendering Engine (CARE)","awardID":"1027962","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[456692],"PO":["565136"]},"171943":{"abstract":"The objective of this research is the design of innovative routing,<br\/>planning and coordination strategies for robot networks, and their<br\/>application to oceanography. The approach is organized in three<br\/>synergistic thrusts: (1) the application of queueing theory and<br\/>combinatorial techniques to networked robots performing sequential tasks,<br\/>(2) the design of novel distributed optimization and coordination schemes<br\/>relying only on asynchronous and asymmetric communication, (3) the design<br\/>of practical routing and coordination algorithms for the USC Networked<br\/>Aquatic Platforms. In collaboration with oceanographers and marine<br\/>biologists, the project aims to design motion, communication and<br\/>interaction protocols that maximize the amount of scientific information<br\/>collected by the platforms.<br\/><br\/>This proposal addresses multi-dimensional problems of relevance in<br\/>Engineering and Computer Science by unifying fundamental concepts from<br\/>multiple cyberphysical domains (robotics, autonomy, combinatorics, and<br\/>network science). Our team has expertise in a broad range of scientific<br\/>disciplines, including control theory and theoretical computer science and<br\/>their applications to multi-agent systems, robotics and sensor networks.<br\/><br\/>The proposed research will have a positive impact on the emerging<br\/>technology of autonomous and reliable robotic networks, performing a broad<br\/>range of environmental monitoring and logistic tasks. Our educational and<br\/>outreach objectives are manifold and focus on (1) integrating the proposed<br\/>research themes into undergraduate education and research, e.g., via the<br\/>existing NSF REU site at the USC Computer Science Department, and (2)<br\/>mounting a vigorous program of outreach activities, e.g., via a<br\/>well-developed collaboration with the UCSB Center for Science and<br\/>Engineering Partnerships.","title":"CPS: Medium: Collaborative Research: Dynamic Routing and Robotic Coordination for Oceanographic Adaptive Sampling","awardID":"1035866","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["560335"],"PO":["564728"]},"161812":{"abstract":"How to retrieve relevant information for a specific user under a specific set of circumstances is a challenging research problem. The goal of this research project is to tackle this challenge and lay the foundation for the next generation of search engines. Instead of simply matching a query to documents that contain query words, the approach developed here is a unified user-centric retrieval framework that consists of: (1) personalization: learning a user model that takes into consideration the content, context and decision criteria of a user; (2) language processing: learning better text representation for retrieval from heterogeneous corpus and linguistic resources; and (3) social networks: further improving the user model based on social norms and a user's social networks. To evaluate the framework, a personalized social search engine will be developed. <br\/><br\/>The result of this project will be a unified retrieval framework with a set of novel techniques applicable across a wide range of information retrieval (IR) tasks, including: search engines, recommender systems and adaptive filtering systems. Through the PI's industry collaboration, the results of this project are expected to be incorporated in commercial systems, and thus benefit millions of users. <br\/><br\/>K-12 students, undergraduate, graduate students, and engineers in Silicon Valley will be involved and benefit from the project. The project will lead to research-based educational materials (lecture slides, video lectures, book chapters and course projects). Project results, including publications, open source software, annotated data sets, demos and course materials, will be disseminated via the project website (http:\/\/www.soe.ucsc.edu\/~yiz\/futureofsearch).","title":"CAREER: Future of Search: User, Social Networks and Language","awardID":"0953908","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["547825"],"PO":["563751"]},"170898":{"abstract":"Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and <br\/>Communicative Behavior<br\/>Lead PI\/Institution: James M. Rehg, Georgia Institute of Technology<br\/>This Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. <br\/>Human behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions. This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.<br\/>The long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles.","title":"Collaborative Research: Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and Communicative Behavior","awardID":"1029549","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["532662",457516],"PO":["565227"]},"173813":{"abstract":"This is funding to support a Doctoral Colloquium (workshop) of promising doctoral students and distinguished research faculty, to be held in conjunction with this year's IEEE VisWeek meeting, which will take place during the week of October 24-29, 2010, in Salt Lake City. Visualization, or the use of interactive graphics to support data analysis and understanding, has become an integral part and critical component of many application areas. VisWeek consists of three main events: IEEE Visualization (Vis), IEEE Information Visualization (InfoVis), and the IEEE Visual Analytics Science and Technology Symposium (VAST). IEEE Vis is the oldest of the three venues of VisWeek, and will celebrate its 21st anniversary this year; its traditional focus has been on a wide range of topics in scientific and medical visualization. InfoVis centers around helping people explore or explain abstract data through interactive software that exploits the capabilities of the human perceptual system, focusing on cognitively useful spatial mappings of abstract datasets that are not inherently spatial, and accompanying the mappings with interaction techniques that allow people to intuitively explore the data. VAST, the youngest event, was founded in 2006 to address the growing interest in the science of analytical reasoning supported by highly interactive visual interfaces; its focus is on visual analytics tools and techniques to synthesize information into knowledge, derive insight from massive, dynamic, and often conflicting data; detect the expected and discover the unexpected, provide timely, defensible, and understandable assessments, and communicate assessments effectively for action. IEEE VisWeek is the premier forum for visualization advances in science and engineering for academia, government, and industry, bringing together about 800 researchers and practitioners from around the world with a shared interest in techniques, tools, and technology. The papers published in the special conference issue of IEEE Transactions of Visualization and Computer Graphics are rigorously refereed and widely cited. <br\/><br\/>The Doctoral Colloquium at IEEE VisWeek is a research-focused meeting of a group of selected proposal-stage Ph.D. candidates and a panel of distinguished research faculty. It has taken place annually at the Visualization conference since 2006, and has helped launch the careers of a number of outstanding young Vis researchers. In 2010 the workshop will bring together approximately 12 doctoral students, from the United States and abroad, who will convene on Sunday, October 24, for a day of discussions and interaction with about 10 faculty researchers, with follow-up events that will take place during the VisWeek technical program. A primary goal of the Doctoral Colloquium is to allow students to discuss their research directions in a supportive atmosphere with a panel of distinguished leaders and with their peers, who will provide helpful feedback and fresh perspectives. The workshop supports community building, by connecting beginning and advanced researchers, one of the objectives being to build a cohort group of new researchers who will then have a network of colleagues across the world. Student research will be disseminated via posters during the VisWeek technical program, and via publication in the VisWeek Extended Abstracts. Feedback about the Doctoral Colloquium will be provided to future conference committees. The PI has affirmed that in managing this event he and his colleagues will try explicitly to identify and include the broadest possible group of highly qualified participants, and they will ensure that NSF funds are used chiefly to support participation by students enrolled in graduate programs in the United States. <br\/><br\/>Broader Impacts: The VisWeek Doctoral Colloquium has taken place annually since 2006, and has helped launch the careers of a number of outstanding young Vis researchers. It brings together the best of the next generation of visualization researchers, and allows them to create a social network both among themselves and with senior researchers, which plays a major role in their enculturation into the profession. Since the students and faculty are a diverse group on several dimensions (nationality, scientific discipline, research specialization), the students' horizons are broadened at a critical stage in their professional development.","title":"Group Travel Grant: Doctoral Colloquium at IEEE VisWeek 2010","awardID":"1046668","effectiveDate":"2010-09-01","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["228773"],"PO":["565227"]},"174913":{"abstract":"Florida International University is augmenting its TerraFly technology by adding support of visualization of scientific measurement aggregation through space and time with a specific applicability to the coastal and near-coastal areas affected by the Gulf Oil Spill. FIU is assembling data, developing and prototyping algorithms and to support specification of special-purpose functions, data analysis, visualization, and knowledge discovery.<br\/><br\/>This project deals with a severe urgency with regard to availability of, and access to, data and involves quick-response research on the economic impact of the Gulf Oil Spill on coastal communities. New forms of analytical queries needs to be efficiently supported. For example, an insurance company may need to have the following complex query answered: \"For any given property, in aggregate for areas, find the value decrease impact that the oil spill had on the property or properties; by correlation of value changes in Florida Panhandle to percentage change of similarly zoned properties elsewhere, adjusted for similar land use (zoning), property size, distance to Water, and near-coastal and coastal oil contamination\". The algorithms and prototype system being developed enable the temporal querying, cross-referencing, visualization, and analysis of geospatial data, including time series multi-temporal aerial imagery, multi-temporal measurement and economic data, and vast existing static geospatial databases. This research enables analysis of differences in imagery and vectors, allows querying differences per location, and the posing of a range of questions pertaining to the economic impact of the Gulf Oil Spill on coastal communities. <br\/><br\/>Results of this RAPID project will allow researchers, stakeholders, and the general public to access, query and analyze relevant databases via flexible graphic interfaces. FIU and extramural researchers will have access to multi-temporal high-resolution imagery and vector data. A system-to-system XML access will enable all academic researchers to use the project's GeoQuery system. The project's data and graphic interface to queries, both user-definable and pre-defined, will be accessible via the project web site (http:\/\/terrafly.fiu.edu\/r.htm).","title":"III: Gulf RAPID: Multi-temporal analysis and correlation of Gulf Oil Spill Related Geospatial Data on TerraFly Platform","awardID":"1052625","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["558108"],"PO":["563751"]},"172647":{"abstract":"Proposal #: 10-40442<br\/>PI(s): Zhan, Justin<br\/>Institution: Dakota State University<br\/>Title: MRI\/Acq.: Equipment to Establish Information Assurance Infrastructure for Research and Education<br\/>Project Proposed:<br\/>This project from a non-PhD granting university in an EPSCoR state, acquiring a set of networking computing devices, aims to facilitate high-performance large-scale secure computing research and education. The devices include high performance servers, Cisco routers, and software for large-scale secure collaborative computing. The work, requiring extensive computing, simulation, and large amounts of data mining and analysis, enables the following research projects:<br\/>- Privacy-preserving collaborative data mining against semi-honest adversaries,<br\/>- Privacy-preserving collaborative data mining against malicious adversaries, and<br\/>- Privacy-preserving protocol library development.<br\/>The projects address issues critical for the nation?s security and contribute to train graduate students in information privacy and security. Thus the instrument contributes to three main activities:<br\/>- Algorithms to account for semi-honest participants;<br\/>- Algorithms to account for malicious participants; and<br\/>- Software libraries for privacy-preserving data-mining to be shared with the community.<br\/>The work aims to unify different metrics for measuring privacy by systematically studying privacy-preserving collaborative computing and performing large-scale simulations. The group is among the first investigating privacy protection theoretically and experimentally in privacy preserving collaborative data-mining. The developed privacy-preserving protocol library is expected to dramatically benefit research in the area.<br\/>Broader Impacts: <br\/>This instrumentation should provide a unique research facility for faculty and graduate students to conduct research on privacy-enhancing technology and education in a primarily undergraduate institution in an EPSCoR state. Other institutions and industries within the state are expected to benefit from local and remote access to the requested information assurance instrumentation. Moreover, the project involves and\/or supports K-12, distance and Internet-based education, and underrepresented students.","title":"MRI: Acquisition of Equipment to Establish Information Assurance Infrastructure for Research and Education","awardID":"1040442","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[462913,"531638"],"PO":["557609"]},"163825":{"abstract":"In this project, the PI and his team will develop a new simulation framework to interactively model and visualize socio-economic and geometric characteristics of urban areas. The framework will consist of a synergistic collaboration of three different areas: behavioral urban modeling, probabilistic graphical modeling, and visualization and computer graphics. In machine learning and statistics, the area of probabilistic graphical modeling offers a flexible framework to build, estimate and simulate from models of substantial complexity and scale, with partially observed data. By accounting for uncertainty and interdependencies, including aspects of dynamic equilibrium that arise in modeling the complex spatio-temporal dynamics of urban areas, the PI argues there is significant potential for breakthroughs in modeling large-scale urban systems. Similarly, by integrating behavioral and geometrical dimensions of urban areas, he expects to exploit the power of behavioral simulations more effectively by filling in geometric details that behavioral models are not well suited to manage, and at the same time provide a powerful framework to generate 2D and 3D geometric representations of urban areas that are behaviorally and geometrically consistent. The PI will take advantage of massive datasets available for urban areas, including parcel and building inventories, business establishment inventories, census data, household surveys, and GIS data on physical and political features, and will fuse these data into a coherent and consistent database to support his modeling objectives. This data fusion will address imputation of missing data, accounting for complex spatial and relational connections among the data sources. The PI will evaluate the accuracy and usability of his system through several deployments in diverse contexts. The PI has elicited engagement from the Urban Land Institute, the European Research Council, and the Council for Scientific and Industrial Research. Several organizations in the San Francisco Bay Area in California and the Puget Sound region in Washington will serve as testbeds for the research. Finally, the PI will collaborate with other NSF-funded research projects, such as the Drought Research Initiative Network, in order to investigate correlations between urban development and water\/drought. <br\/><br\/>Broader Impacts: The results of this multidisciplinary project will have a transformative effect on the area of urban simulation, in that they will enable non-professionals as well as the general public to better understand urban phenomena. City planners, researchers, students, and citizens will be able to efficiently simulate urban processes not previously possible, and to visualize the effects of adopting different urban policies on urban livability and sustainability outcomes, and to address local and global concerns regarding equity, infrastructure, and economic development. The framework will provide interactive desktop and web-based interfaces for configuring urban scenario inputs to a simulation that may reach petabytes in data size, and to visualize the simulation results using 2D aerial views, 3D city walkthroughs, and choroplethic maps and tables of indicators portraying the simulated area. Thus, the work will also advance the fields of visualization and computer graphics, through development of new techniques for large-scale urban modeling and rendering. The PI will develop an open-source system to make the results of this research widely available.","title":"III: Medium: Collaborative Research: Integrating Behavioral, Geometrical and Graphical Modeling to Simulate and Visualize Urban Areas","awardID":"0964302","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["541856",438560],"PO":["565227"]},"164936":{"abstract":"This project proposes to explore integrated methodologies for pattern discovery and network analysis in multi-lingual text corpora. The interdisciplinary project team will focus on recent developments in network analysis of complex problems associated with visual query systems, topic discovery, anomaly detection, and rapid mining of complex time-stamped data as a means for extending approaches to noisy data from a range of disciplinary source materials. In order to look at the various problems and solutions to these major issues in current scholarship, the PIs have chosen three sets of disparate data: Buddhist Canonic texts (Chinese and Sanskrit); Irish studies journals (English and Gaelic); and Danish folklore (English and Danish). The research exercise to be performed is of a scale and complexity never before attempted. The project anticipates finding deficiencies in existing network analysis algorithms dealing with rich external data available on nodes and links and developing new network analysis algorithms to overcome the deficiencies.","title":"EAGER: Network Pattern Recognition Project","awardID":"0970179","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[441922,441923],"PO":["564456"]},"163858":{"abstract":"Wireless ad-hoc networks consist solely of cheap, mobile nodes that operate in the absence of expensive fixed infrastructure such as base stations. In order to save energy, increase data rate, or improve robustness, some nodes may act as helper nodes, relaying some or all of the information. In the simplest form of relaying, data packets are forwarded node-by-node in a manner akin to a fire bucket brigade. In more advanced methods, such as those considered in this research, several nodes can cooperate to forward information. The key design questions are two-fold. First is the design of cooperative communication techniques, i.e., physical-layer approaches for relaying information from one set of nodes to the next. Second is routing, i.e., identifying which of the available nodes should participate in the transmission and what system resources (time, energy, bandwidth) should be allocated to each. <br\/><br\/>This research analyzes interconnections between these two key questions, treated separately in most prior work. We consider the routing problem when rateless codes are employed at the physical layer. Such codes allow receiving nodes to accumulate mutual information (instead of just energy) from multiple transmitting nodes. This yields greater network robustness and efficiency. The research investigates the effect of interference, which automatically arises when multiple messages are being transmitted simultaneously. By using stochastic network optimization, optimum resource allocation can be provided without the need for centralized knowledge of all states of nodes and propagation channels. Cooperative transmission techniques based on a hybrid of network-coding and compute-and-forward, their rateless variants, and application to cooperative routing are investigated as well. The concepts are validated through experiments.","title":"CIF: Medium: Collaborative Research: Cooperative Routing in Wireless Ad- Hoc Networks with Advanced PHY Layers: Interference Management, Resource Allocation, and Information Mixing","awardID":"0964479","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}}],"PIcoPI":["491079","467823"],"PO":["564924"]},"174517":{"abstract":"Data sharing methods have been studied separately in different types of networks, such as P2Ps, MANETs, and WSNs. Little research, however, has investigated pervasive data sharing across heterogeneous networks due to a lack of infrastructure or testbeds to test these ideas. This project will develop, deploy, execute, and analyze a series of data sharing architectures for P2P systems, MANETs, WSNs, and a federated solution across the heterogeneous networks in GENI. In particular, it will investigate: (1) the performance of individual data sharing systems on GENI, (2) the challenges related to achieving pervasive data sharing across heterogeneous networks, and (3) how the different networks can synergistically leverage each others' advantages. The proposed project creates a unified paradigm to study a variety of research areas. The artifacts and results stemming from this work will serve as a catalyst for future work in different computing domains.","title":"EAGER: GENI Experiments on Pervasive Data Sharing over Heterogeneous Networks","awardID":"1049947","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["563519","561722"],"PO":["564993"]},"164507":{"abstract":"People recognize dramatic situations and attribute roles and intentions to perceived characters, even when presented with extremely simple cues. As any cartoon viewer can attest, two animated shapes are sufficient to describe a scene involving tender lovers, brutal bullies, tense confrontations and hair-raising escapes. These basic notions of agency and intentionality are foundational to our social perception of the world. They provide the first discriminations between agents and objects, delineate which elements of the world can move with goal-directed purpose, and provide the primitive structure for describing cause and effect. Extensive laboratory experiments have described many of the basic properties that produce these perceptions on controlled stimuli. However there have been only limited attempts to quantify these processes and no attempts to see if these same properties hold on real-world activity patterns.<br\/><br\/>This project models our human ability to perceive agency, intentionality, and goal-directed behavior in dynamic real-world environments. Using off-the-shelf real-time localization systems, the movements of people and objects are recorded as they engage in unstructured activity and staged group games. Drawing on both this empirical data and theories drawn from the psychophysical data, computational models are constructed that quantify, explain, and predict real-world social and goal-directed behavior. The benefits of this work include: (1) modeling tools for use within behavioral studies, (2) a real-world grounding for psychophysical studies, and (3) a computational model of social and intentional behavior that would enhance human-computer and human-robot interfaces.","title":"SoCS: Modeling Agency and Intentions in Dynamic Environments as a Precursor to Efficient Human-Computer Interaction","awardID":"0968538","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[440698,"497125"],"PO":["565215"]},"167918":{"abstract":"This innovative project proposes to explore new hypotheses with respect to analysis of handwriting by examining and analyzing the written works of native and non-native writers of a particular script or alphabet. One hypothesis to be explored is that handwriting can be taken as analogous to speech in the sense that emphases might be indicated in the script itself without special notation. A second hypothesis is that an individual's handwriting is a mixture of style influences that can be decomposed into identifiable constituents. Insight into these issues could result in expansion of our ability to identify important aspects of written works that could benefit research and applications in a variety of disciplines including computing and computational sciences, forensics, biometrics and also the humanities. Humanists would gain powerful new tools and interfaces for analyzing large collections of handwritten documents in many alphabets and scripts and thus be able to ascertain critical information of use in such tasks as chronological ordering, categorization, determination of geographic origins, etc. A number of scripts and alphabets will be included in the research including Arabic, Oriental scripts, Roman and numerous others with significant feature differences.","title":"EAGER: Automatic Identification of Writer Accent and Script Influences in Handwriting","awardID":"1014540","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["548306"],"PO":["564456"]},"171944":{"abstract":"The objective of this research is to understand the loosely coupled networked control systems and to address the scientific and technological challenges that arise in their development and operation.<br\/>The approach is to (1) develop a mathematical abstraction of the CPS, and an online actuation decision model that takes into account temporal and spatial dependencies among actions; (2) develop algorithms and policies to effectively manage the system and optimize its performance with respect to applications' QoS requirements; and (3) develop an agent-based event-driven framework to facilitate engineers easily monitor, (re)configure and control the system to achieve optimized results. The developed methodologies, algorithms, protocols and frameworks will be evaluated on testbeds and by our collaborating institution.<br\/><br\/>The project provides fundamental understanding of loosely coupled networked control systems and a set of strategies in managing such systems. The components developed under this project enables the use of wireless-sensor-actuator networks for control systems found in a variety of disciplines and benefits waterway systems, air\/ground transportation systems, power grid transmission systems, and the sort.<br\/><br\/>The impact of this project is broadened through collaborations with our collaborating institution. This project provides a set of strategies and tools to help them meet the new standards. The inter-disciplinary labs and curriculum development at both undergraduate and graduate level with an emphasis on CPS interdisciplinary applications, theoretical foundations, and CPS implementations prepare our students as future workforce in the area of CPS applications.","title":"CPS: Medium: Managing Loosely Coupled Networked Control Systems with External Disturbances","awardID":"1035894","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["545038",460572,"560173",460574],"PO":["565274"]},"172703":{"abstract":"This project is aimed at the design and experimental validation of a comprehensive clean-slate future Internet architecture. The proposed MobilityFirst architecture is motivated by the ongoing paradigm shift of Internet usage from today?s fixed PC\/host (client)?server model to emerging mobile data services and pervasive computing applications. The major design goals of the architecture are: mobility as the norm with dynamic host and network mobility at scale; robustness with respect to intrinsic properties of the wireless medium; trustworthiness in the form of enhanced security and privacy; usability features such as support for context-aware services, evolvability, manageability and economic viability. The key components of the MobilityFirst network design are: (1) separation of naming and addressing, implemented via a fast global dynamic name resolution service; (2) self-certifying public key network addresses to support strong authentication and security; (3) generalized delay-tolerant routing with in-network storage for packets in transit; (4) flat-label internetwork routing with public key addresses; (5) hop-by-hop transport protocols operating over segments rather than an end-to-end path; (6) a separate network management plane that provides enhanced visibility; (7) optional privacy features for user and location data; and (8) an integrated computing and storage layer to support programmability. The project?s scope includes architectural design, validation of key protocol components, testbed prototyping of the MobilityFirst architecture as a whole, and real-world protocol deployment on the GENI experimental infrastructure. The results of this project will provide architectural guidance for cellular-Internet convergence, and are expected to influence future technical standards in the networking industry.","title":"FIA: Collaborative Research: MobilityFirst: A Robust and Trustworthy Mobility-Centric Architecture for the Future Internet","awardID":"1040781","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["545655","499259","497218"],"PO":["565090"]},"170657":{"abstract":"This project will advance systems modeling approaches by developing a suite of stochastic modeling approaches, coupled with geostatistical and machine learning techniques. The new system modeling approach will utilize both in situ and satellite remotely sensed data to improve system model parameters and model structure. These novel developments, together with observed data, will advance ecosystem and environmental sciences through computational thinking. The proposed approach will be used to develop a cyber-enabled stochastic carbon-weather system to provide more adequate quantification of regional carbon exchanges, which is critical to better understanding carbon-climate-atmosphere feedbacks and facilitating climate-policy making. <br\/><br\/><br\/>The proposed approach will transform the current system modeling approach by (1) developing a stochastic version of the deterministic differential equation models of ecosystems and environmental systems; (2) developing geospatial statistical techniques to fully exploit multifaceted observational data to improve model parameterization; (3) developing advanced statistical and machine learning techniques to further utilize observational data to improve model structure; and (4) applying the improved model to examine the societal and biogeochemical impacts of land use change. Advantages of the proposed cyber-enabled terrestrial ecosystem model will include: (1) Efficiently quantifying regional net carbon exchanges and associated uncertainty and (2) Improving system model parameters and structure using advanced statistical and machine learning techniques and spatiotemporal data acquired over the U.S. Project deliverables include: (1) An innovative, cyber-enabled carbon-weather system that can quantify net carbon exchanges and associated probabilistic information at high spatial and temporal resolution for the continental U.S. and (2) a suite of transformative advanced mathematical, statistical and system modeling techniques that could be applied to other complex modeling fields (e.g., hydrological modeling). This project will significantly advance ecosystem sciences with computational thinking and will provide a unique opportunity to train a new generation of scientists in a highly interdisciplinary research environment.","title":"CDI-Type II: Collaborative Research: A Paradigm Shift in Ecosystem and Environmental Modeling: An Integrated Stochastic, Deterministic, and Machine Learning Approach","awardID":"1028291","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[456825,"562274",456827,456828,"416053"],"PO":["564318"]},"173935":{"abstract":"The rise of Web 2.0 and large-scale distributed contributor systems is generating opportunities for a new interdisciplinary field on the topic of collective intelligence. Like cognitive science did beginning in the 1970's, this new field may help share perspectives and results from a variety of different fields. In the case of collective intelligence, potentially relevant disciplines include computer science, organization theory, social psychology, economics, and others. This workshop will frame a research agenda covering important aspects of collective intelligence such as: how to define and measure collective intelligence, how to motivate participants to form part of an intelligent collective, what is the effect of different patterns of connection among the participants (i.e., network science), what problems are well-suited to be attacked by a collective intelligence approach, and what are common design patterns among successful systems.<br\/><br\/>The workshop on collective intelligence will facilitate broader impacts in: (a) coalescing a community of people from different disciplines and perspectives, (b) initiating consensus on how to define collective intelligence as a field and the topics that should be central within it, (c) establish a preliminary research agenda for the field, and (d) catalyze publications about the prospects for this field in one or more high quality journals.","title":"Workshop on Collective Intelligence","awardID":"1047567","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["551789"],"PO":["565227"]},"172637":{"abstract":"While the Internet has far exceeded expectations, it has also stretched initial assumptions, often creating tussles that challenge its underlying communication model. Users and applications operate in terms of content, making it increasingly limiting and difficult to conform to IP's requirement to communicate by discovering and specifying location. To carry the Internet into the future, a conceptually simple yet transformational architectural shift is required, from today's focus on where ? addresses and hosts ? to what ? the content that users and applications care about.<br\/>This project investigates a potential new Internet architecture called Named Data Networking (NDN). NDN capitalizes on strengths ? and addresses weaknesses ? of the Internet's current host-based, point-to-point communication architecture in order to naturally accommodate emerging patterns of communication. By naming data instead of their location, NDN transforms data into a first-class entity. The current Internet secures the data container. NDN secures the contents, a design choice that decouples trust in data from trust in hosts, enabling several radically scalable communication mechanisms such as automatic caching to optimize bandwidth. The project studies the technical challenges that must be addressed to validate NDN as a future Internet architecture: routing scalability, fast forwarding, trust models, network security, content protection and privacy, and fundamental communication theory. The project uses end-to-end testbed deployments, simulation, and theoretical analysis to evaluate the proposed architecture, and is developing specifications and prototype implementations of NDN protocols and applications.","title":"FIA: Collaborative Research: Named Data Networking (NDN)","awardID":"1040380","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["553633"],"PO":["565090"]},"175838":{"abstract":"The arts and the sciences each contribute to the improvement of the human condition, yet it is clear that these modes of inquiry feature different values, aims, methods, registers and more. Furthermore, they are often posed in opposition to one another with practitioners highlighting the largely incommensurate extremes, rather than productive synergies, or practices that endeavor to serve integrated arts\/science ends. In contrast, this workshop is intended to provide fertile ground for productive dialogue amongst cultural producers operating in human-centered computing, the arts, and the social sciences. In particular, this workshop will lay the foundation for articulating the types of inquiry, collaboration, funding-opportunities, and innovation that (1) lie at the intersection of concerns of the National Science Foundation and National Endowment for the Arts and (2) represent opportunities for producing knowledge and art unanticipated by either institution alone. It is not necessary to start this process from scratch. As an initiative of the Computer & Information Science & Engineering Directorate (CISE) Information and Intelligent Systems division (IIS) and Human Centered Computing cluster (HCC), the NSF CreativeIT Program funded \"projects that explored interdisciplinary and synergistic cross-disciplinary research in creativity and computer science and information technology.\" The program funded research efforts integrating creative practices outside of the \"traditional\" usability- and productivity-oriented HCC cannon, including art\/science and art\/engineering collaborations. We can learn from the successes and challenges of supporting high-risk, high-reward research from the CreativeIT program. The CreativeIT program provides as its legacy a platform we can use to inform future funding endeavors that support and celebrate creativity-based technology research. <br\/><br\/>The goals and objectives of this workshop are to establish a ground for a thoughtful and vibrant dialogue amongst human-centered computing researchers and technology innovators, artists, creative practitioners, and social scientists. This dialogue can provide insights and indications for brainstorming, understanding, and developing innovations in IT research (building on previous workshops and endeavors in the field over the past decade and longer. Furthermore, this workshop is proposed as a first step to continued involvement between the National Science Foundation, National Endowment for the Arts, and other support organizations to understanding the infrastructure needs of the field in the United States. The goals of this workshop include the following: 1) Fostering current and new inter-agency, inter-institutional relationships for dialogue, collaboration and new inter\/cross agency co-funding opportunities. 2) Identifying points of intersection between in information technology oriented work in digital media arts and human-centered computing. 3)Producing a field impact report that will inform next stage activities at follow-up workshop activities and meetings with the goal of organizing infrastructure support channels that can help this community sustain and thrive. The workshop participants will represent thought leaders and influencers from the following constituency categories: Researchers in games studies, human centered computing, cultural and critical technology studies, technology innovations; University Program Directors in the arts, digital media, design, and computer science.; Creative Practitioners bridging aesthetics, computation, engineering, and cultural practices; Non Government Organizations (NGO) Directors with programs that support technology-based creativity research and arts influenced leadership methodologies; Foundation Leaders from organizations that support creativity-based technology research and applied applications; and Thought leaders and Influencers who have been engaged in the dialogue about transdisciplinary research practices and innovation.","title":"WORKSHOP: Identifying Synergies and Fostering Collaborations in a Joint Workshop of the National Science Foundation and the National Endowment for the Arts","awardID":"1057908","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[471277,"475004"],"PO":["564456"]},"174628":{"abstract":"This work establishes a new approach to providing ad hoc (\"discovery\") queries requiring integration and structuring: such queries help scientists learn possible relationships between topics, and help decision-makers or consumers explore options. The work develops a new system and underlying architecture based on an iterative process, where the system and user engage in a dialogue until the user has answers meeting his or her information need. <br\/><br\/>The resulting system takes sources on the Web, discovers semantic relationships among them, and allows users to pose discovery queries. It leverages existing extraction, matching, and recommendation algorithms as sources of evidence to generate hypotheses and corresponding queries, and adjusts these hypotheses based on user feedback over the query results. Innovations include scalable models for combining features and learning to re weight hypotheses; query and source recommendation techniques; and means of generalizing tuple-based feedback to support or refute hypotheses. <br\/><br\/>The research impact is a new paradigm for data integration by end users, which scalably combines machine learning and database concepts. The broader impact includes better discovery tools for scientific users and other users who sorely need them; improved integration of existing Web data resources; and new educational material on how networks of data can be as important as networks of systems and people. The PI is incorporating the research concepts into courses in the University of Pennsylvania's new Market and Social Systems Engineering Program, focused on the interface between people, protocols, and systems on the Internet, especially through social and data networks, as well as markets. More information on the project can be found on the project website at http:\/\/www.cis.upenn.edu\/~zives\/dialogue\/","title":"III: EAGER: Data Integration as a Dialogue with the User","awardID":"1050448","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["517980"],"PO":["563727"]},"174309":{"abstract":"Today's computer users often run programs for which they do not have the source code. In some cases, those programs are viruses or other malware, and it is desirable to understand how they work in order to prevent them from causing further damage or to track down the author. Part of the process of understanding the program (sometimes called \"reverse engineering\")is to understand how it stores data. This research develops a new technique for revealing the data structures in programs for which only the binary code is available called REWARDS -- Reverse Engeineering Work for Automatic Revelation of Data Structures. The tools developed by the research are evaluated against both benign and malicious programs.","title":"TC: EAGER: Binary-based Data Structure Revelation for Memory Forensics","awardID":"1049303","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["518557","550848"],"PO":["564223"]},"171813":{"abstract":"The current generation of automobiles uses sensors and computers to assist the driver to avoid accidents. The next step is to use communications between automobiles to improve the accuracy of sensor measurements and negotiate maneuvers between vehicles. The objective is to improve safety and increase the capacity of roadways.<br\/><br\/>As the systems evolve, different vehicles will have different capabilities. The communications between vehicles is unreliable. And, the algorithms are complex and failures can be fatal. This year there have been massive recalls of vehicles with faulty control systems.<br\/><br\/>In this project, we are: <br\/><br\/>1) Investigating a variety of roles that communications can play in vehicle control, and the limitations that communications imposes on control. <br\/><br\/>2) Establishing metrics to quantify the performance of cyber-physical systems in several dimensions, including performance, fairness and safety. <br\/><br\/>3) Testing strategies to guarantee that the systems can be operated safely.<br\/><br\/>We are testing our techniques by analyzing and simulating a system that controls multiple lane merges that occur when highways merge, following tolls, and at construction or accident sites. For instance, at the lower level of the New York bound George Washington Bridge, 10 lanes merge to 3. The delays during the morning rush range from 20 to 90 minutes, and there are accidents most days. Assisted lane merging can reduce accidents and delays at these dangerous locations. These systems are the most technically challenging of the collaborative driving applications. They require cooperation and planning between vehicles in addition to controlling the speed, braking and maneuvers of the individual vehicles.","title":"CPS: Small: The Roles of Communications in Lane Merging Systems","awardID":"1035178","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553512"],"PO":["564778"]},"171835":{"abstract":"The objective of this research is to study such properties of classes of cooperative multi-agent systems as stability, performance, and robustness. Multi-agent systems such as vehicle platoons and coupled oscillators can display emergent behavior that is difficult to predict from the behavior of individual subsystems. The approach is to develop and extend the theory of fundamental design limitations to cover multi-agent systems that communicate over both physical and virtual communication links. The theory will further describe known phenomena, such as string instability, and extend the analysis to other systems, such as harmonic oscillators. The theory will be tested and validated in the Michigan Embedded Control Systems Laboratory. <br\/><br\/><br\/>The intellectual merit of the proposed research will be the development of tools that delineate tradeoffs between performance and feedback properties for control systems involving mixes of human and computer agents and classes of hardware dynamics, controllers, and network topology. The contribution to system behavior of each agent?s realization in hardware (constrained by Newton's laws) and realization in software and communications (subject to the constraints discovered by Shannon and Bode) will be assessed. <br\/><br\/><br\/>The broader impacts of the proposed research will be a significant impact on teaching, both at the University of Michigan and at ETH Zurich. At each school, popular teaching laboratories allow over 100 students per year, from diverse backgrounds, to learn concepts from the field of embedded networked distributed control systems. New families of haptic devices will enable the research to be transferred into these teaching laboratories.","title":"CPS: Small: Fundamental Limitations for Classes of Cooperative Multi-Agent Systems","awardID":"1035271","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[460153,"550636"],"PO":["564728"]},"172704":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040784","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["486393"],"PO":["565090"]},"173705":{"abstract":"The REUSSI-2 project funds US graduate student research internships at INRIA, the premier Computer Science research institute in France. The project is made possible by co-funding between the NSF Office of International Science and Engineering and the Directorate of Computer and Information Science and Engineering. The program will support 10 to 20 US student internships each year. Each selected student is expected to spend at least two summer months and at most six months working at INRIA. INRIA pays each student a stipend and the INRIA scientists mentor and guide the student's research during the internship. INRIA also provides students with health insurance during their internships. NSF funds cover the travel costs and costs associated with getting students to the annual summer research colloquium held during the time they are in France. A call for internship applications is published in October of each year. The call is also sent via email to US universities with graduate research programs, including universities with a high proportion of students from under-represented groups. Each applicant has to contact the INRIA site that posted the internship opportunity prior to applying in order to obtain INRIA support for the application. Furthermore, each student applicant must be nominated by his\/her adviser and must state how the visit will enhance his\/her graduate work. Each application must include a brief description of the proposed internship work. The description must be developed in consultation with the INRIA scientists and must include a statement asserting that the INRIA scientists commit to mentoring the student during the internship period. Submitted applications are evaluated by the REUSSI-2 PI with the help of representatives from INRIA sites that the students apply to visit. Final selections will be made by the REUSSI-2 PI in consultation with the INRIA International Relations Office. Selected students and the respective INRIA teams will be informed in mid to late-December.<br\/><br\/>The Computer Science projects currently covered by participating US institutions tackle complex problems in areas such as computer graphics, computational brain anatomy, rigorous modeling and analysis of critical software systems, computational MRI, next generation wireless networks, quantum computing, and ocean modeling. Participating students have the opportunity to develop international research links that can be further strengthened and leveraged in their research careers. These collaborations and student exchanges help to nurture a spirit of international cooperation which, through exchange of high quality ideas, can yield significant insights into some of the more challenging Computer Science research problems.","title":"International: Research Experience for US Students at INRIA - REUSSI 2","awardID":"1045885","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7731","name":"OTHER GLOBAL LEARNING & TRNING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["557996"],"PO":["564388"]},"173947":{"abstract":"Electronic solutions for storing, retrieving, sharing, and analyzing health related information are being deployed rapidly. Solutions may be designed for healthcare professionals or consumers. As a result, individuals may access the records infrequently or frequently, they may access a single record repeatedly (i.e., consumers reviewing their record) or many different records occasionally (i.e., providers preparing to meet with patients), or they may need to compare information across records (i.e., researchers looking for patterns). Individuals may enter or update information, or they may simply access the information which is likely to include a combination of text and graphics. Security must be maintained, collaboration should be supported, and privacy must be ensured. While solutions are being proposed in response to pressure from various stakeholders to move forward rapidly, there is a concern that accessibility of electronic medical records by people with disabilities has not been adequately addressed.<br\/><br\/>This is funding to support a workshop of approximately 15 researchers, to explore these issues. The workshop will have three related goals: to educate accessibility researchers with regard to the concerns and needs of the healthcare community; to educate the healthcare community with regard to issues, challenges, and existing solutions with regard to making relevant information accessible to individuals with disabilities; and to identify critical issues which need to be addressed by the research community if accessibility is to be effectively addressed in the context of electronic medical records. The workshop will take place in Orlando, Florida on October 23-24, 2010, and will be co-located with and on the days immediately preceding ACM's annual conference on computers and accessibility, ASSETS 2010, in the hope of thereby increasing the likelihood of engaging key accessibility researchers in the discussions. The PI will in addition solicit input and encourage participation from beyond the accessibility community, in order to ensure that the needs and concerns of the healthcare community are understood by attendees and integrated into the discussions.<br\/><br\/>Broader Impacts: This workshop will help identify important accessibility-related issues that may be addressed through future research, while providing individuals from the healthcare and accessibility communities with the opportunity to discuss common interests, goals, and concerns. Workshop outcomes will directly affect a broad range of users, including individuals from under-represented groups with a particular emphasis on individuals with disabilities. The event will foster networking amng both new and experienced researchers, and in particular will provide opportunities for new researchers to receive constructive feedback on current and future research plans through interactions with more senior researchers with related interests.","title":"Accessible Electronic Health Records: Defining a Research Agenda","awardID":"1047616","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[466602],"PO":["565227"]},"170923":{"abstract":"Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and <br\/>Communicative Behavior<br\/>Lead PI\/Institution: James M. Rehg, Georgia Institute of Technology<br\/>This Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. <br\/>Human behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions. This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.<br\/>The long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles.","title":"Collaborative Research: Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and Communicative Behavior","awardID":"1029679","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[457579,"563803","550806",457582],"PO":["565227"]},"170934":{"abstract":"Understanding Climate Change: A Data Driven Approach<br\/><br\/>Climate change is the defining environmental challenge now facing our planet. Whether it is an increase in the frequency or intensity of hurricanes, rising sea levels, droughts, floods, or extreme temperatures and severe weather, the social, economic, and environmental consequences are great as the resource-stressed planet nears 7 billion inhabitants later this century. Yet there is considerable uncertainty as to the social and environmental impacts because the predictive potential of numerical models of the earth system is limited. These models are incapable of addressing important questions relating to food security, water resources, biodiversity, mortality, and other socio-economic issues over relevant time and spatial scales.<br\/><br\/>Climate model development has contributed small and incremental improvements; however, extensive modeling gains have not been forthcoming. Modeling limitations have hampered efforts at providing information on climate change impacts and adaptation and mitigation strategies. A new and transformative approach is required to improve prediction of the potential impacts on human welfare. Data driven methods that have been highly successful in other facets of the computational sciences are now being used in the environmental sciences with success. This Expedition project will significantly advance key challenges in climate change science developing exciting and innovative new data driven approaches that take advantage of the wealth of climate and ecosystem data now available from satellite and ground-based sensors, the observational record for atmospheric, oceanic, and terrestrial processes, and physics-based climate model simulations.<br\/><br\/>To realize this ambitious goal, novel methodologies appropriate to climate change science will be developed in four broad areas of data-intensive computer science: relationship mining, complex networks, predictive modeling, and high performance computing. Analysis and discovery approaches will be cognizant of climate and ecosystem data characteristics, such as non-stationarity, nonlinear processes, multi-scale nature, low-frequency variability, long-range spatial dependence, and long-memory temporal processes such as teleconnections. These innovative new approaches will be used to better understand the complex nature of the earth system and the mechanisms contributing to such climate change phenomena as hurricane frequency and intensity in the tropical Atlantic, precipitation regime shifts in the ecologically sensitive African Sahel or the Southern Great Plains, and the propensity for extreme weather events that weaken our infrastructure and result in environmental disasters with economic losses in excess of $100 billion per year in the U.S. alone.<br\/><br\/>Assessments of climate change impacts, which are useful for stakeholders and policymakers, depend critically on regional and decadal scale projections of climate extremes. Thus, climate scientists often need to develop qualitative inferences about inadequately predicted climate extremes based on insights from observations (e.g., increase in hurricane intensity) or conceptual understanding (e.g., relation of wildfires to regional warming or drying and hurricanes to sea surface temperatures). These urgent societal priorities offer fertile grounds for knowledge discovery approaches. In particular, qualitative inferences on climate extremes and impacts may be transformed into quantitative predictive insights based on a combination of hypothesis-guided data analysis and relatively hypothesis-free, yet data-guided discovery processes.<br\/><br\/>A primary focus of this Expedition project will be on uncertainty reduction, which can bring the complementary or supplementary skills of physics-based models together with data-guided insights regarding complex climate processes. The systematic evaluation of climate models and their component processes, as well as uncertainty assessments at regional and decadal scales is a fundamental problem that will be addressed. The ability to translate gains in the predictive skills of climate variables to improvements in impact assessments and attributions is a critical requirement for informing policymakers. Novel methodologies will be developed to gain actionable insights from disparate impacts-related datasets as well as for causal attribution or root-cause analysis. <br\/><br\/>This research will be conducted in close collaboration with the climate science community and will complement insights obtained from physics-based climate models. Improved understanding of salient atmospheric processes will be provided to those contributing to the development and improvement of climate models with the goal of improving predictability. The approaches and formalisms developed in this research are expected to be applicable to a broad range of scientific and engineering problems, which use model simulations to an","title":"Collaborative Research: Understanding Climate Change: A Data Driven Approach","awardID":"1029731","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[457620],"PO":["565223"]},"171913":{"abstract":"The objective of this research is to develop an atomic force microscope based cyber-physical system that can enable automated, robust and efficient assembly of nanoscale components such as nanoparticles, carbon nanotubes, nanowires and DNAs into nanodevices. The approach in this project is based on the premise that automated, robust and efficient nanoassembly can be achieved through tip based pushing in an atomic force microscope with intermittent local scanning of nanoscale components. In particular, in order to resolve temporally and spatially continuous movement of nanoscale components under tip pushing, the research is exploring the combination of intermittent local scanning and interval non-uniform rational B-spline based isogeometric analysis in this research.<br\/><br\/>Successful completion of this research is expected to lead to foundational theories and algorithmic infrastructures for effective integration of physical operations (pushing and scanning) and computation (planning and simulation) for robust, efficient and automated nanoassembly. The resulting theories and algorithms will also be applicable to a broader set of cyber physical systems. <br\/><br\/>If successful, this research will lead to leap progress in nanoscale assembly, from prototype demonstration to large-scale manufacturing. Through its integrated research, education and outreach activities, this project is providing experiences and understanding in cyber-physical systems and nanoassembly for students from high schools to graduate schools. The goal is to increase interest in science and engineering among domestic students and therefore strengthen our competitiveness in the global workforce.","title":"CPS: Small: Collaborative Research: Automated and Robust Nano-Assembly with Atomic Force Microscopes","awardID":"1035563","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["528686"],"PO":["565239"]},"171946":{"abstract":"Abstract <br\/>Abstract (NSF 1035906): <br\/><br\/><br\/>The objective of this research is to establish a foundational framework for smart grids that enables significant penetration of renewable DERs and facilitates flexible deployments of plug-and-play applications, similar to the way users connect to the Internet. The approach is to view the overall grid management as an adaptive optimizer to iteratively solve a system-wide optimization problem, where networked sensing, control and verification carry out distributed computation tasks to achieve reliability at all levels, particularly component-level, system-level, and application level. <br\/><br\/>Intellectual merit. Under the common theme of reliability guarantees, distributed monitoring and inference algorithms will be developed to perform fault diagnosis and operate resiliently against all hazards. To attain high reliability, a trustworthy middleware will be used to shield the grid system design from the complexities of the underlying software world while providing services to grid applications through message passing and transactions. Further, selective load\/generation control using Automatic Generation Control, based on multi-scale state estimation for energy supply and demand, will be carried out to guarantee that the load and generation in the system remain balanced. <br\/><br\/><br\/>Broader impact. The envisioned architecture of the smart grid is an outstanding example of the CPS technology. Built on this critical application study, this collaborative effort will pursue a CPS architecture that enables embedding intelligent computation, communication and control mechanisms into physical systems with active and reconfigurable components. Close collaborations between this team and major EMS and SCADA vendors will pave the path for technology transfer via proof-of-concept demonstrations.","title":"CPS: Medium: Collaborative Research: Architecture and Distributed Management for Reliable Mega-scale Smart Grids","awardID":"1035906","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[460579,"518327"],"PO":["564728"]},"170758":{"abstract":"Abstract: The Variability Expedition<br\/>Project: Variability-Aware Software for Efficient Computing with Nanoscale Devices<br\/><br\/>As semiconductor manufacturers build ever smaller components, circuits and chips at the nano scale become less reliable and more expensive to produce ? no longer behaving like precisely chiseled machines with tight tolerances. Modern computing is effectively ignorant of the variability in behavior of underlying system components from device to device, their wear-out over time, or the environment in which the computing system is placed. This makes them expensive, fragile and vulnerable to even the smallest changes in the environment or component failures. We envision a computing world where system components -- led by proactive software -- routinely monitor, predict and adapt to the variability of manufactured systems. Changing the way software interacts with hardware offers the best hope for perpetuating the fundamental gains in computing performance at lower cost of the past 40 years. The Variability Expedition fundamentally rethinks the rigid, deterministic hardware-software interface, to propose a new class of computing machines that are not only adaptive but also highly energy efficient. These machines will be able to discover the nature and extent of variation in hardware, develop abstractions to capture these variations, and drive adaptations in the software stack from compilers, runtime to applications. The resulting computer systems will work and continue working while using components that vary in performance or grow less reliable over time and across technology generations. A fluid software-hardware interface will thus mitigate the variability of manufactured systems and make machines robust, reliable and responsive to the changing operating conditions.<br\/><br\/>The Variability Expedition marshals the resources of researchers at the California Institute for Telecommunications and Information Technology (Calit2) at UC San Diego and UC Irvine, as well as UCLA, University of Michigan, Stanford and University of Illinois at Urbana-Champaign. With expertise in process technology, architecture, and design tools on the hardware side, and in operating systems, compilers and languages on the software side, the team also has the system implementation and applications expertise needed to drive and evaluate the research as well as transition the research accomplishments into practice via application drivers in wireless sensing, software radio and mobile platforms. <br\/><br\/>A successful Expedition will dramatically change the computing landscape. By re-architecting software to work in a world where monitoring and adaptation are the norm, it will achieve more robust, efficient and affordable systems that are able to predict and withstand not only hardware failures, but other kinds of software bugs or even attacks. The new paradigm will apply across the entire spectrum of embedded, mobile, desktop and server-class computing machines, yielding particular gains in sensor information processing, multimedia rendering, software radios, search, medical imaging and other important applications. Transforming the relationship between hardware and software presents valuable opportunities to integrate research and education, and this Expedition will build on established collaborations with educator-partners in formal and informal arenas to promote interdisciplinary teaching, training, learning and research. The team has built strong industrial and community outreach ties to ensure success and reach out to high-school students through a combination of tutoring and summer school programs. The Variability Expedition will engage undergraduate and graduate students in software, hardware and systems research, while promoting participation by underrepresented groups at all levels and broadly disseminating results within academia and industry.","title":"Collaborative Research: Variability-Aware Software for Efficient Computing with Nanoscale Devices","awardID":"1028888","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["535191"],"PO":["562984"]},"172705":{"abstract":"Today's Internet is under enormous pressure: there is a growing diversity of use models, an urgent need for trustworthy communication, and a growing set of stakeholders who must coordinate to provide Internet services.<br\/>The project is developing the eXpressive Internet Architecture (XIA), a potential new network architecture that is built around several key principles. First, XIA represents a single network that offers inherent support for communication between diverse principals including hosts, content, services, and unknown future entities. For each type of principal, XIA defines a narrow waist that dictates the API for communication and the network communication mechanisms. Second, XIA rests upon a foundation of intrinsic security in which the integrity and authenticity of communication is guaranteed using XIA's various self-certifying identifiers. Third, XIA enables flexible context-dependent mechanisms for establishing trust between the communicating principals, bridging the gap between human and intrinsically secure identifiers. Finally, recognizing the Internet's central role in our society, economic, policy, and usability considerations play a major role in XIA's design. The project includes user experiments to evaluate and refine the interface between the network and users, and studies that analyze the relationship between technical design decisions, and economic incentives and public policy.<br\/>The outcome of the project will be knowledge about a potential future network architecture that is inherently trustworthy, supports long-term evolution of network use models and network technology, and provides explicit interfaces for interaction between network actors. The architecture will also enable greater visibility and control for various stakeholders, including users, ISPs, and content owners.","title":"FIA: Collaborative Research: A Content and Service Friendly Architecture with Intrinsic Security and Explicit Trust","awardID":"1040800","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["313342"],"PO":["565090"]},"171858":{"abstract":"Using the newly introduced idea of a sensor lattice, this project conducts a systematic study of the ``granularity'' at which the world can be sensed and how that affects the ability to accomplish common tasks with cyberphysical systems (CPSs). A sensor is viewed as a device that partitions the physical world states into measurement-invariant equivalence classes, and the sensor lattice indicates how all sensors are related. Several distinctive characteristics of the pursued approach are: 1) Virtual sensor models are developed, which correspond to minimal information requirements of common tasks and are independent of particular physical sensor implementations. 2) Uncertainty is decoupled into disturbances and preimages, the latter of which yields the measurement-invariant equivalence classes and sensor lattice. 3) The development of particular spatial and temporal filters that are based on minimal information requirements of a task. 4) Formally establishing the conditions that enable sensors in a CPS to be interchanged, and then determining the relative complexity tradeoffs.<br\/><br\/>The intellectual merit is to understand how mappings from the physical world to sensor outputs affect the solvability and complexity of commonly occurring tasks. This is a critical step in the development of mathematical and computational CPS foundations. Broader impact is expected by improving design methodologies for CPS solutions to societal problems such as assisted living, environmental monitoring, and automated agriculture. The sensor lattice approach is transformative because it represents a new paradigm with which to address basic sensor-based inference issues, which extend well beyond the traditional academic boundaries.","title":"CPS: Small: Sensor Lattices","awardID":"1035345","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553248"],"PO":["565239"]},"172639":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040391","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548463"],"PO":["565090"]},"163707":{"abstract":"Unprecedented computational power is available from multi-core processors and cloud computing. To date, this power has been used primarily to make programs run faster. However, in many cases the bottleneck to solving users' problems is in the challenge of creating the software, not in the time to run it. This project will apply computational power to the real bottleneck, providing developers with new types of feedback. As a key broader impact, the research will enable developers to create software more quickly, more cheaply, and with higher quality.<br\/><br\/>The key technical idea is to inform developers, in advance, of the consequences of their likely actions. The development environment speculates about developer actions, evaluates the effect of each action (on compilation, tests, version control conflicts, etc.), and unobtrusively makes this information available to the developer. By knowing which choices are good and which are bad, developers can avoid bad choices that cost time or reduce quality. The project's intellectual merits include algorithms to quickly create and evaluate many possible developer actions, UI design for developer awareness, and evaluation of how increased awareness of contingent information, about possible actions, affects developers. This also leads toward an answer to the question: If developers had infinite processing power, what fundamental software engineering research problems would remain?","title":"SHF: Medium: Combining Speculation with Continuous Validation for Software Developers","awardID":"0963757","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["501796","450771"],"PO":["564388"]},"174619":{"abstract":"A hallmark of the scientific method has been that experiments should be described in enough detail that they can be repeated and perhaps generalized. This implies the possibility of repeating results on nominally equal configurations and then generalizing the results by replaying them on new data sets, and seeing how they vary with different parameters. In principle, this should be easier for computational experiments than for natural science experiments, because not only can computational processes be automated but also computational systems do not suffer from the \"biological variation\" that plagues the life sciences. Unfortunately, the state of the art falls far short of this goal. Most computational experiments are specified only informally in papers, where experimental results are briefly described in figure captions; the code that produced the results is seldom available; and configuration parameters change results in unforeseen ways. Because important scientific discoveries are often the result of sequences of smaller, less significant steps, the ability to publish results that are fully documented and reproducible is necessary for advancing science. While concern about repeatability and generalizability cuts across virtually all natural, computational, and social science fields, no single field has identified this concern as a target of a research effort.<br\/><br\/>This collaborative project between the University of Utah and New York University consists of tools and infrastructure that supports the process of sharing, testing and re-using scientific experiments and results by leveraging and extending the infrastructure provided by provenance-enabled scientific workflow systems. The project explores three key research questions: (1) How to package and publish compendia of scientific results that are reproducible and generalizable. (2) What are appropriate algorithms and interfaces for exploring, comparing, re-using the results or potentially discovering better approaches for a given problem? 3) How to aid reviewers to generate experiments that are most informative given a time\/resource limit.<br\/><br\/>An expected result of this work is a software infrastructure that allows authors to create workflows that encode the computational processes that derive the results (including data used, configuration parameters set, and underlying software), publish and connect these to publications where the results are reported. Testers (or reviewers) can repeat and validate results, ask questions anonymously, and modify experimental conditions. Researchers, who want to build upon previous works, are able to search, reproduce, compare and analyze experiments and results. The infrastructure supports scientists, in many disciplines, to derive, publish and share reproducible results. Results of this research, including developed software will be available via the project web site ( http:\/\/www.vistrails.org\/index.php\/RepeatabilityCentral).","title":"III: EAGER: Collaborative Research: A Community Experiment Platform for Reproducibility and Generalizability","awardID":"1050388","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563679"],"PO":["563751"]},"171914":{"abstract":"The objective of this research is to enable cyberphysical systems (CPS) to be context-aware of people in the environment and to use data from real-world probabilistic sensors. The approach is (1) to use radio tomography (RT) and RFID to provide awareness (location and potential identification) of every person in a building or area, and (2) to develop new middleware tools to enable context-aware computing systems to use probabilistic data, thus allowing new applications to exploit sometimes unreliable estimates of the environment.The intellectual merit of the proposal is in the development of new algorithms and models for building-scale RT with low radio densities and across multiple frequencies; the development of efficient multichannel access protocols for rapid and adaptive peer-to-peer measurements; the development of space-time and probabilistic data representations for use in stream-based context awareness systems and for merging ID and non-ID data; (4) and the development of a human context-aware software development toolkit that interfaces between probabilistic data and context-aware applications. <br\/><br\/>The proposal impacts broadly the area of Cyberphysical systems that reason about human presence and rely on noisy and potentially ambiguous (practical) sensors. The research has additional dramatic impact in: (1) smart facilities which automatically enforce safety, privacy, and security procedures, increasing the ability to respond in emergency situations and prevent accidents and sabotage; (2) elder care, to monitor for physical or social decline so that effective intervention can be implemented, extending the period elders can live in their own home, without pervasive video surveillance.","title":"CPS: Medium: Collaborative Research: Enabling and Advancing Human and Probabilistic Context Awareness for Smart Facilities and Elder Care","awardID":"1035565","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["542075","464564","542076"],"PO":["565136"]},"171925":{"abstract":"The objective of this research is to develop methods and tools for designing, implementing and verifying medical robotics. The approach is to capture the computational work-flow of systems with cyber, physical and biological components, to verify that work-flow and to synthesize systems from the work-flow model. The focusing application of this research is MRI-guided, high-frequency ultrasonic tumor ablation. MRI-guided ultrasonic tumor ablation poses challenges beyond the scope of current verification techniques. Medicine is filled with highly non-linear biological systems, which puts them at the frontier of mathematically rigorous correctness checking and verification. For instance, in this research, guaranteeing the safety of a cancer patient undergoing treatment will require verifying against Pennes bioheat equation, a non-linear differential equation with dozens of environmental factors. This research tackles such complexity using tiers of abstractions to efficiently, precisely and safely approximate the behavior of each component of a system. To ensure a faithful implementation of controllers, this research will investigate synthesizing the control code directly from the verified model in a correct by construction manner. The project will help develop the most appropriate family of formal methods for handling the safety and correctness challenges in the area of medical robotics. It directly addresses the CPS agenda of methods and tools by proposing formal techniques that bridge the gap between the cyber and physical elements. It will train manpower in cross-disciplinary areas through new seminars, workshops and courses. And, last but not least, the project will make a direct humanitarian impact on the well-being of society.","title":"CPS: Medium: Safety-Oriented Hybrid Verification for Medical Robotics","awardID":"1035658","effectiveDate":"2010-09-15","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["513354","561775","564587",460509],"PO":["565239"]},"171936":{"abstract":"NSF CPS Proposal: 1035800<br\/>ABSTRACT<br\/>The objective of this research is to develop new methods for verifying the safety of complex cyber-physical systems based on information derived from the wide variety of models and methods used throughout the design process. The approach is based on a new formalism to represent the architecture of systems with cyber components, physical components, and interconnections between these domains. Diverse engineering models of different aspects of the system will be associated through the cyber-physical architecture for the complete system. Formal logic will be developed to express and reason about inter-model consistency and to infer system-level properties from information derived from the domain-specific models. <br\/>The project?s intellectual merit lies in the creation of a comprehensive, unified framework for verifying properties of systems rich in both cyber and physical components. The new formal logic will make it possible to integrate information from the wide range of engineering domains and technical expertise required to design complex systems. This will lead to a principled, rigorous approach to system-level verification engineering for real-world cyber-physical systems.<br\/>The application of the new methodology to verify the safety of cooperative intersection collision avoidance systems will have immediate impact on emerging technologies for safer automobile systems. A new interdisciplinary course in engineering and computer science on system-level design of cyber-physical systems will prepare a new cadre of graduates with the cross-cutting skills needed to develop safety-critical systems. Innovative educational modules will also be developed to inspire pre-college students to pursue education and careers in engineering and computer science.","title":"CPS: Medium: GOALI: An Architecture Approach to Heterogeneous Verfication of Cyber-Physical Systems","awardID":"1035800","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"1504","name":"GRANT OPP FOR ACAD LIA W\/INDUS"}}],"PIcoPI":[460545,"485947","469969",460548],"PO":["564728"]},"170869":{"abstract":"Abstract<br\/><br\/>The creation of the the International Conference for Mesoscopic Methods in Engineering and Science (ICMMES) series is a direct response to the growing interest in multi-scale and multi-physics phenomena observed in nano- or micro-systems and biological systems, and the increasing importance of computational science to research in all disciplines, especially to the aforementioned areas. The focus of the ICMMES conference series is mesoscopic\/ kinetic methods (e.g., lattice Boltzmann equation, lattice gas cellular automata, discrete velocity models, gas-kinetic schemes, dissipative particle dynamics, smoothed particle hydrodynamics, and various hybrid methods) for computational mechanics in its broadest sense. Specific areas of interest include, but are not limited to, mesoscopic\/kinetic methods applied to: computational fluid dynamics, rheology of complex fluids and soft matter, multi-scale\/multi-physics phenomena in macro-, nano- or micro-systems, thermo-chemically nonequilibrium systems, chemical reactive flows, new algorithms, and special computer hardware.<br\/><br\/>The funding from NSF will be used in support of students, post-doctoral researchers, and junior faculty from US institutions actively participate in ICMMES. Special consideration is given to under-represented minorities, women, persons with disabilities, and those in Historically Black Colleges and Universities (HBCU).<br\/><br\/>The objectives of the ICMMES Conferences are as follows: (1) To bring together researchers from academia, government labs., and industry to exchange and disseminate up-to-date information, and explore new opportunities in the field; (2) To expose young and new researchers to the state-of-the-art in the field by means of short courses and interactions with renowned experts in the field; and (3) To actively encourage underrepresented minorities, women, persons with disabilities, and students in HBCUs to explore frontier of research by attending the ICMMES Conferences. Although the United States played a key role in the early development of mesoscopic methods, its strength has been weakening throughout the past decade due to lack of funding, while European and Asian countries have significantly increased their funding level in the field. The relative weakness of the US is indicated by the fact that a small and decreasing percentage of papers published in peer reviewed journals are by US authors. Given the scientific importance of mesoscopic methods, it is urgent and imperative for the US to increase funding support for research in the field. The objective of this proposal is to seek NSF support to increase US participation in ICMMES Conferences and to strengthen the US position in this fast-growing research field.<br\/><br\/>The main intellectual merit of this proposal is that it seeks to expose new or young US scientists to research frontiers in an important and rapidly growing field through active participation in ICMMES Conferences, which constitute an ideal environment for encouraging dialog and inquiry.<br\/><br\/>Broader impact of this proposal includes improving networking between US and international researchers; disseminating up-to-date information to the scientific community at large through conferences, short courses, proceedings, and internet ; helping create a more inclusive and diverse community for young scientists; fostering a synergy among researchers from different disciplines and institutions; and strengthening the US position in a fast-growing field of research. We note that NSF support is particularly crucial to young scientists in the early stage of their careers, most of whom cannot afford to attend international conferences without external funding support.","title":"Conference Proposal to Support US Participation in ICMMES-2010","awardID":"1029428","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1443","name":"FLUID DYNAMICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}}],"PIcoPI":[457430],"PO":["525323"]},"172706":{"abstract":"Today's Internet is under enormous pressure: there is a growing diversity of use models, an urgent need for trustworthy communication, and a growing set of stakeholders who must coordinate to provide Internet services.<br\/>The project is developing the eXpressive Internet Architecture (XIA), a potential new network architecture that is built around several key principles. First, XIA represents a single network that offers inherent support for communication between diverse principals including hosts, content, services, and unknown future entities. For each type of principal, XIA defines a narrow waist that dictates the API for communication and the network communication mechanisms. Second, XIA rests upon a foundation of intrinsic security in which the integrity and authenticity of communication is guaranteed using XIA's various self-certifying identifiers. Third, XIA enables flexible context-dependent mechanisms for establishing trust between the communicating principals, bridging the gap between human and intrinsically secure identifiers. Finally, recognizing the Internet's central role in our society, economic, policy, and usability considerations play a major role in XIA's design. The project includes user experiments to evaluate and refine the interface between the network and users, and studies that analyze the relationship between technical design decisions, and economic incentives and public policy.<br\/>The outcome of the project will be knowledge about a potential future network architecture that is inherently trustworthy, supports long-term evolution of network use models and network technology, and provides explicit interfaces for interaction between network actors. The architecture will also enable greater visibility and control for various stakeholders, including users, ISPs, and content owners.","title":"FIA: Collaborative Research: A Content and Service Friendly Architecture with Intrinsic Security and Explicit Trust","awardID":"1040801","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["496764","435983","548263","560202",463128],"PO":["565090"]},"161827":{"abstract":"By analyzing and predicting program dynamic behaviors, program behavior analysis offers the fundamental support for program transformations and resource management. Its effectiveness is crucial for the maximization of computing efficiency. This research proposes to include program inputs---a so far virtually ignored dimension---into the focus of program behavior analysis, cultivating a new paradigm, namely input-centric program behavior analysis and adaptation. This input-centric paradigm will create many new opportunities for enhancing the matching between software and hardware, hence significantly improving the performance and power efficiency in modern computing.<br\/><br\/>The proposed technique, input-centric program behavior analysis and adaptation, consists of three components. The first two components, program input characterization and input-behavior modeling, resolve the complexities of program inputs, extract important features, and recognize the correlations between characterized input features and program behaviors. The third component, input-centric adaptation, capitalizes on the novel opportunities that the first two components create, making dynamic optimizations proactive and holistic, but without losing the adaptivity to inputs and environmental changes. Together, the three components make evolvable programming systems more feasible than before. In such a system, the input-behavior models embody the central knowledge base, which grows incrementally across program production runs. As the knowledge base becomes larger, behavior prediction becomes more accurate, stimulating better software-hardware matching and making the program and runtime systems perform increasingly better. Because of the fundamental role of program behavior analysis in software-hardware matching, this research helps pave the way for advancing the optimizations in various layers in the software execution stack (compilers, virtual machines, OS, etc.).","title":"CAREER: Input-Centric Program Behavior Analysis and Adaptation","awardID":"0954015","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["551005"],"PO":["565272"]},"172607":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1040190","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[462739],"PO":["565090"]},"173949":{"abstract":"This travel award supports student participation in the Tenth ACM SIGCOMM Internet Measurement Conference (IMC), sponsored by ACM SIGCOMM and ACM SIGMETRICS, in cooperation with USENIX, held in Melbourne, Australia, November 1-3, 2010.<br\/><br\/>IMC 2010 will expose students to new ideas, and allow them to interact with other researchers in the field of network measurements; specific topics include, internet traffic analysis, internet structure and topology characteristics, internet performance measurements, measurement-based network management such as traffic engineering, inter-domain and intra-domain routing, network applications such as multimedia streaming, gaming and on-line social networks, measurements of content distribution, peer-to-peer, overlay, and social networks, data-centric issues, including anonymization, querying, and storage, measurement-based inference of network properties, design of monitoring systems, sampling methods, signal processing methods, network anomaly detection and troubleshooting, network security threats and countermeasures, software tools and environments in support of measurement, measurement-based assessment of simulation\/testbeds, measurement-based workload generation, measurement-based modeling, and reappraisal of previous measurement findings.<br\/><br\/>Approximately 10 US-based graduate students are provided the opportunity to attend IMC 2010. The travel awards will target graduate students, in particular female and under-represented minority students, since they often have limited travel funds to attend workshops; attendance at such events is an important part of their educational experience.","title":"Student Travel Support for the 2010 Internet Measurement Conference","awardID":"1047631","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551132"],"PO":["564993"]},"172508":{"abstract":"While the Internet has far exceeded expectations, it has also stretched initial assumptions, often creating tussles that challenge its underlying communication model. Users and applications operate in terms of content, making it increasingly limiting and difficult to conform to IP's requirement to communicate by discovering and specifying location. To carry the Internet into the future, a conceptually simple yet transformational architectural shift is required, from today's focus on where ? addresses and hosts ? to what ? the content that users and applications care about.<br\/>This project investigates a potential new Internet architecture called Named Data Networking (NDN). NDN capitalizes on strengths ? and addresses weaknesses ? of the Internet's current host-based, point-to-point communication architecture in order to naturally accommodate emerging patterns of communication. By naming data instead of their location, NDN transforms data into a first-class entity. The current Internet secures the data container. NDN secures the contents, a design choice that decouples trust in data from trust in hosts, enabling several radically scalable communication mechanisms such as automatic caching to optimize bandwidth. The project studies the technical challenges that must be addressed to validate NDN as a future Internet architecture: routing scalability, fast forwarding, trust models, network security, content protection and privacy, and fundamental communication theory. The project uses end-to-end testbed deployments, simulation, and theoretical analysis to evaluate the proposed architecture, and is developing specifications and prototype implementations of NDN protocols and applications.","title":"FIA: Collaborative Research: Named Data Networking (NDN)","awardID":"1039615","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["475179"],"PO":["565090"]},"174719":{"abstract":"Digital puppetry refers to the interactive control of virtual characters. This approach can be useful in any virtual experience where a synthetic character?s interactivity must surpass the current capabilities of AI. Examples of this include teacher training; projecting remote docents into museums, science centers and networked virtual environments; and preparing soldiers for their first tours of duty in foreign lands. The objective of this project is to improve the quality and breadth of experiences that can be provided by the puppeteering paradigm, especially when the puppeteer is working from a remote location such as his or her home and the experience is taking place in a location with limited network connectivity. The intent is to reduce latency and bandwidth requirements; cost and complexity of experience creation, capture and delivery; and cognitive load on puppeteers ? while still providing support for complex behaviors. <br\/><br\/>This exploratory research project focuses on micro-poses that can be recognized and assembled into more complex actions. The PI seeks to rapidly identify these poses via the fusion of multiple inexpensive sources of sensor data and the physical constraints appropriate for our virtual characters. The PI approaches the tension between precision and network demand by using these micro-poses to reduce cost, footprint of the puppetry motion capture, and networking demands, while simultaneously increasing the effectiveness and accessibility of the puppeteering paradigm. The focus on accessibility leads to the development of techniques that can be run at interactive rates on in-home tabletop systems, facilitating connections between mentors and mentees across the globe.","title":"EAGER: Efficient control and transmission of digital puppetry","awardID":"1051067","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["513513"],"PO":["565303"]},"175819":{"abstract":"The pervasiveness and mobility of network-enabled devices has changed the way people interact with applications and it has also changed the way we interact with each other. Mobile devices and applications have the potential to provide users with a multitude of context-specific resources, collect a wealth of information about users and their environments, and enable users to become information sources. These systems have great potential to play an increased role in socially relevant domains, but a deeper understanding of the interactions between users, environments, applications and networks, is necessary to realize the potential to address large-scale problems. As we move forward it is critical to consider the entire system including the users. <br\/>The goal of this research is to advance the understanding of network-based socio-technical systems by creating, modeling and analyzing a specific system based at the Chicago Zoological Society?s Brookfield Zoo. The Zoo can be viewed as a rich social system including staff, animals and a diverse group of over two million visitors per year. This project creates a socio-technical system to study by introducing technology with the purpose of enticing visitors to become citizen scientists by observing and reporting animal behavior, and allowing anyone to interact with the animal observation data collected by researchers. Social networking applications will be used to share animal observations and to explicitly make the animals part of the online social network. <br\/>The Intellectual Merit of this project involves the interdisciplinary study of networks as an enabling technology and as a model for understanding the relationships between stakeholders at the Zoo. By creating a unified socio-technical framework to consider and model the relationships between the stakeholders and technology, one can explore many research issues. The research will aid in gaining a deeper understanding of the factors that influence information transfer across social networks. It will allow consideration of the types of information that are likely to stimulate network activity and facilitate a cognitive system that adapts to environment to optimize user outcomes. We will be able to ascertain how information from various sources (e.g. scientists, guests, educators) influences activity of the network and transmission of specific messages through the network. This work will also provide a demonstration of how individuals with fundamentally different roles in the network (animals, application designers, and application users) influence network outcomes. <br\/>The Broader Impact of this project includes the software application introduced at the zoo, the research outcomes and the students exposed to the project. People of varied socio-economic backgrounds as well as many school groups and other organizations visit Brookfield Zoo. The National Research Council (NRC 2009) concludes that informal learning environments (e.g. Zoos) can have a significant impact on science learning outcomes for underrepresented groups. The work proposed here will be fundamental in determining a new role for technology in this learning. More immediately, it can also encourage a diverse audience of zoo visitors to pursue interests in the zoo animals and perhaps become a citizen scientist, reporting observations and investigating the data collected. Increased understanding of the connections between design and engineering of technology and social outcomes can empower us to best utilize technology to solve important social problems. This work will serve as a model for optimizing resource distribution when there is the potential to utilize comprehensive integrated information (social and technical) and the goal is to increase message transfer and understanding. Additionally, a diverse group of students will be involved and trained through this project. The PIs have a track record of working with underrepresented groups and will use this project as a platform to involve even more women and minorities.","title":"Collaborative Research: EAGER: Zoo-Based Network Science Experimentation and Modeling","awardID":"1057829","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[471235],"PO":["565090"]},"171915":{"abstract":"The objective of this research is to apply grammatical inference models recently developed in the field of linguistics and phonology, as a basis for abstraction, composition, symbolic control, and learning in distributed multi-agent cyber-physical systems. The approach is to map the system dynamics, specifications, and task interdependences to finite abstract models, and then describe the desired behavior of the system in an appropriate grammar that can be decomposed into local agent specifications. In this framework, the agents can learn the behavior of their environment by observing its dynamics, and update their specifications accordingly. <br\/><br\/>The proposed approach to learning in cyber-physical systems, which is based on grammatical inference at a purely discrete level, is a significant departure from current works. Following this approach, one can reason about large-scale processes resulting from event interdependencies between agents, without having to construct large product systems. To realize this plan, specific technical advances on modeling, abstraction, and control synthesis are proposed.<br\/><br\/>Questions related to formally factoring and composing heterogeneous systems are pervasive in the fields of formal languages and computational learning. There are also applications of commercial significance in the area of discovering new azeotropic mixtures based on documented pairs of compounds that are known to have the particular property. Proposed dissemination and outreach activities include the involvement of middle and high school students and teachers, integrated in existing NSF-sponsored programs at the University of Delaware and Boston University.","title":"CPS: Medium: Collaborative Research: Efficient Control Synthesis and Learning in Distributed Cyber-Physical Systems","awardID":"1035577","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[460474,"520550"],"PO":["564778"]},"170947":{"abstract":"Abstract: The Variability Expedition<br\/>Project: Variability-Aware Software for Efficient Computing with Nanoscale Devices<br\/><br\/>As semiconductor manufacturers build ever smaller components, circuits and chips at the nano scale become less reliable and more expensive to produce ? no longer behaving like precisely chiseled machines with tight tolerances. Modern computing is effectively ignorant of the variability in behavior of underlying system components from device to device, their wear-out over time, or the environment in which the computing system is placed. This makes them expensive, fragile and vulnerable to even the smallest changes in the environment or component failures. We envision a computing world where system components -- led by proactive software -- routinely monitor, predict and adapt to the variability of manufactured systems. Changing the way software interacts with hardware offers the best hope for perpetuating the fundamental gains in computing performance at lower cost of the past 40 years. The Variability Expedition fundamentally rethinks the rigid, deterministic hardware-software interface, to propose a new class of computing machines that are not only adaptive but also highly energy efficient. These machines will be able to discover the nature and extent of variation in hardware, develop abstractions to capture these variations, and drive adaptations in the software stack from compilers, runtime to applications. The resulting computer systems will work and continue working while using components that vary in performance or grow less reliable over time and across technology generations. A fluid software-hardware interface will thus mitigate the variability of manufactured systems and make machines robust, reliable and responsive to the changing operating conditions.<br\/><br\/>The Variability Expedition marshals the resources of researchers at the California Institute for Telecommunications and Information Technology (Calit2) at UC San Diego and UC Irvine, as well as UCLA, University of Michigan, Stanford and University of Illinois at Urbana-Champaign. With expertise in process technology, architecture, and design tools on the hardware side, and in operating systems, compilers and languages on the software side, the team also has the system implementation and applications expertise needed to drive and evaluate the research as well as transition the research accomplishments into practice via application drivers in wireless sensing, software radio and mobile platforms. <br\/><br\/>A successful Expedition will dramatically change the computing landscape. By re-architecting software to work in a world where monitoring and adaptation are the norm, it will achieve more robust, efficient and affordable systems that are able to predict and withstand not only hardware failures, but other kinds of software bugs or even attacks. The new paradigm will apply across the entire spectrum of embedded, mobile, desktop and server-class computing machines, yielding particular gains in sensor information processing, multimedia rendering, software radios, search, medical imaging and other important applications. Transforming the relationship between hardware and software presents valuable opportunities to integrate research and education, and this Expedition will build on established collaborations with educator-partners in formal and informal arenas to promote interdisciplinary teaching, training, learning and research. The team has built strong industrial and community outreach ties to ensure success and reach out to high-school students through a combination of tutoring and summer school programs. The Variability Expedition will engage undergraduate and graduate students in software, hardware and systems research, while promoting participation by underrepresented groups at all levels and broadly disseminating results within academia and industry.","title":"Collaborative Research: Variability-Aware Software for Efficient Computing with Nanoscale Devices","awardID":"1029783","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[457653,"551097","529115","560640"],"PO":["562984"]},"171926":{"abstract":"The objective of this research is to define programming abstractions with temporal semantics for distributed cyber-physical systems. The approach is to create a coordination language for distributed embedded software that blends naturally with models of physical dynamics. The coordination language is based on a rigorous discrete-event concurrent model of computation. It will be used by system designers to construct models from which software implementations are derived. The objective is distributed software that, if it compiles for a platform, delivers precisely the temporal semantics specified in the model.<br\/>Intellectual merit: This project addresses the core abstractions of computing, which throughout the 20th century, have abstracted away time, and of physical dynamics, which have omitted software and network behaviors. For cyber-physical systems, both are inappropriate. This project is developing new time-centric abstractions for software, programming models, analysis techniques, and integration of software and network models with physical dynamics.<br\/>Broader impacts: Besides the considerable economic and societal impact of CPS in general, the project is expected to have considerable impact on engineering and computer science education. Its focus on engineering applications and on sound computer science methods will erode the boundaries between these disciplines that hamper competitiveness of our students. A new generation of students is needed to dramatically improve our energy efficiency, manufacturing capabilities, transportation efficiency, instrumentation prowess (and hence, scientific knowledge), and infrastructure robustness. Because of the broad societal implications of the work, it will help attract to engineering and computer science a more diverse talent pool.","title":"CPS: Medium: Timing-Centric Software","awardID":"1035672","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"L509","name":"National Security Agency"}}],"PIcoPI":["497138","71498"],"PO":["564778"]},"171827":{"abstract":"The objective of this research is to improve the ability to track the orbits of space debris and thereby reduce the frequency of collisions. The approach is based on two scientific advances: 1) optimizing the scheduling of data transmission from a future constellation of orbiting Cubesats to ground stations located worldwide, and 2) using satellite data to improve models of the ionosphere and thermosphere, which in turn are used to improve estimates of atmospheric density. <br\/>Intellectual Merit<br\/>Robust capacity-constrained scheduling depends on fundamental research on optimization algorithms for nonlinear problems involving both discrete and continuous variables. This objective depends on advances in optimization theory and computational techniques. Model refinement depends on adaptive control algorithms, and can lead to fundamental advances for automatic control systems. These contributions provide new ideas and techniques that are broadly applicable to diverse areas of science and engineering.<br\/>Broader Impacts<br\/>Improving the ability to predict the trajectories of space debris can render the space environment safer in both the near term---by enhancing astronaut safety and satellite reliability---and the long term---by suppressing cascading collisions that could have a devastating impact on the usage of space. This project will impact real-world practice by developing techniques that are applicable to large-scale modeling and data collection, from weather prediction to Homeland Security. The research results will impact education through graduate and undergraduate research as well as through interdisciplinary modules developed for courses in space science, satellite engineering, optimization, and data-based modeling taught across multiple disciplines.","title":"CPS: Medium: Collaborative Research: Robust Capacity-Constrained Scheduling and Data-Based Model Refinement for Enhanced Collision Avoidance in Low-Earth Orbit","awardID":"1035236","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["507685","529154",460124,"519983"],"PO":["564728"]},"171948":{"abstract":"The objective of this research is to develop methods and tools for a multimodal and multi-sensor assessment and rehabilitation game system called CPLAY for children with Cerebral Palsy (CP). CPLAY collects and processes multiple types of stimulation and performance data while a child is playing. Its core has a touch-screen programmable game that has various metrics to measure delay of response, score, stamina\/duration, accuracy of motor\/hand motion. Optional devices attached to extend CPLAY versions provide additional parallel measurements of level of concentration\/participation\/engagement that quantify rehabilitation activity. The approach is to model the process as a cyber-physical system (CPS) feedback loop whereby data collected from various physical 3D devices (including fNIR brain imaging) are processed into hierarchical events of low-to-high semantic meaning that impact\/ adjust treatment decisions.<br\/><br\/>Intellectual Merit: The project will produce groundbreaking algorithms for event identification with a multi-level data to knowledge feedback loop approach. New machine learning, computer vision, data mining, multimodal data fusion, device integration and event-driven algorithms will lead towards a new type of cyber- physical rehabilitation science for neurological disorders. It will deliver fundamental advancements to engineering by showing how to integrate physical devices with a computationally quantitative platform for motor and cognitive skills assessment.<br\/><br\/>Broader Impacts: The project delivers a modular & expandable game system that has huge implications on the future of US healthcare and rehabilitation of chronic neurological disabilities. It brings hope to children with Cerebral Palsy via lower cost and remote rehabilitation alternatives. It brings new directions to human centered computing for intelligent decision-making that supplements evidence-based practices and addresses social and psychological isolation problems.","title":"CPS: Medium: A Novel Human Centric CPS to Improve Motor\/Cognitive Assessment and Enable Adaptive Rehabilitation","awardID":"1035913","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["559589","463572","560636","557541","229551"],"PO":["564778"]},"170859":{"abstract":"Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and <br\/>Communicative Behavior<br\/>Lead PI\/Institution: James M. Rehg, Georgia Institute of Technology<br\/>This Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. <br\/>Human behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions. This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.<br\/>The long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles.","title":"Collaborative Research: Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and Communicative Behavior","awardID":"1029373","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["515830","485589"],"PO":["565227"]},"172707":{"abstract":"While the Internet has far exceeded expectations, it has also stretched initial assumptions, often creating tussles that challenge its underlying communication model. Users and applications operate in terms of content, making it increasingly limiting and difficult to conform to IP's requirement to communicate by discovering and specifying location. To carry the Internet into the future, a conceptually simple yet transformational architectural shift is required, from today's focus on where ? addresses and hosts ? to what ? the content that users and applications care about.<br\/>This project investigates a potential new Internet architecture called Named Data Networking (NDN). NDN capitalizes on strengths ? and addresses weaknesses ? of the Internet's current host-based, point-to-point communication architecture in order to naturally accommodate emerging patterns of communication. By naming data instead of their location, NDN transforms data into a first-class entity. The current Internet secures the data container. NDN secures the contents, a design choice that decouples trust in data from trust in hosts, enabling several radically scalable communication mechanisms such as automatic caching to optimize bandwidth. The project studies the technical challenges that must be addressed to validate NDN as a future Internet architecture: routing scalability, fast forwarding, trust models, network security, content protection and privacy, and fundamental communication theory. The project uses end-to-end testbed deployments, simulation, and theoretical analysis to evaluate the proposed architecture, and is developing specifications and prototype implementations of NDN protocols and applications.","title":"FIA: Collaborative Research: Named Data Networking (NDN)","awardID":"1040802","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["515757"],"PO":["565090"]},"163819":{"abstract":"This project exploits advances in parallel computing hardware and a neuroscience-informed perspective to design next-generation computer vision algorithms that aim to match a human's ability to recognize objects. The human brain has superlative visual object recognition abilities -- humans can effortlessly identify and categorize tens of thousands of objects with high accuracy in a fraction of a second -- and a stronger connection between neuroscience and computer vision has driven new progress on machine algorithms. However, these models have not yet achieved robust, human-level object recognition in part because the number of possible \"bio-inspired\" model configurations is enormous. Powerful models hidden in this model class have yet to be systematically characterized and the correct biological model is not known.<br\/><br\/>To break through this barrier, this project will leverage newly available computational tools to undertake a systematic exploration of the bio-inspired model class by using a high-throughput approach in which millions of candidate models are generated and screened for desirable object recognition properties (Objective 1). To drive this systematic search, the project will create and employ a suite of benchmark vision tasks and performance \"report cards\" that operationally define what constitutes a good visual image representation for object recognition (Objective 2). The highest performing visual representations harvested from these ongoing high-throughput searches will be used: for applications in other machine vision domains, to generate new experimental predictions, and to determine the underlying computing motifs that enable this high performance (Objective 3). Preliminary results show that this approach already yields algorithms that exceed state-of-the-art performance in object recognition tasks and generalize to other visual tasks.<br\/><br\/>As the scale of available computational power continues to expand, this approach holds great potential to rapidly accelerate progress in computer vision, neuroscience, and cognitive science: it will create a large-scale \"laboratory\" for testing neuroscience ideas within the domain of computer vision; it will generate new, testable computational hypotheses to guide neuroscience experiments; it will produce a new kind of multidimensional image challenge suite that will be a rallying point for computer models, neuronal population studies, and behavioral investigations; and it could unleash a host of new applications.","title":"RI: Medium: Collaborative Research: Unlocking Biologically-Inspired Computer Vision: A High-Throughput Approach","awardID":"0964269","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[438544,438545],"PO":["564318"]},"170816":{"abstract":"Understanding Climate Change: A Data Driven Approach<br\/><br\/>Climate change is the defining environmental challenge now facing our planet. Whether it is an increase in the frequency or intensity of hurricanes, rising sea levels, droughts, floods, or extreme temperatures and severe weather, the social, economic, and environmental consequences are great as the resource-stressed planet nears 7 billion inhabitants later this century. Yet there is considerable uncertainty as to the social and environmental impacts because the predictive potential of numerical models of the earth system is limited. These models are incapable of addressing important questions relating to food security, water resources, biodiversity, mortality, and other socio-economic issues over relevant time and spatial scales.<br\/><br\/>Climate model development has contributed small and incremental improvements; however, extensive modeling gains have not been forthcoming. Modeling limitations have hampered efforts at providing information on climate change impacts and adaptation and mitigation strategies. A new and transformative approach is required to improve prediction of the potential impacts on human welfare. Data driven methods that have been highly successful in other facets of the computational sciences are now being used in the environmental sciences with success. This Expedition project will significantly advance key challenges in climate change science developing exciting and innovative new data driven approaches that take advantage of the wealth of climate and ecosystem data now available from satellite and ground-based sensors, the observational record for atmospheric, oceanic, and terrestrial processes, and physics-based climate model simulations.<br\/><br\/>To realize this ambitious goal, novel methodologies appropriate to climate change science will be developed in four broad areas of data-intensive computer science: relationship mining, complex networks, predictive modeling, and high performance computing. Analysis and discovery approaches will be cognizant of climate and ecosystem data characteristics, such as non-stationarity, nonlinear processes, multi-scale nature, low-frequency variability, long-range spatial dependence, and long-memory temporal processes such as teleconnections. These innovative new approaches will be used to better understand the complex nature of the earth system and the mechanisms contributing to such climate change phenomena as hurricane frequency and intensity in the tropical Atlantic, precipitation regime shifts in the ecologically sensitive African Sahel or the Southern Great Plains, and the propensity for extreme weather events that weaken our infrastructure and result in environmental disasters with economic losses in excess of $100 billion per year in the U.S. alone.<br\/><br\/>Assessments of climate change impacts, which are useful for stakeholders and policymakers, depend critically on regional and decadal scale projections of climate extremes. Thus, climate scientists often need to develop qualitative inferences about inadequately predicted climate extremes based on insights from observations (e.g., increase in hurricane intensity) or conceptual understanding (e.g., relation of wildfires to regional warming or drying and hurricanes to sea surface temperatures). These urgent societal priorities offer fertile grounds for knowledge discovery approaches. In particular, qualitative inferences on climate extremes and impacts may be transformed into quantitative predictive insights based on a combination of hypothesis-guided data analysis and relatively hypothesis-free, yet data-guided discovery processes.<br\/><br\/>A primary focus of this Expedition project will be on uncertainty reduction, which can bring the complementary or supplementary skills of physics-based models together with data-guided insights regarding complex climate processes. The systematic evaluation of climate models and their component processes, as well as uncertainty assessments at regional and decadal scales is a fundamental problem that will be addressed. The ability to translate gains in the predictive skills of climate variables to improvements in impact assessments and attributions is a critical requirement for informing policymakers. Novel methodologies will be developed to gain actionable insights from disparate impacts-related datasets as well as for causal attribution or root-cause analysis. <br\/><br\/>This research will be conducted in close collaboration with the climate science community and will complement insights obtained from physics-based climate models. Improved understanding of salient atmospheric processes will be provided to those contributing to the development and improvement of climate models with the goal of improving predictability. The approaches and formalisms developed in this research are expected to be applicable to a broad range of scientific and engineering problems, which use model simulations to an","title":"Collaborative Research: Understanding Climate Change: A Data Driven Approach","awardID":"1029166","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560392"],"PO":["565223"]},"171916":{"abstract":"The objective of this research is to apply grammatical inference models recently developed in the field of linguistics and phonology, as a basis for abstraction, composition, symbolic control, and learning in distributed multi-agent cyber-physical systems. The approach is to map the system dynamics, specifications, and task interdependences to finite abstract models, and then describe the desired behavior of the system in an appropriate grammar that can be decomposed into local agent specifications. In this framework, the agents can learn the behavior of their environment by observing its dynamics, and update their specifications accordingly. <br\/><br\/>The proposed approach to learning in cyber-physical systems, which is based on grammatical inference at a purely discrete level, is a significant departure from current works. Following this approach, one can reason about large-scale processes resulting from event interdependencies between agents, without having to construct large product systems. To realize this plan, specific technical advances on modeling, abstraction, and control synthesis are proposed.<br\/><br\/>Questions related to formally factoring and composing heterogeneous systems are pervasive in the fields of formal languages and computational learning. There are also applications of commercial significance in the area of discovering new azeotropic mixtures based on documented pairs of compounds that are known to have the particular property. Proposed dissemination and outreach activities include the involvement of middle and high school students and teachers, integrated in existing NSF-sponsored programs at the University of Delaware and Boston University.","title":"CPS: Medium: Collaborative Research: Efficient Control Synthesis and Learning in Distributed Cyber-Physical Systems","awardID":"1035588","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["496541"],"PO":["564778"]},"171817":{"abstract":"The objective of this research is to develop new models of computation for multi-robot systems. Algorithm execution proceeds in a cycle of communication, computation, and motion. Computation is inextricably linked to the physical configuration of the system. Current models cannot describe multi-robot systems at a level of abstraction that is both manageable and accurate. This project will combine ideas from distributed algorithms, computational geometry, and control theory to design new models for multi-robot systems that incorporate physical properties of the systems. The approach is to focus on the high-level problem of exploring an unknown environment while performing designated tasks, and the sub-problem of maintaining network connectivity. Key issues to be studied will include algorithmic techniques for handling ongoing discrete failures, and ways of understanding system capabilities as related to failure rates, geometric assumptions and physical parameters such as robot mobility and communication bandwidth. New metrics will be developed for error rates and robot mobility.<br\/><br\/>Intellectual merit arises from the combination of techniques from distributed algorithms, computational geometry, and control theory to develop and analyze algorithms for multi-robot systems. The project will develop a new class of algorithms and techniques for their rigorous analysis, not only under ideal conditions, but under a variety of error assumptions. The project will test theoretical ideas empirically, on three different multi-robot systems.<br\/><br\/>Broader impacts will include new algorithms for robot coordination, and rigorous understanding of the capabilities of different hardware platforms. Robots are an excellent outreach tool, and provide concrete examples of theory in action.","title":"CPS: Medium: Collaborative Research: Geometric Distributed Algorithms for Multi-Robot Coordination and Control","awardID":"1035199","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["517826"],"PO":["565136"]},"170728":{"abstract":"Understanding Climate Change: A Data Driven Approach<br\/><br\/>Climate change is the defining environmental challenge now facing our planet. Whether it is an increase in the frequency or intensity of hurricanes, rising sea levels, droughts, floods, or extreme temperatures and severe weather, the social, economic, and environmental consequences are great as the resource-stressed planet nears 7 billion inhabitants later this century. Yet there is considerable uncertainty as to the social and environmental impacts because the predictive potential of numerical models of the earth system is limited. These models are incapable of addressing important questions relating to food security, water resources, biodiversity, mortality, and other socio-economic issues over relevant time and spatial scales.<br\/><br\/>Climate model development has contributed small and incremental improvements; however, extensive modeling gains have not been forthcoming. Modeling limitations have hampered efforts at providing information on climate change impacts and adaptation and mitigation strategies. A new and transformative approach is required to improve prediction of the potential impacts on human welfare. Data driven methods that have been highly successful in other facets of the computational sciences are now being used in the environmental sciences with success. This Expedition project will significantly advance key challenges in climate change science developing exciting and innovative new data driven approaches that take advantage of the wealth of climate and ecosystem data now available from satellite and ground-based sensors, the observational record for atmospheric, oceanic, and terrestrial processes, and physics-based climate model simulations.<br\/><br\/>To realize this ambitious goal, novel methodologies appropriate to climate change science will be developed in four broad areas of data-intensive computer science: relationship mining, complex networks, predictive modeling, and high performance computing. Analysis and discovery approaches will be cognizant of climate and ecosystem data characteristics, such as non-stationarity, nonlinear processes, multi-scale nature, low-frequency variability, long-range spatial dependence, and long-memory temporal processes such as teleconnections. These innovative new approaches will be used to better understand the complex nature of the earth system and the mechanisms contributing to such climate change phenomena as hurricane frequency and intensity in the tropical Atlantic, precipitation regime shifts in the ecologically sensitive African Sahel or the Southern Great Plains, and the propensity for extreme weather events that weaken our infrastructure and result in environmental disasters with economic losses in excess of $100 billion per year in the U.S. alone.<br\/><br\/>Assessments of climate change impacts, which are useful for stakeholders and policymakers, depend critically on regional and decadal scale projections of climate extremes. Thus, climate scientists often need to develop qualitative inferences about inadequately predicted climate extremes based on insights from observations (e.g., increase in hurricane intensity) or conceptual understanding (e.g., relation of wildfires to regional warming or drying and hurricanes to sea surface temperatures). These urgent societal priorities offer fertile grounds for knowledge discovery approaches. In particular, qualitative inferences on climate extremes and impacts may be transformed into quantitative predictive insights based on a combination of hypothesis-guided data analysis and relatively hypothesis-free, yet data-guided discovery processes.<br\/><br\/>A primary focus of this Expedition project will be on uncertainty reduction, which can bring the complementary or supplementary skills of physics-based models together with data-guided insights regarding complex climate processes. The systematic evaluation of climate models and their component processes, as well as uncertainty assessments at regional and decadal scales is a fundamental problem that will be addressed. The ability to translate gains in the predictive skills of climate variables to improvements in impact assessments and attributions is a critical requirement for informing policymakers. Novel methodologies will be developed to gain actionable insights from disparate impacts-related datasets as well as for causal attribution or root-cause analysis. <br\/><br\/>This research will be conducted in close collaboration with the climate science community and will complement insights obtained from physics-based climate models. Improved understanding of salient atmospheric processes will be provided to those contributing to the development and improvement of climate models with the goal of improving predictability. The approaches and formalisms developed in this research are expected to be applicable to a broad range of scientific and engineering problems, which use model simulations to an","title":"Collaborative Research: Understanding Climate Change: A Data Driven Approach","awardID":"1028746","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["464510","527891"],"PO":["565223"]},"172829":{"abstract":"This grant funds participant costs for the 2010 Software Engineering Educators' Symposium (SEES), where participants will learn about latest pedagogy in Software Engineering education and teaching techniques that appeal to diverse learners. Participants will be also attend the 2010 SIGSOFT Conference on Foundations of Software Engineering (FSE-18), where they will network with researchers in Software Engineering. Leaders in the field have volunteered their time to organize and run the event. The goal of this proposal is to help reverse the decline in the percentages of minority and women students choosing to study computer science at American colleges and universities. To achieve this goal, the grant will emphasize participation from colleges and universities with large minority and\/or female student enrollments.","title":"Group Travel Grant for Faculty at Minority Institutions","awardID":"1041490","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["531512","531513"],"PO":["564388"]},"173819":{"abstract":"\"Bridging STEM to STE(A)M: Developing New Frameworks for ART\/SCIENCE Pedagogy\", hosted by the Rhode Island School of Design (RISD) will be a two-day workshop aimed to develop an innovative educational agenda that forges relationships between art and design disciplines and science, technology, engineering, and mathematics (STEM). The workshop will bring together leading scientists, IT experts and creative technologists, artists, designers, and education researchers to initiate discussions about how to bridge STEM education practices and creative problem-solving. As this innovative educational approach holds the potential to open new areas of exploration, and provide a platform and network for the further development of STEM to STE(A)M pedagogy. The long-term goals of this initiative are to: (1) Develop strategies for enhancing STEM education through the integration of art and design thinking (STEM + ART = STE(A)M); (2) Invent and share techniques that take advantage of simple, freely available IT systems and applications to support enhanced observation, analysis and understanding of pictorial and numerical data; (3) Build new connections between art and design disciplines and scientific fields to advance understanding of complex systems, e.g., through improved strategies and techniques for the shared perception and visualization of scientific data. <br\/><br\/>Methods and practices that promote shared ideas, insight, and language have the potential to alter STEM education and research practices in formal and informal settings. The diverse mix of disciplines and approaches represented at the workshop will give participants access to shared processes of inquiry into art\/science pedagogy with the goal of achieving a high level of comprehensibility and knowledge sharing, broadening the accessibility and appeal of science, and transforming the discourse on STEM discovery and learning. As art thinking influences scientific thinking and vice versa, there is great potential for increased public understanding of science and scientific challenges. Workshop discussions will inform the creation of educational materials that exemplify interdisciplinary couplings between the arts and sciences. To begin to explore this potential, the Rhode Island School of Design (RISD) will develop prototype STE(A)M classes for high school students through a Pre-College summer program offered through RISD's Continuing Education division. In addition, in connection with the workshop, a new graduate-level course will be developed at RISD to prepare future artists and arts educators to lead successful arts\/design\/science collaborations. The broader intention of these prototype courses is to provide tangible examples that can prompt parallel developments at other institutions.","title":"Workshop: Bridging STEM to STEAM: Developing New Frameworks for ART\/SCIENCE Pedagogy","awardID":"1046705","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[466322,466323],"PO":["565227"]},"171906":{"abstract":"The objective of this research is the creation of a coastal observing system that enables dense, in situ, 4D sensing through networked, sensor-equipped underwater drifters. The approach is to develop the technologies required to deploy a swarm of autonomous buoyancy controlled drifters, which are vehicles that can control their depth, but are otherwise carried entirely by the ocean currents. Such Lagrangian sampling promises to deliver a wealth of new data, ranging from applications in physical oceanography (mapping 3D currents), biology (observing the dispersion of larvae and nutrients), environmental science (tracking coastal pollutants and effluents from storm drains), and security (monitoring harbors and ports).<br\/><br\/>This observing system fundamentally requires accurate positions of the drifters (to interpret the spatial correlations of data samples), swarm control algorithms (to achieve desired sampling topologies), and wireless communication (to coordinate between the individual drifters). This research will create distributed techniques to self-localize the drifter swarm, novel swarm control algorithms that enable topology manipulation while purely leveraging the stratified flow environment, and efficient wireless underwater communication for information sharing.<br\/><br\/>This project has significant societal impact and educational elements. Underwater drifter swarms will enable novel insights into a wide array of scientific questions, including understanding plankton transport, accumulation and dispersion as well as monitoring harmful algal blooms. Undergraduates will play an active role in many aspects of this project, thereby offering them a uniquely interdisciplinary experience. Finally, outreach to high school students will occur through the UCSD COSMOS summer program.","title":"CPS: Medium: Collaborative Research: Networked Sensor Swarm of Underwater Drifters","awardID":"1035518","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["560816",460450],"PO":["561889"]},"171917":{"abstract":"The objective of this research is to develop a cyber-physical system capable of displaying the in vivo surgical area directly onto patients' skin in real-time high definition. This system will give surgeons an ?x-ray? vision experience, since they see directly through the skin, and remove a spatial bottleneck and additional scarring caused by laparoscopes in minimally invasive surgery. The approach is to develop micro-cameras that: occupy no space required by surgical tools, produce no additional scarring to the patient, and transfer wireless high-definition video images. A virtual view generating system will project the panoramic videos from all cameras to the right spot on the patient?s body with geometry and color distortion compensation. A surgeon-camera-interaction system will be investigated to allow surgeons to control viewpoint with gesture recognition and finger tracking. Novel techniques will be developed for zero-latency high-definition wireless video transfer through the in vivo\/ex vivo medium. Image viewpoint alignment and distortion compensation in real time will also be investigated. The results will be a potential paradigm shift in minimally invasive surgery. <br\/><br\/>The proposed work benefits the millions of surgeries capable of being performed through a single incision in the abdomen by providing virtually transparent skin to surgeons who will enjoy all the visual benefits of open-cavity surgery without all the associated risks to the patient. The goals of this research are extremely ?hands-on? and immediately applicable to outreach activities that can excite youth, minority students, and others about the science, medicine a and engineering careers.","title":"CPS: Small: Virtually Transparent Epidermal Imagery","awardID":"1035594","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["563303","449067",460481],"PO":["565136"]},"171807":{"abstract":"The objective of this research is to enable cyberphysical systems (CPS) to be context-aware of people in the environment and to use data from real-world probabilistic sensors. The approach is (1) to use radio tomography (RT) and RFID to provide awareness (location and potential identification) of every person in a building or area, and (2) to develop new middleware tools to enable context-aware computing systems to use probabilistic data, thus allowing new applications to exploit sometimes unreliable estimates of the environment.The intellectual merit of the proposal is in the development of new algorithms and models for building-scale RT with low radio densities and across multiple frequencies; the development of efficient multichannel access protocols for rapid and adaptive peer-to-peer measurements; the development of space-time and probabilistic data representations for use in stream-based context awareness systems and for merging ID and non-ID data; (4) and the development of a human context-aware software development toolkit that interfaces between probabilistic data and context-aware applications. <br\/><br\/>The proposal impacts broadly the area of Cyberphysical systems that reason about human presence and rely on noisy and potentially ambiguous (practical) sensors. The research has additional dramatic impact in: (1) smart facilities which automatically enforce safety, privacy, and security procedures, increasing the ability to respond in emergency situations and prevent accidents and sabotage; (2) elder care, to monitor for physical or social decline so that effective intervention can be implemented, extending the period elders can live in their own home, without pervasive video surveillance.","title":"CPS: Medium: Collaborative Research: Enabling and Advancing Human and Probabilistic Context Awareness for Smart Facilities and Elder Care","awardID":"1035152","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["532662"],"PO":["565136"]},"171939":{"abstract":"The objective of this research is the creation of a coastal observing system that enables dense, in situ, 4D sensing through networked, sensor-equipped underwater drifters. The approach is to develop the technologies required to deploy a swarm of autonomous buoyancy controlled drifters, which are vehicles that can control their depth, but are otherwise carried entirely by the ocean currents. Such Lagrangian sampling promises to deliver a wealth of new data, ranging from applications in physical oceanography (mapping 3D currents), biology (observing the dispersion of larvae and nutrients), environmental science (tracking coastal pollutants and effluents from storm drains), and security (monitoring harbors and ports).<br\/><br\/>This observing system fundamentally requires accurate positions of the drifters (to interpret the spatial correlations of data samples), swarm control algorithms (to achieve desired sampling topologies), and wireless communication (to coordinate between the individual drifters). This research will create distributed techniques to self-localize the drifter swarm, novel swarm control algorithms that enable topology manipulation while purely leveraging the stratified flow environment, and efficient wireless underwater communication for information sharing.<br\/><br\/>This project has significant societal impact and educational elements. Underwater drifter swarms will enable novel insights into a wide array of scientific questions, including understanding plankton transport, accumulation and dispersion as well as monitoring harmful algal blooms. Undergraduates will play an active role in many aspects of this project, thereby offering them a uniquely interdisciplinary experience. Finally, outreach to high school students will occur through the UCSD COSMOS summer program.","title":"CPS: Medium: Collaborative Research: Networked Sensor Swarm of Underwater Drifters","awardID":"1035828","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7607","name":"ENERGY,POWER,ADAPTIVE SYS"}}],"PIcoPI":[460558,"560817","560818"],"PO":["564728"]},"172709":{"abstract":"While the Internet has far exceeded expectations, it has also stretched initial assumptions, often creating tussles that challenge its underlying communication model. Users and applications operate in terms of content, making it increasingly limiting and difficult to conform to IP's requirement to communicate by discovering and specifying location. To carry the Internet into the future, a conceptually simple yet transformational architectural shift is required, from today's focus on where ? addresses and hosts ? to what ? the content that users and applications care about.<br\/>This project investigates a potential new Internet architecture called Named Data Networking (NDN). NDN capitalizes on strengths ? and addresses weaknesses ? of the Internet's current host-based, point-to-point communication architecture in order to naturally accommodate emerging patterns of communication. By naming data instead of their location, NDN transforms data into a first-class entity. The current Internet secures the data container. NDN secures the contents, a design choice that decouples trust in data from trust in hosts, enabling several radically scalable communication mechanisms such as automatic caching to optimize bandwidth. The project studies the technical challenges that must be addressed to validate NDN as a future Internet architecture: routing scalability, fast forwarding, trust models, network security, content protection and privacy, and fundamental communication theory. The project uses end-to-end testbed deployments, simulation, and theoretical analysis to evaluate the proposed architecture, and is developing specifications and prototype implementations of NDN protocols and applications.","title":"FIA: Collaborative Research: Named Data Networking (NDN)","awardID":"1040822","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[463134,463135,463136,463137,463138,463139],"PO":["565090"]},"171918":{"abstract":"Complex surgical procedures in hospitals are increasingly aided by robotic surgery systems, often at the request of patients. These systems allow greatly increased precision, reach and flexibility to the surgeon. However, their powerful capabilities entail substantial system complexity in both hardware and software. The high probability of serious injuries should a malfunction occur calls for rigorous assessment and monitoring of the reliability and safety of these cyber-physical systems.<br\/><br\/>In this research project, a framework for assessing and monitoring the reliability and safety of robotic surgery systems during development, field testing, and general deployment is being developed. The proposed framework complements existing techniques used in earlier phases of validation by taking into account how surgeons actually use a robotic surgery system, how it is affected by operating conditions, and how its observable behavior is related to its hardware and software dynamics.<br\/><br\/>Before deployment, this framework uses accurate simulations to assess pre-clinical reliability. After deployment, the framework uses data collection through online monitoring of the system as it is being used in the field, followed by analysis to obtain assessments of operational reliability and safety. The collected data is also used to improve the simulations for future testing. The framework also aims to support post-market surveillance of these systems by providing a workable basis for reassessing reliability and safety properties after system maintenance.<br\/><br\/>The developed tools and methods will also have applications in the validation of safety and reliability of other medical devices with embedded software and other cyber-physical systems in general.","title":"CPS: Small: A Framework for Validation and Monitoring of Robotic Surgery Systems","awardID":"1035602","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[460483,460484,460485],"PO":["565239"]},"171929":{"abstract":"The objective of this research is to develop new models of computation for multi-robot systems. Algorithm execution proceeds in a cycle of communication, computation, and motion. Computation is inextricably linked to the physical configuration of the system. Current models cannot describe multi-robot systems at a level of abstraction that is both manageable and accurate. This project will combine ideas from distributed algorithms, computational geometry, and control theory to design new models for multi-robot systems that incorporate physical properties of the systems. The approach is to focus on the high-level problem of exploring an unknown environment while performing designated tasks, and the sub-problem of maintaining network connectivity. Key issues to be studied will include algorithmic techniques for handling ongoing discrete failures, and ways of understanding system capabilities as related to failure rates, geometric assumptions and physical parameters such as robot mobility and communication bandwidth. New metrics will be developed for error rates and robot mobility.<br\/><br\/>Intellectual merit arises from the combination of techniques from distributed algorithms, computational geometry, and control theory to develop and analyze algorithms for multi-robot systems. The project will develop a new class of algorithms and techniques for their rigorous analysis, not only under ideal conditions, but under a variety of error assumptions. The project will test theoretical ideas empirically, on three different multi-robot systems.<br\/><br\/>Broader impacts will include new algorithms for robot coordination, and rigorous understanding of the capabilities of different hardware platforms. Robots are an excellent outreach tool, and provide concrete examples of theory in action.","title":"CPS: Medium: Collaborative Research: Geometric Distributed Algorithms for Multi-Robot Coordination and Control","awardID":"1035716","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["553693"],"PO":["565136"]},"171919":{"abstract":"The objective of this research is to develop a prototype programmable microfluidic laboratory-on-chip that concurrently executes assays (chemical algorithms) in an on-line fashion. A chemist specifies an assay (chemical algorithm) using a text-based language. Assays arrive at the device in real-time and an operating system\/virtual machine running on an attached microcontroller interprets them. The approach is to develop a software simulation infrastructure for the laboratory-on-chip and to build the operating system\/virtual machine on top of it. <br\/><br\/>The intellectual merit of this activity is due to the fact that no type of runtime support system has yet been proposed for microfluidic devices. The key challenges to be solved in this project include: deadlock-free deterministic and adaptive routing algorithms; real-time constraints for routing droplets in the system; routing wash droplets for decontamination; scheduling assay operations on the devices; congestion estimation; and fault diagnosis and recovery. <br\/><br\/><br\/>In terms of broader impact, advances in laboratory-on-chip technology will improve public health worldwide and lead to significant advances in clinical diagnostics and medicine. Laboratory-on-chips are commercially available from established companies such as Agilent Technologies as well as startup companies such as Advanced Liquid Logic, Silicon Biosystems, and Ayanda Biosystems; thus, the economic impact of this research is tremendous. The University of California, Riverside is a Minority-Serving Institution. The PI is committed to the introduction of laboratory-on-chip technology in both undergraduate and graduate education and will make every possible effort to recruit underrepresented minorities (including women) at the graduate and undergraduate level to work on the project.","title":"CPS: Small: System support for generally programmable digital microfluidic biochip devices","awardID":"1035603","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["562983"],"PO":["562984"]},"171909":{"abstract":"The objective of the research is to develop tools for comprehensive design and optimization of air traffic flow management capabilities at multiple spatial and temporal resolutions: a national airspace-wide scale and one-day time horizon (strategic time-frame); and at a regional scale (of one or a few Centers) and a two-hour time horizon (tactical time-frame). The approach is to develop a suite of tools for designing complex multi-scale dynamical networks, and in turn to use these tools to comprehensively address the strategic-to-tactical traffic flow management problem. <br\/><br\/>The two directions in tool development include 1) the meshed modeling\/design of flow- and queueing-networks under network topology variation for cyber- and physical- resource allocation, and 2) large-scale network simulation and numerical analysis. This research will yield aggregate modeling, management design, and validation tools for multi-scale dynamical infrastructure networks, and comprehensive solutions for national-wide strategic-to-tactical traffic flow management using these tools. <br\/><br\/>The broader impact of the research lies in the significant improvement in cost and equity that may be achieved by the National Airspace System customers, and in the introduction of systematic tools for infrastructure-network design that will have impact not only in transportation but in fields such as electric power network control and health-infrastructure design. The development of an Infrastructure Network Ideas Cluster will enhance inter-disciplinary collaboration on the project topics and discussion of their potential societal impact. Activities of the cluster include cross-university undergraduate research training, seminars on technological and societal-impact aspects of the project, and new course development.","title":"CPS: Small: Collaborative Research: Dynamical-Network Evaluation and Design Tools for Strategic-to-Tactical Air Traffic Flow Management","awardID":"1035532","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[460458],"PO":["565274"]},"170909":{"abstract":"Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and <br\/>Communicative Behavior<br\/>Lead PI\/Institution: James M. Rehg, Georgia Institute of Technology<br\/>This Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. <br\/>Human behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions. This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.<br\/>The long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles.","title":"Collaborative Research: Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and Communicative Behavior","awardID":"1029585","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["457548",457546,457547,457548],"PO":["565227"]},"168590":{"abstract":"While the mathematical study of cryptography has yielded a rich theory, and while the use of cryptography has become quite widespread, there is unfortunately still a significant gap between the theory and practice of cryptography. The goal of this project is to bridge this gap. The emphasis will be on the design and analysis of fundamental cryptographic primitives, such as hash functions and block ciphers, as well as other primitives derived from them, that are practical and yet theoretically sound. Indeed, hash functions and block ciphers are used in almost any cryptographic application. Yet, many such practical applications often do not have sufficient theoretical foundations behind them. Therefore, there is renewed interest and urgency to study the basic design principles of hash functions, as well as how such hash functions should be appropriately used in applications.<br\/><br\/>This project will revisit the basic design principle for constructing secure hash functions, block ciphers, and various important cryptographic primitives which are built from them. In particular, this project will investigate new types of constructions that are based on firmer theoretical foundations, and yet are still efficient enough for practical use. The PI will devote special attention to analyzing and improving the use of hash functions and block ciphers as message digests, key derivation functions, message authentication codes, commitment schemes and random oracles. Additionally, this project will study novel modes of operation to build complex variable-length primitives from simpler, fixed length components, such as block ciphers and fixed-length compression functions. Finally, the project will build firmer foundations for analyzing cryptographic schemes in the idealized security models, such as the random oracle and the ideal cipher models.<br\/><br\/>As a result, this project will potentially yield more secure hash functions and block ciphers, and more secure and\/or efficient usage of hash functions and block ciphers in important cryptographic applications. The project will have impact both on technology, as well as on education and collaboration. For example, besides advancing the theory of cryptography, this project will also impact the real-world design of secure systems. Where appropriate, the PI will strive to turn the new primitives and protocols into standards, so that they can be used in practice. Additionally, the PI regularly teaches courses in cryptography and network security, and will be able incorporate the new results into the courses he teaches. Finally, the project has a significant graduate student and postdoc training component.","title":"TC: Small: The Design of Secure Hash Functions and Block Ciphers","awardID":"1017471","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550227"],"PO":["565239"]},"168480":{"abstract":"One dominant characteristic of today's large-scale computing systems<br\/>is the prevalence of large storage clusters. Storage clusters at the<br\/>scale of hundreds or thousands of commodity machines are<br\/>increasingly being deployed. At companies like Amazon, Google, Yahoo,<br\/>and others, thousands of nodes are managed as a single system.<br\/><br\/>As large clusters have brought many benefits, they also bring a new<br\/>challenge: a growing number and frequency of failures that must be<br\/>managed. Bits, sectors, disks, machines, racks, and many other<br\/>components fail. With millions of servers and hundreds of data<br\/>centers, there are millions of opportunities for these components to<br\/>fail. Failing to deal with failures will directly impact the<br\/>reliability and availability of data and jobs.<br\/><br\/>Unfortunately, we still hear data-loss stories even recently. For<br\/>example, in March 2009, Facebook lost millions of photos due to<br\/>simultaneous disk failures that \"should\" rarely happen at the same<br\/>time (but it happened); in July 2009, a large bank was fined a record<br\/>total of 3 millions pounds after losing data on thousands of its<br\/>customers; more recently, in October 2009, T-Mobile Sidekick, which<br\/>uses Microsoft's cloud service, also lost its customer data. These<br\/>incidents have shown that existing large-scale storage systems are<br\/>still fragile to failures.<br\/><br\/>To address the challenges of large-scale recovery, the goal of this<br\/>project is to: (1) seek the fundamental problems of recovery in<br\/>today's scalable world of computing, (2) improve the reliability,<br\/>performance, and scalability of existing large-scale recovery, and (3)<br\/>explore formally grounded languages to empower rigorous specification<br\/>of recovery properties and behaviors. Our vision is to build systems<br\/>that \"DARE to fail\": systems that deliberately fail themselves,<br\/>exercise recovery routinely, and enable easy and correct deployment of<br\/>new recovery policies.<br\/><br\/>For more information, please visit this website:<br\/>http:\/\/boom.cs.berkeley.edu\/dare\/","title":"DC: Small: Collaborative Research: DARE: Declarative and Scalable Recovery","awardID":"1016924","effectiveDate":"2010-09-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":[451018,"562887"],"PO":["366560"]},"168491":{"abstract":"Abstract<br\/><br\/>Multicast applications, such as content sharing and multimedia broadcasting, is the single most important class of applications over the internet. Multicast applications assume overlay network models, which consist of relevant nodes connected by abstracted virtual logical links. While scalable multicasting in such a network requires error-correction coding, classical coding approaches are highly inefficient due to the fact that virtual links do not enjoy known statistical channel models. To overcome this challenge, this project will develop a systematic coding theory based on a new fountain communication model for efficient multicasting in overlay networks. In fountain communication, the source node encodes a message into an infinite number of packets, a destination decodes the message after the number of received packets exceeds certain threshold. <br\/><br\/>The investigator will first develop a fountain coding framework for end-to-end multicast transmission over virtual network links. For delay nonsensitive traffic, fountain codes will be developed to achieve ideal rate-error performance with a linear coding complexity. For delay sensitive traffic, fountain coding will be integrated with flow control algorithms to ensure timely information delivery over channels with arbitrary distortions and erasures. The objectives are characterizing fundamental performance limitations and developing practical coding schemes. The project will then investigate multiuser cooperative communication for multicast applications in node-capacitated overlay networks, where the sum upload rate of each node is kept below a predetermined bound. For delay sensitive communication, the objective is to overcome the challenge that network nodes may randomly access or disconnect from the network. For delay nonsensitive communication, the objective is to overcome the \"selfish-peer-node\" challenge where a peer node disconnects from the network whenever its desired messages become fully decodable.","title":"CIF: Small: Fountain Coding Theory for Content Sharing and Multimedia Broadcasting in Overlay Networks","awardID":"1016985","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["485630"],"PO":["564924"]},"168392":{"abstract":"This project aims to investigate two kinds of problems in theoretical computer science and information theory. The first is about Hardness Amplification. Here the goal is to find ways to manipulate functions that are hard to compute in some computational model to obtain new functions that are significantly harder to compute. For example, in communication complexity, one might expect that computing k copies of a functionality should take k times the communication, but to date we do not know how to prove this. Prior work has shown that the communication must grow by a factor of roughly the square root of k, but it remains to be seen whether this can be increased to a factor of k. Another domain where this kind of problem makes sense is for streaming algorithms. In a streaming algorithm, the input arrives as a massive data stream that cannot be stored. The goal is to compute a function of the data using as little memory as possible. One might expect that handling k independent streams of data in parallel should require k times the memory, yet we do not know how to prove this. Similar questions can be asked about amplifying the hardness of approximation algorithms, and showing that composing a function with itself increases its circuit depth. This kind of question is related to proving lowerbounds, a central goal of theoretical computer science.<br\/><br\/>The second kind of problem is about compression. Today we have a good understanding of how single messages can be compressed so that the number of bits it takes to represent them is more or less equal to the information that they carry. Here the information can be measured using Shannon's Entropy function, or in the case of randomized transmissions, the mutual information between the inputs and the messages. However, if we have an interactive communication process between several parties, it is not clear how to reduce the communication in the interaction so that the communication is close to the amount of information conveyed between the parties. This problem is closely related to the problem of amplifying the communication complexity of a function, discussed above. Prior work has shown how to reduce the communication of a protocol that conveys small information, and such a compression scheme turns out to be useful to prove that computing many copies of a function must require larger communication. Indeed, an optimal compression scheme would give an optimal result in the setting of hardness amplification. Finding such a scheme is a major goal of this project. This project also aims to study the compression of memory used by streaming algorithms. Given a streaming algorithm, can we always reduce the memory usage of the algorithm until the number of bits used is close to the amount of information stored by the algorithm. In this setting, it is not clear what the right measure of information should be, and defining a meaningful measure of the information is another goal.<br\/><br\/>The common theme tying the problems of this proposal together is an information theory based method that is applicable to these problems.","title":"AF: Small: Information Theory-Based Methods for Hardness Amplification and Compression","awardID":"1016565","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["502165"],"PO":["565157"]},"167480":{"abstract":"This project will create a new category of intelligent, autonomous virtual or robotic agent, which is continuously operating and interacting with humans - always on - for long periods of time and whose primary motivation is building and maintaining long-term social relationships with humans. The initial application focus of this research is to provide companionship and social support and to promote wellness for older adults who are living alone. For example, during a typical day, an always-on relational agent might play a social game of cards with the adult, act as an exercise coach and help arrange visits or phone calls with the adult's family and friends.<br\/><br\/>A new integrated theory of social agency, called SharedPlans Relationship Theory, will be developed to serve as a principled foundation for these relational agents. The theory will be grounded in an always-on relational software architecture, which will be distributed as open-source for others to use and extend. Using a participatory design process, including home and laboratory studies, the target user population will help develop the specifications for a relational agent, which will then be constructed using the theory and software architecture, and placed in users' homes for long-term (month or more) longitudinal evaluation.<br\/><br\/>This project will make fundamental, theoretical contributions to models of relationship, sociality, interactional engagement and social support. The effort will also produce new insights into how people in general, and older adults in particular, enact social support at the relational, activity and micro-behavioral levels of analysis. The new always-on relational software architecture will be a fundamental advance over current agent architectures, which only support brief, focused interactions around a well-specified task. This architecture will also support incremental extension of agent capabilities and be able to control either virtual and robotic agent embodiments.<br\/><br\/>Social isolation is a broadly troubling trend in modern society. Always-on relational agents have the potential to counteract this isolation both directly, by providing companionship, and as intermediaries, by putting isolated people in contact with other people, both electronically and physically. Companionship and social support are also known to be significant positive factors in disease recovery and mortality, especially for older adults. The application focus of this project therefore has the potential for helping with health care cost control.","title":"HCC: Large: Collaborative Research: Always-On Relational Agents for Social Support of Older Adults","awardID":"1012083","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[448731,448732],"PO":["564456"]},"168580":{"abstract":"Given a graph, such as a social\/computer network, or the blogo-<br\/>sphere, how will a virus (or rumor or new product) propagate in<br\/>it? Will it take over, creating a pandemic? How to select the<br\/>'k' best nodes\/edges for immunization, or, conversely, the best<br\/>'k' blogs for the fastest dissemination of a new idea? The an-<br\/>swer to such questions is vital, for public health, for network<br\/>security, for market penetration, for blog monitoring and many<br\/>more applications.<br\/><br\/>In the PI's past work, they studied arbitrary graphs, and showed<br\/>that propagation depends on a single number, namely, the first<br\/>eigenvalue of the adjacency matrix of the network. Specifically,<br\/>they studied the so-called 'epidemic threshold' for flu-like<br\/>propagation (``SIS'' model = susceptible-infectious-susceptible),<br\/>on un-directed, un-weighted static graphs. All earlier work fo-<br\/>cused on full cliques, or homogeneous graphs, or specific cases<br\/>of power-law graphs - *all* of which are special cases of the<br\/>PI's eigenvalue result.<br\/><br\/>The major thrusts of the current proposal are two. The first is<br\/>*theory*: For a mumps-like model (``SIR'' = susceptible - infect-<br\/>ed - recovered), and for additional models, when will a virus re-<br\/>sult in a pandemic? What can we say about weighted graphs? About<br\/>time-evolving graphs, like an ad-hoc network of mobile phone<br\/>users? The second thrust is on *algorithms*: Given a graph, a<br\/>virus model (SIS, SIR, etc), and a fixed budget of 'k'<br\/>nodes\/edges to immunize, how can we quickly find an optimal or<br\/>near-optimal solution, to best contain the virus? How can we<br\/>modify the algorithm, when the network changes over time?<br\/><br\/><br\/>The TECHNICAL MERIT of the work is that it is the first to focus<br\/>on *arbitrary* graphs, thus including real ones. In contrast,<br\/>the vast majority of past analytical work makes unrealistic as-<br\/>sumptions about the graph topology (cliques, homogeneous graphs<br\/>etc.).<br\/><br\/>The BROADER IMPACT is high, as dynamics of large-scale graphs ap-<br\/>pear in numerous settings: cascades on blogs; product penetration<br\/>and viral marketing; rumor\/information propagation; immunization<br\/>policies; advertisement policies etc.<br\/><br\/>For further information see the project web page: URL:<br\/>http:\/\/www.cs.cmu.edu\/~christos\/NSF-PROJECTS\/Immunization\/","title":"III: Small: Influence and Virus Propagation in Large Graphs - Theory and Algorithms","awardID":"1017415","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["548220",451252],"PO":["565136"]},"168360":{"abstract":"This project focuses on developing the theoretical foundation of differential ray geometry. The PI first derives a comprehensive ray geometry framework including the ray-distortion, ray-caustics, and ray-curvature theories as well as ray differential operators. This new framework is widely applicable to real-world problems. On the computer vision front, the PI explores robust and efficient schemes to infer ray structures from distortions or from caustics patterns and then recover surface geometry from ray differential attributes. This leads to a new class of specular (reflective and refractive) surface reconstruction algorithms. On the computer graphics front, the PI employs a novel normal-ray representation that converts a smooth 3D surface into a 2D ray manifold so that surface differential attributes can be directly derived from normal-ray geometry. The PI further develops new subdivision, re-meshing, and mesh simplification schemes for generating surfaces consistent with the underlying normal ray structures. <br\/><br\/>This research benefits many computer vision and graphics applications by providing a differential ray geometry model for cameras, light sources, and surfaces. It also benefits shape designs in aircraft, automobile, and many other industries, where higher-order shape consistencies are required. This project contributes to education through the development of new differential geometry courses and seminars and by involving women and under-represented students in mathematical and computer science research. The PI further seeks to build strong connections with the fields of mathematics and physics, optical engineering, and mechanical engineering through the project.","title":"RI: Small:Differential Ray Geometry for Surface Reconstruction and Modeling","awardID":"1016395","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["550477"],"PO":["564316"]},"169185":{"abstract":"The increasing ubiquity of network communication and the changes in the World Wide Web due to the social networking tools of Web 2.0 are revolutionizing the way that scholars collaborate and share information. However, the receptivity to and use of these new tools differs radically among the various scientific disciplines. This project will initiate planning for an international symposium to advance a very unique and promising set of research discussions on these issues begun in a workshop titled \"New Models for Scholarly Communication in Chemistry\", held in Washington DC in October 2008 (http:\/\/hdl.handle.net\/1813\/14150). The international symposium envisioned will address complex issues associated with academic scholarly communication practices and emergent technologies and the ways in which web-based intellectual content is created, managed and used to advance research productivity. A goal will be to determine the interdependence of these processes and points of beneficial intervention. To begin the planning process for the symposium, this award will support the formation of a small international steering committee to develop the agenda for the larger symposium and identify necessary participants and potential sources of financial support. Community input will be actively solicited in all stages of the planning process.","title":"Advancing the State of EChemistry: Planning an International Symposium","awardID":"1020513","effectiveDate":"2010-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["541699"],"PO":["564456"]},"173080":{"abstract":"Increasingly, technology mediated interactions play a significant role in science and engineering research. This proposal will manage a workshop to identify and address issues surrounding the impact of advances in information and communications technologies and the resulting human disengagement with the natural world on research and education in the information sciences. <br\/><br\/>The proposed workshop will take a very broad view and bring together creative and visionary thinkers from five disparate constituencies. The organizers will invite leaders from information schools, key thinkers in CI, thought leaders from the IT worlds, representatives from cognate fields, and CI researchers from minority-serving institutions. The workshop will result in papers outlining the intellectual frontiers of iSchool research and synergies produced in the workshop, which will be presented at major conferences and published in appropriate journals.","title":"Workshop: Emerging Configurations of the Virtual and the Real-Chicago, Fall 2010","awardID":"1042697","effectiveDate":"2010-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["532090","464231",464231],"PO":["565342"]},"174070":{"abstract":"The PI together with her students are exploring the possibility of establishing a research group in Language and Speech Processing at Montclair State University as a venue for faculty and students to bring together their cross-disciplinary strengths, share ideas, collaborate on research topics, and discuss the current state of the arts. Students are acquiring valuable research experiences rooted in on-going multi-disciplinary projects designed and managed by experienced faculty in the fields of Linguistics, Computer Science, Psychology, Communication Sciences and Disorders, Political Science, Anthropology, Mathematics, Biology, and Management and Information Systems.<br\/><br\/>The research objectives are to 1) study language comprehension, production, acquisition, and representation through a combination of computational modeling and experimental multidisciplinary studies, 2) create and evaluate technology to automatically analyze a wide range of speech, text, and document image data in multiple languages, and 3) understand such aspects of intelligent performance as perception, language processing, planning, problem solving, reasoning, and learning, in terms of both the computational processes that underlie these skills and the computational mechanisms that may instantiate them.<br\/><br\/>The group will provide an enriching educational experience by exposing the students to non-classroom faculty-student interactions, academic-industry, multidisciplinary research interaction and the opportunity to gain hands-on experience with state-of-the-art language technology. This project aims to increase the number of women, minorities and students who engage in computing research, improve oral and written communication and knowledge dissemination skills of the participating students through regular group presentations, research discussion and conference article submissions.","title":"RI:EAGER: A Montclair Group in Cognitive and Computational Aspects of Language and Speech Processing: An Exploration","awardID":"1048406","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550607"],"PO":["565215"]},"168790":{"abstract":"Numerous organizations including government agencies are sitting on <br\/>mountains of spreadsheet data that are becoming increasingly common on <br\/>the web, but whose contents remain out of reach via search engines <br\/>because direct links to the contents of their constituent cells are<br\/>rare. Thus spreadsheet data represent legacy databases, especially<br\/>since many of their underlying schemas are no longer accessible. The<br\/>goal of this research is to discover the schema according to which the <br\/>spreadsheet is constructed. The focus is on the spatio-textual<br\/>spreadsheet which is a spreadsheet where the values of the spatial<br\/>attributes are specified textually. Such spreadsheets support spatial<br\/>searches whose output is visual and whose utility is enhanced by being<br\/>able to handle spatial synonyms. This is done, in part, by devising<br\/>methods to automatically discover the spatial attributes of the<br\/>spreadsheet as well as how to distinguish between several instances of<br\/>them which arise due to the presence of a containment hierarchy. In<br\/>particular, use is made of spatial coherence which is manifested by<br\/>observing that spatial data in the same column are usually of the same<br\/>spatial type, while spatial data in the same spreadsheet row usually<br\/>exhibit a containment relationship. Moreover, adjacent or nearby rows<br\/>exhibit spreadsheet coherence in that they are usually similar. The<br\/>broad impact of this research is to make spreadsheet data a first<br\/>class citizen on the web with the same chances of being discovered and<br\/>accessed as data found in other documents. Reports describing<br\/>results of this and related research will be available at<br\/>http:\/\/www.cs.umd.edu\/~hjs\/spreadsheets.html","title":"III: Small: Issues in Understanding, Indexing, Querying, and Visualizing Spatio-Textual Spreadsheets on the Web","awardID":"1018475","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["551003"],"PO":["563727"]},"177381":{"abstract":"In this project, the fundamental issue of dynamic bandwidth provisioning services is investigated. The goal is to gain a better understanding of the theoretical aspects of multi-domain routing and to develop novel techniques that will substantially improve the performance of multi-domain networks. The proposed solutions will assist in the successful deployment of computer services across multi-domain networks. In particular, this project will develop novel algorithms for QoS-guaranteed routing. The goal is to evaluate those algorithms through use of multiple kinds of GENI resources.<br\/><br\/>The obtained results will be expected to generate a strong interest in the network community at large for QoS-guaranteed routing in multi-domain networks. They will also generate significant impacts on computer network research through a better understanding of the theoretical issues of multi-domain routing for the design of future Internet architectures.","title":"EAGER: The Performance Evaluation of Intra-domain Bandwidth Allocation and Inter-domain Routing Algorithms for a QoS-guaranteed Routing Path Discovery","awardID":"1065665","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["542430"],"PO":["564993"]},"168680":{"abstract":"NetSE: Small: Collaborative Research:<br\/>Dynamic Flow Equilibria in Vehicular Traffic and Data Communication Networks<br\/><br\/>Project Summary<br\/><br\/>This project will develop a new methodology, algorithms, and models for dynamic flow equilibria in networked systems, with emphasis on two specific real-world networking applications ? vehicular traffic network modeling and efficiency analysis, and routing and flow control in data communication networks. The first research goal of this project involves appropriate modeling of dynamic flow problems in networks with self-interested agents, and understanding the properties of the equilibria for these problems. The other major research goal is to specifically study the application of dynamic flows to vehicular traffic networks and data communication networks. The research goals of this project will be achieved by an interdisciplinary but closely-integrated effort bringing together techniques from game theory, algorithm design, optimization, and real-world network simulation.<br\/>Intellectual Merit: The novelty of this project is that it provides a holistic understanding of the theoretical, algorithmic, and implementation issues of dynamic flow equilibria in networked systems, particularly in the context of vehicular traffic and data communication networks. This research explicitly takes into account the non-negligible travel time of flows in a network, and its variation as a function of the time-varying congestion in the network ? this results in new notions of flow equilibria that are fundamentally different and significantly more complex than those for non time-varying flows. The models used in the project are based on emerging concepts in game theory, optimization theory, and vehicular traffic modeling, and the project is expected to result in the development of a new algorithmic framework for studying dynamic flow equilibria in networks. In addition, this research will contribute techniques for dynamic flow equilibria study to many interested research communities, including transportation, algorithmic game theory, economics, sociology, and multi-agent systems, and facilitate the transfer of techniques between disciplines.<br\/>Broader Impact: This project will facilitate better network engineering, particularly in the context of transportation and communication networks. The implementation of the models developed by this research in specific disciplines (vehicular transportation and data communication networks) will have significant societal impacts, such as (i) enabling more efficient analysis and provisioning of transportation networks, leading to lower travel delays, and (ii) faster Internet access and download speeds due to more efficient routing and flow control protocols. This research will help rethink and possibly redesign important core components of the Internet through better flow control and routing choices. The findings of this research will be integrated into several different courses, and in Interactive Learning Modules aimed at attracting undergraduate and high-school students to research careers. Special efforts will be made to encourage participation of undergraduate and minority students.","title":"NetSE: Small: Collaborative Research: Dynamic Flow Equilibria in Vehicular Traffic and Data Communication Networks","awardID":"1017933","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["493567"],"PO":["565090"]},"176061":{"abstract":"Research supported by this EAGER award is developing the NeuroPhone system, the first Brain-Mobile phone Interface (BMI) that enables neural signals from consumer-level wireless electroencephalography (EEG) headsets worn by people as they go about their everyday lives to be interfaced to mobile phones and combined with existing sensor streams on the phone (e.g., accelerometers, gyroscopes, GPS) to enable new forms of interaction, communications and human behavior modeling. <br\/><br\/>Specifically, this high-risk exploratory research is to:<br\/><br\/>1) study new energy-efficient techniques and algorithms for low-cost wireless EEG headsets and mobile phones for robust sensing, processing and duty cycling of neural signals using consumer devices;<br\/><br\/>2) develop new learning and classifications algorithms for the mobile phone to extract and infer cognitively informative signals (e.g., P300, N400, and neural synchrony) from EEG headsets in noisy mobile environments;<br\/><br\/>3) deploy networked NeuroPhone systems with a focus on real-time multi-party neural synchrony and the networking, privacy and sharing of neural signals between networked NeuroPhones; and<br\/><br\/>4) evaluate networked NeuroPhones applications, specifically, measuring teacher-student engagement in the classroom and measuring group level emotional state.<br\/><br\/>This interdisciplinary research opens up opportunities in education, teaching and outreach, in part because it focuses on an educational NeuroPhone application, which contributes new insights into cognitive engagements of students in the classroom as well as engages students from the Department of Computer Science and the Department of Psychological and Brain Sciences in the project. Results from this work will transform applications across diverse domains such as education, health monitoring, and social networking.","title":"EAGER: Brain-Mobile Interfaces: Exploratory Research into the Development of Networked NeuroPhones","awardID":"1058753","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["529645","560929","521199"],"PO":["565303"]},"168691":{"abstract":"Event detection is a function common to many wireless sensor network (WSN) applications, e.g. intruder detection in surveillance networks, presence of people detection in building energy management applications, and crack detection in strain sensor networks. Cost of deployment and maintenance is considered by many to be the reason why WSN technology is not more widespread. While hierarchical or single-hop network architectures are attractive from a communication performance point of view, their required highly functional and long-transmission-range nodes are prohibitively expensive in large-area applications. This leaves multi-hop WSNs as the only possibility for large-area, cost-constrained WSN applications. However, multi-hop WSNs are still limited in terms of battery life. While ambient energy harvesting and rechargeable storage elements extend WSN lifetime, these technologies add to the cost of the network. Therefore, the demand still exists for extremely low-cost sensors that can run on low-cost non-rechargeable batteries.<br\/> In this project, we investigate new routing and medium access control (MAC) protocols to optimize the lifetime of a WSN that does event detection, while taking advantage of a new cooperative transmission (CT) range-extension forwarding strategy. CT is a technique wherein one or more radios assist another radio, in the physical (PHY) layer (i.e. the radios form a ?virtual transmit array?), to transmit a single message. In the context of multi-hop WSNs, CT range extension becomes a very promising energy balancing mechanism. This project defines realistic energy consumption models and optimizes MAC and routing metrics that are specifically tied to event detection quality and WSN lifetime, assuming CT range extension is available, along with other life-extension strategies, such as such as in-network filtering, sleep scheduling, energy-aware routing, and non-uniform node deployment.","title":"NetSE:Small: Long-Lasting Wireless Sensor Networks for Event Detection","awardID":"1017984","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["562753","560261"],"PO":["564924"]},"167481":{"abstract":"Abstract <br\/>This project will create a new category of intelligent, autonomous virtual or robotic agent, which is continuously operating and interacting with humans - always on - for long periods of time and whose primary motivation is building and maintaining long-term social relationships with humans. The initial application focus of this research is to provide companionship and social support and to promote wellness for older adults who are living alone. For example, during a typical day, an always-on relational agent might play a social game of cards with the adult, act as an exercise coach and help arrange visits or phone calls with the adult's family and friends. <br\/><br\/>A new integrated theory of social agency, called SharedPlans Relationship Theory, will be developed to serve as a principled foundation for these relational agents. The theory will be grounded in an always-on relational software architecture, which will be distributed as open-source for others to use and extend. Using a participatory design process, including home and laboratory studies, the target user population will help develop the specifications for a relational agent, which will then be constructed using the theory and software architecture, and placed in users' homes for long-term (month or more) longitudinal evaluation. <br\/><br\/>This project will make fundamental, theoretical contributions to models of relationship, sociality, interactional engagement and social support. The effort will also produce new insights into how people in general, and older adults in particular, enact social support at the relational, activity and micro-behavioral levels of analysis. The new always-on relational software architecture will be a fundamental advance over current agent architectures, which only support brief, focused interactions around a well-specified task. This architecture will also support incremental extension of agent capabilities and be able to control either virtual and robotic agent embodiments. <br\/><br\/>Social isolation is a broadly troubling trend in modern society. Always-on relational agents have the potential to counteract this isolation both directly, by providing companionship, and as intermediaries, by putting isolated people in contact with other people, both electronically and physically. Companionship and social support are also known to be significant positive factors in disease recovery and mortality, especially for older adults. The application focus of this project therefore has the potential for helping with health care cost control.","title":"HCC: Large: Collaborative Research: Always-On Relational Agents for Social Support of Older Adults","awardID":"1012086","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[448734],"PO":["564456"]},"166161":{"abstract":"A series of annual research workshops on Intelligent Information Systems, centered on machine learning for speech, language and vision technologies, are being organized at Johns Hopkins University to bring together diverse ?dream teams? of leading professionals, graduate students, and undergraduates, in a truly cooperative, intensive, and substantive effort to advance the state of the science.<br\/>The primary goals of the proposed workshop series are to develop machine learning principles applicable to a broad spectrum of intelligent systems, to attract students to the field and to prepare them for research by putting them to work on exciting problems alongside senior researchers in a highly collaborative environment. Creation of research infrastructure and lasting collaborations are secondary goals.<br\/>An open call for workshop project proposals is being issued each year to researchers in the worldwide IIS community. Received proposals are competitively evaluated and cooperatively refined at interactive peer review meetings, where project proponents, government representatives, and experts from related fields meet to assess their scientific merit, viability and potential impact. The graduate students attending the workshop are familiar with the field and are selected in accordance with their demonstrated performance. The undergraduates are entering seniors who are new to the field and who have shown outstanding academic promise; they are selected through a national search. The participation of undergraduates in these research programs encourages talented young scholars to pursue graduate studies in IIS.<br\/>By the end of this 3-year workshop series (beginning 2010), more than a hundred individuals will have conducted intensive collaborative research: about 30 academic and industry researchers, 20 researchers from government and national laboratories, 30 graduate students, and 20 undergraduates. Additional benefits of the workshops will be the collection or creation, and dissemination of valuable tools and data for IIS research, the establishment of fruitful and long-lasting collaborations, and the cross-fertilization of ideas among the participants.","title":"Cross-Cutting Research Workshops on Intelligent Information Systems","awardID":"1005411","effectiveDate":"2010-09-15","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["531055",445169,"555788","445173",445172,445173],"PO":["565215"]},"168350":{"abstract":"The project will investigate a new programming model for web programming. Modern Web programming practice typically uses a pattern referred to as \"callbacks,\" which obscures the connection between parts of the Web display and the application logic that corresponds to those parts. This makes Web application development more difficult, expensive and error prone. These problems are, of course, passed on to Web application users. The project's hypothesis is that programming without callbacks will lead to more reliable web applications. Specifically, this research will apply functional reactive data-flow programming techniques to Web 2.0 programming. The first challenge is whether realistic web applications can be programmed at all without callbacks; further progress will lead to improved programming models and tools for the development of web applications. The new programming approaches will be evaluated by assessing the difficulty of programming existing and new web applications while also assessing performance and other measures.","title":"SHF: Small: Modern Web Applications without Callbacks","awardID":"1016334","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["562082"],"PO":["564388"]},"168471":{"abstract":"This project is a collaborative effort between the University of Delaware and Millersville University. Information graphics (non-pictorial graphics such as bar charts and line graphs) occur frequently in popular media such as newspapers and magazines. Not only is the knowledge conveyed by these graphics very often not included in the article's text, but (in contrast with scientific documents) the article's text most often does not even explicitly refer to the graphics. Information retrieval research has focused on the text of documents, and their information graphics have largely been ignored. Yet, the graphic designer considered the graphic's message important enough to warrant designing a graphic to convey it. This project's goal is a novel methodology for retrieving relevant information graphics from a digital library in response to user queries.<br\/><br\/>Information graphics in popular media generally have a communicative goal or message that they are intended to convey. This message encapsulates the high-level knowledge contained in the graphic. The approach of the project is a language model that treats the relevance of a graphic to a query as a mixture of three components: a graphic's intended message, other textual components of the graphic such as its caption and additional textual description augmenting the caption, and the text of the document containing the graphic. Challenges that are being addressed include identifying the portion of the article that is relevant to the graphic, associating query terms with the intended messages of graphics in the document library, expanding the abbreviated captions and additional textual descriptions of graphics to more fully capture their content, and appropriately weighting the contribution of individual components of the mixture model. In addition, some kinds of graphics, such as grouped bar charts, have both a primary intended message and a secondary message. The impact of the secondary message on retrieval when an ideal graphic is unavailable is also being addressed. Evaluation of the graph retrieval methodology consists of experiments in which human subjects rate the relevance of retrieved graphics to user queries.<br\/><br\/>The goal of this project is to produce a system for retrieving relevant information graphics, thereby expanding the utility of digital libraries. Together with the SIGHT system, which conveys the content of information graphics via speech, the project will extend the information resources available to individuals with sight-impairments. The project will also produce a corpus of information graphics and their XML representations that can be used by other researchers. Corpora and research results will be disseminated on the project web site (http:\/\/www.cis.udel.edu\/~carberry\/Graph-Retrieval). In addition to significantly increasing the resources accessible from a digital library, the research will lay the foundation for expanding research on question-answering to take into account information graphics. The project will contribute to the development of future scientists by educating graduate students, providing research opportunities for undergraduates at a predominantly undergraduate institution, and enhancing the mentoring skills of graduate students as they work on a team that includes undergraduates.","title":"III: Small: RUI: Collaborative Research: Exploiting Information Graphics in a Digital Library","awardID":"1016900","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[450997],"PO":["563751"]},"168592":{"abstract":"A common feature of many modern human-engineered systems, such as medical devices, automobiles and aerospace vehicles, is that they involve interaction between discrete software systems and continuous physical systems. Several such systems are safety critical and failures can be catastrophic. How to guarantee that these systems are designed and built correctly? Traditional approaches based on testing need to be supplemented with approaches based on formal methods. Unfortunately, formal verification is an intractable problem in general and, hence, no single formal verification approach can uniformly perform well. This project develops a new approach for formal verification that complements existing approaches. Having a suite of formal verification tools can help find errors earlier in the design cycle to reduce overall development cost and increase assurance of designed complex cyber-physical systems. <br\/><br\/>This project contributes to the existing formal verification technology by developing a new approach for formal verification, called bounded verification. Bounded verification verifies a system by performing a bounded search for a witness that would establish the property. Depending on the property, a witness is a Lyapunov function, an inductive invariant, a controlled invariant and so on. Search for a witness is cast as satisfiability of a quantified (\\exists\\forall) formula. Satisfiability is decided using a combination of techniques including counterexample guided inductive reasoning, compositional reasoning, simulations, and fixpoint computations. Witnesses generated by bounded verification of the design are used to bootstrap formal verification of the implementation. This project also extends the bounded verification approach to performing automated synthesis of systems. Bounded verification explicitly provides witnesses for correctness, which can be used to aid in the certification process. This project also introduces new links for interaction between the fields of theorem proving and formal verification that aim to foster collaboration and promote progress in both areas.","title":"SHF: CSR: Small: Bounded Verification and Bounded Synthesis","awardID":"1017483","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[451280],"PO":["565264"]},"168372":{"abstract":"Modern operating systems (OSs) are the foundation of our software stacks. Most OS code consists of device drivers -- code that controls devices like keyboards and disks -- yet drivers are complex, stagnant, poorly written, and are responsible for most OS crashes and bugs. Worse, driver frameworks haven't been re-examined for decades, holding back OS innovation.<br\/><br\/>We are building \"driverless OSs,\" in which drivers are completely removed from the OS. We are replacing complex, low-level device interconnects (like PCI) with commodity, high-speed networks (like USB or Ethernet). With this, drivers become high-level, simple services that act as an RPC layer between OS frameworks and the devices themselves.<br\/><br\/>We are prototyping two driverless OSs. Our first, called ND, is retrofitted into Linux and is our vehicle for exploring the relationship between the driverless approach and modern multicore hardware. The only part of ND that needs conventional interrupt-driven code is the network driver; as a result, we can eliminate complexity like interrupt-context code and synchronization.<br\/><br\/>Our second, called browserOS, treats drivers and frameworks as untrusted Web programs. \"Web drivers\" are written in JavaScript or compiled Native Client code, and are downloaded and executed on-demand by the browser. Web services push Web drivers to clients to interact safely with client-side devices in an OS-agnostic manner.<br\/><br\/>The expected impact of our work is (a) to make OSs simpler, safer, and more robust, (b) to accelerate the convergence of Web browsers and OSs, and (c) to facilitate new architectural innovations in operating systems.","title":"CSR: Small: Driverless Operating Systems","awardID":"1016477","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[450764,"532591"],"PO":["565255"]},"172091":{"abstract":"Scientific computing as a means of discovery has the promise of solving some of the most enduring challenges in science. Understanding global climate, unraveling the mysteries of turbulence, predicting natural disasters such as earthquakes and tsunamis, untangling the complexities of life by simulating the proteins that make its building- blocks, all these, and more, are being tackled by scientists today using high-performance computing (HPC). And today, more than ever, an opportunity presents itself for exciting discoveries through HPC, thanks to the advent of new computer architectures that bring huge increases in performance, at lower power consumption and much reduced prices. The new HPC hardware based on graphics processors (GPUs) is a technology that can level the playing field for scientists in many parts of the world to participate in leading-edge computational research. <br\/><br\/>This Pan-American Advanced Studies Institutes (PASI) award, jointly supported by the NSF and the Department of Energy (DOE), will take place January 3-14, 2011 at the Universidad Tecnica Federico Santa Mar\u00eda (UTFSM) in Valpara\u00edso, Chile. Organized by Dr. Lorena Barba of Boston University, an interdisciplinary group of collaborators and participants will explore the feasibility of adapting and applying GPU technologies to complex, outstanding problems in the physical sciences. Participants will include a complementary mix of geoscientists, computer scientists, mathematicians, and physicists. Lectures, tutorials and hands-on activities will be focused on modern hardware computing, fundamental algorithms for massively parallel computational applications, and recent developments in open source libraries and programming. PASI participants will include approximately 30 U.S. and Latin American students supported by this award and a similar number of local participants supported by Chilean agencies. An ancillary mentoring session for postdoctoral scholars will provide advice on succeeding in modern academic environments. <br\/><br\/>This PASI aims to initiate a pole of development for high-performance computing using modern hardware, and to stimulate international collaboration and future initiatives leading to student exchanges, joint projects and new funding opportunities for the participants. Graduate students and postdoctoral researchers will have a unique learning experience; they will be trained in the use of the most important software tools for HPC, including those specific to GPUs, and the syllabus will put emphasis on the open-source model for science. The chosen applications, e.g., simulation of tsunamis, will attract the attention of the general public, offering opportunities for dissemination in the press and other media. Extensive dissemination of the learning materials online will ensure impact beyond the duration of the institute itself.","title":"Scientific computing in the Americas: the challenge of massive parallelism; Valparaiso, Chile; January 3-14, 2011","awardID":"1036435","effectiveDate":"2010-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":["528841"],"PO":["531406"]},"164490":{"abstract":"Social production communities can be powerful engines for harnessing the efforts of many individuals to produce valuable artifacts and knowledge. However, their success critically depends on members' ability to effectively contribute. As the size and complexity of the community grows, so do challenges to members' understanding of the content and collaboration. These challenges decrease the ability of the team to work together, and the quality of the work product.<br\/><br\/>The researchers propose partnering humans with intelligent interfaces that improve contribution effectiveness. They will create intelligent algorithms and interfaces that go beyond supporting people simply foraging for information to information farming, in which members of the community work together to plant the seeds of the information the community needs, nurture the growth of those seeds into valuable information, and weed out the information that detracts from the value of the farm.<br\/><br\/>The research is based on theories of human information processing, and will extend those theories to environments in which people are producing information. The researchers will explore new algorithms and interfaces based on the extended theories, and will carry out studies to understand how the theories work in practice.<br\/><br\/>Social production communities are economically and socially important. Open source software runs large parts of our economy; Wikipedia is revolutionizing knowledge production and consumption, providing free access to one of the largest bodies of knowledge gathered in human history. The proposed research will directly improve Wikipedia, and will contribute to understanding how social production communities work.","title":"SoCS: Collaborative Research: Information Farming: Intelligent Interfaces for an Online Production Community","awardID":"0968484","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["517858"],"PO":["564456"]},"174181":{"abstract":"Smartphones are fast becoming a full-fledged computing platform that<br\/>our society depends upon. Smartphone applications that access data<br\/>and computing resources in the \"cloud\" are inevitable given the<br\/>processing and storage limitations on the phones. Today the burden of<br\/>partitioning smartphone applications between the phone and the cloud<br\/>lies squarely with the programmer. This manual approach to<br\/>partitioning applications is fundamentally limited and will not scale<br\/>up to allow smartphones to become a truly rich and robust computing<br\/>platform. Manual partitioning is tedious and error prone. Moreover,<br\/>manual partitioning requires the programmer to make important<br\/>decisions that cannot be properly made until run time.<br\/><br\/>This project explores the requirements, design, and implementation of<br\/>a programming system for cloud-enabled smartphone applications that is<br\/>inherently adaptive, partitioning applications transparently in order<br\/>to cope with a diverse set of dynamic constraints. The project is<br\/>studying cloud-enabled smartphone applications from a variety of<br\/>domains in order to understand application requirements, constraints,<br\/>and tradeoffs in practice. The project is also pursuing programming<br\/>models that allow developers to flexibly and declaratively express an<br\/>application's components along with their dependencies and<br\/>constraints. Finally, the project is developing a prototype system<br\/>architecture that collaboratively executes an application on the phone<br\/>and the cloud subject to the application's requirements. Within a<br\/>decade, smartphones will transform the way health and lifestyle<br\/>choices are delivered to much of the population. This project is<br\/>helping to enable this transformation by making a rich class of<br\/>smartphone applications much easier to create, adapt, and understand.","title":"EAGER: Collaborative Research: Toward An Adaptive Programming System for Cloud-Enabled Smartphone Applications","awardID":"1048824","effectiveDate":"2010-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["553707"],"PO":["523800"]},"174192":{"abstract":"The growth of the Internet means everyone from system administrators to casual users are regularly confronted with making decisions on how to share data. Research suggests that even experts struggle to make these decisions accurately using current access-control mechanisms. As users start to share information across social and professional applications, usable access-control mechanisms that help prevent such semantic errors are all the more urgent. This project develops an interactive authoring paradigm that helps users identify and clarify policy inconsistencies before they turn into semantic errors. The envisioned tools examine policies and their consequences during authoring, alert users to potential inconsistencies (such as isolated documents shared more globally than most others), and ask questions in order to eliminate ambiguities.<br\/><br\/>The challenge in building such proactive authoring tools lies in knowing what inconsistencies and issues to track without overwhelming a user with too much interaction. The proposal therefore combines user studies with tool building and evaluation. The intellectual merit of this project lies in its marriage of research on user behavior and logical tools to produce a new paradigm of policy authoring. Broader impacts come from building tools for mainstream end-users, guided by ethnographic studies of social-network users. For further information see the project web site at the URL: http:\/\/www.margrave-tool.org\/","title":"EAGER: Interfaces to Reduce Human Error in Social Network Access Control Policy Authoring","awardID":"1048846","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["485803","519555"],"PO":["543481"]},"168780":{"abstract":"Learning complex statistical models from data is intractable for many models of interest. The PIs are studying a new approach to learning from data that formulates learning as a weakly chaotic nonlinear dynamical system. They show that this dynamical system, which they call ?herding?, combines learning and inference into one tractable forward mapping. They study the abstract mathematical properties of this nonlinear mapping, such as the properties of its attractor set and the topological and metric entropy of the mapping. They then relate these to properties of learning systems. <br\/><br\/>The PIs apply herding systems to a wide range of applications in machine learning. In supervised learning they show that herding suggests a natural extension to the ?voted perceptron algorithm? by including hidden variables. In unsupervised learning, herding is used to train Markov random field models from data. Herding is also extended to Hilbert spaces where it naturally leads to a deterministic sampling algorithm. Due to negative autocorrelations, this ?kernel herding? generates samples that have superior convergence properties than random sampling. They also apply herding to active learning problems. <br\/><br\/>Herding has the potential to radically transform the way we view learning systems. It connects learning to the vast field of nonlinear dynamical systems and chaos theory. As such the impact on machine learning is significant. Scientific results will be disseminated through journal publications and conference proceedings. The PIs also introduce a new course on learning, chaos and fractals to expose students to the intriguing connections between these fields.","title":"IIS: RI: Small: Nonlinear Dynamical System Theory for Machine Learning","awardID":"1018433","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["516952","541441"],"PO":["562760"]},"168791":{"abstract":"This project will: (1) Build an experimental setup for conducting evacuation experiments inside 3D virtual online communities. (2) Analyze the realism of the experimental setup and research the ways to improve it. (3) Investigate the use of intelligent signs for controlling peoples' behavior in emergency situations. One of the major aspects in the design of buildings, stadiums and city blocks is their suitability for evacuation. Peoples' lives depend on how quickly these constructions can be evacuated in the emergency situations such as fires, earthquakes, terrorist attacks and collapsing structures. As a result of the 9\/11 terrorist attacks however, it became apparent that current approaches to building design in regard to emergency evacuation for various building typologies such as high-rises, airports and stadiums need to be re-examined. In particular, the designs must be carefully evaluated against evacuation procedures. This raised a major concern about the lack of tools that would allow robust predictions of realistic human movements and interaction in the designed environments. It is clearly impractical to establish live experiments with thousands of people evacuating every possible building design for every possible emergency condition. <br\/><br\/>The research will not only evaluate virtual-world information technology as a tool for building design to facilitate evacuation, but it will also develop new information technology that could be incorporated in real-world buildings. For example, intelligent exit signs could automatically direct people during emergencies based on the known information about the construction, the type and location of emergency, and the current distribution of people. Building an experimental setup for conducting evacuation experiments within 3D virtual online communities requires answering such unorthodox questions as how to attract research subjects to the experiments, how to motivate the participants to evacuate buildings when emergency occurs, and what setup should be made to evaluate the efficiency of evacuation as truthfully as possible. The analysis and improvement of the realism of the setup requires research in realistic simulation of natural effects such as fire, real-time realistic human motion synthesis for hundreds of characters and developing effective means of measuring the immersiveness of participants. Finally, the design of control strategies for intelligent signs requires the research of real-time decision-theoretic planning under uncertainty algorithms suitable for the control of massive multi-agent systems. <br\/><br\/>The safety of buildings is of critical importance to any society. Natural hazards, terrorist attacks and fire accidents cause losses of thousands of lives every year. By designing buildings that are easier to evacuate, engineers can save a significant fraction of these lives. Yet, there is a lack of tools that would allow engineers to conduct high-fidelity evaluations of building designs in terms of evacuation efficiency. This research is directed towards providing engineers with access to conducting such large-scale high-fidelity experiments at drastically lower expense than previously possible. Progress in this direction will also have positive educational impacts. The project will play a significant part in the classes offered in an undergraduate Digital Media Design program, which has about 50% female students.","title":"HCC: Small: Cyber-Enabled Analysis and Control of Building Evacuation","awardID":"1018486","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["461714",451767,"562688"],"PO":["564456"]},"179560":{"abstract":"Large-scale wireless networks are projected to dominate the information technology sector in the future, giving rise to a new set of research problems on scalability. The main goal of this project is to develop an essential understanding of the impact of large scales on the performance of wireless networks. In particular, the project examines how the finiteness of resources (memory, computational power, etc.) at individual nodes affects the overall network performance. The developed understanding is then used to design a set of algorithms that support efficient operation of large-scale networks of nodes with very limited resources. The algorithmic aspect is particularly important given that some of widely considered algorithms require excessive resources at individual nodes and, hence, are not scalable. However, the project demonstrates the existence of algorithms that require only negligible resources but achieve comparable performance. Furthermore, the study reveals that completely new protocols are needed to support operation of large-scales wireless networks. <br\/><br\/>In contrast to the majority of earlier studies that examined either large networks with unlimited node resources or small networks with limited node resources, the focus of this project is on relationship between the network size and node resources. Most of the considered problems are impractical to be addressed experimentally due to a considerable cost of building large-scale prototypes. Moreover, even simulating such systems is often very difficult because of computational limitations. Thus, a comprehensive research agenda is based on an analytical framework that overcomes the difficulties imposed by large scales.","title":"CAREER: Scalability Limits of Wireless Networks","awardID":"1107395","effectiveDate":"2010-09-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[481294],"PO":["557315"]},"168560":{"abstract":"Recent advances in imaging of biological systems at all scales, from molecular and cellular up to organ levels, have given biologists and clinicians opportunities to observe processes and interactions at a never-before-seen level, leading to the collection of huge amounts of high-dimensional data. As a result, the visual inspection of these data sets,already error-prone, nonreproducible and subjective, has become impractical as well.<br\/>There is thus an acute need for the development of systems to both automate this analysis, as well as mine interactions not visible to the human eye.<br\/>The task of classification has been at the heart of several of the group's projects in the past few years, including the determination of developmental stages in fly embryos,the recognition of H&E-stained tissue types in stem-cell teratomas, and the diagnosis of otitis media. As an accurate and efficient algorithm for automated classification would have been of great use to biologists and clinicians, a multiresolution (MR) classification<br\/>algorithm was developed and, in each of the problems, consistent trends emerged:<br\/>1. MR classification always performed better than the no-MR version;<br\/>2. Redundant MR transforms frames, always performed better than the<br\/>nonredundant ones bases. This consistency across data sets and applications indicates that MR has the power to make a significant impact on biomedical image classification performance. The investigators thus study MR classification to gain fundamental understanding of its underpinnings, in particular, the following two questions:<br\/>1. When\/why does the MR classification work?<br\/>2. When\/why does the MR frame classification work?<br\/>These questions are approached by setting up a measure-theoretic theory of<br\/>classification as a mathematically rigorous framework within which to pose and<br\/>investigate real-world classification problems.","title":"CIF: Small: Theory of Multiresolution Classification with Bases and Frames","awardID":"1017278","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["551540","493223"],"PO":["564898"]},"168571":{"abstract":"This research project is to investigate principles and methods for uncovering sophisticated patterns and actionable knowledge from massive moving object data. Thanks to the rapid progress and broad adoption of sensor, GPS, wireless network, and other advanced technologies, moving object data have been accumulating in unprecedented scale. However, moving object data could be dynamic, sparse, scattered, and noisy, and patterns and knowledge to be mined could be deeply hidden, sophisticated, and subtle. The MoveMine project investigates effective and scalable methods for mining various kinds of complex patterns from dynamic and noisy moving object data, finding multiple interleaved periodic patterns, and performing in-depth multidimensional analysis of moving object data. It integrates and extends multiple disciplinary approaches derived from spatiotemporal data analysis, data mining, pattern recognition, statistics, and machine learning. The study takes bird and animal movement data and traffic data as the major sources of data for investigation. However, developed methods can be applied to the analysis of many other kinds of moving object data for environmental study, traffic control, law enforcement, and protection of homeland security. The study also addresses the issue of ensuring privacy and security protection while developing powerful pattern and knowledge discovery mechanisms. The research results are to be published in various research and application forums and be integrated into the educational programs at UIUC. The progress of the project and the research results are also disseminated via the project Web site (http:\/\/www.cs.uiuc.edu\/homes\/hanj\/projs\/movemine.htm).","title":"III-Core:Small: MoveMine: Mining Sophisticated Patterns and Actionable Knowledge from Massive Moving Object Data","awardID":"1017362","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563535"],"PO":["563727"]},"168692":{"abstract":"Due to the complexity and cost associated with managing data, many organizations are looking towards outsourcing their data management services. In recent years especially, Cloud Computing has gained significant interest. Although data outsourcing holds great promise, it raises a number of security and privacy concerns. In particular, since the clients have little or no direct control over the software and hardware that is running at the servers, there is a reluctance to blindly trust the server. A server may sacrifice the quality of service for a client either intentionally or inadvertently. In addition, there is a concern about the fidelity of the service. Databases have precise semantics of operation which must be preserved by the outsourced database. There is a critical need to develop authentication mechanisms that allow a database to be operated (for querying and updates) at an outsourcing site while providing guarantees to the data owner regarding transactional consistency of the database.<br\/><br\/>This project aims to make significant advances in the authentication of dynamic outsourced databases. The project will develop solutions that enable a data owner and authorized clients to ensure that the outsourced database represents exactly the state that corresponds to valid transactions that have been executed by the owner or clients. Comprehensive and efficient solutions that minimize the burden on the data owner, and the overhead on the outsourcing site for proving correct execution will be developed. <br\/><br\/>For further information, see the project website http:\/\/www.cs.purdue.edu\/homes\/sunil\/AuthenticDB","title":"III: Small: Ensuring Integrity and Authenticity of Outsourced Databases","awardID":"1017990","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["470080"],"PO":["565136"]},"168461":{"abstract":"Distributed source coding and routing are strongly motivated by high density sensor networks with promising applications in numerous scientific and engineering disciplines, where it is critical to minimize resource requirements for data communication. This research project stems from the observation that traditional separate treatment of distributed coding and routing is only optimal under strict simplifying assumptions that are often invalid. Major theoretical and practical challenges emerge once these simplifying assumptions are removed, including derivation of the fundamental performance bounds, and optimal practical system design. The degree to which distributed source coding will be practically applicable to future network environments, crucially depends on the development of such technology.<br\/><br\/>This research project formalizes the tradeoffs that underlie distributed coding of sources with information routing over multiple sink networks, and develops system paradigms that allow joint optimization. Having established that optimality requires the ability to disperse fragments of a source information to various sinks, and to allow related but unrequested sources to convey information to any particular sink, this research develops the \"dispersive information routing\" paradigm and its integration within the distributed coding system. The main research thrusts include: foundation and performance bounds (derivation of the theoretical foundation from source coding, estimation and information theory principles); joint encoder-router-decoder design (development of efficient optimization tools for joint design of all system components); distributed storage (advances on the closely related problem of data storage and retrieval on a network); large scale distributed coding (eliminating the main complexity bottlenecks for distributed coding in very dense sensor networks).","title":"CIF: Small: An Integrated Framework for Distributed Source Coding and Dispersive Information Routing","awardID":"1016861","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["550914"],"PO":["564924"]},"168230":{"abstract":"Recent advances in technology have made the design of parallel computers with thousands of processors more feasible. Consequently, the study of different networks for linking processors is an integral part of the design of high-performance computers. This project will study the interconnection topologies of three important families of networks from the point of view of network efficiency. Examples of the type of problems to be considered include: algorithms for efficient communication among processors; effective placement of scarce or otherwise limited resources; and fault-tolerant communication algorithms in the presence of node\/link failures. In addition to facilitating graduate training, the project would provide detailed insight for understanding various tradeoffs in designing interconnection networks for large multiprocessor architectures.","title":"SHF: Small: Interconnection Networks: Topological Properties and Communication Algorithms","awardID":"1015804","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[450412,"486183"],"PO":["366560"]},"168472":{"abstract":"The reliability, safety, and security of today's applications depend on controlled data accesses and updates during execution. For instance, many emerging applications are composed of multiple software modules. To protect these modules from each other within a single address space, inter-module operations need to be carefully monitored and controlled. Additionally, the reliability of online systems can benefit from live checking of memory access errors such as buffer overflows, memory leaks, and accesses to uninitialized data. Similarly, memory access monitoring can support information flow mtracking in a complex system for enhanced security.<br\/><br\/>Available mechanisms in today's processors are tied to support for virtual memory, making implementation of access control both heavy weight and coarse grained. The proposed research will design and utilize new light-weight memory access control mechanisms that are independent of and subordinate to existing system memory protection. At the hardware level, this approach minimizes impact on the processor core by placing the access control mechanisms outside the common critical path. At the operating system level, the required support is largely outside of the kernel memory management functions, incurring overhead only when exercised. Such auxiliary mechanisms are more amenable to practical deployment, yet they are capable of supporting fine-grained and flexible memory protection. In conjunction with these hardware\/software mechanisms, the research will devise a new protection model that can be manipulated either at user or privileged level based on an application's requirements. The flexible, efficient memory monitoring framework developed will enable debugging tools that can help detect memory access errors such as out-of-bound accesses, and help enforce data security or privacy policies in live systems. The proposed work will target a wide variety of applications and utilizations with a view to validating the goal of improved programmer productivity.","title":"SHF: Small: Auxiliary Hardware\/Software Mechanisms for Flexible Memory Access Control","awardID":"1016902","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["556692","550397"],"PO":["366560"]},"167152":{"abstract":"Complex cognitive functions such as spatial cognition, language development, and episodic memory require associations between multiple sensory experiences, such as images and sound, and require that associations are remembered in sequence. The rodent hippocampus has been one of the leading models for understanding neuronal mechanisms for remembering a sequence of spatial locations. Yet, it remains unknown whether the mechanisms that are used for encoding a path through space are the same as those that are used for encoding sequences that contain multiple modalities. To address this question, the auditory modality is of particular interest since it provides a mean to present a sequence of stimuli with high temporal precision and thus a mean to investigate time constraints for sequence learning. The proposed research investigates auditory sequence learning in a rodent species that is a hearing-specialist and tests whether the hippocampus of Mongolian gerbils can encode sequences of auditory stimuli with mechanisms similar to those used for spatial sequences. <br\/><br\/>It will be tested whether place fields and theta phase precession exist in Mongolian gerbils, whether complex sound stimuli are encoded in the gerbil hippocampus in a spatially-independent manner or in association with the location of the animal, and whether sound sequences are encoded with network mechanisms related to those that are used for encoding spatial sequences. These questions will be addressed with single-unit recording from hippocampal principal cell populations of behaving animals, and experiments will be conducted in a virtual reality setup that allows for the precise delivery of auditory stimuli. Performing these experiments in a rodent species with an auditory specialization might result in important advances in addressing how the hippocampus encodes multimodal sequences. This research can provide important insight into neural network mechanisms for sequence coding and can lead to a better understanding of the contribution of the hippocampus to language development in humans.<br\/><br\/>This project is jointly funded by Collaborative Research in Computational Neuroscience and the Office of International Science and Engineering. A companion project is being funded by the German Ministry of Education and Research (BMBF).","title":"CRCNS: US-German Collaboration: Auditory and Spatial Sequence Encoding in the Hippocampus","awardID":"1010463","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[447717],"PO":["564318"]},"168373":{"abstract":"This project will design and implement prototypes of intelligent collaborative assistants that help human users participate in joint activities as a member of a team. These teams can include both human and non-human (robotic or software) agents collaborating to perform tasks and solve problems. Examples of such tasks include helping the leader of a search-and-rescue team coordinate the search of collapsed buildings following an earthquake or searching for trapped miners following a mine accident, helping coordinate a team responsible for ongoing surveillance and anomaly detection in some area, helping manage a team of agents exploring a distant planet, or helping an analyst locate, monitor and interpret various streams and sources of information in support of a decision or activity. This research will extend prior work in several significant ways: (1) integrating and extending a rich model of teams and activities; (2) increasing the role of knowledge and reasoning in driving the behavior of the collaborative agent in a team setting; (3) extending a model of collaborative problem solving to support human control of agent teams; and (4) developing a feature-rich, interactive, simulated environment based on videogame engine technology for development, demonstration, and evaluation of human-agent teams and assistants. <br\/><br\/>Collaborative assistants have already shown promise in a number of different application domains such as learning and automating tasks on the web or providing natural, effective interfaces for patients to access their personal health information. Several researchers have applied the \"conversational assistant\" paradigm to domains ranging from customer service agents to embodied virtual agents for education and training. But these assistants have generally been strictly one-on-one, communicating solely with the user and typically responsive only to the user's utterances. They are also generally \"face-to-face,\" in that the participants are located next to each other and a shared communicative state is more or less assumed. This research will greatly broaden the applicability of intelligent collaborative assistants to more complex tasks with multiple participants in more realistic settings. Because the approach is based on a general model of collaborative assistants, the advances from this work will improve the capabilities of collaborative assistants in general. <br\/><br\/>The game-engine-based human-agent team environment developed in this research will be built from freely-redistributable components and will be made freely available to the community for use in education and research. This environment will be suitable for use in undergraduate classes, allowing students to see algorithms and techniques in action controlling agents in a realistic world that can also include humans. Researchers should also find it a useful testbed for experimentation and evaluation. The project will involve both graduate and undergraduate students with a wide range of skills, interests, backgrounds, and personality types, not just hardcore gamers.","title":"HCC: Small: Collaborative Assistants for Team Activities in Virtual Environments","awardID":"1016486","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[450767],"PO":["564456"]},"159452":{"abstract":"Many of the most important functions in society are undertaken by large groups or teams. Emergency response, product development, health care, education, and economic activity are pursued in the context of large, dynamic, interacting networks of groups. Theory and research on such networks of groups is much less developed than research on isolated small groups or formal organizations. A major challenge for research on networks of groups is the difficulties that accompany the collection and analysis of the huge bodies of high resolution, high volume, observational data necessary to study these large, dynamic networks of groups. The goal of this project is to address this challenge by applying advanced computing applications to capture, manage, annotate and analyze these massive observational sets of video, audio, and other data. The resulting data analysis system, GroupScope, will enable breakthrough research into social interaction in large, dynamic groups to be conducted much more quickly and with much higher reliability than was previously possible. It will do this by automating as many functions as possible to the highest degree possible, including managing huge volumes of video, audio, and sensor data, transcription, parsing audio for critical discourse events, annotation and indexing of video streams, and coding interaction. These first pass analyses can then be supplemented by human analysts (and their analyses in turn will feed into machine learning that will improve the computerized analysis). <br\/><br\/>GroupScope will be developed with the collaboration of social scientists studying emergency response teams, children's playground behavior, distributed teams, and product development teams. When developed, GroupScope will be deployed in a cyberenvironment, a Web 2.0 based cyberinfrastructure that enables a community of researchers to collaborate on common problems. The cyberenvironment will enable multiple researchers to analyze and code the same group data for both small groups and large dynamic groups and networks. Multiple analyses and codings working from diverse perspectives will enable discovery of previously unsuspected relationships among different levels and layers of human interaction. They can also be linked to survey responses from participants, enabling linkage to the realm of perceptions and traits.<br\/><br\/>Many of the most fundamental advances in science have come through the development of new instruments, such as more powerful telescopes or microscopes that can allow scientists to view molecules. In the same way GroupScope will shed light on the workings of critical functions performed by real world groups such as emergency response units, health care teams, stock exchanges, and military units. GroupScope will also have applications in the training of those working in multi-team systems, such as first responders to disasters. It can be used to record and \"grade\" training sessions, giving participants feedback on both strengths and weaknesses of their approaches.","title":"CDI-Type II: Collaborative Research: Groupscope: Instrumenting Research on Interaction Networks in Complex Social Contexts","awardID":"0941268","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561056","457204","508612",426305,"473994","554468"],"PO":["513851"]},"168285":{"abstract":"Real-time information is a fundamental emerging issue in the creation<br\/>and management of Web content. Increasingly, rather than consulting<br\/>relatively static sources that are indexed on a periodic basis,<br\/>people refer to information on news sites, blogs, social-networking<br\/>sites, and Twitter feeds that change dynamically and spread rapidly.<br\/>This project will study how information content varies over time, how<br\/>it is transmitted through underlying social networks, and how its<br\/>recipients assemble it into larger units. The project will explore<br\/>new techniques for addressing these issues, based on novel methods<br\/>for tracking, analyzing, and presenting information that evolves and<br\/>spreads rapidly over time. The resulting approach aims to transform<br\/>important aspects of the ways in which real-time information on the<br\/>Web is handled.<br\/><br\/>First the fundamental units of information that spread through the<br\/>underlying information networks will be identified. From a set of<br\/>nearly 1 billion news media articles and blog posts (approx. 6TB of<br\/>data), and a collection of 500 million tweets from Twitter, small<br\/>(generally textual) units of information will be identified that<br\/>remain relatively stable as they spread through the Web. The<br\/>temporal variation within these basic units will be analyzed and<br\/>modeled. This modeling will include connections with biological<br\/>models of epidemics, as well as new frameworks that exploit the<br\/>fundamental differences between biological and social contagion.<br\/>Finally, the temporal variation will be related to network-level<br\/>models for the diffusion of this information. Generally, the actual<br\/>networks on which real-time information spreads cannot be directly<br\/>observed, nor can the influence of any particular node in the network<br\/>be directly measured. Therefore, the project will develop machine-<br\/>learning techniques that infer these hidden networks and unobserved<br\/>levels of influence.<br\/><br\/>For more information see the project web site at:<br\/>http:\/\/snap.stanford.edu\/proj\/mipro","title":"III: Small: Collaborative Research: Mining Information Propagation on the Web","awardID":"1016099","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[450550],"PO":["565136"]},"174490":{"abstract":"This proposal seeks $ 15,000 of funding to support around 20 students from US-based universities to attend the 2010 IEEE International Conference on Cluster Computing Conference by defraying travel and hotel expenses for them. The web page for this important conference, also known as CLUSTER2010, is http:\/\/www.cluster2010.org","title":"Increasing Student Participation in Cluster Computing through IEEE Cluster 2010 Attendance","awardID":"1049858","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[468070],"PO":["535244"]},"174270":{"abstract":"This grant provides international travel support for U.S. based graduate student participants to attend the 2010 International Conference on Data Mining (ICDM 2010), which will be held in Sydney, Australia, on December 13-17, 2010. ICDM has established itself as the world's premier research conference in data mining. It provides an international forum for presentation of original research results, as well as exchange and dissemination of innovative, practical development experiences.<br\/><br\/>The conference seeks to continuously advance the state-of-the-art in data mining, including algorithms, software and systems, as well as related areas such as data management, machine learning and their use in a wide range of applications. With the growth of the Web, wireless communication and data intensive technologies such as sensor networks, social media, multimedia information systems, cloud computing, and application domains such as bioinformatics, climate change, or security, advances in data mining have a significant impact. <br\/><br\/>A strong representation of U.S. researchers at the Conference is useful in maintaining U.S. competitiveness in this important area. The total number of ICDM participants in the past has been in excess of 300, with a majority of the participants from the U.S., then Europe and Asia. It is expected to provide scholarships to 15 U.S. based graduate student participants. This grant will partially support the travel costs for the U.S. based graduate student participants. <br\/><br\/>The ICDM proceedings are published by IEEE. The student award results will be announced at the ICDM 2010 conference website (http:\/\/datamining.it.uts.edu.au\/icdm10\/).","title":"Support for US-Based Students to Attend the 2010 IEEE International Conference on Data Mining (ICDM 2010), December 13-17, 2010, Sydney, Australia","awardID":"1049139","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["526618"],"PO":["563751"]},"173071":{"abstract":"Proposal #: 10-42644 & 10-42642<br\/>PI(s): Fortes, Jose & Winston, Flaura K.; Zonfrillo, Mark<br\/>Institution: University of Florida & The Childrens Hospital of Philadelphia<br\/>Title: SpProj.: Collab Rsch: Adaptive IT Appliance for Collaborative Review of Child-Death Cases<br\/>Project Proposed:<br\/>These collaborative projects, investigating techniques for the creation, deployment, and management cyberinfrastructure for collaborative review of cases of child death, aim to identify strategies to improve children?s safety. In this context, cyberinfrastructure encompasses the tools and services, encapsulated in an IT appliance) needed for capturing, communicating, authoring, viewing, sharing, controlling access to, storing, and conferencing about data and information regarding events resulting in the children?s death. The project builds on an existing functional IT appliance developed for collaborative mechanisms of injury to children in motor vehicle crashes. Enabling its extension, this appliance could quickly be adapted to a more diverse range of causes of death, allowing for different kinds of participants with varying degrees of security and privacy. The work is expected to enrich the presentation of death scenarios for quicker analysis of their causes, leading to more efficient identification of potential prevention strategies. Expected contributions within the research thrusts include techniques for:<br\/>- Automatic generation of interfaces, integration of components and services, and recovery of domain-specific collaborative IT appliances and<br\/>- Fine-grained spatio-temporal access-control of shared objects.<br\/>Broader Impacts: <br\/>This project addresses a real need for easy-to-use tools that reflect semantics and workflow collaborative activities by non-IT experts as undertaken by professional teams engaged in child death reviews. The project engages graduate students in advanced IT research. Minorities and women will be recruited and encouraged to apply.","title":"Collaborative Research: Adaptive IT appliance for collaborative review of child-death cases","awardID":"1042642","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["522859",464205],"PO":["557609"]},"164491":{"abstract":"Health support groups, including those on the internet, can substantially benefit participants, but the social processes responsible for these benefits are unclear. A team of researchers led by Robert Kraut at Carnegie-Mellon University will explore how the conversational dynamics of online cancer support groups influence group functioning and participant quality of life and will develop computational tools that can be used to analyze online conversations and improve their effectiveness. The research project has four specific goals. (1) To understand how conversational episodes in online support groups facilitate social support. For example, what must a person say to get others to respond empathically? (2) To understand how support in these groups influences group commitment and affects health outcomes. (3) To develop computational tools to make the analysis of large datasets of health conversations tractable. (4) To use these tools to improve the training of support group facilitators.<br\/><br\/>Online health support groups are popular, being used by about 58% of American adults. Identifying the role of communication in online cancer support groups will provide valuable information to users and facilitators of these groups and will enhance their training. Moreover, a tool for analyzing large corpora of conversational data will facilitate the work of researchers who are interested in conversational behavior in other kinds of online groups","title":"SoCS: Collaborative Research: Conversational Dynamics in Online Support Groups","awardID":"0968485","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["554179","560995"],"PO":["563458"]},"174182":{"abstract":"Smartphones are fast becoming a full-fledged computing platform that our society depends upon. Smartphone applications that access data and computing resources in the \"cloud\" are inevitable given the processing and storage limitations on the phones. Today the burden of partitioning smartphone applications between the phone and the cloud lies squarely with the programmer. This manual approach to partitioning applications is fundamentally limited and will not scale up to allow smartphones to become a truly rich and robust computing platform. Manual partitioning is tedious and error prone. Moreover, manual partitioning requires the programmer to make important decisions that cannot be properly made until run time.<br\/><br\/>This project explores the requirements, design, and implementation of a programming system for cloud-enabled smartphone applications that is inherently adaptive, partitioning applications transparently in order to cope with a diverse set of dynamic constraints. The project is studying cloud-enabled smartphone applications from a variety of domains in order to understand application requirements, constraints, and tradeoffs in practice. The project is also pursuing programming models that allow developers to flexibly and declaratively express an application's components along with their dependencies and constraints. Finally, the project is developing a prototype system architecture that collaboratively executes an application on the phone and the cloud subject to the application's requirements. Within a decade, smartphones will transform the way health and lifestyle choices are delivered to much of the population. This project is helping to enable this transformation by making a rich class of smartphone applications much easier to create, adapt, and understand.","title":"EAGER: Collaborative Research: Toward An Adaptive Programming System for Cloud-Enabled Smartphone Applications","awardID":"1048826","effectiveDate":"2010-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["515836"],"PO":["523800"]},"168880":{"abstract":"Communications systems are becoming increasingly commonplace and appear in a vast variety of applications such as: mobile phones, the internet, embedded systems, and medical devices. As systems become more sophisticated, the demands on processors to compute complex workloads also increase for several reasons: large increases in data throughput rates, and the computational tasks required in a sophisticated system become more complex and more numerous. At the same time, power dissipation demands are becoming ever more stringent due to trends such as increased portability requiring battery-powered operation. The objective of this project is to study, design and implement digital processors that utilize novel algorithms and architectures for complex communications systems. Processors across a wide variety of implementation architectures will be examined including: dedicated-purpose processors and many-core arrays. Three complex workloads which are critical components of many modern communications systems will be studied: software-defined-radios (SDRs), Low Density Parity Check (LDPC) decoders, and Multiple-Input Multiple-Output (MIMO) related processing.<br\/><br\/>Results of this research are expected to enable new application capabilities that were previously not possible. Lessons learned from the project will be deployed in two undergraduate courses and one graduate course. The PI is active in several campus-wide and national organizations that work to attract and retain members of under-represented groups to engage in research and complete graduate degrees in science and engineering. Research effort and results will be instrumental in the cross-disciplinary training of future scientists and engineers in the design of future communications systems.","title":"CIF: Small: Efficient Hardware For Complex Communications Processors","awardID":"1018972","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["551167"],"PO":["562984"]},"175062":{"abstract":"Passive radio frequency identification (RFID) tags, which do not have on-tag power sources, have become the standard mechanism for identifying countless objects. Currently, two security-related capabilities are missing from these tags: authentication and transfer-of-ownership. <br\/><br\/>In this project, the PIs propose to re-define the authentication of an RFID tag from being something the tag knows to being something the tag is. <br\/><br\/>In particular, the PIs explore methods to measure the response times of passive RFID tags, which are unique due to manufacturing variances, and use these measured times to uniquely identify (and authenticate) their corresponding tags. (Note that using measured response times is better, in identifying passive RFID tags, than using baseband radio frequency signals because the former does not require high-bandwidth and expensive measuring equipment.) The PIs explore how to augment the functionality of measuring the response times of RFID tags into regular RFID readers. They also develop classification algorithms for comparing the enrolled response times with the observed response times. <br\/><br\/>The PIs also develop privacy-preserving protocols to perform transfer-of-ownership of RFID tags based on the lightweight authentication algorithm described above. The PIs also develop new hardware primitives for transferring ownership of an RFID tag by manipulating the measured response time of the tag in a controlled way such that it is still a function of manufacturing variances.","title":"EAGER: Fingerprinting RFID Tags with Transfer-of-Ownership Capabilities","awardID":"1053286","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[469533,"525965"],"PO":["565327"]},"168660":{"abstract":"This project aims to answer a fundamental question in wireless networking: what is the energy needed to transmit one bit of information over a wireless network? And the related question: how can practical networks be designed to come close to this limit? The motivation is to save energy. It is evident that there is a strong current interest in energy conservation. Currently it is estimated that consumer electronics account for 11% of total residential electricity consumption in the US. While this is not all used on communications, as most devices have wireless capability, wireless communications could account for a significant part of this energy consumption. Clearly, if this energy consumption can be cut in half, the saving is significant. In fact, preliminary results show that by optimizing the signaling, energy consumption in wireless communications can be reduced much more than 50%.<br\/><br\/>As is well known, there are few networks where the exact Shannon capacity has been found. The research therefore approaches the theoretical part of this problem in different ways. For some networks, the minimum energy per bit can be found even if the exact capacity cannot be found. When the exact minimum energy per bit cannot be found, approximations to the minimum energy per bit are sought in the form of a figure within a certain number of dB that is universal over a certain class of networks. A key part of the research will be to look at networks with correlated information and distortion. Joint source-channel coding can reduce the energy consumption beyond what a separate approach can provide. The theoretical approach will be combined with practical coding methods.","title":"CIF:Small: Collaborative Research: Minimum Energy Communications in Wireless Networks","awardID":"1017829","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}}],"PIcoPI":["516912"],"PO":["564924"]},"168781":{"abstract":"Recent advances in sensor technologies and expansion of wired and<br\/>wireless communication protocols enable us to continuously collect<br\/>information about the physical world, resulting in a rich set of novel<br\/>services. The ability to infer relevant patterns from these event<br\/>streams in real-time and at various levels of abstractions to make<br\/>near instantaneous decisions is crucial for a wide range of mission<br\/>critical applications ranging from real-time crisis management to<br\/>security. This project designs, implements, and evaluates a novel<br\/>complex event processing methodology, henceforth called Complex Event<br\/>Analytics (CEA). CEA integrates the capabilities of pattern matching<br\/>from complex event processing with the power of multi-level analysis<br\/>from static OLAP engines to provide multi-dimensional sequential<br\/>pattern analysis over high-speed event streams. The CEA Model<br\/>combines CEP and OLAP techniques for efficient multi-dimensional event<br\/>pattern analysis at different abstraction levels. Based on<br\/>interrelationships in both concept and pattern refinement among<br\/>queries, sequence queries are composed into an integrated event<br\/>pattern hierarchy. OLAP like operations enable analysts to navigate<br\/>from one E-cuboid to another in this event analytics space. CEA<br\/>optimization strategies, including rewriting rules, physical<br\/>operators, and cost-based search algorithms, achieve scalable event<br\/>processing. CEA offers high-performance analytics by maximal shared<br\/>processing of event pattern queries. Experimental studies compare the<br\/>CEA solution to the state-of-the-art, including traditional stream<br\/>query systems and customized event engines. Intellectual merit lies<br\/>in the design, development and evaluation of a novel Complex Event<br\/>Analytics technology for real-time event stream analysis, -- a perfect<br\/>middle ground offering both the sophisticated power of pattern<br\/>matching found in modern event processing systems and the capability<br\/>of online analytic techniques at multiple levels of abstraction of<br\/>OLAP engines. CEA impacts society by facilitating a broad range of<br\/>stream-centric applications ranging from monitoring of hygiene<br\/>compliance to prevent the spread of infectuous diseases in medical<br\/>settings to business intelligence processing, and by integrating<br\/>project activities with education.<br\/><br\/>For further information see the project web site at the URL:<br\/>http:\/\/davis.wpi.edu\/dsrg\/PROJECTS\/CEA","title":"III: Small: Complex Event Analytics","awardID":"1018443","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543520"],"PO":["565136"]},"168550":{"abstract":"This project presents a new paradigm-shift approach in fault diagnosis by investigating network problems without requiring any monitoring sensors or active measurements, and assuming little or no knowledge about the network. The goal is to develop accurate, scalable and cost-effective network problem diagnosis that reason about uncertainty in case of incomplete knowledge without intrusive active probing or network monitoring. This project investigates a novel approach that uses evidential reasoning based on user observations to analyze the end-user views as evidence and compute a combined belief for determining the most possible root causes in overlay networks at real-time. The project also investigates techniques to rank the overlay paths based on their quality. The reasoning results can then be fedback into adaptive active monitoring, and dynamic virtual assignment\/reconfiguration systems to optimize problem monitoring and recovery, respectively. <br\/><br\/>Developing techniques and tools that enable sharing and analyzing end-host observations provide powerful diagnosing capabilities to service providers, system developers, and administrators to in problem determination, characterizing network conditions, configuration debugging and troubleshooting. These techniques are applicable on both overlay and traditional networks. This project enables trained workforce in this area through teaching and supervising students.","title":"CSR: Small: Collaborative Research: Towards Collaborative Overlay Problem Diagnosis Using Evidential Reasoning and Adaptive Monitoring","awardID":"1017237","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563217"],"PO":["565255"]},"167340":{"abstract":"Despite revolutionary advances in how images are recorded, manipulated, and reproduced, our ability to re-create the visual experience remains remarkably limited. Few realistic computer models exist for the characteristic appearance of natural materials such as marble, wood, coral, or skin, or man-made ones such as color-shifting automotive paints. Digitizing and creating realistic images of these substances involves reproducing their interaction with light: the way light is reflected from surfaces, or scattered and absorbed within the materials. Full reproducibility also involves \"printing\" a material as a real, physical object that modulates the light around us. However, it is currently impossible to output complex appearance the way we print color on a paper with fixed gloss, or create shapes using a 3D printer. This project encompasses a comprehensive, collaborative research agenda in computer graphics and related areas, to develop an end-to-end framework for acquiring, representing, and fabricating complex appearance, as well as to understand how it is perceived by the human visual system.<br\/><br\/>The enabling technical idea of the project is to treat materials as thin three-dimensional volumes populated with general scattering sites. This is a radical departure from the hitherto standard approach in computer graphics, which has studied materials purely as surfaces. The volumetric representation subsumes and generalizes the diverse set of conventional representations that currently exist in graphics, including surface-based notions such as bidirectional reflectance (BRDF), spatially varying BRDF, and subsurface scattering distributions (BSSRDF). Moreover, it enables fundamentally improved approaches to efficient yet general acquisition, fast and realistic rendering, and fabrication of objects exhibiting phenomena beyond simple surface reflectance and spatially homogeneous subsurface scattering.","title":"HCC: Large: Collaborative Research: Beyond Flat Images: Acquiring, Processing, and Fabricating Visually Rich Material Appearance","awardID":"1011444","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[448317],"PO":["565227"]},"168671":{"abstract":"The PIs are working on developing and evaluating a data-driven three-phase adaptive, sparse multicore data mining framework for scalable and efficient supervised classification and statistical analysis.<br\/><br\/>Phase-I seeks to characterize data attributes in terms of sparsity, graph-theoretic structure and geometric and numeric measures toward data transformations with a focus on dimensionality reduction. The goal is to explore the trade-offs between quality of solution (accuracy and precision of classification) and total work (sequential computational costs) toward faster, yet improved methods. <br\/><br\/>Phase-II operates on the transformed data to increase the degree of fine to coarse grained concurrency while restructuring the data for enhanced reuse and locality of access. This phase provides a weighted annotated graph model of the computations indicating dependencies, data sharing measures and computational costs.<br\/><br\/>Phase-III utilizes this model to formulate and explore architecture-aware mappings of data mining computations to the multicore processors, including cache and bandwidth aware thread-to-core mappings that consider both performance and power. <br\/><br\/>The PIs thus seek adaptations to utilize data set attributes, including approximations and concurrency of computations latent in the sparsity structure, toward improved utilization of processor and memory hardware on current and future multicores with larger core counts, complex cache hierarchies and off-chip bandwidth constraints.","title":"DC: Small: Adaptive Sparse Data Mining On Multicores","awardID":"1017882","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["550407","542016"],"PO":["565255"]},"168792":{"abstract":"The project addresses the fundamental challenge of grounding high-level semantic concepts about events into low-level video data. The key innovations include: (1) Representing events via probabilistic event logic (PEL) along with corresponding inference and learning algorithms, (2) Video segmentation into a hierarchy of space-time tubes, and (3) Robustly grounding PEL into space-time tubes via AND-OR grammars. Space-time tubes are extracted by tracking candidate object boundaries across frames, where both boundary detection and tracking are learned from training videos. PEL allows for arbitrary, probabilistic, spatiotemporal constraints among events, including the traditional compositional rules, Allen relations between time intervals, and correlations among different events. Unlike existing work, the logical nature of PEL allows humans, even non-experts, to easily inject their own knowledge into the system. PEL conducts joint, holistic inference to find the globally best parse over all events, which is grounded in an AND-OR grammar of primitive events. The AND-OR grammar uses robust graph matching of video tubes for handling uncertainty in low-level visual processing. <br\/>For evaluation, two video datasets of American football and a building?s atrium are compiled, with fully annotated event labels, object tracks, and spatiotemporal segmentations. <br\/><br\/>Training is provided for graduate and undergraduate students, including those from under-represented groups. The project is expected to: (a) advance the state of the art which typically focuses only on video classification; (b) make the two datasets public; (c) generate workshops\/tutorials on the related topics; and (d) produce publications in the highest-impact journals\/conferences.","title":"RI: Small: Grounding Probabilistic Event Logic in a Hierarchy of Video Segmentation Tubes","awardID":"1018490","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["551065","542093"],"PO":["564316"]},"168561":{"abstract":"Database systems are valued today on account of their ability to manage complex information and efficiently process queries on large data sets. However, they are difficult to use, requiring careful design of database structure, and precise specification of queries to match this structure. In consequence, there is a large barrier to adoption. This project seeks to remove these burdens from the user through the notion of organic, rather than engineered, creation of both database and queries.<br\/><br\/>This project is developing databases that can be used even before the complete structure is specified. In the beginning, before much information is added, there may even be no structure at all. Over time, the user will be able to grow and evolve the structure organically as data is added and needs change. This project is also developing querying techniques for databases that reduce the burden on the user to specify a query exactly, and to know both the structure of the database being queried and the desired structure of the query result. This project, in contrast, will allow users to state an information need incrementally. Rather than structuring the result at the time of query specification, the user will be able to manipulate and structure the result set. These benefits are accomplished through the use of a presentation data model, which is implemented in the database system as a full-fledged layer above the logical and physical data model layers. <br\/><br\/>Biomedical database applications are employed to test and refine the developed system. The research results are expected to greatly improve the way databases are used by both technical and non-technical users and to influence a generation of research in data management. Additional information about the project is available at http:\/\/www.eecs.umich.edu\/db\/usable\/.","title":"III: Small: Usable Databases Through Organic Technology","awardID":"1017296","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["533266"],"PO":["565136"]},"168682":{"abstract":"The growing power of supercomputers provides significant advancements to the scientists' capability to simulate more complex problems at greater detail, leading to high-impact scientific and engineering breakthroughs. To fully understand the vast amounts of data, scientists need scalable solutions that can perform complex data analysis at different levels of detail. Over the years, visualization has become an important method to analyze data generated by a variety of computationally intensive applications. The selection of visualization parameters and identification of important features, however, are mostly done in an ad-hoc manner. To enable the user to explore the data systematically and effectively, in this collaborative research effort involving the Ohio State University and the Michigan Technological University, the PIs explore an information-theoretical framework to evaluate the quality of visualization and guide the selection of algorithm parameters.<br\/><br\/>The research team plans to develop a four-tier analysis framework based on information theory. The bottom tier of the framework consists of the components of information measures where data are modeled as probability distributions. Based on the information measurement components, in the tier two of the framework the most common visualization algorithms including isosurface extraction and flowline generation are evaluated and optimized to effectively reveal the most amount of information in the data. The PIs also investigate issues related to information measurement in image space and optimize the direct volume rendering results. The tier three of the framework is focused on the analysis of time-varying and multivariate data sets. Methods for identifying important spatio-temporal regions in time-varying data sets and to measure the information flow in multivariate data sets to identify the causal relationship among different variables will be developed. In the fourth tier of the framework, the information theory is used to assess the quality of different levels of detail in multi-resolution volumes and images, and to select the level of detail to optimize the visualization quality while satisfying the underlying performance constraints.<br\/><br\/>The key accomplishment of this project will be the development of a rigorous information theory based solution to assist scientists in comprehending the vast amounts of data generated by large-scale simulations and effective visualizations. To target the research at real world applications, the PIs are collaborating with the combustion scientists at Sandia National Laboratories who are at the forefront of their field to employ extreme-scale computing to solve the most challenging problems. The four-tier information-theoretic framework will be implemented using the Visualization Toolkit (VTK), which is to be released to general users. New algorithms and techniques developed in the project will be disseminated through the project web site (http:\/\/www.cse.ohio-state.edu\/~hwshen\/Research\/NSF_GV2010), presentations at the annual visualization and application-specific conferences that the PIs have been actively participating in. Dissemination plan will also includes reaching general audiences through news, stories, and presentations to enhance their understanding and appreciation of the value of visualization. This project provides training to graduate, undergraduate, and underrepresented students in the area of computational science and large-scale data analysis and visualization.","title":"GV: Small: Collaborative Research: An Information-Theoretic Framework for Large-Scale Data Analysis and Visualization","awardID":"1017935","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["550368"],"PO":["563751"]},"168451":{"abstract":"Modern malware is used extensively in computer crime and cyber-warfare<br\/>and poses a serious threat to the cyber-infrastructure of the United<br\/>States, at the military, civil, and corporate levels. Malware can<br\/>employ a number of techniques to gain access to needed resources and<br\/>to prevent detection, including hooking or modifying system calls,<br\/>adding new system calls, inserting new kernel modules, and directly<br\/>patching kernel code. Furthermore, malware is increasingly stealthy,<br\/>being both difficult to detect and to analyze, and current-generation<br\/>schemes for detection, analysis, and mitigation will become<br\/>increasingly ineffective as the trend toward additional stealth<br\/>increases, with more esoteric infection vectors, complex packing<br\/>schemes, polymorphism, and metamorphism being employed.<br\/><br\/>This proposal leverages emerging live digital forensics techniques, to<br\/>create powerful techniques for malware detection and mitigation. These<br\/>live forensics techniques deeply analyze memory dumps and build<br\/>accurate models of kernel and application structures that reflect the<br\/>state of the machine at the time of an investigation. By integrating<br\/>live forensics techniques into a virtual machine monitor (VMM) and<br\/>developing hardware-supported introspection techniques to analyze<br\/>system state, malware detection facilities can be created that prevent<br\/>malware from interfering with detection and mitigation strategies.<br\/>The proposal discusses a number of necessary tasks to support this<br\/>research agenda, including the design of and development of a<br\/>hardware-assisted VMM introspection architecture and deep, portable<br\/>modeling of kernel data structures and other guest VM state, including<br\/>the filesystem. These modeling techniques can then be used for<br\/>real-time verification of critical kernel code, cross-verification of<br\/>kernel structures, application state analysis, and protection of<br\/>critical system files. A novel aspect of the proposed research is the<br\/>use of commodity Graphics Processing Units (GPUs), protected by<br\/>hardware directed-I\/O virtualization, as malware detection<br\/>accelerators.<br\/><br\/>The intellectual merit of the proposed research is to increase the<br\/>depth, flexibility, and capabilities of introspected live forensics<br\/>analysis and to expand the scope of live forensics to the detection of<br\/>sophisticated malware. The proposed techniques expand<br\/>state-of-the-art in live forensics techniques, virtual machine<br\/>introspection, and kernel-level malware detection and will provide a<br\/>foundation on which to build even more powerful techniques. The<br\/>broader impacts of the proposed work touch all sectors of society,<br\/>since individual citizens, as well as the law enforcement, military,<br\/>and corporate communities all benefit from the deployment of more<br\/>sophisticated malware detection mechanisms. The proposed work also<br\/>enhances the existing curriculum in information assurance at the<br\/>University of New Orleans, since research results from this effort<br\/>will be incorporated into both undergraduate and graduate courses,<br\/>exposing students to an important area of study in which the supply of<br\/>practitioners falls far short of the demand.<br\/><br\/>For further information see the project web site at the URL<br\/>http:\/\/www.cs.uno.edu\/~golden\/live-forensics.html.","title":"TC-Small-Virtual Machine Introspection-based Live Forensics for Detection of Malicious Software","awardID":"1016807","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":[450955],"PO":["564388"]},"168572":{"abstract":"Wireless sensor network technology is being considered for many real world applications that require high reliability and long lifetimes. For example, new, low cost wireless sensor networks (WSN) can be embedded into large city skyscrapers to support fire detection and reaction. Such systems must reliably detect a fire on any floor, activate alarms, notify fire stations, and announce and illuminate egress routes. These buildings are passively monitored for hazards and are largely unattended. However, such systems require high confidence in their operation and must also be able to demonstrate that they are operational on a periodic inspection basis (at a minimum). This project determines how to specify and support, at runtime, a collection of solutions that enable embedded systems to improve confidence and demonstrate application operability. <br\/><br\/>The project is novel in several ways. First, it develops a requirements language that permits designers to specify, via a combination of declarative statements, invariants, and rules, the runtime assurances required for high confidence. The language addresses application semantics, the statistical nature of WSN, costs, future predictions on system performance, and monitoring needs for various mechanisms. It also permits automatic code generation. Second, a runtime assurance methodology and framework is developed that supports specific demonstrations of a system?s key functional capabilities on demand and offers a well defined set of diagnosis capabilities including data mining when the system fails to meet its assurances. Third, various runtime mechanisms are created and used in novel ways including virtual event generation and real event replay. Fourth, as a system evolves solutions for understanding the system model as applied to controller design are developed. Fifth, an implementation and evaluation in an application domain is undertaken. Broad impact of the work is possible because similar issues exist for WSN applications in industrial plants, home and assisted living health care, and transportation. A set of course modules is developed and incorporated into two current course offerings at the University of Virginia: Wireless Sensor Networks and Cyber Physical Systems. The corresponding teaching materials (slides and labs) are available for use at other Universities via the Web. The School of Engineering Office of Minority Affairs is used to match minority students with this research.","title":"CSR: Small: Maintaining System Operation in Wireless Sensor Networks Over Long Lifetimes","awardID":"1017363","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550342","543576"],"PO":["565255"]},"168693":{"abstract":"In many applications, from undersea to space, an autonomous agent is given a set of operational goals to achieve optimally, while taking into account the uncertainties that arise from uncontrollable events. For example, in a monitoring mission for an autonomous under-water vehicle (AUV), the goal might be to maximize scientific return, while avoiding hazards. Due to uncertainty, it is unrealistic for many real-world mission to guarantee 100% success. One approach explored extensively within the decision-theoretic planning community is to maximize an objective that trades risk for utility. However, this does not provide any hard guarantees. An alternative approach, commonly employed in engineering practice is to specify risk as a hard constraint, in terms of an upper bound on mission failure (called a chance constraint). For example, NASA Mars missions are designed to meet or exceed a requirement on the probability of successful landing; human-rated vehicles are designed to similar requirements. Given a chance-constrained mission, an agent performing the mission may strive to maximize expected reward, while ensuring that the chance constraint and other operating constraints are met. <br\/><br\/>This research is developing a model-based executive that achieves goal-level plans within specified risk bounds, while attempting to maximize expected reward. Key attributes of this executive include: 1) user specification of time-evolved goal behaviors; 2) plan execution by generating a sequence of discrete and continuous actions for controlling the plant; and 3) optimal, stochastic planning of control actions within risk bounds and dynamic constraints. The research under this grant is laying the groundwork for longer-term objectives of facilitating continuous adaptation of the initial plan and allocation of risk as uncertainties are resolved during plan execution. Among other applications, we plan tests with AUVs engaged in scientific missions, measuring performance within obstacle-related, time and energy bounds.","title":"RI: Small: Plan Execution for Continuous Dynamical Systems Within Risk Bounds","awardID":"1017992","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["461208"],"PO":["562760"]},"168462":{"abstract":"Intelligent systems, both artificial and biological, must find effective ways to organize a complex visual world. The cross-disciplinary field of scene understanding is in need of a comprehensive framework in which to integrate cognitive, computational and neural approaches to the organization of knowledge. <br\/><br\/>This research program aims to create a framework for organizing knowledge of visual environments that human and artificial systems encounter when navigating in the world or browsing visual databases. The aim is to determine which taxonomies are best suited for solving different visual tasks, and use computer vision algorithms to organize visual environments as humans do. For example, semantic relationships between scenes are well captured by a hierarchical tree (e.g. a basilica is a type of church, which is a type of building) but functional similarities between different environments may be best represented as clusters (e.g. restaurants, kitchens and picnic areas clustered as places to eat; offices and internet caf\u00e9s as places to work). <br\/><br\/>Because hierarchies and taxonomies provide a way of formalizing many types of contextual information (spatial, temporal, and semantic), they can be used to enhance the performance of computer vision systems at object and scene recognition, and aid in the development of smarter image search algorithms. <br\/><br\/>Besides serving as a unified benchmark for comparing different models and theories, this enterprise offers new teaching and applied tools for research and courses, which will be made available through websites and symposia.","title":"RI: Small: Hierarchical Visual Scene Understanding","awardID":"1016862","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["509344"],"PO":["564316"]},"168374":{"abstract":"Emerging computational RFID (Radio Frequency IDentification) tags combine sensing and computation with traditional RFID technology. The combination allows small, long-lived sensors that are as unobtrusive as a sticker to be placed on everyday objects and read when they are in the proximity of an RFID reader. The technology is an enabler for ubiquitous computing, cyber-physical systems, and sensor networks. This project is developing computational RFIDs as a networked system, with an emphasis on operating system software and hardware support on the computational RFID tags and network protocols that will support new applications. One key research challenge is that these devices are extremely energy limited and dependent on the varying energy they can harvest; the tags must schedule tasks well to use energy effectively. A second research challenge is to design network protocols that are well suited to computational RFID, since traditional RFID protocols are intended for repetitive inventorying tasks and sensor network protocols assume that nodes have symmetric abilities. The approach taken is experimental. The project is building software support and hardware extensions on an existing computational RFID tag, and prototyping candidate applications. The impacts of this research will be to extend the coverage with which computing systems can instrument the physical world, which in turn enables new applications, such as automated activity detection for eldercare, that are beneficial to society. The software and hardware developed as part of this project will be made available to other researchers and for educational use.","title":"NeTS: Small: RFID-Based Networking","awardID":"1016487","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543394"],"PO":["565303"]},"168495":{"abstract":"The research involves the design and analysis of a framework to compute the spatial arrangements, also known as conformations, in which a protein chain of amino acids is biologically-active (in its native state). This is an important goal towards understanding protein function. While proteins are central to many biochemical processes, little is known about millions of protein sequences obtained from organismal genomes.<br\/><br\/>Intellectual Merit: The intellectual merit of this work lies in the development of a novel computational framework that combines probabilistic exploration with the theory of statistical mechanics to efficiently enhance the sampling of the conformational space near the native state. Low-dimensional projections guide the exploration towards low-energy and geometrically-diverse conformations. Additional intellectual merit lies in the incorporation of knowledge and observations emerging from biophysical theory and experiment, such as the use of coarse graining, relation between energy barrier height and temperature, and hierarchical organization of tertiary structure. Algorithmic components of the framework will be systematically evaluated for efficiency, accuracy, and how they enhance the sampling of the conformational space near the native state.<br\/><br\/>Broader Impact: The broader impact of this research will be the creation of a filter that efficiently computes diverse coarse-grained conformations relevant for the protein native state that can then be further refined through detailed biophysical studies. The work lies at the interface between computer science and protein biophysics and can benefit both communities. On the computational side, the work will lead to new algorithms on modeling articulated chains characterized by continuous high-dimensional search spaces and complex energy surfaces. On the biophysical side, the framework will elucidate which aspects of our understanding of proteins allow efficient and accurate modeling. The work will impact both undergraduate and graduate students. New courses are proposed by the investigator as part of efforts to introduce computational biology in the computer science curriculum at George Mason University. The work will be employed as a pedagogic device in courses and educational outreach venues to spawn and maintain interest in computer science, with a particular focus on women and minorities.","title":"AF: Small: A Unified Computational Framework to Enhance the Ab-Initio Sampling of Native-Like Protein Conformations","awardID":"1016995","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":["565088"],"PO":["565223"]},"168275":{"abstract":"Computer malware codes are usually heavily obfuscated via a variety of techniques that make it difficult to understand the logic of the code. Existing tools for malware analysis do not provide much support for automatically removing such obfuscations, which therefore requires a great deal of time-consuming manual intervention. This project aims to develop techniques and tools to automate the identification and removal of obfuscation code from malware programs, focusing in particular on a class of obfuscations called \"virtualization-based obfuscation\". It uses program analysis techniques to identify instructions that affect the program's observable behavior; these instructions are extracted and, where appropriate, simplified to obtain the deobfuscated malware code. The main impact of this project will be to make it easier and quicker for security researchers to figure out the internal logic of malware programs. This, in turn, will make it possible to respond more quickly to new malware and develop countermeasures to them faster and with less manual intervention. The effect will be to reduce the damage done by malware before they can be neutralized.","title":"SHF: Small: Reverse Engineering Obfuscated Executables","awardID":"1016058","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550173"],"PO":["564388"]},"159376":{"abstract":"Many of the most important functions in society are undertaken by large groups or teams. Emergency response, product development, health care, education, and economic activity are pursued in the context of large, dynamic, interacting networks of groups. Theory and research on such networks of groups is much less developed than research on isolated small groups or formal organizations. A major challenge for research on networks of groups is the difficulties that accompany the collection and analysis of the huge bodies of high resolution, high volume, observational data necessary to study these large, dynamic networks of groups. The goal of this project is to address this challenge by applying advanced computing applications to capture, manage, annotate and analyze these massive observational sets of video, audio, and other data. The resulting data analysis system, GroupScope, will enable breakthrough research into social interaction in large, dynamic groups to be conducted much more quickly and with much higher reliability than was previously possible. It will do this by automating as many functions as possible to the highest degree possible, including managing huge volumes of video, audio, and sensor data, transcription, parsing audio for critical discourse events, annotation and indexing of video streams, and coding interaction. These first pass analyses can then be supplemented by human analysts (and their analyses in turn will feed into machine learning that will improve the computerized analysis). <br\/><br\/>GroupScope will be developed with the collaboration of social scientists studying emergency response teams, children's playground behavior, distributed teams, and product development teams. When developed, GroupScope will be deployed in a cyberenvironment, a Web 2.0 based cyberinfrastructure that enables a community of researchers to collaborate on common problems. The cyberenvironment will enable multiple researchers to analyze and code the same group data for both small groups and large dynamic groups and networks. Multiple analyses and codings working from diverse perspectives will enable discovery of previously unsuspected relationships among different levels and layers of human interaction. They can also be linked to survey responses from participants, enabling linkage to the realm of perceptions and traits. <br\/><br\/>Many of the most fundamental advances in science have come through the development of new instruments, such as more powerful telescopes or microscopes that can allow scientists to view molecules. In the same way GroupScope will shed light on the workings of critical functions performed by real world groups such as emergency response units, health care teams, stock exchanges, and military units. GroupScope will also have applications in the training of those working in multi-team systems, such as first responders to disasters. It can be used to record and \"grade\" training sessions, giving participants feedback on both strengths and weaknesses of their approaches.","title":"CDI-Type II: Collaborative Research: Groupscope: Instrumenting Research on Interaction Networks in Complex Social Contexts","awardID":"0940851","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["532398"],"PO":["513851"]},"174590":{"abstract":"This award provides funding support for 10 full time students from US-based institutions to attend the IEEE Global Communications Conference, the premier telecommunications event for industry professionals and academics from companies, governmental agencies, and Universities. This international conference is held in Miami on December 6-10, 2010. For over five decades, IEEE's Global Communication Conference has brought together engineers and professionals from around the globe to share ideas and new perspectives on a wide range of communications technologies. By promoting achievement and innovation in technology and engineering. This conference facilitates the assembly of prominent scientists from academia, governments and industries to discuss the emerging and multi-disciplinary frontiers of networking and communications? technology. This Conference organizes a number of free tutorial sessions in several major and timely areas of communications and networking. Further to the above learning opportunity, the students can also attend various workshops that are organized for this event and become familiar with the latest trend and advancement in the area of information and communications technology. In addition, this Conference integrates research and education, and provides an environment which stimulates the collaboration among various disciplines. It also provides a unique opportunity to further enhance and raise the knowledge of students specifically underrepresented minorities and women students and in general trains skilled and educated workforce for our society. Upon their return, these students can share their gained knowledge and experiences with other students and faculty in their respective Universities.","title":"Global Communications Research Student Support","awardID":"1050258","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[468323],"PO":["557315"]},"164481":{"abstract":"New paradigms for socio-technical knowledge exchange, especially within and across academic disciplines, is important in order to generate insights about how new knowledge is (and can be) created. Academic researchers regularly use Web-based tools such as wikis, blogs, electronic repositories and open publishing systems to promote the open exchange of knowledge, but with varied levels of success. This work creates an open knowledge exchange system that is based on socio-technical principles, one conducive to collaborative research and the generation of new knowledge. This work will facilitate an egalitarian review process, provide support for micro-contributions as well as full-length reviews of working papers, and allow for immediate feedback on the relevance and utility of contributions. The work begins with a conceptual design and develops a socio-technical system comprised of existing tools as the basis for a KES openly accessible and available to all. It will gather data for future analysis of user behaviors and outcomes to assess the relevance, adequacy and performance of the system?s functional elements.<br\/><br\/>Intellectual Merit: This work will identify new knowledge about the participants, interactions, and contributions required for a successful, community-mediated system of open academic exchange. <br\/><br\/>Broader Impact: OKES will provide a research-driven blueprint for launching and operating an open, academic knowledge exchange, which promises to enrich the academic research climate for many fields. It will help students and practitioners in industry more actively engage in knowledge generation, and produce a rich research dataset to support follow-on studies.","title":"SoCS: OKES: An Open Knowledge Exchange System to Promote Meta-Disciplinary Collaboration Based on Socio-Technical Principles","awardID":"0968445","effectiveDate":"2010-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[440621,440622,440623,"487172",440625],"PO":["563324"]},"173072":{"abstract":"Proposal #: 10-42644 & 10-42642<br\/>PI(s): Fortes, Jose & Winston, Flaura K.; Zonfrillo, Mark<br\/>Institution: University of Florida & The Childrens Hospital of Philadelphia<br\/>Title: SpProj.: Collab Rsch: Adaptive IT Appliance for Collaborative Review of Child-Death Cases<br\/>Project Proposed:<br\/>These collaborative projects, investigating techniques for the creation, deployment, and management cyberinfrastructure for collaborative review of cases of child death, aim to identify strategies to improve children?s safety. In this context, cyberinfrastructure encompasses the tools and services, encapsulated in an IT appliance) needed for capturing, communicating, authoring, viewing, sharing, controlling access to, storing, and conferencing about data and information regarding events resulting in the children?s death. The project builds on an existing functional IT appliance developed for collaborative mechanisms of injury to children in motor vehicle crashes. Enabling its extension, this appliance could quickly be adapted to a more diverse range of causes of death, allowing for different kinds of participants with varying degrees of security and privacy. The work is expected to enrich the presentation of death scenarios for quicker analysis of their causes, leading to more efficient identification of potential prevention strategies. Expected contributions within the research thrusts include techniques for:<br\/>- Automatic generation of interfaces, integration of components and services, and recovery of domain-specific collaborative IT appliances and<br\/>- Fine-grained spatio-temporal access-control of shared objects.<br\/>Broader Impacts: <br\/>This project addresses a real need for easy-to-use tools that reflect semantics and workflow collaborative activities by non-IT experts as undertaken by professional teams engaged in child death reviews. The project engages graduate students in advanced IT research. Minorities and women will be recruited and encouraged to apply.","title":"Collaborative Research: Adaptive IT appliance for collaborative review of child-death cases","awardID":"1042644","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["540130"],"PO":["557609"]},"168870":{"abstract":"This research aims to develop an optimization-based approach to network information theory, that goes well beyond current networking theory and practice. There is a great deal of recent interest in the problem of simultaneous information transmission among many users over wired and wireless networks. Information theory is well poised to have an impact on the manner in which such future networks are designed and maintained, both because wired networks are ripe for applications such as network coding (where information streams are actually combined rather than simply routed) and also because wireless networks cannot be satisfactorily dealt with using conventional networking tools. The challenge is that even the simplest network information theory problems are notoriously difficult and, as a result, information theory has not been able to provide many tools to network practitioners. The research aims to remedy this situation by developing tools for more effective network design. <br\/><br\/>While, in principle, it is possible to obtain the information-theoretic rates in wired networks via convex optimization over the space of entropy vectors, this effort is severely hampered by the fact that an explicit characterization of the entropic space does not appear to be within reach. To circumvent this, the research will consider frameworks that, while possibly suboptimal, apply to arbitrary networks, have reasonable complexity and lend themselves to distributed implementation. The mathematical approach taken is four-fold and makes use of the representation theory of matroids (to design linear network codes), Monte Carlo Markov chain methods to distributedly design \"good\" network codes, group-theoretic techniques to construct nonlinear network codes from non-Abelian groups, and determinantal inequalities to study the entropic space.","title":"CIF: Small: Information Flow in Networks: Entropy, Matroids and Groups","awardID":"1018927","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[451966],"PO":["564924"]},"165482":{"abstract":"Improvisational Theater for Computing Scientists is a pilot project designed to evaluate use of the performance art of improvisation to develop the creative capacity of individuals and groups in science education and research in the emerging field of computational biology. The ultimate research question for this project is whether training in improvisational theatre can provide scientists and science students with the ability to generate new inquiry spaces for their research? Scientists and science educators are rarely taught how to build creative environments that encourage open exploration and risk taking. In contrast performers in improvisational theatre are explicitly trained to develop such environments and their ability for experimentation and risk taking. Improvisational theatre (IT) training is an established approach for stimulating creativity and team collaboration in business, early education and engineering design. This emergent, collaborative idea generation and experimentation can lead to creative and transformative actions for the individual as well as the ensemble. Science education and research positioned as an improvisational, ensemble performance may give the ?actors? in the sciences the required lens for transforming their research and training into a continuous creative and innovative process. This is crucial for the field of computational biology, as it is reliant on the generation of new scientific relationships, synergies and integrative methodologies.<br\/><br\/>Over the course of this project, educators, scientists and students in computing and computational biology disciplines will be brought together in improvisational theater workshops led by creative artists to 1) learn the principles of improvisational theatre 2) develop their ability to build creative, social risk-taking environments 3) develop indicators of creativity specific to the field of computational biology and 4) design improvisation exercises for creativity in computational biology that can be incorporated into the computational biology curriculum. A broad dissemination of the project results to journals and conferences in biology education, computational science and computing is anticipated. Improvisational exercises for concepts and creativity in computational biology will be made available via the project website and incorporated into submitted presentations and workshops at computing science symposiums and conferences that support scientific communities in the biosciences and support broadening participation initiatives for women and underrepresented minorities in the computing sciences.","title":"Pilot: Improvisational Theater for Computing Scientists","awardID":"1002878","effectiveDate":"2010-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["465048"],"PO":["565227"]},"168650":{"abstract":"The most dramatic gains in compute density in the last decade have come from graphics processing units (GPUs) rather than central processing units (CPUs). Unfortunately, current operating systems (OSes) do not provide the same kind of high-level programming abstractions for GPUs that applications expect for other resources like CPUs, input devices, and file systems. OSes hide GPUs behind an awkward ioctl interface, shifting the burden of abstraction onto user libraries and run-times.<br\/><br\/>New technologies require new abstractions. Rich interfaces like recognizing gestures, brain-computer interfaces, and audio\/visual interfaces are highly compute-intensive. Because they process voluminous data under real-time constraints, they are beyond the capabilities of modern CPUs. These workloads rely on data-parallel algorithms, making GPUs an ideal resource to accelerate these tasks, but some form of OS support is required to ensure safe interaction with the user.<br\/><br\/>The SymbiOS model is a fundamental reorganization of kernel abstractions for managing interactive, massively parallel devices. The kernel must expose enough of the hardware detail of GPUs to allow programmers to take advantage of their enormous processing capabilities, but must hide programmer inconveniences like memory that is incoherent between the CPU and GPU. Under the SymbiOS model, GPUs are promoted to first-class computing resources, with traditional OS guarantees such as fairness and isolation.<br\/><br\/>The goal of this project is the design and development of OS abstractions for GPUs, and implementation of several case-studies including a gesture-driven UI that leverages the SymbiOS Model to deliver real-time performance on commodity GPU hardware.","title":"CSR: Small: Operating System Abstractions for GPU-Accelerated Interactive Applications","awardID":"1017785","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["555324",451419],"PO":["565274"]},"167440":{"abstract":"Cooperation and Learning over Cognitive Networks<br\/>Studies on herding and self-organization in economics and the social and biological sciences have observed that coordination among multiple agents leads to regular patterns of behavior and swarm intelligence, even when each group member shows limited behavioral complexity. In ant colonies, for example, individual ants cannot capture rich spatial information from their environment because of their limited sensing ability. Nevertheless, when the ants coordinate their activities within a colony, the group ends up exhibiting better sensing abilities. Using signal processing and communications techniques, the research studies how and why such manifestations of rational and organized behavior arise at the group level from local interactions among agents with limited abilities, what communication topologies enable such behavior, and what type of signal processing enables such formations. <br\/><br\/>This research seeks to understand and reverse-engineer the distributed intelligence encountered in socio-economic-biological networks, by investigating relations with learning and rationality over cognitive networks. The latter are adaptive networks that avoid centralized information processing and perform in-network inference and control decisions. Cognitive networks contrast with networks that rely on centralized and parallel information fusion, which are not scalable, are hard to adapt to changing topologies, and suffer from points of vulnerability and information bottlenecks. The research considers large scale networks of agents and studies how global (rational or irrational) patterns of behavior emerge, including herds, contagions and bubbles in economics. An understanding of how the biotic environment influences collective behavior in animal societies provides a real world guide to good cognitive networks, which can be used in turn to design engineered systems. Cognitive networks have applications in areas ranging from precision agriculture, to environmental monitoring, disaster relief management, and smart spaces.","title":"CIF: Large: Collaborative Research: Cooperation and Learning over Cognitive Networks","awardID":"1011903","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":["451785"],"PO":["564898"]},"168771":{"abstract":"Research on multiple-input, multiple-output (MIMO) communications has shown that using multiple antennas can dramatically improve the capacity of wireless channels. Since wireless devices are limited in size, using multiple antennas often requires close spacing which leads to coupling among the antennas. Coupling can profoundly impact the received power, diversity and system capacity. Moreover, this impact depends not only on the antennas and how they are arranged in space; it also depends on detailed aspects of the wireless transceiver, such as the impedance matching networks that connect the antennas to the rest of the receiver front end. Current approaches to designing these networks for coupled MIMO systems are intrinsically narrowband and exhibit poor performance under broadband conditions.<br\/><br\/>This project seeks to develop a unified theoretical framework for the design of broadband wireless transceivers. The main idea is that Fano's broadband matching theory provides a characterization of physically-realizable matching networks, while Shannon's information theory provides a way to evaluate how each network could be used to communicate in the best possible way. By combining these theories, this project considers how antennas, matching networks and communications algorithms interact to determine overall system performance, and how best to jointly optimize these components. <br\/><br\/>Three main issues are addressed: new information- and decision-theoretic bounds on the performance of broadband single-antenna systems; extensions to broadband MIMO systems; and information-theoretic design criteria to jointly optimize the antennas, matching networks and communications algorithms. This work has the potential to significantly advance science and engineering by providing a more unified view of the RF front end and by developing new communications and matching techniques that may significantly improve wireless performance.","title":"CIF: Small: From Fano to Shannon: Information Theory and Broadband Matching","awardID":"1018382","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["560179"],"PO":["564924"]},"168540":{"abstract":"Reconstructing the 3D shape of an object from multiple 2D images is a fundamental problem in computer vision. Prior work on this problem usually requires the object of interest to be rigid or the available 2D images to be well organized, such as consecutive frames in a video. This project investigates the challenging problem of reconstructing a nonrigid 3D object from a large number of unorganized 2D images, which may be taken at different times, with different backgrounds, from different perspectives, under different lighting conditions, and\/or using different cameras.<br\/><br\/>The research team develops new algorithms of combining object localization, feature matching, and partial shape matching across the images to segment the 2D object of interest from the input images. The segmented 2D objects are organized into clusters to recover the underlying 3D nonrigid deformation. Pieces of the 3D object are reconstructed from these clusters and finally assembled to obtain the complete 3D object by removing the in-between nonrigid deformations. An image database with 2D images of selected nonrigid objects is constructed for performance evaluation.<br\/><br\/>This research benefits many applications in computer vision, computer graphics, computer gaming, zoology, microbiology, marine science, and medical research, which all involve the modeling of 3D norigid objects. Progress made on object localization, feature matching and partial shape matching has immediate applications in object detection, object recognition, image search, surveillance, tracking, and segmentation. This research also provides an excellent setting for the training of both undergraduate and graduate students.","title":"RI: Small: 3D Nonrigid Object Reconstruction from Large-Scale Unorganized 2D Images","awardID":"1017199","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[451161],"PO":["564316"]},"168661":{"abstract":"There has been an increasing shift away from traditions of individual based scientific research toward more collaborative models via online scientific communities. One famous example of scientific online communities is nanoHUB.org powered by the HUBzero platform. nanoHUB has been well received by nanotechnology community and has attracted more than 90,000 active users by providing thousands of resources such as simulation tools, teaching materials and publications. The rapid growth of information in scientific online communities demands intelligent agents that can identify the most valuable to the users. Existing solutions of information recommendation are not adequate for online scientific communities. For example, users in online scientific communities undertake different types of tasks (e.g., seeking teaching materials or conducting experiments for dissertation work) and require recommendation that distinguishes different tasks, which is not provided by existing recommendation solutions. Furthermore, a substantial amount of information from users of online scientific communities is implicit feedback (e.g., click through data). However, most existing recommendation solutions focus on explicit feedback information (e.g., user ratings of movies).<br\/><br\/>The proposed research seeks to overcome the limitations of existing recommendation solutions with a new integrated information recommendation framework for online scientific communities. The proposed research thrusts include: (1) Task-Specific Recommendation: estimate possible tasks undertaken and incorporate the estimation results into the process of making recommendation; (2) Intelligent Hybrid Recommendation: integrate collaborative recommendation and content-based recommendation techniques within a single model that intelligently tunes the weights of content based information and collaborative usage information; (3) Pairwise Comparison Approach for Implicit Feedback: model users? implicit feedback information of recommended resources in a probabilistic model with a natural assumption of pairwise comparison; (4) System Development and Evaluation: integrate proposed algorithms into the HUBzero platform. The research results will be evaluated in carefully designed user studies as well as in real world operational environments (i.e., nanoHUB). <br\/><br\/>The proposed research will yield substantial benefits in broad areas. The information recommendation tool will be incorporated into nanoHUB to benefit a large number of users. The source code of proposed algorithms will be released with the HUBzero platform to enable further advance and development in information recommendation. The proposed information recommendation solutions can be adapted and used in other general purpose social network applications like LinkedIn\/Facebook. Some research topics will be integrated into the courses that the PIs teach. The PIs will encourage the involvement of underrepresented students in the research project.","title":"III: Small: Information Recommendation for Online Scientific Communities","awardID":"1017837","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["535139","535140","548255"],"PO":["565136"]},"167451":{"abstract":"Cooperation and Learning over Cognitive Networks<br\/>Studies on herding and self-organization in economics and the social and biological sciences have observed that coordination among multiple agents leads to regular patterns of behavior and swarm intelligence, even when each group member shows limited behavioral complexity. In ant colonies, for example, individual ants cannot capture rich spatial information from their environment because of their limited sensing ability. Nevertheless, when the ants coordinate their activities within a colony, the group ends up exhibiting better sensing abilities. Using signal processing and communications techniques, the research studies how and why such manifestations of rational and organized behavior arise at the group level from local interactions among agents with limited abilities, what communication topologies enable such behavior, and what type of signal processing enables such formations. <br\/><br\/>This research seeks to understand and reverse-engineer the distributed intelligence encountered in socio-economic-biological networks, by investigating relations with learning and rationality over cognitive networks. The latter are adaptive networks that avoid centralized information processing and perform in-network inference and control decisions. Cognitive networks contrast with networks that rely on centralized and parallel information fusion, which are not scalable, are hard to adapt to changing topologies, and suffer from points of vulnerability and information bottlenecks. The research considers large scale networks of agents and studies how global (rational or irrational) patterns of behavior emerge, including herds, contagions and bubbles in economics. An understanding of how the biotic environment influences collective behavior in animal societies provides a real world guide to good cognitive networks, which can be used in turn to design engineered systems. Cognitive networks have applications in areas ranging from precision agriculture, to environmental monitoring, disaster relief management, and smart spaces.","title":"CIF: Large: Collaborative Research: Cooperation and Learning Over Cognitive Networks","awardID":"1011956","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":[448658],"PO":["564898"]},"168782":{"abstract":"In today's information-centric networked world, concerns about protecting identities and other private information are growing in importance. It is important to establish not only a legal baseline but also a technological baseline that protects such information. At the same time, data search and analysis technologies are emerging that are capable of processing extremely large volumes of information. As a result, research is needed into data analysis technologies that enhance privacy and protect private information in a computationally efficient manner. One important area of technology that supports data analysis is optimization, a set of procedures that make a system as efficient as possible. Solving optimization problems efficiently has been one of the major themes of computer science throughout the history of the field. Unfortunately many optimization problems that need to be solved in practice are unlikely to have efficient algorithmic solutions. To cope with this difficulty, computer scientists have developed numerous practical approximation algorithms along with general techniques for designing such algorithms. Often the optimization problems that need to be solved arise from the analysis of real data with potential privacy restrictions. Importantly, there are no known general tools to design approximation algorithms which are both efficient and provably private.<br\/><br\/>As an initial case study, community discovery in social network analysis will be studied. It is a natural candidate for private approximation for two reasons: first, the underlying social network data in many cases can be sensitive; second, community structure should not depend crucially on any single relation in the network, and, therefore, it should be possible to find a private community discovery algorithm with good utility. The intellectual merit of the project is in the research required to develop general methods for designing efficient differentially private approximation algorithms for combinatorial optimization problems. The project's broader impacts include applications in real-world law enforcement and counterterrorism.","title":"III: RI: Small: Efficient Privacy Methods Using Linear Programming","awardID":"1018445","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["540234",451739],"PO":["565264"]},"168551":{"abstract":"The main objective of the project is to study the fundamental limits and possible modifications of the Adiabatic Quantum Optimization approach to the NP-complete computational problems. PI plans to use the connection of the Adiabatic Quantum Optimization with the theory of Anderson Localization, more precisely its recent extension to the Many-Body problems of Condensed Matter Physics and Statistical Mechanics. By applying techniques used in the Quantum Physics of Complex Systems, PI plans to analyze in details the distribution of small spectral gaps and their effect on the efficiency of the Adiabatic Quantum algorithms for various problems. The connection with the localization implies that the loss of the adiabaticity due to the existence of the exponentially small gaps is likely and the difficulty is fundamental. However, a better understanding of the adiabatic evolution of the complex quantum models, which arise in connection with NP-complete problems, may help to design a modified quantum algorithm that has advantages over known classical algorithms. For example, PI will study possibilities to design quantum algorithms that have advantages over classical heuristics or approximation algorithms, where a local minimum with energy close enough to the global minimum is an acceptable solution. The research under this award is on the edge of Computer Science, Quantum Physics of Complex Systems and Mathematical Physics.","title":"AF: Small: Adiabatic Quantum Optimization, NP-Completeness and Anderson Localization","awardID":"1017244","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7928","name":"QUANTUM COMPUTING"}}],"PIcoPI":[451184,451185],"PO":["565157"]},"168793":{"abstract":"Modern multicore and manycore architectures have a number of new security threats. For example, shared microarchitecture components such as caches, core inter-connection networks, and memory controllers can be exploited for side-channel attacks or denial of service attacks. The evolution of workloads to exploit explicit parallelism will also likely lead to additional new threats. New forms of active viruses and trojans that reside on some cores and attempt to attack other applications are likely to arise. It is critical to anticipate such new forms of threats and design manycore systems in a manner that facilitates defeating them. If security is not treated as a first order design principle, these systems will be highly vulnerable to attacks, leading to enormous losses in money and productivity and a substantial effort to retrofit security in after the fact. The overall theme of this project is to identify and analyze security threats that can arise in a multicore and manycore environment and develop algorithms and techniques to address these threats in a complexity-effective manner and without sacrificing performance. Specific interest is on the techniques and solution patterns that can be reused to help with different threats. These include the use of additional cores and thread contexts to provide security without significant performance losses, and the development of techniques for virtual and physical isolation of shared resources to defend against sidechannel attacks and denial-of-service attacks. In addition, the project explores approaches for trading-off performance and security and also considers security vulnerabilities of new memory technologies.","title":"SHF: Small: Architectural Support for Security in the Many-core Age: Threats and Opportunities","awardID":"1018496","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[451773,451774],"PO":["564388"]},"168683":{"abstract":"This project will enable full-body nonverbal communication in virtual worlds, applying state-of-the-art machine learning and computer animation techniques to the synthesis of nonverbal communication, advancing and refining these techniques in the process. Virtual worlds are an emerging computer-mediated communication medium that situates geographically distributed participants in a shared communication space and enables embodied interaction with others in a simulated environment. Participants are represented as animated virtual humans that can convey both speech and body language. Yet no viable technology exists that can animate the virtual human's body during a live conversation without resorting to esoteric hardware or brittle algorithmic techniques.<br\/><br\/>This research will develop an approach that can convey body language through virtual humans in real time, using a natural control interface: the speech and motion of the participants. The proposal is based on, and sometimes advances, the state of the art in machine learning, computer animation, and the relevant aspects of linguistics and cognitive psychology. Body language animation based purely on visual tracking of the participant's motion is prone to significant defects due to tracking noise and failure. Thus this approach analyzes the speech of the participant together with the motion. This principled integration of live speech and motion input constitutes a fundamentally new approach to the control of nonverbal expression of human self-representations in virtual worlds.<br\/><br\/>The ability to convey rich nonverbal communication in virtual worlds will advance the capabilities of computer-mediated communication as a whole. This will provide basic infrastructure for distributed collaboration in science and engineering. Powerful forms of situated learning and social-scientific inquiry in education will be enabled, with positive impact on the self-efficacy of students who traditionally underperform in science curricula. Social science will be enriched with a new medium for the study of human interaction.","title":"HCC: Small: Body Language Animation for Virtual Worlds and Computer-Mediated Communication","awardID":"1017938","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[451500],"PO":["564456"]},"168452":{"abstract":"Currently there is a significant need for increasing mathematical literacy in the United States. Among other benefits, this would permit more Americans to pursue careers in STEM (Science, Technology, Engineering and Mathematics) disciplines. The most extensive resource for finding introductory information on math, the internet, primarily supports text-based search. Similarly, current Portable Document Format (.pdf) viewers support search for text, but not math. The goal of this research is to develop a query-by-expression mechanism, where users enter expressions using images, stylus\/finger, mouse and keyboard. Users may then search using a combination of the expression appearance, symbols, structure, and mathematical semantics. Expression properties may be combined with text-based search, allowing queries for mathematical information to be more precise than current text-based methods.<br\/><br\/>For query-by-expression methods to be viable, improvements in math recognition are needed, along with the development of efficient methods for indexing and retrieving mathematical expressions. In particular, the project seeks to improve optical character recognition (OCR) for handwritten and typeset mathematics, along with methods for parsing expression structure. Approach based on Graph Transformer Networks (GTN) and adaptations of boosting techniques is applied to intelligent combination of modules that locate, recognize and relate mathematical symbols with an aim to further improve recognition. Research focuses on identifying appropriate features, distance metrics, indexing and search methods for expression retrieval. Developed techniques are evaluated via user studies both in-lab settings and through the internet. Additional user studies to identify appropriate use cases for query-by-expression are also planned.<br\/><br\/>This project is expected to produce new query-by-expression methods usable by both math experts and (perhaps more importantly) non-experts. These methods might be adapted to retrieving other non-textual document elements such as chemical diagrams, tables, and figures. Source code and experimental data developed for the project will be made public via the project web site (http:\/\/www.cs.rit.edu\/~dprl\/msearch.html). To promote mathematical literacy, the principal investigator and graduate students working on the project will visit middle schools and talk about the history, recognition and retrieval of mathematical notation. The PI also plans to participate in the McNair Scholars program at RIT, which seeks to provide research experiences to low-income, first-generation college students that are interested in pursuing doctoral studies.","title":"III: Small: Combining Algorithms for Recognition and Retrieval of Mathematics","awardID":"1016815","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["518471"],"PO":["563751"]},"167484":{"abstract":"This work proposes to design a programmable many-core for Extreme-Scale Computing in mobile platforms (netbooks and smart-phones) of year 2020. This work cuts across the architecture, compiler, operating system, and correctness\/performance tools areas. A key technology explored is that of cores and all of the software continuously operating in Chunks (i.e., atomic blocks) of instructions at a time --- eliminating the need for in-order, single-instruction-at-a-time commit. The PIs will develop a novel chunk-based architecture that supports the high levels of performance, power\/energy efficiency, concurrency, and locality required. They will develop advanced compiler support for chunk generation that delivers high performance at low power, and leverages all the programmability features of the architecture. They will also design an OS that supports and takes advantage of chunks. Finally, they will design a set of novel correctness and performance tools that exploit chunks, signatures, hashes, and all the other features of this architecture.<br\/><br\/>The broader impacts of this work involve the creation of a multidisciplinary research and education center at University of Illinois and Purdue on Programmable Extreme Scale Computing. Faculty of diverse expertise will be devoted to solving the problem of programmable, very-high performance, very power\/energy-efficient many-cores for mobile platforms of year 2020 and beyond. The PIs will broaden the course offerings at University of Illinois and Purdue in the four areas, with multidisciplinary courses at different depth levels. Graduate and undergraduate researchers in ECE and CS will be involved in the research. Overall, the PIs hope to prove that programmable, high-performance, and highly power\/energy-efficient many-cores based on continuous atomic-block operation are attractive.","title":"SHF: Large: Collaborative Research: Designing the Programmable Many-Core for Extreme Scale Computing","awardID":"1012099","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["550995"],"PO":["366560"]},"168342":{"abstract":"This project is developing methods that allow a computer to automatically learn to understand and generate instructions in human language. Traditional approaches to natural-language learning require linguistic experts to laboriously annotate large numbers of sentences with detailed information about their grammar and meaning. In this project, instructional language is initially learned by simply observing humans following instructions given by other humans. Once the system has learned reasonably well from observation, it also actively participates in the learning process by following human-given instructions itself, or giving its own instructions to humans and observing their behavior. The approach is being evaluated on its ability to interpret and generate English instructions for navigating in a virtual environment (e.g. \"Go down the hall and turn left after you pass the chair.\"). A novel machine learning method infers a probable formal meaning for a sentence from the resulting actions performed by a human follower, and then existing language-learning methods are used to acquire a language interpreter and generator. The learned system is being evaluated in a range of virtual environments, testing its ability to follow human-provided natural language instructions to achieve prescribed goals, as well as to generate natural language instructions that humans can successfully follow to find specific destinations. The methods developed for this project will contribute to the development of virtual agents in games and educational simulations that learn to interpret and generate English instructions, and eventually aid the development of robots that can learn to interpret human language instruction from observation.","title":"RI: Small: Perceptually Grounded Learning of Instructional Language","awardID":"1016312","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[450689],"PO":["565215"]},"168584":{"abstract":"The goal of the research is to determine the fundamental, information theoretic limits of when and how to layer multiple wireless networks on shared and\/or unlicensed bands in a seamless and spectrally efficient manner.<br\/>Wireless networks are everywhere: WiFi, Bluetooth, cordless phones populate increasingly dense unlicensed frequency bands. Cellular, satellite, military and first-responder networks occupy exclusively licensed bands that are gradually giving way to dynamic, secondary spectrum sharing forms of licensing. For both types of licensing, it is crucial that multiple wireless networks co-exist in the same finite spectral resources in an intelligent, efficient and scalable manner.<br\/>The time is ripe for a fresh look at how to optimally layer wireless networks, reaching far-beyond today's ``interference-limited'' solutions which combine orthogonal access and the treatment of interference as noise. <br\/><br\/> The research moves away from classical information theoretic single-layer, homogeneous networks to include realistic oblivion constraints on how different layers should interact in a hierarchical fashion. Understanding how to best layer networks constitutes a major step towards eliminating current spectral inefficiencies. The fundamental bounds on the performance of layered networks developed will reveal when incentives for networks to adopt a layered policy exist, which is expected to significantly impact the design of future networks.<br\/>Both distributed and centralized layered networks are investigated, with goals to:<br\/>1) develop a structured framework for layered networks, <br\/>2) derive capacity regions for deterministic layered networks and associated Gaussian layered networks to within a constant gap, <br\/>3) understand layered networks through asymptotic metrics by considering the generalized degrees of freedom of the layered network, the throughput scaling laws with number of nodes in each layer, and the throughput scaling law with number of layers.","title":"CIF: Small: Fundamental Limits of Layered Wireless Networks","awardID":"1017436","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["518391","517407"],"PO":["564924"]},"167495":{"abstract":"Despite revolutionary advances in how images are recorded, manipulated, and reproduced, our ability to re-create the visual experience remains remarkably limited. Few realistic computer models exist for the characteristic appearance of natural materials such as marble, wood, coral, or skin, or man-made ones such as color-shifting automotive paints. Digitizing and creating realistic images of these substances involves reproducing their interaction with light: the way light is reflected from surfaces, or scattered and absorbed within the materials. Full reproducibility also involves \"printing\" a material as a real, physical object that modulates the light around us. However, it is currently impossible to output complex appearance the way we print color on a paper with fixed gloss, or create shapes using a 3D printer. This project encompasses a comprehensive, collaborative research agenda in computer graphics and related areas, to develop an end-to-end framework for acquiring, representing, and fabricating complex appearance, as well as to understand how it is perceived by the human visual system.<br\/><br\/>The enabling technical idea of the project is to treat materials as thin three-dimensional volumes populated with general scattering sites. This is a radical departure from the hitherto standard approach in computer graphics, which has studied materials purely as surfaces. The volumetric representation subsumes and generalizes the diverse set of conventional representations that currently exist in graphics, including surface-based notions such as bidirectional reflectance (BRDF), spatially varying BRDF, and subsurface scattering distributions (BSSRDF). Moreover, it enables fundamentally improved approaches to efficient yet general acquisition, fast and realistic rendering, and fabrication of objects exhibiting phenomena beyond simple surface reflectance and spatially homogeneous subsurface scattering.","title":"HCC: Large: Collaborative Research: Beyond Flat Images: Acquiring, Processing, and Fabricating Visually Rich Material Appearance","awardID":"1012147","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["456692"],"PO":["565227"]},"168353":{"abstract":"Fundamental research is proposed on a novel concept for combined neutron detection and retrieval of information about the level and timing of thermal neutron exposure that may have occurred prior to recovery of the data stored by a miniature, nanocrystal-based sensor. The concept is based on the unique properties of a dominant naturally occurring isotope of dysprosium,Dy, which upon exposure to thermal neutrons converts into a metastable state 165m, and then subsequently decays into a stable isotope of holmium, or, upon capturing a second neutron, into a stable erbium isotope. Combination of the high thermal neutron capture cross section of ~2,650 barns and transmutation into two other lanthanides makes dysporium a good candiate. Dy-containing nanocrystals of various chemical compositions will be synthesized, doped with Ho and Er, and optically characterized for maximum spectral differentiation between the three lanthanides. Reconstruction of data about neutron exposure will then be demonstrated by optical spectral analysis of the nanocrystalline samples. Fundamental research is proposed on a novel concept for combined neutron detection and retrieval of information about the level and timing of thermal neutron exposure that may have occurred prior to recovery of the data stored by a miniature, nanocrystal-based sensor. The concept is based on the unique properties of a dominant naturally occurring isotope of dysprosium, 164Dy, which upon exposure to thermal neutrons converts into a metastable state 165mDy, and then subsequently decays into a stable isotope of holmium 165Ho, or, upon capturing a second neutron, into a stable erbium isotope 166Er. Combination of the high thermal neutron capture cross section of ~2,650 barns and transmutation into two other lanthanides makes 164Dy very attractive for the proposed new sensor. Dy-containing nanocrystals of various chemical compositions will be synthesized, doped with Ho and Er, and optically characterized for maximum spectral differentiation between the three lanthanides. Reconstruction of data about neutron exposure will then be demonstrated by optical spectral analysis of the nanocrystalline samples. The educational component will emphasize collaboration and interactions across traditional academic disciplines, with the proposed project spanning the fields of chemistry, physics, electrical engineering, and nuclear engineering.","title":"Miniature Dysprosium-Based Monitors of Thermal Neutron Exposure History","awardID":"1016352","effectiveDate":"2010-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}}],"PIcoPI":["474428"],"PO":["565136"]},"168364":{"abstract":"Users rely on computers to save valuable data, with the expectation that the data will be available and accessible at any time. Consequently, storage and server systems have to provide stringent reliability guarantees. Many techniques - redundant data copies, multiple servers, and backup hardware - are employed in modern data centers to prevent data loss due to failures. However, these techniques consume more energy either to sustain additional hardware or to perform additional software tasks that keep disks busy longer. This poses trade-offs between using energy management and data reliability improvement - both of which are critical technologies that will direct the future of computer systems development. Thus, this project investigates the combined impact of energy efficiency and data reliability on storage systems. The utilization of a novel metric for capturing the energy-reliability interactions allows for designing optimization techniques that provide integrated reliability and energy management for modern storage systems. The results from this project are expected to lead to a better understanding of the interactions of energy management and reliability improvement techniques in storage systems, and to novel energy-efficient and reliable storage system organizations and designs that balance reliability and energy efficiency. The developed mechanisms will also enable further research in energy efficient and reliable systems at scale. Moreover, the project employs an integrated research and education approach for training both undergraduate and graduate researchers, especially from underrepresented groups. The training will instill critical system development skills and provide valuable learning opportunities in designing energy-efficient and reliable computer systems.","title":"DC: Small: Collaborative Research: Exploring Energy-Reliability Trade-offs in Data Storage Systems","awardID":"1016408","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["468070"],"PO":["493916"]},"167297":{"abstract":"Across many fields of science, engineering, and business, massive data sets are being generated at unprecedented rate by high-bandwidth sensors and cameras, large-scale simulations, or web-enabled large scale data collection. Much of this data has a geometric character, either directly or indirectly. For example, second generation LiDARs can map the earth's surface at 15-20 cm resolution; the Large Synoptic Telescope is set to produce about 30 terabytes of data each night; thirteen hours of video are uploaded to YouTube every minute; Facebook manages over 40 billion photos requiring more than one petabyte of data.<br\/><br\/>These data sets provide tremendous opportunities to enable novel capabilities that were unimaginable a few years ago. Capitalizing on these opportunities, however, and transforming these massive amounts of heterogeneous data into useful information for vastly different types of applications and users requires solving challenging algorithmic problems. An effective way of addressing this challenge is by designing efficient methods for producing informative yet succinct summaries of such geometric data sets. These summaries must work at multiple scales, and allow a wide variety of queries to be answered approximately but efficiently. The goal of this project is to study the theoretical underpinnings of compact representations and efficient algorithms for organizing, summarizing, cross-correlating, interlinking, and querying large distributed geometric data sets.<br\/><br\/>This project will design methods for computing summaries of many kinds of flavors, all with provable properties. Summaries can be combinatorial and metric (core sets and kernels), algebraic (linear sketches), topological (persistence diagrams), feature-based, and structural (encoding self-similarities in the data). The properties they aim to capture extend from low-level metric attributes, such as the diameter or width of a point set, to higher-level attributes revealing the internal structure of the data, as in the detection of symmetries and repeated patterns. This processing must be done in the presence of uncertainty in data coming from sensors, and optimize multiple performance measures, including communication cost for data distributed across multiple locations in a network. Another key aspect of this project is that it aims to understand not individual data sets in isolation but rather the inter-relationships and correspondences among different data sets, and to do so by communicating only summary information, without even having all the data in one place. <br\/><br\/>This work touches upon many topics in theoretical computer science and applied mathematics including low-distortion embeddings, compressive sensing, transportation metrics, spectral graph theory or harmonic analysis, machine learning, and computational topology.","title":"AF: Large: Collaborative Research: Compact Representations and Efficient Algorithms for Distributed Geometric Data","awardID":"1011228","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":["521232"],"PO":["565157"]},"172380":{"abstract":"Cloud computing provides economic advantages from shared resources, but security is a major risk for remote operations and a major barrier to the approach, with challenges for both hosts and the network. NEBULA is a potential future Internet architecture providing trustworthy networking for the emerging cloud computing model of always-available network services. NEBULA addresses many network security issues, including data availability with a new core architecture (NCore) based on redundant connections to and between NEBULA core routers, accountability and trust with a new policy-driven data plane (NDP), and extensibility with a new control plane (NVENT) that supports network virtualization, enabling results from other future Internet architectures to be incorporated in NEBULA. NEBULA?s data plane uses cryptographic tokens as demonstrable proofs that a path was both authorized and followed. The NEBULA control plane provides one or more authorized paths to NEBULA edge nodes; multiple paths provide reliability and load-balancing. The NEBULA core uses redundant high-speed paths between data centers and core routers, as well as fault-tolerant router software, for always-on core networking. The NEBULA architecture removes network (in) security as a prohibitive factor that would otherwise prevent the realization of many cloud computing applications, such as electronic health records and data from medical sensors. NEBULA will produce a working system that is deployable on core routers and is viable from both an economic and a regulatory perspective.","title":"FIA: Collaborative Research: NEBULA: A Future Internet That Supports Trustworthy Cloud Computing","awardID":"1038695","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["508219"],"PO":["565090"]},"174580":{"abstract":"This research will generate new knowledge about the design and deployment of resilient networks using GENI. It will evaluate alternatives for future Internet design using the GpENI infrastructure, under the GENI PlanetLab control framework, and -- stitched together with several ProtoGENI facilities -- perform resilience and survivability experiments at scale, investigating, in particular, the geographic scope needed to emulate large-scale disasters. GpENI provides the ability to construct a large set of arbitrary backbone topologies, while the dense ProtoGENI clusters will emulate both wired and wireless access networks. These experiments will cross-verify analytical and simulation-based resilience research currently underway, leveraging topology and challenge generation tools developed for this purpose, and emphasizing multi-path multi-realm diverse transport protocols. The broader impact of the project includes fulfilling the vision of GENI supporting future internet design, and contributing to the education of graduate students at Kansas Univeristy.","title":"EAGER: Multilayer Network Resilience Analysis and Experimentation on GENI","awardID":"1050226","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["536602"],"PO":["564993"]},"174360":{"abstract":"This project will use a frame of comparative economic systems to gather and analyze data from economies in the most recent virtual worlds and social media. If a coherent system seems to be emerging, it will be interpreted as new territory on the map of the psychology of commerce. These new systems - having been born in the space between real and virtual - might move quite easily into the real world and, there, have a powerful transformative effect. Thus, this project is an effort to move quickly, in the early stages of these rapid technological developments, to see whether the unique but untested economic practices in virtual\/real boundary spaces might have a transformative effect on the real world.<br\/><br\/>To test for potential transformational power, this research will examine a wide variety of virtual economies, from games, social media systems, and 3D immersive platforms, and attempt to identify common features. The functioning of economies will be directly observed by researchers; there will be no research protocols that require human subjects. The common features most likely to be found would include the presence of dual currencies (one entirely virtual, another between real and virtual); commitments to equality of opportunity and fair process; indifference to outcome inequality; and free goods alongside extremely rare goods. As a very rough simplification, we might suppose at this point, prior to any research, that if the virtual economies focus on emotional satisfaction, and the real ones focus on efficiency, the real\/virtual hybrid system seeks policies that promote emotional satisfaction in the most efficient way. Put another way, the new systems will have companies aggressively seeking profits using methods that preserve the customers' fantasy that they are not the target of profit-seeking. If refined, such a strategy could have a heavy impact on commerce in general.<br\/><br\/>Institutions and policies birthed in the space between real and virtual are highly unlikely to remain there. For one thing, much of the real world already operates according to patterns we now label \"virtual.\" For another, history indicates that systems melding freedom and profits with security - born in the drive to create a Third Way - have been incredibly powerful forces in social evolution. Even the United States now has a near-universal health care policy. If technology companies discover how to meld freedom and profits with emotional satisfaction generally- not just a sense of security but also feelings of self-efficacy, significance, and belonging - the models they design may be adopted well beyond the internet. First signs of such a change are emerging, as companies consider how to \"game-ify\" their workplace policies and professional organizations seek to exploit social media and games for serious ends. A general recoding of human organization may be in the offing. Thus while it is still far too early to rest easy on such grand concepts as \"new economic systems\" constituting a \"new way,\" the overall significance of the possibilities warrants an initial exploration and testing.","title":"EAGER: An Exploratory Study of Systems Emerging Between Real and Virtual Economies","awardID":"1049449","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[467760],"PO":["564456"]},"162161":{"abstract":"Award: 0955935<br\/>PI: Theresa A. Pardo<br\/>Title: INTEROP: Building Information Sharing Networks to Support Consumer Choice (I-Choose)<br\/><br\/>Most products consumed within the North American Free Trade Area (NAFTA) are produced and distributed through low cost supply chains that typically do not reveal certain types of information to end consumers. Without this information it is difficult for consumers to assess the quality of the products they buy or exercise their preferences for safe, environmentally sustainable, and economically just products and services. Producers also have much less of an incentive to provide such goods without an effective, trustworthy way to inform consumers. In order to provide full information about how, when, and by whom manufactured goods were produced, the producers, supply chain operators, and third party certifiers will need to agree on a data architecture that can facilitate exchange and sharing of information that comes from production systems, supply chain distribution systems, and systems used to determine compliance with voluntary and government-mandated product standards. <br\/><br\/>This project will create I-Choose; a data interoperability framework to support the provision of a wide range of information about how, where, and by whom commodities are manufactured and brought to market. This includes information about ?green? supply chains, production methods, wages paid to producers or workers in the supply chain, working conditions, environmental impact, and a wide range of other information about the products can be delivered to consumers. A data architecture designed to enable interoperability will be generated through a multi-stage iterative process of sequential consensus building activities. These activities will include the stakeholders involved in Mexican coffee production for distribution in Canada and the US, along with researchers from the fields of information science, computer science, economics, and political science. We will explore interoperability with three types of specific information systems: (1) Those designed and maintained by government regulators, (2) Those designed and maintained by consumer advocates using social networking technologies, and (3) proprietary data systems from individual firms in the producer, supply chain, or retail systems. <br\/><br\/>The I-Choose data interoperability network will be unprecedented in nature as it will involve consumers, producers, government regulatory agencies and supply chain\/distribution across multiple domains and countries. It will allow more information into market transactions allowing consumers more informed decision-making that maximize their specific utility preferences and align the strategies of these stakeholder groups through market mechanisms rather than through cumbersome regulation. These diverse stakeholders will collaborate to create a series of technical products of the increasing granularity and specificity (ontology, taxonomy, data architecture) necessary for supporting interoperability while gradually expanding their network. The result of this process will be a fully-formed research and practice network and a high quality set of deliverables produced through the consensus of all relevant stakeholder groups, thus ensuring maximum interoperability of information systems. The knowledge gained through constructing and expanding I-Choose will inform a wide range of future collaborations in terms of how to create a trusted environment where incentives for collaboration and competition are complementary, not mutually exclusive. The study is relevant for a wide range of actors who are already experimenting with new forms of collaboration such as labor, environment, and agriculture departments and agencies in the NAFTA region, interested legislators, businesses, trade unions, environmental NGOs, consumer groups, and agricultural associations.","title":"INTEROP: Building Information Sharing Networks to Support Consumer Choice ( I-Choose)","awardID":"0955935","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7701","name":"DATA INTEROPERABILITY NETWORKS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["26296",433409,"551444",433411],"PO":["565292"]},"165461":{"abstract":"This project will establish and evaluate an innovative educational approach where a large and diverse group of students develop their general creativity using a web-based, online learning environment. Unique to the proposed learning environment is that it provides automated grading, using proven techniques of computer-based peer review, while engaging students in a discipline-based fine arts curriculum. The environment will be designed to handle very large classes and to move students through the course content autonomously (without an instructor), automatically and asynchronously within a schedule of content delivery and creative assignments.<br\/><br\/>This new approach to education will establish a method of teaching and learning that could completely change, in some instances, the landscape of accessibility and availability of education. All that is required is a community of learners agreeing on participation in a pre-designed and broadly scheduled learning process (thus becoming a cohort). A cohort can be a group of high school seniors, a group of new Army recruits, an online community of home-schooled students, a group of senior citizens (or any life-long learners), or any combination of these. One could envision a variety of open source courses developing around the explosive amount of content now freely available. Autonomous cohort learning is one solution to the burgeoning growth in learners across the globe, and a way to guide large groups of learners to realize their individual creative potentials.","title":"Pilot Program: Autonomous Cohorts and Emergent Learning","awardID":"1002758","effectiveDate":"2010-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["486875"],"PO":["562669"]},"168860":{"abstract":"The continuous evolution of the Web has made itself the primary<br\/>knowledge source for many people. It has become an information<br\/>repository full of entities (material or virtual) and descriptions<br\/>of their properties and relationships. In discovering and exploring<br\/>the entities that fascinate them, the users are in need of<br\/>structured querying facilities, coupled with text retrieval<br\/>capabilities, that explicitly deal with the entities, their<br\/>properties, and relationships.<br\/><br\/><br\/>In this project, the PIs investigate a novel declarative query<br\/>mechanism, entity-relationship queries (ERQ), for users to discover<br\/>and explore the rich structured and entity-centric information on<br\/>the Web. The research objective is to produce general methods for<br\/>efficient processing and optimization of entity-relationship<br\/>queries and automatic ranking of query results, and to<br\/>systematically develop a query engine for such queries. The<br\/>methodology is to exploit the evidence of the co-occurrence of<br\/>entities and keyword constraints, through the integration of DB and<br\/>IR methods. A systematic approach will be taken to produce automatic<br\/>ranking function formulation method, efficient entity-centric index<br\/>and index selection methods, and top-k query processing algorithms.<br\/><br\/><br\/>The research results will have broader impacts on the higher<br\/>education system, high-tech industries, the scientific community,<br\/>and the general public. The educational goal of the project is to<br\/>be achieved by integrating research and educational efforts through<br\/>these activities: broadening database curriculum; involving<br\/>under-represented students and undergraduates in research;<br\/>outreach; and publicly releasing the online demo, software,<br\/>datasets, publications, and course materials.<br\/><br\/><br\/>For further information see the project web page:<br\/>URL: http:\/\/idir.uta.edu\/erq","title":"III: Small: EntityEngine: A Query Engine for Entity-Relationship Queries Over Web Text","awardID":"1018865","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560637","486261"],"PO":["565136"]},"168750":{"abstract":"Current technologies have made it possible for submarines to evade standard sonar detection. Finding solutions to detect intruding submarines therefore becomes important and timely. A viable approach is to deploy magnetic or acoustic sensors in close proximity of possible underwater pathways intruders may pass through. This project seeks to develop a comprehensive theoretical and practical solution to construct undersea sensor networks for intrusion detection. When sensors are randomly deployed, spatial barriers are unlikely to exist, allowing intruders to pass through the bounded 3D space undetected. This motivates the use of mobile sensors to dynamically form sensor barriers. How to minimize the energy consumed by the movement of underwater sensors is a challenging issue. This project tackles the problem via three thrusts: (1) Develop an energy-efficient approach to using mobile sensors to construct a spatial barrier in 3D space; (2) Devise near-optimal practical solutions to reduce computation and communication costs, and develop these algorithms into practical protocols; and (3) Develop simulation modules and test-beds to evaluate the proposed solutions with realistic undersea environment parameters. The project integrates concepts and techniques in auction algorithms, geometry, combinatorial optimization, underwater acoustic communications and networking, software and system development to construct analytical models and practical solutions. The research results are expected to have a substantial impact on the understanding of constructing sensing barriers in underwater environments, and will be integrated into graduate and undergraduate teaching and outreach activities. Efforts will be also proactively pursued to recruit students from under-represented groups to participate in the project.","title":"NeTS: Small: Collaborative Research: Undersea Sensor Networks for Intrusion Detection: Foundations and Practice","awardID":"1018303","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["554394",451664],"PO":["565303"]},"168871":{"abstract":"Modern computer security requires bug-free code at every layer of the software stack. But in a world where operating systems and hypervisors are increasingly buggy, it can be dangerous to assume these components are trustworthy. LockBox provides an additional layer of security such that if the operating system or other system management software fails, certain portions of the system remain resistant to attack. LockBox embeds a set of security features into the architecture to provide a form of memory protection that enables correctly coded applications to resist attack even if underlying portions of the software stack become malicious or are otherwise compromised. <br\/><br\/>A nesting hypervisor is used to prototype the hardware modifications. Ultimately, the security features can be implemented either as a series of small hardware modifications or as a nesting hypervisor. In the former case, the hypervisor is unnecessary and the user will gain performance benefits. In the latter, users will not need to wait for new hardware to benefit from LockBox's security features. <br\/><br\/>LockBox provides the user with final authority to set security policy on the machine. It is a rights-preserving architecture in which the user's capabilities cannot be restricted. This is critical to alleviating fears that hardware security systems could one day restrict a user's capability to control their own hardware. <br\/><br\/>In summary, LockBox creates a next-generation trustworthy computing environment that can be trusted by users to keep data safe against malicious management software.","title":"TC: Small: LockBox: Enabling Users to Keep Data Safe","awardID":"1018928","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["540845","540846"],"PO":["565327"]},"176131":{"abstract":"This project is developing techniques for secured real-time services for cyber-physical systems. In particular, the research is incorporating real-time traffic modeling techniques into the security service, consequently enhancing both system security and real-time capabilities in an adverse environment. While this proposed methodology has not yet been fully tested, it is potentially transformative. <br\/><br\/>To defend against traffic analysis attacks, the research is developing algorithms that can effectively mask the actual operational modes of cyber-physical applications without compromising the guaranteed quality of service. This is achieved by using the traffic modeling theory, developed by the PIs, to precisely manage the network traffic at the right time and the right place. This traffic modeling theory can also help in develop efficient attack detection and suppression methods that can identify and restrain an attack in real-time.<br\/><br\/>The proposed methods are expected to be more effective, efficient, and scale-able than traditional methods.","title":"EAGER: A Study of Security Countermeasures for Cyber-Physical Systems","awardID":"1059116","effectiveDate":"2010-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[472006],"PO":["565239"]},"174074":{"abstract":"CSR proposal #0917137<br\/><br\/>CSR:Small:Collaborative Research: FastStor: Data-Mining-Based<br\/>Multilayer Prefetching for Hybrid Storage Systems<br\/><br\/><br\/>Abstract<br\/><br\/>A large number of existing parallel storage systems consist of hybrid storage components, including solid-state drives (SSD), hard disks (HDD), and tapes. Compared with high-speed storage components (e.g. SSD and HDD), tapes inevitably become an I\/O performance bottleneck. Prefetching and caching are commonly employed techniques to boost I\/O performance by increasing the data hitting rate of high-end storage components. However, prefetching in the context of hybrid storage systems is technically challenging due to an interesting dilemma: aggressive prefetching schemes can efficiently reduce I\/O latency, whereas overaggressive schemes may waste I\/O bandwidth by transferring useless data from HDDs to SSDs or from tapes to HDDs. In this research project, called FastStor, we investigate new data-mining-based multilayer prefetching techniques to improve performance of hybrid storage systems. The goals of this research are to (1) design data-mining algorithms for multilayer prefetching; (2) develop predictive parallel prefetching mechanism for SSD-based storage systems; (3) implement parallel data transfer among SSDs, HDDs, and tapes; (4) develop meta-data management schemes; and (5) implement a simulation framework named FastStor-SIM. The developed toolkit can be used to improve the I\/O performance of data centers with hybrid storage systems. The research findings of this project are published in conferences or journals for public knowledge. Through the collaboration of Auburn University, South Dakota School of Mines and Technology, and the University of Southern Mississippi, PIs promote learning and training by exposing graduate and undergraduate students to technological underpinnings in the fields of storage systems.","title":"CSR: Small: Collaborative Research: FastStor: Data-Mining-Based Multilayer Prefetching for Hybrid Storage Systems","awardID":"1048432","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["527426"],"PO":["565255"]},"168761":{"abstract":"Desktop computers run many different applications, the<br\/>compromise of any one of which can compromise the entire desktop given<br\/>the lack of isolation among applications. Recovering a compromised<br\/>desktop remains a time consuming task, which typically requires wiping<br\/>everything and reinstalling the system from scratch. These <br\/>security issues pose fundamental challenges as desktop computers are<br\/>relied on for everything from financial transactions to<br\/>medical records. To address these problems, we are creating novel<br\/>virtual layered file system (VLFS) technologies to improve system <br\/>security. Unlike a traditional file system which is a monolithic <br\/>entity, a VLFS dynamically composes together a set of software layers<br\/>into a single file system view for a desktop. Changes to one layer<br\/>are isolated and decoupled from changes to another. The VLFS dynamic<br\/>composition feature enables powerful and easy-to-use security<br\/>functionality. We are using VLFSes to build an architecture to enable<br\/>security patches to be deployed effectively when managing large<br\/>numbers of heterogeneously configured machines, and to speed system<br\/>recovery from security exploits. We are also using VLFSes to develop<br\/>a transparent desktop application fault containment architecture that<br\/>is effective at limiting the damage from exploits to enable quick<br\/>recovery while being as easy to use as a traditional desktop system.<br\/>The results of this proposal will provide a foundation for future<br\/>computer innovations to provide improved system security for users'<br\/>systems. Because we are working with industry-standard operating<br\/>systems and binary application and patch distributions, our results<br\/>will be directly applicable to the commercial world.","title":"TC: Small: Improving System Security through Virtual Layered File Systems","awardID":"1018355","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["508477"],"PO":["565327"]},"168882":{"abstract":"With the increasing levels of variability in the characteristics of nanoscale CMOS devices and VLSI interconnects and continued uncertainty in the operating conditions of VLSI circuits, achieving power efficiency and high performance in electronic systems under process, voltage, and temperature variations as well as current stress, device aging, and interconnect wear-out phenomena has become a daunting, yet vital, task. This proposal tackles the problem of system-level dynamic power management (DPM) in systems which are manufactured in nanoscale CMOS technologies and are operated under widely varying conditions over the lifetime of the system. Such systems are greatly affected by increasing levels of process variations typically materializing as intrinsic (random) or systematic sources of variability and wearout\/aging effects in device and interconnect characteristics, and widely varying workloads and temperature fluctuations usually appearing as sources of uncertainty. At the system level this variability and uncertainty is beginning to undermine the effectiveness of traditional DPM approaches. It is thus critically important that we develop the mathematical basis and practical applications of a variability-aware, uncertainty-reducing DPM approach with the following unique features and capabilities: Utilization of a two-tier stochastic modeling framework based on the theories of variability-sensitive, partially observable Markovian Decision Model and closed-loop feedback control theory, which can efficiently cope with variability and effectively reduce uncertainty in key system parameters. The framework also allows for self-learning (adaptive) policy optimization approaches, and multi-manager systems with multiple reward and cost rates for simultaneous optimization of the system energy consumption and performance.<br\/><br\/>Successfully overcoming the challenges addressed by this project will result in significant energy savings for a typical server. Other impacts of this research includes the development of a new and powerful mathematical framework for resource management in complex and large systems that can deal with multiple-agents, multiple reward and cost rates and discount factors while accounting for effects of variability and simultaneously reducing the impact of uncertainty through measurements and sampling. The stochastic decision making framework with closed loop feedback control is also useful for solving a variety of other problems including dynamic thermal control, concurrent DPM and task scheduling in multi-core processor systems, consideration of total system?s energy efficiency, energy-efficient power delivery network design. If successful, the approach can result in a practical stochastic optimization framework for handling many important problems, ranging from energy efficiency improvement (and hence reduction in cost of operation) for electronics systems to data centers comprised of a large number of server\/storage elements. Education, Outreach, and Training Programs include new curricula; recruiting under-represented students; research internship opportunities for undergraduates; and a Junior Scholars program for high school students.","title":"SHF: Small: Variability-Aware System-Level Power Management in Multi-Processor Systems","awardID":"1018980","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["518663"],"PO":["562984"]},"168772":{"abstract":"The methodologies of computational geometry will be applied to design,<br\/>analyze, implement, and test algorithms for problems that arise in<br\/>several application areas, including geometric network optimization,<br\/>air traffic management, sensor networks, robotics, geometric modeling,<br\/>and manufacturing. The main project goal is the development of<br\/>fundamental advances in approximation algorithms for geometric<br\/>problems. Additionally, the project will strive to foster and deepen<br\/>collaborations with researchers and domain experts in application<br\/>areas and industry, in order to formulate their algorithmic needs<br\/>precisely and to make available algorithmic tools, insights from<br\/>theoretical results, and software from experimental investigations.<br\/><br\/>The specific repertoire of problems includes: (a) Geometric Network<br\/>Optimization: optimal routing and network design in geometric<br\/>contexts, including traveling salesman (TSP) variants, vehicle<br\/>routing, constrained spanning trees, minimum-weight subdivisions,<br\/>optimal route planning with various constraints, and survivable<br\/>network design; (b) Air Traffic Management: optimal use of airspace<br\/>in the face of dynamic and uncertain constraints induced by weather<br\/>and traffic congestion, sectorization (load balancing), and<br\/>optimization of flow management structures for the National Airspace<br\/>System; (c) Sensor Networks and Coverage: sensor deployment,<br\/>localization, data field monitoring, and coverage for stationary or<br\/>mobile (robotic) sensors.<br\/><br\/>The problems will be attacked on two fronts: (1) Use of formal<br\/>algorithmic analysis, attempting to prove the tightest possible bounds<br\/>(upper and lower) on the worst-case or average-case time\/space, or<br\/>approximation ratio for the problem; and (2) Development of solution<br\/>techniques designed to be simple, fast, and practical, and which are<br\/>compared experimentally.","title":"AF: Small: Approximation Algorithms for Geometric Optimization","awardID":"1018388","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":[451713,"471875"],"PO":["565157"]},"168420":{"abstract":"Graphs and combinatorial optimization problems are central to algorithmic development, and have numerous applications in computer science and beyond. Many natural problems in these two areas are NP-Hard and approximation algorithms have been a very successful approach to address this intractability. In addition to providing algorithms and heuristics, approximation is a useful lens to examine the structure of NP-Hard problems. Despite the enormous progress made in the area of approximation algorithms and hardness of approximation, several basic and fundamental problems still remain wide open. This project will examine several interrelated problems from four broad areas. Our main tools will be linear and mathematical programming methods coupled with graph theoretic ideas. The problem areas of interest are:<br\/><br\/>(i) Multiflow and routing problems such as maximum disjoint paths, congestion minimization and flow-cut gaps. The central goal is to understand the relationship between fractional multiflows, integer multiflows and cuts both in the throughput and concurrent flow settings. (ii) Network design, in particular obtaining a poly-logarithmic approximation for the directed Steiner tree problem, and approximability of variants of the survivable network design problem. (iii) Traveling salesman problem (TSP), orienteering and related tour and walk problems in directed graphs. (iv) Submodular function maximization subject to constraints and applications.<br\/><br\/>The proposed research is at the intersection of algorithms, classical combinatorial optimization, mathematical programming, and graph theory. The technical work serves to exchange ideas between these areas and it is expected that it will lead to new algorithms and heuristics for fundamental problems. These problems arise in many applications in computer science (in particular network problems), operations research, and engineering; these would benefit from the algorithmic advances. The project will train two PhD students and a manuscript on algorithms and applications of submodular function maximization is expected to be produced.","title":"AF: Small: Approximation Algorithms for Graph and Combinatorial Optimization Problems","awardID":"1016684","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["550375"],"PO":["565251"]},"168541":{"abstract":"Many object-oriented programs, and in particular large enterprise applications, suffer from chronic run-time bloat: the excessive memory usage and run-time work that occur as part of seemingly simple computations. Such bloat significantly affects scalability and performance, and presents a serious problem for software used every day by thousands of businesses. Performance tuning may find substantial optimization opportunities, but it is very labor-intensive and requires a great deal of skill.<br\/><br\/>This project develops novel algorithms for run-time analysis of Java programs to identify the symptoms of bloat and to pinpoint their causes. These algorithms can be used in checking tools during software development, and later in tuning tools for performance debugging. A framework for algorithm design and implementation defines a generalized form of a run-time data dependence graph, with abstractions specific to the targeted analysis, and with several dimensions of parameterization. Framework instances are used to create analyses of temporary data structures, analyses of copy chains, data structure cost-benefit analyses, and analyses of inefficiently-used containers. Experimental evaluation investigates the cost\/precision trade-offs in the design and implementation of these algorithms, and their effectiveness in helping a programmer to improve performance.<br\/><br\/>The project provides a foundation for systematic exploration of bloat analyses, which will help increase software performance and reduce tuning efforts. The framework and its instances will be made publicly available. These advances could become part of development toolkits, leading to higher performance of enterprise applications. Educational efforts will contribute to the skills of the next generation of developers of enterprise systems.","title":"SHF: Small: Algorithms for Dynamic Analysis of Run-Time Bloat","awardID":"1017204","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["550527"],"PO":["565264"]},"168662":{"abstract":"Social media sites such as Twitter, Facebook, YouTube, and Flickr host an ever-increasing amount of user content captured or produced in association with real-world events, from presidential inaugurations to community-specific events. Unfortunately, the existing tools to find, organize, and present the social media content associated with events are extremely limited. This project will address critical end-to-end information processing and presentation methods that will transform public access to real-world event information from social media sources. In particular, this work will increase the digital presence of currently underrepresented communities and address their information needs: for these communities, events are often not covered by mainstream media, but are increasingly available on social media services. As a distinctive characteristic, the project will draw on several research areas, namely, information retrieval and databases, human-computer interaction, and social media, thus contributing to educating multidisciplinary students. The PIs will continue to include undergraduate students and students from underrepresented populations in the research.<br\/><br\/>The project will result in new data analysis and visualization techniques for event-based information tasks, addressing human and computational factors in social media systems to handle vast collections of noisy, user-contributed content of widely varying structure and quality. To enable effective browsing, search, and presentation of event content, this work will use the wealth of social media documents to address several fundamental problems. The first<br\/>problem is the detection of events in repositories of social media content. Such content, increasingly posted by users in real time, is noisy and highly heterogeneous, but can help in the early detection of a wide range of events of all sizes. The second problem is the comprehensive identification of content related to detected or known events, currently fragmented across social media sites and often hard to find and collect. The third problem is content presentation, which requires the development of novel presentation and visualization techniques for social media event content. The amount of content<br\/>available even for a single event can be overwhelming and hinder data exploration and sense-making. <br\/><br\/>The project will create new tools that will transform the viewing experience of the event information. These tools will allow users to create and share personalized views of the event data as a story-telling practice. Finally, as a main outcome, the data used in the research will be made available to other researchers whenever possible. Moreover, another main outcome will be a publicly available prototype system based on this research, designed to help connect computing and information science challenges to the activities and natural interests of a diverse set of users.","title":"III: Small: Collaborative Research: Detection and Presentation of Community and Global Event Content from Social Media Sources","awardID":"1017845","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["529950",451447],"PO":["565136"]},"168783":{"abstract":"This project focuses on the theoretical foundations for vehicular ad hoc networks (VANETs), which have emerged as a radically new paradigm for the design of networking protocols, mobility models, and a variety of new applications. This technology has its roots in on-board sensors in vehicles, global position systems (GPS) receivers, and algorithms\/protocols for ad hoc networks, which enable vehicle-to-vehicle communications without infrastructure equipment (e.g., base stations in cellular systems). A fundamental yet open issue is addressed: how rapidly and efficiently can information be disseminated in a vehicular ad hoc network? To address the unique challenges presented by mobility-induced time dynamics, a complimentary approach of networking analysis and physical channel exploitation is employed.<br\/><br\/>The project focuses on three issues: (1) Development and analysis of new measures of connection times among vehicles in percolated VANETs, in contrast to traditional measures of network connectivity. (2) Exploration of the impact of fading-induced channel variation on network performance and development of new fading prediction-aided routing mechanisms that integrate adaptive transmission techniques, e.g. rate and relay selection. (3) Identification of the theoretical time limits of information dissemination and capacity-delay trade-offs when nodes move at high speeds and in highly dynamic vehicular networks. <br\/><br\/>As vehicular communications advance large-scale and social networks, this project addresses an acute and timely demand for exploring fundamental principles of mobility-induced channels and network dynamics, which have not been studied systematically, but have tremendous impact on routing protocol designs, optimization techniques for performance analysis and estimation, and modeling of network architecture and topology.","title":"NeTS: Small: A Timing Perspective on Information Dissemination in Vehicular Adhoc Networks","awardID":"1018447","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["534041",451742],"PO":["557315"]},"168552":{"abstract":"Information privacy and security has long focused on the individual. Most technological safeguards and policies have been oriented towards individual privacy practices (IPP). Yet, many organizational settings are highly collaborative where team work is the norm. Consequently, project researchers will investigate why and how people enact collaborative privacy practices (CPP) and provide design recommendations to develop more effective mechanisms to assure privacy during these activities. <br\/>Specifically the project will<br\/>1. Improve the conceptual understanding of CPP by investigating these practices in highly collaborative and information-intensive domain where information privacy is essential (e.g., healthcare)<br\/>2. Develop a conceptual model of CPP using a multi-method research approach<br\/>3. Examine privacy-enhancing technical features that can most effectively support CPP<br\/>This project will make three contributions to our knowledge of privacy and security. First, it will advance the theoretical understanding of the collaborative nature of privacy practices. Second, this project will advance the design of privacy enhancing technologies to focus on collaborative privacy practices. Third, it will help foster more effective design interventions by understanding the users? collaborative privacy practices that are often ignored in technical and organizational specifications of privacy and security.<br\/>The future development of privacy-enhancing features in information systems must not only focus on privacy assurance for individual users but also privacy assurance during collaborative activities. That is the central thrust of this project. Its broader impact lies in the development of new processes, policies, and technologies to support privacy in collaborative environments without hindering people?s activities in these environments.","title":"HCC: Small: Collaborative Privacy Practices: Exploring Privacy in Information Intensive Environments","awardID":"1017247","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["550223","559463"],"PO":["565227"]},"168673":{"abstract":"Online social networks (OSNs) have witnessed tremendous growth and popularity over the recent years. The huge success and increasing popularity of social networks makes it important to characterize and study their behavior in detail. Recent work in analyzing online social network data has focused primarily on either static social network structure or evolving social networks. However, popular OSNs sites provide mechanisms to form and maintain community over time by facilitating communication, content sharing, and other forms of activities. <br\/><br\/>This research will develop a suite of algorithmic and analytic methods to support the characterization and modeling of activity networks. In particular, we will conduct static and temporal characterization studies of social network activity, study sampling techniques that can preserve graph properties for different communication activity graphs, investigate the fundamental theoretical trade-offs between preserving different properties of the graph, and develop procedural modeling techniques to generate social network activity graphs to better represent the temporal dynamics and burstiness of activity patterns.<br\/><br\/>We &#64257;rmly believe that the insights garnered from the proposed algorithm development and theoretical analysis will have a significant impact on sampling and analysis in other network-centric domains in addition to OSNs. All the ideas that come out of the research will be incorporated into both graduate as well as undergraduate level networking and data-mining courses.","title":"NETSE: Small: Towards Better Modeling of Communication Activity Dynamics in Large-Scale Online Social Networks","awardID":"1017898","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["541857","518558"],"PO":["565136"]},"168563":{"abstract":"Joint source-channel coding and decoding techniques are rapidly emerging as important design tools for the complexity- and latency-constrained transmission systems that underlie the multimedia revolution. In such scenarios these techniques have the potential to offer the same performance with less complexity or delay compared with systems which completely separate the source and channel coding functions. The investigators develop theoretical insights and practical approaches into the construction of joint source-channel codes by addressing certain classes of optimal variable-length error correcting codes and their application to networks. The insights gained by these studies facilitates new advanced coding strategies as well as a fundamental theory that guides the design of future wireless and multimedia systems.<br\/><br\/>One approach to joint source-channel coding is to consider prefix condition codes which have an inherent source compression property and are in addition able to detect or correct errors resulting from noise on the communication channel. Thus, these codes typically require a smaller amount of redundancy than classical channel codes to achieve the same amount of error resilience. However, the current understanding of these codes remains rather limited which has led researchers to focus on heuristics. The investigators address these issues by tackling research problems in three interrelated directions. In particular, we (1) develop new minimum-redundancy variable-length codes with inherent error resilience properties and investigate issues related to their design and compression performance; (2) study the application of this family of codes to sensor and ad hoc networks and gain insight into their repercussions for higher communication layers; (3) investigate the construction of reversible variable-length codes including those with special error-correcting properties.","title":"CIF: Small: Collaborative Research: New Approaches to the Design of Joint Source-Channel Codes","awardID":"1017303","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["509405"],"PO":["564924"]},"168684":{"abstract":"The goal of this project is to design and build gaze mechanisms for embodied agents that can achieve high-level social and communicative goals that people achieve using such mechanisms and that can be applied across a wide range of agent presentations and task domains.<br\/><br\/>Embodied agents promise significant social, cognitive, and organizational benefits through applications in education, training, rehabilitation, and collaborative work. However, in order to be effective across a wide range of applications, agents must be able to use the nonverbal social cues that humans employ in their communication and to employ these cues in whatever modality the agent is presented in - whether it be a social robot, a life-sized virtual human, or an animated avatar on a portable display. Gaze cues are particularly important social signals. Although they are subtle, they can serve as powerful mechanisms for achieving high-level social and communicative goals, such as improving a listener?s comprehension, controlling the flow of a conversation, and indicating interest in or appraisal of objects. This project investigates how such mechanisms might be designed and built for embodied agents and how similar social and communicative goals could be achieved using different agent representations across different task domains.<br\/><br\/>This investigation will involve (1) performing formal observational studies to better understand how people use gaze, (2) developing computational models that synthesize gaze behaviors that can be controlled precisely and retargeted to a range of agent platforms, and (3) evaluating in experimental studies the effectiveness of using gaze cues across a range of agent presentations and task contexts. Success in this project will create new knowledge on human gaze behaviors, connecting the high-level findings in the social science literature to more detailed, low-level cues and mechanisms. It will also produce a set of techniques that are based on this understanding for synthesizing controllable and flexible gaze movements that agents can use in order to achieve social and communicative goals. Finally, it will validate the effectiveness of the use of gaze cues by agents across a variety of agent presentations and task contexts.<br\/><br\/>A trans-disciplinary approach will combine rigorous, formal observational studies to build detailed models of human communicative mechanisms with practical efforts to build usable computational models that meet the needs of creating agents that work in real-world tasks. The focus on human models insures that the computational models are well founded, while the focus on developing practical algorithms guides the human studies towards creating understanding that will be most informative for agent design. The project plan involves connecting the disparate communities that work on developing social agents and training students to do the trans-disciplinary work required to create effective embodied agents. The project will also enable K-12 outreach efforts to use robots and connections to social science to engage students and increase participation by under-represented groups.","title":"HCC: Small: Designing Effective Gaze Mechanisms for Cross-Modal Embodied Agents","awardID":"1017952","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["520932","531411"],"PO":["564456"]},"168332":{"abstract":"THz RADAR systems provide the ability to enhance optical imagers in a variety of important detection tasks. THz systems have a small enough wavelength to provide image resolution on the order of millimeters, and THz radiation penetrates many materials, such as clothing, wall board, wood, etc., that are opaque to optical and infrared imagers. In addition to their beneficial imaging properties, spectroscopic systems in the THz regime provide the ability to fingerprint molecules based on their absorption features. The team has developed a compact scanning THz radar that will be used to identify materials by considering precision non-imaging THz spectroscopy in the laboratory. The team will also investigate the utility in the environment. The proposed work is aimed at applying high resolution Terahertz spectroscopy techniques to standoff imaging problems. The union of high resolution THz spectroscopy and imaging technology can readily be applied to many important societal needs. For example this technology could be used to quickly inspect mail for chemical or biological agents, look for traces of E-coli in food processing plants, or to check the relative concentration of therapeutic isomers versus non clinical compositions in drugs. The proposed technology also has real potential to help physicians diagnose skin cancer in its earliest stages. On the education front, this proposed effort will involve two graduate students and an undergraduate student, as well as a Masters student.","title":"Spectroscopic THz RADAR Imaging for Standoff Explosives Detection","awardID":"1016277","effectiveDate":"2010-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}}],"PIcoPI":[450665,450666,450667,450668],"PO":["565136"]},"168453":{"abstract":"The objective of this research is to advance usability testing of mobile applications by integrating contextualized and automated techniques. Unlike the traditional desktop environment, mobile user experience is heavily in&#64258;uenced by user context such as physical location, transport mode, social surroundings, and task intention. The novelty of this project is a model-based usability testing approach that quantitatively integrates user context. The expected outcomes include: 1) a new framework of automated usability analysis to improve the effectiveness of diary studies by jointly modeling user cognition, application state, and user context; 2) a set of operationalized usability rules developed for mobile applications; and 3) a simulation-based development toolkit for automated usability inspection. This project addresses an emerging research theme and an urgent practical usability problem, and is expected to produce technology solutions as well as educational materials.<br\/><br\/>This project addresses a practical need of the fast-growing mobile application industry. The software artifacts will be made available to both research communities and industry practitioners through open source technology transfer, which can significantly reduce the cost of mobile usability testing. The proposed research will be integrated with three new course modules taught by PI. Women and minority students will be recruited to participate both research and education activities. All the course materials will be made available online.","title":"HCC: Small: Contextualized and Automated Usability Testing for Mobile Applications","awardID":"1016823","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["463098"],"PO":["564456"]},"168574":{"abstract":"Social media sites such as Twitter, Facebook, YouTube, and Flickr host an ever-increasing amount of user content captured or produced in association with real-world events, from presidential inaugurations to community-specific events. Unfortunately, the existing tools to find, organize, and present the social media content associated with events are extremely limited. This project will address critical end-to-end information processing and presentation methods that will transform public access to real-world event information from social media sources. In particular, this work will increase the digital presence of currently underrepresented communities and address their information needs: for these communities, events are often not covered by mainstream media, but are increasingly available on social media services. As a distinctive characteristic, the project will draw on several research areas, namely, information retrieval and databases, human-computer interaction, and social media, thus contributing to educating multidisciplinary students. The PIs will continue to include undergraduate students and students from underrepresented populations in the research.<br\/><br\/>The project will result in new data analysis and visualization techniques for event-based information tasks, addressing human and computational factors in social media systems to handle vast collections of noisy, user-contributed content of widely varying structure and quality. To enable effective browsing, search, and presentation of event content, this work will use the wealth of social media documents to address several fundamental problems. The first<br\/>problem is the detection of events in repositories of social media content. Such content, increasingly posted by users in real time, is noisy and highly heterogeneous, but can help in the early detection of a wide range of events of all sizes. The second problem is the comprehensive identification of content related to detected or known events, currently fragmented across social media sites and often hard to find and collect. The third problem is content presentation, which requires the development of novel presentation and visualization techniques for social media event content. The amount of content<br\/>available even for a single event can be overwhelming and hinder data exploration and sense-making. <br\/><br\/>The project will create new tools that will transform the viewing experience of the event information. These tools will allow users to create and share personalized views of the event data as a story-telling practice. Finally, as a main outcome, the data used in the research will be made available to other researchers whenever possible. Moreover, another main outcome will be a publicly available prototype system based on this research, designed to help connect computing and information science challenges to the activities and natural interests of a diverse set of users.","title":"III: Small: Collaborative Research: Detection and Presentation of Community and Global Event Content from Social Media Sources","awardID":"1017389","effectiveDate":"2010-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[451238],"PO":["565136"]},"168695":{"abstract":"Homeless young people, like most adolescents in American society, frequently use digital media, for life and work. Even if gaining access to computers is difficult, homeless youth, aged 13-25, go online for many purposes: to communicate with family and friends; to find and apply for jobs; to participate in popular culture; and in general to seek and use information in all its forms. Yet, this adoption of digital media presents a significant challenge to community-based service agencies. These organizations, focused on supporting youth's basic needs, are largely unprepared for bringing digital media into their programs. To tackle this challenge, this three-year project will first investigate how homeless young people conduct themselves in relation to digital media, especially at social networking sites such as MySpace. Then, seeking to accommodate their abilities and interests, this project will develop a web application that positions youth to successfully communicate with employers. Specifically, the system will enable youth to create appropriate online identities, to build dignified resumes, to find and apply for suitable work-related openings, and to share experiences. Finally, the system will be deployed at a service agency located in Seattle, WA and evaluated for its overall effectiveness in brokering relationships between youth and employers. In summary, this project will discover social and technology approaches for developing usable information systems that enable homeless young people to better communicate with institutions. Research findings, including theory, design methods, and guidelines, will contribute to a national dialog about the use of digital media for escaping homelessness.","title":"HCC: Small: Life-Work Bridges: Design Knowledge for Information Systems that Connect Homeless Young People to Institutions","awardID":"1018008","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[451529],"PO":["565227"]},"168585":{"abstract":"Fault-tolerance is now a primary design constraint for all major microprocessors; however, perfect fault-tolerance is not a requirement for most designs. Instead, designs strive to maximize performance subject to an acceptable failure rate constraint. Therefore, vendors typically set a failure rate (FIT) target for each design and validate that the design meets this target with extensive pre-silicon and post-silicon analysis. One method to quantify fault masking is to use vulnerability factors. A system consists of multiple independent components that interact through well-defined interfaces. Therefore, fault masking can be quantified within a single component by focusing on its interfaces. This abstraction is called the \"vulnerability stack\", and is the major focus of this project.<br\/><br\/>The vulnerability stack can have immediate tangible benefits to the Computer Architecture community. First, by enabling independent vulnerability assessment of each system component, the vulnerability stack allows a designer to assess (and potentially improve) the fault-tolerance of a particular component (e.g., a user program). This enables a much broader segment of the Computer Architecture and Software Engineering communities to participate in the vulnerability assessment and remediation process; currently, these activities are typically performed by architects equipped with a microarchitectural model. A second benefit of the vulnerability stack is a substantial reduction in the overall effort required for vulnerability assessment. A third benefit of the vulnerability stack is its application to runtime vulnerability estimation techniques. These are of interest because they allow a system to dynamically tune redundancy features to match the current vulnerability environment; this can improve performance during periods of low vulnerability.<br\/><br\/>This project will impact undergraduate and graduate education by introducing vulnerability concepts in the Computer Architecture curriculum at Northeastern University and deliver a tutorial at a major Computer Architecture conference. The project will also include participation by under-represented groups.","title":"SHF: Small: The Cross-layer Reliability Stack","awardID":"1017439","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["557272"],"PO":["565272"]},"166165":{"abstract":"The potential power of quantum computers is of enormous interest and consequence. Quantum complexity theory has identified the problem class QMA-complete. QMA (Quantum Merlin Arthur) is a set of decision problems, i.e. the answer is either \"YES\" or \"NO\", such that if the answer is \"YES\", there exists a polynomial size quantum state (Merlin) that convinces a polynomial time quantum verifier (Arthur) of the answer \"YES\" with high probability (=2\/3). Also, if the answer is \"NO\", any polynomial size quantum state is rejected by the verifier with high probability. This QMA-complete class is believed to be too hard even for quantum computers to solve efficiently in every possible case, i.e. in a time that grows only polynomially in the size of the input problem. The study of the corresponding hard problems, e.g. SAT, in standard classical computation has benefitted from the investigation of typical cases using techniques from statistical physics. SAT (SATisfiability) is the problem of determining if the variables of a formula F can be assigned in such a way that F evaluates to value 1. This has led to insights into the organization of their solution spaces and new algorithms for solving them. This strategy will serve as inspiration for generating quantum statistical mechanical insights into quantum computational challenges---by focusing on typical instances of QMA-complete problems. The primary effort will focus on the so-called quantum satisfiability (QSAT) problem, where work will range from locating phase transitions and understanding their implications to constructing new algorithms based on this understanding. Extensions of the methodology to other QMA-complete problems (e.g. k-local Hamiltonian or density matrix consistency) will also be considered. <br\/><br\/>The broader impact of this research will lie principally in the training of a postdoctoral fellow who will take part in this work and in the exposure of undergraduates to ideas in this field as part of their standard research experience at the PI's home institution. As quantum information and computation is a relatively young field with much promise, such training and exposure will have a substantial impact on its trajectory.","title":"The Statistical Mechanics of Quantum Satisfiability","awardID":"1005429","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7281","name":"QUATM INFO & REVOLUTIONARY COM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7928","name":"QUANTUM COMPUTING"}}],"PIcoPI":["546934"],"PO":["564326"]},"168475":{"abstract":"Real-time information is a fundamental emerging issue in the creation<br\/>and management of Web content. Increasingly, rather than consulting<br\/>relatively static sources that are indexed on a periodic basis,<br\/>people refer to information on news sites, blogs, social-networking<br\/>sites, and Twitter feeds that change dynamically and spread rapidly.<br\/>This project will study how information content varies over time, how<br\/>it is transmitted through underlying social networks, and how its<br\/>recipients assemble it into larger units. The project will explore<br\/>new techniques for addressing these issues, based on novel methods<br\/>for tracking, analyzing, and presenting information that evolves and<br\/>spreads rapidly over time. The resulting approach aims to transform<br\/>important aspects of the ways in which real-time information on the<br\/>Web is handled.<br\/><br\/>First the fundamental units of information that spread through the<br\/>underlying information networks will be identified. From a set of<br\/>nearly 1 billion news media articles and blog posts (approx. 6TB of<br\/>data), and a collection of 500 million tweets from Twitter, small<br\/>(generally textual) units of information will be identified that<br\/>remain relatively stable as they spread through the Web. The<br\/>temporal variation within these basic units will be analyzed and<br\/>modeled. This modeling will include connections with biological<br\/>models of epidemics, as well as new frameworks that exploit the<br\/>fundamental differences between biological and social contagion.<br\/>Finally, the temporal variation will be related to network-level<br\/>models for the diffusion of this information. Generally, the actual<br\/>networks on which real-time information spreads cannot be directly<br\/>observed, nor can the influence of any particular node in the network<br\/>be directly measured. Therefore, the project will develop machine-<br\/>learning techniques that infer these hidden networks and unobserved<br\/>levels of influence.<br\/><br\/>For more information see the project web site at:<br\/>http:\/\/snap.stanford.edu\/proj\/mipro","title":"III: Small: Collaborative Research: Mining Information Propagation on the Web","awardID":"1016909","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["507065"],"PO":["565136"]},"168596":{"abstract":"Micro-chips are at the heart of modern microelectronic systems for computing, communication, entertainment, and other consumer electronics. In order to design and manufacture next generations of complex microelectronic systems, major innovations in the design of EDA (electronic design automation) software are needed. This project addresses four new challenges in EDA for complex microelectronic systems at both the micro-chip and the circuit board levels: (1) Beyond-die EDA: The routing (wiring) of today?s high-density complex circuit boards has to be done manually since no existing EDA software can solve the problem. Research will be carried out in circuit board routing to handle various new technology issues. (2) Litho-aware EDA: Since there is no alternative practical option but to continue using 193nm light to print (manufacture) on-chip features of size 32nm and below, accurate printing has become extremely difficult. EDA software will be developed to produce designs that are friendly to lithography for successful micro-chip manufacturing. (3) GPU EDA: Graphics processing unit (GPU) has become a popular cost-effective parallel computing platform recently. How to take advantage of GPU to accelerate critical EDA tasks is a challenge and will be studied. (4) Stochastic EDA: In order to handle process variations in advanced technology nodes, EDA software will be designed to solve fundamental graph optimization problems (e.g., shortest path, minimum spanning tree, and network flow etc.) where edge weights (costs) are random variables. <br\/><br\/>The proposed research will advance knowledge in EDA. It will also add new knowledge to other fields such as mathematical programming and combinatorial optimization since ultimately the research will need to solve large scale optimization problems. The broader impacts of this project include technology advancement and the education of next generation of engineers. The proposed research improves the design and manufacturing of microelectronic systems which will benefit the society at large. New research results will be passed on to undergraduate and graduate students through dissertation research, course projects, homework, and classroom teaching.","title":"SHF: Small: Research on New Challenges in EDA","awardID":"1017516","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["550908"],"PO":["562984"]},"168486":{"abstract":"This project explores fundamental performance and design issues for unstructured peer-to-peer (P2P) communication. It focuses on communication over the public Internet, which is the sharing of widely distributed resources, which are typically owned by different entities, and which typically involve end users' computers acting as both clients and servers. But the analysis also ranges beyond the scope of the Internet, to the ecology of people and devices connected to the Internet. The project contributes to our ability to measure, design, control, and understand the explosion in P2P communication that is already underway. There are exciting possibilities on the horizon for more interactive user generated content, interactive gaming, online interactive instruction, and applications to come. Peer-to-peer communication is likely to significantly alter the structure of the Internet. There is a tension between the open, uncontrolled aura of P2P systems, and reliability and security concerns. By providing a better understanding of the capabilities of P2P mechanisms, this research enhances the value of the future Internet.<br\/><br\/>The investigators study basic aspects of P2P systems in a variety of contexts. These aspects include: strategies of peer selection and piece selection, push vs. pull, proactive vs. reactive, effects of heterogeneous link and host speeds, the impact of incentive mechanisms, effects of network topology--in particular clustering and reduction of inter-ISP traffic, delay, and coding. The contexts include file transfer, live streaming video, video on demand, and delay tolerant interactive systems. The approach is to devise and analyze models capturing various combinations of the above aspects and contexts. The investigators quantify fundamental performance limits, and develop tractable performance analysis and design methods.","title":"CIF: Small: Fundamental Issues in Peer-to-Peer Communication","awardID":"1016959","effectiveDate":"2010-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["456909"],"PO":["564924"]},"168497":{"abstract":"Dynamic random access memory (DRAM) has been used as the main memory in computer systems for decades. However, DRAM technologies are facing both scalability and power issues. With the superior scalability, phase-change memory (PCM) has become an attractive DRAM alternative to implement high-capacity, ultra-dense main memory systems. Recent advances in nano-scale material engineering have also enabled fabricating phase change memory using nano-scale structures (e.g. nano-wire), which exhibit ultra-low programming power than the conventional thin-film based substrates. Although technology scaling and advanced material engineering provide smaller and denser devices, they make architecting reliable, power-efficient and high-performance phase change memory systems increasingly challenging. If left unattended, these challenges will soon become showstoppers of future phase change memory systems by either preventing them from scaling down to smaller feature sizes or resulting in the inefficient operation of these systems. This collaborative research project aims to improve the efficiency of phase change memory systems as the underlying processing technology scaling continues, including: (1) Cross-layer process variation characterization, modeling and mitigation for phase change memory (2) Nano-wire based PCM design exploration and (3) Resistance drift resilient phase change memory system. In addition, this project will develop a comprehensive full-system simulation infrastructure that consists of PCM device\/array\/architecture multi-scale models and architecture\/OS techniques that will allow the computer architecture design community to study the trade offs and optimizations of employing emerging phase change based memory systems in light of advanced process technology and material engineering. This collaborative research project will facilitate ultra-density, low-power and reliable phase change based non-volatile memory systems to most effectively leverage emerging nano-scale material and fabrication technologies to tackle the grand \"Memory Wall\" challenge faced in today's computer design community. It can greatly contribute to enabling high-performance computing to stay on track with its historic scaling as the number of CPU cores increases and workloads become more memory intensive, and hence benefit numerous real-life applications running from high-end servers to low-end embedded systems. This collaborative research project will also contribute to society through engaging under-represented groups, research infrastructure dissemination for education and training, and outreach to non-volatile memory design industries.","title":"SHF: Small: Collaborative Research: Architecting Technology Enabled Phase Change Memory Systems","awardID":"1017000","effectiveDate":"2010-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["523600","550720"],"PO":["565157"]}}