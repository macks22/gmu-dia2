{"186890":{"abstract":"While there is a tremendous amount of research in the algorithmic and protocol aspects of cognitive radios, very little attention is given to the antennas used in cognitive links. This project focuses on the enhancement of cognitive dynamic spectrum access (DSA) techniques with electrically reconfigurable antennas that are capable of dynamically adjusting their radiation patterns and operating frequency in response to the needs of overlying communication link and network. Based upon the results of field testing, new reconfigurable antennas are being designed that provide not only flexibility in radiation pattern, but also frequency agility. The design and performance of the cross?layer control stack is being evaluated for identification of the optimal control policy for secondary radios seeking to maximize their throughput. With the additional support of our collaborators in Finland, the Drexel SDC Testbed is being extended to provide real-time implementations of the proposed enhanced DSA algorithms.<br\/><br\/>This research is enabled through the reconfigurable leaky wave metamaterial antenna technology, developed at Drexel University. The highly adaptive frequency agility and spatial filtering capabilities of this antenna will be used to develop new DSA algorithms to leverage these degrees of freedom. Enhanced performance will be demonstrated in terms of the user capacity of the cognitive radio network and increased throughput of secondary cognitive radio users. These antennas and control algorithms will be field tested and demonstrated using a FGPA-based SDR platform built to evaluate reconfigurable antenna-enhanced DSA algorithms.","title":"Reconfigurable Antenna-based Enhancement of Dynamic Spectrum Access Algorithms","awardID":"1147838","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["533238","563559"],"PO":["557315"]},"181093":{"abstract":"Over the past five years, the network neutrality debate involving for-profit ISPs and \"content\" providers, together with security-related issues, has figured most prominently in the Western media's coverage of the Internet and in government regulatory hearings in both North America and Europe. The two principal issues have to do with equitable treatment of applications (application neutrality) and side payments between independent content and service providers.<br\/><br\/>The four research thrusts of this grant are: the development of unbiased, parsimonious models of macro-economic and networking dynamics of all parties involved; analyzing these models with an aim to assess the relative benefit of different pricing regimes, provider alliances, and service-differentiation strategies; acquiring current, real-world data and practical lessons-learned to inform these models; and focusing in particular on comparing neutral to non-neutral frameworks.<br\/><br\/>In a preliminary example study, a passive model of end-user demand was used to define a game between multiple ISPs and multiple content providers. The users could engage in two types of applications: one delay sensitive, the other throughput sensitive. The fraction of users engaged with a particular provider depended on the provider?s current prices, subject to a customer inertia model when competitors? prices were close. A regulated side-payment between providers of different types was considered. A surprising finding at stable Nash equilibrium was that monopolistic providers (say a single ISP) receiving side payments actually had less income than the ?neutral? scenario without side-payments (side payments result in increased end-user prices by the payee which lowers end-user demand). Revenues from the application types which consumed the most bandwidth were naturally affected the most.<br\/><br\/>The primary intellectual merit of this research has to do with the challenge of formulating tractable though realistic mathematical models of the cross-disciplinary elements of the macroscopic interactions among different entities participating in the Internet economy. Identified near-optimal strategies are tracked in the presence of naturally time-varying system parameters. Though a model may be simple, it often yields unexpectedly complex behavior (e.g., multiple Nash equilibria with differing stability qualities). Important real-world data and practical lessons will be identified in this research through the study of sensitivity of derived results to the different model parameters in play.<br\/><br\/>One aspect of the broader impact of this research pertains to the enormous financial stakes involved in the network neutrality debate, and therefore the potential of this research to influence significantly Internet operations and architectural development even in the near term. Industry outreach is a significant part of this research, not only to keep abreast of current developments, but also to obtain first-hand relevant data that hopefully can be disseminated to the broader research community. Another aspect of the broader impact of this research is the development and dissemination of related \"economics\" teaching modules suitable for networking graduate courses, and the recruitment and training of students from under-represented minority groups in Computer Science and Electrical and Computer Engineering.","title":"NeTS: Small: Collaborative Research: Inter-provider Dynamics in Neutral and Non-neutral Networks","awardID":"1115547","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517945"],"PO":["564993"]},"187990":{"abstract":"Contemporary information technology is ever more central to science and society in the midst of the deluge of complex data. The impact on bioscience is notable, where the pace of production and the data complexity means that a large amount of data is often not adequately analyzed by the data producers, yet researchers expect rapid dissemination of such types of data. To ensure effective impact, a solution promising to be transformational is to open \"big data\" analysis to the broader community. An avenue is provided by modern IT and the explosive growth and democratizing impact of the Internet, which, following the digitization of information and communication, has changed the pace of information exchange and opens up new channels for disseminating data and for engaging disparate disciplines in extended, productive collaborations. The result of this will be a platform with a customized pre-build interface that will significantly reduce the downside of the form-based data input approach. The input interface will be small, easy to use and readily accepted by users but still relevant to what a user might want to input. The interface will provide strong search ability to the controlled vocabulary and provide users with this information through \"input hint\", dropdown lists or auto-completion, according to what is most efficient for the specific extension and provides an effective, readily followed and precise process. Sustaining the free text input section will provide users with maximum freedom of data input. By enabling community collaboration via Web access and implementing a database resource linked with the knowledge collection interface together with free text entry format, this system will provide a venue for researchers among many communities, including those located at non-research intensive universities, community colleges and minority-serving institutions, in this Nation and worldwide, to contribute their insight to experimental research observations that currently requires expensive specialized equipment only available in a few centers around the world.","title":"EAGER: An Exploration in Enabling Community-driven Collaboration","awardID":"1153617","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["534860"],"PO":["565136"]},"185361":{"abstract":"The project advances the state-of-the-art of various robotics fields, including home health care robotics, robot mechanisms and kinematics, visual servoing, modeling and analysis, estimation and control, search and tracking, and localization and mapping. In addition, the integration of these technologies and its demonstration provides an opportunity to verify the capabilities and limitations of the state-of-the-art technologies, discovering new subsequent robotics problems to tackle.<br\/><br\/>This project addresses the fundamental aspects relevant to many scientific and engineering applications and includes experimental demonstrations, and broadly impacts teaching, training and education. Further, the international collaboration provides graduate students who reside in the rural Southside Virginia opportunities to observe scientific, cultural and political similarities and differences between countries and encourages them to continue their efforts toward research, and to establish an international community of home health care robotics. The project contributes to the modernization of the engineering curriculum in general and the teaching of mobile robotics in particular.","title":"EAGER: Autonomous Mobile Robots for Home Health Care of Motor-function Impaired Persons","awardID":"1139770","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["538557"],"PO":["543539"]},"186120":{"abstract":"While current cellular networks are based essentially on one-to-many and many-to-one single-hop subnets and cope with inter-cell interference by careful centralized resource planning, future wireless networks must consider heterogeneous environments characterized by user-deployed and user-operated infrastructure in which multiple flows and multiple hops will play an increasingly relevant role. Indeed, such networks are expected to open doors to trillions of dollars of e-commerce, while also providing vast amounts of easily accessible knowledge to the public. Developing a fundamental understanding of multihop multiflow wireless networks is therefore critically important at this time.<br\/><br\/>This exploratory project will seek to discover the fundamentals of such networks by obtaining their information theoretic capacity in an approximated sense. It is expected that scalable and extensible solutions are possible for such networks ranging from the seemingly simple ones involving two hops and two flows to apparently more complex ones involving multiple hops and more than two flows with arbitrary connectivity. In so demonstrating, multiple metrics will be employed. These metrics in the increasing order of accuracy in the high signal-to-noise ratio regime are (a) the fundamental limit on the available signaling (temporal\/spectral\/spatial) dimensions of the network, (b) the fundamental limit on the available signaling and signal-level dimensions, and (c) the capacity to within a (universal) constant number of bits independently of channel parameters.","title":"EAGER: Collaborative Research: CIF: Exploring the Fundamentals of Multihop Multiflow Wireless Networks","awardID":"1144000","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["565302"],"PO":["564924"]},"186241":{"abstract":"Abstract - Ebert (FODAVA II Workshop)<br\/><br\/>Society, as well as the science and engineering communities, is experiencing unprecedented growth in our capability to generate and access data. Turning this data deluge into usable, actionable information is a challenging, necessary task that is crucial to effective decision making, scientific discovery, and engineering advances. This growing need led to the development of the field of visual analytics. Key findings over the past years have illustrated that collaboration and interaction are key components that complete the integrated computational-human decision making loop. This occurs at many levels from individual manipulation of data representation to interactive cognitive discovery combined with automated analysis, to coordinative and collective interactive analysis among groups of individuals. Therefore, a research agenda for the \"science of interaction\" is needed that will support ubiquitous and collaborative analysis and discovery utilizing new, transparent interaction tools. <br\/><br\/>This workshop will help define the research topics within this Science of Interaction for data and visual analytics. The workshop will gather leading researchers from the variety of disciplines that underpin this new topic. Focal topics will be (1) ubiquitous, embodied interaction; (2) capturing user intent to guide the analytical process; (3) knowledge-based interfaces based on visual cognition and machine reasoning; (4) effective collaboration and collaboration tools; (5) principals of design, perception, and usability; and (6) composability and integration of tools. The main outcome of the workshop will be the workshop report defining a research roadmap for the Science of Interaction for Visual and Data Analytics, as well as a summary paper to be submitted to IEEE Computer Graphics and Applications? Visualization Viewpoints or IEEE Computer magazine.","title":"FODAVA II - The Science of Interaction Workshop","awardID":"1144379","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[499748,"543781"],"PO":["565227"]},"185163":{"abstract":"The University of California, San Diego and San Diego State University propose the Computing Principles for All Students' Success (ComPASS) Project that will build local capacity for teaching the proposed new Advanced Placement CS Principles (CSP) course. ComPASS will create novel curricula and methodology content for teacher profession development. The project will develop and evaluate pedagogical content knowledge curriculum to support the adoption of best methods and practices in teaching CSP content. It will continue the engagement of the San Diego-area computing education community, and tailor its offered training and support to engage university faculty, as well as in-service and pre-service teachers both with and without computing backgrounds. It will build comprehensive, multi-pronged, flexible, and scalable infrastructure to train and support teachers and faculty and it will pilot that infrastructure at 2 universities, 5 community colleges, and 15 high schools. The project's research component will evaluate the use of blended-learning approaches in transferring effective pedagogical techniques to diverse instructor groups. In addition, the pilot sites have been chosen to reflect a commitment to serving underrepresented populations and the research plan includes a qualitative study of the attitudes of those students with respect to course content and their beliefs about computing. ComPASS will foster the implementation of broadbased, inclusive, and motivational education in computing foundations and computational thinking for all students, regardless of their eventual career path. The ComPASS project will directly impact 105 pre-service teachers, 19 in-service teachers, and about 5000 students. If successful, its model could be adopted at other universities, colleges, and school districts.","title":"Collaborative Research: Type I: CE 21: Computing Principles for All Students' Success (ComPASS)","awardID":"1138512","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":[496824,"558312"],"PO":["561855"]},"186021":{"abstract":"This award provides funding for a collaborative project between Dartmouth College, Rice University and the Indian Institute of Technology in New Delhi. Soon, technology for mobile health (mHealth) will enable individuals to wear one or more sensing devices to better monitor their health conditions, or enable rural health workers to make periodic visits to villages that may not have access to routine healthcare services. The investigators in this project are developing the scientific foundations for a modular kit of mHealth components -- portable, inexpensive, and usable by patients or healthcare workers with limited training -- that can be assembled into a variety of combinations for different circumstances or healthcare purposes. Scientifically, they are addressing two fundamental questions: (1) how to construct secure, self-aware sensors that can attest to the provenance of the sensor data and its context; (2) how to design a system for computational triage that can provide real-time on-site feedback to the patient, avoiding the need for every patient visit, every data point, to be examined by skilled health professionals. The intellectual merit of this project is in (1) developing a new breed of portable medical sensors with the intelligence to identify and securely attest to the origin and quality of the data, and (2) developing computational triage algorithms that guide individual subjects to a medical facility when tests reveal a high chance of potential health problems. The research should result in broader impacts including (1) technology that could radically improve preventive health, (2) students trained on healthcare technologies in a wider global context, and (3) technologies that will have applications beyond healthcare, such as in critical infrastructure monitoring. This project is part of the Pervasive Communications and Computing Collaboration (PC3) initiative.","title":"PC3: Collaborative Research: Foundation for Trusted and Scalable Mobile Healthcare","awardID":"1143548","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["553543"],"PO":["564181"]},"185174":{"abstract":"The University of California, Berkeley and the University of North Carolina, Charlotte propose a collaborative effort, called FRABJOUS, to develop and deploy a proposed, new Advanced Placement (AP) computing course that can successfully achieve outreach -- attracting women and underrepresented minorities -- while having a technically rigorous programming component. The work extends the PIs' previous work on the Berkeley \"Beauty and Joy of Computing\" course and the College Board's CS Principles course to the high school level, addressing the development and study of new instructional materials as well as the impact of teacher professional development on student learning outcomes. The course uses a visually rich programming environment, called Snap, that is based on Scratch. Scratch has had well-documented success in teaching computer programming to 8-14 year olds because of the power of its visual metaphor. Snap extends the metaphor to teach more advanced methods, including recursion, higher order procedures, and object-oriented programming, to 14-19 year olds. Specifically the FRABJOUS project will<br\/><br\/>. Develop a core group of mentor teachers in the Berkeley and Charlotte areas,<br\/>. Conduct and evaluate intensive summer professional development workshops for in-service high school teachers,<br\/>. Develop regional partnerships between universities and high schools, creating CSTA chapters and connecting them through the STARS Alliance,<br\/>. Study university and high school student learning outcomes, disaggregating data by race, gender, age, course, and curricular models to understand the curriculum's effectiveness, ease of use, and impact, particularly the introduction of advanced concepts (higher order functions, recursion,<br\/>distributed computing, concurrency, simulation) at this early level, <br\/>. Compare outcomes for students and teaches trained directly by the PIs with those trained by the mentor teachers, and<br\/>. Expand the capability of Snap.<br\/><br\/>The project thus includes tool and materials development, assessments of student learning outcomes, and study of the impact of teacher professional development via workshops and school year support activities, including peer-to-peer and online support.","title":"Collaborative Research: Type 1: FRABJOUS CS - Framing a Rigourous Approach to Beauty and Joy for Outreach to Underrepresented Students in Computing at Scale","awardID":"1138596","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":["533235","499211"],"PO":["561855"]},"186043":{"abstract":"This award provides funding for a collaborative project between Dartmouth College, Rice University and the Indian Institute of Technology in New Delhi. Soon, technology for mobile health (mHealth) will enable individuals to wear one or more sensing devices to better monitor their health conditions, or enable rural health workers to make periodic visits to villages that may not have access to routine healthcare services. The investigators in this project are developing the scientific foundations for a modular kit of mHealth components -- portable, inexpensive, and usable by patients or healthcare workers with limited training -- that can be assembled into a variety of combinations for different circumstances or healthcare purposes. Scientifically, they are addressing two fundamental questions: (1) how to construct secure, self-aware sensors that can attest to the provenance of the sensor data and its context; (2) how to design a system for computational triage that can provide real-time on-site feedback to the patient, avoiding the need for every patient visit, every data point, to be examined by skilled health professionals. The intellectual merit of this project is in (1) developing a new breed of portable medical sensors with the intelligence to identify and securely attest to the origin and quality of the data, and (2) developing computational triage algorithms that guide individual subjects to a medical facility when tests reveal a high chance of potential health problems. The research should result in broader impacts including (1) technology that could radically improve preventive health, (2) students trained on healthcare technologies in a wider global context, and (3) technologies that will have applications beyond healthcare, such as in critical infrastructure monitoring. This project is part of the Pervasive Communications and Computing Collaboration (PC3) initiative.","title":"PC3: Collaborative Research: Foundation for Trusted and Scalable Mobile Healthcare","awardID":"1143644","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["548311"],"PO":["564181"]},"187033":{"abstract":"The shift to an ever-increasing number of processing cores--within a<br\/>single socket in consumer devices and across multiple sockets in<br\/>servers--has brought interconnects to the forefront of the challenges<br\/>facing the computing industry. While evidence suggests that<br\/>alternatives to conventional metal interconnects will be needed to<br\/>meet future performance demands and power constraints, research in<br\/>these areas has been largely limited in scope to specific areas of the<br\/>computing stack, and little progress has been made across problem<br\/>sub-domains. Thus, there is a dire need for holistic research efforts<br\/>spanning the stack from physics to systems, and that produce<br\/>prototypes and development tools that are of much greater<br\/>sophistication than exist today in order to enable commercial<br\/>adoption.<br\/><br\/>The Workshop on Emerging Technologies for Interconnects will bring<br\/>together key researchers, industry developers, and program managers in<br\/>order to define an agenda for the research and commercial adoption of<br\/>emerging interconnect technologies. Presentations and discussions on<br\/>the \"state of the state-of-the-art\" of emerging technologies for<br\/>interconnects will be followed by break-out sessions and discussions.<br\/>These sessions will identify and articulate the key research<br\/>challenges, and potentially most promising solutions\/directions, and<br\/>chart the recommended larger-scale national strategy and research<br\/>agenda. The broader impact will be the elimination of the key","title":"Workshop on Emerging Technologies for Interconnects","awardID":"1148697","effectiveDate":"2011-09-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550887"],"PO":["366560"]},"185097":{"abstract":"In many areas of professional and social life, people form communities based on some obvious feature, so that members tend to be similar in some aspect of interest or behavior. However, as the number of groups expands, new dimensions of similarity are introduced. This project will focus on the ways to understand many different communities that differ in many dimensions and to present that understanding in ways that help to understand the community structure. The modern web provides a number of alternative data sources for discover communities, with activities ranging from blog comments to tagging of resources. This data can be used to discover and model communities reliably and present the complex data in clear and efficient ways that decision makers and other stakeholders can readily understand. The visualization of the complex data will also be interactive, permitting exploration of the data. The knowledge of the existence of these communities can be used to support recommendation approaches, such as identification of mentors or development of wide scientific collaborations.","title":"EAGER: Interactive Visualization and Modeling of Latent Communities","awardID":"1138094","effectiveDate":"2011-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"K603","name":"National Security Agency"}}],"PIcoPI":[496622],"PO":["565136"]},"186076":{"abstract":"Computer science, and computer security in particular, tends to learn from our successes and ignore our failures. The workshop series Learning from Unanticipated Scientific Security Research Results<br\/>(LUSSRR) addresses this limitation. Through this series of workshops, researchers present their unexpected results - which may be failures, but may also be opportunities to learn something other than what was expected. This process encourages researchers to learn from each other and avoid duplication of effort, while encouraging new approaches to old problems. LUSSRR workshops publish proceedings which are included in the traditional digital libraries such as IEEE and ACM.","title":"Learning from Unanticipated Scientific Security Research Results Workshop","awardID":"1143766","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["565327","529389"],"PO":["564223"]},"177254":{"abstract":"This project addresses parallelism in applications with the goal of improving the efficiency of those applications.<br\/><br\/>Today's multicore and manycore computers provide increasing amounts of computational power in the form of parallel processing. But, before a software application can take advantage of such parallel hardware and exhibit speedups in execution, a software developer must (re)write the program to indicate which portions may be executed in parallel and which portions must be executed sequentially. The Manticore research project designed and implemented the Parallel ML programming language, a functional programming language with a rich collection of explicitly- and implicitly-parallel programming features. To date, this team built an implementation of PML that is efficient and scalable. However, PML lacks some features present in other languages, such as shared state, which grants the ability to freely modify data shared between parallel threads, and nondeterminism, which grants the ability to return results that may depend upon the order of parallel execution. These features are generally considered difficult to use correctly and difficult to implement efficiently in a parallel setting; yet, they have the potential to make greater portions of an application amenable to parallel execution.<br\/><br\/>Therefore, this project focuses on the significant problem of increasing the amount of parallelism exposed by applications by extending Parallel ML with mechanisms like shared state and nondeterminism in a safe and efficient manner. A key feature of the design is that it provides ways to isolate the stateful and nondeterministic components of a program; this isolation makes these mechanisms easier and safer to use by software developers. Another key feature of the design is that it captures common programming idioms, such as caching to avoid redundant computations and make independent writes to a shared sparse data structure in a manner that ensures safe and efficient program execution. Thus, this proejct frees the software developer from the difficult and error-prone task of explicitly programming the low-level details that manage the parallel execution of an application; instead, the software developer focuses on the high-level application logic, while the compiler and runtime system allocates the parallel execution over the available computational resources. This research is helping guide future language design efforts and transforming programming practice toward higher-level and more declarative models, yielding improved productivity, correctness, performance, and scalability.","title":"SHF: Medium: Collaborative Research: Extending Declarative Parallel Programming with State and Nondeterminism","awardID":"1065002","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[475197,"523800",475199],"PO":["551712"]},"178354":{"abstract":"This project brings social networks and geography into the economic theory of public goods. Public goods are goods that benefit many people all at once. For example, innovation, education, and social services are all critical to modern economies and economic growth. The project studies the long-standing problem in public good provision: individual contributions benefit many people, but contributors do not receive payment or recompense for the total impact of their work. This project considers social interactions and social incentives in public good provision. Communities, neighborhoods, ethnicity, and kin have all been argued to be central to the provision of public goods. The project draws heavily on these empirical findings. It formalizes social networks and social identity, and integrates them into mathematical models of decision-making. By developing a network theory of public goods and social interactions, the project both advances basic science and provides a guide to new directions for empirical research and policy.<br\/><br\/>Public goods are vital to a productive workforce and sustainable economic growth. Industrial research and development, health, security, and environmental preservation are just some examples of public goods. In its scientific mission, this project will advance understanding of how actual and virtual communities and governmental agencies help or hinder the provision of public goods. The project combines new economic techniques and computer science techniques to understand how networks of people can contribute to economic growth. In its education mission, the project will promote and advance the participation and education of women in two scientific fields - computer science and economic science - where women are significantly underrepresented. The project will develop courses and run workshops to train students in a set of tools for studying networks and strategic games. In its personnel and subject matter, the project follows national panel recommendations to increase the participation of women in science by providing role models and fostering research with social objectives.","title":"ICES: Small: Networks, Public Goods, and Social Interactions: At the Edge of Analytics and Complexity","awardID":"1101673","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[478157],"PO":["565251"]},"177287":{"abstract":"Hypervisors and virtualization simplify application and system deployment. The many benefits of virtualization have resulted in a headlong rush into a world where virtualization is ubiquitous. However, virtualization can break assumptions that applications and operating systems make about the platform. This research investigates an important case: the intersection of virtualization and random-number generators (RNGs). Strong randomization is requisite in today's computer security tools.<br\/><br\/>Deployment of existing RNGs in virtualized settings introduces vulnerabilities. When RNGs fail, catastrophic attacks can be mounted on the the cryptographic services upon which modern information security relies. VM snapshots, which can be used to reset a VM and its contained applications, can cause RNGs to repeat outputs and break some encryption systems. Moreover, the environment presented by virtualization can degrade the quality of RNG outputs because entropy sources are virtual rather than physical hardware and hence lower quality.<br\/><br\/>This research develops the theoretical and architectural foundations for the next generation of RNG designs and RNG-using mechanisms. The investigators quantify the scope of VM-introduced vulnerabilities using dynamic and static analysis of program source code. They develop new, secure RNG systems for use in VMs. Finally, the reserearch advances cryptographic theory by extending provable security techniques to better account for the realities of RNG deployment and use in virtualized settings.<br\/><br\/>This work not only provides practical impact via stronger RNG systems but also opens up new directions in cryptographic theory in the important areas of generating and using randomness.","title":"TC: Medium: Collaborative Research: Random Number Generation and Use in Virtualized Environments","awardID":"1065134","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["559530","553788"],"PO":["565327"]},"177298":{"abstract":"Malicious and exploitable web advertisements (ads) are widely recognized as a major emerging source of online attacks and privacy violations. Rogue ads can often escape existing weak defenses employed by ad networks and websites, inflicting much harm on end-users. This ad security crisis is exacerbated by several factors: complex mechanisms by which web ads are produced, distributed and deployed; weak filtering strategies of ad networks; web sites' inability to control content supplied by ad networks; and poor browser-level primitives for ad isolation and confinement.<br\/><br\/>This project tackles the ad crisis by developing a comprehensive framework that integrates and extends recent research on browser-level script sandboxing, bytecode in-lined reference monitoring, information flow analysis, and binary code certification. A key priority is to transparently preserve important web ad technologies, such as ad-billing, Flash-JavaScript interoperability, cross-site scripting, and ad network contextual targeting. The complementary strengths of the two PIs forms a natural synergy that lends itself to an elegant and easily adoptable framework for protecting users from the severe online security and privacy risks currently posed by malicious ads.<br\/><br\/>With the web advertisement industry estimated to be at a USD $50 billion mark in 2010, the techniques developed by this project are contributing to the vitality of this industry. To maximize impact, the PIs are transitioning results from this research to the industrial sector engaged in the development of ads as well as their dissemination.","title":"TC: Medium: Collaborative Research: Securing Web Advertisements: Fixing the Short-term Crisis and Addressing Long-term Challenges","awardID":"1065216","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["522482"],"PO":["562974"]},"180290":{"abstract":"Using the global female Muslim blogosphere, this research aims to understand the complexity of cyber-collective action and factors contributing to its success or failure. Despite the exponential growth of Internet users in Muslim countries, there is a lack of empirical study of socio-political uses of the technology for expressing opinions and mobilizing individuals in these countries. The female Muslim blogosphere was selected as a test-bed for two reasons: First, while research shows that three of four females online are active social media users, very little research attempts to understand social, cultural and political roles of female bloggers and collectivity among female social groups. Second, the domain epitomizes an important contrast deserving attention, between socio-political systems where women are frequently denied freedom of expression and active political uses of social media by female Internet users. Female Muslim bloggers find the blogosphere as a digital recourse to exercise their freedom of speech if compared to their physical and repressively controlled spaces.<br\/><br\/>This longitudinal study will develop the theoretical underpinnings and experimental tools to examine the factors that govern the success and failure of cyber-collective movements more generally. It will develop novel algorithms modeling cyber-collective movements by utilizing existing social theories on collective action and computational social network analysis and basing the analysis upon three central tenets of individual, community, and transnational perspectives. Essential questions to be addressed in this study are: What transforms individual sentiments into collective sentiments? What are the dynamics of various socio-cultural dimensions in the evolution of opinion leaders? What social or organizational factors help transcend the nation-state barriers? Several independent validation strategies will be investigated, including monitoring the manifestation of cyber-collective movements as physical social movements, human evaluation, and crowdsourcing initiatives to bridge the gap between qualitative and quantitative evaluation measures.<br\/><br\/>The lessons learned from this research will create greater synergies between social science and computational science. Data collected from this research will be made publicly available due to its efficacy for various interdisciplinary research endeavors, especially in human-computer interaction, game theory, political communication, social network analysis and mining, and social computing, among others. Members of underrepresented groups, especially female bloggers will play an essential role in the project, lending insights into the idiosyncrasies of their socio-technical behavior advancing our understanding of the female demographics, thus making a significant impact on society at large. Educational impacts include the creation of much-needed interdisciplinary courses and training undergraduate, graduate and doctoral students by involving them at all stages of the research.","title":"Collaborative Research: Cyber-Collective Movements: Novel Socio-Computational Approaches in Studying the Blogosphere","awardID":"1110649","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[483135],"PO":["564456"]},"184690":{"abstract":"Harnessing wind energy is one of the pressing challenges of our time. The scale, complexity, and robustness of wind power systems present compelling cyber-physical system design issues. Leveraging the physical infrastructure at Purdue, this project aims to develop comprehensive computational infrastructure for distributed real-time control. In contrast to traditional efforts that focus on programming-in-the-small, this project emphasizes programmability, robustness, longevity, and assurance of integrated wind farms. The design of the proposed computational infrastructure is motivated by, and validated on, complex cyber-physical interactions underlying Wind Power Engineering. There are currently no high-level tools for expressing coordinated behavior of wind farms. Using the proposed cyber-physical system, the project aims to validate the thesis that integrated control techniques can significantly improve performance, reduce downtime, improve predictability of maintenance, and enhance safety in operational environments.<br\/><br\/>The project has significant broader impact. Wind energy in the US is the fastest growing source of clean, renewable domestically produced energy. Improvements in productivity and longevity of this clean energy source, even by a few percentage points will have significant impact on the overall energy landscape and decision-making. Mitigating failures and enhancing safety will go a long way towards shaping popular perceptions of wind farms -- accelerating broader acceptance within local communities. Given the relative infancy of \"smart\" wind farms, the potential of the project cannot be overstated.","title":"CPS: Medium: Robust Distributed Wind Power Engineering","awardID":"1136045","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["549800",495344,"540776","558390"],"PO":["564778"]},"184580":{"abstract":"Are computing professionals adequately prepared for the ethical challenges that they will face in an increasingly global and interdisciplinary workplace? In this multi-institutional research\/education project, the PIs will investigate the gap between the need for ethical computing professionals and the ethical learning that occurs in graduate computing programs. They will then apply these insights to develop and disseminate best practices in graduate ethics education. The mixed-method research combines surveys, interviews, focus groups, content analysis, and experimental design, and will be conducted in partnership with ACM's SIGCAS and the IEEE's SSIT. The project will begin with an investigation of computing programs and courses at four diverse institutions: a traditional research 1 university, a rural polytechnic, an urban liberal arts college, and a leading institution for online education. What are the existing goals and strategies used in graduate computing ethics education at these sites? What ethical issues are covered? What pedagogical approaches and materials are used? Faculty and students will be surveyed and interviewed about their perspectives on computing ethics education. Observations of teaching ethics across the courses will be conducted at each institution by the project team and the evaluation team. With baseline data from these four institutions, the PIs will survey members of leading professional associations to gauge alignment between industry practice and interests and the education in ethics provided by postsecondary institutions. Finally, the PIs will refine a set of best practices and pedagogical recommendations for CS ethics education, and disseminate their findings along with examples of teaching materials designed to be applicable across a range of institutional settings. Specific research questions to be addressed include:<br\/><br\/>1. What specific ethical issues are CS instructors currently teaching and what pedagogies are currently being used in graduate-level computing courses?<br\/>a. What are the similarities and differences in computing ethics issues covered within curricula across different institutions?<br\/>b. What materials (texts, readings, videos, simulations, social media, etc.) are used in classes?<br\/>2. How can professionals? experience in the computing industry enrich teaching about ethical challenges in the workplace?<br\/>a. What do computer professionals think students should know about ethics before entering the workplace?<br\/>b. How do computer professionals think this information can best be conveyed?<br\/>3. How can computing ethics education be improved?<br\/>a. What do CS students need to learn about ethics that they are not currently learning?<br\/>b. What are the best pedagogical approaches for teaching students these ideas?<br\/><br\/>Project outcomes will include a report on the state of ethics education in graduate computer science\/technology, a report on industry needs for an ethically knowledgeable workforce, and recommendations for best practices in ethics education effective in graduate education and the workplace. The project will ultimately result in computing professionals who are more attuned to their ethical responsibilities to the public, leading to more reliable computing systems.<br\/><br\/>Broader Impacts: This work will fill an important gap in the research literature about the appropriateness and effectiveness of pedagogical approaches currently used to increase graduate computing students' awareness of ethical issues relative to the challenges that they will face in the workplace. Results of the study will be based on, and thus applicable to, a broad range of stakeholders in graduate computing ethics education, and thus could transform curricular standards promulgated by professional societies such as the ACM and IEEE. The innovative mixed-method approach that will be used has merit not only for this study but could also be applied to future studies in other domains.","title":"EESE: Collaborative Research: Understanding and Preparing Future Computer Professionals for the Ethical Complexities of a Diverse World","awardID":"1135308","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":["520564"],"PO":["565227"]},"181094":{"abstract":"The line speed of modern routers is reaching beyond OC-768 (40Gb\/s) to 100Gb\/s or even terabits per second. In order to keep up with such high throughput, online network functions for traffic measurement, packet scheduling, access control, and quality of service will have to be implemented using on-chip SRAM. However, fitting these network functions in fast but small on-chip memory represents a major technical challenge today. Many online functions rely heavily on several fundamental building blocks called online primitives for data processing and storage. Three fundamental online primitives are of particular importance: (1) spread estimators for measuring the number of distinct elements in each flow, (2) size estimators for measuring the size of each flow, and (3) high-performance Bloom filters for membership check against large data sets. They have numerous applications in service provision, capacity planning, billing, routing-table lookup, traffic measurement, firewall design, and intrusion detection. A key technical challenge is how to make online primitives both fast and compact. Being fast, the requirement is that they should make only one memory access or update one counter in the worst case when processing each packet. Being compact, the requirement is that they should use a minimum amount of SRAM memory and be able to handle a large, unpredictable number of flows. This project strives to fulfill the above requirements with new methodologies, called virtual bit vectors and virtual counting vectors, for online data storage and retrieval. The project consists of four research components: (1) one-memory-access compact spread estimators, (2) one-counter-update compact size estimators, (3) one-memory-access fast Bloom filters, and (4) architecture-aware online primitive designs.<br\/><br\/>Broader Impact: The proposed research will advance our knowledge for designing large-scale online operations in a very tight on-chip memory space. New design approaches developed by this project are expected to improve the performance of modern routers and firewalls. In addition, because the basic data structures embodied in these fundamental online primitives are widely applicable in Computer Science, improvement in their performance can potentially have broad impact in other research areas. Research outcome will be disseminated through conference and journal publications. New educational materials will be developed to incorporate online network functions and research results from this project into graduate courses.","title":"NeTS:Small: Making Online Network Functions Fast and Compact","awardID":"1115548","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[485309,485310],"PO":["565090"]},"183162":{"abstract":"This project, aiming to develop instrumentation that enables rigorous experimental quality and dependability assessment of cloud computing systems, including cloud service-oriented architecture<br\/>(SOA) systems, dramatically enhances the validation capability of cloud platform services and cyberinfrastructure. Cloud platforms must meet specified service level agreements (SLA) and provide mechanisms to support the minimization of the power used in cloud data centers without adversely affecting the quality of service (QoS). Also, some safety-critical emerging cloud applications, such as health-care and transportation applications, must meet stringent dependability requirements, that include high availability, reliability, performance, resilience, safety, and security. The proposed work establishes a high performance, metrics-driven instrument enabling rigorous evaluation for the following research projects on cloud performance: <br\/>- Assurance of QoS in Service Clouds,<br\/>- Optimization of Dependability in Evolving Clouds,<br\/>- Mobile Device Power Management in Service Clouds,<br\/>- Achievement of Highly Secure Compositions in Service Clouds, and<br\/>- Testing and Validation of Secure Hardware-Software Architectures.<br\/>The work aims to develop a flexible instrument for validation and verification of cloud performance, seen to be a key element in the future of computing services. In recent years, computer services have been moving to remote virtual machines ?in the cloud.? The commercial success of this new business model is based on service quality guarantees, which are becoming increasingly hard to verify as the complexity and volume of cloud services increase. Testbeds of this type are critical to the economic and research vitality of the academic and industrial communities.<br\/><br\/>Broader Impacts: <br\/>This instrumentation substantially raises the quality, scale, and scope of experimental research in dependability enhancement methods for cloud computing systems. It helps foster a strong scientifically based experimental paradigm for computing and provides capabilities that will greatly enhance the quality of undergraduate and graduate courses in computer science and engineering, as well as senior design projects by enabling students to work on realistic platforms. The instrumentation enhances the facilities of an NSF I\/UCRC and will be available to researchers at the participating institutions and industrial partners.","title":"MRI Consortium: Development of Instrumentation for Measuring the Dependability and Quality of Cloud Computing Systems","awardID":"1126747","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":[491096,491097,491098],"PO":["557609"]},"187760":{"abstract":"Inaccuracy in computation has usually been considered with a negative connotation and, therefore,<br\/>conventional computing systems have been designed with a strict notion of correctness.<br\/>However, inaccuracy or approximation is not always bad since several application domains<br\/>are intrinsically tolerant to varying degrees of relaxation in accuracy,<br\/>and thus, such a property can be exploited for significant gain in application performance or fault-tolerance.<br\/>The motivation of this EAGER project is to investigate the feasibility of utilizing such approximation,<br\/>also known as \"soft computing\", for data-intensive applications for predicting the performance-power-accuracy<br\/>trade-offs. The research consists of three intertwined tasks. The first task would examine a variety of<br\/>high performance computing (HPC) and MapReduce style data analytic applications, and determine<br\/>which classes of applications are suitable for soft computing.<br\/>The second component of the research is aimed at developing appropriate techniques for facilitating<br\/>soft computing, while the last task focuses on examining the possibility of developing a control theoretic<br\/>model for formalizing the various tradeoff analysis.<br\/><br\/>This project aims at demonstrating that it is possible to achieve significant power and performance<br\/>gain for a wide variety of data intensive applications through soft computing. <br\/>The approach adopted in this research has the potential to influence the programming paradigm for many<br\/>classes of scientific and business applications for optimizing the power-performance behavior.<br\/>The cross-cutting nature of this research has potential to foster new research directions in several areas,<br\/>spanning high performance computing, computer architecture, compilers, and system\/application software.<br\/>Undergraduate and graduate students involved in this research will get versatile training in several areas.<br\/>The software tools developed in this research will be used in teaching<br\/>existing and new courses, and will be made publicly available.","title":"CISE:CNS:EAGER: Exploring Managed Soft Computing for Data Intensive Applications","awardID":"1152479","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550859","542015","542016"],"PO":["565255"]},"184020":{"abstract":"Functional magnetic resonance imaging (fMRI) has become the most common tool for cognitive neuroscience, because it provides a safe, non-invasive, and powerful means to image human brain function. Based on recent rates of publication, there are currently more than 2000 fMRI studies being performed every year worldwide. The aggregation of data across multiple studies can provide the ability to answer questions that cannot be answered based on a single study. For example, using datasets from multiple domains one can start to investigate to what degree a region is selectively engaged in relation to a particular mental process, as opposed to being generally engaged across a broad range of tasks and processes. In addition, it provides the ability to integrate across specific tasks to obtain stronger empirical generalizations about mind-brain relationships, and to better understand the nature of individual variability across different measures. Recent work in neuroimaging analysis has focused on the application of methods such as machine learning techniques to understand the coding of information at the macroscopic level, and network analysis techniques to understand the interactions inherent in large-scale neural systems. The availability of a large testbed of high-quality fMRI data from published studies would also provide an important resource for the development of these and other new analytic techniques for fMRI data. However, sharing of raw fMRI data is challenging due to the large size of the datasets and the complexity of the associated metadata, and there is currently no infrastructure for the open sharing of new fMRI datasets.<br\/><br\/>This project, OpenfMRI, will provide a new infrastructure for the broad dissemination of raw data within cognitive neuroscience, addressing a critical need by providing an open data sharing resource for neuroimaging. The initial project is already online at http:\/\/www.openfmri.org with a limited number of datasets. The full project will greatly expand this repository by providing access to a large number of fMRI datasets from several prominent neuroimaging labs, spanning across a broad range of cognitive domains. Utilizing the substantial computational resources of the Texas Advanced Computing Center, the project will also perform standard fMRI analyses on all data in the repository using a common analysis pipeline, thus providing directly comparable analysis results for all of the studies in the database. The OpenfMRI project will support the development of infrastructural elements to make sharing of data by additional investigators more straightforward.<br\/><br\/>The repository of data that will be created by the OpenfMRI project will also serve as an important resource for teaching by providing students with the ability to replicate the analyses from published studies using the same data. By providing any researcher in the world with the ability to acquire large fMRI datasets, it will also provide all researchers with the ability to work with the same state-of-the-art datasets, regardless of institution. By creating the infrastructure for open sharing of research data, the project will also enhance the impact of other NSF-funded neuroimaging research projects by providing an infrastructure that can be used to make their data available. The planned work has the potential to benefit society by improving education, health, and human productivity through an increased understanding of mental function and its relationship to brain function.","title":"CRCNS Data Sharing: An open data repository for cognitive neuroscience: The Open fMRI Project","awardID":"1131338","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[493497],"PO":["565292"]},"186473":{"abstract":"This project develops unified cognitive network management architecture for end-to-end application-oriented quality of service (QoS) provisioning in heterogeneous cognitive radio networks. The core of the architecture is a unified cross-layer controller, which has two control plans: vertical nodal control plan and horizontal network control plan. The nodal cross-layer optimized resource allocation is guided by the control policy dynamically generated by horizontal network control based on a cognitive agent network, and thus leads to a multi-scale cross-layer architecture for distributive and autonomous application-oriented QoS provisioning for future cognitive radio networks. The transformative significance is two-fold. First, characterizing and understanding the end-to-end network behaviors of cognitive radio networks is of major fundamental research interest. Second, cognitive network management is a technique to implement end-to-end application-oriented QoS provisioning under various randomness and uncertainty in cognitive radio networks. <br\/><br\/>This project provides solutions for a variety of domain-specific applications while addressing future societal needs. By using cognitive network management to implement end-to-end application-oriented QoS provisioning under various randomness and uncertainty in cognitive radio networks, this project benefits other kinds of networks such as the 3G\/4G mobile networks, and WLAN\/WMAN\/WWAN. The research findings will be integrated into networking courses. Research results will be disseminated in journals and conferences.","title":"NeTS: EAGER: C2RN: Towards Cognitive Cognitive Radio Networks","awardID":"1145596","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[500372],"PO":["557315"]},"195196":{"abstract":"Scalable kinship inference in wild populations across years and generations<br\/><br\/>A cornerstone of research in molecular ecology is the reconstruction of family groups (kinship analysis).<br\/>Understanding how individuals in free-living populations are related to each other provides the best<br\/>opportunity to study many important biological processes, ranging from sexual selection to patterns<br\/>of dispersal and recruitment. Recent advances in molecular DNA technologies and computational<br\/>methods have made these studies possible. However, many conceptual and computational challenges<br\/>remain and need to be addressed in order to advance these studies. To date, existing research work<br\/>on kinship analysis has primarily focused on computational methods that address a single relationship, such as parentage assignment or reconstruction of full sib groups. Inclusion of multiple objectives, such as half-sib reconstruction with minimum parentage assignment, or hierarchy over multiple generations, makes formulation of the underlying computational problem extremely challenging, and simple extensions of previous methods do not address in a practical, scalable, and robust manner the problem of kinship reconstruction for data sets that include multiple generations of species or involve multiple optimization functions.<br\/><br\/>The goal of the proposed research is to design robust, parsimonious, and versatile computational<br\/>approaches for inferring multi-generation kinship relationships in wild populations from multiallelic<br\/>markers. Parsimony assumption is fundamental to these approaches as it requires no prior knowledge,<br\/>assumptions about sampling methodology, or existence of models, which is the case for most free-living<br\/>populations. The diverse tasks of this project include formulating computational kinship inference<br\/>problems based on existing biological studies, analyzing computational complexity of and providing<br\/>solutions to the resulting combinatorial optimization problems, and designing robust, scalable and<br\/>efficient high performance implementations. The resulting computational methods will be evaluated<br\/>on datasets collected from existing biological studies and will be deployed to the biological community<br\/>through the Kinalyzer web-based service, currently actively used for sibship inference only.<br\/><br\/>The research proposed in this project will greatly impact diverse application areas including funda-<br\/>mental research in combinatorial optimization and data mining, and within biology, areas as diverse as<br\/>behavioral ecology, evolutionary genetics, conservation, forensics, and epidemiology. The multidisci-<br\/>plinary nature of the project and the research team will enhance curriculum design of related areas and<br\/>introduce new cross-disciplinary courses. This cohesive, multidisciplinary project will provide training<br\/>opportunities in biology, operation research, algorithms analysis, bioinformatics and high performance<br\/>computing, within a single application framework. The project will leverage the diverse scientific ex-<br\/>pertise and extensive mentoring experience of the team to foster a true interdisciplinary collaboration<br\/>and to provide a thriving environment for a new generation of interdisciplinary scientists.","title":"III: Medium: Collaborative Research: Scalable Kinship Inference in Wild Populations Across Years and Generations","awardID":"1231132","effectiveDate":"2011-09-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":["555420"],"PO":["565136"]},"187694":{"abstract":"Recently there has been a rapid growing interest in developing underwater acoustic sensor networks, which can be used in monitoring aquatic environments for scientific exploration, commercial exploitation, and coastline protection. The complexity of aquatic environments and the sophistication of the networking scenarios demand new solutions for underwater networks, and require significant research efforts at every level of the protocol suite. In this project, a novel approach of using surface radios to help underwater acoustics is employed. An integrated hybrid radio and acoustic distributed system for geometrydynamic shallow water applications is developed. This system has numerous benefits such as high energy efficiency, high reliability and low end-to-end delay. Deliverables include solutions to three critical tasks, namely, distributed gateway deployment algorithms to reduce computational complexity, joint optimization with underwater sensor network to improve the whole network performance, and dynamic gateway deployment for mobile network scenarios. A set of protocols and algorithms are also a part of the deliverables. These solutions and algorithms contribute toward the intellectual merit. Beyond the research significance, this project has important impact on education on three fronts including supporting graduate students in their advanced research, supporting undergraduates, women and other under-represented groups, and promoting multi-disciplinary collaborations among faculty and students across departments.","title":"Optimal Surface Gateway Deployment for Underwater Acoustic Sensor Networks","awardID":"1152134","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["505744","559638","526410"],"PO":["565303"]},"175242":{"abstract":"We are at the beginning of a fundamental shift in how content is created and exchanged over the Internet. While content was previously created primarily by a small minority of organizations, now, individual users--empowered by the popularity of digital devices and social networks, as well as the ubiquity of Internet access--are creating content that represents a significant fraction of Internet traffic. Unfortunately, existing techniques and infrastructure are ill-suited for the new patterns of content creation and exchange, resulting in a mismatch of infrastructure and workload that is evident in places ranging from the ways in which content is distributed to the ways in users are able to express access control. To make matters worse, existing providers have been slow to develop new techniques, as their current business models are often heavily reliant on existing approaches. <br\/><br\/>Intellectual Merit: Motivated by these trends, this project is developing systems, networks, and distribution architectures that are tailored to the changing patterns of content creation and exchange, enabling users to freely exchange content and express meaningful privacy policies for end user-generated content. <br\/><br\/>Broader Impact: Fully delegating the responsibility for addressing these challenges to industry risks entrenching the providers of today into a position of ensuring that content can only be shared in ways that are in-line with their business interests. Thus, the impact of the proposed research will be potentially felt by all users of online social networks, and will thus have significant public impact.","title":"CAREER: Systems for the emerging patterns of content exchange","awardID":"1054233","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550216"],"PO":["565255"]},"186132":{"abstract":"While current cellular networks are based essentially on one-to-many and many-to-one single-hop subnets and cope with inter-cell interference by careful centralized resource planning, future wireless networks must consider heterogeneous environments characterized by user-deployed and user-operated infrastructure in which multiple flows and multiple hops will play an increasingly relevant role. Indeed, such networks are expected to open doors to trillions of dollars of e-commerce, while also providing vast amounts of easily accessible knowledge to the public. Developing a fundamental understanding of multihop multiflow wireless networks is therefore critically important at this time.<br\/><br\/>This exploratory project will seek to discover the fundamentals of such networks by obtaining their information theoretic capacity in an approximated sense. It is expected that scalable and extensible solutions are possible for such networks ranging from the seemingly simple ones involving two hops and two flows to apparently more complex ones involving multiple hops and more than two flows with arbitrary connectivity. In so demonstrating, multiple metrics will be employed. These metrics in the increasing order of accuracy in the high signal-to-noise ratio regime are (a) the fundamental limit on the available signaling (temporal\/spectral\/spatial) dimensions of the network, (b) the fundamental limit on the available signaling and signal-level dimensions, and (c) the capacity to within a (universal) constant number of bits independently of channel parameters.","title":"EAGER: Collaborative Research: CIF: Exploring the Fundamentals of Multihop Multiflow Wireless Networks","awardID":"1144041","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["548311"],"PO":["564924"]},"185164":{"abstract":"DePaul University and Loyola University of Chicago propose a project to improve and expand computer science (CS) education in Chicago Public Schools (CPS) high schools. The project will create a high-quality CS course that will serve as the introductory course for all tracks of the three-year CPS Career and Technology Education InfoTech (CTE InfoTech) program that is offered at 32 high schools. The course will adapt and extend the successful pilot \"Exploring Computer Science\" (ECS) curriculum originally developed for the Los Angeles Unified School District. With a focus on computational thinking, the ECS curriculum includes units on Human Computer Interaction, Problem Solving, Web Design, Programming, Computing Applications, and Robotics. This project will create new units on Game Programming and Project Management as alternatives to the Robotics unit. These new units won?t require expensive technology, facilitating the adoption of ECS in a wider range of schools; in addition, they will also better serve some of the tracks being introduced in the newly revamped CTE InfoTech curriculum. To increase adoption beyond the CTE program, the new course is likely to be offered also as a Mathematics elective and it will be a great preparatory course for the new AP Computer Science Principles course that is being developed. Finally, the CPS high school population is 51% African American and 37% Hispanic, making Chicago an ideal location to reach students from underrepresented groups, and leveraging the expertise of the PIs, specific efforts will also be made to achieve a more equitable representation of the female half of the population.","title":"Collaborative Research: Type I: Taste of Computing: Adding a CS Entree to the Education Choices in a Large Urban School District","awardID":"1138515","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[496827,496828,496829,496830],"PO":["561855"]},"186022":{"abstract":"Humankind's knowledge of the world and its ability to manipulate it for the betterment of quality of life and understanding through science, technology, engineering, and mathematics (STEM) is increasingly dependent on the ability to store, access, and manage extremely large persistent data sets representing scientific and process measurements, results from science and engineering simulations, and long-term knowledge. Supercomputers conventionally operate in dual or separate modes: one to do the computations in their temporary (ephemeral)-main memory-and the other to supervise the use of large persistent data storage. As supercomputers get larger, perhaps to the scale of an Exaflops by the end of this decade, the comparable scale and ease of use of mass storage is severely challenged. This research will address the problems of efficiency and scalability of data migration through the vertical memory hierarchy and will unify the way both main memory data objects and persistent storage data are named creating a single, easy to use programming. This will revolutionize data intensive supercomputing and establish a new path towards future Exascale system design and programming. This research is in collaboration with Clemson University to provide a proof-of-concept system to evaluate the new concepts.<br\/><br\/>The semantic and performance barriers between computing in main memory and manipulation of mass storage for persistent data have imposed significant limitations to performance and programmability. Because of uncertainties of access latency times combined with overheads and the need to exploit data access parallelism for high throughput, a new relationship between ephemeral storage and persistent objects is needed to unify their association and manage the asynchrony of operation while achieving high efficiency. This research is deriving an innovative execution model and developing a proof-of-concept experimental system to test and evaluate its underlying concepts for a new generation of persistent mass storage at extreme scale. It will address the challenges and provide the means for the unification of the semantics of ephemeral and mass storage through a single abstraction of data manipulation and the integration of meta-data and synchronization to manage asynchrony and uncertainty of response time as well as logical conflicting accesses while automatically hiding latency. The new model will support dynamic data path management for the asynchronous vertical storage hierarchy, exploiting adaptive runtime event-driven techniques for enhanced efficiency and scalability including management of vertical transport of data, which demands an innovative strategy of dynamic control of the entire data path.","title":"EAGER: Dynamic Data Path Management for Asynchronous Vertical Storage Hierarchy","awardID":"1143565","effectiveDate":"2011-09-01","expirationDate":"2012-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"K155","name":"National Security Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563330","563330","563331","563331"],"PO":["565136"]},"185175":{"abstract":"Location-based services are rapidly gaining traction in the online world as they allow highly personalized services and easier retrieval and organization of multimedia. However, such services require accurate geolocation information (geo-tags) to be associated with the multimedia data e.g., videos. Because only a small fraction of available video data is geo-tagged. Hence, there is a growing interest in systems that estimate the geolocation of a given video automatically that does not include geo-location metadata. While machine learning offers a potential approach to training automatic location estimators, it requires a standardized training corpus of geo-tagged videos. Automatic collection of videos introduces a bias toward videos that are easily processible by machines and towards geographical locations that are over-represented in current corpora. Hence there is a need for carefully curated standard data sets. <br\/><br\/>This EArly-concept Grants for Exploratory Research (EAGER) project explores a novel, somewhat high risk, approach to collecting such an annotated training corpus of geo-tagged videos using Mechanical Turk (http:\/\/www.mturk.com), a \"marketplace for work\" for engaging workers with the desired expertise from around the world to work on a specific task, in this case, participating in a game that involves annotating videos with geolocation metadata e.g., GPS coordinates. The user interface for the game will allow participants to estimate the location of videos by clicking on a map. The knowledge gained from this EAGER would set the stage for more comprehensive geotagged multimedia data collection efforts. The resulting data sets and benchmarks will be made available to the research community to enable detailed and systematic comparative analysis of alternative methods (e.g., machine learning algorithms for predicting geolocation information from videos). <br\/><br\/>The availability of standardized geo-tagged multimedia data sets will help drive advances in machine learning techniques for geo-location prediction. The resulting advances in geo-tagging multimedia data would enable intelligent location based services and a variety of domains including law enforcement, personalized and location-aware media retrieval, for a variety of applications including journalistic and criminal investigations.","title":"EAGER: Collecting Training Videos for Location Estimation with Mechanical Turk","awardID":"1138599","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["558409"],"PO":["560586"]},"177200":{"abstract":"Researchers and providers alike are recognizing that human-centric smart environments can provide health monitoring services and support aging in place through adaptive interventions. The need for the development of such technologies is underscored by the aging of the population, the cost of formal health care, and the importance that individuals place on remaining independent in their own homes. The goal of this project is to design, implement, and evaluate in-home techniques for generating reports of activities and social interactions that are useful for monitoring well being and for automating intervention strategies for persons with dementia. The plan is to design machine learning techniques that make effective use of sensor data to perform automated activity monitoring and prompting-based interventions that are beneficial for the residents as well as for their caregivers and family. The environment is human-centric because it learns information about its human residents and uses this information to provide activity-aware monitoring and intervention services. By transforming everyday environments into smart environments, many older adults with cognitive and physical impairment can lead independent lives in their own homes. A key component of this project is an evaluation of the technologies in actual homes with volunteer older adults and thus will assess the technologies for acceptance with the target population. <br\/><br\/>This project addresses NSF?s Smart Health and Wellbeing goal of leveraging computational expertise leading to fundamental advances in the development of algorithms to create improvements in safe, effective, and patient-centered health and wellness services. The development of a Gerontechnology class is focused on training students to design and use these technologies. This effort includes REU and IGERT students in the research project, which involves students from underrepresented groups in this multidisciplinary, collaborative effort. To facility community-wide use, comparison and collaboration, all of our datasets, tools, and course materials will be disseminated from our project web page.","title":"SHB: Medium: Collaborative Research: Crafting a Human-Centric Environment to Support Human Health Needs","awardID":"1064628","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["547675"],"PO":["564768"]},"177321":{"abstract":"This project advances computer science by producing scientific insights, algorithms, system designs, implementation techniques, and experimental validations at the intersection of three major subdisciplines. These subdisciplines are (1) computer systems (including mobile computing, operating systems, and wireless networking), (2) vision technologies (including computer vision and machine learning), and (3) human-computer interaction (including activity inferencing, distraction reduction, and context awareness). These will be integrated to create cognitive assistive systems that can function \"in the wild\" with sufficient functionality, performance and usability to be valuable at any time and place to provide help for the cognitively impaired.<br\/><br\/>From a societal perspective, this research has the potential to improve the quality of lives of individuals whose cognitive capabilities have declined due to natural aging, illness or traumatic injuries (estimated at 20 million Americans). In addition, cognitive support can assure safe use and compliance with instructions in rehabilitation and management of chronic illness. From an educational viewpoint, this research offers many unique opportunities to train graduate and undergraduate students on how to approach problems from a broad multi-interdisciplinary perspective. In close partnership with industry, this research has the potential to impact mobile computing by empowering resource-poor mobile devices to run interactive, compute-intensive applications at any time and place. While this proposal focuses on applying this new capability to the problem of cognitive assistance, it can also address important needs of the general population. Further, the resulting cloudlet architecture has the potential to transform arenas as diverse as business, engineering, health care, and defense.","title":"SHB: Medium: Assistive Cloudlet-Based Mobile Computing for the Cognitively Impaired","awardID":"1065336","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["520920","492191",475390],"PO":["564768"]},"177233":{"abstract":"Access to communication plays a pivotal role in the socio-economic development of any nation. While the Internet has revolutionized the development of economic, social, financial and educational sectors of the industrialized world, it has also created a 'digital divide' that separates the affluent and developed nations from the developing and under-developed regions of the world. Significant progress has been made in bridging this digital divide by bringing Internet connectivity to rural regions through Internet kiosks and cafes whereby citizens travel, often by foot, to these central areas in order to access the Internet. While clearly Internet access through this model is much better than no access at all, these public terminals are not a satisfactory end solution due to long travel distances from homes, limited hours of availability, high usage costs, and long wait times.<br\/><br\/>The goal of this research is to extend Internet connectivity from the point where it is brought into the community by a long distance link (i.e., satellite, long range WiFi, etc.), to provide coverage throughout the village such that residents have Internet access in their homes, offices, schools and public buildings. The research consists of an ambitious, integrated set of research projects that provides Internet connectivity throughout a village in a developing region. The work differs from, and is complementary to, prior work on rural wireless networks in that the focus is, not on the long-distance links that connect the local network to the Internet, but on the development of solutions that provide widespread, local coverage across a geographically dispersed community for currently available end devices. Working in partnership with rural Zambians, a network architecture will be developed that greatly enhances Internet access in rural Africa and elsewhere. This work makes several key contributions:<br\/><br\/>- To provide widespread connectivity across a geographically dispersed rural community, a customized cross-layer protocol stack for the white spaces spectrum will be developed. This stack includes an integrated PHY\/MAC layer, called a transmission layer, that jointly considers interference properties, energy constraints and application requirements to select transmission parameters and channel access strategies to most efficiently utilize available spectrum.<br\/><br\/> - To minimize impact on already congested Internet gateway links, a novel network architecture and supporting application, called VillageShare, will be designed to isolate local network traffic: traffic that originates and ends within the local community network completely avoids the gateway link. As discovered in preliminary work, unnecessary transmissions on the gateway link constitute a catastrophic problem for rural communities and lead to aborted sessions, dropped connections, and poor end user experience.<br\/>- To decrease connectivity cost and provide Internet access to users without home computers, this work will develop VillageCell, a low-cost femtocell-inspired system that provides off-the-shelf cellular phones with free local Internet, voice and chat access utilizing the white spaces network as a backbone.<br\/>- To evaluate the efficacy of the work and influence the solution design, a qualitative ethnographic study of ICT in the community of Macha, Zambia, will be conducted through cooperation with partner institutions. The study will explore the social, cultural and economic impacts of developed solutions, and ensure solutions are designed in partnership with rural Zambians.<br\/><br\/>- To demonstrate the benefits of our integrated system, we develop RemoteMath, an SMS\/voice-based mathematics tutoring system through which students can obtain after school assistance on math homework.<br\/><br\/>Broader Impact. The work from this award will have far-reaching impact by expanding the utility of Internet access in developing regions. Prior research clearly indicates the vast economic, social and educational benefits of Internet connectivity in a rural community. Through the principal investigators' (PIs) partnership with two African organizations, the work will directly impact local Africans through the development and deployment of technology that solves complex technological problems while enabling practical, deployable solutions. Locally, the immediate impact of this work is the education of undergraduate and graduate students about the vast potential for societal impact of computer science research. The PIs will leverage their participation in the UCSB Center for Information Technology and Society (CITS) to create an interdisciplinary course on technology for developing regions. In a time when CS enrollments are shrinking, the PIs will use the societal impact of this work to increase student enthusiasm, enrollment, and diversity.","title":"NetSE:Medium:VillageNet: Intelligent Wireless Networks for Rural Areas","awardID":"1064821","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["560332",475145],"PO":["565090"]},"177354":{"abstract":"Malicious and exploitable web advertisements (ads) are widely recognized as a major emerging source of online attacks and privacy violations. Rogue ads can often escape existing weak defenses employed by ad networks and websites, inflicting much harm on end-users. This ad security crisis is exacerbated by several factors: complex mechanisms by which web ads are produced, distributed and deployed; weak filtering strategies of ad networks; web sites' inability to control content supplied by ad networks; and poor browser-level primitives for ad isolation and confinement.<br\/><br\/>This project tackles the ad crisis by developing a comprehensive framework that integrates and extends recent research on browser-level script sandboxing, bytecode in-lined reference monitoring, information flow analysis, and binary code certification. A key priority is to transparently preserve important web ad technologies, such as ad-billing, Flash-JavaScript interoperability, cross-site scripting, and ad network contextual targeting. The complementary strengths of the two PIs forms a natural synergy that lends itself to an elegant and easily adoptable framework for protecting users from the severe online security and privacy risks currently posed by malicious ads.<br\/><br\/>With the web advertisement industry estimated to be at a USD $50 billion mark in 2010, the techniques developed by this project are contributing to the vitality of this industry. To maximize impact, the PIs are transitioning results from this research to the industrial sector engaged in the development of ads as well as their dissemination.","title":"TC: Medium: Collaborative Research: Securing Web Advertisements: Fixing the Short-term Crisis and Addressing Long-term Challenges","awardID":"1065537","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["532213"],"PO":["562974"]},"186066":{"abstract":"Linked Open Data (LOD) is rapidly developing into an open data movement to connect a large variety of data across the World Wide Web using standards adopted by the World Wide Web Consortium (W3C). Driven by researchers, government agencies and companies, the resulting Web of Data has grown to over 25 billion RDF triples and is showing exponential growth. However, simply putting collections of data on the Web will be of very limited value. The key to unlocking the value for developing more powerful search, browsing, exploration and analysis is to richly interlink or semantically integrate components of LOD. Given the size, growth rate, heterogeneity and growing areas of coverage, manual semantic integration or interlinking is not practical. Furthermore, current techniques focus on 'same-as' relationship, which is much abused due to limited expressivity. This calls for ways to represent and identify richer and more explicit relationships between different entities that reflect the richness of relations that exist in the real world.<br\/><br\/>This project develops exploratory techniques to richly interlink components of LOD and then addresses the challenge of querying the LOD cloud, i.e., of obtaining answers to questions which require accessing, retrieving and combining information from different parts of the LOD cloud. Techniques for overcoming semantic heterogeneity include: semantic enrichment through Wikipedia bootstrapping; semantic integration through abstraction by means of upper-level ontologies; and, massively parallel methods for tractable ontology reasoning. Specifically, this research will: (1) identify richer, broader, and more relevant relationships between LOD datasets at instance and schema level (these relationships will promote better knowledge discovery, querying, and mapping of ontologies); (2) realize LOD query federation through an upper level ontology; and, (3) enable access to implicit knowledge through ontology reasoning. The project involves significant risk as it treads new paths in a new terrain, primarily due to the lack of descriptive information (schema) about the data provided by highly autonomous data sources, the significant syntactic and semantic heterogeneity among data originating from independent data sources, and the significantly larger scale, as well as unforeseeable obstacles associated with a rapidly changing and expanding environment. <br\/><br\/>This project aims to advance the state of the art in semantic integration of large amounts of heterogeneous and autonomously developed or managed data. It seeks to fundamentally transform the landscape of LOD usage because successful LOD querying is a key enabler for a variety of applications. The results of this project could set the stage for the development, and the far reaching adoption, of Semantic Web. The project is integrated with education and research-based advanced training of graduate and undergraduate students. Additional information about the project can be found at: http:\/\/knoesis.org\/research\/semweb\/projects\/ESQuILO.","title":"III: EAGER - Expressive Scalable Querying over Integrated Linked Open Data","awardID":"1143717","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563585","560054"],"PO":["565136"]},"178212":{"abstract":"The intersection of Computer Science and Economics has become increasingly important to the development of both fields. Today's software often must handle multiple individuals with their own interests in mind, bringing incentive issues to the forefront in algorithm design. Economic problems, especially in electronic commerce, increasingly involve large numbers of goods and buyers as well as unknown and complex market conditions, making algorithms and machine learning of key importance. This project aims to address fundamental questions at the heart of the intersection of these two fields. These include problems of modeling and influencing behavior in systems with large numbers of agents and components, problems of optimization under complex and changing preferences and constraints in electronic commerce, and problems of efficiently computing and estimating basic economic quantities.<br\/><br\/>This project specifically has three main thrusts. The first is development of algorithms and analysis techniques for positively influencing dynamics in systems with large numbers of interacting agents. For example, if behavior is currently at a poor-quality equilibrium, when can additional information or few targeted incentives be used \"nudge\" behavior towards a good equilibrium? This applies not only to self-interested agents but also to components in a distributed system acting on local information (such as sensors in a sensor network). The second thrust is development of algorithms for efficiently computing or estimating important economic quantities. This includes approximately computing Nash equilibria in large interactions, and learning submodular functions and other common valuation classes from observations of behavior or experimentation. The third thrust is developing mathematical frameworks for understanding and solving problems of pricing and resource allocation in settings with unknown and changing market conditions. These frameworks are crucial for next-generation markets of resources such as computing power and network bandwidth.","title":"ICES: Small: Collaborative Research: Algorithms and Mechanisms for Pricing, Influencing Dynamics, and Economic Optimization","awardID":"1101215","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":["554195"],"PO":["565251"]},"177244":{"abstract":"Mobile handheld devices such as smartphones, PDAs, and smart media players have outpaced the growth of wired hosts, and are emerging as the predominant vehicle for Internet access. In recent years, newer mobile phones, including various versions from Apple, Google, Nokia, and others, have promoted greater programmability, radically changing the age-old model of mobile phones being a closed platform. However, openness arrives with new challenges of trustworthiness. The goal of this project is to improve the trustworthiness of mobile phones in their daily operations, by analyzing threats that occur either due to malware or due to regular applications, designing mitigation strategies, and evaluating developed solutions through a real deployment on a smartphone platform (Google Android) and operating in a real network (Sprint-Nextel).<br\/><br\/>This project will undertake crosscutting research, educational, and outreach plan to improve the robustness, reliability, security, privacy, and overall trustworthiness of mobile phones. The primary focus of this project will be on performance and security threats that are unique to mobile phones, including malicious applications that ex-filtrate data, performance loss due to resource constraints, privacy threats of lost devices, and remote network-based attacks. Specifically, this project will investigate issues related to following topics: (i) performance instability due to resource constraints (ii) protection against malicious applications (iii) privacy against lost phones (iv) detection and prevention against other network attacks. Techniques developed will have broad benefits to research and society. These techniques will enhance the trustworthiness of mobile phones, thereby improving the confidence of users in using these devices in their daily activities. An educational plan will introduce new curriculum centered on the mobile phone platform and establishes a new undergraduate laboratory for hands-on mobile device programming.","title":"TC: Medium: Collaborative Research: Building Trustworthy Applications for Mobile Devices","awardID":"1064944","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["521593","560207","559530"],"PO":["564388"]},"188376":{"abstract":"In this project, the PIs study secure computation outsourcing in cloud computing with the focus on widely applicable engineering computing and optimization problems. Their methodology is to explicitly decompose computations into public programs and private data and leverage the structures of specific computations for achieving desirable trade-offs among security, efficiency, and practicality. <br\/><br\/>The PIs propose to organize the mechanisms into a hierarchy where computation can be represented at various abstraction levels, and then explore a systematic methodology consisting of the following three methods: (1) problem transformations that encrypt the data such that the computation can be performed on the same abstraction level, (2) procedure transformations that leverage the mechanisms defined at a lower abstraction level as a subroutine for secure computation outsourcing, and (3) structural-preserving transformations that further improve the practical efficiency of mechanisms by maintaining favorable problem structures. <br\/><br\/>The PIs expect the outcomes of this research to be adopted by application developers, who will build applications to support secure computation outsourcing either privately for end-users within the same organization, or for public end-users resembling the practices of software-as-a-service (SaaS).","title":"CSR: Small: Collaborative Research: Engineering Secure Data Computation Outsourcing in Cloud Computing","awardID":"1155988","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564847"],"PO":["565255"]},"180390":{"abstract":"Crowdsourcing is a powerful way to marshal small contributions from large numbers of people to solve real-world problems. Success stories range from classifying craters on Mars' surface (ClickWorker) to labeling images (the ESP Game, now Google Image Labeler) to task marketplaces (Amazon's Mechanical Turk). This project moves towards a vision of crowdsourcing that extends it to support complex, creative, and interdependent tasks, and embeds it into computing systems as part of our everyday lives. The project will focus on two application areas for complex crowdsourcing: science journalism and software development.<br\/><br\/>The intellectual merits of the project include the uncovering of new scientific knowledge about how to model online crowd behavior, and the development of new methods and tools for using crowds as part of computer system designs, particularly for complex, interdependent, real time work. The project will also show that these methods can be used for real-world problems. <br\/><br\/>The potential broader impacts include those specifically having to do with the two application areas, which could have significant impacts on society. Crowdsourcing science journalism will directly involve citizens in the process of science dissemination, making scientific information more accessible to the general public, and promoting greater awareness of science and the scientific process. Crowdsourcing software development can transform the way that software is created, lowering barriers and broadening participation in open source software development, and helping larger masses of people use and improve their programming skills. Other impacts will flow from the researchers' plans to publically share the infrastructure that they develop to facilitate complex crowdsourcing in many other areas. They also plan to integrate their research results into undergraduate courses.","title":"Collaborative Research: Programming with Crowds: Models and Tools for General Purpose Crowdsourcing","awardID":"1111124","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["517858"],"PO":["563324"]},"181490":{"abstract":"The massive energy consumption of today?s datacenters translates into high monetary and environmental costs; the latter because most of the electricity produced in the US comes from burning coal, a greenhouse-gas-intensive approach for producing energy. We refer to such energy as ?brown?, as opposed to the ?green? energy produced by clean energy sources.<br\/>An increasingly popular approach for reducing both costs is for datacenters to generate their own green energy or draw power directly from a nearby green energy plant. In light of this trend, the goal of this project is to study how best to exploit solar and wind energy for lowering energy costs and brown energy consumption in datacenters. The major challenge in using these types of green energy is that they are not always available.<br\/>In this context, our research focuses on: (1) Characterizing and modeling datacenter workloads and green energy production; (2) Designing load scheduling and energy usage policies; (3) Designing energy management policies that account for green energy; and (4) Designing systems that leverage our models and policies.<br\/>Our project will impact society in many ways, including: (1) reducing the brown energy consumption and the carbon footprint of datacenters; (2) promoting the generation and consumption of green energy; and (3) creating the machinery needed to exploit green energy in datacenters for highest bene&#64257;t. Furthermore, we believe that undertaking work with such clearly de&#64257;ned societal impact will help us attract and train a diverse and committed set of undergraduate and graduate students.","title":"CSR: Small: Scheduling Energy Consumption in Green Datacenters","awardID":"1117368","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["486839","556616"],"PO":["565255"]},"181391":{"abstract":"This project aims to study computational tractability of several fundamental problems concerning cuts, flows, and matchings in networks. For instance, how does one design a minimum cost network that realizes a given set of pair-wise connectivity requirements among the nodes? How does one assign routes in a network so as to avoid congestion? How fast can one find an assignment of tasks to machines so that each task is assigned to exactly one machine capable of executing the task and no machine is given more than one task? Together, these are among the most widely studied combinatorial optimization problems, and it is no surprise that the study of these problems is connected to major developments in algorithms design, hardness of approximation, and graph theory. The goal of this project is to design improved algorithms for these and related problems as well as to identify the complexity of obtaining near-optimal solutions for them.<br\/><br\/>The problems outlined in this proposal are intrinsic to many applications, and thus improved algorithms for these problems are of value to computer science and related disciplines where these optimization problems routinely arise. The research proposed here will go hand-in-hand with educational and student-training initiatives as well as outreach activities. The PI will integrate topics from this research in an advanced undergraduate course that will include research opportunities for students. The PI will also develop a lecture series to introduce high school students to exciting ideas in theoretical computer science.","title":"AF: Small: Cut, Flow, and Matching Problems in Graphs","awardID":"1116961","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["497006"],"PO":["565251"]},"181281":{"abstract":"Most research on target monitoring using sensor networks requires the geographic locations of the sensors to be known. However, in practice, it is not always possible for every sensor node to have a built-in GPS-like capability. On the other hand, applying a localization procedure to all the sensor nodes can be expensive for large networks. Even if the location information of many sensors can be computed, it may never be used because targets usually appear very sparse. <br\/><br\/>This project, therefore, tackles the target monitoring problem in the context of low-cost sensor networks, where a sensor node does not need built-in capability to determine its location. Instead, hopcount information serves as the primary source of information to track the target. The challenges result from the unknown mobility and nature of the target and the coarseness of the hopcount data. The matter is more sophisticated if there are multiple moving targets and it is not known whether they move in groups or independently.<br\/><br\/>The research objective of the project is to design and implement a novel solution framework to address these challenges. This framework, based on a machine-learning approach, can be applied to a wide range of sensor networks which can have modest resource capacities or be deployed in non-conventional physical settings such as under the water or on wet ground. Building on the research, an education plan is proposed that seeks to transfer knowledge to younger generations, improve student enrollment and retention, and encourage active participation from students of under-represented groups.","title":"NeTS: Small: Target Monitoring with Low-Cost Sensor Networks","awardID":"1116430","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[485752,485753],"PO":["565303"]},"181292":{"abstract":"Recognizing speech or other auditory objects in adverse environments -- e.g. with noise, reverberation, and multiple speakers -- is essential for human and animal communication. Current speech recognition technologies work well in high signal-to-noise conditions, but perform orders of magnitude below human performance in adverse conditions. Converging evidence from neuroscience suggests that auditory information is encoded in sparse and precisely timed spikes of sub-cortical neurons. However, the extent to which codes based on spike timing might underlie the robustness of human auditory object recognition has not yet been fully investigated. This project bridges this gap by devising a biologically inspired computational model of auditory processing at the cortical level and extracting computational principles that are essential for the model to achieve robust auditory object recognition.<br\/><br\/>The approach is to transform sounds into the spike sequences generated by feature-detecting thalamic auditory neurons, and to integrate these spikes spatially and temporally using the state-dependent dynamics of cortical neurons with active dendrites. In the proposed model, an auditory object first evokes sequential spiking of thalamic neurons that have been trained to detect useful features. Then, through feed-forward excitation and inhibition from the thalamus, and lateral excitation and inhibition from the cortical neurons, the state of the cortical network evolves, leading to temporal integration. Recognition of the auditory object is signaled when the cortical neurons reach a specific network state. The computational model is constrained by experimental results on the properties of cortical neurons, the organization principles of cortical networks, and the activity-dependent plasticity rules of the network structures. The project aims both to design feature detectors that can robustly represent auditory objects with spatiotemporal spike sequences, and to build a cortical network model that can recognize specific auditory objects using state transitions driven by the thalamic inputs, with neuron dynamics that can be compared with those observed in the auditory cortex. The recognition performance of the computational model will be evaluated and improved with auditory tasks designed to compare different approaches to speech recognition.","title":"RI: Small: Robust Auditory Object Recognition with Spike Sequence Coding and the State-Dependent Dynamics of Cortical Networks","awardID":"1116530","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[485777],"PO":["564318"]},"183152":{"abstract":"Proposal #: CNS 11-26709<br\/>PI(s): Andresen, Daniel; Caragea, Doina; Dodds, Walter K; Esry, Brett; Steward, David R. <br\/>Institution: Kansas State University<br\/>Title: MRI\/ Acq.: A Hybrid GPU Computing Cluster High-End Applications in Science and Engineering<br\/>Project Proposed:<br\/>This project, acquiring a hybrid computing cluster for high-end applications in science and engineering, services, among others, bioinformatics, ecological modeling, and physics. GPU-based computing support for distributed memory parallel applications constitutes a specific novel feature of the cluster.<br\/>The work aims to support the following activities:<br\/>- Modeling genomes, hyper-extractive economies, and ecological forecasting (by bringing much greater computational power) and,<br\/>- Enabling new science utilizing the instrument to develop new algorithms in physics modeling and genomics. <br\/>Broader Impacts:<br\/>Mainly, the multidisciplinary nature of the proposed research provides the broader impacts. Expected are large broader impacts on basic physics research. It is expected to also impact on medicine through the development of better molecular models to view how our proteins and membranes interact. Planned are training activities of a new generation of researchers in tools and techniques for high-performance computing. The PIs would build on the broad past experience in preparing widely-used undergraduate and graduate educational materials, allowing students to perform real-world projects and impacting K-12 and STEM education. Hence, the project aims to significantly enhance and integrate our educational efforts at the K-12, undergraduate and graduate levels in bioinformatics.","title":"MRI: Acquisition of a Hybrid GPU Computing Cluster High-End Applications in Science and Engineering","awardID":"1126709","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["555229","559268",491046,491047,"559271"],"PO":["557609"]},"184483":{"abstract":"IIP 1134684 <br\/>University of Cincinnati; Lee <br\/><br\/>IIP 1134676 <br\/>University of Michigan; Ni <br\/><br\/>IIP 1134721 <br\/>Missouri University of Science and Technology; Sarangapani <br\/><br\/>The NSF Industry\/University Cooperative Research Center (I\/UCRC) on Intelligent <br\/>Maintenance Systems (IMS) was established in 2001. This proposal builds upon the accomplishments of the previous ten years and seeks funding to continue supporting a three campus operation among the University of Cincinnati (leading institution), the University of Michigan, and Missouri Univ. of S&T. <br\/><br\/>The Center addresses the underlying issues in machine degradation modeling and prediction as well as develops the transformational technology in advanced prognostics. Over the past 10 years, the Center has developed systematic methodology and tools that made evident impacts to a number of member companies including Toyota, G.M., Boeing, P&G, and National Instruments, amongst others. Over the next five years, the Center intends to advance the scientific base as well as to validate the developed tools to further accelerate the deployment and commercialization of the developed technologies. The center also plans to have international sites in Singapore, Brazil and Spain. In addition, the Center plans to develop spin-off companies with a compelling Marketing Plan in order to commercialize its tools through its member company, National Instruments, in 2011. <br\/><br\/>The IMS IUCRC fills an important niche to maintain industry global competiveness by continuous improvement of manufacturing effectiveness and efficiency. The center educates students and its membership through an extensive system of internship and scholar exchanges as well as international workshops and courses. IMS has developed and continues to execute an effective system for innovation and IP generation. The Center plans to develop spin-off companies with a compelling Marketing Plan in order to commercialize its tools through its member company, National Instruments, in 2011.","title":"IMS I\/UCRC: Five Year Renewal","awardID":"1134676","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":["554242"],"PO":["564474"]},"181095":{"abstract":"This project aims at a systematic approach that integrates multi-level IC design automation <br\/>flow by leveraging the parallel computational power in current and upcoming multi-core\/many-core <br\/>processors. The main challenge in this approach is to provide responsive high-level design decisions <br\/>while incurring the massive computational cost of lower-level design algorithms. Fortunately, recent <br\/>trends in processor architectures provide a solution. Compared with traditional uniprocessor systems, <br\/>emerging multi-core\/many-core microprocessors have far more computational power but limited global <br\/>memory access capabilities. Parallel computational power may make it possible to break <br\/>the boundaries of the existing IC design hierarchy and to vertically integrate the IC optimization fow. <br\/>The potential benefits of an integrated solution are significant - accurate high-level design decisions <br\/>become possible as low-level design details are derived concurrently, and low-level designs can also <br\/>greatly benefit from high-quality high-level decisions. Together, an efficient and high-quality design flow <br\/>becomes feasible, making design closure faster, thus saving time and reducing costs. <br\/><br\/>The proposed work has the potential to overcome the key limitations of existing hierarchical IC CAD <br\/>technologies and enable new IC design automation solutions, which in turn can benefit the IC and <br\/>semiconductor industry. The PIs will work together with their industrial collaborators to develop and <br\/>commercialize the proposed work. The project will have beneficial impact on education. <br\/>The PIs intend to educate the next generation of software developers and practicing engineers <br\/>in the design and innovation of IC design automation and parallel computing.","title":"SHF: Small: Collaborative Research: A Systematic Approach to Multicore Parallel CAD","awardID":"1115550","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[485312],"PO":["562984"]},"187761":{"abstract":"Large-scale science and engineering campaigns have typically considered data management from the inception of the project and funds for data management have been included in the projects' budgets. This proposal is aimed at data acquisition and curation strategies in support of single PI or small group research projects at academic institutions, data in the so-called \"long tail\". Long-term data management in these projects is much more problematic and particularly acute. Smaller research projects are often strapped for funds to conduct the research that generates the data; management of the data was in the past often an afterthought. With data management plans now being required by funding agencies, the issues must be considered as part of a proposal, but the funding available for date management is still frequently small and economical resources available to researchers still need to be cultivated. At academic institutions, the institutional repository (IR) has emerged as the means of harnessing technology to improve scholarly communication and it is the IR that offers the potential to address the data curation problems of smaller projects. Although institutional repositories have a broad intuitive appeal to all the stakeholders involved with science and engineering data management, they have met with very limited acceptance in practice. This proposal seeks to increase faculty contribution of their data to the IR by appealing to their needs directly and providing them with tools and support for developing personal repositories that can subsequently be federated into the IR. The strategy is to lower the barrier of entry to archiving facilities and to provide incentives for researchers to participate.<br\/><br\/>Broader impacts will be realized in two key areas. First, archive and preservation of datasets will be enhanced by increasing the participation of faculty and researchers generating data at the nation's research institutions. Second, open source software well be available for deployment by other institutions beyond the project's partners thereby increasing the effectiveness of dataset archiving and sharing across a growing set of participating institutions. The project will also offer research and training opportunities to undergraduate and graduate students involved as software developers and data consultants who interact with faculty and other researchers as part of the project.","title":"EAGER: INSPIRE: Institutional Support for Personal\/Institutional Repository Environments","awardID":"1152481","effectiveDate":"2011-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["355797",503343],"PO":["565136"]},"187530":{"abstract":"The increasing popularity of cloud storage and cloud computing is leading organizations to consider moving data and computation out of their own data centers and into the cloud. However, success for cloud providers can present a significant risk to customers; namely, it becomes very difficult and expensive to switch providers. This research agenda will explore methods that allow cloud customers to diversify the set of cloud storage and cloud computing providers they use. Further, it will model, measure, and optimize the resulting more diverse systems. <br\/><br\/>To diversify cloud storage, the research agenda includes investigating how to apply RAID-like techniques used by disks and file systems, but at the cloud storage level. By striping user data across multiple providers, customers can avoid vendor lock-in, reduce the cost of switching providers, and better tolerate provider outages or failures. A redundant array of cloud storage providers (RACS) acts as a proxy that transparently spreads the storage load over many providers. To diversity cloud computations, the research agenda investigates a data model and structure that allows computation to be sent to where the data is stored and performed directly on local data. This new diversified storage cloud and diversified compute cloud has the potential to return control back to the user for assurance on the integrity of data and computation, while still benefiting from the whole cloud paradigm.","title":"Parallacs: Research in Storage and Compute Cloud Diversity","awardID":"1151268","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[502829],"PO":["565255"]},"186320":{"abstract":"The goal of this project is to develop a system that combines the strengths of both human and computer capabilities to help solve a complex societal problem: global climate change. The project will develop an on-line community called the Climate CoLab, in which many thousands of people around the world create, analyze, and ultimately select detailed plans for what humans can do about climate change. At the core of the system will be an evolving collection of user-created proposals based on computer simulations of the actions humans can take and the predicted impacts of those actions. Users will also be able to debate the pros and cons of different proposals and vote for the proposals and arguments they find most credible and desirable. By integrating three capabilities (computer simulation models, on-line debates, and electronic voting) in a novel way, the system lets a very large group of people define and evaluate alternative problem solutions while computers do the rapid calculations needed to assess key consequences of each alternative. By including relevant experts from different disciplines and members of the public who have novel points of view, the community can consider a wide range of plausible alternatives. And by involving policy makers and large numbers of citizens, the eventual political adoption of the most promising alternatives is facilitated. <br\/><br\/>Intellectual merit: The primary intellectual contributions of this work will be generalizable lessons about how to design large-scale, on-line communities that use computational models to help solve difficult societal and managerial problems. <br\/><br\/>Broader impacts: The project will help educate the general public about the issues involved in global climate change. In addition, by constructively engaging a broad range of scientists, policy makers, and concerned citizens, this system may help develop plans and policies that are actually better than any that would have otherwise been developed.","title":"EAGER: The Climate CoLab: A System for Very Large-Scale Model-Based Group Problem-Solving","awardID":"1144663","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[499969,"551967","551789"],"PO":["565227"]},"183064":{"abstract":"Proposal #: CNS 11-26327<br\/>PI(s): Lee, Tai-Chi; Freed, Alan D; Hallouche, Farid; Kotsidou, Kassiani<br\/>Institution: Saginaw Valley State University<br\/>Title: MRI\/Dev.: Custom Platform with Parallel Application from Rapid Simulation (PARS) Interconnecting DSPs and FPGAs for High Performance Computing.<br\/>Project Proposed:<br\/>This project, developing an instrument for high performance computing based on PARS technology with multiple digital signal processors (DSP) and field programmable field arrays (FPGAs) (as well as inclusion of an embedded processor with custom instructions capability, a development tool from Altera EP1C12 NIOS II), allows users to run their applications on the entire system within the Simulink environment and then automatically generate code for multi-DSP and multi-FPGA in the system. The research activities enabled by this instrument are expected to spotlight the need for adding the capabilities of parallel processing and reconfigurability offered by FPGA and DSP, as well as suggest important applications of the instruments in various areas of science. These areas include mathematics (number theory, fixed point mapping), computer science (data structures, algorithm analysis, computer architectures, and networking), and engineering. The instrument will service the following five projects: <br\/>- Fractal image compression, <br\/>- Cryptosystem with elliptic curve, <br\/>- Experimental soft-tissue mechanics, <br\/>- Image processing, and <br\/>- DSP implementation for measuring ultrasonic waves.<br\/>Broader Impacts: <br\/>The acquisition of the platform will provide the faculty members from many disciplines a parallel platform including both DSPs and FPGAs, and expose cutting-edge computing to students. Students will be trained in the use of new and novel technologies that might impact an economically depressed area by providing a trained workforce. SVSU has good outreach to secondary school teachers and K-12.","title":"MRI: Development of Custom Platform with Parallel Application from Rapid Simulation (PARS) Interconnecting DSPs and FPGAs for High Performance Computing.","awardID":"1126327","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[490641,490642,490643,490644],"PO":["557609"]},"187420":{"abstract":"The Internet's astounding success and growth can also lead to its gradual `ossification', hampering its ability to evolve and accommodate new services and applications. To address this problem, Software-Defined Networking (SDN) has been proposed as a way to 'program' networks and make it easier to deploy new protocols and new applications, as well as tune network performance. To-date, SDN techniques have, for the most part, targeted infrastructure-based networks. However, as self-organizing, infrastructure-less networks become more prevalent and ubiquitous, they will become integral parts of the Internets of the future, enabling a variety of applications such as vehicular communications, community services, healthcare delivery, emergency response, environmental monitoring, to name a few.<br\/><br\/>Motivated by this vision of the internet of the future, this project will develop Hybrid-SDN, or H-SDN, which will enable SDN in future internets consisting of infrastructure-based and infrastructure-less networks. To accomplish this goal, current SDN approaches, e.g., OpenFlow, which are inherently centralized, will be augmented so that they can operate in infrastructure-less, decentralized networked environments. The main deliverable of this project is the basic H-SDN prototype. Subsequently, we plan to (1) continue the H-SDN development and (2) develop efficient and flexible content delivery services in hybrid networks using H-SDN.<br\/><br\/>Broader Impact: By developing H-SDN, this research will likely have considerable broader impact as it will enable efficient content delivery in future internets. With content and computation moving to the cloud, efficient content delivery will be critical for content-- and service providers, as well as end users. This project also has a strong education component to this project including an exchange and co-supervision of junior researchers and graduate students between the two partner institutions.","title":"NeTS: EAGER: Software-Defined Networking in Hybrid Networked Environments","awardID":"1150704","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551159"],"PO":["565090"]},"183075":{"abstract":"Proposal #: 11-26357 <br\/>PI(s): Melodia, Tommaso; Atkinson, Joseph F; Batalama, Stella; Pados, Dimitris A; Su, Weifeng<br\/>Institution: SUNY - Buffalo<br\/>Title: MRI\/Dev.: Shared Underwater Acoustic MIMO Networking Testbed<br\/>Project Proposed:<br\/>This project proposes a novel instrument and testbed environment based on a MIMO (Multiple-Input Multiple-Output) networking testbed for underwater deployment. The proposed instrument is based on a commercial system, i.e., Teledyne Bethos Telesonar modem, which would be extended for reconfigurability and rapid deployment, and thus adopted for wider usage. The basic extension of the existing commercial modem is the addition of an external controller hosting an open-source software communication suite. This software suite would provide the functionalities for reconfiguration of various networking functions for underwater deployment. The proposed instrument is expected to enable research in (i) underwater networking, (ii) acoustic signal processing and communications, and (iii) environmental ecosystem monitoring, modeling, and engineering, including:<br\/>- MIMO underwater acoustic transceiver designs via high-end Digital Signal Processor (DSP) and a data recorder (hosted on the modems) for testing MIMO functions. <br\/>- New MAC and routing protocols for underwater MIMO links and their testing under realistic conditions;<br\/>- Collection of useful data that can be used in analysis and validation of theoretical models; <br\/>- Access interface in order to allow other researchers to access the hardware;<br\/>- Applications in a variety of important water and sea floor observation challenges, including earthquake and tsunami prediction, early warning and observation applications, as well as long term observations on water quality, currents, etc. in the Great Lakes.<br\/>Broader Impacts: <br\/>This project, unique in its goals and expected results, will provide the research community with an experimental platform for testing underwater communication ideas. The testbed will benefit research on underwater networking, acoustic underwater communications, and environmental monitoring. The developed testbed will be a research and training facility for undergraduate and graduate students, with unique theoretical and system design skills in underwater signal processing, communications, and networking. The PI and Co-PIs have a strong history and a current demonstration of their ability to attract and train both women and minorities in their areas of research. Students, including minority and women, will be engaged and a new course will be developed.","title":"MRI: Development of a Shared Underwater Acoustic MIMO Networking Testbed","awardID":"1126357","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[490695,"555021",490697,490698,490699],"PO":["557609"]},"186100":{"abstract":"Ontologies are developed to provide semantics for a particular domain and to support information retrieval, reasoning and knowledge discovery. However, as separate groups develop ontologies, there is a need to combine or match ontologies to support connecting information across heterogeneous sources. Ontology matching is a complicated process that stems from the need to involve several types of matching algorithms that take into account syntactic, lexical, structural, instance, and logic features of the ontologies. The current support provided to users to understand and evaluate the results provided by ontology matching systems is very limited; therefore ontology matching is an arduous and time consuming task. This exploratory project focuses on development of a novel approach to ontology matching that employs visual analytics to guide the users in the process. It is expected to result in increased quality of resulting ontologies while also reducing the time and effort of experts involved in ontology matching.<br\/><br\/>Visual analytics is at the confluence of information visualization, data analytics, and data transformation. This project explores the potential of visual analytics to effectively assist real-time decisions by domain experts and ontology researchers alike during the ontology matching process. The project is organized around three key research challenges:<br\/>(1) Visualization: Data and analytically extracted features need to be encoded into rich visualizations that can be effectively manipulated. In particular, visualizations should lend themselves well to complex transformations that facilitate the discernment of trends or patterns.<br\/>(2) Architecture: The interaction between the automatic matching and the visual analytics modules is central to the proposed approach. The envisioned architecture will support a quality-controlled feedback loop in which users will intervene to change the analytic and visual parameters of the system.<br\/>(3) Performance evaluation: Performance measures will be developed to objectively identify the obtained gains in terms of the effort saved by users and of the quality of the matching results as enabled by the proposed visual analytics approach to ontology matching.<br\/><br\/>If successful, this proof-of-concept project is expected to make a significant contribution in effective ontology matching that in turn will enable semantically enriched access to complex, heterogeneous, and distributed data to an increasing number of users in a variety of domains. Research results, including developed software, will be made available via the project web site (http:\/\/agreementmaker.org\/wiki\/index.php\/Visual_Analytics). The project provides research experience to students and results from this research will be included in the computer science curriculum.","title":"EAGER: Visual Analytics for Ontology Matching","awardID":"1143926","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["554456"],"PO":["563751"]},"185253":{"abstract":"This EAGER project will deploy an experimental wireless testbed in the downtown area of Philadelphia. The proposed testbed will be based on WiMAX technologies and will be jointly administered by Temple and Drexel University faculty with a wide range of expertise, including wireless networks, sensor applications and wireless security. The proposed platform is unique and has the following characteristics: (a) Open Access. The testbed will be integrated into GENI, which has a national footprint and is available at many campuses across the country. (b) Urban location. The projected coverage area includes a metropolitan downtown area with many tall buildings and competing wireless services. (c) Potential for expansion. At this initial stage, two base stations are planned, one on each campus. But both Temple and Drexel have other buildings across the city where more base stations can be located in the future. (d) Alignment with Digital Philadelphia. This project is a good match with the current vision for Philadelphia, which seeks to provide gigabit connectivity throughout the City.<br\/>Specifically, the PIs will 1) complete the installation and testing of the testbed and the corresponding hardware (smartphones, laptops, sensors and vehicular devices), 2) integrate the testbed with GENI, and 3) carry out experiments that make extensive use of the testbed. The current portfolio of experiments include air quality sensor networks for urban environmental monitoring, WiMAX-based data network for law enforcement, mobile content delivery networks, sensor-based telemedicine, and location-based services for tourists.<br\/>In terms of broader impacts, the proposed testbed will serve the research community, allowing a realistic platform on which to conduct experiments not possible elsewhere. In addition, the testbed will be integrated into classes at Drexel and Temple, facilitating the education and training of undergraduate and graduate students in next generation wireless networking, large-systems research. The testbed will also be used in outreach to local middle and high school students.","title":"A Meso-Scale GENI WiMAX Project","awardID":"1138949","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[497058,"563559"],"PO":["564993"]},"176200":{"abstract":"Power consumption imposes significant design constraints across the entire spectrum of computing, from the smallest handheld device to the largest data center. New technology nodes provide significant size reduction advantages, but introduce significant challenges in the power and process variability domain. These new technology nodes introduce concerns in the available first-order models commonly used by the research community. Transistor-level and gate-level simulators can offer higher accuracy, but are too slow to model multicore processors running real programs.<br\/><br\/>Fundamentally, validating novel power-centric ideas is limited by our ability to anticipate the future and to model large-scale effects or relatively poorly understood phenomenon. Fabricating prototypes can bridge the gap, but prototype-based architecture research requires a considerable amount of complex infrastructure making it relatively rare for academic researchers. This projects proposes a complete prototyping platform, that will greatly reduce the cost and effort required for prototype-based research into power-centric multicore architectures.","title":"Collaborative Research: II-NEW: Prototyping Platform to Enable Power-Centric Multicore Research","awardID":"1059442","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["556721"],"PO":["563661"]},"185154":{"abstract":"DePaul University and Loyola University of Chicago propose a project to improve and expand computer science (CS) education in Chicago Public Schools (CPS) high schools. The project will create a high-quality CS course that will serve as the introductory course for all tracks of the three-year CPS Career and Technology Education InfoTech (CTE InfoTech) program that is offered at 32 high schools. The course will adapt and extend the successful pilot \"Exploring Computer Science\" (ECS) curriculum originally developed for the Los Angeles Unified School District. With a focus on computational thinking, the ECS curriculum includes units on Human Computer Interaction, Problem Solving, Web Design, Programming, Computing Applications, and Robotics. This project will create new units on Game Programming and Project Management as alternatives to the Robotics unit. These new units won?t require expensive technology, facilitating the adoption of ECS in a wider range of schools; in addition, they will also better serve some of the tracks being introduced in the newly revamped CTE InfoTech curriculum. To increase adoption beyond the CTE program, the new course is likely to be offered also as a Mathematics elective and it will be a great preparatory course for the new AP Computer Science Principles course that is being developed. Finally, the CPS high school population is 51% African American and 37% Hispanic, making Chicago an ideal location to reach students from underrepresented groups, and leveraging the expertise of the PIs, specific efforts will also be made to achieve a more equitable representation of the female half of the population.","title":"Collaborative Research: Type I: A Taste of Computing: Adding a CS Entree to the Education Choices in a Large Urban School District","awardID":"1138417","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[496796],"PO":["561855"]},"186023":{"abstract":"The University of California Berkeley proposes to build on the work of their pilot of the proposed College Board AP CS Principles course, working with and training an initial group of high school teachers during the summer of 2011. The PIs piloted their course -- called the Beauty and Joy of Computing (BJC)-- at the college level in 2010-2011; with this work, they will adapt it for high school students and provide professional development for their teachers. BJC invokes passion, beauty, and awe by engaging students in a rigorous computing curriculum that promotes creativity and collaboration using Snap's visually rich programming environment, while also provoking thought around current events and how computing relates to people's lives. This summer effort will conduct and evaluate team-based professional development for in-service teachers and it will enhance the development of the Snap software (an extension of Scratch formerly known as \"Build your own Blocks (BYOB)\"), which combines technical sophistication with an attractive drag-and-drop interface. Specifically the project will (1) develop a core group of mentor teachers in the Berkeley area who will in later years help to scale the professional development around BJC to new locations, (2) conduct and evaluate intensive summer professional development for teachers, and (3) reimplement the Snap programming language and development environment to improve its speed and to create a version that does not require local software installation. This project is designed to continue the momentum developed around the pilot BJC course and establish a firm base for a larger project that has been separately proposed to NSF.","title":"Advanced Placement Computer Science: Principles - Summer 2011 Professional Development for UC Berkeley Cluster of High School Teachers","awardID":"1143566","effectiveDate":"2011-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[499211,"533235"],"PO":["561855"]},"186045":{"abstract":"This award provides funding for a collaborative project between University of Massachussetes, Amherst and Indian Institute of Technology, Bombay, India. There has recently been an increasing focus on developing new technologies for a more sustainable future for our society. In this context, the design of new Information and Communication technologies hold particular promise for designing the sustainable systems of tomorrow. This project will address key research challenges in the design of a smarter and greener electric grid, specifically focusing on pervasive computing and communication issues that arise both in the ?core? and on the \"edge\" of the smart grid. The intellectual merit of the effort is to bring a multi-disciplinary approach to addressing problems in data collection, dissemination, monitoring, and demand-response for the grid, with a common theme being a data-driven methodology using data obtained from measurements to drive actuation\/control, optimization or resource management to address problems for the smart grid and smart homes that interface with the grid. The project's activities span three inter-related topics: (i) measurement and monitoring for the smart-grid, (ii) data dissemination architectures for the smart grid and (iii) demand-response for smart residential and office buildings. <br\/><br\/>The broader impacts of this project include (i) industrial internship opportunities with industrial collaborators for student researchers, enabling them to work on practical problems in this area, (ii) developing a three-credit course on computing and networking technologies for the smart grid, offered jointly between UMass and IIT Bombay and building on the smart-grid reading group that has been jointly conducted for the past year, and (iii) organizing a smart grid workshop in Holyoke MA, an economically disadvantaged gateway city with a large minority population, and a municipally-owned hydroelectric utility. <br\/><br\/>The project is structured as, and will result in, an international collaboration between India and the US. Smart grid, smart homes and sustainability are important areas of research in both India and the USA; however there are numerous context-specific geographical issues that must be addressed in each country. Through collaboration and by leveraging each other?s insights, project participants will be able to develop research methods that are broadly applicable in international settings. US and Indian industry partners, which include utilities, research labs and power generation companies, will bring a real-world perspective to this project. This project is a part of pervasive communications and computing collaboration (PC3) initiative.","title":"PC3: Designing a Smarter and Greener Electric Grid: A Sensor-data Driven Approach","awardID":"1143655","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[499259,"558563"],"PO":["563661"]},"186177":{"abstract":"Remarkable progress in the understanding of the brain in recent years is due in part to the increasing role that theory and computational methods are playing in the design of experiments and interpretation of data. The annual Computational and Systems Neuroscience (Cosyne) conference promotes this process by providing an inclusive forum for the exchange of experimental and theoretical\/computational approaches to problems in systems neuroscience. This purpose of this project is to broaden participation of women and other under-represented groups at the Cosyne meeting. Travel awards and a variety of outreach activities are planned for the 2012, 2013, and 2014 meetings.","title":"Broadening Participation at the Computational and Systems Neuroscience Conference (Cosyne)","awardID":"1144185","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":[499592],"PO":["564318"]},"186298":{"abstract":"As many children are connected to their peers and spend a significant amount of time on social web sites (Facebook, Twitter, etc.), cyber bullying in social media is becoming a severe problem that can lead to serious social, psychological, and health effects. To alleviate the problem, intervention from adults (teachers, parents, law enforcement, social web site moderators, etc.) is the key. However, many victims do not report bullying to adults, and bullies can use aliases and act anonymously, and thus they are difficult to identify. The goal of this exploratory project is to eliminate or at least reduce these problems by developing an intelligent system to automatically detect and track cyber bullies on the social web.<br\/><br\/>This project explores a solution to cyber bullying based on a combination of machine learning, natural language processing, information filtering, and recommendation and social network modeling techniques. The expected results of the project include: (1) algorithm(s) that can detect cyber bullies and bullying messages automatically; (2) piloting results that suggest what prediction accuracy to expect; (3) a preliminary social web bullying detection prototype system and (4) the first labeled social cyber-bullying data set for testing of the prototype and future research in this direction. The project has high risk, as whether such a system can be developed is an untested idea and the task is challenging, largely due to the diversity of bully behaviors, ambiguity, and the special language used by bullies in social media. <br\/><br\/>Results from this research project are expected to create a foundation for future larger-scale projects investigating the cyber-bullying problem in social media, which will eventually make the social interaction much safer for hundreds of millions of children and beyond. Teaching, training and learning will be promoted directly for the graduate students who serve as research assistants and programmers, and several undergraduates will contribute to the programming. The impact will be strengthened by UCSC's ethnic and cultural diversity, its proximity to Silicon Valley, and the PI's industry collaborations. Results of this research, including data generated, publications, and demo software will be available via the project web site (http:\/\/users.soe.ucsc.edu\/~yiz\/bullying\/).","title":"EAGER: Detecting and Tracking Cyber Bullying on the Social Web","awardID":"1144564","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["547825"],"PO":["563751"]},"177245":{"abstract":"The project assesses patient cardiovascular risk and matches patients to the treatments most likely to be effective. The project addresses this problem through sophisticated computational methods that identify new markers of disease, improve the ability to measure both new and existing markers, and construct personalized models that can provide highly accurate assessments of individual risk. The core focus of the research addresses the poor performance of existing tools for cardiovascular decision support through advanced methods at the intersection of machine learning, data mining, signal processing, and applied algorithms; with the research guided by knowledge of cardiac pathophysiology.<br\/><br\/>This project impacts patient care for a disease that causes roughly one death every 38 seconds in the United States and imposes a burden of over half a trillion dollars in the U. S. each year. More generally, many of the ideas explored here (e.g., personalization of risk models) extends to a wide variety of other disorders in a straightforward manner and leads to wide improvements in outcomes while controlling costs. The research also strengthens interdisciplinary research in EECs and medicine throughout the computer science research community.","title":"SHB: Medium: Collaborative Research: Novel Computational Techniques for Cardiovascular Risk Stratification","awardID":"1064948","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550371","496138"],"PO":["564768"]},"176156":{"abstract":"Power consumption imposes significant design constraints across the entire spectrum of computing, from the smallest handheld device to the largest data center. New technology nodes provide significant size reduction advantages, but introduce significant challenges in the power and process variability domain. These new technology nodes introduce concerns in the available first-order models commonly used by the research community. Transistor-level and gate-level simulators can offer higher accuracy, but are too slow to model multicore processors running real programs.<br\/><br\/>Fundamentally, validating novel power-centric ideas is limited by our ability to anticipate the future and to model large-scale effects or relatively poorly understood phenomenon. Fabricating prototypes can bridge the gap, but prototype-based architecture research requires a considerable amount of complex infrastructure making it relatively rare for academic researchers. This projects proposes a complete prototyping platform, that will greatly reduce the cost and effort required for prototype-based research into power-centric multicore architectures.","title":"Collaborative Research: II-NEW: Prototyping Platform to Enable Power-Centric Multicore Research","awardID":"1059233","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["556706"],"PO":["563661"]},"177278":{"abstract":"This project addresses parallelism in applications with the goal of improving the efficiency of those applications.<br\/><br\/>Today's multicore and manycore computers provide increasing amounts of computational power in the form of parallel processing. But, before a software application can take advantage of such parallel hardware and exhibit speedups in execution, a software developer must (re)write the program to indicate which portions may be executed in parallel and which portions must be executed sequentially. The Manticore research project designed and implemented the Parallel ML programming language, a functional programming language with a rich collection of explicitly- and implicitly-parallel programming features. To date, this team built an implementation of PML that is efficient and scalable. However, PML lacks some features present in other languages, such as shared state, which grants the ability to freely modify data shared between parallel threads, and nondeterminism, which grants the ability to return results that may depend upon the order of parallel execution. These features are generally considered difficult to use correctly and difficult to implement efficiently in a parallel setting; yet, they have the potential to make greater portions of an application amenable to parallel execution.<br\/><br\/>Therefore, this project focuses on the significant problem of increasing the amount of parallelism exposed by applications by extending Parallel ML with mechanisms like shared state and nondeterminism in a safe and efficient manner. A key feature of the design is that it provides ways to isolate the stateful and nondeterministic components of a program; this isolation makes these mechanisms easier and safer to use by software developers. Another key feature of the design is that it captures common programming idioms, such as caching to avoid redundant computations and make independent writes to a shared sparse data structure in a manner that ensures safe and efficient program execution. Thus, this proejct frees the software developer from the difficult and error-prone task of explicitly programming the low-level details that manage the parallel execution of an application; instead, the software developer focuses on the high-level application logic, while the compiler and runtime system allocates the parallel execution over the available computational resources. This research is helping guide future language design efforts and transforming programming practice toward higher-level and more declarative models, yielding improved productivity, correctness, performance, and scalability.","title":"SHF: Medium: Collaborative Research: Extending Declarative Parallel Programming with State and Nondeterminism","awardID":"1065099","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[475259],"PO":["551712"]},"180380":{"abstract":"CIF: Large: Collaborative Research: Controlled Sensing, and Distributed Signal Processing and Decision Making in Networked Systems<br\/><br\/>PIs: Demosthenis Teneketzis (Michigan) and Venugopal Veeravalli (Illinois) <br\/><br\/>Abstract:<br\/><br\/>Many modern technological systems are networked systems. Networked systems are informationally decentralized, comprise many nodes carrying disparate information, and are subject to constraints on energy, data storage and computational capabilities. This research project entails a comprehensive study of fundamental issues that arise in networked systems, pertaining to controlled sensing, distributed signal processing, and distributed decision making, whose resolution will lead to substantial improvements in network performance. The project aims at (i) improving our understanding of the role of information in sensing, signal processing and decision making for networked systems under various architectures, in controlled and distributed settings; (ii) improving our understanding of coordination of networked systems, by evaluating the performance of the different architectures; and (iii) generating novel algorithms that will lead to networked systems that exhibit superior performance over current ones. The problems underlying these objectives cannot be adequately tackled using standard approaches in signal processing or stochastic and deterministic control theory. The investigators use key tools from stochastic optimization, distributed computation, and probability theory to develop novel methodologies that address the underlying challenges. <br\/><br\/>This project has broader impact on several fronts. It provides systematic design methodologies that are essential in many modern networked systems, and in particular, in systems for environmental (e.g., soil moisture) monitoring with distributed sensors. In addition, the research output of this project is expected to be useful to NSF's NEON program, to NASA's earth science program, and to NOAA's monitoring program. The research activities are expected to have an impact on technology transfer and graduate education through course development and training of students, with a special emphasis on including women and under-represented minority students through a strong mentorship program.","title":"CIF: Large: Collaborative Research: Controlled Sensing, and Distributed Signal Processing and Decision Making in Networked Systems","awardID":"1111061","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["526786",483401,483402,"485560"],"PO":["564898"]},"181491":{"abstract":"Modern organizations such as social networking service providers, life-science research centers, or security agencies own an unprecedented amount of data. Such organizations want to analyze their data via software applications that are written against that data. Writing, testing, and debugging such data-intensive software applications is notoriously complex. This research develops novel techniques for dealing with this complexity. <br\/><br\/>The first objective of this research is to develop techniques that can automatically find a representative subset of an existing large-scale data set that allows the programmer to predict how the program will behave on the full data set. The intuition is that the resources needed for finding a representative data subset plus executing the program on that subset can be orders of magnitude lower than running the application on the full data set. The second research objective is to develop techniques that automatically check if a user program violates the correctness conditions imposed by data processing systems that offer a MapReduce-style programming interface.","title":"SHF: Small: Testing Large-Scale Database-Centric Applications","awardID":"1117369","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[486261,"558117","553595"],"PO":["564388"]},"182470":{"abstract":"This project is leveraging emerging technologies in social robotics with recent findings from social, developmental, and cognitive psychology to design, implement, and evaluate a new generation of robots that is capable of interacting with and instructing young learners (ages 3 through 6) in a truly social way. The robot incorporates signals that the mind implicitly uses to ascertain another's intentions, motivations, and affiliations (e.g., motor mimicry and synchrony, affective cues, gaze direction), making it capable of serving as a true embodiment of a human instructor. The robotic platform can be controlled remotely, through a direct and proximate connection or a remote, Internet-based operator interface. As such, the system can be placed in several different environments, ranging from a child's home to medical areas where issues of mobility or immunosuppression make it difficult for direct interaction with instructors. Research is aimed at better understanding children's concepts of robot mind and of robots as agents, uncovering mental operations behind learning new words, and adding to what is known about the added value (if any) of non-verbal utterances to understanding, communication, and collaboration.<br\/><br\/>Emerging research has identified the acquisition of early language and vocabulary skills primary predictors of later academic success. Impoverished vocabulary upon entering kindergarten strongly predicts poor subsequent academic performance. Accordingly, the use of technologies designed to build vocabulary during the preschool years is key to facilitating many types of learning. Interactions with a robotic language partner are expected to have particularly important ramifications for children with compromised opportunities to interact regularly with attentive, nurturing caregivers willing and able to foster their vital socio-intellectual developmental needs. In addition, the rationales, artifacts, and cyber platforms and infrastructure created for this project could lend themselves to a broad range of design extensions, such as providing opportunities for children who are learning English as a second language to participate in English-language-based social activities, outreach to rural areas where children have infrequent access to social activities, supporting children of deaf parents, and assessing\/assisting children with pragmatic language impairments.","title":"DIP: Collaborative Research: Social Robots as Mechanisms for Language Instruction, Interaction, and Evaluation in Pre-School Children","awardID":"1122845","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":[488847],"PO":["562669"]},"181381":{"abstract":"This project is aimed at developing effective decision-theoretic planning algorithms for multi-agent systems that involve dozens or hundreds of agents. Current approaches to agent coordination that provide rigorous performance guarantees can only handle a few agents. The project addresses this barrier with the following objectives: (1) develop new problem representations that allow planning algorithms to leverage the interaction structure and independence relationships within a domain; (2) develop approximation methods that operate with limited memory and time, and exhibit anytime characteristics; (3) perform rigorous convergence analysis and establish tight error bounds on solution quality; (4) develop techniques that make it easy to exploit parallelization offered by multi-core processors; and (5) create a new set of challenging test problems and perform a rigorous evaluation. The project produces two fundamentally new approaches to planning in multi-agent settings. The first approach offers efficient message-passing planning algorithms based on computational paradigms such as expectation-maximization (EM) and the concave-convex procedure (CCCP). The second approach offers rollout sampling methods for domains that are too large to be explicitly represented. These new methods improve the scalability of existing techniques by several orders of magnitude. The results transform the ability of researchers and practitioners to apply rigorous decision-theoretic planning to multi-agent domains such as sensor networks and mobile robot coordination. The broader impact stems from the wide applicability of the resulting technology, undergraduate and graduate educational activities at UMass, dissemination efforts that make the experimental domain and algorithms publically available, and the development of international collaborations.","title":"RI: Small: Planning Algorithms for Large Decentralized Multiagent Settings","awardID":"1116917","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[485994],"PO":["564316"]},"181392":{"abstract":"The research component of this proposal is about ranking and clustering. A given collection of items is to be ordered according to some criterion (e.g., from most to least important). In clustering, the goal is to group items so that similar items appear together. Though well-studied, ranking and clustering research has been dominated by heuristic methods that produce approximate results quickly. Optimization methods that produce exact optimal results have been far less studied, possibly because these methods require longer computational times, and the gains in accuracy do not outweigh the computational costs in many applications. This is unfortunate since optimization methods are based on a beautiful theoretical framework and can lead to novel and interesting results. For example, preliminary work by the PI on a ranking optimization method, indicates that multiple optimal solutions can be linked to ties in the ranked list. On the other hand, heuristic methods are not designed to handle ties in the output ranking. Two main goals of the proposed research are: (1) to reveal interesting theoretical connections, and (2) to increase the size limits of optimally solvable problems using both classical and clever new relaxation techniques.<br\/><br\/>Ranking, also known as linear ordering (LOR), is close in spirit to the Traveling Salesman Problem (TSP): both are simple to state, yet hard to solve optimally. Over several decades, huge gains have been made on the size of solvable TSPs, that have resulted in new and unforeseen uses. Notable examples occur in the transportation industry (involving thousand-city TSPs) and in the microprocessor industry (with even larger TSPs routing copper wiring on circuit-boards). Similar progress is expected for the LOR, whose current limit is a few hundred to a few thousand items in some cases. Yet applications for much larger LORs abound, e.g. rankings of genes, products, and webpages. Furthermore, breakthroughs for the TSP (and likewise the proposed LOR work) have not solely been related to scale, but theoretical advances and progress in understanding connections to other problems and fields have been equally crucial in the development of general purpose methods for integer programming, such as cutting plane and branch and cut techniques. <br\/><br\/>The proposed research has great impact. Ranking and clustering have become standard data analysis tools with many uses. For example, Google uses ranking to order webpages resulting from user queries, and also uses clustering for its \"Find Similar Pages\" function. Amazon uses clustering in its \"Customers Who Bought X Also Bought Y\" feature. Facebook and Twitter can generate ads and friend recommendations based on ranking and clustering algorithms. To ensure the results of the proposed research reach these consumers, the work will be widely disseminated through journal publications and two books. The project's novel student training plan, which includes peer mentoring and an international exchange program, will broaden participation of underrepresented groups. The educational component and its Calculus Activity Book, being aimed at changing students attitudes towards the sciences and at instilling confidence in scientific ability, will have the stronger impact on those students who more commonly fail to be retained (likely a relatively large number coming from underrepresented groups), and thus will help further diversify and broaden participation in STEM disciplines.","title":"AF: Small: RUI: Ranking and Clustering by Integer and Linear Optimization","awardID":"1116963","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[486025],"PO":["565251"]},"184681":{"abstract":"The national transmission networks that deliver high voltage electric power underpin our society and are central to the ongoing transformation of the American energy infrastructure. Transmission networks are very large and complicated engineering systems, and \"keeping the lights on\" as the transformation of the American energy infrastructure proceeds is a fundamental engineering challenge involving both the physical aspects of the equipment and the cyber aspects of the controls, communications, and computers that run the system. The project develops new principles of cyber-physical engineering by focusing on instabilities of electric power networks that can cause blackouts. It proposes novel approaches to analyze these instabilities and to design cyber-physical control methods to monitor, detect, and mitigate them. The controls must perform robustly in the presence of variability and uncertainty in electric generation, loads, communications, and equipment status, and during abnormal states caused by natural faults or malicious attacks.<br\/><br\/>The research produces cyber-physical engineering methodologies that specifically help to mitigate power system blackouts and more generally show the way forward in designing robust cyber-physical systems in environments characterized by rich dynamics and uncertainty. Education and outreach efforts involve students at high school, undergraduate, and graduate levels, as well as dissemination of results to the public and the engineering and applied science communities in industry, government and universities.","title":"CPS: Medium: Collaborative Research: The CyberPhyscial Challenges of Transient Stability and Security in Power Grids","awardID":"1135895","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553646"],"PO":["565239"]},"181172":{"abstract":"This research will advance the state of the art in conversational character systems (Intelligent Virtual Agents) in two ways. First, it seeks to better understand the interplay of gesture and language in both generating the perception of personality and allowing participants to adapt to the ongoing conversational context. Second, it will use this understanding to build novel computational models for gesture and language generation that provide fine grained control over the perception of personality and support agent adaptation in response to the conversational context. The theoretical basis for the personality-based modeling in this project is the well-established \"Big Five\" model of personality, which consists of five orthogonal dimensions of individual variation.<br\/><br\/>The work on adaptation will be couched in the collaborative theory of language use and communication accommodation theory, which predict that communicative behavior varies based on partner specificity. Initial work will form a motion capture, video and audio corpus of three kinds of exchanges. This will be used to both study gestural entrainment during human interactions, determining if audio-based findings extend to the gestural domain, and to enhance scientific understanding of the relationship between gesture and personality. This will inform the modeling work which will build a joint model for personality-based language and gesture production. The model will extend a pilot study on gesture generation for extraversion to three Big Five traits and integrate it with personality-based language generation. An experimental stage will validate these models and study the interactions of movement and language. The research will also study the role of adaptation. Questions to be answered include: (1) whether people gesturally entrain with computers, or indeed produce any gestures while communicating with a computer, (2) whether computers? gestural entrainment promotes similar levels of affiliation as observed with vocal entrainment, and (3) whether changing gestural entrainment over the course of an interaction is more powerful than aligning gestures from the outset of an interaction. <br\/><br\/>Character systems are becoming increasingly important for a range of applications, from virtual worlds to tutoring systems. There is growing evidence that the way personality is presented through these characters, and how well they mimic expected human behavior like entrainment, has a direct impact on the effectiveness of the applications in which they are used. For example, it will have a direct impact on student learning. As these applications become more ubiquitous in society, particularly among children, it is important to be able to harness their full benefit, and indeed, avoid unintended negative consequences. This involves both advances in computational models that allow an agent to reflect a given personality and adapt to a human user, and also a deeper understanding of the role of personality and adaptation in effective human-agent interactions.","title":"HCC: Small: Collaborative Research: Gestural and Linguistic Expressivity and Entrainment in Dialogue","awardID":"1115872","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["550684"],"PO":["564456"]},"184692":{"abstract":"CPS: Medium: Collaborative Research: CyberMech, a novel run-time substrate for cyber-mechanical systems<br\/><br\/>Growing demands on our civil infrastructure have heightened the need for smart structural components and systems whose behavior and performance can be controlled under a variety of loading scenarios such as high winds and earthquakes. However, due to the sheer size, scale and cost of most civil engineering structures, design and testing of such smart structures needs to be conducted using a hybrid cyber-physical approach where the infrastructure system in question, for example a bridge, is studied by coupling a small number of physical components with a numerical model of the rest of the structure. Undoubtedly, the success of such a hybrid approach, especially for dynamic real-time applications, hinges on effective integration of the cyber and physical components of the system. This project provides the essential building blocks and a computational integration platform to enable real-time hybrid testing of civil engineering structures.<br\/><br\/>Design and development of physical components, multi-level numerical models, and real-time control algorithms will be conducted at Purdue University. Washington University will provide an adaptive, configurable concurrency platform and communication mechanisms that meet the strict scheduling constraints of real-time cyber-physical systems. The two institutions will collaboratively design a prototype system and conduct extensive testing to validate the integration of the various components and evaluate system performance. Specifications, software, benchmarks, and data developed during the course of this project will be made freely available to the cyber-physical research community. In addition to directly advancing the state-of-the-art in real-time hybrid testing, this research will also impact the areas of avionics, automotive design, smart grids for distributed power transmission and similar applications in other domains.","title":"CPS: Medium: Collaborative Research: CyberMech, a Novel Run-Time Substrate for Cyber-Mechanical Systems","awardID":"1136073","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["556687","560533","556689"],"PO":["565264"]},"181194":{"abstract":"The Internet represents essential communication infrastructure that needs to be protected from malicious attacks. Many existing attacks and corresponding defense mechanisms have focused on the computers connected to the Internet rather than the network infrastructure itself. However, the network can also be attacked since modern network components use software and hardware components that can exhibit vulnerabilities that have not been previously studied. This project explores this new type of in-network attacks and develops a novel approach to providing fundamental security capabilities in networking hardware based on hardware monitoring techniques.<br\/><br\/>The goals of this research are to significantly improve the understanding of emerging vulnerabilities in the Internet infrastructure and to develop a hardware monitoring system that can detect and stop an entire class of new attacks in order to maintain an operational Internet. This research on the design, implementation, and operation of protected router platforms is essential for the continued success of the Internet. In addition, this project integrates underrepresented minority and undergraduate students into research, develops instructional components, and contributes to workforce development through graduate student training.","title":"TC: Small: Securing the Router Infrastructure of the Internet","awardID":"1115999","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["549952",485542],"PO":["564223"]},"186893":{"abstract":"Synthetic Biology is a nascent field with applications that range from bio-fabrication to alternative energy. Despite its significance, engineering of biological circuits still relies on trial-and-error tinkering techniques, with limited computational support. If Synthetic Biology is to advance to more complex synthetic systems that go beyond a handful of interacting parts, a scalable, integrative, methodological approach is necessary. In an analogy to integrated circuits, when it comes to circuit engineering, the role of detailed computer models, optimization methods, simulators and design tools is paramount.<br\/><br\/>Intellectual Merit: This project aims to pave the way towards an optimization-based, automated design framework for synthetic gene circuits that adhere to user-defined constraints. A synthetic gene circuit is a collection of one or more genes, together with elements (promoters, ribosome binding sites, etc.) that influence gene expression. The wiring, i.e. the order and position of every element, within a synthetic gene circuit determines the gene expression pattern, and overall behavior of the circuit. These circuits are introduced, usually as part of a plasmid(s), in a host organism that can be readily manipulated in order to achieve a desired outcome (e.g. specific temporal behavior, or production of an enzyme). <br\/>To facilitate faster time-to-market solutions and more robust, predictable designs, PIs will develop a design and optimization tool prototype. To that end, PIs propose a new optimization formulation that encompasses multiple biological models relevant to synthetic genetic circuit design. In addition, they propose a hybrid optimization-simulation technique to capture additional effects related to cell division, noise, and evolutionary processes. The investigation will focus on how state-of-the-art techniques from combinatorial optimization can be applied to find the optimal circuit for a specific task. Since the tool will need a library of well-characterized components to operate, PIs will create a mutant library of three widely-used regulators, then quantitatively characterize them, and store this information in a publicly available database. As a proof-of-concept experiment, they will assess their integrative approach by constructing an automatically-designed synthetic circuit, measuring its output and deviation from the desired goal, and then comparing it to other similar designs that have been already available in literature. <br\/><br\/>Broader Impact: An optimization-based, design tool for synthetic biology has the potential to provide a service to the academic community by reducing drastically the time-to-market aspect of synthetic designs, and providing insight on biological function, thus accelerating research in an exponentially growing field. All components and characterized libraries that will be developed as part of this award will be publicly available, deposited in the synthetic biology community?s standard Parts Registry. Furthermore, this award will partially support the work and training of the UC Davis IGEM team, a synthetic biology undergraduate team who competes in the annual IGEM competition. Knowledge from this project will be directly transferred into classrooms through the course ECS 289K \"Computational Challenges in Systems and Synthetic Biology\" (UC Davis), and the course CSC 450\/550 \"Algorithms for Bioinformatics\" (U. Arizona).","title":"Collaborative: EAGER: A Model Based System for the Automated Design of Synthetic Genetic Circuits by Mathematical Optimization","awardID":"1147844","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560602"],"PO":["565223"]},"184484":{"abstract":"IIP 1134684 <br\/>University of Cincinnati; Lee <br\/><br\/>IIP 1134676 <br\/>University of Michigan; Ni <br\/><br\/>IIP 1134721 <br\/>Missouri University of Science and Technology; Sarangapani <br\/><br\/>The NSF Industry\/University Cooperative Research Center (I\/UCRC) on Intelligent <br\/>Maintenance Systems (IMS) was established in 2001. This proposal builds upon the accomplishments of the previous ten years and seeks funding to continue supporting a three campus operation among the University of Cincinnati (leading institution), the University of Michigan, and Missouri Univ. of S&T. <br\/><br\/>The Center addresses the underlying issues in machine degradation modeling and prediction as well as develops the transformational technology in advanced prognostics. Over the past 10 years, the Center has developed systematic methodology and tools that made evident impacts to a number of member companies including Toyota, G.M., Boeing, P&G, and National Instruments, amongst others. Over the next five years, the Center intends to advance the scientific base as well as to validate the developed tools to further accelerate the deployment and commercialization of the developed technologies. The center also plans to have international sites in Singapore, Brazil and Spain. In addition, the Center plans to develop spin-off companies with a compelling Marketing Plan in order to commercialize its tools through its member company, National Instruments, in 2011. <br\/><br\/>The IMS IUCRC fills an important niche to maintain industry global competiveness by continuous improvement of manufacturing effectiveness and efficiency. The center educates students and its membership through an extensive system of internship and scholar exchanges as well as international workshops and courses. IMS has developed and continues to execute an effective system for innovation and IP generation. The Center plans to develop spin-off companies with a compelling Marketing Plan in order to commercialize its tools through its member company, National Instruments, in 2011.","title":"NSF I\/UCRC 5-Year Renewal, Phase III","awardID":"1134684","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":["477110","554411","554413"],"PO":["564474"]},"186794":{"abstract":"Heterogeneous multicores\/Chip Multiprocessors (CMPs) are envisioned to be a key design paradigm to combat the challenges of power, memory, and reliability walls that are impeding chip design using deep sub-micron technology. There are so many dimensions to creating heterogeneous architectures, with the issues spanning multiple devices, technology platforms and software stacks. Further, despite the promise that heterogeneity offers, it is not clear (I) what are the most salient forms of heterogeneity that will be really needed, and (ii) how do all these forms interacting in non-intuitive ways at the entire system level. These issues make this topic a high-risk high-reward proposition. <br\/>This project will provide preliminary results to gauge the potential and feasibility of heterogeneous architectures, and develop strategies for systematically evaluating them.<br\/><br\/>The semiconductor industry is vital to the national security and economy of the United States. With all major chip vendors projecting increased number of cores as the key to their future road maps, innovations in chip multiprocessors is critical. Enabling heterogeneous computing can largely reduce energy costs of computing, while making it more powerful and dependable. Collaboration with industry partners would facilitate <br\/>direct transfer of many ideas to industry. The tools and techniques <br\/>developed in this research will be made publicly available.","title":"EAGER: SHF: Harnessing Cross-Layer Heterogeneity for Future CMPs","awardID":"1147388","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550859","542015","549542","542016","518504"],"PO":["366560"]},"186321":{"abstract":"The next generation of wireless sensor networks will monitor critical infrastructure, collect vital signs from patients, and disseminate medical and planning information during emergency responses. In contrast to earlier wireless sensor networks for which best-effort services were sufficient, such systems require predictable performance and high reliability. Failure to meet these requirements may have significant adverse effects. This project aims at the development of an engineering methodology for predictable wireless sensor networks. A predictable wireless sensor network is a system for which it is possible to check that its requirements are met under reasonable assumptions regarding its workload and network properties. This project enables the development of predictable wireless sensor networks by providing developers with analytical tools to characterize and optimize the performance of sensor network systems. The intllectual merit of the project includes: (i) Statistical methods for assessing the properties of wireless sensor networks and for provisioning resources to achieve robustness in spite of node failures or temporal variations; (ii) Novel transmission scheduling techniques that ensure a system meets its reliability and real-time requirements; (iii) A new schedulability analysis that bounds network capacity and message latencies under realistic interference models; and (iv) A wireless architecture that instantiates proposed transmission scheduling techniques and the schedulability analysis. In terms of broader impacts, this project will help advance our national capability to develop performance-critical wireless systems. The PIs will teach the developed design and analytical techniques as part of wireless sensor network curriculum and share them with the research community through tutorials.","title":"NeTS: Small: Collaborative Research: Protocols and Analysis for Predictable Wireless Sensor Networks","awardID":"1144664","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[499973],"PO":["565303"]},"186222":{"abstract":"The proposed research will advance scientific knowledge about health information dissemination and the design of appropriate social media tools for the African American female college student community. The goal of this project is to broaden access to and utilization of HIV prevention information, thereby strengthening African American organization and individual capacity to address the HIV\/AIDS epidemic in these communities. The project will achieve this goal the following aims: 1) Describe the ways in which African American female college students construct their cultural\/racial identities; 2) Identify the relationship between these identities and the use of smart health information technology and social networking systems by the target user group. <br\/><br\/>The research project will provide empirical evidence on the design and implementation of HIV\/AIDS preventive education, as well as the culturally-specific challenges related to the use of Information Computer Technology (ICT) for HIV\/AIDS preventive education. It will contribute to understanding how social networks targeting African American female college students for HIV\/AIDS prevention are received by the target community and how to improve the design of such tools for optimal effectiveness. This research will have very far-reaching implications for science and health education within and beyond the target research study community. These intellectual contributions will be of interest to scholars in communication and information studies, software engineering, pervasive mobile devices, and smart health information systems and trustworthy computing. <br\/><br\/>The project will engage college students in the Delta Sigma Theta Sorority as both users and participatory designers of social media tools intended to disseminate HIV information. The National Delta Sigma Theta Sorority, an organization with national and international programs for outreach and networking African American women in institutes of higher education, will offer a mechanism to reach additional college students beyond the physical locale of North Carolina State University - thereby providing a network penetration to other North Carolina chapters and beyond for future direction and interdisciplinary, inter-institutional collaborations. More specifically, this research is to broaden access to and utilization of HIV prevention information, thereby strengthening African American organization and individual capacity to address the epidemic in these communities using innovative smart health information technologies.","title":"EAGER: Collaborative Research: Developing a Culturally Compelling Social Network Approach to HIV\/AIDS Prevention for African American College Students","awardID":"1144327","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[499700,499701,499702],"PO":["564456"]},"185254":{"abstract":"This EAGER project will deploy an experimental wireless testbed in the downtown area of Philadelphia. The proposed testbed will be based on WiMAX technologies and will be jointly administered by Temple and Drexel University faculty with a wide range of expertise, including wireless networks, sensor applications and wireless security. The proposed platform is unique and has the following characteristics: (a) Open Access. The testbed will be integrated into GENI, which has a national footprint and is available at many campuses across the country. (b) Urban location. The projected coverage area includes a metropolitan downtown area with many tall buildings and competing wireless services. (c) Potential for expansion. At this initial stage, two base stations are planned, one on each campus. But both Temple and Drexel have other buildings across the city where more base stations can be located in the future. (d) Alignment with Digital Philadelphia. This project is a good match with the current vision for Philadelphia, which seeks to provide gigabit connectivity throughout the City.<br\/><br\/>Specifically, the PIs will 1) complete the installation and testing of the testbed and the corresponding hardware (smartphones, laptops, sensors and vehicular devices), 2) integrate the testbed with GENI, and 3) carry out experiments that make extensive use of the testbed. The current portfolio of experiments include air quality sensor networks for urban environmental monitoring, WiMAX-based data network for law enforcement, mobile content delivery networks, sensor-based telemedicine, and location-based services for tourists.<br\/>In terms of broader impacts, the proposed testbed will serve the research community, allowing a realistic platform on which to conduct experiments not possible elsewhere. In addition, the testbed will be integrated into classes at Drexel and Temple, facilitating the education and training of undergraduate and graduate students in next generation wireless networking, large-systems research. The testbed will also be used in outreach to local middle and high school students.","title":"EAGER:A Meso-Scale GENI WiMAX Project","awardID":"1138963","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["7594","541634","541635",497064],"PO":["564993"]},"177301":{"abstract":"The goal of this research is to develop techniques that will permit a computer or robot to learn from examples to carry out multipart tasks specified in natural language on behalf of a user. It will study each of these components in isolation, but a significant focus will be on integrating them into a coherent system. The project will also leverage this technology to provide an entry point to educate non- or pre-computer science students about the capabilities and utility of computers as tools.<br\/><br\/>Our approach uses three main subcomponents, each of which requires innovative research to solve its portion of the overall problem. In addition, the integrated architecture is a novel contribution of this work. The three components are (1) recognizing intention from observed behavior using extensions of inverse reinforcement learning, (2) translating instructions to task specifications using novel techniques in the area of natural language processing, and (3) creating generalized task specifications to match user intentions using probabilistic methods for creating and managing abstractions.<br\/><br\/>The goal of the work is develop technology for an improved ability for human users to interact with intelligent agents, the incorporation of novel AI research insights and activities into education and outreach activities, and the development of resources for the AI educator community. In addition to permitting intelligent agents to be developed and trained in the future for a broad range of complex application domains, the interactive agents that we will develop will be used for outreach and student learning.","title":"RI: Medium: Collaborative Research: Teaching Computers to Follow Verbal Instructions","awardID":"1065228","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["558297"],"PO":["562760"]},"186035":{"abstract":"As the use of mobile, wireless computing devices continues to grow, so does concern with assuring that communications within these wireless networks is not vulnerable to various kinds of attacks. Physical-layer Network Coding (PNC) was developed as a means for improving communication in wireless networks. This project will conduct exploratory research to determine whether and how the use of PNC can be exploited to detect attacks. The work is organized into three tasks. The first task will identify capabilities to detect attacks and design corresponding mechanisms for differing network infrastructures and attacker models. Signal strength attacks, Sybil attacks, and wormhole attacks will be the initial targets of study. The second task will study the detection accuracy of the proposed mechanisms and explore more complex network scenarios. The third task will develop simulations to model the attack detection mechanisms.","title":"EAGER: Exploring the Security Capabilities of Physical Layer Network Coding","awardID":"1143602","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["542414"],"PO":["565327"]},"185188":{"abstract":"Following an earthquake, or similar natural disaster, a key problem is rapid and accurate on-site damage assessment to support local first responders; however, trained experts are typically remote from the disaster and it can be time consuming and expensive to bring them onsite. Accessing remote experts to improve the accuracy of rapid assessments is a promising method to streamline provisioning of emergency shelters and other resources. This project focuses on new methods for improved rapid assessment of earthquake damaged building structures in Christchurch, New Zealand. The methods are based on collaboration using augmented-reality (AR) imagery, mobile phone based sensor technologies and crowdsourcing techniques for guided remote data collection. A key element of the system is intuitive remote collaboration. Our mobile AR system can be used to connect a user in the disaster zone to a remote expert via audio and shared still images and\/or video, helping them to rapidly collect data on building structural integrity. A user evaluation will be performed to compare the performance between the prototype and more traditional approaches (e.g., waiting for an expert to arrive on the ground), and assessment based on imagery recorded from an untrained and unguided user. Two hypotheses will be tested: 1) a collaborative mobile AR system can improve the quality and type of data collected for structural assessment 2) the time to provide data from non-experts assisted by experts to decision makers in a digestible format is dramatically reduced as compared to traditional methods.<br\/><br\/>The approach will enable rapid post-event damage assessment, streamline emergency provisioning of shelters by allowing people to stay in safe dwellings, and speed up emergency response and reconstruction. The resulting valuable dataset will assist development of rapid assessment forms, contribute to earthquake structural damage case studies, provide key baseline to test several computer science research projects on improved disaster response, and provide key data for development of life-saving tools. The international collaboration also provides engagement of underrepresented groups in this computing research.","title":"RAPID: Mobile Augmented Reality to Improve Rapid Assessments in Disasters","awardID":"1138642","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[496890,"496892",496892,496893],"PO":["565136"]},"184099":{"abstract":"Functional magnetic resonance imaging (fMRI) has become the most common tool for cognitive neuroscience, because it provides a safe, non-invasive, and powerful means to image human brain function. Based on recent rates of publication, there are currently more than 2000 fMRI studies being performed every year worldwide. The aggregation of data across multiple studies can provide the ability to answer questions that cannot be answered based on a single study. For example, using datasets from multiple domains one can start to investigate to what degree a region is selectively engaged in relation to a particular mental process, as opposed to being generally engaged across a broad range of tasks and processes. In addition, it provides the ability to integrate across specific tasks to obtain stronger empirical generalizations about mind-brain relationships, and to better understand the nature of individual variability across different measures. Recent work in neuroimaging analysis has focused on the application of methods such as machine learning techniques to understand the coding of information at the macroscopic level, and network analysis techniques to understand the interactions inherent in large-scale neural systems. The availability of a large testbed of high-quality fMRI data from published studies would also provide an important resource for the development of these and other new analytic techniques for fMRI data. However, sharing of raw fMRI data is challenging due to the large size of the datasets and the complexity of the associated metadata, and there is currently no infrastructure for the open sharing of new fMRI datasets.<br\/><br\/>This project, OpenfMRI, will provide a new infrastructure for the broad dissemination of raw data within cognitive neuroscience, addressing a critical need by providing an open data sharing resource for neuroimaging. The initial project is already online at http:\/\/www.openfmri.org with a limited number of datasets. The full project will greatly expand this repository by providing access to a large number of fMRI datasets from several prominent neuroimaging labs, spanning across a broad range of cognitive domains. Utilizing the substantial computational resources of the Texas Advanced Computing Center, the project will also perform standard fMRI analyses on all data in the repository using a common analysis pipeline, thus providing directly comparable analysis results for all of the studies in the database. The OpenfMRI project will support the development of infrastructural elements to make sharing of data by additional investigators more straightforward.<br\/><br\/>The repository of data that will be created by the OpenfMRI project will also serve as an important resource for teaching by providing students with the ability to replicate the analyses from published studies using the same data. By providing any researcher in the world with the ability to acquire large fMRI datasets, it will also provide all researchers with the ability to work with the same state-of-the-art datasets, regardless of institution. By creating the infrastructure for open sharing of research data, the project will also enhance the impact of other NSF-funded neuroimaging research projects by providing an infrastructure that can be used to make their data available. The planned work has the potential to benefit society by improving education, health, and human productivity through an increased understanding of mental function and its relationship to brain function.","title":"CRCNS Data Sharing: An open data repository for cognitive neuroscience: The OpenfMRI Project","awardID":"1131801","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[493703],"PO":["565292"]},"176124":{"abstract":"In contrast to the prevalent uni-modal perspective, the project focuses on quantitatively integrating information residing in multiple modalities to yield observational behavior analysis descriptions that range from global categories to time continuous behavioral abstractions and contributes novel algorithms and models for recognizing and modeling communicative and affective interaction dynamics elicited in realistic settings of couples and family therapy. The computational challenges are multiple from automated perception of emotionally rich behaviors and cognition through models for domain specific interpretation of the sensed information, to action through combining the knowledge and expertise of humans with the information processing abilities of the machine.<br\/><br\/>The research impacts a wide range of applications centered on observations of the human state and interactions, e.g., mental health applications, business customer services, negotiation tactics, law enforcement (interviews), etc. The project also provides multi-disciplinary training for undergraduate and graduate students. The expected outcomes include benefits to psychology through novel information augmentation, in technology through improved intelligent and robust human behavior computing, and in observational practice through the introduction of transformational tools.","title":"SHB: Medium: Quantitative Observational Practice in Family Studies: The Case of Reactivity","awardID":"1059095","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["515830",471987,471988],"PO":["564768"]},"189797":{"abstract":"Data are increasingly generated, stored, and processed distributively. Meanwhile, when large amounts of data are generated, ambiguity, uncertainty, and errors are inherently introduced, especially in a distributed setup. It is best to represent such data in a distributed probabilistic database. In distributed data management, summary queries are useful tools for obtaining the most important answers from massive quantities of data effectively and efficiently, e.g., top-k queries, heavy hitters (aka frequent items), histograms and wavelets, threshold monitoring queries, etc. This project investigates novel query processing techniques for various, important summary queries in distributed probabilistic data.<br\/><br\/>Broadly classified, this project examines both snapshot summary queries in static (i.e., no updates) distributed probabilistic databases, and continuous summary queries in dynamic (i.e., with updates) distributed probabilistic databases. A number of techniques are explored to design novel, communication and computation efficient algorithms for processing these queries.<br\/><br\/>A distributed probabilistic data management system (DPDMS) prototype is implemented based on the query processing techniques developed in this project. This DPDMS is released to and used in practice by scientists and engineers from other science disciplines as well as industry.<br\/><br\/>Graduate and undergraduate students, including those from minority groups, are actively involved in this project. Findings from the project have been integrated into different courses, demos, and educational projects. For further information, such as publications, data sets, source code, and education initiatives, please visit the project website at http:\/\/www.cs.fsu.edu\/~lifeifei\/dpdm.","title":"CAREER: Novel Query Processing Techniques for Distributed Probabilistic Data","awardID":"1200792","effectiveDate":"2011-09-29","expirationDate":"2016-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["548382"],"PO":["563727"]},"186167":{"abstract":"The organizations and institutions which historically have borne the responsibility for the curation, management, preservation, and retrieval of information contained in physical objects now find themselves confronted by the similar need to manage digital data though the challenges of doing so are distinctly different. <br\/><br\/>This award will convene a committee of experts from the National Research Council's (NRC) Board on Research Data and Information (BRDI) to:<br\/>- Conduct a three day public workshop public of key stakeholders for intensive structured discussions in order to obtain a better understanding of the unprecedented challenges of managing what has been called an \"exaflood\" of data. <br\/>- Design and implement a focused study to better understand the needs and opportunities for a workforce with blended skills and expertise necessary to effectively manage and preserve diverse digital resources and workforce changes as \"digital natives\" enter the workforce.<br\/>- Generate a report that will inform the community on the education and training needs and requirements, career alternatives, and workforce development in regards to digital curation.","title":"Future Career Opportunities and Educational Requirements for Digital Curation","awardID":"1144157","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[499569],"PO":["565292"]},"186079":{"abstract":"Social media have become increasingly critical in many domains, such as commerce, disaster management, science, and national security. In these domains, applications often have to integrate social media to detect emerging events. Today however few solutions for event detection have been developed and they suffer from several important limitations. This exploratory project addresses these limitations and develops a solution that effectively integrates social media to detect emerging events. The solution will focus on the Twittersphere, and will address the following three key challenges: (a) how to exploit characteristics unique to social media to improve the accuracy of detecting events, (b) how to design the solutions such that they scale to high-speed streams of social media (such as 1500 tweets per second), and (c) how to leverage crowdsourcing to find truly interesting events and extract attributes of these events.<br\/><br\/>The project will be among the first to explore in depth how to integrate social media to detect emerging events, taking into account social media characteristics. As such, it is a high-risk\/high-payoff project that can open the door to novel research directions, and help accelerate research into social media integration, an increasingly critical problem that impacts many areas of the society. If successful, the project can also help build practical event discovery tools that can make immediate impacts. Finally, the project will help train a Ph.D. student for two years, and help build and release a set of infrastructure tools and testbeds that can help accelerate subsequent research into social media integration, for both the PI's group and other research groups in social media. The project information will be disseminated via publications, workshops, tutorials, and the Web site (http:\/\/www.cs.wisc.edu\/~anhai\/projects\/event-detection.html) that will include the resulting research results, data and system artifacts.","title":"EAGER: Discovering Emerging Events in Social Media","awardID":"1143807","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[499351],"PO":["563751"]},"181580":{"abstract":"The shifting demographics associated with an aging population require novel solutions to meet the health needs of the growing number of older adults in the US and around the world. Since caring for individuals in assisted living and long-term care facilities costs nearly twice what it costs to care for their non-institutionalized counterparts, technologies that support aging in place are seen as one way to address this pressing problem. Among older adults, the groups at the highest risk for extensive care and services are individuals from rural areas, and underprivileged urban areas. Of these two sub-populations, rural individuals make up one fifth of the elderly population and are at highest-risk for requiring long-term care services and support. Similarly, urban-dwelling older adults in low-SES neighborhoods often experience higher rates of functional loss, and poorer overall health outcomes. In addition to stressing the long-term care resources of Medicare, these high-need older adults often require support from informal caregivers. Informal caregivers provide service that would otherwise cost the Medicare system $375 billion dollars a year. The average caregiver is employed, has children, and sixty-six percent of all informal caregivers in the U.S. are women. These caregivers are often called the \"sandwich generation\" because, in addition to traditional family and work roles, they must also provide care to an older adult relative. Thus, there is a huge need to ease the burden on these caregivers so that they can continue to provide the care required to keep older family members out of assisted living.<br\/><br\/>This project will provide guidance to community members, service providers, and governmental agencies about how to wield technology to enable low-SES, urban- and rural-dwelling older adults to age in place, while simultaneously easing the burden on caregivers. Specifically, the project will perform a needs analysis of these two groups, with an eye to how they are similar to and different from the higher-SES older adults for whom aging in place technologies have already been designed. The project will develop design guidelines to assist designers in targeting this high-need population, taking into account attributes such as proximity of caregivers, access to transportation, access to health services, technology infrastructure and attitudes towards technology. The project will then utilize these guidelines to customize a suite of existing technologies for the specific needs of these two populations. The technologies will be deployed in the homes of older adults in rural and urban settings so that the project can assess how older adults use such technologies and how well these technologies support their ability to age in place. The results will show how pioneering technologies developed in other contexts may be customized for use by low SES, urban- and rural-dwelling older adults. <br\/><br\/>The broader impact of this project include outreach to underserved communities, training of undergraduate and graduate students, broad dissemination of research results beyond traditional disciplinary silos, and building strong connections between academia, private companies, and government agencies, all of whom share the goal of enhancing the quality of life for underserved older adults. Finally, the broader impact in terms of benefits to society is inherent in the research; the project seeks to discover innovative ways of providing more appealing, less invasive, less costly options for caregivers and private and public payers, while simultaneously serving the underserved.","title":"SHB: Small: Privacy-Enhanced Technologies to Support Underserved Older Adults Age in Place","awardID":"1117860","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[486499,"548119"],"PO":["565136"]},"181481":{"abstract":"Spatial navigation is a complex cognitive process that relies on robust and adaptive mechanisms to relate current and future spatial positions to specific locations in the environment. The goal of this project is to provide a better understanding of spatial navigation by integrating information obtained from experimental studies in rats, computational models, and experiments on robots that will test new hypotheses on how these mechanisms work. <br\/><br\/>The hippocampus and medial entorhinal cortex (MEC) are major brain regions involved in mammalian spatial navigation. While the role of place cells in the hippocampus has been extensively studied, there are still many open questions on the functional role of MEC grid cells and their interaction with the hippocampal place cells. Of interest to this proposal is the recent finding that grid cells are organized in an orderly fashion along the dorso-ventral axis of the MEC, with dorsal grids being much more tightly spaced than ventral ones. The investigators hypothesize that this multiscale organization endows the navigation system with a coding mechanism that will inherently achieve robustness with respect to external perturbations such as obstacles or unexpected changes in visual cues. In order to evaluate this hypothesis the investigators will develop computational and robotic models while systematically performing experiments in rat in which the dorsal or ventral portions of MEC or hippocampus will be inactivated. They will introduce new types of mazes in which the spatial frequency of the trajectories will be controlled. This work will contribute to better spatial navigation in robotics by: (1) providing a robotic testbed to evaluate hypotheses on the role of the entorhinal cortex and (2) providing biologically plausible models for robust spatial navigation under uncertain and dynamic environments. These models will suggest alternatives to classical probabilistic methods commonly used in robot Simultaneous Localization And Mapping paradigms. This work will also contribute to studies of spatial navigation in rats by: (1) showing the usefulness of robots in providing a physical testbed beyond pure computational modeling, and (2) exploiting the shorter cycle of robot experimentation to produce maze configurations that are optimal for testing specific hypotheses in rat experiments.","title":"RI: SMALL: Collabrative Research: Investigations of the Role of Dorsal versus Ventral Place and Grid Cells during Multi-Scale Spatial Navigation in Rats and Robots","awardID":"1117303","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["486270",486236],"PO":["564318"]},"183791":{"abstract":"Methods known as 'multivariate pattern' (MVP) analysis can be used to decode the information patterns in brain activity obtained using functional magnetic resonance imaging (fMRI). However, a new decoding model has to be built for each brain, because two brains (and the representational spaces they employ) are difficult to align at a fine spatial scale. As a consequence, we do not yet know if different brains use the same codes or idiosyncratic codes to represent the same things. With funding from the National Science Foundation, Drs. James V. Haxby of Dartmouth College, and Peter J. Ramadge of Princeton University, in collaboration with Michael Hanke of the University of Magdeburg (Germany), are developing new methods to discover a coding scheme that works accurately across different brains. The methods being developed align brain activity across brains by projecting individual brain data into a common, high-dimensional space. This approach allows the researchers to build models of brain representational spaces for different cortical areas that are valid both across brains and across a wide range of stimuli and cognitive states. The researchers are developing two algorithms. One is referred to as 'hyperalignment' and the other as 'functional connectivity hyperalignment.' Hyperalignment rotates the voxel spaces (i.e., the smallest units in a brain image) of individual brains into a single high-dimensional space, in which each dimension is a profile of differential responses to stimuli, that is common across brains. Functional connectivity hyperalignment aligns voxel spaces based on the functional connectivity profile (i.e., relationships among activated brain areas) for each cortical location. Functional connectivity profiles allow for models of areas that do not respond to external stimuli in a consistent manner, for example, those areas in the so-called 'default-intrinsic system' that plays a central role in social cognition. The investigators are an interdisciplinary partnership - cognitive neuroscientists and signal-processing engineers - who have been working together successfully for several years. <br\/><br\/>Developing the computational methods to build common models of representational spaces will augment the power of brain activity decoding techniques, making it possible to investigate how finer, more detailed information is embedded in brain activity patterns, and to read out that information from functional brain imaging data. The proposed methods also will allow extension of brain decoding to the neural codes that underlie social cognition, that is, the representation of knowledge about the personal traits and mental states of others. These models also will allow investigation of how neural coding is altered within brain regions that are affected by experience, by development, and by psychopathology.<br\/><br\/>This project is jointly funded by Collaborative Research in Computational Neuroscience and the Office of International Science and Engineering. A companion project is being funded by the German Ministry of Education and Research (BMBF).","title":"U.S.-German Collaboration: Building common high-dimensional models of neural representational spaces","awardID":"1129855","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1699","name":"COGNEURO"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[492896],"PO":["562348"]},"181382":{"abstract":"Finding and quantifying differences between shapes is important in many areas of the biological sciences. This methodological research will contribute to ongoing research in two areas, neuroscience and paleontology. In neuroscience, the interest is mainly in tracking the progress of Alzheimer's disease and normal aging processes in the brain, and relating the 3D shape changes seen in MRI scans to cognitive measurements and other variables. NIH studies provide access to large amounts of such data. In paleontology, the only information on many extinct species comes from fossils, and estimates of the relationships between these fossil species and human ancestors is based largely on differences and similarities of shape. The goal is to put fossil shape data into the context of much larger sets of data collected from existing species, both morphological and genomic data from earlier research. <br\/><br\/>This collaboration is interested in defining and computing what it means for three-dimensional biological shapes to resemble each other; as specific examples, they consider the shapes of fossil primate bones and of regions in the brain such as the hippocampus. Current practical measures of shape difference are based on sets of corresponding point samples on the object surfaces. The team will add a surface mesh connecting these corresponding points, and represent a shape by the vector of the lengths of the edges in its copy of the mesh. The distance between two shapes is then the Euclidean distance between their corresponding edge vectors. This representation has some attractive mathematical properties. With a few simple additional requirements on the mesh, the edge-length vectors form a high-dimensional Euclidean space, within which standard statistical analyses can be performed. Second, the measure is invariant to rotations and translations not only of the entire object, but to a large extent to transformations of one part of the object with respect to the rest. <br\/><br\/>The research will include experimental work to compare the proposed metric and<br\/>current methods in both neurobiology and in physical anthropology. They also intend to work on methods to simplify finding and optimizing corresponding points and meshes connecting them on input specimens, a perennial problem in three-dimensional data analysis. Not only is this important to facilitate experiments, but having a good practical shape metric will help improve techniques in this area. Finally, the team plans work on interesting related mathematical problems, specifically the convergence of the metric to property of smooth surfaces as the sampling density is increased <br\/><br\/>There are plans to release both software for the use of practitioners and ensembles of data annotated with corresponding meshes for the use of other researchers into the methodology of shape differences. In this way the research should benefit many others who analyze shape differences: our colleagues in paleontology and neuroscience, people who study the anatomy of humans, other animals and even plants, forensic scientists, and others.","title":"III: Small: Collaborative Research: Shape Differences in the Biological Sciences","awardID":"1116921","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[485996,485997,485998,485999],"PO":["565136"]},"181272":{"abstract":"The United States is a world-leader in software and in multimedia content (e.g. music, film). To remain so, we must continually raise the bar in both software and media production. Software tools for media production (e.g. the audio production suite Protools) often have complex interfaces, conceptualized in ways that makes it difficult for any but the most expert to realize the power of these tools. Complex interfaces and steep learning curves can discourage creative people from doing their best work with such tools. Here, we focus on audio production tools. We propose a user-centered approach to remove the great disconnect between existing audio production tools and the conceptual frameworks within which many people work, both expert musicians and the broader public. The tools we develop will automatically adapt to the user's conceptual framework, rather than forcing the user to adapt to the tools. Where appropriate, the tools will speed and enhance their adaptation using active learning informed by interaction with previous users (transfer learning). The tools will also automatically build a crowdsourced audio concept map. This will help provide facilities for computer-aided, directed learning, so that tool users can expand their conceptual frameworks and abilities. By letting people manipulate audio on their own terms and enhancing their knowledge of such tools with directed learning, we expect to transform the interaction experience, making the computer a device that supports and enhances creativity, rather than an obstacle.<br\/><br\/>This work will have a number of broader impacts. The tools developed will be directly usable by practicing musicians and will also facilitate learning and creativity for the general public. These techniques will also be applicable to personalization of hearing aids and new diagnostic systems for audiologists. Our approach to tool personalization is core work in human-computer interaction and should generalize to other creative activities (e.g. image manipulation). Resulting advances in active and transfer learning will be of great value to machine learning researchers. Finding the relationships between quantifiable parameters of audio and the language and metaphors used by practicing musicians to describe sound is central to this work. This is of great interest to cognitive scientists, linguists, artificial intelligence researchers, and engineers. Concept maps for audio terms should also prove useful for machine translation. Broad application of techniques to map human descriptive terms on to machine-manipulable parameters will change expectations for both artists and scientists. Artists will be able to explore new lines of creativity that currently require significant investments of time in vastly disparate fields (e.g. signal processing and painting). This has the potential to transform information science and lead to new cognitive models of creativity, forming the basis for new approaches to education and research in both technology and in art.","title":"HCC: Small: Building Audio Interfaces with Crowdsourced Concept Maps and Active Transfer Learning","awardID":"1116384","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["562931",485732],"PO":["565227"]},"184671":{"abstract":"The electric grid in the United States has evolved over the past century from a series of small independent community-based systems to one of the largest and most complex cyber-physical systems today. However, the established conditions that made the electric grid an engineering marvel are being challenged by major changes, the most important being a worldwide effort to mitigate climate change by reducing carbon emissions.<br\/><br\/>This research investigates key aspects of a computation and information foundation for future cyber-physical energy systems?the smart grids. The overall project objective is to support high penetrations of renewable energy sources, community based micro-grids, and the widespread use of electric cars and smart appliances.<br\/><br\/>The research has three interconnected components that, collectively, address issues of computation architecture, information hierarchy, and experimental modeling and validation. On computation architecture, the framework based on cloud computing is investigated for the scalable, consistent, and secure operations of smart grids. The research aims to quantify fundamental design tradeoffs among scalability, data consistency, security, and trustworthiness for emerging applications of smart grids. On information hierarchy, temporal and spatial characteristics of information hierarchy are investigated with the goal of gaining a foundational understanding on how information should be partitioned, collected, distributed, compressed, and aggregated. The research also develops an open and scalable experimental platform (SmartGridLab) for empirical investigations and testing of algorithms and concepts developed in this project. SmartGridLab integrates the hardware testbed with a software simulator so that software virtual nodes can interact with physical nodes in the testbed. This research also includes a significant education component aimed at integrating frontier research with undergraduate and graduate curricula.","title":"CPS:Medium:Collaborative Research:Information and Computation Hierarchy for Smart Grids","awardID":"1135844","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[495285,495286,495287,"531874"],"PO":["565239"]},"181162":{"abstract":"Programs with potentially malicious content are becoming increasingly common. Such programs are usually highly obfuscated, using a variety of techniques that make it difficult to analyze the code, figure out its internal logic, and develop countermeasures. Existing tools for reverse engineering such programs are primitive and require a great deal of tedious and time-consuming manual intervention, which hampers the timely development of defenses against newly discovered malware. This project aims to devise automatic techniques to simplify away these obfuscations and thereby make it significantly faster and easier to understand the internal logic of obfuscated code with potentially malicious content. <br\/><br\/>The project uses dynamic program analysis techniques to identify instructions that affect the program's observable behavior; these instructions are then extracted and, where appropriate, simplified using equational techniques. Key research questions investigated include simplification in the face of arbitrary obfuscations and combinations of obfuscations, including (possibly multiple layers of) self-modification and emulation. The main impact of this project will be to make it easier and quicker for security researchers to figure out the internal logic of malware programs. This, in turn, will make it possible to respond more quickly to new malware and develop countermeasures to them faster and with less manual intervention. The effect will be to reduce the damage done by malware before they can be neutralized.","title":"TC: Small: Simplification of Obfuscated Executables","awardID":"1115829","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550173"],"PO":["564388"]},"184682":{"abstract":"Robotic devices are excellent candidates for delivering repetitive and intensive practice that can restore functional use of the upper limbs, even years after a stroke. Rehabilitation of the wrist and hand in particular are critical for recovery of function, since hands are the primary interface with the world. However, robotic devices that focus on hand rehabilitation are limited due to excessive cost, complexity, or limited functionality. A design and control strategy for such devices that bridges this gap is critical. The goals of the research effort are to analyze the properties and role of passive dynamics, defined by joint stiffness and damping, in the human hand and wrist during grasping and manipulation, and then mimic such properties in a wrist-hand exoskeleton for stroke rehabilitation. The project will culminate with device testing in collaboration with rehabilitation clinicians.<br\/><br\/>A significant problem in robotic rehabilitation is how to provide assisted movement to the multiple degrees of freedom of the hand in order to restore motor coordination and function, with a system that is practical for deployment in a clinical environment. Armed with a clearer understanding of the mechanisms underlying passive dynamics and control of systems exhibiting such behavior, this project will inform the design of more effective wrist\/hand rehabilitation devices that are feasible for clinical use. In addition, the proposed project will create a unique interdisciplinary environment enabling education, training, and co-advising of graduate students, undergraduate research, and significant and targeted outreach activities to underrepresented groups in science and engineering.","title":"NSF-CPS-Medium: Collaborative Research: Design and development of a cybernetic exoskeleton for hand-wrist rehabilitation through the integration of human passive properties","awardID":"1135916","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["532891"],"PO":["565239"]},"184693":{"abstract":"CPS: Medium: Collaborative Research: CyberMech, a novel run-time substrate for cyber-mechanical systems<br\/><br\/>Growing demands on our civil infrastructure have heightened the need for smart structural components and systems whose behavior and performance can be controlled under a variety of loading scenarios such as high winds and earthquakes. However, due to the sheer size, scale and cost of most civil engineering structures, design and testing of such smart structures needs to be conducted using a hybrid cyber-physical approach where the infrastructure system in question, for example a bridge, is studied by coupling a small number of physical components with a numerical model of the rest of the structure. Undoubtedly, the success of such a hybrid approach, especially for dynamic real-time applications, hinges on effective integration of the cyber and physical components of the system. This project provides the essential building blocks and a computational integration platform to enable real-time hybrid testing of civil engineering structures.<br\/><br\/>Design and development of physical components, multi-level numerical models, and real-time control algorithms will be conducted at Purdue University. Washington University will provide an adaptive, configurable concurrency platform and communication mechanisms that meet the strict scheduling constraints of real-time cyber-physical systems. The two institutions will collaboratively design a prototype system and conduct extensive testing to validate the integration of the various components and evaluate system performance. Specifications, software, benchmarks, and data developed during the course of this project will be made freely available to the cyber-physical research community. In addition to directly advancing the state-of-the-art in real-time hybrid testing, this research will also impact the areas of avionics, automotive design, smart grids for distributed power transmission and similar applications in other domains.","title":"CPS: Medium: Collaborative Research: CyberMech, a Novel Run-Time Substrate for Cyber-Mechanical Systems","awardID":"1136075","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["501588","517390"],"PO":["565264"]},"181063":{"abstract":"Location is a type of information that can be used by various applications to provides new opportunities for business and commercial success, and at the same time may be misused. This proposed research aims at developing a multi-model architecture with privacy-enhancing techniques for countering location spoofing attacks while respecting location privacy of mobile users. The multi-model architecture promotes the parallel use of alternative positioning models and multi-beacon methods to make it harder to launch consistent location spoofing attacks. A pseudo-identity obfuscation technique is incorporated into the multi-model defense architecture based on mobility-aware mix-zones to address the legal, social, and ethical implications of continuous location verifications. In this technique, mobile users may customize the settings of mix-zones in order to meet their personalized privacy preference.<br\/><br\/>The intellectual merit of the proposed research includes a transformative approach that advocates privacy-aware and customizable defense architecture and algorithms to detect and filter out compromised mobile nodes. This detection and filtering is based on the amount of inconsistency between the client-claimed location and the system-determined location as well as the amount of inconsistency among multiple beacons. The broader impacts of this research are two-fold. First, the development of a systematic and privacy enhancing approach for countering location spoofing threats will help enabling a wide range of subscription-driven location based services, such as location-based advertisements, location-based content dissemination and billing, and location-based entertainment. Second, the technical results and the proof-of-concept prototype will be disseminated to a broader audience through educational activities and involvement of women and minority in the proposed research. The unique combination of location spoofing countermeasures with a location privacy awareness is a direct contribution to the multi-disciplinary efforts aimed at meeting the security and location privacy challenges with technical, legal, social, and ethical considerations, and increases the societal confidence in the cyber infrastructure.","title":"TC: Small: Countering Location Spoofing Attacks: Multi-Model Architecture with Privacy-Enhancing Techniques","awardID":"1115375","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521101"],"PO":["562974"]},"181184":{"abstract":"This research will develop techniques that enable a server to verify the behavior of a client with which it is communicating as being consistent with the sanctioned client software. A client's behavior might deviate from the sanctioned client software due to manipulation of the client software or its data structures by an adversary with physical access to the client computer or by malware that has infected the client. This manipulation may yield incorrect state at the client; examples might include modifications to shared state in a collaborative application that should not have been possible, or an input to an imminent server-side invocation containing content that the sanctioned client software would not have allowed. If this state is authoritative within a larger distributed application or otherwise dangerous to the server or other clients, then this incorrect state may compromise the integrity of the application. The techniques developed in this proposed work will detect client behaviors arising from such modifications or, more specifically, any client-to-server messages that are inconsistent with the sanctioned client software.<br\/><br\/>A central challenge in validating client behavior is that this behavior is the result of client processing with inputs that are potentially unknown to the server. These unknown inputs can include environmental inputs at the client (e.g., values sensed at the client location), user inputs (e.g., the user's keystrokes), and even which server messages were processed by the client at the point at which it sent the message being verified. To permit verification despite this obstacle, this project will investigate the use of symbolic execution of the sanctioned client software and constraint solving to enable the server to determine whether there are any inputs that could have given rise to this client message. If it finds that no inputs could have given rise to this message, then it detects the client behavior as being inconsistent with the sanctioned client software. The project will produce new research results and tools to enable this analysis to be performed efficiently. Moreover, the use of computer games as one vehicle to demonstrate this research makes this project ideal for outreach to high-school students and undergraduates, with whom computer games are immensely popular.","title":"TC: Small: Server-side Verification of Client Behavior in Distributed Applications","awardID":"1115948","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553884"],"PO":["564388"]},"182296":{"abstract":"Economic competitiveness relies upon innovation and digitized tools, services and data representation. These innovations are required for organizations to remain effective. Designers and design managers guide the evolution of digitally enabled design capabilities by integrating different types of digital process capabilities and resources. Such capabilities can also help optimize complex systems (e.g., smart grid, pervasive healthcare). Building on organizational and evolutionary theory, this project studies changes in organizational processes as they incorporate innovative virtual elements. It applies a process modeling framework to explore underlying mechanisms that generate patterns of change, and uses computational tools in conjunction with theories of evolutionary genetics to analyze longitudinal changes in organizational processes for integrating virtualized innovations. Generative structural elements of design processes (e.g., genotypes) give birth to surface-level design routines and variations (e.g., phenotypes) over time. Processes are represented as sequences akin to biological genes and their translated protein products. while combinations of elements akin to DNA base pairs and their corresponding amino acids capture essential traits of design activity. This new vocabulary helps us delineate structurally the fundamental design task elements and their variation across design task instances.<br\/><br\/>The study advances theoretical understanding of how digital capabilities alter organizational processes. It shows how mutations emerge and how processes change over time. It identifies strategies for embedding digital capabilities into processes, and explores the impact of complexity. It advances instrumentation, methodology and analytical techniques by describing digitally-enabled processes and performing comparative, hierarchical, structural-analytical analyses of event-sequence-based process data. It provides longitudinal data on the micro- and meso-level changes in design processes from systematic studies of design for cars, chips and buildings. Genetics research is used to evaluate design in light of evolutionary models and agent-based simulations and to identify patterns of integration of digital capabilities into design processes over time.","title":"VOSS-Collaborative Research: Evolution of Virtualized Design Processes in Project-Based Design Organizations","awardID":"1121935","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"5376","name":"INNOVATION & ORG SCIENCES(IOS)"}}],"PIcoPI":["517735"],"PO":["565255"]},"186784":{"abstract":"In many areas of science, simulations and experiments begin to generate many petabytes of data, with some sciences facing exabytes of data near term. Similarly, the collection of information about the Internet applications and users for a variety of purposes is generating only more data. Our ability to manage, mine, analyze, and visualize the data is fundamental to the knowledge discovery process. That is, the value of data at extreme scale can be fully realized only if we have an end-to-end solution, which demands a collective, inter-disciplinary effort to develop. We are in need of an international venue to gather researchers and practitioners from government agencies, universities, industry, and oversea to exchange ideas and experience, layout research directions, and establish collaborations. The first symposium on large data analysis and visualization is founded to serve those purposes.<br\/><br\/>The proposed symposium, held during October 23-24 in conjunction with VisWeek 2011, aims at bringing together domain scientists, data analytics and visualization researchers, and users, and fostering the needed exchange to develop the next-generation data-intensive analysis and visualization technology. Attendees of the symposium are introduced to the latest and greatest research innovations in large data management, analysis, and visualization, learn how these innovations impact data intensive computing and knowledge discovery, and also learn about the critical issues in creating a complete solution through both invited and contributed talks, poster presentations, panel discussion, and a large data visualization contest that provides massive data and supercomputing time to contestants.","title":"The 1st Symposium on Large Data Analysis and Visualization","awardID":"1147363","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["552243"],"PO":["565136"]},"186795":{"abstract":"Computing has enabled immense innovations in many fields and social<br\/>life due to continued performance, power, and cost improvements<br\/>enabled by technology scaling. Unfortunately, two key trends threaten<br\/>performance and cost improvement of computers going into the<br\/>future. First, technology scaling is at jeopardy, leading to major<br\/>challenges in power consumption, reliability, and performance. Second,<br\/>power and energy consumption has become a key constraint, yet existing<br\/>systems are mostly designed in a one-size-fits-all way agnostic to the<br\/>needs of different applications. To overcome both problems, this<br\/>research investigates novel uses of heterogeneous technologies in<br\/>three key components of a computing system: cores, interconnect, and<br\/>memory. The approach taken is an application-driven approach that aims<br\/>to seamlessly integrate heterogeneity in the three components. Major<br\/>expected contributions of the research include: (1) an initial study<br\/>of first-principles based and application-driven design of cores, (2)<br\/>new mechanisms for enabling phase-change memory based heterogeneous<br\/>main memory, (3) exploration of tradeoffs in the design of<br\/>3-dimensional optical interconnects, (4) initial exploration of the<br\/>interaction of heterogeneous components in cores, interconnect, and<br\/>memory.<br\/><br\/>The proposed research has the potential to transform the design and<br\/>architecture of future multi-core systems, which are already a part of<br\/>the entire IT sector and our daily lives. It can enable overcoming key<br\/>challenges that impediment higher-performance and lower-power<br\/>lower-cost computing, which has traditionally enabled new applications<br\/>and discoveries. Enabling fundamentally efficient heterogeneous<br\/>multi-core systems can largely reduce energy and technology-scaling<br\/>costs of computing, and improve dependability and performance. Direct<br\/>transfer of many ideas to industry are expected through extensive<br\/>collaborations with platform and chip design industries.","title":"EAGER: Collaborative Research: Heterogeneous Cores, Memory-Hierarchy and Communication Architectures for Future CMPs","awardID":"1147397","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550874"],"PO":["366560"]},"175311":{"abstract":"Message passing in wireless networked sensing and control systems must be reliable and in real-time. Such design challenges require new models and distributed protocols for messaging that can handle interference locally and accurately, given the basic problem of computing probabilistic path delays is NP-hard. Focusing on single-hop transmission scheduling and multi-hop spatio-temporal data flow control, this project makes novel contributions by proposing two major research tasks: 1) investigation of control-theoretic approaches to online model instantiation, based on the physical-ratio-K (PRK) interference model, and addressing the challenges of large interference range as well as anisotropic, asymmetric wireless communication; 2) developing a lightweight approach to computing probabilistic path delays followed by a multi-timescale adaptation framework for real-time messaging. In particular, the PRK interference model integrates protocol model's locality with physical model's high-fidelity, thus bridging the gap between the suitability for distributed implementation and the enabled scheduling performance. By controlling network operations at the same timescale as the corresponding dynamics, the proposed multi-timescale adaptation framework ensures long-term optimality while simultaneously addressing short-term dynamics. Additionally, this project includes an integrated, multi-level, multi-component education plan. The education activities will raise public awareness, improve student retention and participation of underrepresented groups in computing.","title":"CAREER: Taming Uncertainties in Reliable, Real-Time Messaging for Wireless Networked Sensing and Control","awardID":"1054634","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["495329"],"PO":["565303"]},"185002":{"abstract":"Fueled by the ubiquity of communications access, networked systems have become pervasive and given rise to behaviors whose evolution depends on both individual decisions and the interactions on the network. Examples of such behaviors include media sharing websites, where user recommendations influence product adoption decisions of other users, or more generally public discussion forums where past voting records of users provide indications on how they may influence each other and, therefore, how initial opinions may determine the outcome of future votes. Understanding the evolution of decisions in such connected settings can, therefore, be of significant social and economic benefit. For example, this can help predict the adoption of new social policies, or more pragmatically the commercial success of a new shared application. The importance of those questions has attracted much recent attention, but due to the complexity of networked interactions, much remains to be done. This project takes a multi-disciplinary approach to tackling these challenging questions, and seeks to build on models from statistical physics developed to capture the interactions of charged particles, which interact with each other in a manner akin to how users influence each other in a social network. If successful, the work can both expand the set of tools available to explore the behavior of networked systems, and offer insight into specific problems of interest.<br\/><br\/>This project explores two fundamental aspects of networked systems, namely, the formation of opinions in networks, and how adoption decisions are made when they are influenced by network neighbors. Networked systems can be of many different forms, including communication networks, social networks, political networks, geographical networks, etc., and are characterized by the fact that connections between network members influence their interactions. Characterizing these interactions is a complex task. The two main goals of the project are to (i) extend models from statistical physics to apply them to fundamental problems in networked systems; and (ii) empirically validate the predictive abilities of these models. Specifically, the project seeks to leverage and extend the Ising spin glass model, and apply these extensions to problems of opinion formation and adoption decisions in networked systems. Empirical validation of the results will then be sought through comparison to data collected from social media websites.","title":"EAGER: Collaborative Research: Information Diffusion and Opinion Formation in Networked Systems","awardID":"1137597","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[496368],"PO":["565251"]},"186102":{"abstract":"This project, generalizing mean-field approaches from physics and chemistry for integrated design of scalable, network resource aware, distributed control strategies for multi-agent robotic systems, aims to develop macroscopic models that retain salient features of the underlying multi-agent robotic system and use these models in the design of distributed control strategies. For complex cyber physical systems, this promises to provide a novel design methodology that is potentially applicable to a large class of systems and, therefore, will result in foundational knowledge of use to the community at large. This high-risk, high-reward project integrates ideas from physics, chemistry, control theory, and robotics to develop new theoretical foundations for the design, validation, and improvement of coordination strategies for multi-agent robotic systems.<br\/><br\/>The project?s intellectual merit lies in the ensemble approach towards the design, validation, and improvement of cyber physical systems. Mean-field methods provide a system-level abstraction of the underlying distributed system while retaining the salient features of the various agent-level interactions. The generalization of these models to ensembles of interacting engineered systems provides new methods for designing distributed controllers that are sensitive to changing network resources and whose performance can be predicted and adjusted to achieve both the desired short-term and long-term performance specifications.<br\/><br\/>Broader Impacts: The broader impacts of this project are twofold. First, the mean-field approach takes into account network resource usage and management, providing an integrated strategy for designing scalable decentralized control and coordination strategies. Second, different from biologically-inspired approaches, the mean-field approach enables the design of distributed coordination strategies whose performance can be systematically predicted and tuned to meet detailed performance specifications. This has the potential to unify various existing multi-agent coordination approaches. The research outcomes will be disseminated through publications in technical conferences and journals and incorporated into the PI?s existing undergraduate and graduate curriculum and K-12 outreach efforts targeted at increasing female participation in STEM fields.","title":"EAGER: Ensemble Design of Resource-Aware Control Strategies for Multi-Agent Robotic Systems","awardID":"1143941","effectiveDate":"2011-09-15","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["551322"],"PO":["543539"]},"185376":{"abstract":"The workshop gathers developers and users of lexical resources, corpus and computational linguists and researchers in natural language processing to discuss a targeted restructuring of the adjectives in the lexical database WordNet. Specific proposals for replacing a subset of the current clustering of adjectives around antonyms with ordered scales reflecting the relative intensity of dimensional adjectives, such as \"big\", \"huge\" and \"gigantic\", are presented along with preliminary work demonstrating the feasibility of corpus-based construction of scales by means of lexical-semantic patterns and their potential benefits for NLP. Discussion topics include (1) the principal benefits of encoding scalar properties for applications including word sense disambiguation, textual entailment and language pedagogy; (2) suitable corpora for extracting data for scale construction; (3) limitations of the recently-developed AdjScales method and alternative or complementary methods for extracting scalar properties; and (4) modeling of scalar adjectives in WordNet. Participants evaluate the proposed restructuring of adjectives for its feasibility, value and relevance to their own work and its potential for future research and applications. A report including the presentations, discussions and recommendations of the group will be prepared and freely disseminated via the WordNet website. <br\/><br\/>The directions for targeted future developments of the widely used WordNet database as spelled out and agreed upon by representatives from a broad expert community assure significant consequences for research and applications in language technology and pedagogy. For a post-doctoral fellow and a graduate student the workshop provides a unique opportunity to interact with experts in the field.","title":"A Workshop on Restructuring Adjectives in WordNet","awardID":"1139844","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["511536"],"PO":["565215"]},"186113":{"abstract":"While current cellular networks are based essentially on one-to-many and many-to-one single-hop subnets and cope with inter-cell interference by careful centralized resource planning, future wireless networks must consider heterogeneous environments characterized by user-deployed and user-operated infrastructure in which multiple flows and multiple hops will play an increasingly relevant role. Indeed, such networks are expected to open doors to trillions of dollars of e-commerce, while also providing vast amounts of easily accessible knowledge to the public. Developing a fundamental understanding of multihop multiflow wireless networks is therefore critically important at this time.<br\/><br\/>This exploratory project will seek to discover the fundamentals of such networks by obtaining their information theoretic capacity in an approximated sense. It is expected that scalable and extensible solutions are possible for such networks ranging from the seemingly simple ones involving two hops and two flows to apparently more complex ones involving multiple hops and more than two flows with arbitrary connectivity. In so demonstrating, multiple metrics will be employed. These metrics in the increasing order of accuracy in the high signal-to-noise ratio regime are (a) the fundamental limit on the available signaling (temporal\/spectral\/spatial) dimensions of the network, (b) the fundamental limit on the available signaling and signal-level dimensions, and (c) the capacity to within a (universal) constant number of bits independently of channel parameters.","title":"EAGER: Collaborative Research: CIF: Exploring the Fundamentals of Multihop Multiflow Wireless Networks","awardID":"1143982","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["550258"],"PO":["564924"]},"186377":{"abstract":"Modern multicore architectures, that provide high raw gigaflops and teraflops, have deep memory hierarchies and low overhead threading capabilities. Lack of support for directly exploiting these capabilities leads to severe under-utilization especially for data intensive applications. This project expects to develop methods that efficiently use the available computational power to provide cost improvement for large scale data processing systems. <br\/><br\/>This project will develop a highly efficient computation framework called GLADE that will support a large class of data intensive applications, and will be based on a novel computational model called generalized linear aggregates. The commutative and associative properties of Generalized Linear Aggregates facilitate highly efficient parallel and distributed computation as well as exploitation of deep memory hierarchies, especially when multiple queries are simultaneously executed as is typical in many data-processing tasks. The resulting one to two orders of magnitude improvement in computational efficiency can be expected to yield corresponding reduction in cost and energy requirements of data processing tasks which in turn will make it feasible to analyze much larger data sets than currently possible.<br\/><br\/>The proposed work will make the synergistic combination of high performance computing and large scale data analysis widely available to researchers, and other interested groups in government, industry, and education. The enabling of a large number of data intensive application using inexpensive computers that cost in low tens of thousands of dollars will broaden the use of data analysis, exploration and mining for a wide variety of existing and emerging applications. Examples of such applications include network intrusion detection, social network analysis, climate data, ecosystem analysis, and customer relationship management. Additional information about the project can be found at: http:\/\/sites.google.com\/site\/sanjayranka\/glade.","title":"III: EAGER: A Framework for Large Data Analysis","awardID":"1144985","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["533539","530024"],"PO":["565136"]},"188005":{"abstract":"It has been widely cited that configuration errors enable 65% of cyber attacks and cause 62% of infrastructure downtime. This SafeConfig is a 2-day Symposium on Configuration Analytics and Automation that focuses on addresses challenges and future solution to develop assurable, measurable and usable security and network configurations (www.safeconfig.org). The main objective of this project is to encourage graduate student participation in SafeConfig 2011, which will bring together the research, industry and government communities to exchange experiences, discuss challenges and propose research directions. Early faculty researchers and students will have a unique opportunity to interact with senior researchers in the field from all three communities. They will greatly benefit from the collocation with NIST Security Automation Conference by learning about the state-of-the-art solutions, and connect to industry and government activities. Today's graduate students will play a central role in shaping the future of networking and security technologies. They are the future the administrators, developers, and researchers who will manage, implemented and create solutions to address our current and future challenges of developing secure and assurable network and system configuration systems. Attending specialized and focused event on this area is the most effective way to expose students to the current challenges and future development of this area. This project will facilitate the attendance of young researchers and students to attend SafeConfig 2011 and interact with top researchers from academic, industry and government.","title":"SafeConfig Symposium Student Travel Award","awardID":"1153691","effectiveDate":"2011-09-15","expirationDate":"2013-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563217"],"PO":["551712"]},"176059":{"abstract":"Logic solvers are software programs that can solve complex logical<br\/>formulas fully automatically. Problems in many areas of Computer<br\/>Science, such as artificial intelligence, program analysis, security,<br\/>hardware verification, and cyber-physical systems can be<br\/>translated into logical formulas. Those formulas can then be solved<br\/>fully automatically by logic solvers. Over the past two decades, at<br\/>least ten different logic-solving communities have emerged, based on<br\/>different logical languages and solving techniques. These communities<br\/>have independently been building computing infrastructure to aid<br\/>development and evaluation of their solvers: libraries of benchmark<br\/>formulas, cluster-backed web services, annual competitions, and more.<br\/>Such infrastructure also provides an important access point for<br\/>users, who can find all the solvers at one site, or even run solvers<br\/>on the infrastructure cluster to test their relative capabilities.<br\/><br\/>The goal of this research is to build a single piece of shared<br\/>computing infrastructure called StarExec, which will be used by <br\/>different logic solving communities. StarExec will provide improved<br\/>services for established logic-solving communities, and lower the<br\/>entry barrier for new and emerging communities.<br\/><br\/>The StarExec infrastructure will consist of a custom web service<br\/>interfacing to a medium-sized compute cluster. This open-source<br\/>service will allow multiple logic-solving communities to host<br\/>benchmark libraries, run jobs comparing different solvers, and host<br\/>competitions. StarExec will leverage economies of scale to provide<br\/>more sophisticated services than is feasible for most individual<br\/>logic-solving communities. A very important goal of StarExec is not<br\/>just to collocate different logic-solving communities, but to unite<br\/>them. To this end, the StarExec team will develop formal<br\/>specifications of both the syntax and proof-theoretic semantics of<br\/>different communities' logical languages. This will be done using a<br\/>meta-language called LFSC (\"Logical Framework with Side Conditions\"),<br\/>developed in previous NSF-funded research. Translation of formulas<br\/>between compatible fragments of different logics will be implemented,<br\/>which will will enable a greater degree of integration between solver<br\/>communities than was previously possible. For example, it will be<br\/>possible for solvers in one community to be run on benchmarks from<br\/>another. This integration will also aid users of logic solvers, who<br\/>will have a greater variety of options, all in a common framework, for<br\/>solving their problems. The broader impact of the StarExec project<br\/>will be to accelerate the development, adoption, and convergence of<br\/>different logic-solving technologies. This will enable faster<br\/>progress in nationally important application areas such as artificial<br\/>intelligence, verification, security, and cyber-physical systems,<br\/>which increasingly depend on high-performance logic solvers.","title":"Collaborative Research: CI-ADDO-NEW: StarExec: Cross-Community Infrastructure for Logic Solving","awardID":"1058748","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521573","532995"],"PO":["565264"]},"181570":{"abstract":"This project, which is to be conducted by researchers from UNC Charlotte and the Electric Power Research Institute (EPRI), addresses practical design issues for achieving reliable and uninterrupted operation of wireless sensor networks (WSNs) using harvested ambient energy. The challenge is that these energy sources are often subject to significant spatial and temporal variations. The goal of this project is to create a framework allowing rechargeable nodes to automatically adapt to estimated energy budgets while performing their required monitoring tasks. This adaptive framework is implemented at two levels. The first applies to transmission power control and energy-aware routing; while the second addresses adaptations to temporal variations using an adaptive level-crossing sampling scheme. <br\/><br\/>Intellectual Merit: The proposed research components may be applied to any rechargeable sensor network. The proposed cooperative power control method can potentially solve the overhearing problem, which is a key issue in large-scale wireless sensor networks. The energy-aware and load-balanced routing problems considered here address the unique requirement of meeting specific energy budgets. These network-level solutions are integrated with an adaptive application-level solution designed to overcome the challenges introduced by energy variations.<br\/><br\/>Broader Impacts: This research addresses a critical issue that is currently of wide interest in the research community. In addition, this project will make educational impacts on UNC-Charlotte students by offering two graduate courses and creating graduate level research projects. This project will bridge the gap between theoretical research and applications and will facilitate stronger research collaborations between the academic and industrial partners involved.","title":"NeTS: GOALI: Towards Adaptability to Variations of Renewable Energy in Large Scale Rechargeable Wireless Sensor Networks","awardID":"1117790","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[486469,486470,"507823","490060",486473],"PO":["565303"]},"181460":{"abstract":"Computation in many emerging applications, such as online advertising and large scale social, media or sensor networks, is increasingly moving away from a simplistic view of computing a fixed function on a well defined input. Increasingly we are realizing that the input and the function are only the means to an end; and are inexact and imprecise at best. In many of these applications, the cost of realizing the input, in possibly distributed and dynamic\/interactive environments, is a significant fraction of the cost of the computation itself. The emerging theme has been (i) to formulate models (very often probabilistic) of the input, (ii) precompute strategies that probe or realize few pieces of the input, and (iii) execute the strategies while making small adjustments as the data is incrementally made available. Moreover all these three stages are interleaved and the optimization is often repetitive. The overall process corresponds to repeatedly adapting to the short run behavior of the input which is reset often, starting from an initial and aggregate model of the long term behavior. Thus the task is to design and analyze algorithms that span and adapt to multiple scales of time.<br\/><br\/>Similar problems which encode the tradeoffs between exploration and exploitation has classically been modeled by the Multi-Armed Bandit problem, where the arms correspond to the available choices. However, these emerging domains differ in several critical aspects. This proposal seeks to extend the optimization and analysis of Multi-Armed Bandit problems in a number of novel dimensions, specifically in terms of nonlinear and subadditive objective functions, noisy and error-prone feedbacks, lack of centrality and entangled feedbacks, implementation barriers of budgets or policies, and dynamic behavior. These extensions are connected, and progress on these problems would lead to a wealth of new results and more importantly, new techniques, in optimization as well as in bandit literature.<br\/><br\/>In addition to the development of new algorithmic and analysis ideas, the proposal would train graduate students to develop simultaneous expertise in theoretical computer science, machine learning and statistics, as well as stochastic control. Moreover the crosscutting aspect of the research would be disseminated through tutorials, surveys and monographs.","title":"AF: Small: Optimization Algorithms for Multi-Armed Bandit Problems","awardID":"1117216","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[486185],"PO":["565251"]},"181581":{"abstract":"Peer-to-peer (P2P) systems are gaining popularity and importance for applications ranging from communications to content delivery over the Internet. Since such systems are inherently formed by a large collection of untrusted peers, their security and reliability can be adversely impacted by malicious peers in the system. In particular, P2P systems must provide a reliable decentralized directory service for locating peers with the desired content and services. If malicious peers are able to subvert directory lookups, the integrity of the system is greatly compromised. <br\/><br\/>This project advances the state of the art in P2P security and reliability by applying reputation information at the directory level for improved success of subsequent lookups. The new systems will use information from successful and failed lookups, as well as the structure of the peer-to-peer system, to derive reputation information for various peers and estimate the locations of malicious nodes in the system. The project will also include an investigation into mechanisms to limit Sybil attacks, in which attackers attempt to overwhelm the system with malicious peers. The mechanisms will combine the use of social network links and the structure of the P2P system to create a robust identifier space for nodes, thus constraining how many Sybils can be introduced into the system. Through a combination of such techniques, the project will make P2P systems more trustworthy and reliable, directly impacting the millions of users who already make use of such systems today.","title":"NeTS: Small: Collaborative Research: ReDS: Reputation for Directory Services in P2P Systems","awardID":"1117866","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[486502,"561003"],"PO":["564993"]},"180382":{"abstract":"Computer networks, in particular the Internet, represent critical infrastructure for business, government, military, and personal communication. Several recent trends in technology and network use have pushed the capabilities required of the Internet beyond what can be provided by the currently deployed infrastructure. This project develops a new architectural design for the Internet of the near future that represents a transformative shift to enable sustained innovation in the core of the network, using economic principles. The core idea of this new network architecture is to support choice as the central aspect of the architecture. A network built on these principles will be able to adapt to emerging solutions for current and future challenges. The network architecture designed and prototyped in this work aims to (1) encourage alternatives to allow users to choose from a range of services, (2) let users vote with their wallet to reward superior and innovative services, (3) provide the mechanisms to stay informed on available alternatives and their performances. Solutions are approached from different directions, reflecting the team?' multidisciplinary expertise in computer networking, network systems, management science, and network economics.<br\/><br\/>The broader impact of this project contributes to enhancing the functionality and usability of the next-generation Internet, which is expected to become an important piece of infrastructure. The project also integrates research and education of graduate and undergraduate students at the participating organizations, where current efforts to integrate underrepresented minorities are continued. Results from this work are disseminated in the form of an open-source prototype and publications.","title":"NeTS: Large: Collaborative Research:Network Innovation Through Choice","awardID":"1111088","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["564672","484227"],"PO":["565090"]},"184991":{"abstract":"The goal of this project is to build a distributed experimentation infrastructure spanning multiple sites in the US and Europe that is uniquely positioned to facilitate experimental research on global scale mobile services. The infrastructure would consist of cameras and touch-screen displays at different locations in New York and Madison as well as in CERTH and IBBT In Europe, allowing wireless based connectivity for its users through a layer 2 tunnel.<br\/><br\/>This project will enable research in distributed mobile services at a global scale. The research questions revolve around tradeoffs in placing computation across diverse locations around the globe and how they should be best replicated to optimize between performance latencies, bandwidth consumed and operational costs of such a service. The PIs are considering an application that they call a distributed wall where each site has a number or sensors and actuators, i.e. motion-detecting cameras and displays. A core local computational task is to quickly detect individuals and focus the cameras on them. As the number of sites grows, a key challenge for the application developers is to determine how and when to provision servers in different parts of the globe to optimize on the key experimental metrics. The proposed outcomes include better understanding of distributed deployment of global scale mobile services.<br\/><br\/>The project also has significant educational impact. The PIs will incorporate learnings from the project into the classroom through various networking and wireless communication courses at the respective universities. In addition, this project will bring students together from several countries to work together on a single project. The students will travel to the remote locations to give them exposure to research in different institutions across different countries with different research cultures and approaches to addressing networking research.","title":"EAGER: Collaborative: A Multi-Party Distributed Wall through Dispersed Sensing and Computation","awardID":"1137558","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560207"],"PO":["564993"]},"181482":{"abstract":"Graph expansion refers to the problem of partitioning a graph into two (or more) large pieces while minimizing the size of the \"interface\" between them. Graph partitions or separators are central objects of study in the theory of Markov chains, geometric embeddings, etc., and are a natural algorithmic primitive in numerous settings. Exact computation is NP-hard, so we are interested in approximate solutions. Despite much work, the status of most expansion-type problems is still open, in contrast to better-understood problems such as MAX-3SAT. In recent years it has become clearer that expansion-like problems hold the key to many of the remaining mysteries of approximation, such as the unique games conjecture or UGC (formulated by Khot when he was the PI's graduate student) and the Small-set expansion conjecture (formulated recently by Raghavendra and Steuerer, and part of Steurer's 2010 dissertation supervised by the PI). <br\/><br\/>A principal goal of this award is to apply new spectral (as in eigenvalues\/eigenvectors) ideas to study graph expansion. These ideas were introduced in the PI's recent coauthored work with Barak and Steurer on subexponential algorithms for Unique Games problem.<br\/><br\/>This award may result in transformative outcomes such as resolution of the unique games conjecture, or new algorithms for graph partitioning based upon the full spectrum (as opposed to algorithms using just the second eigenvector whose limitations are well-known).","title":"AF: Small: Expansion, Unique Games, and Efficient Algorithms","awardID":"1117309","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["549429"],"PO":["565157"]},"184881":{"abstract":"The evolutionary tree or phylogeny of a set of species is a tree that explains the history of their evolution from a common ancestor. To estimate this history, scientists make observations about species that are alive today and seek to find a tree that best fits this data. The most common types of observations these days are in the form of biomolecular sequences such as DNA or protein sequences for genes or proteins. These sequences are aligned so that corresponding positions in the given sequences exhibit as much similarity as possible. Each column of the alignment is called a site or a character. In the standard model of evolution each node in the tree has a certain state for the character and transmits this state to its children. However, the state is probabilistically mutated along each edge of the tree. The standard model also assumes that all characters evolve according to identical, independent stochastic processes. Tight bounds are known for the number of characters needed to infer the tree (and mutation probabilities on the edges) under these assumptions. The problem is that these assumptions are not biologically realistic. It is well known that selection pressure operates differently on different sites and that the evolution of one character can be dependent on other characters. Much more sophisticated mathematical analysis is needed to infer the tree and dependence structure under these conditions, and this is precisely the major goal of this project.<br\/><br\/>The problem of reconstructing evolutionary trees is of central importance in biology since evolution is the theory in biology. Computer scientists have made contributions to this field, but the solutions provided by computer scientists so far simplify the problem too much to produce reliable solutions on realistic data. This project aims to take an important step towards making tree inference algorithms more realistic.","title":"EAGER: Estimating Phylogenetic Trees when Character Evolution is neither Independent nor Identically Distributed","awardID":"1137084","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["382346"],"PO":["565251"]},"181130":{"abstract":"Peer-to-peer (P2P) systems are gaining popularity and importance for applications ranging from communications to content delivery over the Internet. Since such systems are inherently formed by a large collection of untrusted peers, their security and reliability can be adversely impacted by malicious peers in the system. In particular, P2P systems must provide a reliable decentralized directory service for locating peers with the desired content and services. If malicious peers are able to subvert directory lookups, the integrity of the system is greatly compromised. <br\/><br\/>This project advances the state of the art in P2P security and reliability by applying reputation information at the directory level for improved success of subsequent lookups. The new systems will use information from successful and failed lookups, as well as the structure of the peer-to-peer system, to derive reputation information for various peers and estimate the locations of malicious nodes in the system. The project will also include an investigation into mechanisms to limit Sybil attacks, in which attackers attempt to overwhelm the system with malicious peers. The mechanisms will combine the use of social network links and the structure of the P2P system to create a robust identifier space for nodes, thus constraining how many Sybils can be introduced into the system. Through a combination of such techniques, the project will make P2P systems more trustworthy and reliable, directly impacting the millions of users who already make use of such systems today.","title":"NeTS: Small: Collaborative Research: ReDS: Reputation for Directory Services in P2P Systems","awardID":"1115693","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["534031"],"PO":["564993"]},"181251":{"abstract":"Digital storage media failure is a common occurrence, but an understanding of the mechanisms for the failure can be elusive and have far reaching implications. This project utilizes a digital laser microscope to investigate the impact of physical and environmental manipulation of digital storage media on failure rates and data recoverability. This investigation into the physical characteristics of digital media is establishing failure thresholds and their suitability for data recovery. The results of the project are being stored in a taxonomy of digital media failure characteristics, potential data recovery techniques, and microscopic image maps of the media failures and interventions. An additional aspect of the project is an extensive outreach component, which includes the K-12 and community college environments. Further impacts of this investigation include the ability to utilize physical media manipulation as a security mechanism, as well as improve digital media reliability.","title":"TC: Small: RUI: Digital Laser Microscopy Analysis of Active, Altered, and Damaged Storage Media for Security and Digital Forensic Recovery","awardID":"1116268","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[485678,485679,"562935",485681,485682],"PO":["565327"]},"181493":{"abstract":"Developers of networked embedded systems often find it difficult to diagnose bugs. A key observation is that in such systems, it can be beneficial to exploit domain knowledge about events in the physical world to detect failures. For example, in a sensor network deployment, knowing that the received signal strength of a radio transmission will normally decrease over distance, the application developer can enforce runtime checks to detect faulty nodes based on their relative distances to the source and the orderings of their received signal strength.<br\/><br\/>Based on this intuition, this project addresses the challenge of developing correct, resilient, and reliable networked embedded systems by (i) proposing, developing, and evaluating a methodology of using physical events to detect software bugs, (ii) developing software libraries and APIs to facilitate easy access to physical event constraints by application developers, and (iii) evaluating the effectiveness of the software libraries using real-world applications. <br\/><br\/>The completed framework could significantly reduce the debugging and maintenance costs for complicated networked embedded systems, and improve their reliability. Beyond such direct social and economic benefits, the broader impacts of this work include: (i) improving curriculum with hands-on debugging sessions; (ii) raising interest in technology among high school seniors through a Pre-Collegiate Research Scholars Program; (iii) supporting talented female and under-represented minority PhD students to successfully accomplish their doctoral studies; (iv) disseminating research results through high-quality publications, high-profile tutorials, and open-source sites.","title":"CSR: Small: Collaborative Research: Autonomous Failure Detection and Recovery in Networked Embedded Systems","awardID":"1117384","effectiveDate":"2011-09-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554423","527046"],"PO":["564778"]},"173650":{"abstract":"This project will improve the communication, teaching and leadership skills of graduate students conducting research in Cyber-Physical Systems (CPS) via teaching and mentoring in 7-12 secondary education, while advancing their research through the planned inquiry-based educational activities. The graduate fellows selected from multidisciplinary engineering disciplines will partner with teachers in planning, preparing and delivering CPS related enhancements to existing science and technology course topics, hence infusing CPS related basic engineering concepts into grades 7-12. Fellows will partner with selected teachers of technology, science, and math, and will act as role models and in-class ?resource persons?, while also mentoring students in various engineering and computational aspects of Alaska relevant CPS applications and projects. The educational activities and projects will be directly related to the fellows? CPS research, such as autonomous unmanned ground and aerial vehicles for exploration and search & rescue in the Arctic, internet-based bilateral control and teleoperation systems; sensor\/actuator networks for decision support systems and for energy efficient automated buildings.<br\/><br\/>CYBER-Alaska will address this need and provide systematic mentorship for engineering education with different applications of CPS, a theme identified as the technology of 21st century and a top priority for the USA. Our project will contribute to the education and training of well-rounded graduate students in this emerging area, while also addressing the urgent technical educational needs of Alaska public teachers and students, primarily aiming for rural schools and schools with high percentage of minorities and Alaskan natives.","title":"New, GK-12: CYBER-Alaska- Training Tomorrow's Engineers in Cyber-Physical Systems (CYBER: Creating Young Brilliant Engineers and Researchers)","awardID":"1045601","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"6892","name":"CI REUSE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7477","name":"CI-TEAM"}}],"PIcoPI":["543243","493949",465927],"PO":["565272"]},"185750":{"abstract":"Web Application Frameworks, such as Google Web Toolkit (GWT) and Rails are being widely used nowadays because of numerous advantages they offer their users. A growing concern is whether such tools introduce security vulnerabilities during the translations they perform. Translation validation is an approach that allows one to verify the correctness of a translation rather than that of a translator. The input to translation validation is a source and target code (before and after translation), and the output is a set of verification conditions (VCs) that establish the semantic correctness of the translation. The VCs are automatically generated and can be charged to independent theorem provers. Translations validations had been successfully applied to optimizing compilers and to backward compatibility of microcode. <br\/><br\/>The work is a preliminary feasibility study of applying translation validation to verifying that frameworks do not introduce security vulnerabilities. The focus is GWT's translations from Java into JavaScript. The project's goal is to develop automatic tools that given a source and target code, as well as a suitably encoded list of security vulnerabilities, automatically generates VCs that, in aggregate, prove that the target does not have any of the security vulnerabilities from the list that do not exist in the source code. <br\/><br\/>A successful completion of this feasibility study will allow for the development of methodologies and tools for automatic and formal proofs that frameworks do not introduce security vulnerabilities that will be of interest to web developers as well as to industry.","title":"EAGER: From Devlopment Tools to Secure Web Applications","awardID":"1141863","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":["362818","532213"],"PO":["564388"]},"184540":{"abstract":"Are computing professionals adequately prepared for the ethical challenges that they will face in an increasingly global and interdisciplinary workplace? In this multi-institutional research\/education project, the PIs will investigate the gap between the need for ethical computing professionals and the ethical learning that occurs in graduate computing programs. They will then apply these insights to develop and disseminate best practices in graduate ethics education. The mixed-method research combines surveys, interviews, focus groups, content analysis, and experimental design, and will be conducted in partnership with ACM's SIGCAS and the IEEE's SSIT. The project will begin with an investigation of computing programs and courses at four diverse institutions: a traditional research 1 university, a rural polytechnic, an urban liberal arts college, and a leading institution for online education. What are the existing goals and strategies used in graduate computing ethics education at these sites? What ethical issues are covered? What pedagogical approaches and materials are used? Faculty and students will be surveyed and interviewed about their perspectives on computing ethics education. Observations of teaching ethics across the courses will be conducted at each institution by the project team and the evaluation team. With baseline data from these four institutions, the PIs will survey members of leading professional associations to gauge alignment between industry practice and interests and the education in ethics provided by postsecondary institutions. Finally, the PIs will refine a set of best practices and pedagogical recommendations for CS ethics education, and disseminate their findings along with examples of teaching materials designed to be applicable across a range of institutional settings. Specific research questions to be addressed include:<br\/><br\/>1. What specific ethical issues are CS instructors currently teaching and what pedagogies are currently being used in graduate-level computing courses?<br\/>a. What are the similarities and differences in computing ethics issues covered within curricula across different institutions?<br\/>b. What materials (texts, readings, videos, simulations, social media, etc.) are used in classes?<br\/>2. How can professionals? experience in the computing industry enrich teaching about ethical challenges in the workplace?<br\/>a. What do computer professionals think students should know about ethics before entering the workplace?<br\/>b. How do computer professionals think this information can best be conveyed?<br\/>3. How can computing ethics education be improved?<br\/>a. What do CS students need to learn about ethics that they are not currently learning?<br\/>b. What are the best pedagogical approaches for teaching students these ideas?<br\/><br\/>Project outcomes will include a report on the state of ethics education in graduate computer science\/technology, a report on industry needs for an ethically knowledgeable workforce, and recommendations for best practices in ethics education effective in graduate education and the workplace. The project will ultimately result in computing professionals who are more attuned to their ethical responsibilities to the public, leading to more reliable computing systems.<br\/><br\/>Broader Impacts: This work will fill an important gap in the research literature about the appropriateness and effectiveness of pedagogical approaches currently used to increase graduate computing students' awareness of ethical issues relative to the challenges that they will face in the workplace. Results of the study will be based on, and thus applicable to, a broad range of stakeholders in graduate computing ethics education, and thus could transform curricular standards promulgated by professional societies such as the ACM and IEEE. The innovative mixed-method approach that will be used has merit not only for this study but could also be applied to future studies in other domains.","title":"EESE: Collaborative Research: Understanding and Preparing Future Computer Professionals for the Ethical Complexities of a Diverse World","awardID":"1134984","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":[494865],"PO":["565227"]},"181273":{"abstract":"This project, investigating formal modeling and analysis of medical device control operations to verify patient safety, aims to advance the state-of-the-art in guaranteeing patient safety impacted by Smart Health Infrastructure (SHI). Medical devices and their networks directly interact with human physiology and often control physiological parameters. As such, any failure in medical device control systems can cause abnormal physiological conditions resulting in health hazards and patient injury. <br\/><br\/>The physiological parameters controlled by medical devices are usually governed by complex physical processes and often vary over both space and time. For example, the concentration in blood of a drug administered by an infusion pump is governed by the drug diffusion process and varies with time and distance from the site of infusion. Further, the physical processes themselves are time-variant processes, e.g. the diffusion process changes with time depending on the past history of infusion. Any formal method should characterize the time-variant processes and spatio-temporal variations to analyze the impact of the control operations in medical devices on human physiology. This renders traditional formal methods, such as hybrid automata, inapplicable for patient safety verification. The problem gets exacerbated when two or more medical devices operate simultaneously, exhibiting aggregate effects of their individual control operations. Composition of formal models for individual medical device has to characterize the aggregate effects, which themselves can vary over space and time. To address all these challenges, the PI proposes the development of Spatio-Temporal Hybrid Automata (STHA), that migrates from the conventional perspective of temporal event based state transition to a spatio-temporal perspective where state transitions are instigated over both time and space.<br\/><br\/>Broader Impacts: With the increasingly aging population and a linear increase in life expectancy the need for health-care anywhere anytime is immense. Further, the cost of health-care rises exponentially when diseases are identified at a later stage. Thus, early detection of diseases can lead to better health at a lower cost. SHIs, enabling health-care anytime anywhere, and early detection of diseases require complex medical control systems to be deployed on the human body. Unsafe operation of these medical device control systems can lead to hazards within the human body. Increasing cases of such hazards leads to decreased social acceptance of these devices. Further, it also leads to stricter compliance rules on these devices from regulatory agencies such as FDA. A methodology for providing guarantees on safety of a medical device control system will make a stronger case for their reliable operation. This will help the regulatory agencies to perform a better evaluation of the device and will lead to increased social acceptance. The PI also has a history of employing underrepresented populations, particularly women and Hispanics, at both the graduate and undergraduate levels.","title":"SHB: Small: Toward Verifying Smart-Health Infrastructure Safety from their Impact on Human Physiology","awardID":"1116385","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["535238"],"PO":["564768"]},"180195":{"abstract":"This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br\/><br\/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br\/><br\/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists \"in the loop\" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http:\/\/www.scidb.org\/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http:\/\/database.cs.brown.edu\/projects\/scidb).","title":"III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","awardID":"1110370","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["536677"],"PO":["563751"]},"184683":{"abstract":"Robotic devices are excellent candidates for delivering repetitive and intensive practice that can restore functional use of the upper limbs, even years after a stroke. Rehabilitation of the wrist and hand in particular are critical for recovery of function, since hands are the primary interface with the world. However, robotic devices that focus on hand rehabilitation are limited due to excessive cost, complexity, or limited functionality. A design and control strategy for such devices that bridges this gap is critical. The goals of the research effort are to analyze the properties and role of passive dynamics, defined by joint stiffness and damping, in the human hand and wrist during grasping and manipulation, and then mimic such properties in a wrist-hand exoskeleton for stroke rehabilitation. The project will culminate with device testing in collaboration with rehabilitation clinicians.<br\/><br\/>A significant problem in robotic rehabilitation is how to provide assisted movement to the multiple degrees of freedom of the hand in order to restore motor coordination and function, with a system that is practical for deployment in a clinical environment. Armed with a clearer understanding of the mechanisms underlying passive dynamics and control of systems exhibiting such behavior, this project will inform the design of more effective wrist\/hand rehabilitation devices that are feasible for clinical use. In addition, the proposed project will create a unique interdisciplinary environment enabling education, training, and co-advising of graduate students, undergraduate research, and significant and targeted outreach activities to underrepresented groups in science and engineering.","title":"NSF-CPS-Medium: Collaborative Research: Design and development of a cybernetic exoskeleton for hand-wrist rehabilitation through the integration of human passive properties","awardID":"1135949","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0704","name":"Division of EMERGING FRONTIERS IN RES & IN","abbr":"EFRI"},"pgm":{"id":"7633","name":"EFRI RESEARCH PROJECTS"}}],"PIcoPI":["506396"],"PO":["565239"]},"187730":{"abstract":"The field of computational biology has undergone explosive in the last decade. To understand the computational challenges facing computational biology in the next 5-8 years, the PI proposes to run a special session at the next RECOMB2012 (http:\/\/recomb2012.crg.cat\/) focused on emerging areas. RECOMB is an international scientific conference bridging the computational, mathematical and biological sciences, and is an excellent forum for disseminating the latest developments in computational biology.","title":"Recomb Special Session: Computational Challenges and Emerging Areas within Computational Biology","awardID":"1152312","effectiveDate":"2011-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["553259"],"PO":["565223"]},"186895":{"abstract":"Due to the emergence of ever increasing diversified applications provided by the smart devices such as smart phones, traditional telecommunications systems such as the wireless cellular systems no longer meet the ever exploding traffic demand, and cannot effectively deal with the shortage of available spectrum or congestion over wireless systems. On the other hand, tremendous temporal and spatial network resources, such as spectrum and computational capability, are severely under-utilized. Obviously, how to proactively harvest such residual resources and utilize them opportunistically to support diversified user traffic is an important yet challenging research direction. Although cognitive radio networks are to address this pressing issue, there is lack of viable network architecture in taking full advantage of the opportunistic spectrum access and there exist many practical design issues to be resolved. In this project, the PIs propose a flexible Cognitive Capacity Harvesting (CCH) network architecture to intelligently harvest network resources in both time and space and develop the corresponding technologies to support users' services effectively. Moreover, the CCH network along with the newly developed networking technologies can enable non-cognitive devices to significantly gain benefits from cognitive radio networks and provides innovative approaches to the cognitive radio networks design. Furthermore, this project research opens a new school of thoughts in better utilizing the residual network resources and potentially changes the design approaches for next-generation telecommunications systems. Finally, this project involves the international partners and can enhance the international components in the educational program and prepare more competitive workforce.","title":"NeTS: Collaborative Research: Cognitive Capacity Harvesting Networks","awardID":"1147851","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["560137"],"PO":["557315"]},"181087":{"abstract":"Many important computational tasks can be cast as optimization problems, where the goal is to find a solution obeying stipulated constraints that maximizes or minimizes a certain objective value. Unfortunately, most of these problems are NP-hard to solve optimally. One of the most extensively studied and successful approaches to cope with this intractability is to settle for approximation algorithms, which are efficient heuristics that find solutions with provable guarantees on quality. This approach is appealing as it does not make any assumptions about the problem instance. Further, on typical instances the algorithm could perform much better than the proven bound. Research in this subject has made huge strides, and for many problems we now have good approximation algorithms as well as strong complementary hardness results. In fact, for large classes of problems, a common frontier called ``Unique-Games hardness'' has been identified as the best approximation achievable with known techniques.<br\/><br\/>Despite all this progress, certain classes of optimization problems have eluded existing techniques and their status remains wide open. Also, the recent breakthroughs open up exciting research topics that could not be imagined before. The proposed research will identify and investigate several such frontiers where progress has been lacking, both in terms of the underlying techniques as well as the end result statements. The topics studied will include the algorithmic power of strong semidefinite programming relaxations to tackle some difficult optimization problems, constraint satisfaction style problems where a solution obeying a global property is sought, and the approximability of (near)-satisfiable instances of constraint satisfaction problems. Initial investigations into exploratory topics such as connections with parameterized complexity and the possibility of bypassing the Unique Games conjecture in some of its known consequences will also be pursued.<br\/><br\/>The proposed research will shed light on the approximability of basic optimization problems that abstract some of the core computational tasks arising in practice. The research and outreach activities will aim to foster a cross-fertilization of ideas between the approximation and constraint satisfaction communities, which have largely progressed via disparate methods with little interaction. On the education front, the project will train and mentor graduate students and provide a stimulating research environment for them. The research findings, as appropriate, will be integrated into a unified course highlighting the emerging confluence of approximation algorithms and inapproximability results.","title":"AF: Small: Some Frontiers in the Approximability of Constraint Satisfaction and Related Problems","awardID":"1115525","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[485293],"PO":["565251"]},"186785":{"abstract":"This award will help to support student attendance at the 52nd IEEE Annual Symposium on the Foundations of Computer Science (FOCS) in Palm Springs, California, on October 22 through October 25, 2011, as well as to support attendance by some qualified postdoctoral fellows who do not have other sources of travel funding. FOCS and its sister conference, the ACM STOC meeting, are the premier broad-based conferences on the Theory of Computing. FOCS has a record of strongly encouraging participation by students, for whom the conference serves as a valuable educational experience, both for the technical content of the talks and for the opportunities for networking that it provides. In recent years, the annual FOCS conference has been attended by eighty to one hundred students who have comprised more than a third of all attendees. This award will provide partial support to twenty or more students, covering shared hotel rooms and travel. (Student registration will be supported by other means.)","title":"Travel Support for IEEE Symposium on Foundations of Computer Science (FOCS 2011)","awardID":"1147364","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["517581"],"PO":["565157"]},"186444":{"abstract":"The PI proposes to investigate the numerical accuracy and robustness of randomized algorithms for matrix multiplication and overdetermined least squares problems. Existing analyses of randomized algorithms are mostly concerned with asymptotic time and space complexity in exact arithmetic, and very little is known about their numerical behavior in floating point arithmetic. The PI proposes to develop a numerical perturbation and stability theory for randomized algorithms for matrix multiplication and least squares problems. This entails the invention of new approaches and concepts to capture the numerical behavior of randomized algorithms. It is not at all clear what ``numerical stability'' means in this context, let alone how it should be defined. How does one distinguish variability caused by randomization from variability caused by finite precision? Where should parameters like failure probability, choice of probabilities, and amount of sampling be accounted for? Proposed approaches for answering these questions will include matrix perturbation analysis, probability theory, and methods on matrix manifolds. Extensive numerical experiments will be performed to corroborate the analyses.<br\/><br\/>The motivation for randomized algorithms is the need for streaming massive data sets that are too large for traditional deterministic algorithms. Randomized algorithms have been implemented successfully for applications such as pattern recognition, social network analysis, population genetics, circuit testing, and text classification. The proposed research will help to determine for which application domains a randomized algorithm is suitable, and it will also result in practical bounds and recommendations for parameter choices to achieve a user-specified accuracy. The proposed research is highly relevant because randomized algorithms will be indispensable for exascale computing, in applications like high energy physics and astronomy, where peta bytes of data are expected to stream in daily and tasks like rare event detection make it imperative to have a good understanding of numerical accuracy and robustness.","title":"EAGER: Numerical Accuracy of Randomized Algorithms for Matrix Multiplication and Least Squares","awardID":"1145383","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[500300],"PO":["565251"]},"186213":{"abstract":"This Grant for Rapid Response Research (RAPID) project will study patterns of learning, design, and repurposing in social computing by networks of activists preparing for the upcoming Tunisian elections. Tunisia's popular uprising for democracy inspired similar movements across North Africa and the Middle East. New norms of interactivity and expectations for information access are being encoded in constitutional drafts, senior public officials are imagining new ways of shaping public bureaucracy around e-government tools, and the public debate about election rules and politics candidates is booming online. Tech-savvy activists and student leaders are designing new tools and repurposing existing tools in ways unintended and unexpected by the original computer scientists and engineers. Local activists are building maps for tracking electoral fraud by means of open-source software developed by the non-profit Ushahidi organization, using microblogging platforms for vibrant forums for debate about election rules, and accessing content from Western news agencies, Al Jazeera, and citizen journalists over social networking applications. Large numbers of people with large numbers of devices on multiple digital platforms are behind these new discursive practices.<br\/><br\/>The research team was already prepared to undertake this general kind of research in Tunisia and its region, but the specific focus on the Tunisian election takes advantage of a remarkable confluence of political and technological innovations, in two stages. First, the team will expand its ability to track blog and microblog conversations about Tunisian political life, preserving as much geolocation data and link information as possible. Second, it will ethnographically investigate specific transmission acts whereby social computing strategies - understood as large numbers of people using diverse devices - are developed in one civil society group and diffused to others. <br\/><br\/>The intellectual merit of this proposal is in (1) analyzing rigorous social science data about how social computing is used during sensitive moments of political transformation, and (2) advancing our knowledge of how to relate the evolution of opinion in a vibrant blogosphere to political events on the ground. Even if democratic institutions are slow to form, there is merit in explaining how modern publics conduct constitutional conversations, arrive at preferences in political leadership, and connect online conversations with offline action. <br\/><br\/>In terms of broad impact, this RAPID project will: 1) generate real-time social science, which entails actively disseminating research findings to journalists, other researchers and foreign policy experts at the US Department of State, and 2) cultivate and mentor a network of US and Tunisian experts in the study of social computing, and 3) expand our understanding of a country that has suddenly become important to the evolution of political institutions and technology applications in the Arab world. This work will help foreign policy makers better understand the relationship between technology diffusion and political processes. In addition students are central to the team, and will gain a unique educational experience from participating.","title":"RAPID Social Computing and Political Transition in Tunisia","awardID":"1144286","effectiveDate":"2011-09-01","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[499677],"PO":["564456"]},"186334":{"abstract":"The next generation of wireless sensor networks will monitor critical infrastructure, collect vital signs from patients, and disseminate medical and planning information during emergency responses. In contrast to earlier wireless sensor networks for which best-effort services were sufficient, such systems require predictable performance and high reliability. Failure to meet these requirements may have significant adverse effects. This project aims at the development of an engineering methodology for predictable wireless sensor networks. A predictable wireless sensor network is a system for which it is possible to check that its requirements are met under reasonable assumptions regarding its workload and network properties. This project enables the development of predictable wireless sensor networks by providing developers with analytical tools to characterize and optimize the performance of sensor network systems. The intllectual merit of the project includes: (i) Statistical methods for assessing the properties of wireless sensor networks and for provisioning resources to achieve robustness in spite of node failures or temporal variations; (ii) Novel transmission scheduling techniques that ensure a system meets its reliability and real-time requirements; (iii) A new schedulability analysis that bounds network capacity and message latencies under realistic interference models; and (iv) A wireless architecture that instantiates proposed transmission scheduling techniques and the schedulability analysis. In terms of broader impacts, this project will help advance our national capability to develop performance-critical wireless systems. The PIs will teach the developed design and analytical techniques as part of wireless sensor network curriculum and share them with the research community through tutorials.","title":"NeTS:Small:Collaborative Research: Protocols and Analysis for Predictable Wireless Sensor Networks","awardID":"1144757","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564209"],"PO":["565303"]},"183089":{"abstract":"Proposal #: 11-26393 (Consortium) 11-26747<br\/>PI(s): Bastani, Farokh & Tian, Jeff<br\/> Gupta, Gopal; Huynh, Dung T.; Yen, I-Ling & Huang, LiGuo; Nair, Sukumaran<br\/>Institution: University of Texas-Dallas; & Southern Methodist University<br\/>Title: MRI Consortium\/Dev.: Instrumentation for Measuring the Dependability and Quality of Cloud Computing Systems<br\/>Project Proposed:<br\/>This project, aiming to develop instrumentation that enables rigorous experimental quality and dependability assessment of cloud computing systems, including cloud service-oriented architecture<br\/>(SOA) systems, dramatically enhances the validation capability of cloud platform services and cyberinfrastructure. Cloud platforms must meet specified service level agreements (SLA) and provide mechanisms to support the minimization of the power used in cloud data centers without adversely affecting the quality of service (QoS). Also, some safety-critical emerging cloud applications, such as health-care and transportation applications, must meet stringent dependability requirements, that include high availability, reliability, performance, resilience, safety, and security. The proposed work establishes a high performance, metrics-driven instrument enabling rigorous evaluation for the following research projects on cloud performance: <br\/>- Assurance of QoS in Service Clouds,<br\/>- Optimization of Dependability in Evolving Clouds,<br\/>- Mobile Device Power Management in Service Clouds,<br\/>- Achievement of Highly Secure Compositions in Service Clouds, and<br\/>- Testing and Validation of Secure Hardware-Software Architectures.<br\/>The work aims to develop a flexible instrument for validation and verification of cloud performance, seen to be a key element in the future of computing services. In recent years, computer services have been moving to remote virtual machines ?in the cloud.? The commercial success of this new business model is based on service quality guarantees, which are becoming increasingly hard to verify as the complexity and volume of cloud services increase. Testbeds of this type are critical to the economic and research vitality of the academic and industrial communities.<br\/>Broader Impacts: <br\/>This instrumentation substantially raises the quality, scale, and scope of experimental research in dependability enhancement methods for cloud computing systems. It helps foster a strong scientifically based experimental paradigm for computing and provides capabilities that will greatly enhance the quality of undergraduate and graduate courses in computer science and engineering, as well as senior design projects by enabling students to work on realistic platforms. The instrumentation enhances the facilities of an NSF I\/UCRC and will be available to researchers at the participating institutions and industrial partners.","title":"MRI Consortium: Development of Instrumentation for Measuring the Dependability and Quality of Cloud Computing Systems","awardID":"1126393","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":[490758,"492042",490760,"526352"],"PO":["557609"]},"185399":{"abstract":"Social network services have transformed daily lives and have influenced most aspects of society in the developed world, including politics, entertainment, sports and education. These services provide information that is both generated and consumed by their users. In some cases it has resulted in billions of dollars of commerce, but in other cases the search for a revenue stream persists. The true economic value of this information and its dissemination is neither understood today nor recognized by providers of online social network service.<br\/><br\/>This project entails a research approach combining the analysis of competitive market equilibria and their computational properties, analysis of online social networks and their communication properties, and cooperative game theory, to reach such an understanding and provide mechanisms to benefit from it. The project will also illustrate and validate the mechanisms on case studies. More specifically, the project aims to understand the impact of social influence on the Arrow-Debreu market model. The project investigates the nature of utility functions, the nature of social influence graphs, and the mix of traders in the information dissemination market. It aims to understand the effects of these on the computational complexity of market equilibria as well as the convergence of market dynamics.<br\/><br\/>This project will provide fundamental insights on the economics of social information dissemination. It will enable a better understanding of these complex systems and will provide fundamental tools for more efficient and robust designs. A successful completion of the project will not only provide theoretical and technical contributions, but will affect the design and implementation of the next generation of social networks and the information market that exists therein. The results can aid in the public understanding of such complex systems as well as inform policy debate.","title":"EAGER: Social Information Dissemination: A Market Based Approach","awardID":"1139915","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[497480,"559442","93200"],"PO":["565251"]},"177314":{"abstract":"Hypervisors and virtualization simplify application and system deployment. The many benefits of virtualization have resulted in a headlong rush into a world where virtualization is ubiquitous. However, virtualization can break assumptions that applications and operating systems make about the platform. This research investigates an important case: the intersection of virtualization and random-number generators (RNGs). Strong randomization is requisite in today's computer security tools.<br\/><br\/>Deployment of existing RNGs in virtualized settings introduces vulnerabilities. When RNGs fail, catastrophic attacks can be mounted on the the cryptographic services upon which modern information security relies. VM snapshots, which can be used to reset a VM and its contained applications, can cause RNGs to repeat outputs and break some encryption systems. Moreover, the environment presented by virtualization can degrade the quality of RNG outputs because entropy sources are virtual rather than physical hardware and hence lower quality.<br\/><br\/>This research develops the theoretical and architectural foundations for the next generation of RNG designs and RNG-using mechanisms. The investigators quantify the scope of VM-introduced vulnerabilities using dynamic and static analysis of program source code. They develop new, secure RNG systems for use in VMs. Finally, the reserearch advances cryptographic theory by extending provable security techniques to better account for the realities of RNG deployment and use in virtualized settings.<br\/><br\/>This work not only provides practical impact via stronger RNG systems but also opens up new directions in cryptographic theory in the important areas of generating and using randomness.","title":"TC: Medium: Collaborative Research: Random Number Generation and Use in Virtualized Environments","awardID":"1065288","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550227"],"PO":["565327"]},"168855":{"abstract":"Machine Learning algorithms are ubiquitous in computer science with important applications to data-mining, classification, and ranking. These algorithms are typically applied to data sets that contain a sizable fraction of noisy training examples. This project focuses on developing learning algorithms that can succeed in the presence of noisy data sets that have been corrupted in a potentially adversarial or malicious manner. Algorithms that can tolerate these types of worst-case noise are critical for the depolyment of complex machine learning systems, as real-world data sets (for example, data related to spam detection) are often noisy in unpredictable ways. Previous work on learning in the presence of noise focused on models with strong assumptions on how the noise is applied (e.g., independently for each data point).<br\/><br\/>The intellectual merit of this project lies in understanding the computational complexity of optimization problems associated with learning in worst-case noise models. More specifically, the project will design algorithms that can find a classifier whose error is competitive with the best function from a large class of concepts. In order to design these algorithms, the project will prove new structural results on how well classes of Boolean functions can be approximated with respect to a variety of well-studied probability distributions. Additionally, the project will explore hardness results for learning functions with respect to adversarial noise via reductions to notoriously difficult problems in cryptography and computational complexity.<br\/><br\/>The broader impact of this project is the potential to realize more powerful classification tools in a variety of application areas in the sciences such as computational biology (e.g., protein detection) and linguistics (e.g., text categorization). Additionally, the PI will develop a new graduate course that furthers the relationship between computational and statistical methods in machine learning theory.","title":"AF: Small: Learning in Worst-Case Noise Models","awardID":"1018829","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[451925],"PO":["565251"]},"178304":{"abstract":"Recent years have seen a remarkable growth of communication networks and computational platforms overlaid on these networks; primary examples are the Internet and the systems created and enabled by it. At the same time, it has been recognized that to properly understand and engineer such systems one needs to incorporate insights and methods from both Computer Science and Economics into their study, as these systems tend to be large, highly distributed, and owned, operated and used by thousands, or even millions, of self-interested parties. The proposed research will contribute to the growing interactions between Computer Science and Economics a new research direction motivated by a systematic study of the role of uncertainty in the structure and tractability of economic systems. Crucial in this study will be the use of concepts and tools from Statistical Physics and Probability Theory, ultimately strengthening the interaction of these fields with Algorithmic Game Theory.<br\/><br\/>Uncertainty is most certainly both present and taken into account in the study of systems of interacting individuals. A player of a game may be uncertain about her opponents'payoffs or even her own payoff, may be unable to fully observe the strategies used by the other players and the potential opportunities created by these strategies, or may even be uncertain about the exact number of opponents, the structure of the game, the order of players' moves, etc. Likewise a social planner, or mechanism designer, may have uncertainty about the values or budgets of the agents in the mechanism, the number of participants, the information that the participants have about the other participants, etc. This uncertainty is sometimes modeled by assigning probabilistic beliefs to the parameters of the system that are not fixed, and other times eliminated by obtaining worst-case guarantees.<br\/><br\/>Both harnessing uncertainty in the Bayesian way and tackling it via worst-case\/prior-free results have been central in the development of Game Theory. Nevertheless, we believe that there still remain large benefits to be obtained by a systematic treatment of uncertainty, through the import of tools from Probability Theory, Statistical Physics and Algorithms into Game Theory. We will employ these tools (1) to understand the equilibrium structure and complexity of large games of aggregative form (games with a lot of symmetries or anonymity), (2) to make progress in optimal multi-dimensional mechanism design, (3) to study dynamics in network games, (4) to understand the correlation of behaviors across large networks of interacting individuals, (5) to characterize the complexity and structural properties of equilibria in random ensembles of games, and (6) to study the Price of Anarchy in selfish routing games where the players' utilities are non-linear probabilistic functions of the delay.","title":"ICES: Small: A Probabilistic Look at Algorithmic Game Theory","awardID":"1101491","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[478035],"PO":["565251"]},"178359":{"abstract":"Dynamic environments where computational nodes or decision makers interact repeatedly over time arise in a variety of settings, such as Internet protocols, large-scale markets, social networks, and multi-processor computer architectures. In many such settings, the prescribed behavior of the nodes is simple, natural, and myopic, reflecting either the desire or necessity for computational nodes (whether humans or computers) to provide quick responses and have a limited computational burden. These \"adaptive heuristics\" can often, in the long run, move the global system in good directions and yield highly rational and sophisticated behavior, such as in game-theoretic results demonstrating the convergence of best-response or no-regret dynamics to equilibrium points. However, these positive results for adaptive heuristics in game theory are primarily based on the often unrealistic premise that nodes' actions are somehow synchronously coordinated. In many settings, where nodes can act at any time, this kind of synchrony is not available; it has long been known that asynchrony introduces substantial difficulties in distributed systems. The project draws ideas from distributed-computing theory and from game theory to investigate provable properties and possible worst-case system behavior of adaptive heuristics in asynchronous computational environments. A central thrust of project research is understanding the convergence behavior of distributed computing with adaptive heuristics. Identifying dynamics that provably converge to equilibria even in the presence of asynchrony both strengthens classic results regarding game dynamics and has implications across a wide domain of applications, including: convergence of game dynamics to pure Nash equilibria; stabilization of asynchronous circuits; and convergence to a stable routing tree of the Border Gateway Protocol, which handles Internet routing.<br\/><br\/>Project results strengthen classic results regarding game dynamics and guide the design of new protocols for routing, congestion control, and other Internet environments. The outcomes of this project include new applications of existing techniques from game theory and distributed computing and the development of new techniques that are of use to both communities. A thorough understanding of convergence behaviors of systems is both of scientific interest and has significant potential to affect real-world systems and policy decisions. With an improved understanding of the impact that assumptions about the environment and participants of a complex system have on possible global and local outcomes, policy makers, system designers, and system participants can engage in more informed discussion and make better decisions.","title":"ICES: Small: Distributed Computing with Adaptive Heuristics","awardID":"1101690","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[478168,"540234"],"PO":["565251"]},"180460":{"abstract":"In the face of the vast scale of software-intensive systems needed today, modern development environments fail dramatically, typically leading to information overload, an inability to deal with the highly dynamic nature of both the systems and the organizations that develop them, and failure to support collaboration across organizational boundaries. The overarching aim of this project is to provide a scientific foundation for human-centered environments that make large-scale and distributed project awareness, communication, and coordination as effortless as in a small team. It accomplishes this by (a) performing empirical studies of real-world large-scale high-complexity software projects to understand how task coordination occurs in and contributes to organizational context, (b) developing an underlying theory of coordination in context, which will motivate and guide (c) the design of new coordination technology that explicitly addresses information overload, dynamism, and organizational boundaries. <br\/><br\/>Intellectual merit: The research will result in four contributions: (a) a sound theoretical basis that captures how task coordination and organizational context interplay at scale; (b) theory-driven empirical studies of in-context coordination; (c) knowledge about how to achieve improvements in productivity, quality, and development speed; and (d) a suite of design principles, tool prototypes, and interaction techniques for collaboration at a very large scale. These outcomes will transform the landscape of coordination technology by squarely addressing the issue of scale, moving from coordination within a team to coordination across many developers, across many teams, and across multiple geographical and organizational boundaries.<br\/><br\/>Broader Impacts: As society enters the era of \"ultra large scale\" software-intensive systems, coordination at such scales is a major unsolved problem, persistently hampering development and advances in vital domains such as healthcare, security, defense, eGovernment, and energy. The outcomes of this project will not only provide major economic benefits, but also major societal benefits in the form of the new systems that now can be developed. Through close collaboration with industry partners, the results will quickly find their way into practice. The project will also increase involvement of women in computer science through workshops and mentoring activities.","title":"HCC: Large: Collaborative Research: Large-Scale Human-Centered Coordination Systems to Support Interdependent Tasks in Context","awardID":"1111446","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[483634,"551130"],"PO":["565342"]},"181450":{"abstract":"Verification is a bottleneck of crisis proportions in the design<br\/>of the hardware and software systems society depends on. The two<br\/>main approaches to verification are formal verification and<br\/>testing. Formal verification has the advantage that it rules out<br\/>the existence of any logical bugs that violate the properties<br\/>under consideration. Unfortunately, current formal methods are<br\/>not scalable and cannot be directly applied to entire designs. In<br\/>contrast, testing is very scalable and is therefore the method of<br\/>choice in practice. The disadvantage of testing is that it does<br\/>not rule out the existence of bugs, and bugs that escape the<br\/>testing process can lead to recalls, software crashes, and even<br\/>the loss of life. The research proposed will make testing more<br\/>effective by developing methods of test generation that reduce<br\/>the probability of missing bugs while simultaneously keeping the<br\/>number of tests generated relatively small.<br\/><br\/>The proposed research is based on the new idea that tests can be<br\/>thought of as encodings of proofs. This is a fundamentally<br\/>different way of viewing testing, which is traditionally thought<br\/>of as a method for sampling the space of all possible system<br\/>behaviors. The research will explore several potentially<br\/>tranformative directions. The first is that one can effectively<br\/>generate small and complete test sets, i.e., tests sets that rule<br\/>out the existence of bugs. Another direction is that testing<br\/>regimes can be compared by checking to see which lead to test<br\/>sets that are closest to encoding relevant proofs. A third<br\/>direction is to establish strong connections that bridge the gap<br\/>between formal verification and testing. Finally, the proposed<br\/>research will lead to the development of efficient algorithms for<br\/>test generation that will be applied to a range of important<br\/>problems arising in hardware and software verification.","title":"SHF: Small: Generation of High-Quality Tests by Treating Tests as Proof Encoding","awardID":"1117184","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550467","550468"],"PO":["565264"]},"180361":{"abstract":"This project enables measuring the value of user interfaces and the associated tasks carried out with those interfaces. In doing so it integrates the fields of Economics and Human-Computer Interaction (HCI) into a new field called Interaction Economics. By measuring value, the project quantifies the costs and benefits underlying user preference for different computer systems. The project will develop new methods that use Internet microtask labor markets to create virtual scientific laboratories, which researchers and designers can use to test new interfaces and social configurations easily, cheaply, and quickly. Designers will be able to measure the utility of their system-the quantitative degree to which users want to use it. This will allow researchers and designers to experimentally design new systems of greater complexity and novelty, with greater certainty of success. <br\/><br\/>Intellectual merit. This work will enable new economic measurements of social-computational systems. These measurements will in turn enable a new scientific understanding of these systems. This project will use these methods to answer a basic set of questions about these systems and will give other researchers the tools to answer new questions. By bringing economics to HCI and an analysis of burdens and non-monetary values to economics, the project will help both fields move forward in a way that allows them to make more impact on one of the most important phenomena of modern times, the Internet.<br\/><br\/>Broader impacts. The method of experimenting with online human behavior and measuring effects economically can be applied in many domains beyond Economics and HCI. By bringing Economics and HCI together, both in language and in methods, the project will impact a new generation of researchers in many other fields. The multidisciplinary students trained over the course of this research will serve as connectors between previously disjoint areas of inquiry. The project will provide an open-sourced website that practicing designers and researchers can use to learn the economic value of their interface designs and thus make more data-driven decisions with respect to design iteration and selection. This system will also be available for other researchers to modify and use for different online economic experiments.","title":"Interaction Economics: Instruments that Measure Social-Computational Systems","awardID":"1110965","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[483342,483343],"PO":["564456"]},"181340":{"abstract":"Non-volatile data storage devices, particularly those based upon NAND flash memory and emerging phase-change memory (PCM) technologies, are revolutionizing the way we access and manipulate information. They have many attractive features compared to magnetic hard disk drives, including their compactness, shock resistance, and faster data access. Flash memory is now preferred in portable consumer electronics, and high performance solid-state drives (SSDs) are being introduced in mobile computing, enterprise storage, data warehousing, and data-intensive computing applications. Accordingly, there is a surge in interest in the refinement, development, and expanded commercial use of these non-volatile memory technologies. On the other hand, these technologies present major challenges in the areas of device reliability, endurance, and energy efficiency. These challenges can be overcome, in part, through innovative coding and data handling techniques, which is the subject of this research project. Specifically, the problems addressed include: (1) the design of efficient, error-resilient rewriting codes for single-level cell (SLC) flash memories using write-once memory (WOM) coding techniques; (2) the design of non-binary rewriting codes for multi-level cell (MLC) flash memories, as well as codes that tolerate asymmetric cell-level transitions and writing errors; (3) the development of coding techniques that mitigate the effects of heat accumulation in PCMs; and (4) the design of error-correcting codes for PCMs with stuck cells.<br\/><br\/>The research involves the information-theoretic analysis of flash memory and PCM channel models, the development of novel coding schemes, and system performance evaluation. A unique aspect of the project is the use of the facilities of the Non-Volatile Systems Laboratory at UC San Diego, providing an experimental platform for device characterization and empirical performance comparisons of new coding techniques and architectures.","title":"CIF: Small: Coding for Non-Volatile Memories","awardID":"1116739","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["522738"],"PO":["564924"]},"180383":{"abstract":"Social science takes as axiomatic that agents act on beliefs: however, teasing out the correlations between belief and action is no simple feat. Traditionally, social scientists relied on survey data to measure sentiment that might indicate changing economic trends, and on lab experiments to test actions given manipulated beliefs. Surveys, however, are notoriously expensive to scale, difficult to conduct frequently, and possess bias; lab experiments artificially constrain decision-making and thus fail to capture the complex dependencies of real-world actions. <br\/><br\/>This project will generate measurements of public sentiment directly from the actions of people, using one of the largest datasets of human behavior ever studied: online opinions expressed on platforms like Twitter or comments posted on news websites, time series representing the volume of search queries on Google, and call detail records. Using these digital footprints, the project will develop new social-computational measures of public sentiments related to the state of the economy, expected unemployment, and concerns about national priorities. <br\/><br\/>Broader impacts: The project will offer new alternatives to surveys as a measure of public sentiment, and will also generate unprecedented insight into the online and onsite behavior of the American population. This research also has the potential to help public and private organizations better understand the dynamic behaviors of customers and constituents, and to make business and policy decisions informed by economic trends derived from data. The project will enhance education through the interdisciplinary training of graduate students. Both graduate and undergraduate students from underrepresented groups will be actively encouraged to participate in the project. A public website will also be set up detailing the project results.","title":"Collaborative Research: Using Multi-Modal Digital Footprints to Infer Public Sentiment","awardID":"1111092","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[483410],"PO":["565215"]},"184992":{"abstract":"The goal of this project is to build a distributed experimentation infrastructure spanning multiple sites in the US and Europe that is uniquely positioned to facilitate experimental research on global scale mobile services. The infrastructure would consist of cameras and touch-screen displays at different locations in New York and Madison as well as in CERTH and IBBT In Europe, allowing wireless based connectivity for its users through a layer 2 tunnel.<br\/><br\/>This project will enable research in distributed mobile services at a global scale. The research questions revolve around tradeoffs in placing computation across diverse locations around the globe and how they should be best replicated to optimize between performance latencies, bandwidth consumed and operational costs of such a service. The PIs are considering an application that they call a distributed wall where each site has a number or sensors and actuators, i.e. motion-detecting cameras and displays. A core local computational task is to quickly detect individuals and focus the cameras on them. As the number of sites grows, a key challenge for the application developers is to determine how and when to provision servers in different parts of the globe to optimize on the key experimental metrics. The proposed outcomes include better understanding of distributed deployment of global scale mobile services.<br\/><br\/>The project also has significant educational impact. The PIs will incorporate learnings from the project into the classroom through various networking and wireless communication courses at the respective universities. In addition, this project will bring students together from several countries to work together on a single project. The students will travel to the remote locations to give them exposure to research in different institutions across different countries with different research cultures and approaches to addressing networking research.","title":"EAGER: Collaborative : A Multi-Party Distributed Wall through Dispersed Sensing and Computation","awardID":"1137568","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["561994"],"PO":["564993"]},"181120":{"abstract":"This project is motivated by successful deployment of eScience applications<br\/>on clouds: how to deploy HPC analytics applications on the cloud? Both eScience applications<br\/>and HPC analytics applications manipulate with tera-scale or peta-scale data and require <br\/>access to expensive computing resources. However, HPC analytics applications bear several <br\/>distinct characteristics such as complex data access patterns and interest locality, which <br\/>pose new challenges to its adoption in clouds. <br\/><br\/>The goal of this project is to develop a data semantics <br\/>aware framework to enable HPC analytics at clouds. Such a framework is composed of three components; <br\/>1) a MapReduce API with data semantics awareness used to develop high-performance<br\/>analysis applications, 2) a translation layer equipped with data-semantics aware HPC interfaces, <br\/>and 3) a data-affinity-aware data placement scheme. It is anticipated that high productivity on the<br\/>economic impact is significantly improved through the cost-effective scientific data processing.<br\/>Delivering an open source software to the community speeds up the 21st century scientific <br\/>discovery process in any HPC analytics areas such as cosmology, astrophysics, chromodynamics, <br\/>bioinformatics, etc. Numerous educational benefits are expected to be generated from collaborative <br\/>effort with several UCF educational projects and external collaboration and community ties <br\/>through the integration into the FutureGrid, and scientific computing cloud at Department of Energy.","title":"CSR: Small: DSA-Cloud: Data Semantics Aware Clouds for High Performance Analytics","awardID":"1115665","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["464413"],"PO":["565255"]},"181494":{"abstract":"Spatial navigation is a complex cognitive process that relies on robust and adaptive mechanisms to relate current and future spatial positions to specific locations in the environment. The goal of this project is to provide a better understanding of spatial navigation by integrating information obtained from experimental studies in rats, computational models, and experiments on robots that will test new hypotheses on how these mechanisms work. <br\/><br\/>The hippocampus and medial entorhinal cortex (MEC) are major brain regions involved in mammalian spatial navigation. While the role of place cells in the hippocampus has been extensively studied, there are still many open questions on the functional role of MEC grid cells and their interaction with the hippocampal place cells. Of interest to this proposal is the recent finding that grid cells are organized in an orderly fashion along the dorso-ventral axis of the MEC, with dorsal grids being much more tightly spaced than ventral ones. The investigators hypothesize that this multiscale organization endows the navigation system with a coding mechanism that will inherently achieve robustness with respect to external perturbations such as obstacles or unexpected changes in visual cues. In order to evaluate this hypothesis the investigators will develop computational and robotic models while systematically performing experiments in rat in which the dorsal or ventral portions of MEC or hippocampus will be inactivated. They will introduce new types of mazes in which the spatial frequency of the trajectories will be controlled. This work will contribute to better spatial navigation in robotics by: (1) providing a robotic testbed to evaluate hypotheses on the role of the entorhinal cortex and (2) providing biologically plausible models for robust spatial navigation under uncertain and dynamic environments. These models will suggest alternatives to classical probabilistic methods commonly used in robot Simultaneous Localization And Mapping paradigms. This work will also contribute to studies of spatial navigation in rats by: (1) showing the usefulness of robots in providing a physical testbed beyond pure computational modeling, and (2) exploiting the shorter cycle of robot experimentation to produce maze configurations that are optimal for testing specific hypotheses in rat experiments.","title":"RI: SMALL: Collaborative Research: Investigations of the Role of Dorsal versus Ventral Place and Grid Cells during Multi-Scale Spatial Navigation in Rats and Robots","awardID":"1117388","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[486270],"PO":["564318"]},"182473":{"abstract":"This project is leveraging emerging technologies in social robotics with recent findings from social, developmental, and cognitive psychology to design, implement, and evaluate a new generation of robots that is capable of interacting with and instructing young learners (ages 3 through 6) in a truly social way. The robot incorporates signals that the mind implicitly uses to ascertain another's intentions, motivations, and affiliations (e.g., motor mimicry and synchrony, affective cues, gaze direction), making it capable of serving as a true embodiment of a human instructor. The robotic platform can be controlled remotely, through a direct and proximate connection or a remote, Internet-based operator interface. As such, the system can be placed in several different environments, ranging from a child's home to medical areas where issues of mobility or immunosuppression make it difficult for direct interaction with instructors. Research is aimed at better understanding children's concepts of robot mind and of robots as agents, uncovering mental operations behind learning new words, and adding to what is known about the added value (if any) of non-verbal utterances to understanding, communication, and collaboration.<br\/><br\/>Emerging research has identified the acquisition of early language and vocabulary skills primary predictors of later academic success. Impoverished vocabulary upon entering kindergarten strongly predicts poor subsequent academic performance. Accordingly, the use of technologies designed to build vocabulary during the preschool years is key to facilitating many types of learning. Interactions with a robotic language partner are expected to have particularly important ramifications for children with compromised opportunities to interact regularly with attentive, nurturing caregivers willing and able to foster their vital socio-intellectual developmental needs. In addition, the rationales, artifacts, and cyber platforms and infrastructure created for this project could lend themselves to a broad range of design extensions, such as providing opportunities for children who are learning English as a second language to participate in English-language-based social activities, outreach to rural areas where children have infrequent access to social activities, supporting children of deaf parents, and assessing\/assisting children with pragmatic language impairments.","title":"DIP: Collaborative Research: Social Robots as Mechanisms for Language Instruction, Interaction, and Evaluation in Pre-School Children","awardID":"1122886","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":["497073"],"PO":["562669"]},"181263":{"abstract":"The PI's goal in this project is to enable a quantum leap towards next-generation social assistive aids that enrich the lived social experiences of individuals with visual impairments. Social interaction is a central component of the human experience. The ability to communicate effectively with fellow individuals is a fundamental necessity for professional success as well as personal fulfillment. But nonverbal cues (including prosody, environment attributes, the appearance of communicators and their physical movements) account for a substantial and important part of the information conveyed during social interactions. As a consequence, the more than 1.3 million individuals in the United States (and 37 million worldwide) who are legally blind have only a limited experience of social interaction. This \"social disability\" often isolates them from their social environments. Existing assistive technologies are focused on problems such as navigation, reading text, and access to everyday appliances as well as to computers and the Internet, whereas little or no work has been devoted to real-time accessibility to social and behavioral cues. Providing real-time access to nonverbal communication cues to visually impaired users poses fundamental challenges in several related fields including affective computing, human communication engineering, behavioral modeling, machine learning, human-machine interaction, multimodal interfaces, usability engineering, multimedia computing, and assistive technology design and development<br\/><br\/>As a first step towards practical and viable social assistive solutions, the PI will focus in this project on the design and development of a social situational awareness assistive prototype for dyadic (one-on-one) interactions, with an emphasis on head\/face-based nonverbal cues. The research will be accomplished through the following specific objectives: (1) Design and development of a dyadic interpersonal mediation interface; (2) Extraction and understanding of nonverbal communication cues; (3) Visuo-haptic sensory substitution for delivering high-bandwidth socio-behavioral data; and (4) Evaluation of the social assistive prototype system in dyadic interaction scenarios representing real-world conditions. The project draws upon intellectual synergies among the team members, who are experts in human-centered multimedia computing, human-computer interfaces and machine intelligence (Panchanathan, Computer Science); assistive technology design and usability engineering (Hedgpeth, Disability Resources Center); and human communication modeling and socio-behavioral analysis (Ramirez, Human Communication). The work will build on the team's past successes in developing assistive technologies that have been designed, prototyped, deployed and tested for individuals who are visually impaired. Project outcomes will be evaluated through the Arizona State University Disability Resource Center and the Arizona Center for the Blind and Visually Impaired.<br\/><br\/>Broader Impacts: This project will pioneer the development of next-generation social assistive aids for individuals with visual impairments and thus will have a significant impact on their lives. The research to these ends will result in the advancement of computational thinking within and at the confluence of the component disciplines, namely socio-behavioral computing (through the introduction of novel methodologies for computational analysis and evaluation of human communication dynamics in general and social behavior in dyadic interactions, specifically), human-computer interfaces (through the design of novel interfaces that deliver high-bandwidth social data), machine intelligence (through the study of algorithms that elicit various levels of interaction semantics) and assistive technology\/usability (through the development and evaluation of social assistive prototypes). The concepts and technologies developed will also provide pathways to technologies for individuals with other disabilities, such as autism, dementia, and (in the most general sense) a very large portion of society. The methodologies developed will provide a wealth of data and information that will be made publicly accessible to promote and catalyze further research in the component disciplines.","title":"HCC: Small: Assistive Social Situational Awareness Aids for Individuals with Disabilities","awardID":"1116360","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["495194",485708,"528940",485710],"PO":["565227"]},"184673":{"abstract":"This project aims to develop a computational framework and a physical platform for enabling dense networks of micro-robotic swarms for medical applications. The approach relies on a new stochastic framework for design and analysis of dense networks, as well as new fabrication and characterization methods for building and understanding bacteria propelled micro-robotic swarms. This project enhances the CPS science beyond passive networks of millimeter-scale bio-implantable devices with active networks of micro-robotic swarms that could be more effective in combating various critical diseases with minimal impact on the human body.<br\/><br\/>Three major research objectives are proposed in this project: 1) Statistical physics inspired approach to the modeling and analysis of dense networks of swarms: The theory envisioned for characterizing the dynamics of dense networks of swarms aims at achieving ?beyond Turing? computation via dense networks, designing autonomous reliable communication protocols for dense networks, and estimating and controlling their performance; 2) Fabrication and steering of swarms of bacteria propelled swimming micro-robots: Large numbers of both chemotactic and magnetotactic bacteria integrated micro-robotic bodies will be fabricated using self-assembly and micro\/nano-fabrication methods. Chemotaxis and magnetotaxis will be respectively used as passive and active steering mechanisms for navigating the swarms of micro-robots in small spaces to perform specified tasks; 3) Characterization of the behavior and control of bacteria propelled micro-robotic swarms: To validate and fine tune the proposed computational models, the motion and behavior of single and large numbers of bacteria propelled micro-robots will be characterized using optical and other microscopy methods.<br\/><br\/>Intellectual Merit: <br\/>The research breakthrough proposed herein consists of building a new physical platform for micro-robotic swarms by using attached bacteria as on-board actuators and chemotaxis and magnetotaxis as passive and active steering control methods, and developing a new computational dense network framework for designing and analyzing such stochastic micro-robotic swarms. The statistical computational framework to be developed in this study will improve understanding of swarming behavior and control of large numbers of bacteria propelled micro-robots. This framework offers an integrated approach towards CPS design that is meant to operate under uncertainty conditions, yet be able to succeed in performing a specified task through self-organization and collective behavior. This bottom-top approach is meant to improve the theoretical foundations of the current computational models of CPS. <br\/><br\/>Broader Impacts: <br\/>The resulting computational framework and the physical platform could be adapted to a wide range of different stochastic dense network systems ranging from migration of cancer cell populations or dynamics of virus populations to immune system support and modeling. The proposed swarms of bacteria integrated micro-robots have potential future applications in health-care for the diagnosis of diseases and targeted drug delivery inside the stagnant or low velocity fluids of the human body or the medical diagnosis inside lab-on-a-chip microfluidic devices. Such health-care applications could improve the welfare of our society. To foster learning and training of next generation CPS workforce, the PIs plan to emphasize a cross-disciplinary approach to teaching topics that are usually offered in disjoint tracks. The PIs will integrate the CPS research activities in this study into their newly developed courses, and they will also teach one of these courses jointly. As a joint international educational activity, a three-day Summer School will be held alternately in US and Europe every year on various CPS topics related to our project. This will help building a strong international CPS community and training US and European students in CPS topics. The PIs will present the research results of this project to children, K-12 students, K-12 teachers, IEEE and ACM student members, and college students inside and outside of USA through public lectures. This project and the Sloan Foundation will support underrepresented and minority graduate students in the project. Moreover, underrepresented minority undergraduate students will be trained through the CMU ICES summer outreach program called The SURE Thing and the NSF REU program.","title":"CPS: Medium: Dense Networks of Bacteria Propelled Micro-Robotic Swarms","awardID":"1135850","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["549509","507615","554461"],"PO":["565239"]},"185894":{"abstract":"This travel grant supports USA participants to the workshop on \"Modeling, Simulation, and Visual Analysis of Large Crowds\" in November 2011 at 13th International Conference on Computer Vision. This is a multi-disciplinary workshop that addresses challenges related to visual analysis and simulation of large crowds. The workshop engages complimentary viewpoints from different areas including computer vision, computer graphics, physics-based simulation, and evacuation dynamics to develop additional insight into crowd analysis, modeling and simulation problem. This grant partially supports the travel of invited speakers and participants, especially from computer graphics, simulation, and pedestrian dynamics. The final proceedings of the workshop along with speaker slides would be made available via WWW.","title":"Travel Support for Workshop on Modeling, Simulation and Visual Analysis of Large Crowds","awardID":"1142382","effectiveDate":"2011-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["543535",498919],"PO":["564316"]},"184684":{"abstract":"The computing landscape is a richly-heterogeneous space including both fixed and mobile nodes with a large variety of sensing, actuation and computational capabilities (including mobile devices, home electronics, taxis, robotic drones, etc.). Cyber-physical applications built on these devices have the potential to gather data on, analyze, and adapt to or control a range of environments. The challenge, however, is that Cyber-Physical Systems (CPSs) are difficult to program, and even more difficult to incorporate from one deployment to another, or to dynamically manage as nodes availability changes. Thus, CPS applications are too often programmed in a brittle fashion that impedes their ability to efficiently use available compute\/sense\/actuate resources beyond a one-shot deployment. In response, this project is improving CPS design and control in four primary thrusts. First, the project is developing CPSISA, an abstraction layer or intermediate representation to facilitate CPS applications expressing their compute\/sense\/actuate requirements to lower-level mapping and management layers. Second, the project is exploring methods of providing a Device Attribute Catalog (DAC) that summarizes a region?s available CPS nodes and their capabilities. Third, this research is improving and exploiting the ability to model, predict, and control the mobility of CPS nodes. When some CPS nodes are mobile, the accuracy and performance of a CPS application fundamentally is a function of where nodes will be positioned at any moment in time. This work exploits both static statistical coverage analysis and dynamic prediction and interpolation. Fourth, using CPSISA, DAC, and other resources as input, the team is developing tools to statically or dynamically optimize mappings of CPS applications onto available resources. To test ideas in a detailed and concrete manner, two applications are being studied and deployed. First, the FireGuide application for emergency response assistance uses groups of mobile\/robotic nodes for guiding first responders in building fires. Second, a Regional Traffic Management (RTM) application demonstrates ideas at the regional level and will explore CPS scenarios for automobile traffic sensing and dynamic toll pricing. <br\/><br\/>The proposed research program has the potential for broad societal impact. Studies that improve how building emergencies are handled will improve emergency response safety both for occupants and for first responders around the country. Likewise, the deployment plans regarding regional traffic management will improve traffic patterns, fuel efficiency and quality-of-life for commuters across the United States. The research team is distributing the CPSISA, CPSMap, and CPSDyn software frameworks to allow other researchers and developers to make use of them. Extensive industry collaborations foster effective technology transfer. Finally, the project continues and broadens the PIs? prior track records for undergraduate research advising and for mentoring women students and members of under-represented minority groups.","title":"CPS: Medium: Collaborative Research: Efficient Mapping and Management of Applications onto Cyber-Physical Systems","awardID":"1135953","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[495323],"PO":["565136"]},"181186":{"abstract":"Abstract: SHB: Small: Computational Algorithms for Predictive Health Assessment<br\/>This project leverages ongoing work at Tiger Place (TP), University of Missouri (MU) in the use of sensor technology for in-home health assessment. The TP team has deployed sensor networks in the homes of seniors, with a wide range of sensor types and analysis approaches. They are integrating their sensor networks with an in-house nursing electronic health record (EHR) and investigating health context-aware computational algorithms for health and wellbeing assessments. The proposed project has the following objectives: (1) Integrate the sensor network with an EHR developed in-house to provide automatic health context for comprehensive algorithm development; (2) Investigate algorithms for identifying health patterns based on sensor data and contextual health information such as chronic conditions and medication changes that are provided by the EHR data; and (3) Investigate the possibility of predicting physiological changes such as blood pressure based on sensor data. A variety of machine learning methods are investigated for predictive health assessment. There are two potential difficulties that this research tackles: ground truth uncertainty and data unbalance. To address these problems the project is developing two new machine learning methods: a fuzzy extension of multiple instance learning and a sensor firing sequence similarity based method for recognizing pattern changes. Existing sensor data is used as a starting point to develop the proposed methods, along with simulated data for more diverse testing scenarios. The integrated combination of the sensor network and EHR is expected provide a unique, rich dataset in which to investigate health context-aware algorithms.","title":"SHB: Small: Computational Algorithms for Predictive Health Assessment","awardID":"1115956","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[485520,"561794",485522],"PO":["564768"]},"181076":{"abstract":"Descriptive Complexity measures the richness of a language or sentence needed to describe a given property. There is a profound relationship between the traditional computational complexity of a problem and the descriptive complexity of the problem. In particular, the trade-off between parallel time and amount of hardware, which is a fundamental issue in computation, has been characterized as the trade-off between formula size and number of variables. <br\/><br\/>Informed by descriptive complexity, PI will use modern SAT solvers, SMT solvers and AI planners to automatically derive efficient algorithms from high-level specifications. PI and his research group will also develop a system that uses solvers to automatically derive low-level reductions between combinatorial problems. Thus methods will be developed to automatically go from high-level specifications to efficient programs as well as to automatically derive lower bounds on how efficient such implementations can be. In using and building these systems, students and established researchers will gain knowledge on what makes problems computationally complex, and how to use state-of-the art solvers to automatically build efficient and reliable software.","title":"AF: Small: Descriptive Complexity and Inductive Synthesis","awardID":"1115448","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[485266],"PO":["565157"]},"186884":{"abstract":"Cognitive radio is a promising paradigm for dramatically increasing the utilization of wireless spectrum to support the continuing exponential growth in wireless traffic. Research on cognitive networks has mainly focused on sensing of spectrum opportunities and managing radio resources such that the primary users' quality of service is not compromised. Much less attention has been paid to the coexistence of secondary users, which may be associated with different cognitive networks and seek to operate in the same frequency bands. Effective coexistence of such users is essential for the success of future cognitive networks, and is the main objective of this project. In addition, the particularly open nature of cognitive radio raises significant new issues for the security and privacy of the transmitted data, as well as new opportunities for malicious behavior among cognitive or outside entities. The project addresses all of these issues in a holistic framework.<br\/><br\/>Coexistence requires effective allocation of radio resources in time, frequency, and space among multiple cognitive secondary users, while respecting primary interference constraints. The investigators are developing theoretical bounds for such radio resource management schemes and designing low-overhead distributed algorithms, which account for the incentives of competing secondary service providers as well as the stronger security and privacy measures needed in a cognitive environment. Information-theoretic physical-layer security techniques are being utilized to develop provably secure paradigms for secondary cognitive users and game-theoretic models are being adapted to study the robustness of these networks to various jamming attacks and other malicious behavior.","title":"Collaborative Research: Robust and Secure Cognitive Radio Networks","awardID":"1147811","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["548269"],"PO":["557315"]},"186665":{"abstract":"The workshop brings together a group of scientists with complementary expertise in health informatics, population health, and computer science to identify the research challenges and opportunities in population health data measurement, representation, and predictive modeling. <br\/><br\/>Despite great advances in measurement, computing, and communication technologies, the health data measurement relies on legacy practices (e.g., phone surveys). In contrast, billions of persons worldwide have mobile devices, such as cell phones and music players, which contain measurement sensors and are increasingly network aware. If these devices could be appropriately employed for population health data measurement, they could revolutionize the acquisition and use of population health data. However, there are many research challenges that need to be addressed in order to make widespread use of actionable population health data. <br\/><br\/>The workshop is organized around a vision of actionable data for population health. It covers a broad range of questions such as: What data should be recorded to measure everyday health? How should this data be most helpfully collected? How should the sensor data be classified into actionable data? How should the diverse sources be judged for quality? How should this data be mined and correlated? How can population data be transformed into usable knowledge? How should this data be used to develop practical health systems? How can multiple knowledge sources be integrated for multiple users? How can existing data (medical records and clinical trials) be leveraged using model-based inference to support customized decision making and refine predictive models? What is the impact of this new data on health quality and cost? <br\/><br\/>Workshop participants include experts in the areas of health informatics, knowledge representation and inference, machine learning and data mining. Thw workshop aims to increase the awareness of research challenges and opportunities in health informatics in general, and population data measurement, representation, and predictive modeling in particular, among researchers in data mining, knowledge representation and inference, machine learning, text analysis, human-computer interaction, social networks and social media, semantic web, decision theory. It also aims to make researchers in health informatics, public health, and related areas better aware of the state of the art informatics approaches that could be leveraged to develop the next generation health informatics infrastructure. The workshop results, including new research challenges and opportunities in discovery informatics, will be broadly disseminated through the workshop report, publications by workshop participants, and outreach efforts through follow-up activities that engage the research community.","title":"IIS: Workshop on Population Health Data Measurement, Representation, and Predictive Modeling.","awardID":"1146740","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[500851],"PO":["560586"]},"184124":{"abstract":"Like Miss Marple in an Agathie Christie detective novel, the brain is often faced with the task of inferring a state of the world from noisy and ambiguous clues. An important question is whether, and if so how, the brain performs such inference in a near-optimal manner. This project combines visual decision-making experiments in humans and monkeys with computational modeling and state-of-the-art population recordings in monkey to investigate this question. The project will lead to new insights into the neural code and the relation between neurons and behavior.<br\/><br\/>A task is used in which an observer classifies a briefly flashed oriented stimulus into one of two classes. The classes are defined by fixed, overlapping probability distributions over orientation. Two common forms of uncertainty play a role in this task. Noise in the sensory observation causes sensory uncertainty, but even if this noise were taken away, a given observation would be consistent with either class; this is an example of ambiguity or class uncertainty. The optimal decision strategy requires the observer to keep track of sensory uncertainty on every trial and to appropriately combine this information with knowledge of the two classes.<br\/><br\/>The first part of this project will determine whether the computational strategy taken by humans and monkeys during this task is near-optimal. The second part is concerned with whether and how sensory uncertainty is encoded on a trial-by-trial basis in monkey primary visual cortex, and subsequently used in the monkey's decision. This study will put to the test well-known theoretical frameworks for the representation of sensory uncertainty. In the third part, the propagation of sensory uncertainty information from visual cortex to a higher-level decision area, prefrontal cortex, will be examined. Taken together, this project will constitute the first comprehensive test of optimal inference at the level of cortical populations.","title":"CRCNS Research Proposal: Coding and Propagation of Uncertainty Information During Perceptual Decisions","awardID":"1132009","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["493766",493766,"560732","560732"],"PO":["564318"]},"185466":{"abstract":"This award is funded under NSF's Science, Engineering, and Education for Sustainability (SEES) activities, which aim to address the challenges of creating a sustainable world. This Research Coordination Network (RCN) sustainable energy project brings together a multidisciplinary team including U.S. academics from Arizona State University, Northeastern University, University of Michigan and Rochester Institute of Technology , together with academics from Cardiff University (U.K) and Mountains of the Moon and Makerere Universities (Uganda) as well as researchers at the U.S. Environmental Protection Agency and the US Army Corps of Engineers. <br\/><br\/>Based on concepts of strong and weak ties, the network will build ties among stakeholders for sustainable energy systems with subgroups focused on 1) innovations in energy technologies, 2) sustainability implications of manufacture, use and end-of-life at scale, and 3) energy and human development. Ties between and within groups will be developed through industrial, government and developing country residencies through which graduate students acquire tacit knowledge necessary to bridge various stages of the innovation system.<br\/><br\/>This project develops knowledge and the human capital necessary for sustainable energy systems as well as mechanisms for interdisciplinary training necessary in a variety of technical domains.","title":"RCN-SEES: Sustainable Energy Systems","awardID":"1140190","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1664","name":"Research Coordination Networks"}}],"PIcoPI":["557952","560480",497697,497698],"PO":["564728"]},"186797":{"abstract":"Computing has enabled immense innovations in many fields and social<br\/>life due to continued performance, power, and cost improvements<br\/>enabled by technology scaling. Unfortunately, two key trends threaten<br\/>performance and cost improvement of computers going into the<br\/>future. First, technology scaling is at jeopardy, leading to major<br\/>challenges in power consumption, reliability, and performance. Second,<br\/>power and energy consumption has become a key constraint, yet existing<br\/>systems are mostly designed in a one-size-fits-all way agnostic to the<br\/>needs of different applications. To overcome both problems, this<br\/>research investigates novel uses of heterogeneous technologies in<br\/>three key components of a computing system: cores, interconnect, and<br\/>memory. The approach taken is an application-driven approach that aims<br\/>to seamlessly integrate heterogeneity in the three components. Major<br\/>expected contributions of the research include: (1) an initial study<br\/>of first-principles based and application-driven design of cores, (2)<br\/>new mechanisms for enabling phase-change memory based heterogeneous<br\/>main memory, (3) exploration of tradeoffs in the design of<br\/>3-dimensional optical interconnects, (4) initial exploration of the<br\/>interaction of heterogeneous components in cores, interconnect, and<br\/>memory.<br\/><br\/>The proposed research has the potential to transform the design and<br\/>architecture of future multi-core systems, which are already a part of<br\/>the entire IT sector and our daily lives. It can enable overcoming key<br\/>challenges that impediment higher-performance and lower-power<br\/>lower-cost computing, which has traditionally enabled new applications<br\/>and discoveries. Enabling fundamentally efficient heterogeneous<br\/>multi-core systems can largely reduce energy and technology-scaling<br\/>costs of computing, and improve dependability and performance. Direct<br\/>transfer of many ideas to industry are expected through extensive<br\/>collaborations with platform and chip design industries.","title":"EAGER: Collaborative Research: Heterogeneous Cores, Memory-Hierarchy and Communication Architectures for Future CMPs","awardID":"1147406","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["518555"],"PO":["366560"]},"196136":{"abstract":"As the Internet emerges as the platform for computation, we have become increasingly reliant on cryptography to provide privacy and security in many of our day-to-day activities. We rely on cryptographic protocols to protect our credit card numbers from hackers in electronic transactions and our personal information from unauthorized access on online social networks. However, the design of many cryptosystems do not adequately account for new computational and cryptographic attacks made possible by advances in quantum computing and complex protocol interactions on the Internet. The focus of this project lies in the design and analysis of new cryptographic protocols that address these new attacks.<br\/><br\/>The research is centered around two goals: (1) to develop cryptosystems from large classes of intractability assumptions as viable alternatives to the widely-used factorization-based cryptosystems; (2) to obtain new techniques and efficient protocols secure against coordinated attacks amidst concurrent protocol executions.<br\/><br\/>This research is expected to develop ideas and techniques which hold the potential to bridge the gap between theory and practice in cryptography, and to fundamentally change the way we communicate, compute and collaborate. To ensure broader impact of this research, this project also encompasses a program of educational and outreach activities, including curriculum development (with an emphasis on new pedagogical approaches) as well as collaboration and regular exchanges with research institutions in the New York area and abroad.","title":"CAREER: Secure Public-Key Cryptography","awardID":"1237429","effectiveDate":"2011-09-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550219"],"PO":["564223"]},"186225":{"abstract":"The proposed research will advance scientific knowledge about health information dissemination and the design of appropriate social media tools for the African American female college student community. The goal of this project is to broaden access to and utilization of HIV prevention information, thereby strengthening African American organization and individual capacity to address the HIV\/AIDS epidemic in these communities. The project will achieve this goal the following aims: 1) Describe the ways in which African American female college students construct their cultural\/racial identities; 2) Identify the relationship between these identities and the use of smart health information technology and social networking systems by the target user group. <br\/><br\/>The research project will provide empirical evidence on the design and implementation of HIV\/AIDS preventive education, as well as the culturally-specific challenges related to the use of Information Computer Technology (ICT) for HIV\/AIDS preventive education. It will contribute to understanding how social networks targeting African American female college students for HIV\/AIDS prevention are received by the target community and how to improve the design of such tools for optimal effectiveness. This research will have very far-reaching implications for science and health education within and beyond the target research study community. These intellectual contributions will be of interest to scholars in communication and information studies, software engineering, pervasive mobile devices, and smart health information systems and trustworthy computing. <br\/><br\/>The project will engage college students in the Delta Sigma Theta Sorority as both users and participatory designers of social media tools intended to disseminate HIV information. The National Delta Sigma Theta Sorority, an organization with national and international programs for outreach and networking African American women in institutes of higher education, will offer a mechanism to reach additional college students beyond the physical locale of North Carolina State University - thereby providing a network penetration to other North Carolina chapters and beyond for future direction and interdisciplinary, inter-institutional collaborations. More specifically, this research is to broaden access to and utilization of HIV prevention information, thereby strengthening African American organization and individual capacity to address the epidemic in these communities using innovative smart health information technologies.","title":"EAGER: Collaborative Research: Developing a Culturally Compelling Social Network Approach to HIV\/AIDS Prevention for African American College Students","awardID":"1144340","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["523742"],"PO":["564456"]},"184168":{"abstract":"SRI International (SRI) proposes a planning effort that will lay the groundwork for a larger project to advance the field of assessment in computer science (CS) and computational thinking (CT). Planning for the Assessment of Computational Thinking (PACT) will build new partnerships focused on the development and application of a CT assessment framework in the context of a CS high school curriculum. In today's broad push to improve science, technology, engineering, and mathematics education, measurements for science and mathematics learning are much more advanced and clearly defined than for computer science and technology. Most computer scientists agree that there is a skill called computational thinking that is needed to apply computational techniques to problems and projects in a wide range of fields. Over the past decade there has been a growing focus on the concept of CT from both within and outside of CS. Despite this, CS struggles to embed its constructs in the crowded K-12 curriculum. Computational thinking has begun to find a strong footing in some high schools, however, in the form of the NSF-funded Exploring Computer Science (ECS) pre-AP curriculum. The ECS curriculum, despite its comprehensiveness and clear value to the CS and STEM communities, is not yet accompanied by a clear assessment framework or tools to measure computational thinking learning outcomes, and it provides instructors with only general guidance on how they should assess their students? computational thinking knowledge and skills. As a result, the ECS curriculum provides a relevant foundation for a planning meeting to begin developing an assessment framework for CT, as well as a clear stepping-stone for building a partnership for a Type I project focused on designing, developing and validating CT assessments that can be used with ECS and other CS curricula. In the planning stage of the project, the critical thinking of experts in computer science, computer science education, and assessment will be leveraged through a face-to-face meeting to discuss and begin designing an assessment framework for computational thinking (CT). The assessment framework and other meeting outcomes will be summarized in a white paper to be disseminated on a web site that will include an innovative component for ongoing discussion about, and revision of, the framework.","title":"Planning Grant: Planning for the Assessment of Computational Thinking (PACT)","awardID":"1132232","effectiveDate":"2011-09-15","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":["527853","558257"],"PO":["560704"]},"175346":{"abstract":"Testing is one of the most frequently performed and important activities in the work life of all programmers. Unfortunately, for critical and frequently re-used code, manual testing often requires great effort for mediocre results. This project focuses on automatically generating tests for modules with an interface that alters system state, e.g. critical modules such as file systems and data structures that are used in many safety- or economically- critical software systems.<br\/><br\/>This project improves the state-of-the-art through a novel integration of proven methods, combined with fundamental improvements to underlying testing approaches. The most efficient test methods (in terms of program paths explored per second) are used to generate very large numbers of unique paths to expose faults, while the most effective method (in terms of exploring hard-to-reach paths that reveal very difficult-to-find faults) are used to complete testing in a two-stage approach. The central idea is to resort to expensive test generation methods only when it is unlikely that cost-effective methods will succeed.<br\/><br\/>This project improves software testing education by curriculum and textbook development aimed at introducing undergraduate students to principled testing, a far-too-common omission in current CS education.<br\/><br\/>Spacecraft flight software, including file systems and data structures used in flight systems, provides early applications for this approach. Inadequate testing methods cost tens of billions of dollars each year, despite high test budgets. More effective testing will provide economic benefit and contribute (e.g., through spacecraft software or other scientific applications) to basic scientific research and exploration in other fields.","title":"CAREER: Integrating Automated Software Testing Methods","awardID":"1054876","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["517993"],"PO":["565264"]},"186236":{"abstract":"This proposal requests NSF support to broaden participation in the International Workshop on Languages and Compilers for Parallel Computing. This workshop covers all aspects of languages, compiler techniques, run-time environments, and architectures for parallel and high-performance computing.<br\/>The organizers asked for financial support in the amount of $2,500 to offset the registration fees for US-based students.","title":"The 24th International Workshop on Languages and Compilers for Parallel Computing (LCPC 2011)","awardID":"1144370","effectiveDate":"2011-09-01","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["528018",499736],"PO":["565272"]},"186137":{"abstract":"This is funding to support travel for a diverse group of US PhD students and distinguished faculty mentors to participate in an international doctoral consortium on research on recommender systems that will be co-located with the 2011 ACM Conference on Recommender Systems (ACM RecSys) in Chicago, Illinois. RecSys is a leading forum that brings together faculty, students, research staff, and industry researchers who share an interest in advancing the science of recommender systems, both in terms of the underlying algorithms that predict choices based on a variety of data (e.g., ratings, social links, context) and in terms of the human elements of the process such as eliciting ratings or presenting recommendations to users. The main goal of this Doctoral Colloquium is to help train the next generation of researchers in this area.<br\/><br\/>The 2011 RecSys Doctoral Consortium will provide a group of approximately 6 PhD students studying recommender systems with an environment in which they can share and discuss their goals, methods and results at an early stage of their research. It will take place on October 23, 2011, the first day of the conference. By participating in the doctoral consortium, students will gain feedback on their work from other students and six prominent faculty members, allowing them to enhance their own research proposal. Students will also develop a better understanding of the different research communities engaged in the study of recommender systems, and learn how to position their own work within this community. In addition, the consortium will provide students with opportunities to make new professional connections beyond their own disciplines. <br\/><br\/>Students will be recruited for the doctoral consortium through advertisement on the conference website, postings to relevant mailing lists and direct solicitation to faculty working in the area of information science and related fields. Particular attention will be placed on identifying participants from under-represented groups. To apply for the consortium, students will submit an extended abstract outlining their research goals and work to date, a curriculum vita, a paragraph describing what they expect to get from participating in the doctoral consortium, and a letter of reference from their primary advisor. Applications will be rated by the consortium chairs in terms of originality, importance of research topic, intellectual and methodological rigor, stage of work, and advisor recommendation. Priority will be given to students who have formulated their dissertation topic but are early enough in the process that they can still benefit from feedback. <br\/><br\/>Broader impacts: The RecSys doctoral consortia traditionally bring together the best of the next generation of researchers in recommender systems and related areas, allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Participation is encouraged from a broad range of relevant disciplines and approaches, thereby broadening attendees' perspectives on their topics of study and promoting advancement of the field. The organizers will try explicitly to identify and include the broadest possible group of highly qualified participants. As a consequence of these steps, the student and faculty participants will constitute a diverse group across a variety of dimensions, which will help broaden the students' horizons to the future benefit of the field and to U.S. e-commerce, which relies heavily on recommender systems.","title":"ACM Recommender Systems Conference 2011 Doctoral Symposium","awardID":"1144050","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["535295"],"PO":["564456"]},"177315":{"abstract":"The project addresses specific health challenges of patients with diabetic foot ulcers and focuses on two key challenges: automatically analyzing wound healing progress of patients with diabetic foot ulcers, and using technology to motivate these patients to better care for their wounds and their diabetes. The proposed smart phone application requires the development of image analysis algorithms and is patient-centered and aims to improve patient health and wellbeing in a patient population that is experiencing severe and expensive health problems.<br\/><br\/>In the performance of this work, the project extends the medical education of students to include how state-of-the-art computing technologies can assist healing. This research is of societal importance and provides technology-enabled care for patients with advanced problems like diabetic foot ulcers. Furthermore, it improves the quality of lives and reduces health care costs. Finally, the cross-disciplinary research team broadly disseminates results to multiple disciplines and is quite diverse. The team's diversity and the societal value of a health care application are helpful in recruiting a diverse group of students.","title":"SHB: Medium: Self-Care Management: Patient-Centered Diabetic Wound Care Using Smart Phones","awardID":"1065298","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[475364,475365,475366,475367,475368],"PO":["564768"]},"188447":{"abstract":"Abstract:<br\/><br\/>Opportunistic routing (OR) is a powerful new concept that exploits broadcast nature of wireless medium and spatial diversity of network topology to cope with time-varying wireless links in multihop wireless networks. Its potential to improve the network performance, such as network capacity, has not been well understood and there is also a lack of efficient and distributed routing protocols that fully exploit its advantage to achieve performance optimality at the end-to-end path level. <br\/><br\/>This project focuses on the theory and protocol design of OR in multihop wireless networks. The results will also be extended to incorporate other emerging wireless technologies, such as multi-rate, multi-channel, etc. There are two main thrusts in this project. The first thrust focuses on a theoretic study on the network capacity and performance bounds achievable by OR. A novel theoretical framework will be established to characterize the wireless interference, multirate capability, time-varying channel fading, and their impact on the performance of OR. A method to compute the throughput bounds between a source and destination pair in a given OR network will be devised. The second thrust is to develop distributed and efficient communication protocols. While existing OR schemes mainly focus on the link layer coordination mechanisms, the emphasis of routing protocol design in this project is on the exploit of the spatial diversity in a larger scale at path level and target to end-to-end performance optimality. <br\/><br\/>This research will advance the theoretical frontier in characterizing fundamental limits of OR in multihop wireless networks and will provide a better understanding of theoretical guidelines to the efficient OR protocol design in such networks.","title":"CAREER: Opportunistic Routing in Multihop and Multirate Wireless Networks","awardID":"1156311","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564847"],"PO":["557315"]},"178349":{"abstract":"In mechanism design, the goal is to design rules that lead to desirable outcomes even when agents behave strategically. This project focuses on a specific type of strategic behavior: a single agent can pretend to be multiple agents, and thereby participate in the mechanism more than once. One approach to address this is to design the mechanism so that this behavior is always suboptimal for the agent. Other approaches include: making it costly to obtain additional identifiers; doing some limited verification of identities; detecting false identifiers based on the social-network structure among the agents; and designing methods to sample from the agents in an unbiased way. These approaches require a blend of techniques from computer science and economics.<br\/><br\/>Internet-based mechanisms such as online rating systems and online elections, as well as mechanisms for electronic commerce, play an increasingly important role in the economy and social infrastructure. It is often easy to participate multiple times in such mechanisms, leading to distorted results and economic inefficiencies. Hence, the research under this project has the potential to make Internet-based mechanisms more meaningful and efficient.","title":"ICES: Small: Mechanism Design for Highly Anonymous Environments","awardID":"1101659","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":["556682"],"PO":["565251"]},"182771":{"abstract":"This project is awarded under the Nanoelectronics for 2020 and Beyond competition, with support by multiple Directorates and Divisions at the National Science Foundation as well as by the Nanoelectronics Research Initiative of the Semiconductor Research Corporation.<br\/><br\/>****Technical Abstract.****<br\/>Recent breakthroughs by the PI\/co-PIs on the efficient injection and transport of spin in graphene at room temperature and the design of novel magnetologic gates (MLG) and circuits enable a new paradigm for computing that utilizes the electron spin to store and process information. In this project, graphene-based MLG devices and circuits will be designed and demonstrated through a concerted interdisciplinary effort that includes experiment (materials\/devices\/circuits), theory, and circuit design and simulation. A successful implementation of the MLG will lead to high-speed, low-power information processing by enabling computing architectures that integrate logic and memory to avoid the von Neumann bottleneck which hampers performance in modern computers. The interdisciplinary team will work together to tackle the three critical challenges for developing a functional MLG circuit: (1) to understand and optimize the spin injection and transport in graphene, (2) to develop a high-speed, low-power method of switching the FM electrodes that is compatible with graphene, (3) to design and implement CMOS-compatible MLG circuits. The program will promote diversity within the US technical workforce and prepare valuable specialists for the US electronics and magnetic recording industries.<br\/><br\/>****Non-technical abstract****<br\/>As silicon electronics approaches its physical limits, there is a need to explore alternative technologies in order to develop faster computers that consume less energy. This project will develop a new paradigm for computing that exploits the magnetic poles (i.e. \"spin\") of electrons traveling inside a one-atom-thick layer of carbon known as graphene (recipient of the 2010 Nobel Prize in Physics). A long-term advantage will be to greatly accelerate computing applications that involve large amounts of data, such as database searching, data compression, and image recognition, which are important for homeland security. Technically, this will be accomplished by developing a new electronic device called a \"magnetologic gate,\" which will serve as the building block for circuits that combine the functions of microprocessors (for decision making) and hard drives (for information storage) into a single chip. The team consists of the physicists, material scientists, and electrical engineers who have pioneered the key scientific breakthroughs that enable this future technology. The program will promote diversity within the US technical workforce and prepare valuable specialists for the US electronics and magnetic recording industries.","title":"NEB: Developing a Graphene Spin Computer: Materials, Nano-Devices, Modeling, and Circuits","awardID":"1124601","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["509691",489700,"546121","545578","523455"],"PO":["559992"]},"181330":{"abstract":"This project addresses optimizing energy efficiency in the execution of parallel algorithms.<br\/><br\/>High energy cost is a salient constraint when running large scale parallel applications on the next generation of supercomputers that contain heterogeneous multicore processors and interconnections, motivating a rethinking of conventional approaches to modeling, designing and scheduling parallel tasks by taking energy-efficiency into consideration. <br\/><br\/>In this collaborative research, this team explores energy-efficient parallel task design, scheduling, and implementation and develops an power profiling tool (PowerPack) that can measure decomposed runtime power consumption of different computing components (e.g. processors, memory, networks and disks) when running large scale parallel applications.<br\/><br\/>The results of the research will be widely disseminated by maintaining an active project website, publishing peer-reviewed journal and conference papers, making the code available to other researchers, and presenting the research results in professional meetings. The availability of the research outcomes will provide ample opportunities for other researchers to further study the energy-efficiency of parallel applications. Through the collaboration of Texas State University ? San Marcos, Colorado School of Mines, and the Marquette University, PIs promote teaching, learning, and training by exposing graduate and undergraduate students to technological underpinnings in the fields of high performance computing in general and energy-efficient computing in particular. The close partnerships with a number of universities, data centers and national laboratories will also facilitate the broad dissemination of the proposed energy-efficient parallel tasks designing and scheduling techniques as well as the developed power profiling toolkits.","title":"CSR: Small: Collaborative Research: EEDAG: Exploring Energy-Efficient Parallel Tasks Generation and Scheduling for Heterogeneous Multicore Systems","awardID":"1116691","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["543606"],"PO":["551712"]},"181451":{"abstract":"Cloud computing enables flexible, dynamic outsourcing while improving cost efficiencies. These operational and economic benefits, however, are today not available to safety-critical and mission-critical real-time applications due to the lack of timeliness supports by current cloud infrastructures. Providing real-time guarantees on cloud platforms faces several novel challenges because cloud platforms are not designed for response time guarantees but to achieve elasticity and the illusion of abundant resources available on demand.<br\/><br\/>This research extends current cloud infrastructures with resource management techniques to enable real-time guarantees on the cloud. The proposed work focuses on the scheduling of data-intensive real-time applications onto cloud resources to meet their timing requirements. The project (i) proposes a formal framework for modeling and performance evaluation of real-time applications in cloud environments, with a focus on data-parallel middleware; (ii) develops algorithms for scheduling continuous streams of real-time cloud applications in an online setting; (iii) designs techniques to address issues introduced by virtualization and machine failures based on probabilistic models, hierarchical scheduling techniques, multi-mode techniques, and feedback control techniques; and (v) evaluates these techniques in the context of practical real-time applications.<br\/><br\/>The research will result in the development of a real-time variant of at least one data-parallel middleware infrastructure by enhancing existing open-source platforms. Research prototypes will be released as open source to spur the research and development of cloud computing targeting real-time applications and systems. Research concepts and tools developed in this project will be incorporated into relevant courses at Penn.","title":"CSR: Small: Resource Management for Real-time Cloud Computing","awardID":"1117185","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553656","518109","553658"],"PO":["565255"]},"181583":{"abstract":"Sensor technology has grown tremendously in the recent decades. Using micro- and nano-technologies, sensor devices nowadays can be implemented in extremely small sizes. Networks of inexpensive sensors can now be easily deployed to areas in harsh conditions to provide continuous monitoring for environmental, military, and other scientific applications. As most sensor networks are utilized in hardly accessible areas such as a wilderness or battlefield, it is very costly or even infeasible to keep periodic maintenance of individual sensors. Therefore, the average battery life of the sensors essentially determines the life of the network itself. While the processing power consumption of a sensor can be reduced through the advance of computing technology, power consumed for communications can only be conserved by reducing the net amount of transferred information. Thus, research on advanced signal processing techniques for reducing communications power is essential for next-generation sensor networks.<br\/><br\/>Distributed source coding (DSC) has been considered as the technology to drastically reduce energy consumption due to communications in sensor networks. However, current limitations of DSC prevent its adoption in sensor networks. The objective of this research is to advance the state-of-the-art of DSC for next-generation sensor networks by remodeling DSC as graphical inference problems. The resulting technologies are expected to lead to significant reduction of power consumption for communications and thus prolonged life span of such networks. To accomplish the goal, the researchers study DSC design for sources with more than two terminals, adaptive DSC algorithms for sources with dynamic varying correlation, and variational inference of DSC beyond the belief propagation (BP) algorithm.","title":"III: Small: Reformulating Distributed Source Coding using Graphical Inference for Sensor Networks","awardID":"1117886","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[486511],"PO":["564924"]},"181231":{"abstract":"Cyber-Physical Systems (CPS) tightly integrate computation and communication to control a physical system. Examples of computer-controlled systems include medical devices, airplanes, and automobiles. Such systems are too complex for the designers to completely understand their behavior in every detail. On the other hand, understanding the high-level properties of such systems is of paramount importance since most are safety-critical.<br\/><br\/>This project seeks to improve model exploration techniques for control systems in two distinct directions. First, it investigates formal languages that partially specify the properties of a system. The goal is to make those specifications more concrete, in a way that they demonstrate what are precisely the properties satisfied by the system. Second, it studies the temporal logic revision problem. Namely, if automatic analysis shows that a desired system specification cannot be satisfied, how can tools propose an alternative specification which can be satisfied and is as close as possible to the originally intended one? The research project will adopt and adapt ideas from temporal logic queries, vacuity and coverage to the CPS setting.<br\/><br\/>Expected results of the project include tools for (i) the model based exploration of control systems and (ii) the debugging of control system synthesis tools. As a result, the developed techniques will be readily available to designers of embedded control systems to help them explore and better understand their systems. Additionally, the practical and theoretical results of this research will be disseminated to undergraduate and graduate students as well as engineers in local industries through a number of advanced courses and seminars that the PI is teaching.","title":"CSR: Small: Model Exploration for Cyber-Physical Systems","awardID":"1116136","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562871"],"PO":["564778"]},"181594":{"abstract":"The PI's objective in this research is to empower children with certain kinds of disabilities so they can participate fully in initial programming environments (IPEs) that are used to teach computer science. Specifically, the PI will investigate the science and necessary tool construction to support speech-enabled adaptation of IPEs such as Scratch, Lego LabVIEW for Mindstorms, and Alice, which were originally designed for manual input with a keyboard and mouse, in order to allow children with limited use of their limbs to interact via alternative interfaces. The aforementioned IPEs traditionally rely on user interfaces involving windows, icons, and other graphical widgets, and require a mode of program input that can pose a barrier to those with upper limb motor impairments, who may lack the dexterity and mobility needed to control a mouse or keyboard with their hands. The PI's approach will be to imitate the common mouse and keyboard interactions with a voice-driven interface that is customized for each IPE. To these ends, the PI will develop a speech-aware application that runs in parallel to the IPE, listens to the voice commands from the user, interprets the commands according to a grammar influenced by the IPE concepts, and imitates appropriate actions similar to mouse and keyboard operation within the IPE. Core research questions will include how such assistive customizations can be added with automation using reverse engineering and model-driven engineering.<br\/><br\/>During the first year of the project, the PI will extended a previously developed proof-of-concept to cover the entire Scratch interface. The result will be a robust tool that enables Programming by Voice in Scratch, and which will serve as the evaluation instrument for a target group of children with disabilities. The lessons learned from the first phase of the project will drive a generalization of the steps needed to customize a speech interface for an existing application. Techniques involving screen scraping and reverse engineering, as well as model-driven engineering, will be investigated to automate the process of adapting IPEs to Programming by Voice. The resulting tools will be applied to a new IPE, the Lego LabVIEW for Mindstorms, to allow children with disabilities to program robots. The design and evaluation of the project will be performed in collaboration with United Cerebral Palsy of Birmingham, who will recruit participants into the project and provide resources for training, evaluation, and feedback on the project design.<br\/><br\/>Broader Impacts: This project unites ideas of human-computer interaction with computer science education to provide customized assistive environments for teaching computational thinking to children with disabilities (targeting grades 6-12). The work will advance our ability to automate the generation of software development environments that support Programming by Voice, resulting in advanced capabilities to enable children with upper limb motor impairments to participate fully in computer science education opportunities. The PI will involve graduate students in the research; he will supervision undergraduate Honors projects, and he will also mentor high school students from underrepresented groups with science fair projects related to this work. The results of the research will be disseminated through a project web page that will include open source software, teaching materials, video demonstrations and publications.","title":"HCC: Small: Programming by Voice: Extending Initial Programming Environments for Children with Disabilities","awardID":"1117940","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["555863",486538],"PO":["565227"]},"185961":{"abstract":"The 7th International Conference on emerging Networking EXperiments and Technologies (CoNEXT) will be held from December 6th to December 9th 2011 on the campus of the University of Tokyo in Japan. This award funds 10 US-based graduate students to attend this conference. Participation in conferences such as CoNEXT is an extremely important part of the graduate school experience as it provides students with an opportunity to interact with more senior researchers and exposes them to leading-edge research in the field. ACM CoNEXT is unique in its emphasis on interactions between networking researchers at an international level; and attending CoNEXT is an excellent opportunity for US graduate students to connect with a thriving international research community. A special student workshop will be organized in association with CoNEXT that will enable students to present and obtain feedback on their work in progress. The support from this award will enable students to attend the main conference and associated workshops at CoNEXT 2011. The travel grant chair is committed to encouraging the participation of women and under-represented minorities.<br\/><br\/>Intellectual Merit: This award provides support for graduate students to attend CoNEXT 2011 and the associated workshops, which include the student workshop, the Workshop on Internet of Things and Service Platforms, and the Special Workshop on the Internet and Disasters. This rich program will expose students to new ideas, and allow them to interact with other researchers. In particular, the student workshop is geared to provide students an opportunity to present their work in progress, receive feedback on their work, and obtain valuable experience in writing and presenting technical papers.<br\/><br\/>Broader Impact: This project integrates research and education of students through exposure to a premier technical meeting in computer networks and communications. Students will have the opportunity to observe high-quality presentations and interact with senior researchers in the field both in the main conference and the associated workshops. The proposed student participation will have a positive impact on the quality of their research. Women and other minorities will be encouraged to participate. A distinguishing feature of the CoNEXT conference is its truly international flavor which presents a tremendous opportunity to students to expand their breadth of ideas, research skills, and technical perspective.","title":"A Proposal to Support Student Travel for the ACM CoNEXT 2011 Conference","awardID":"1143049","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543600"],"PO":["565090"]},"181484":{"abstract":"Growing energy demands and environmental concerns have significantly increased the interest of academia, industry, and governments in the development of a smart electric power grid. Security is one of the key aspects of power systems. The objective of this research is to advance methods of vulnerability analysis and to develop innovative responses to maintain the integrity of power grids under complex attacks (both cyber attacks and physical failures). This research will contribute to developing robust, secure, and reliable future smart grid systems. <br\/><br\/>Unlike many of the existing efforts that focuses on abstract topological structure or load-based analysis, this project considers both network topology and intrinsic power flow characteristics to understand system behavior in complex power grid attacks. This includes single-node and multiple-node vulnerability analysis, development of new risk-aware metrics, spatial-temporal attacks with consideration of timing and location, and multifaceted attacks augmented by link failures. Knowledge of power grid system behavior under attack scenarios will allow us to develop new defense strategies. <br\/><br\/>As power and energy systems have become one of the key technology and economic development focuses across the world, this project will have far-reaching impacts at different levels. This includes enhancing national power system security, providing technical support to government agencies and policy-makers for the U.S. energy sustainability community, and student education and workforce preparation in this field. The integrative educational and outreach approaches will also provide a unique platform to encourage women and minority students to the critical Electrical\/Computer Engineering disciplines.","title":"TC: Small: Secure the Electrical Power Grid: Smart Grid versus Smart Attacks","awardID":"1117314","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["491296",486244],"PO":["565327"]},"181132":{"abstract":"Machine learning is a dynamic and rapidly growing research area that plays an important role in many applications over a diverse range of areas including scientific discovery, search technology, finance, natural language, and more. An important goal in machine learning theory is to understand which types of binary classification rules (i.e. Boolean functions) can be efficiently learned from labeled data, and which cannot. This proposal describes a detailed program of theoretical research on understanding the learnability of different types of monotone Boolean functions from uniform random examples. Monotone functions are highly natural from a learning point of view; they are also a central class of functions in computational complexity theory and the analysis of Boolean functions, and the study of their learnability has close connections to these areas.<br\/><br\/>Recent years have seen exciting advances both on efficient algorithms and on hardness results for learning monotone functions. The PI believes that building on this progress, a fine-grained understanding of the boundary between learnable and unlearnable classes of monotone functions may be within reach. More precisely, the PI will work to show that monotone DNF formulas (depth-2 circuits) are efficiently learnable, while monotone depth-3 circuits are not. Establishing this would be a landmark in our understanding of the learnability of this important class of Boolean functions.<br\/><br\/>On the positive side the PI will work on a range of intermediate problems, leading up to the goal of obtaining a poly(n)-time algorithm for learning arbitrary poly(n)-term monotone DNF formulas:<br\/><br\/>* Learning Monotone Decision Trees Better. The PI will analyze a widely used machine learning heuristic for decision tree induction and work to show that it is in fact an efficient algorithm for learning poly(n)-size monotone decision trees.<br\/><br\/>* Learning Monotone CDNF. Using results and techniques from discrete Fourier analysis of Boolean functions, the PI will work to obtain a polynomial time algorithm for monotone Boolean functions whose CNF (Conjunctive Normal Form) size and DNF (Disjunctive Normal Form) size are both polynomial in n (a broader class than poly(n)-size monotone decision trees).<br\/><br\/>* Learning Monotone DNF Formulas. The PI has developed an algorithm for learning monotone DNF formulas with a subpolynomial number of terms; using different techniques he has also given a poly(n)-time algorithm that can learn random poly(n)-size monotone DNF formulas. The PI will work to unify these two approaches to obtain a single, more powerful, algorithm for learning monotone DNF.<br\/><br\/>* Other approaches. The PI will study other approaches that may be useful for monotone function learning problems: 1) analyzing the distribution of \"Fourier weight\" in monotone functions; 2) applying specialized boosting algorithms to learn monotone functions; and 3) using conjectures in Fourier analysis of Boolean functions as tools toward learning results.<br\/><br\/>Building on his recent work, the PI will also work to establish two types of negative results for learning monotone functions: cryptographic hardness results, and lower bounds for Strong Statistical Query learning. The goal in both cases is to show that learning depth-3 monotone circuits is hard; techniques for monotone hardness amplification in complexity theory are expected to play a role in both of these directions.","title":"AF: Small: The Boundary of Learnability for Monotone Boolean Functions","awardID":"1115703","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["550576"],"PO":["565251"]},"181253":{"abstract":"Developing and maintaining software is a key challenge in computer science,<br\/>with failures costing up to one half of one percent of the US GDP each<br\/>year. Most code is retained and evolved, rather than created from scratch,<br\/>and professional software developers spend over three-fourths of their time<br\/>trying to understand existing code. Understandability and documentation<br\/>have become key components of software quality, yet they remain poorly<br\/>understood by both researchers and practitioners. In a future where the<br\/>software engineering focus shifts from implementation to design and<br\/>composition concerns, program understandability will become even more<br\/>important. This research develops tools and techniques for mechanically<br\/>generating documentation to help make programs easier to understand.<br\/><br\/>The research follows the insight that modern analysis techniques can form<br\/>rich descriptive models of programs that are both precise and succinct.<br\/>Human-readable documentation can then be synthesized from such models.<br\/>The approach applies to large programs across multiple application domains.<br\/>The research focuses on documenting how code should be used correctly, a<br\/>critical aspect in an era of components-of-the-shelf development, as well<br\/>as documenting how code has changed and evolved over time, a key<br\/>part of software maintenance. The research leverages program analysis<br\/>techniques, machine learning, and textual synthesis, with results<br\/>disseminated through academic publication; the education, training and<br\/>mentoring of students; as well as freely-available, open-source tools.","title":"SHF: Small: Synthesizing Human-Readable Documentation","awardID":"1116289","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["496766"],"PO":["564388"]},"181495":{"abstract":"Social networks (SNs), including Facebook, Twitter and LinkedIn have developed on the Internet to become a leading paradigm of online interaction. SNs have been successful in attracting users, and providing a medium where users can easily share and distribute content. Such open availability of data exposes SN users to a number of security and privacy risks. Current SN architectures adopt a simple user centric policy management approach, where a security aware user is able to specify a policy that manages access to their posted content. However, the majority of users lack appropriate information to make informed privacy decisions.<br\/><br\/>The goal of this project is to develop a comprehensive and compelling framework that leverages data mining approaches and policies composed by other community members to provide the user with appropriate information required when making policy decisions. The wisdom of the community is aggregated and summarized to assist users when making policy decisions related to user-to-user interactions, and third party applications. The principal intellectual products resulting from this project will be the development of novel policy management frameworks that focuses on both usability, and leverages data mining, recommendations and policy sharing techniques to consult the SN community to aid in enhancing users? privacy policies. <br\/><br\/>This project has a broad societal impact on new business and community models for sharing on SNs, providing mechanisms that enable users to make more informed access decisions. In addition this project will support graduate and undergraduate students, and will engage K-12 students and enhance their understanding of privacy in SNs.","title":"CSR: Small: User Centric Policy Management for Social Networks","awardID":"1117411","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[486272],"PO":["565255"]},"192385":{"abstract":"CSR proposal #0917137<br\/><br\/>CSR:Small:Collaborative Research: FastStor: Data-Mining-Based<br\/>Multilayer Prefetching for Hybrid Storage Systems<br\/><br\/><br\/>Abstract<br\/><br\/>A large number of existing parallel storage systems consist of hybrid storage components, including solid-state drives (SSD), hard disks (HDD), and tapes. Compared with high-speed storage components (e.g. SSD and HDD), tapes inevitably become an I\/O performance bottleneck. Prefetching and caching are commonly employed techniques to boost I\/O performance by increasing the data hitting rate of high-end storage components. However, prefetching in the context of hybrid storage systems is technically challenging due to an interesting dilemma: aggressive prefetching schemes can efficiently reduce I\/O latency, whereas overaggressive schemes may waste I\/O bandwidth by transferring useless data from HDDs to SSDs or from tapes to HDDs. In this research project, called FastStor, we investigate new data-mining-based multilayer prefetching techniques to improve performance of hybrid storage systems. The goals of this research are to (1) design data-mining algorithms for multilayer prefetching; (2) develop predictive parallel prefetching mechanism for SSD-based storage systems; (3) implement parallel data transfer among SSDs, HDDs, and tapes; (4) develop meta-data management schemes; and (5) implement a simulation framework named FastStor-SIM. The developed toolkit can be used to improve the I\/O performance of data centers with hybrid storage systems. The research findings of this project are published in conferences or journals for public knowledge. Through the collaboration of Auburn University, South Dakota School of Mines and Technology, and the University of Southern Mississippi, PIs promote learning and training by exposing graduate and undergraduate students to technological underpinnings in the fields of storage systems.","title":"CSR: Small: Collaborative Research: FastStor: Data-Mining-Based Multilayer Prefetching for Hybrid Storage Systems","awardID":"1212535","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["543571"],"PO":["565255"]},"181264":{"abstract":"The goal of this project is to develop new forms of programming that are more intuitive and more flexible than traditional programming models. Our new programming model is targeted towards low-level system's programming for systems like databases and operating systems where performance and reliability requirements make development particularly challenging. One of the components of our new programming model is new set of graphical notations to allow programmers to pictorially describe the behavior of their programs and automatically get implementations from these high-level drawings. The new programming technologies developed and released as part of this project could have a dramatic impact in programmer productivity, particularly for low-level systems programming. <br\/><br\/>The technology we are developing relies on new algorithms for constraint based program synthesis that allow the system to combine different forms of input ranging from high-level graphical descriptions of program behavior with more formal notations such as invariants and pre\/post conditions. The project will also explore new forms of interaction between the software synthesis engine and the programmer, allowing for a more interactive development model for complex algorithms. These new forms of interaction will be analyzed and evaluated in terms of their impact on programmer productivity through user studies and other forms of usability evaluation.","title":"SHF: Small: Human-Centered Software Synthesis","awardID":"1116362","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["508201"],"PO":["565264"]},"181385":{"abstract":"Key management in wireless networks is a very challenging problem because of the unreliable transmission medium, the lack of network infrastructure, and stringent energy and complexity limitations at terminals. Recently, there has been increased interest in exploiting physical layer dynamics to generate keys. However, existing schemes exploit only the channel dynamics in the point-to-point channel or basic small wireless systems, but not other rich dynamics inherent to multiuser wireless networks. Furthermore, current studies focus mainly on the pairwise key agreement problem, and did not address issues arising from user interactions in networks. This project develops practical key generation schemes for large scale networks, which 1) fully exploit rich opportunities inherent to network dynamics, and 2) properly address issues arising from interaction among multiple users in networks. Topics including unicast and\/or multicast key generation, oblivious relay-assisted key generation, and secret sharing among multiple users are investigated. The goal of this project is to design transmission protocols and algorithms that have engineering impact and practical feasibility. Furthermore, these protocols and algorithms are implemented and tested on a testbed. This project also has strong education components. In addition to providing thesis topics for graduate students, this project provides hands-on lab opportunities for undergraduate education on communication security.","title":"TC: Small: Collaborative Research: Exploiting Network Dynamics for Secret Key Generation","awardID":"1116932","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550133","518302"],"PO":["565327"]},"181275":{"abstract":"This project targets the theoretical foundations of the next generation of large scale distributed storage systems, which are currently undergoing explosive growth because they form a critical component of cloud computing. This growth has been driven primarily by a system-building approach, and the theory is underdeveloped and lagging behind.<br\/><br\/>This project develops the mathematical foundations as well as practical engineering constructions related to meeting the data-integrity challenges of next-generation distributed storage systems, and focuses on: (i) Energy-aware Distributed Storage Network Codes aimed at optimizing system energy tradeoffs across the dimensions of storage cost, network bandwidth, disk access cost, and encoding\/decoding complexity; (ii) Secure Distributed Storage Capacity with regard to both active and passive attacks; and (iii) Latency-minimized Distributed Storage Systems that minimize user-experienced latency through codes by exploring the complex interplay between coding and queuing delay.","title":"Small: CIF: Foundations of Next-Generation Reliable, Energy-Efficient and Secure Distributed Storage Systems","awardID":"1116404","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["521731"],"PO":["564898"]},"184674":{"abstract":"This project integrates digital microfluidics with thin-film photodetectors and control software to realize DNA target sensing using fluorescence. This cyberphysical vision is being realized through tight coupling between physical components?the microfluidic platform and miniaturized sensors, and cyber components?software for control, decision-making, and adaptation. Such a level of integration, decision, and controlled reconfigurability is a significant step forward in clinical diagnostics using digital microfluidic biochips. Topics being investigated include: (i) silicon-based digital microfluidics and integration of optical sensors; (ii) closed-loop operation and run-time optimization under software control; (iii) decision-tree architectures, adaptive reconfiguration, and error recovery. A complete testbed is being developed for nucleic acid identification on a fabricated chip with detection sites.<br\/><br\/><br\/>Cyberphysical system integration will transform biochip use, in the same way as compilers and operating systems revolutionized computing, and design automation revolutionized chip design. Benefits to society include the potential to transform personalized medicine, home diagnostics, and portable diagnostics. Integration of digital microfluidics, optical sensing, and software control has the potential to create systems that can be used by any person, regardless of sample preparation skill. One example is the identification of bacterial DNA associated with bacterial blood infection (sepsis), which results in death if not diagnosed early (this is in the top 10 causes of death in the US). Students are being trained through a Senior Design course to understand the design","title":"CPS:Medium:Hardware\/Software Co-Design for the Life Sciences: Towards a Programmable and Reconfigurable Lab-on-Chip","awardID":"1135853","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[495296,495297,"506171"],"PO":["562984"]},"184685":{"abstract":"The CrAVES project seeks to lay down intellectual foundations for credible autocoding of embedded systems, by which graphical control system specifications that satisfy given open-loop and closed-loop properties are automatically transformed into source code guaranteed to satisfy the same properties. The goal is that the correctness of these codes can be easily and independently verified by dedicated proof checking systems. During the autocoding process, the properties of control system specifications are transformed into proven assertions explicitly written in the resulting source code. Thus CrAVES aims at transforming the extensive safety and reliability analyses conducted by control system engineers, such as those based on Lyapunov theory, into rigorous, embedded analyses of the corresponding software implementations. CrAVES comes as a useful complement to current static software analysis methods, which it leverages to develop independent verification systems.<br\/><br\/>Computers and computer programs used to manage documents and spreadsheets. They now also interact with physical artifacts (airplanes, power plants, automobile brakes and robotic surgeons), to create Cyber-Physical Systems. Software means complexity and bugs - bugs which can cause real tragedy, far beyond the frozen screens we associate with system crashes on our current PCs. Software autocoding is becoming the de facto recommended practice for many safety-critical applications. CrAVES aims to evolve this towards higher standards of quality and reduced design times and costs. Rigorous, mathematical arguments supporting safety-critical functionalities are the cornerstone of CrAVES. Collaborative programs involving high-school teachers will encourage the transmission of this message to STEM education in high-schools through university programs designed for that purpose.","title":"CPS: Medium: Collaborative Research: Credible Autocoding and Verification of Embedded Software (CrAVES)","awardID":"1135955","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[495325],"PO":["565274"]},"184696":{"abstract":"In many important situations, analytically predicting the behavior of physical systems is not possible. For example, the three dimensional nature of physical systems makes it provably impossible to express closed-form analytical solutions for even the simplest systems. This has made experimentation the primary modality for designing new cyber-physical systems (CPS). Since physical prototyping and experiments are typically costly and hard to conduct, \"virtual experiments\" in the form of modeling and simulation can dramatically accelerate innovation in CPS. Unfortunately, major technical challenges often impede the effectiveness of modeling and simulation. This project develops foundations and tools for overcoming these challenges. The project focuses on robotics as an important, archetypical class of CPS, and consists of four key tasks: 1) Compiling and analyzing a benchmark suite for modeling and simulating robots, 2) Developing a meta-theory for relating cyber-physical models, as well as tools and a test bed for robot modeling and simulation, 3) Validating the research results of the project using two state-of-the-art robot platforms that incorporate novel control technologies and will require novel programming techniques to fully realize their potential 4) Developing course materials incorporating the project's research results and test bed.<br\/><br\/>With the aim of accelerating innovation in a wide range of domains including stroke rehabilitation and prosthetic limbs, the project is developing new control concepts and modeling and simulation technologies for robotics. In addition to new mathematical foundations, models, and validation methods, the project will also develop software tools and systematic methods for using them. The project trains four doctoral students; develops a new course on modeling and simulation for cyber-physical systems that balances both control and programming concepts; and includes an outreach component to the public and to minority-serving K-12 programs.","title":"CPS: Medium: Collaborative Research: A CPS Approach to Robot Design","awardID":"1136099","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[495364,495365,"532891"],"PO":["565239"]},"186511":{"abstract":"This high-risk high-reward project is concerned with the urgent need to design and deploy wireless networks that withstand time in hazardous, radioactive environments, such as a nuclear plant disaster. A hazardous, radioactive environment is particularly insidious because sensing and communication devices deployed in the environment are exposed to radioactive emissions - hence, their extraction for recharging\/repair is challenging, and their efficient operation may be seriously impacted if hardware not hardened for radiation is used, and because in this physical space non-cooperating wireless communication technologies, e.g., wireless mesh and sensor networks, need to coexist. This EAGER project explores a pathway and solutions towards achieving a significant increase in the operation time of coexisting wireless mesh and sensor networks deployed in a hazardous environment. The intellectual merit lies in a radical new approach (anchored in a new and solid Markov chain-based theoretical foundation, for achievable throughput, delay and energy efficiency) for a crosslayer design of ultra-energy efficient wireless communication protocols that employ duty cycling and network coding. The broader societal impact of the proposed research goes beyond the traditional impact of scientific research, literally affecting life and death. Results of the proposed research will be integrated with RESPOND-R, an NSF-funded instrument for emergency response research, deployable in hazardous environments throughout the US, where it could possibly save lives. This project will also offer research opportunities to graduate and undergraduate students and to underrepresented groups.","title":"EAGER: Exploratory Research into Ultra Energy Efficiency in Wireless Mesh and Sensor Networks for Hazardous Environments","awardID":"1145858","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["561708"],"PO":["565303"]},"184586":{"abstract":"This education project introduces novel science ethics coursework at the University of Houston (UH) that features three levels: theoretical, case studies, and experiential. The theoretical level identifies and explains central moral issues and principles relevant to research ethics. This is followed by dialectic investigation of famous cases in science ethics. The coursework culminates with the experiential level, an ethics practicum with an emphasis on topics of peer review, human subjects and animal experiments, which form cornerstones of modern research life. The practicum element involves student placement in participating labs or research groups, and is supported by an ever-expanding group of mentors from UH and local medical schools, as well as by conference committees and journal boards. In the introductory course the practicum lasts 2-3 weeks whereas in the advanced course students are immersed in the practicum throughout the semester; regardless of duration, concurrently with the practicum students are engaged in the classroom in a deeper philosophical investigation of relevant issues. Although it is challenging to incorporate a practicum into the field of ethics, the PI believes it is of immense value because it transforms the abstract into the concrete. A pilot version of the course offered by the PI allowed him to identify and to formulate processes for addressing major concerns relating to finding a placement for all students, the mechanics of peer review traineeship, and the mechanics of human\/animal research traineeship. <br\/>A diverse set of outreach activities complements the above, and includes the traditional (such as seminar and workshop organization and publication of a book) along with interaction via social media (e.g., blogging and Facebook), in order to engage young people in ethics discourse on an everyday basis. <br\/><br\/>Broader Impacts: The processes developed by the PI and his team in successfully implementing this challenging methodology will serve as an exemplar and be widely adopted, thereby transforming the preparation of young researchers. A minority institution (the University of Texas at Brownsville), several research labs, and a number of conferences and journals have already expressed support for this initiative and their intention to participate. This unique educational program links theoretical analysis to real ethical experiences gained via a practicum, a methodology the PI believes may prove particularly effective with blue collar student populations who have a technical orientation and a very practical view of the world. It advances \"thinking aloud\" as a strategy to help people deal with ethical drift, a ubiquitous cause of unethical behavior, by regularly soliciting feedback from friends. It advocates the use of social media on a large scale, not only as a global outreach platform, but also as a lifelong data gathering tool for evaluation purposes.","title":"EESE: Experiencing Ethics","awardID":"1135357","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":[495002,"532471",495004,"496746"],"PO":["565227"]},"187974":{"abstract":"Existing techniques for reasoning about the behavior and correctness of software running on multi-processor computers assume that each location in the shared memory always has a single, unique value as observed by the processors. But, on modern computer systems, this assumption is false---programs executing on different processors may simultaneously observe different values for some locations in memory. As a consequence, when applied to some important classes of programs, existing reasoning techniques may falsely assert that an incorrect program is in fact correct, thus potentially leading to runtime errors or even security breaches. The goal of this research project is to develop foundational theories and automatic, practical tools for program reasoning that are correct for such modern multi-processor computer systems.<br\/><br\/>The theory consists of a Hoare-style program logic, which deeply incorporates the specifics of the x86 memory model, and which can be used to give rigorous, high-level proofs of partial correctness properties of C-like, multi-threaded programs. The logic is inspired by separation logic, and embodies a x86-specific principle of local reasoning, which allows specifications and proofs to be restricted to just those resources used at runtime, instead of the global system state. The project additionally includes program checkers based on this logic, for automatically constructing proofs of partially-specified programs. Using these tools, the project intends to target, in particular, concurrent data structures: concurrent, and typically race-prone implementations of traditional sequential data structures, which carefully omit locks and other synchronization instructions to maximize concurrent throughput.","title":"EAGER:Theories and Tools for Safe Concurrent Data Structures","awardID":"1153558","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[503869],"PO":["565264"]},"186303":{"abstract":"This project is providing support for travel and registration for U.S. participants in a key global venue for research and training in the learning sciences via the Doctoral Consortium and Early Career Workshops at the Computer-Supported Collaborative Learning (CSCL) 2011 conference in Hong Kong. Prior versions of these workshops have had a significant impact on the career and research of pre- and post-PhD scholars in the learning sciences from diverse domains such as computer science, information science, education, psychology, and cognitive science. The intellectual merit of this project rests in its selection of top-quality pre- and post-doctoral candidates whose research in computer-supported collaborative learning addresses the conference theme of connecting theory and practice in the learning sciences. Their participation in the conference provides opportunities to improve the dissertations of approximately twenty graduate students and the research agendas of approximately twenty early career, post-doctoral scholars. As such it is an important capacity-building project that leverages the expertise of the CSCL community and the outcomes of previous workshops held with the International Conference of the Learning Sciences (ICLS). The broader impacts of this project include multiplying opportunities to develop international collaborations in the field of CSCL, and supporting the career development of some of the best and brightest researchers in multiple disciplines who work in the CSCL area.","title":"Training the next generation of learning scientists: CSCL 2011 workshop support","awardID":"1144590","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":["549180"],"PO":["560894"]},"184015":{"abstract":"Functional magnetic resonance imaging (fMRI) has become the most common tool for cognitive neuroscience, because it provides a safe, non-invasive, and powerful means to image human brain function. Based on recent rates of publication, there are currently more than 2000 fMRI studies being performed every year worldwide. The aggregation of data across multiple studies can provide the ability to answer questions that cannot be answered based on a single study. For example, using datasets from multiple domains one can start to investigate to what degree a region is selectively engaged in relation to a particular mental process, as opposed to being generally engaged across a broad range of tasks and processes. In addition, it provides the ability to integrate across specific tasks to obtain stronger empirical generalizations about mind-brain relationships, and to better understand the nature of individual variability across different measures. Recent work in neuroimaging analysis has focused on the application of methods such as machine learning techniques to understand the coding of information at the macroscopic level, and network analysis techniques to understand the interactions inherent in large-scale neural systems. The availability of a large testbed of high-quality fMRI data from published studies would also provide an important resource for the development of these and other new analytic techniques for fMRI data. However, sharing of raw fMRI data is challenging due to the large size of the datasets and the complexity of the associated metadata, and there is currently no infrastructure for the open sharing of new fMRI datasets.<br\/><br\/>This project, OpenfMRI, will provide a new infrastructure for the broad dissemination of raw data within cognitive neuroscience, addressing a critical need by providing an open data sharing resource for neuroimaging. The initial project is already online at http:\/\/www.openfmri.org with a limited number of datasets. The full project will greatly expand this repository by providing access to a large number of fMRI datasets from several prominent neuroimaging labs, spanning across a broad range of cognitive domains. Utilizing the substantial computational resources of the Texas Advanced Computing Center, the project will also perform standard fMRI analyses on all data in the repository using a common analysis pipeline, thus providing directly comparable analysis results for all of the studies in the database. The OpenfMRI project will support the development of infrastructural elements to make sharing of data by additional investigators more straightforward.<br\/><br\/>The repository of data that will be created by the OpenfMRI project will also serve as an important resource for teaching by providing students with the ability to replicate the analyses from published studies using the same data. By providing any researcher in the world with the ability to acquire large fMRI datasets, it will also provide all researchers with the ability to work with the same state-of-the-art datasets, regardless of institution. By creating the infrastructure for open sharing of research data, the project will also enhance the impact of other NSF-funded neuroimaging research projects by providing an infrastructure that can be used to make their data available. The planned work has the potential to benefit society by improving education, health, and human productivity through an increased understanding of mental function and its relationship to brain function.","title":"CRCNS Data Sharing: An open data repository for cognitive neuroscience: The OpenfMRI Project","awardID":"1131291","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[493483],"PO":["565292"]},"175314":{"abstract":"The objective of this project is to develop algorithms that can predict future events, in the context of a data stream containing multiple correlated threads with many types of patterns. The domain chosen to explore this research is music. Music is richly patterned, with long-term dependencies, dependencies across time-scales, and correlations between parallel information streams. This makes it an ideal domain for advancing predictive modeling in information streams. When a person is listening to a song, the listener is anticipating, at any given moment, the timing and nature of the next event by decoding the musical signal. Even when analyzing a simple song, the brain utilizes complex correlations between the musical elements to make accurate predictions. <br\/><br\/>The research will examine the following specific questions: (1) Can prediction be improved by using ensemble methods, such as mixtures-of-experts and product-of-experts, in which the predictions of multiple models are merged? (2) Can novel Probabilistic Graphical Models (PGMs) improve upon standard approaches, such as Hidden Markov Models (HMMs), for predicting events in a musical signal? (3) Can computational predictive models provide testable cognitive hypotheses that help explain how humans form mental schemas of music? A primary education goal of this proposal is to create a series of interactive online learning modules, dealing with the synthesis, analysis, perception, and manipulation of musical sound, in order to investigate how music can be incorporated into core curricula to inspire greater interest in math, physics, and computer science and to teach core STEM concepts to at-risk youth.","title":"RI: CAREER: Predictive Models of Music","awardID":"1054659","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[470115],"PO":["565035"]},"186369":{"abstract":"Similar yet visually non-identical objects form recurring patterns that are ubiquitous in the world we live in. Thus an automatic recurring pattern detection algorithm can serve as a stepping stone towards robust higher level machine intelligence. The recognition of such recurring patterns is especially relevant for computer vision since it can lead to saliency detection, image segmentation, image compression and super-resolution, image retrieval and semantically meaningful organization of unlabeled data. This project explores automatic recurring pattern discovery from domain independent images and videos to capture, robustly and flexibly, varying mid-level visual cues emerging from any cluttered background. The work leads to effective and efficient object discovery and scene interpretation. The research team develops an un-supervised method for discovering recurring patterns in a single or multiple images . The key property is the nature of recurring without knowing what recurs. Differing from previous feature- or object-level pairwise-matching-based approaches, recurring pattern discovery from real images is formulated as a joint, 2-dimensional feature assignment optimization problem where multiple objects and multiple feature clusters are considered simultaneously. <br\/><br\/>The project disseminates the results through publications and sharing data with other researchers. The research of this project contributes to the understanding and capturing of recurring patterns in higher spatial dimensions and spatiotemporal domains. Besides computer vision and computer graphics, many other research fields can also benefit from this research.","title":"EAGER: Recurring Pattern Discovery","awardID":"1144938","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["531866"],"PO":["564316"]},"185159":{"abstract":"The Georgia Institute of Technology proposes a project to engage and retain African-Americans in computing using music composition for the contextualization of computing practices. African-American participation in computing is relatively low compared to other ethnic groups. Recent research has shown that the relationship between computer games, once thought a \"silver bullet\" for CS education, and an eventual interest in computer science is not as strong as many have assumed, especially for African Americans; therefore, there is a need for more culturally-motivated approaches. Currently existing approaches for directly motivating African Americans in CS address pre-computational topics or are used for recruiting students into high school programs; however, there are no current approaches in addressing culturally motivated core CS topics for high school students. This project represents one such approach: the development of an audio composition environment, called EarSketch, which enables students to create computational remixes (i.e. musical compositions that are comprised of code snippets that manipulate small musical samples and beats). This approach with its focus on hip hop remixes may (a) sidestep the cultural issues that computer games have had in the engagement of minorities and therefore be more successful in engaging these constituencies; (b) make computational music more accessible to those without classical training by operating on the more accessible hierarchical level of \"loops\" and \"beats\" as opposed to the finer-grained note and event level of classical Western composition; and (c) allow students to create culturally relevant artifacts that have a deep meaning to them. The EarSketch curriculum will be initially deployed in summer workshops for high school students with a final piloting in a high school CS course at Lanier High School. Students will learn how to remix music in digital audio workstation (DAW) software and how to write code to algorithmically generate remixes within this environment, approaching remixing from the perspective of computing concepts aligned with the CS: Principles national curriculum (e.g. creating computational artifacts, using abstractions and models, and working effectively in teams). EarSketch is designed to motivate students to learn and apply computational concepts in order to achieve musical goals such as the creation of additive, repetitive, and varying textural constructs. The curriculum also borrows from ideas of pair programming and leverages social media as a means of sharing and collaborating while adding the unique feature of students creatively reusing and remixing each other?s works, as is done with musical remixes. An EarSketch social media sharing site will enable students to share their creative works and remix other?s work, by reusing, altering, and augmenting code, samples, and beats.","title":"Type I: Engaging African Americans in Computing through the Collaborative Creation of Musical Remixes","awardID":"1138469","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":["550870",496811],"PO":["561855"]},"186017":{"abstract":"Parallel and Distributed Computing (PDC) now permeates most computing activities. The penetration of this technology in the daily lives has resulted in common users relying on its effectiveness and reliability. The mass marketing of multicores and general-purpose graphics processing units in home and office PCs and laptops has a potential for empowering even common users to become a technology contributor. Certainly, it is no longer sufficient for even basic programmers to acquire only the conventional programming skills. All this phenomena point to the need for imparting a broad-based skill set in parallel and distributed computing t various levels, impacting Computer Science (CS) and Computer Engineering (CE) programs and related computational disciplines. However, the rapid change in computing hardware platforms and devices, languages, and supporting programming environments, and the research advances, more than ever challenges the educators what to teach in any given semester. Students and their employer face similar challenges on what constitutes basic expertise. The proposed activity includes all stakeholder experts working together and periodically providing guidance on restructuring standard curriculum across various courses and modules related to parallel and distributed computing. Immediate benefit would be for CS\/CE students and their instructors with periodic guidelines on what aspects to cover in what courses.<br\/>The PI plans to revise the preliminary version of the curriculum, and to hold a second round of competition for Fall-11 for early adopter status, supported by NSF and Intel. It is planned to have early adopter status competitions for Spring-12 and for Fall-12. EduPar-12 workshop to be organized at IPDPS-12 in Shanghai in May 2012, with expanded scope.","title":"Toward Parallel and Distributed Computing into Core Curriculum of CS\/CE Undergraduates","awardID":"1143533","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"K155","name":"National Security Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526127"],"PO":["565136"]},"186138":{"abstract":"Broadly defined, entrepreneurship is the discovery, evaluation, and exploitation of profitable opportunities. In the context of NSF-funded science and engineering research, entrepreneurship can range from a graduate student starting a new company based on knowledge gained through an NSF-funded graduate research fellowship program to researchers licensing a new technology developed through an NSF-funded center. This project focuses on identifying examples of entrepreneurship in NSF-funded science and engineering research, which will help better document the economic impact of NSF-funded research (e.g., new companies started, technology licensed) as well as better understand the conditions under which scientific discovery results in entrepreneurship. <br\/>This project will survey the landscape of entrepreneurial activities engaged in by NSF-funded research projects (year 1) and conduct qualitative interviews with a representative sample of these projects (year 2). The research aims to broaden, beyond patents, the ways in which the economic impact of NSF-funded research is measured. These measures include new companies that are started based on the research, hardware and software developed during the research that are incorporated into commercial products, and technology originating from the research that is licensed to a company. <br\/>In addition to furthering the scientific understanding of entrepreneurship, a potentially transformative outcome of this research is discovering ways that NSF could better support entrepreneurship, thus increasing the potential for economic impact from science and engineering research. Furthermore, identifying practices that successful investigators use could boost entrepreneurship among researchers in an increasingly knowledge-intensive economy, as the US looks for new ways to foster start-up companies and create jobs.","title":"EAGER: What is the Economic Impact of NSF-Funded Research? Connecting the Dots Between Scientific Discovery and Entrepreneurship","awardID":"1144054","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[499499],"PO":["565136"]},"177239":{"abstract":"Mobile handheld devices such as smartphones, PDAs, and smart media players have outpaced the growth of wired hosts, and are emerging as the predominant vehicle for Internet access. In recent years, newer mobile phones, including various versions from Apple, Google, Nokia, and others, have promoted greater programmability, radically changing the age-old model of mobile phones being a closed platform. However, openness arrives with new challenges of trustworthiness. The goal of this project is to improve the trustworthiness of mobile phones in their daily operations, by analyzing threats that occur either due to malware or due to regular applications, designing mitigation strategies, and evaluating developed solutions through a real deployment on a smartphone platform (Google Android) and operating in a real network (Sprint-Nextel).<br\/><br\/>This project will undertake crosscutting research, educational, and outreach plan to improve the robustness, reliability, security, privacy, and overall trustworthiness of mobile phones. The primary focus of this project will be on performance and security threats that are unique to mobile phones, including malicious applications that ex-filtrate data, performance loss due to resource constraints, privacy threats of lost devices, and remote network-based attacks. Specifically, this project will investigate issues related to following topics: (i) performance instability due to resource constraints (ii) protection against malicious applications (iii) privacy against lost phones (iv) detection and prevention against other network attacks. Techniques developed will have broad benefits to research and society. These techniques will enhance the trustworthiness of mobile phones, thereby improving the confidence of users in using these devices in their daily activities. An educational plan will introduce new curriculum centered on the mobile phone platform and establishes a new undergraduate laboratory for hands-on mobile device programming.","title":"TC: Medium: Collaborative Research: Building Trustworthy Applications for Mobile Devices","awardID":"1064900","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521556"],"PO":["564388"]},"182871":{"abstract":"An interdisciplinary team of computer scientists, statisticians, and ornithologists will develop novel computer science methods and apply them to the challenge of understanding the annual migration of birds across North America, which is one of the most complex and dynamic natural phenomena on the planet. While direct observation of migrating birds is limited to a handful of birds wearing tracking devices, other sources of data provide partial information about migration that, when appropriately combined, will provide insight into migration at a scale previously unimaginable. These sources include a continent-wide network of volunteer bird watchers, night flight calls captured by a network of acoustic monitoring stations, continent-scale weather patterns gathered by a network of weather stations, and clouds of migrating birds detected at night by WSR-88D weather radar stations. To analyze these data, the team will develop two innovative machine learning techniques-Collective Graphical Models (CGMs) and Semi-Parametric Latent Process Models (SLPMs). The resulting model will be able to identify the complex conditions governing the dynamics of migration behavior including the choice of migratory pathways, the factors that influence when birds migrate, and the speed and duration of each night's movements. CGMs greatly extend the scope of phenomena that can be captured with graphical models. Under suitable conditions, a CGM is able to recover a model of the behavior of individuals using only collective observations.<br\/><br\/>For BirdCast, it will construct a model of individual bird dynamics from the collective observations provided by birders, acoustic and weather stations, and weather radar. Once the model is constructed, it will be applied to live data feeds (bird sightings, acoustic detections, radar detections, and weather forecasts) to predict bird migration in real time. SLPMs are an extension of latent process models, such as the CGM for bird migration, in which the dynamics of a process is represented by latent variables that are observed only indirectly. In an SLPM, the conditional probability distribution of each variable is modeled using flexible, non-parametric methods from machine learning, such as boosted regression trees. Introducing such flexible methods such as CGMs and SLPMs into latent variable models raises difficult challenges for model fitting and validation. Preventing over-fitting will require the creation of novel information regularization and latent model cross-validation methods to enforce latent variable semantics.<br\/><br\/>The proposed work will allow, for the first time, real-time predictions of bird migrations: when they migrate, where they migrate, and how far they will be flying. Accurate models of migration have broad application for basic research by allowing researchers to understand behavioral aspects of migration, how migration timing and pathways respond to variation in climatic conditions, and whether linkages exist between annual variation in migration timing and subsequent inter-annual changes in population size.<br\/><br\/>BirdCast will expand opportunities for the public to participate in the gathering of data and its analysis. The existing data set has more than 60 million observations, and the size is growing exponentially. Last year, volunteers contributed more than 1.3 million hours observing birds. Student engagement in the research is significant as well.","title":"Collaborative Research: CDI-Type II: BirdCast: Novel Machine Learning Methods for Understanding Continent-Scale Bird Migration","awardID":"1125228","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["554550"],"PO":["565136"]},"180451":{"abstract":"This collaborative research project leverages expertise of four research teams (IIS-1111415, Massachusetts Institute of Technology; IIS-1110955, Harvard University; IIS-1111398, Washington University; and IIS-1111534, Cornell University). Understanding time-varying processes and phenomena is fundamental to science and engineering. Due to tremendous progress in digital photography, images and videos (including images from webcams, time- lapse photography captured by scientists, surveillance videos, and Internet photo collections) are becoming an important source of information about our dynamic world. However, techniques for automated understanding and visualization of time-varying processes from images or videos are scarce and underdeveloped, requiring fundamental new models and algorithms for representing changes over time. This research involves creating systems that enable modeling, analysis, and visualization of time-varying processes based on image data. These models and algorithms will form the basis for a new set of tools that can help answer important questions about how our environment is changing, how our cities are evolving, and what significant events are happening around the world.<br\/><br\/>Analyzing images over time poses fundamental new technical challenges. This project focuses on developing and demonstrating end-to-end systems consisting of (1) novel representations necessary to model time-varying image datasets; (2) algorithms for estimating long-range temporal correspondence in image datasets; (3) algorithms for decomposing image datasets into intuitive primitives such as shading, illumination, reflectance, and motion; (4) analysis tools for deriving higher level information from the decomposed representations (e.g., trends, repeated patterns, and unusual events); and (5) tools for visualization of the high-level information and methods for re-synthesis of image data.<br\/><br\/>This work has the potential to have significant impact in a broad range of areas where images are generated over time, e.g., in ecology, astronomy, urban planning, health, and many others. The results of this research will be broadly disseminated by making source code and datasets publicly available via the project web site (https:\/\/groups.csail.mit.edu\/vision\/image_time\/) and offering tutorials and organizing workshops at significant conferences. The project provides educational opportunities and offers hands-on collaborative research experience to students at both the undergraduate and graduate levels and the four institutions.","title":"CGV: Large: Collaborative Research: Analyzing Images Through Time","awardID":"1111398","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[483609],"PO":["563751"]},"181320":{"abstract":"The objective of this research is to enable more effective design and use of virtual worlds. The pervasiveness of visually-oriented online and interactive digital media allows people to represent themselves increasingly through surrogates in virtual worlds. These digital personae are called \"avatars,\" and when they closely represent the user, \"self-avatars.\" Self-avatars enable forms of learning, interaction, and skill development that can increase a user's effectiveness in a virtual world. This project will explore how self-avatars play a significant role through three key components of perception and action: the relationship between action and the perception of space and objects, active acquisition of spatial memory, and the planning and execution of actions themselves. <br\/><br\/>This research will consider three properties of self-avatars themselves, each likely to have an effect across a broad range of situations: (1) the virtual perspective from which the avatar is seen, (2) the nature of the coupling between user size and motion and avatar size and motion, and (3) the naturalness of the interface system by which the user controls the avatar. The work builds on a growing body of knowledge about the role of body ownership in perceptual and cognitive tasks. This framework provides a theory in which to ground the research, a body of empirical knowledge about perception and action in the real world, and established methodologies that can be used for assessing the results of the research. The ability to utilize work from cognitive and perceptual science to solve a problem in computer graphics and user interaction is a major strength of the research. <br\/><br\/>Virtual environments are important in many domains, including architecture, education, medicine, simulation, training, and visualization. The core impact of this research is to enable self-avatars to enhance user experience in virtual environments, which are a major category of computer simulations. A broad impact of this project is that enhancing the user experience will lead to more capable applications of virtual environments in the aforementioned domains. This research will also have utility in entertainment systems, the dominant environments for avatars. It advances discovery and understanding while training students in cross-disciplinary research methods in an innovative intellectual environment. The interdisciplinary nature of the research and its consequent applications, together with the close integration of two research groups, will aid in bringing new students to computer science, beyond the students traditionally attracted to that field.","title":"HCC: Small: Collaborative Research: The Influence of Self-Avatars on Perception and Action in Virtual Worlds","awardID":"1116636","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["553308","553309","560997"],"PO":["564456"]},"181562":{"abstract":"Current information technology enables many organizations to collect, store, and use massive amount and various types of information about individuals. Governments and other organizations increasingly recognize the critical value and enormous opportunities in sharing such a wealth of information. However data privacy has been a major barrier for such information sharing, bringing much attention to privacy preserving data publishing and analysis techniques. Differential privacy is widely accepted as one of the strongest unconditional privacy guarantees. While many effective mechanisms have been proposed for the interactive model with differential privacy, non-interactive data release with differential privacy remains an open problem with the recent years only see negative results. <br\/><br\/>This project aims to build a data-driven and adaptive framework for differentially private data release. It circumvents the hardness of differentially private data release in the non-interactive setting by novel and sophisticated use of the differentially private primitives exploiting the characteristics of the underlying data. The specific research objectives include: (1) design adaptive query strategies for releasing data with differential privacy, including traditional relational data and high dimensional and sparse set-valued data, (2) design statistical inference technique to accurately answer user queries using the released data, and (3) design algorithms to model and incorporate potentially dynamic workload characteristics in the framework. In addition to formal analysis and experimental evaluations, the project will evaluate and integrate the developed solutions in real health applications at Emory University to support health research while providing rigorous privacy guarantee.<br\/><br\/>Success of the proposed research will help overcoming barriers for large scale data sharing and will have broader impacts to large societies beyond the field of data privacy and information management. The proposal also includes a set of closely integrated educational activities including new course development on data privacy and security emphasizing a strong interdisciplinary aspect, continued involvement of undergraduate students in research, and encouragement of women and minority for participation. The project also closely aligns with Emory's university-wide strategic initiatives in Predictive Health and will help develop the new Ph.D. program in Computer Science and Informatics at Emory University.","title":"TC: Small: Adaptive Differentially Private Data Release","awardID":"1117763","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["283237"],"PO":["562974"]},"180352":{"abstract":"This research will involve designing, implementing, and evaluating computational tools to support frame reflection in processes of online political engagement. The internet, social media, and online communication have great potential as a platform for political engagement, from seeking political information to participating in political discussion and deliberation. The wealth of content available via the web can make for more informed discussion, and the fact that discussion can take place on a much larger scale than face-to-face forums offers the potential for participation by many and diverse groups. However, thus far, online political participation has not proven radically democratic. Rather, it has tended to reproduce preexisting inequalities and balkanization in political talk. The constantly and rapidly increasing quantity of political content produced on a daily basis can also be difficult to understand and evaluate, particularly with respect to how issues are framed. The latter is especially important given the fact that, as numerous researchers have shown, how issues are framed?that is, how they are formulated in terms of familiar assumptions, metaphors, and images?profoundly affects how citizens understand, assess, and act upon those issues.<br\/><br\/>This project will both leverage existing computational techniques and develop novel analytic approaches to encourage citizens to identify and evaluate the frames that underpin competing positions on issues. Through evaluation in two real-world settings, public deliberative forums and readers of political blogs, this work will make two distinct sets of contributions. First, this project will develop human-computer interaction design principles for interactive tools and visualizations involving complex computational techniques. These principles will help ensure that such tools are designed to be useful for, comprehensible to, and interpretable by users. Second, by examining the impacts of various computational interventions, this work will enhance political and social scientific understanding of online political deliberation, both in terms of how technology mediates the deliberative process, and in terms of how deliberation can be improved through increased awareness of and reflection about framing.<br\/><br\/>The immediate impacts of this research will take the form of tools deployed in real-world settings with politically engaged users, namely through a partnership with a non-partisan convener of online forums, and through public deployment among readers of political blogs. Additionally, the tools developed in this project will be made readily available for use by others, either in support of political deliberative processes or in other contexts. In the long term, the work has significant potential to improve understanding of political deliberation, and it provides an opportunity to explore alternative roles that technology can play in supporting political participation.","title":"Collaborative Research: Improving Online Deliberation with Computational Supports for Frame Reflection","awardID":"1110932","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["560930"],"PO":["564456"]},"181210":{"abstract":"Proteins are the workhorses of the cell, involved in virtually every process in life. Many proteins are flexible molecules that undergo structural changes as part of their function. In other words ? they can assume various possible structures (conformations) via changes that range from small-scale movements to large domain motions. The question of how the structure and dynamics of proteins relate to their function has challenged scientists for several decades but still remains largely open. Existing computational methods for simulating protein dynamics can sample atomic level dynamic processes, yet their usefulness is limited as they require large computational resources, and they only allow for modeling of interactions that take place on very small time scales (e.g., several hundreds of nanoseconds). There is promise that understanding the connection between protein structure, dynamics and function can contribute a lot to the understanding of how molecular machines function and may aid in drug design and functional analysis. <br\/><br\/>A computational framework for an efficient large-scale exploration of protein conformational changes is proposed in this work. Given a protein structure, the aim is to efficiently generate a diverse set of conformations representing the low energy landscape of this protein under physiological conditions. The suggested methodology can be used to explore the conformational space of proteins and protein complexes and gain better understanding of protein dynamics and function. <br\/><br\/>To overcome the computational demands of a full scale conformational search, the search will be done in two stages: first, conduct a fast and approximate geometry-based exploration of the low energy landscape of proteins and protein complexes in an efficient way, temporarily sacrificing small-scale details for efficiency. The approximate search is enhanced with a novel biasing scheme that drives the search towards more flexible regions of the protein, reducing the huge search space into a manageable size. The reduced representation of the conformational landscape will be enhanced and complemented with detailed, physics based simulations applied to interesting and important regions in the proteins or to intermediate structures. This last stage will take advantage of massive parallel computing. The combination of fast, approximate search techniques and detailed physics-based simulation methods will create an enhanced, more complete picture of the low-energy landscape of those proteins and will improve understanding about how proteins perform their function. The methodology can be applied to problems related to protein interactions and rational drug design.<br\/><br\/>The broader impact of this project is partly due to the central role of proteins in virtually every basic biological function. This project addresses a significant question of the biological research community. Educational and outreach activities will be implemented through the following: <br\/>a) Interdisciplinary collaborations with members of the CS department and other departments in the College of Science and Mathematics at UMass Boston. <br\/>b) Training and mentoring the research of undergraduate and graduate students, including women and students from under-represented groups in science. <br\/>c) Help setting up a Bioinformatics research and teaching program at UMass Boston.","title":"AF: SMALL: Developing Novel Computational Methods for Investigating Protein Dynamics Using a Multi-Scale Approach","awardID":"1116060","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[485580],"PO":["565223"]},"181331":{"abstract":"The Internet revolution enabled private users across the world to send and receive messages to one another. Coupled with cryptographic techniques like public key encryption and digital signatures, this gave rise to the development of the world wide web, e-commerce, and so many other technological changes that we routinely take for granted today. We are now facing a second revolution in which we are changing not just how we communicate, but how we compute. More and more we are sending large datasets to untrusted servers, having them perform calculations on our behalf. From our cell phones and our GPS units, we send compromising information to our service providers in order to outsource the computation that we cannot do on-the-go. Cryptography has a new role to play in these emerging environments.<br\/><br\/>The PI intends to explore the theoretical underpinnings of the cryptographic challenges that arise in this context. The proposed directions of research touch on the following questions:<br\/>-- How can we safely allow others to perform computation on our encrypted data while maintaining its privacy?<br\/>-- How can we verify that outsourced computation was done correctly?<br\/>-- What stronger security models are needed in this new, highly interactive environment?<br\/><br\/>The PI will address the theoretical aspects of these problems, including modeling, protocol design, and negative results. As part of her investigations, PI will study the powerful cryptographic primitives of fully homomorphic encryption and functional encryption (in particular, the relationship between them and outsourced and verifiable computations), as well as the area of leakage-resilient cryptography.","title":"AF: Small: How to Let an Adversary Compute for You","awardID":"1116702","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[485875],"PO":["565157"]},"181452":{"abstract":"The objective of this research is to investigate a computer aided design (CAD) framework that can be used for verification and reliability analysis of hybrid bio-silicon circuits used for designing biosensors. It is envisioned that similar to integrated circuit (IC) CAD design tools, the same framework will be useful in biosensor system optimization and in the discovery of new sensing modalities that combine proteins and silicon circuits at a system level. Similar to an IC design-flow, the proposed simulation and analysis framework will be used to verify the functionality and reliability of biosensor systems before undertaking laborious fabrication and experimental procedures.<br\/><br\/>With advances in micro-nano-fabrication, the emerging biosensors can integrate an ever increasing number of detection elements on the same device. This has opened the possibility that perhaps exploiting spatial redundancies across multiple detection experiments could be used to alleviate the effects of biosensor artifacts using forward error-correcting techniques. However, the full potential of this technique in biosensing methods can only be achieved on high-density arrays that can potentially integrate millions of protein-based circuits. The proposed research would serve as a simulation and analysis framework to verify the functionality and reliability of these high-density assays before undertaking painstaking fabrication and experimental procedures. <br\/><br\/>As an outreach component of this proposal, the PI plans to make software tools and the library of protein-based circuit models publicly available through a webportal. The users will be able to modify the software and integrate the modules with other circuit simulation tools. From the perspective of a computer scientist or a VLSI researcher the software could serve as a useful tool for explorations in the area of hybrid bio-silicon circuits without resorting to time-consuming laboratory experiments. The PI is also strongly committed to the training of women, underrepresented and K-12 students. Different outreach programs which are available at Michigan State University be used to recruit students to participate in the proposed research.","title":"SHF: Small: FAST: A Simulation and Analysis Framework for Designing Large-Scale Biomolecular-Silicon Hybrid Circuits","awardID":"1117186","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["491679"],"PO":["562984"]},"181221":{"abstract":"The objective of this project is to explore technology for low-power reconfigurable computing at extreme environment, i.e. at a temperature > 250\u00b0C and at high radiation (1-30 Mrad), where conventional electronics fail to work reliably. The project seeks to develop the computing platform through a device-circuit-architecture co-design approach. The platform uses polycrystalline SiC nanoelectromechanical system (NEMS) switches to achieve nanoscale dimension, superior mechanical and chemical stability at extreme conditions and virtually zero leakage. The project studies a novel switch structure with multi-layer cantilever beams to realize the reconfigurable building blocks with high density and robustness. Possible hybridization with SiC junction field effect transistor (JFET) will be explored to address the issue of cascading mechanical logic blocks with limited driving capability. The project also investigates a novel computational model and architecture to adapt to failures and to achieve low interconnect overhead. Considering the lack of simulation models for NEMS switches and circuits, it will develop appropriate circuit-compatible models. Operation of the building blocks at high temperature will be validated through simulation as well as fabrication and measurements of test chips. <br\/><br\/>The proposed low-power reconfigurable hardware design approach can provide enabling technology for extreme-environment computing in number of application areas including automotive and industrial applications, space, avionics, combustion engine, and intelligent propulsion systems. It can provide an order of magnitude lower power and area than state-of-the-art SiC transistor based electronics. The simulation models can be valuable research tool for analysis of nanoscale mechanical switches. The research will integrate education and training through development of a new undergraduate course, interdisciplinary senior projects, and an internet group on harsh environment electronics.","title":"SHF: Small: Device-Circuit-Architecture Co-Design for Reconfigurable Computing at the Extreme","awardID":"1116102","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["530582",485607,"531177"],"PO":["562984"]},"181463":{"abstract":"The last decade witnesses the explosive growth of the Internet traffic and emerging applications such as IPTV, VoIP, VoD, P2P sharing and Cloud Computing. The traffic growth demands an enormous amount of network bandwidth and power consumption, which poses a huge challenge to current Internet infrastructure. The focus of this project is to investigate a new switching paradigm called spectrum-sliced elastic optical path (SLICE) network. Instead of allocating fixed-size frequencies to each channel as traditional networks, SLICE employs the Orthogonal Frequency Division Multiplexing (OFDM) technologies by splitting the signal into multiple smaller sub-carriers that are then transmitted simultaneously at different frequencies to the receiver.<br\/><br\/>Intellectual Merit: The objective of this project is to develop novel SLICE schemes to efficiently accommodate the traffic and alleviate power consumption in the backbone networks. The study includes (i) efficient and flexible bandwidth management through elastic sub-carriers allocation; (ii) robust optical path establishment with a finer granularity to best accommodate the traffic requests; (iii) joint optimization of RSA and virtual network mapping to ease the ossification problem in current Internet; and (iv) energy-efficient allocation of the constrained SLICE resources. This work will result in theoretic analysis, practical algorithms, simulation tools and performance modeling, which can serve as useful guidelines, and provide insights for the design of next-generation Internet.<br\/><br\/>Broader Impacts: This research will advance the state-of-the-art knowledge about optical and future networks. The modeling and design techniques from this project are applicable to a wide range of networking technologies such as resources allocation, network virtualization and survivability. Some of the new protocols, algorithms, modeling and performance results can be practically adopted by the industry. By involving both undergraduate and graduate students in the research, incorporating research agenda into both undergraduate and graduate courses and disseminating the findings, the project will help train the future scientists and engineers in high demand fields.","title":"NeTS: Small: Design and Analysis of Spectrum-sliced Elastic Optical Path Networks","awardID":"1117229","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[486191],"PO":["564993"]},"181584":{"abstract":"The face of emerging computing systems is changing rapidly. On one hand computers are looking smaller than ever. The smart phone is nothing but a pocket computer which also has the ability to make a phone call. On the other hand, computers are getting bigger than ever, as in a cloud computing server. These cloud systems are distributed systems with a large number of processors, abundant memory and disks and plentiful network resources and bandwidth, and are huge. This project is on workload characterization and benchmark synthesis for emerging computing systems such as the embedded computer and the cloud computer.<br\/><br\/>The first component of this project consists in characterizing and understanding workloads on emerging computing platforms. Characteristics of embedded computing software in embedded Java or paradigms such as the .NET, or cloud applications such as Hadoop are not well-understood. It is also unclear whether next generation cloud servers should use simple energy efficient processors or more powerful processors geared towards performance. The characterization component of our project is geared towards understanding these issues. <br\/><br\/>The second component of this project consists of benchmark synthesis to create workload proxies that have equivalent performance and energy characteristics as the original applications but without the functionality. These proxy workloads will enable efficient pre-silicon design exploration and sharing of proprietary applications.<br\/><br\/>At a broader level, the research creates mechanisms that enable hardware and software developers to collaborate on joint product development without fear of loss of intellectual property. It also trains several graduate and undergraduate students in an important research area, and influences courses on embedded and cloud computing.","title":"SHF: Small: Workload Characterization and Benchmark Synthesis for Emerging Computing Systems","awardID":"1117895","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["556800"],"PO":["565272"]},"181232":{"abstract":"Shannon's source-channel separation theorem states that separating the source coder (compressor\/decompressor) and the channel coder (error correction coder\/decoder) via the universal digital interface of 'bits' is optimal for point-to-point communication of a single data source. While this modular design principle has inspired the basic architecture for most of today's communication systems, it is outperformed by more complex 'joint' source-channel coders for communication of multiple sources over networks---an important task in today's explosive demand and supply of distributed information sources. At the same time, many emerging applications involve computing a summary of data from multiple nodes, making a coordinated decision, and performing a joint action among these nodes, rather than merely communicating sources. This research establishes a hybrid source-channel coding architecture for these applications that is as simple as Shannon's separation architecture, yet achieves much improved performance. The new architecture will eventually lead to the discovery of practical algorithms for distributed computation, sensing, decision making, and coordination over networks.<br\/><br\/>Specifically, this research focuses on and develops new approaches for tackling the following problems: 1) hybrid coding for communicating correlated sources over multiuser channels (a unified approach for joint source-channel coding), 2) hybrid coding for network communication (a new relaying scheme based on joint source-channel coding), 3) implementation issues for hybrid coding (design of a practical code that is a good channel code and a good source code simultaneously), and 4) a mathematical framework for performance analysis and code design (information theoretic tools when the codebook and the message are entangled).","title":"CIF: Small: Collaborative Research: A New Approach to Joint Source-Channel Coding","awardID":"1116139","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["551039"],"PO":["564924"]},"181353":{"abstract":"The increasing numbers of overweight and obese adolescents is a key health challenge in 21st century<br\/>America. Since the 1980s, rates of overweight adolescents have doubled, and rates of obese adolescents<br\/>have tripled; adolescent obesity is now the single biggest predictor of adult obesity. At the same time,<br\/>adolescents are spending increasing portions of their lives interacting with video games and social<br\/>network sites, incorporating computing into their leisure and social communication practices on a large<br\/>scale. This project uses computing technology to address adolescent obesity through the<br\/>development and study of social tools to promote sustained everyday healthy practices by adolescents.<br\/>The research demonstrates how social computing<br\/>can enable offline healthy behaviors, using peers as motivators in contrast to \"top-down\"<br\/>approaches. The work is in partnership with DeKalb County Schools, Georgia's<br\/>most urban school district and a leading awardee of research-focused programs.<br\/><br\/>Research in this project is exploring the effects of various social computing<br\/>tools and features on a set of validated outcome measures grounded in our previous work and best<br\/>practices. During the school year the project deploys a series of pedometer-based social health<br\/>applications and games for 8th graders in two middle schools. In the summers between deployment cycles, a small subset of participants takes part in design sessions for the next school year.<br\/><br\/>Research focuses on three main topics:<br\/>1. The role of online social identity presentation in intrinsic motivation.<br\/><br\/>2. The ability of social computing interventions to facilitate offline rituals and habits.<br\/><br\/>3. The impact of collective experiences.<br\/><br\/>This research will contribute to our understanding of the connections between social<br\/>media activity and offline behavior. It will also demonstrate improvements in health behaviors and attitudes for adolescents. Moreover by deepening the connection between the<br\/>Dekalb School System in Atlanta and Georgia Tech, the project enriches the educational environment<br\/>of these middle school students.","title":"SHB: Small: Social Tools for Everyday Adolescent Health","awardID":"1116801","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["506686"],"PO":["549626"]},"180385":{"abstract":"This project will develop and evaluate an innovative research tool, based on Natural Language Processing (NLP) and Machine Learning (ML), to support qualitative social science research, specifically content analysis. Content analysis is a qualitative research technique for finding evidence of concepts of theoretical interest using text rather than numbers as its raw data. The process of identifying and labeling significant features in text is referred to as \"coding,\" and the result of such an analysis is a text annotated with codes for the concepts exhibited. This technique has become increasingly popular and more applicable as the volume of available \"born-digital\" text has exploded. However, the reliance on manual analysis of the text limits the scale and scope of content analysis research.<br\/><br\/>In this project, the problem of coding qualitative data is conceptualized as an information extraction problem amenable to automation using NLP. However, rather than seeking to automate the process, the technologies will be used in a supporting role, creating a human-computer partnership. ML will be used to induce NLP rules from examples of coded text, avoiding the need to develop rules manually. To reduce the amount of training data needed from the human participants, an active learning process will be employed, in which a few hand-coded examples are used to create an initial model that can be further evolved through interaction with the user. These approaches will be combined in a prototype tool to support qualitative content analysis. As a demonstration and test of the tool, it will be applied to current and novel studies of cyber-infrastructure-supported distributed groups, specifically free\/libre open source software development teams, and then to a broad range of social science research problems. This broad usage will also provide a test of the generalizability of a socio-computational approach to this problem.<br\/><br\/>The intellectual merit of the research is four-fold. First, the proposal seeks to develop a novel socio-computational system that supports a human-computer partnership through the integration of information extraction and active learning. Second, a validation study will apply the tool to a diverse set of codes, providing evidence of the generality and limits of a socio-computational approach. Third, the demonstration studies using the tool will contribute to research on distributed groups. Finally, the project addresses a fundamental methodological problem in the broad domain of qualitative research, namely dealing with large quantities of unstructured qualitative data, by applying innovative computer-support. By avoiding the need for hand-written rules and reducing the required amount of hand-annotated training data, this partnership will make practical the use of a system for coding large quantities of qualitative data in various domains.<br\/><br\/>The project has numerous broader impacts. It will benefit society by providing useful infrastructure for research in the form of a content analysis tool for scientific research and in for the form of corpora of annotated data for use in future Natural Language Processing research. The demonstration studies will provide generalizable knowledge to improve the effectiveness of distributed groups, an increasingly important mode of organization. Finally, the project contributes to the education and training, of women and minority group members in particular.","title":"SOCS: Socially Intelligent Computing for Coding of Qualitative Data","awardID":"1111107","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["483415",483415,"565342"],"PO":["565215"]},"181122":{"abstract":"Biometrics, such as fingerprints, provide a great tool for personalized authentication. While people are usually willing to submit their biometric information to government agencies, they are less likely to do so for commercial companies without a guarantee of privacy protection. This project will have significant societal impact by triggering wide acceptability of large-scale biometrics enabled applications.<br\/>The primary technological hurdle faced by large scale biometric systems today is the ability to address two competing objectives: (1) provide fast matching of a biometric against a large database of stored biometric readings and (2) provide privacy of the biometrics in the database such that it can withstand malicious attacks. Existing solutions tackle either of the two problem but not both simultaneously.<br\/>Tackling the two problems in an integrated fashion is non-trivial as any solution to conceal the biometric data to ensure privacy involves breaking down the structure inherent in the biometric template, thus making it extremely challenging to index the records efficiently. This project presents a unified approach by developing \"cryptographically hidden\" biometric templates which will lend themselves to fast searches. This effort will draw upon new research in the fields of biometrics, databases, and coding theory.","title":"TC: Small: Integrating Privacy Preserving Biometric Templates and Efficient Indexing Methods","awardID":"1115670","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":["548306","550387"],"PO":["562974"]},"182695":{"abstract":"This project's investigation is at the nexus between scientific thinking, computational thinking, modeling as an investigative endeavor, and visual programming tools. The PIs are infusing middle-school science with efforts to promote computational thinking, doing that through making modeling a more significant part of science activities. The modeling experiences learners have become progressively more complex throughout each module and more complex across modules, with the increases in complexity informed by complexities of becoming a computational thinker. Modeling and computational thinking are foregrounded in each module, with each becoming more fluid over time as a result of the repetition of increasingly complex modeling experiences in a variety of situations, all of which build on each other. The mental model building, computational thinking, modeling, and science education literatures all inform the endeavor. The technological innovation includes creating and refining a modeling environment appropriate to middle schoolers, including an appropriate visual programming language. Research questions address issues in learning computational thinking in the context of learning to model and use models for investigation (and vice versa) and trajectories towards competency in computational thinking and modeling as their research questions.<br\/><br\/>Computational thinking is becoming a more and more important required expertise of scientists -- both those who work at the high levels of computational science and engineering and those who support them and apply computational science. In addition, as computation becomes more and more ubiquitous in a whole variety of disciplines and workplace responsibilities, the rest of the population, too, needs to be more expert at computational thinking and at using computational tools. Infusing computational thinking and the use of computational tools into the curriculum in appropriate ways is the right way to promote this cross-cutting expertise. Science is one place in the curriculum where computational thinking can easily be integrated, and doing so not only holds the promise for readying more of the population for careers and jobs that require computational thinking and use of computational tools but also making middle school science more exciting to more of the population.","title":"EXP: CTSiM: Fostering Computational Thinking in Middle Schools through Scientific Modeling and Simulation","awardID":"1124175","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":["536406",489472,"502419"],"PO":["562669"]},"181496":{"abstract":"This project aims to build a reliable and efficient communication support for highly mobile ad hoc networks. This type of networks many time are mission or safety critical requiring reliable communication. For an ad hoc network, this problem is especially challenging because two communication nodes may have never encountered before and do not possibly belong to the same organization. Pre-sharing any information between two nodes may not be feasible. This project addresses a number of adversary attacks in highly mobile ad hoc networks, including communication jamming and eavesdropping, by building a supporting communication layer. More precisely, the main research in this project is to design novel schemes to defend against jamming attacks by agilely changing communication channels, and extract physical layer information to build a secure communication channel. The supporting communication layer provides a secure infrastructure for efficient communications. The project applies both theoretical analysis and real experiments to validate the solutions.","title":"NeTS: SMALL: Reliable and Efficient Communication Support for Highly Mobile Ad Hoc Networks","awardID":"1117412","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551983"],"PO":["557315"]},"193002":{"abstract":"This research will explore novel \"authoring by demonstration\" techniques for real-time strategy (RTS) games. Creating rich artificial intelligence (AI) behavior sets for complex computer games requires significant engineering effort. Developers need to anticipate all imaginable circumstances that the AI may encounter within the game world. The resulting AI is often static and results in predictable behaviors, detracting from the player experience. In addition, it is difficult for average players to create AI behaviors, without significant expertise in both AI and scripting. Modeling human-like goals and behaviors required for multiplayer games with semi-autonomous avatars adds additional complexity. This potentially transformative project will develop novel learning techniques that allow users to create intelligent behaviors simply by demonstrating them. The research will be done within the domain of RTS games, as these domains pose significant challenges that must be tackled in order to scale up the learning techniques to real-world tasks.<br\/><br\/>Case-based planners, hierarchical task network planners, or industry-standard behavior-tree execution engines require a library of base behaviors or methods in order to generate complete plans, which traditionally are coded by hand. The project will investigate ways to automate the process of generating such behavior libraries based on novel methods for learning strategic plans from user demonstrations. The techniques will be evaluated in the context of a case-based planning system for RTS games. RTS games are complex and involve strategic decision-making, multi-agent coordination, real-time interaction, and partially-observable environments. These properties pose significant challenges to existing AI methods for planning and learning. This research will make fundamental scientific contributions to learning, case-based reasoning, and AI for real-time strategic domains, addressing key problems in goal recognition, plan learning, and authoring support. <br\/><br\/>This research will enable game designers and other non-programmers to create the behavior sets for RTS games without requiring programming knowledge. This capability has two main consequences: first, it allows game developers to create games with less effort, and second it will enable a new genre of games where players would be able to create their own AIs as part of the game play. Additionally, as RTS games are essentially domain-specific simulations, the research will support authoring of behavior sets for domains such as simulation environments for training, real-time robotic control, organizational modeling for business decision-making, or sophisticated market simulations for economics strategy or public policy. The educational impact of the project is twofold. First, the project will constitute an important advance towards easy authoring of training simulators for educational applications that require environment with complex AI behaviors. This will enable development of new educational technologies with simulators or virtual worlds. Second, the project will involve undergraduate and graduate students in all phases of the work.","title":"HCC: EAGER: Authoring Game AIs by Demonstration for Real-Time Strategy Games","awardID":"1216253","effectiveDate":"2011-09-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[517042],"PO":["564456"]},"181144":{"abstract":"Nearly all modern processors now contain multiple cores and almost all modern computer systems contain multiple processors. Thus future software is likely to be both multithreaded (in which threads of a process communicate using shared memory) and distributed (in which processes in a system communicate using messages). Ensuring that a program works correctly under all possible scenarios is a very dif&#64257;cult task. Most real-world programs contain a large number of components which makes their formal veri&#64257;cation infeasible. Effective tools for testing and debugging programs prior to their deployment are indispensable. Bugs persist even after extensive testing and debugging especially those that manifest under rare circumstances. Monitoring programs at runtime and possibly controlling their execution to avoid bad states is an important way to tolerate residual software bugs. <br\/>In this project, we are working on developing a theory and algorithms for monitoring, analyzing and controlling a multithreaded distributed computation. Specifically, we are developing (i) a unifying framework for modeling synchronization in multicore distributed systems resulting from messages, locks and other synchronization primitives (e.g., wait\/notify), (ii) offline and online algorithms for detecting and controlling predicates, expressed as temporal logic formulas, using slicing and other approaches, and (iii) scalable approaches for tracking dependency among events.<br\/>Besides multicore computing, the work has applications in a variety of other areas including cloud computing, distributed databases, recovery, replica consistency and resource management. We are also developing educational tools that can be used in courses to enhance the learning experience of students working with multicore distributed systems.","title":"CSR: Small: Collaborative Research: Improving Dependability of Multithreaded Distributed Programs","awardID":"1115733","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[485416],"PO":["565255"]},"181386":{"abstract":"This project focuses on improving the effectiveness of computer security warning dialogs ? on-screen prompts that warn users about a potential security risks and give users a choice between two or more courses of action. Security dialogs should help users avoid unsafe actions while allowing them to take safe actions by presenting information that allows users to make informed decisions that the system cannot make with user input. This research takes a novel approach to the design and rigorous evaluation of computer security warning dialogs, with the goal of developing generalizable guidelines for designing effective warning dialogs for software products. This has the potential to help end users make better security decisions that keep their information and computer systems safer, and improve the computer security ecosystem.<br\/>Based on the Carnegie-Mellon team?s previous work, review of the literature, and discussions with collaborators, they have developed a set of candidate features that will have a significant impact on the effectiveness of security dialogs. For example, these features include: amount and placemen of text, severity of tone, how to help users decide, describing risks and consequences, use of recommended and default options, and more. They plan to systematically study each feature, applied to a variety of security dialogs, to determine the impact of each (individually and in combination) and to develop guidelines on how to use each feature to best effect. They will follow an iterative design and evaluation approach that will involve five types of studies: exploratory interviews, Mechanical Turk studies, laboratory studies, field studies, and interface designer studies. In the Mechanical Turk studies, participants will be provided with a scenario and a security dialog triggered by that scenario and asked how they would be most likely to respond. They will also be asked follow-up questions to learn why they made that decision, their perception of the risks associated with each warning dialog, their understanding of the warning dialog, their beliefs about how well they think they understand the warning dialog, and their knowledge of the concepts and vocabulary included in each dialog. We will measure the tendency for users to take the recommended action in risky scenarios and the non-recommended action in benign scenarios. The follow-up questions will help determine why users behave the way they do and how to most effectively design security warning dialogs to influence that behavior. It is important to determine how to communicate effectively about the risks and consequences, but also to determine how much users need to be able to understand before they make appropriate decisions. It is anticipated that of some aspects of the situation will be correlated with behavior, but that there will be some information that increases understanding with little or no impact on behavior. In addition, the features are likely to have varying impacts on understanding risks and consequences, motivation to take the safe course of action, and behavior. To test the generalizability of the guidelines, a large set of security dialogs from a wide range of software products will be collected. As candidate guidelines emerge, they will apply them to a variety of dialogs in their catalog and also observe which guidelines seem generally applicable and which seem to apply to only certain types of dialogs in our collection. Based on the final set of guidelines, the team will provide a number of example redesigns in a final project report and security dialog design tutorial that they will make publicly available.","title":"TC: Small: Effective Security Warning Dialogs","awardID":"1116934","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553878"],"PO":["565136"]},"181034":{"abstract":"The traveling salesman problem (TSP) is easily the most famous problem in discrete optimization. Given a set of n cities and the costs c(i,j) of traveling from city i to city j for all i and j, the goal of the problem is to find the least expensive tour that visits each city exactly once and returns to its starting point. A linear programming relaxation of the problem called the subtour LP is known to give extremely good lower bounds on the length of an optimal tour in practice. Nevertheless, the subtour LP bound is poorly understood from a theoretical point of view. For 30 years it has been known that it is always at least 2\/3 times the length of an optimal tour, and it is known that there are instances such that it is at most 3\/4 times the length of an optimal tour, but no progress has been made in tightening these bounds. It has been conjectured that the subtour LP is always at least 3\/4 times the length of the optimal tour. The goal of this research is to resolve this conjecture. Because this goal is very ambitious, a number of intermediate goals have been proposed.<br\/><br\/>Theoretical computer scientists have intensively studied approximation algorithms for NP-hard problems; these are polynomial-time algorithms that always provide solutions that are provably close to optimal (in terms of some performance guarantee). The main issue driving theoretical work has been improvements in performance guarantee rather than whether the algorithms are implementable or practical. While understanding the limits of approximability is and should be one of the issues that theoretical work advances, one can also explore whether those limits can be reached with algorithms that are less computationally intensive than the ones currently in the literature. We call this the creation of lightweight versions of approximation algorithms. This exploration advances the potential impact of approximation algorithm on practice without losing the <br\/>theoretical rigor of the field.<br\/><br\/>The intellectual merit of the proposal lies in the possibility of making substantial progress in resolving outstanding problems related to the subtour LP for the traveling salesman problem, and also in making practical some of the outstanding theoretical work in approximation algorithms. The goal of this research lies in moving theoretical and practical studies of optimization problems closer to each other. In the case of the traveling salesman problem, we have a bound that is very good in practice, but we do not understand its theoretical properties. In the case of approximation algorithms, we have some very good theoretical algorithms, but they are often not practical. We would like to understand the theoretical properties of the subtour LP bound for the traveling salesman problem, and to make practical some of the good theoretical work in approximation algorithms.","title":"AF: Small: The Traveling Salesman Problem and Lightweight Approximation Algorithms","awardID":"1115256","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[485172],"PO":["565251"]},"184675":{"abstract":"This project develops a framework for design automation of cyber-physical systems to augment human interaction with complex systems that integrate across computational and physical environments. As a design driver, the project develops a Body\/Brain Computer Interface (BBCI) for the population of functionally locked-in individuals, who are unable to interact with the physical world through movement and speech. The BBCI will enable communication with other humans through expressive language generation and interaction with the environment through robotic manipulators. <br\/><br\/>Utilizing advances in system-level design, this project develops a holistic framework for design and implementation of heterogeneous human-in-the-loop cyber-physical systems composed of physically distributed, networked components. It will advance BBCI technology by incorporating context aware inference and learning of task-specific human intent estimation in applications involving semi-autonomous robotic actuators and an efficient wireless communication framework.<br\/><br\/>The results of this project are expected to significantly speed up the design of complex cyber-physical systems. By accelerating the path from idea to prototype, this work shortens the time frame of and cost of development for assistive technology to improve the quality-of-life for functionally locked-in individuals. This project establishes an open prototyping platform and a design framework for rapid exploration of other novel human-in-the-loop applications. The open platform will foster undergraduate involvement in cyber-physical systems research, building confidence and expertise. In addition, new activities at the Museum of Science in Boston will engage visitors to experiment with systematic design principles in context of a brain computer interface application, while offering learning opportunities about basic brain functions.","title":"CPS: Medium: Collaborative Research: Holistic Design Methodology for Automated Implementation of Human-in-the-Loop Cyber-Physical Systems","awardID":"1135854","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["563719"],"PO":["564778"]},"182134":{"abstract":"Economic competitiveness relies upon innovation and digitized tools, services and data representation. These innovations are required for organizations to remain effective. Designers and design managers guide the evolution of digitally enabled design capabilities by integrating different types of digital process capabilities and resources. Such capabilities can also help optimize complex systems (e.g., smart grid, pervasive healthcare). Building on organizational and evolutionary theory, this project studies changes in organizational processes as they incorporate innovative virtual elements. It applies a process modeling framework to explore underlying mechanisms that generate patterns of change, and uses computational tools in conjunction with theories of evolutionary genetics to analyze longitudinal changes in organizational processes for integrating virtualized innovations. Generative structural elements of design processes (e.g., genotypes) give birth to surface-level design routines and variations (e.g., phenotypes) over time. Processes are represented as sequences akin to biological genes and their translated protein products. while combinations of elements akin to DNA base pairs and their corresponding amino acids capture essential traits of design activity. This new vocabulary helps us delineate structurally the fundamental design task elements and their variation across design task instances.<br\/><br\/>The study advances theoretical understanding of how digital capabilities alter organizational processes. It shows how mutations emerge and how processes change over time. It identifies strategies for embedding digital capabilities into processes, and explores the impact of complexity. It advances instrumentation, methodology and analytical techniques by describing digitally-enabled processes and performing comparative, hierarchical, structural-analytical analyses of event-sequence-based process data. It provides longitudinal data on the micro- and meso-level changes in design processes from systematic studies of design for cars, chips and buildings. Genetics research is used to evaluate design in light of evolutionary models and agent-based simulations and to identify patterns of integration of digital capabilities into design processes over time.","title":"VOSS-Collaborative Research: Evolution in Virtualized Design Processes in Project-Based Design Organizations","awardID":"1120966","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"5376","name":"INNOVATION & ORG SCIENCES(IOS)"}}],"PIcoPI":["538337","538335"],"PO":["565255"]},"186853":{"abstract":"The proposed research is in the general area of \"planning under uncertainty.\" This topic addresses the problem of choosing good actions in situations where actions do not have deterministic outcomes. Applications for this general framework include but are not limited to robotic control, medical decision making, and business optimization. The overarching mathematical framework for this problem is that of decision theory or Markov decision processes, topics that are studied in a wide range of fields, including engineering, economics, operations research and, more recently, artificial intelligence. <br\/><br\/>Recent technical efforts in this area have sought to address large problems by combining successful statistical and machine learning techniques with decision-theoretic reasoning. The underlying insight behind these efforts is that machine learning can generalize across similar states of the world, thereby allowing algorithms to propose good actions for new states of the world without explicitly considering every possible state or outcome, as was required by classical approaches.<br\/><br\/>The combination of classical decision theoretic methods and machine learning has shown great promise for large state spaces, but one aspect that has been under-explored is large action spaces. Large action spaces arise naturally from a fine discretization of a continuous action space or from a large set of discrete choices, such as assignments of firefighters to regions on a map. One way to address the general challenge would be to group actions into sets and use machine learning methods to predict which set is preferred. By doing this multiple times over carefully arranged partitions of the action space, it should possible to achieve an exponential reduction in the effort required to select the best action.<br\/><br\/>Potential applications of this research include robotic control, power grid management, and forest\/fire management strategies.","title":"EAGER: IIS: RI: Learning in Continuous and High Dimensional Action Spaces","awardID":"1147641","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["518533"],"PO":["562760"]},"184686":{"abstract":"This project proposes a cross-layer framework in which vehicular wireless networking and platoon control interact with each other to tame cyber-physical uncertainties. Based on the real-time capacity region of wireless networking and the physical process of vehicle movements, platoon control selects its control strategies and the corresponding requirements on the timeliness and throughput of wireless data delivery to optimize control performance. Based on the requirements from platoon control, wireless networking controls co-channel interference and adapts to cyber-physical uncertainties to ensure the timeliness and throughput of single-hop as well as multi-hop broadcast. For proactively addressing the impact of vehicle mobility on wireless broadcast, wireless networking also leverages input from platoon control on vehicle movement prediction. In realizing the cross-layer framework, wireless scheduling ensures agile, predictable interference control in the presence of cyber-physical uncertainties. <br\/><br\/>If successful, this project will lead to a general and rigorous framework for wireless vehicular cyber-physical network control that will enable safe, efficient, and clean transportation. The principles and techniques for taming cyber-physical uncertainties will provide insight into other application domains of wireless networked sensing and control such as unmanned aerial vehicles and smart power grids. This project will also develop integrative research and education on wireless cyber-physical systems through multi-level, multi-component educational activities.","title":"CPS: Medium: A Cross-Layer Approach to Taming Cyber-Physical Uncertainties in Vehicular Wireless Networking and Platoon Control","awardID":"1136007","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["512884","509467",495329],"PO":["502772"]},"181199":{"abstract":"This project aims at a systematic approach that integrates multi-level IC design automation <br\/>flow by leveraging the parallel computational power in current and upcoming multi-core\/many-core <br\/>processors. The main challenge in this approach is to provide responsive high-level design decisions <br\/>while incurring the massive computational cost of lower-level design algorithms. Fortunately, recent <br\/>trends in processor architectures provide a solution. Compared with traditional uniprocessor systems, <br\/>emerging multi-core\/many-core microprocessors have far more computational power but limited global <br\/>memory access capabilities. Parallel computational power may make it possible to break <br\/>the boundaries of the existing IC design hierarchy and to vertically integrate the IC optimization fow. <br\/>The potential benefits of an integrated solution are significant - accurate high-level design decisions <br\/>become possible as low-level design details are derived concurrently, and low-level designs can also <br\/>greatly benefit from high-quality high-level decisions. Together, an efficient and high-quality design flow <br\/>becomes feasible, making design closure faster, thus saving time and reducing costs.<br\/><br\/>The proposed work has the potential to overcome the key limitations of existing hierarchical IC CAD <br\/>technologies and enable new IC design automation solutions, which in turn can benefit the IC and <br\/>semiconductor industry. The PIs will work together with their industrial collaborators to develop and<br\/>commercialize the proposed work. The project will have beneficial impact on education.<br\/>The PIs intend to educate the next generation of software developers and practicing engineers <br\/>in the design and innovation of IC design automation and parallel computing.","title":"SHF: Small: Collaborative Research: A Systematic Approach to Multicore Parallel CAD","awardID":"1116015","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[485555],"PO":["562984"]},"187733":{"abstract":"This EAGER project will carry out three classes of experiments on GENI, all related to security and privacy and all involving low-level network facilities. Of particular interest is the issue of adoptability: will real users (system administrators) accept novel security solutions and under what circumstances? Three experiments are proposed to address these challenges.<br\/><br\/>The first experiment focuses on a monitoring system to detect infrastructure attacks: Currently, the protocol WATCHERS is known to be able to detect almost all attacks on routers, but its behavior under realistic network traffic is unknown. This experiment will ask questions like: What is the effect of monitoring on the infrastructure itself? How do the benefits of monitoring weighed against the cost of monitoring affect the adoption of the service by autonomous network entities?<br\/><br\/>The second experiment is focused on attack mitigation with modified infrastructure services. Specifically, they will investigate how incremental adoption of a DNS protocol modification might affect the global domain name service when both standard and modified protocols operate simultaneously. Key questions are: Does a new infrastructure attack mitigation scheme interfere with the vulnerable service in widespread use? How do the new and old services compete with one another during the adoption phase?<br\/><br\/>The third experiment focuses on distributed private online social networking. The PIs propose to explore deployment of secure and privacy-flexible p2p-client platforms for migrating from a centralized to a decentralized peer-to-peer social on-line network. The PIs are proposing to develop a social caching\/name-resolution server, analogous to DNS for IP networks, to assist the p2p clients (or super peers) connected through GENI as they manage their privacy settings for their communities of interest. Key questions are: how can superpeers identify communities of interest and other social groups? Can they interface with centralized social networking frameworks, like facebook? Can they aid in the protection of privacy of their constituent clients?<br\/><br\/>As for the broader impacts, GENI will be used for experimentation in six security-related university classes. The PIs also participate in the UC Davis COSMOS (Computer Security, Privacy, and Cybervillainy) program, which provides high achieving high school students the opportunity to explore advanced topics in math and science in a university setting. Laboratory experimentation is 30% of the COSMOS program curricula for which GENI will serve as an ideal platform.","title":"GENI: EAGER: GENI Experiments to Explore Adoption of New Security Services","awardID":"1152320","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["562302"],"PO":["564993"]},"186886":{"abstract":"Due to the emergence of ever increasing diversified applications provided by the smart devices such as smart phones, traditional telecommunications systems such as the wireless cellular systems no longer meet the ever exploding traffic demand, and cannot effectively deal with the shortage of available spectrum or congestion over wireless systems. On the other hand, tremendous temporal and spatial network resources, such as spectrum and computational capability, are severely under-utilized. Obviously, how to proactively harvest such residual resources and utilize them opportunistically to support diversified user traffic is an important yet challenging research direction. Although cognitive radio networks are to address this pressing issue, there is lack of viable network architecture in taking full advantage of the opportunistic spectrum access and there exist many practical design issues to be resolved. In this project, the PIs propose a flexible Cognitive Capacity Harvesting (CCH) network architecture to intelligently harvest network resources in both time and space and develop the corresponding technologies to support users' services effectively. Moreover, the CCH network along with the newly developed networking technologies can enable non-cognitive devices to significantly gain benefits from cognitive radio networks and provides innovative approaches to the cognitive radio networks design. Furthermore, this project research opens a new school of thoughts in better utilizing the residual network resources and potentially changes the design approaches for next-generation telecommunications systems. Finally, this project involves the international partners and can enhance the international components in the educational program and prepare more competitive workforce.","title":"NeTS:Collaborative Research: Cognitive Capacity Harvesting Networks","awardID":"1147813","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["560200"],"PO":["557315"]},"198514":{"abstract":"The objective of this research is to develop algorithms and software for treatment planning in intensity modulated radiation therapy under assumption of tumor and healthy organs motion. The current approach to addressing tumor motion in radiation therapy is to treat it as a problem and not as a therapeutic opportunity. However, it is possible that during tumor and healthy organs motion the tumor is better exposed for treatment, allowing for the prescribed dose treatment of the tumor (target) while reducing the exposure of healthy organs to radiation. The approach is to treat tumor and healthy organs motion as an opportunity to improve the treatment outcome, rather than as an obstacle that needs to be overcome. <br\/>Intellectual Merit: The leading intellectual merit of this proposal is to develop treatment planning and delivery algorithms for motion-optimized intensity modulated radiation therapy that exploit differential organ motion to provide a dose distribution that surpasses the static case. This work will show that the proposed motion-optimized IMRT treatment planning paradigm provides superior dose distributions when compared to current state-of-the art motion management protocols. <br\/>Broader Impact: Successful completion of the project will mark a major step for clinical applications of intensity modulated radiation therapy and will help to improve the quality of life of many cancer patients. The results could be integrated within existing devices and could be used for training of students and practitioners. The visualization software for dose accumulation could be used to train medical students in radiation therapy treatment planning.","title":"CPS: Small: Collaborative Research: Tumor and Organs at Risk Motion: An Opportunity for Better DMLC IMRT Delivery Systems","awardID":"1249434","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[532650],"PO":["564728"]},"184489":{"abstract":"IIP 1134684 <br\/>University of Cincinnati; Lee <br\/><br\/>IIP 1134676 <br\/>University of Michigan; Ni <br\/><br\/>IIP 1134721 <br\/>Missouri University of Science and Technology; Sarangapani <br\/><br\/>The NSF Industry\/University Cooperative Research Center (I\/UCRC) on Intelligent <br\/>Maintenance Systems (IMS) was established in 2001. This proposal builds upon the accomplishments of the previous ten years and seeks funding to continue supporting a three campus operation among the University of Cincinnati (leading institution), the University of Michigan, and Missouri Univ. of S&T. <br\/><br\/>The Center addresses the underlying issues in machine degradation modeling and prediction as well as develops the transformational technology in advanced prognostics. Over the past 10 years, the Center has developed systematic methodology and tools that made evident impacts to a number of member companies including Toyota, G.M., Boeing, P&G, and National Instruments, amongst others. Over the next five years, the Center intends to advance the scientific base as well as to validate the developed tools to further accelerate the deployment and commercialization of the developed technologies. The center also plans to have international sites in Singapore, Brazil and Spain. In addition, the Center plans to develop spin-off companies with a compelling Marketing Plan in order to commercialize its tools through its member company, National Instruments, in 2011. <br\/><br\/>The IMS IUCRC fills an important niche to maintain industry global competiveness by continuous improvement of manufacturing effectiveness and efficiency. The center educates students and its membership through an extensive system of internship and scholar exchanges as well as international workshops and courses. IMS has developed and continues to execute an effective system for innovation and IP generation. The Center plans to develop spin-off companies with a compelling Marketing Plan in order to commercialize its tools through its member company, National Instruments, in 2011.","title":"I\/UCRC CGI: Industry\/University Cooperative Research Center for Intelligent Maintenance Systems Center: Five Year Renewal Phase III","awardID":"1134721","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":["523155"],"PO":["564474"]},"186128":{"abstract":"While current cellular networks are based essentially on one-to-many and many-to-one single-hop subnets and cope with inter-cell interference by careful centralized resource planning, future wireless networks must consider heterogeneous environments characterized by user-deployed and user-operated infrastructure in which multiple flows and multiple hops will play an increasingly relevant role. Indeed, such networks are expected to open doors to trillions of dollars of e-commerce, while also providing vast amounts of easily accessible knowledge to the public. Developing a fundamental understanding of multihop multiflow wireless networks is therefore critically important at this time.<br\/><br\/>This exploratory project will seek to discover the fundamentals of such networks by obtaining their information theoretic capacity in an approximated sense. It is expected that scalable and extensible solutions are possible for such networks ranging from the seemingly simple ones involving two hops and two flows to apparently more complex ones involving multiple hops and more than two flows with arbitrary connectivity. In so demonstrating, multiple metrics will be employed. These metrics in the increasing order of accuracy in the high signal-to-noise ratio regime are (a) the fundamental limit on the available signaling (temporal\/spectral\/spatial) dimensions of the network, (b) the fundamental limit on the available signaling and signal-level dimensions, and (c) the capacity to within a (universal) constant number of bits independently of channel parameters.","title":"EAGER: Collaborative Research: CIF: Exploring the Fundamentals of Multihop Multiflow Wireless Networks","awardID":"1144026","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["508378"],"PO":["564924"]},"177306":{"abstract":"Machine learning (ML) has witnessed tremendous success both in establishing firm theoretical foundations and reaching out to major applications ranging from the scientific (e.g. computational biology) to the practical (e.g. financial fraud detection, spam detection). However the reach of machine learning has been hampered by an underlying inductive framework that largely has not evolved from using only labeled instances of concepts (e.g. emails and yes\/no labels on whether they are spam) and its overly simple view of the role of the user or subject matter expert (SME) as a mere provider of the labels for the training instances. However, when instructing humans, teachers provide richer information: Why is an instance of a concept a good positive example? What are key differences between instances belonging to different classes? Which properties are transient and which are invariant? Where should the learner focus attention? What does the current learning task have in common with previously acquired concepts or processes? Answers to such questions not only enrich the learning process, but they also can effectively reduce the hypothesis space and provide significant speed ups in learning than can be achieved with use of class membership feedback only.<br\/><br\/>The aim of this project is to bring this kind of richer interaction into the realm of machine learning by developing frameworks as well as machine learning methods that can take advantage of fuller mixed-initiative communication. In particular, this project aims to develop ML algorithms that can exploit information from SME's such as (1) identification of landmark instances; (2) proposing rules of thumb; (3) providing feedback on similarity of instances; and (4) transfer of similarity measures themselves. This project brings to bear four streams of research: (1) algorithms based on similarity functions and landmark instances; (2) active and \"pro-active\" learning; (3) Bayesian active transfer learning; and (4) learning to cope with temporal evolution in the underlying data distribution. In order to reach practical results, this project focuses on challenges where these new methods are both most needed and likely to prove most effective, such as learning in dynamic environments with concept drift, and where potential for long-term transfer learning is present. Broader impacts include more effective learning by incorporating scientific domain knowledge in eScience, for instance in computational proteomics. Educational and research-community outreach includes participation of graduates and undergraduates from Howard University, for instance in yearly research gatherings involving all students on the project, and reusable open-source methods and data sets.","title":"RI: Medium: Interactive Transfer Learning in Dynamic Environments","awardID":"1065251","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["554195","562859"],"PO":["565035"]},"188449":{"abstract":"Mobile content distribution (MCD) is an important emerging application in vehicular ad hoc networks (VANETs). Its high and stable data rate requirement puts significant stress on the severely bandwidth-limited and highly mobile VANETs. Symbol level network coding (SLNC) provides better error-resilience and in turn higher spatial reusability for wireless transmission. It thus is a promising approach for the very bandwidth-hungry MCD networks. This project focuses on two main fundamental problems related to exploiting SLNC for MCD in VANETs. First, a theoretic study on the network capacity and performance bounds achievable by SLNC in mobile wireless networks is carried out. A new model is proposed to characterize the SLNC operation in a flow network setting. Key factors that impact the achievable throughput are identified. Methods to derive accumulated throughput for a mobile receiver following certain mobility pattern are investigated. The second research focus is on the design of distributed and localized algorithms and protocols for MCD networks using SLNC. A suite of new network protocols for SLNC-based MCD network are proposed in order to maximize the throughput of the MCD network.","title":"NeTS: Small: Collaborative Research: Mobile Content Distribution in Vehicular Ad Hoc Networks","awardID":"1156318","effectiveDate":"2011-09-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564847"],"PO":["557315"]},"187008":{"abstract":"This EAGER supports a process that will lead to the development of a national-scale infrastructure that will enable research on future internets, distributed clouds, and novel, large-scale applications. It has two parts. First, technical and administrative personnel from GENI-enabled campuses will serve as mentors for other campuses wishing to GENI-enable their own networks. This will be accomplished via site visits and then routine advising as the new campuses deploy the technologies necessary to become GENI-enabled. The second part of the project consists of a workshop for all the network engineers working at GENI-enabled campuses as well as those at campuses still wishing to become GENI-enabled. The workshop will be hosted at the next GENI Engineering Conference in November in Kansas City. <br\/><br\/>This project is high-risk high reward; it proposes a strategy for exploratory work to increase the number of GENI-enabled campuses across the country to thirty by the end of 2012. When combined with Internet2's commitment and forthcoming regional network commitments to GENI-enable parts of their backbones, the result could well be a national-scale GENI-enabled experimental network. This work is at a very early stage and the ideas are untested, but if successful, it will have an impact on society that is potentially as significant as that of the Internet. <br\/><br\/>The broader impacts of this project are considerable. Campuses across the country will become part of the GENI network infrastructure, allowing for their researchers to carry out experiments not possible anywhere else on the globe. There is great potential for new technologies of significant scientific and societal importance to be developed. The students on these campuses will be able to 'live in the future' taking computer science and engineering courses that require use of the GENI infrastructure to build prototype distributed cloud systems, new security architectures, or large-scale applications, for example.","title":"Campus Participation in National Scale GENI-enabled Infrastructure","awardID":"1148589","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560207"],"PO":["564993"]},"180892":{"abstract":"Innovation in public health is often bottom up: new processes and technologies are often identified by grassroots and non-governmental organizations and deployed locally before achieving broader use. Mobile technologies have a vast potential to strengthen health systems for under-served populations, but innovation is hindered by the difficulty and expertise required to create robust and deployable solutions. This work seeks to change this state of affairs by providing a set of tools based on commonly available mobile devices that will permit these organizations to easily deploy new health services, supervise their delivery, improve logistics, evaluate their programs' effectiveness, and disseminate their learning and tools to others around the world. The approach is based on cost-realism, namely, the appropriate mix of technology elements to tackle a problem based on a realistic assessment of the solution's sustainability in the community where it will be deployed. Thus, the focus is on using a mix of communication devices that are already likely to be in the possession of a large percentage of the target population such as mobile phones. There will also be experimentation with adding new sensor devices to mobile phones for physiological measurements. This collaborative work includes PATH, an organization uniquely suited to realizing scalable technology solutions in the public health space.<br\/><br\/>The goal of the research is to understand how mobile and cloud software can be constructed to make it easier to deploy modular applications that take advantage of components designed by a large community rather than a monolithic solution that is difficult to extend. In this way, a flourishing ecosystem will be created, much like application markets today, with the added capability of composing modules into larger systems. Evaluation will include both the use of the tools in a public health context as well as the ease with which new information services and systems are built and deployed. Given the wide range of potential applications students will be recruited from a wide variety of disciplines including the University of Washington Medical School, School of Public Health, and Information School and inter-disciplinary projects will be introduced into undergraduate capstone courses.<br\/><br\/>As the work is multi-disciplinary, research results will be as well. The focus is on human-computer interaction, mobile systems, communication, and software engineering. The primary technical challenges are in management of mobile data collection, expanding the sensing\/perception capabilities of mobile phones for health, and architecting distributed information services. Improved methods for organizing data collection campaigns and their sustainable management in terms of both the deployment of instruments on mobile devices and tools to supervise the data collectors themselves will be foremost. Connecting mobile phones and their sensors in a structured arrangement that will allow use of everything from paper and cheap voice\/SMS phones on one end of the spectrum to smartphones and tablets on the other will be a significant contribution to data collection methods. Exploiting standard interfaces and internet protocols between cloud-based modules will formalize the development of data architectures (above basic databases) that embody work processes and sustain management feedback loops.","title":"SHB: Large: Collaborative Research: From the Ground Up -- Mobile Tools for Grassroots Programs in Public Health","awardID":"1114622","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[484727],"PO":["565136"]},"181431":{"abstract":"The goal of this research project is to devise new visualization tools to help scientists gain insight from their high-dimensional data. High-dimensional data are observations with many attributes, on the order of 100s and more. Today's data are often inherently high-dimensional: DNA microarrays, financial tick-by-tick data, hyper-spectral imagery, just to name a few. The challenge in visualizing these data comes from the limited dimensionality of the screen. Traditional data visualization paradigms have inherent inabilities to fully map high-dimensional properties to a two-dimensional display without loss of inherent semantics, patterns or structure. This can lead to ambiguous and even misleading visualizations. To overcome this fundamental chasm, the display system developed in this project uses methods gleaned from illustrative design to communicate these elusive properties, derived from analysis in the high-dimensional data space. A second important motivation of this research is that this illustration-inspired approach are expected to produce visualizations that are easier to interpret and manipulate. <br\/><br\/>The overall theme of this work is to use information abstraction and illustrative mappings to improve display comprehensibility, reduce unnecessary complexity, and communicate high-dimensional data patterns more faithfully. The illustrative framework is driven by a two-pronged data analysis suite that uses filtering to create a data representation at multiple levels of scale and pattern classification to identify suitable appearance illustrations. Both of these analyses are performed in the native high-dimensional data space to preserve the original structures. Various illustrative styles are linked to visual semantics to provide an intuitive data display. The generality of our framework allows it to readily map to the three most prominent high-dimensional visualization platforms: space embeddings, parallel coordinates, and scatter plots. Illustrative visualization design and validation is carried out in collaboration with experts in Environmental Science and the Human Microbiome Project.<br\/><br\/>The system is designed to support domain scientists in knowledge discovery, but also appeal to casual users by supporting data analysis via illustrative design. The display looks more natural since it uses familiar graphics design paradigms to construct the illustrative visualizations. The project webpage (http:\/\/www.cs.sunysb.edu\/~mueller\/IllustratorND) provides information on ongoing progress, invites participation in user studies, and also provides some data analysis capabilities within a web-enabled version of the software. The project offers educational and research opportunities for students.","title":"CGV: Small: Illustration Inspired Visualization: A Gateway to Interacting with High-Dimensional Data","awardID":"1117132","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[486115],"PO":["563751"]},"181321":{"abstract":"The objective of the proposed research is to systematically understand, evaluate and contribute towards the problem of membership inference in aggregate data publishing, a generic, novel, and dangerous privacy threat in a wide variety of real-world applications. The main idea proposed to address the problem of membership inference is an information-theoretic model of privacy disclosure as a noisy communication channel. Based on the channel coding theory and the recent advance in multi-input multi-output (MIMO) communication channels, the proposed research studies novel techniques for membership inference and explores the corresponding privacy-preserving mechanisms.<br\/><br\/>Intellectual Merit: The following salient features distinguish the proposed work from existing studies: (1) the proposed research studies a novel problem of membership inference in aggregate data publishing which stands in sharp contrast to the traditional inference control problem. In particular, the sensitive information in danger of disclosure in the proposed problem definition is the selection attributes of an aggregate query instead of its measure attributes which is the focus on traditional inference control. (2) This novel problem also leads to a set of novel solutions based on information theory. In particular, the propose research studies a model of membership inference attacks as modulation techniques in time and frequency domains for various types of communication channels, e.g., single-input single-output (SISO), multiple-input and single-output (MISO), single-input and multiple-output (SIMO), and multiple-input and multiple-output (MIMO) channels. This proposed channel model enables a uniform evaluation of the effectiveness of both membership inference and privacy-preserving techniques.<br\/><br\/>Broader Impact: The outcome of this research has broader impacts on the nation?s higher education system and high-tech industries. The prospect of sensitive membership information disclosure techniques and privacy-preserving techniques can help the providers of aggregated data publishing, including national health organizations, Internet security service providers, etc., to secure their published data. The broader impact of this project also extends to academia. Parts of this project is carried out by students of George Washington University (GWU), Towson University (TU), and University of Massachusetts, Lowell (UML) as part of advanced class projects or individual research projects.","title":"TC: Small: Collaborative Research: Membership Inference in a Differentially Private World and Beyond","awardID":"1116644","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["539562"],"PO":["562974"]},"181563":{"abstract":"Since the development of its earliest technical foundations more than 40 years ago, the Internet?s dominant communication paradigm has been packet-based, host-to-host communication. However, as the Internet has matured and increasingly more applications have been developed on top of this communication abstraction, there is a growing realization that many user applications are primarily concerned with accessing content rather than communicating with a specific host. In this content-centric view, emphasis is placed on what is obtained rather than from where it is obtained, and content search, dissemination (routing), and storage are consequently of increased importance. Indeed, several 'clean slate' approaches towards Internet architecture have emphasized in-network content naming, search, routing, and storage (including in-network caching ) as key architectural components of a next-generation Internet architecture.<br\/><br\/>Intellectual Merit. This project undertakes fundamental research on developing the modeling and performance evaluation tools\/methodologies, and on designing and evaluating approaches for a key architectural element of these content-centric network architectures - dynamic, demand-driven, in-network, content caching. This effort will develop bounding deterministic performance models of caching networks based on a -characterization of content request streams, probabilistic bounds performance using stochastic bounding techniques, and approximate performance models for networks of caches based on reduced-load approximation techniques. The research will also investigate several simple best-effort algorithms for content-caching and content-location; here, the focus will be on the underlying approaches themselves rather than their embodiment in any particular content-centric network architecture. <br\/><br\/>Broader Impact. The modeling and analysis of in-network caching - a component of many content-centric next generation network architectures - will provide tools and techniques for analyzing such networks in much the same way that network calculi and reduced-load approximations have served as foundations for bounding and approximate analyses of complex queueing and blocking networks that have been used to model a wide range of packet-switched and circuit-switched networks and their protocols. The project's investigation of specific simple, 'best effort' content-caching and content-location algorithms is based on the belief that just as a best-effort Internet service model has proven to be 'good enough' compared with more sophisticated network architectures, best-effort caching may similarly prove 'good enough' when compared to more stateful and more complex request routing and cache-content management approaches. This would be a lesson with far-reaching impact. Graduate research assistants and undergraduate REU students will be mentored as part of this project, helping to educate the next generation of networking researchers. Involvement of minority graduate students will be coordinated through the Northeast Alliance for Graduate Education and the Professoriate (NEAGEP). Research results will be adopted into a widely-disseminated graduate networking course taught at the University of Massachusetts.","title":"NeTS Small: Analysis and Design of Best-Effort Content-Caching Networks","awardID":"1117764","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["499259"],"PO":["565090"]},"180353":{"abstract":"Quantum information science has yielded deep theoretical insights into the nature of information and communication, while raising the hope of dramatically more capable computers and communication networks. But the achievement of these practical goals is hindered by the inherent fragility of quantum information. Traditional approaches for obtaining reliability through simple redundancy do not work; instead, fault tolerance must, and can, in principle, be obtained through subtler techniques that contrive to measure and correct errors without learning anything about the encoded data. <br\/><br\/>Unfortunately present methods for fault-tolerant quantum computation require significant overhead, and present understanding of quantum channel capacities remain very limited. For example, no quantum code is known on which arbitrary fault-tolerant quantum computation can be performed without leaving the code space. And only very recently was it discovered that classical information can be sent at rates exceeding the long-conjectured Holevo bound. <br\/><br\/>This project will attempt to develop new methods for reliable quantum communication and computation in the presence of noise. First, the research will push the capabilities and boundaries of quantum error-correction techniques, both by extending and delineating the types of correctable errors, and by determining the scenarios under which such error correction is or is not possible. The second goal is to develop the deep but heretofore largely unexplored connections between quantum codes, entanglement, and many-body physics, complexity theory, cryptography and high-dimensional geometry. The objective is to advance our understanding both of quantum codes as well as the related areas of mathematics, physics and computer science. Finally the team will seek to elucidate the subtle differences between quantum communication and its closest classical analog---private communication. <br\/><br\/>This research endeavors to contribute definitively to realistic embodiments of large-scale quantum computers, which would dramatically improve mankind's ability to process and communicate information. And the research program itself is deeply interdisciplinary, bringing together physicists, computer scientists and mathematicians from industry and academia, and training students and postdocs.","title":"AF: Large: Collaborative Research: Reliable Quantum Communication and Computation in the Presence of Noise","awardID":"1110941","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[483319,483320],"PO":["565157"]},"182663":{"abstract":"In this Cyberlearning Design and Implementation Project, the University of Massachusetts Lowell (UML) and a non-profit collaborator, Machine Science Inc. of Cambridge,Massachusetts, are studying classroom implementations of a web platform that helps middle school and high school teachers engage their students in collaborative scientific inquiry. This technology -- the Internet System for Networked Sensor Experimentation (iSENSE) -- provides a shared repository of user-contributed classroom activities, such as tabletop science experiments, environmental analyses, engineering projects, and surveys, together with the data generated by these activities. The system features tools that enable teachers and students to create their own experiments, upload and tag data, and configure and share dynamic visual representations of the data.<br\/><br\/>School districts in Massachusetts and New Hampshire are participating in the four-year study. Teachers from each district attend annual summer professional development workshops at UML and receive ongoing support from the project team in integrating iSENSE into their science teaching. Educators participate in follow-up meetings during the academic year to report their experiences and exchange best practices. The most promising approaches are documented as lesson plans and shared with the larger iSENSE community. Throughout the project, researchers from UML's Graduate School of Education are collecting formative data to inform system refinement and curriculum development and to answer questions about integration and use of cyber-enabled learning technologies in classrooms, and conducting a summative assessment to determine the project's impact on student learning and science teaching practice.<br\/><br\/>Project deliverables include a set of iSENSE lesson plans, developed in close consultation with participating educators, together with several significant enhancements to the iSENSE data collection and visualization technology and a set of guidelines and justifications for those guidelines pertaining to developing data scientists and to integrating cyber-enabled learning technologies into classrooms. In particular, the project partners are developing data collection and visualization apps for Android and iOS mobile devices. On the iSENSE website, community-building features are being integrated into the system, giving users the ability to \"follow\" each other's system activity, in the manner of Twitter or Facebook. To foster a sense of community, students and teachers are encouraged to append comments to experiments, data sets, and saved visualizations. This enables them to ask questions relating to ongoing experiments,share resources, suggest further investigations, and critique one another's work.<br\/><br\/>Because iSENSE incorporates many emerging cyberlearning technologies, including interactive data visualizations, on-line community-building features, and the use of mobile computing platforms, the project has broad potential implications for the cyberlearning field. The project team is investigating how interacting with cyberlearning technologies and collaborating on-line changes the way students think about scientific data and the nature of science. The team is also examining how cyberlearning resources, such as user-contributed web content, web-based software tools, and mobile computing platforms, can enhance science teaching practice. At the same time, the investigators seek to identify what resources are needed, in terms of technology, professional development, and curriculum, to effectively support incorporation of sophisticated learning technologies in support of science practice and learning in the classroom.","title":"DIP: Collaborative Research: Transforming Science Learning with an Interactive Web Environment for Data Sharing and Visualization","awardID":"1123998","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[489380],"PO":["562669"]},"181453":{"abstract":"Through the experience of serious illness, patients develop substantial expertise about managing their personal health. When experienced patients (\"mentors\") share their expertise with individuals who are facing a health situation for the first time, they find considerable value is this help. Peer health communities offer a broad base of such \"patient expertise\", yet people can miss out on this valuable resource because, all too often, peer mentoring is difficult to obtain and yields advice that doesn't quite fit one's personal situation or context.<br\/><br\/>The efforts within this project are focused on overcoming this challenge by applying social matching as a technical and intellectual framework for connecting peers for mentorship in online health communities. In partnership with an online cancer community, the investigators are conducting a series of three studies that: (1) Identifying critical mentorship characteristics through a comparative study of automated text extraction as contrasted with to direct user entry of data, (2) Developing tools that connect peers for mentorship through rapid prototyping and usability testing with cancer patients, and (3) Assessing the value of matching for peer mentoring through an online community-based field evaluation.<br\/><br\/>The results from this research are expected to significantly improve the way people obtain peer help when faced with a health problem. Through a deeper understanding of patients' support needs, this project will use rich online community data to provide tailored recommendations of suitable peer mentors. This work advances knowledge of collaboration in online communities broadly and will translate to other patient services, such as face-to-face support groups. These contributions are significant because they offer patients crucial support strategies in an increasingly burdened healthcare system. Matchmaking among individuals with shared circumstances helps newcomers glean tailored insights into \"what to expect\" and helps those with experience to share their valuable expertise by \"giving back\". Thus, this work boosts our current understanding of the underlying processes and informs future research and development in technology that enhances the health and wellbeing of citizens by empowering peer mentorship.","title":"SHB: Small: Facilitating Mentoring in Peer Health Communities through Social Matching","awardID":"1117187","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[486167,"543781",486169],"PO":["564316"]},"181574":{"abstract":"Robots are increasingly becoming a part of daily human interactions: They vacuum floors, deliver medicine in hospitals, and provide company for elderly and disabled individuals. This project examines one aspect of people's interactions with these robots: how intentional and self-reflective the robot seems to be. Because the perceived agency of a robot affects many dimensions of people's interactions with that robot, it is important to understand how features of robot design, such as its behavior and cognitive abilities, affect perceptions of agency. This question is addressed through a series of laboratory experiments that manipulate behavior and cognitive abilities and measure the degree of agency attributed to socially interactive robots.<br\/><br\/>Intellectual merit: The project will lead to new measures of perceived robot agency and new knowledge about how people collaborate with robots. The results will inform how engineers construct robots, how artificial intelligence researchers conceptualize behavioral architectures, and how designers craft interactions to produce robots that engage people in simple ways.<br\/><br\/>Broader impacts: The project will provide a new quantitative measurement of agency that can be used in human-robot interaction and related disciplines and new information that can inform how agency is modeled in the design of human-robot interactions, especially in situations where recognition of agency is a primary factor. The outcomes will be used to improve socially assistive robotics for children with social deficits. The project will also enhance interdisciplinary research offerings for graduate and undergraduate students at the investigators' institution.","title":"HCC: Small: Manipulating Perceptions of Robot Agency","awardID":"1117801","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["497125"],"PO":["565227"]},"180364":{"abstract":"This research will involve designing, implementing, and evaluating computational tools to support frame reflection in processes of online political engagement. The internet, social media, and online communication have great potential as a platform for political engagement, from seeking political information to participating in political discussion and deliberation. The wealth of content available via the web can make for more informed discussion, and the fact that discussion can take place on a much larger scale than face-to-face forums offers the potential for participation by many and diverse groups. However, thus far, online political participation has not proven radically democratic. Rather, it has tended to reproduce preexisting inequalities and balkanization in political talk. The constantly and rapidly increasing quantity of political content produced on a daily basis can also be difficult to understand and evaluate, particularly with respect to how issues are framed. The latter is especially important given the fact that, as numerous researchers have shown, how issues are framed - that is, how they are formulated in terms of familiar assumptions, metaphors, and images - profoundly affects how citizens understand, assess, and act upon those issues.<br\/><br\/>This project will both leverage existing computational techniques and develop novel analytic approaches to encourage citizens to identify and evaluate the frames that underpin competing positions on issues. Through evaluation in two real-world settings, public deliberative forums and readers of political blogs, this work will make two distinct sets of contributions. First, this project will develop human-computer interaction design principles for interactive tools and visualizations involving complex computational techniques. These principles will help ensure that such tools are designed to be useful for, comprehensible to, and interpretable by users. Second, by examining the impacts of various computational interventions, this work will enhance political and social scientific understanding of online political deliberation, both in terms of how technology mediates the deliberative process, and in terms of how deliberation can be improved through increased awareness of and reflection about framing.<br\/><br\/>The immediate impacts of this research will take the form of tools deployed in real-world settings with politically engaged users, namely through a partnership with a non-partisan convener of online forums, and through public deployment among readers of political blogs. Additionally, the tools developed in this project will be made readily available for use by others, either in support of political deliberative processes or in other contexts. In the long term, the work has significant potential to improve understanding of political deliberation, and it provides an opportunity to explore alternative roles that technology can play in supporting political participation.","title":"Collaborative Research: Improving Online Deliberation with Computational Supports for Frame Reflection","awardID":"1110981","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[483355],"PO":["564456"]},"180485":{"abstract":"This collaborative research project leverages expertise of four research teams (IIS-1111415, Massachusetts Institute of Technology; IIS-1110955, Harvard University; IIS-1111398, Washington University; and IIS-1111534, Cornell University). Understanding time-varying processes and phenomena is fundamental to science and engineering. Due to tremendous progress in digital photography, images and videos (including images from webcams, time- lapse photography captured by scientists, surveillance videos, and Internet photo collections) are becoming an important source of information about our dynamic world. However, techniques for automated understanding and visualization of time-varying processes from images or videos are scarce and underdeveloped, requiring fundamental new models and algorithms for representing changes over time. This research involves creating systems that enable modeling, analysis, and visualization of time-varying processes based on image data. These models and algorithms will form the basis for a new set of tools that can help answer important questions about how our environment is changing, how our cities are evolving, and what significant events are happening around the world.<br\/><br\/>Analyzing images over time poses fundamental new technical challenges. This project focuses on developing and demonstrating end-to-end systems consisting of (1) novel representations necessary to model time-varying image datasets; (2) algorithms for estimating long-range temporal correspondence in image datasets; (3) algorithms for decomposing image datasets into intuitive primitives such as shading, illumination, reflectance, and motion; (4) analysis tools for deriving higher level information from the decomposed representations (e.g., trends, repeated patterns, and unusual events); and (5) tools for visualization of the high-level information and methods for re-synthesis of image data.<br\/><br\/>This work has the potential to have significant impact in a broad range of areas where images are generated over time, e.g., in ecology, astronomy, urban planning, health, and many others. The results of this research will be broadly disseminated by making source code and datasets publicly available via the project web site (https:\/\/groups.csail.mit.edu\/vision\/image_time\/) and offering tutorials and organizing workshops at significant conferences. The project provides educational opportunities and offers hands-on collaborative research experience to students at both the undergraduate and graduate levels and the four institutions.","title":"CGV: Large: Collaborative Research: Analyzing Images Through Time","awardID":"1111534","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["502048"],"PO":["563751"]},"181101":{"abstract":"The ascension of power, to join time and space, in the top ranks of scarce computational resources is relatively recent. Over the last several decades, when time and space were the key computational resources, computer science researchers developed many algorithmic techniques for designing time and space efficient algorithms, and for analyzing the time and space required by particular algorithms on simple models. The immediate goal of this research is to build a toolkit of widely applicable algorithmic design and analysis techniques for algorithmic problems where energy, power and temperature are the key resources. This will require the discovery of new algorithmic techniques, as these energy related resources have different physical characteristics than the resources of time and space.<br\/><br\/>Energy-efficient computing and power management are two important focus areas within green computing, which is the study and practice of designing, manufacturing, using, and disposing of computers, servers, and associated subsystems, efficiently and effectively with minimal impact on the environment. Currently the energy usage of information technology is roughly comparable to that used by the airline industry. On one hand, given that the growth of information technology is still exponential, this fraction could grow significantly if there are no changes in information technology. On the other hand, given that until recently energy efficiency wasn't a first order design constraint, an order of magnitude improvements in the energy efficiency of information technology is possible.<br\/><br\/>A long term goal of this research is to build a science of algorithmic power management to support the computing community's ability to abstractly reason about power, energy and temperature. This science will serve these software engineers, when faced with information technology design problems in which power\/energy\/temperature is the key scarce resource, just as the science of algorithms serves them when they are concerned with the resources of time and space.","title":"AF: Small: Green Computing Algorithmics","awardID":"1115575","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["534213"],"PO":["565251"]},"181222":{"abstract":"This research aims at developing new theories and techniques to<br\/>better understand and manage shared memory cache in multi-core architectures. <br\/>The core concept is program footprint, which is the amount of memory access in a period of<br\/>execution. Complete measurement requires counting data access in all<br\/>execution windows, which is too costly. This<br\/>research develops computational methods to first make all-window<br\/>analysis feasible through a set of new profiling algorithms and then<br\/>make this analysis cost-effective by reducing the cost through statistical<br\/>inference, sampling, and parallel profiling and effectively obtaining<br\/>this information in real time as a program executes. Footprint<br\/>information is essential in analyzing cache sharing between programs<br\/>and program tasks. It enables the second part of the project, a set<br\/>of tools that predict the performance of parallel workloads without<br\/>parallel testing. In addition, the footprint information enables a<br\/>fundamentally different approach to common techniques. In the third<br\/>part, the project develops a new cache-hint insertion tool to<br\/>approximate optimal caching and a<br\/>memory-performance tuning tool to be used by software developer.<br\/><br\/>As multi-core processors become commonplace and cloud computing is<br\/>gaining acceptance, more applications are run in a shared environment.<br\/>The outcome of this research will fundamentally alter the way<br\/>programmers understand and improve memory performance on multi-core<br\/>systems. Software developers and hardware engineers will have a new<br\/>tool set to tackle the complex problem of managing on-chip memory for<br\/>not just sequential but also parallel code and for not just achieving<br\/>good performance but also for ensuring stable performance in a dynamic<br\/>environment. The broader impacts of this research will include<br\/>deeper understanding and more precise characterization of locality<br\/>in computational processes, which has implications in other<br\/>computing-related disciplines, and memory efficient software and<br\/>hardware design, which saves energy and cost and has broad economical<br\/>and social benefits.","title":"SHF: Small: Footprint Models and Techniques for Multi-core Cache Management","awardID":"1116104","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["550486"],"PO":["366560"]},"182795":{"abstract":"Intellectual merit: This project is awarded under the Nanoelectronics for 2020 and Beyond competition, with support by multiple Directorates and Divisions at the National Science Foundation as well as by the Nanoelectronics Research Initiative of the Semiconductor Research Corporation. The complementary metal oxide semiconductor field effect transistor, considered the workhorse of modern computing machinery, is inherently energy-inefficient because it is a charge-based digital switch. In contrast, a single-domain nanomagnet with uniaxial shape anisotropy, that encodes binary bits in its magnetization orientation, is much more energy-efficient because it is a spin-based switch in which the spins internally interact. Therefore, magnetic computing circuits hold a potential advantage over their electronic counterparts. That advantage however will be lost if the methodology used to switch the magnet becomes so energy-inefficient that it adds an exorbitant energy overhead. To this end, a hybrid spintronic\/straintronic paradigm for switching magnets has been developed that reduces the energy dissipation by several orders of magnitude and heralds an ultra-energy-efficient magnetic computing and signal processing architecture. This project will: (1) develop all the modeling tools necessary to simulate these devices and their switching dynamics. They will incorporate the effects of device and circuit stochasticity and thermal fluctuations via appropriate models such as stochastic Landau-Lifshitz-Gilbert equations and\/or Fokker-Planck equations; (2) demonstrate Bennett clocking and successful logic bit propagation in a digital gate array fabricated with nanolithography, where clocking is carried out with tiny voltages generating strain; (3) design energy-efficient neuromorphic architectures based on multi-state hybrid spintronic\/straintronic synapses and neurons that can process analog signals; and (4) demonstrate image processing with straintronic\/spintronic nodes communicating via spin waves to implement specific image morphing algorithms. These image processors will be extremely fast since they will rely on the physics of magnetic interactions between spin wave circuits and the collective activity of multiferroic magnetic cells to elicit the required functionality, without requiring any software or execution of instruction sets. <br\/><br\/>Broader Impact: The proposed research will potentially impact all areas of computing and signal processing. Computers employing the hybrid spintronics\/straintronics approach can be so energy-efficient that they could operate by harvesting energy from the surroundings, without requiring a battery. Thus, they have unprecedented applications in medical devices implanted in an epileptic patient?s brain to monitor brain signals and warn of an impending seizure. They can run by harvesting energy from the patient?s body motion alone. They also have other applications in areas such as structural health monitoring where they can constantly monitor fatigue and fracture propagation in bridges and buildings, while harvesting energy from vibrations induced by wind or passing traffic. Integration of this research with education will entail traditional graduate and undergraduate student training, while minority enrichment will involve training high-school students recruited through the Richmond Area Program for Minorities in Engineering at Virginia Commonwealth University, minority outreach centers at University of California-Riverside, Office of Engineering Outreach and Engagement at Michigan, and the Center for Diversity in Engineering at University of Virginia. K-12 outreach will leverage the Math and Science Innovation Center at Richmond and the Summer Discovery Program at Virginia Commonwealth University. New graduate course material will be developed at each participating institution and disseminated through textbooks, tutorials and the worldwide web.","title":"NEB: Hybrid Spintronics and Straintronics: A New Technology for Ultra-Low Energy Computing and Signal Processing Beyond the Year 2020.","awardID":"1124714","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}}],"PIcoPI":["541220","521045","524905","541221","516336"],"PO":["564454"]},"181585":{"abstract":"The oceans cover 71% of the earth's surface and represent one of the least explored frontiers, yet the oceans are integral to climate regulation, nutrient production, oil retrieval, and transportation. Future scientific and technological efforts to achieve better understanding of oceans and water-related applications will rely heavily on our ability to communicate reliably between instruments, vehicles (manned and unmanned), human operators, platforms, and sensors of all types. The glue of such underwater networks will be the underwater acoustic communication link. Despite recent activity on acoustic physical layer single-links, digital acoustic communication is in its infancy in comparison to comparable efforts for radio-based terrestrial wireless communication. This project exploits the unique features of the underwater acoustic channel to significantly improve performance of underwater networks. <br\/><br\/>The research focus is on design for the inherently multi-scale, multipath channels in this wideband environment. Surprisingly, transceiver design for the coupled efforts of wideband channels and distinct Doppler scales for practical underwater communication systems does not appear to have been thoroughly investigated. The network is examined from the perspective of individual links up to entire networks of multiple nodes, encompassing novel multi-scale, multi-lag channel modeling, waveform design, equalizer designs, channel estimation, single-link and network capacity evaluation, novel coding to achieve capacity, as well as signaling and routing over large-scale networks. In a principled manner, the fundamental properties of multi-scale, multipath channels are explored in order to design and analyze high performance underwater acoustic networks. Implementable algorithms are designed which endeavor to achieve the fundamental limits. The research outcomes will also impact ultrasound, ultrawideband, wideband radar, sonar, acoustic signal processing, and moderate to high speed vehicle-to-vehicle (V2V) communication and possibly understanding of biosonar.","title":"CIF: Small: Multiscale Methods for Mobile Underwater Networks","awardID":"1117896","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["515828"],"PO":["564898"]},"180496":{"abstract":"This collaborative research investigates a new class of dialog-based, home robotic healthcare assistants to facilitate a new level of in-home, real-time care to elderly and depressed patients, providing lower total costs and higher quality of life. An emotive, physical avatar, called a companionbot, which possesses the ability to engage humans in a way that is unobtrusive and suspends disbelief will be built in this project. The companionbot will be an integration of human language technology, vision, other sensory processing and emotive robotic technology to proactively recognize and dialog with isolated and elderly patients suffering from depression. The companionbot will utilize proactive or companionable dialog based on the context with users suffering from depression. This will require the first multimodal integration of a user model, environment model, and temporal processing with spoken dialog understanding and generation to produce dynamic dialog and emotive interaction, beyond the traditional scripted dialog and emotion. Object recognition, facial expression recognition, and human activity recognition will augment natural language processing to provide current and historical context important to dynamic dialog. <br\/><br\/>A team of skilled researchers, assembled from the University of Colorado Boulder, University of Denver, CU Anschutz Medical Campus, and Boulder Language Technologies, will work together to achieve the project goals. The investigators will use the companionbots as a tool to run clinical trials to monitor and dialog with their partners to detect signs of physical and emotional deterioration. The companionbots can then notify remote caregivers, as necessary, provide warnings, reminders, life coaching and therapeutic dialog, extending independence and quality of life, and even saving lives. The other benefits of such a system include continuous, annotated data to improve doctor-patient interaction and analysis, real-time monitoring of mental state for remote healthcare providers and, ultimately, real-time intervention as part of a comprehensive treatment strategy.<br\/><br\/>In addition, this research will promote both STEM practice and research education at the graduate and the undergraduate levels of the affiliated institutions. The companionbots are ideal for teaching the next generation of engineers and scientists in critical emerging technologies, as they permit either a deep focus on specific topics or an interdisciplinary perspective while providing a simple high-level interface to manage everything else. Furthermore, the project will develop related educational material to support others and will provide public outreach to K-12 classes in the area.","title":"SHB: Large: Collaborative Research: Companionbots for Proactive Therapeutic Dialog on Depression","awardID":"1111568","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["522995"],"PO":["565136"]},"181475":{"abstract":"The world's population is growing older; it is estimated that in 2050 there will be three times more people over the age 85 than there are today. Many are expected to need physical and cognitive assistance, and all will need additional healthcare. Shortages in primary care physicians, nurses, and managed care facility space and staff are already an issue today, creating a niche for assistive technologies to fill the care gap. A growing body of research shows that certain behavior patterns have a positive impact on longevity and wellness, including regular physical exercise, social interaction, and cognitive engagement. This project aims to develop and evaluate socially assistive human-machine interaction techniques that influence the user to engage in and comply with wellness-promoting behaviors in the home or nursing home in order to enhance longevity and quality of life.<br\/>This work is focused on developing socially assistive systems (SAS) using peer-level human-machine interaction in which the machine serves in the role of a knowledgeable embodied agent capable of providing time-extended, sustained, and engaging interaction. The research focuses on two types of wellness-promoting human-machine interactions: 1) exercise sessions (cognitive and\/or physical) and 2) socializing sessions. For one-on-one exercise sessions, the project is developing SAS capabilities that provide exercise monitoring, coaching, and motivation. For socialization, the research is developing SAS capabilities that provide social interaction and friendly reminders and encouragement to comply with health regimens (taking medicine, being physically active) and healthy habits (calling family, meeting friends). The two types of interactions share the common goal of influencing human behavior, and the main contribution of the research is the set of methods and algorithms for influencing behavior though human-machine interaction. This is achieved through a novel two-fold approach: 1) adaptive interaction steering for short-term interactions, and 2) motivation and coaching of behavior in longer-term interactions to maintain engagement and enhance task performance. The embodiment of the SAS is leveraged to maximize engagement and compliance; a key focus of the work is on developing a comprehensive method for natural, persuasive and engaging embodied communication. The methods and algorithms being developed are general, and will be implemented and tested on both computer-based and robot-based agents. In this way the work validates the developed methods on multiple technology platforms and embodiments, and compares their relative effectiveness and acceptability by the intended user population. The specifics of the implementation are informed by an early focus group with elderly participants, the target user population. The developed techniques are being implemented in both human-computer interaction (HCI) and human-robot interaction (HRI) versions, and are being evaluated with a large group of elderly users interacting with the SAS implementations over a multi-week user study. The work is focused on generating methods, algorithms, and a large corpus of multi-modal data (video, audio, and questionnaires) for grounding continued research into health and wellness-relevant HRI and HCI.<br\/> This project aims to address a component of the nationally recognized healthcare challenge of promoting wellness and longevity in the aging population. Beyond basic algorithm and method development, the project implements and tests real-world socially assistive systems, both computer-based and robot-based, with a large population of elderly retirement home residents. The project is expected to produce insights useful for both research and healthcare product development for addressing this growing segment of the population. In addition to the socially relevant research focus, the project team is also engaged in a comprehensive program of K-12 outreach activities, which use robotics to promote STEM topic learning using the health theme of the proposal. The project involves inner city K-12 teachers and students in annual open houses, assemblies, and workshops that provide hands-on experiences with assistive systems for the elderly, as well as take-home materials for continued learning. The project team includes PhD students, undergraduates, and K-12 volunteers, and establishes a mentoring pipeline so that university students are both mentored and serve as mentors and role models for their younger peers.","title":"SHB: Small: Socially Assistive Human-Machine Interaction for Improved Compliance and Health Outcomes","awardID":"1117279","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["558935"],"PO":["564768"]},"180386":{"abstract":"This project will exploit algebraic properties of operators associated with graphs in an integrated set of research and educational activities designed to develop new mathematical and algorithmic techniques; apply these to the solution of real-world problems and longstanding theoretical questions in mathematics, computer science, biology, and physics; and make these techniques broadly known and accessible to students, researchers, and practitioners in many fields.<br\/><br\/>This research has its origins in spectral graph theory, which studies how the eigenvalues and eigenvectors of the graph Laplacian (and other related matrices) interact with the combinatorial structure of the graph. Spectral graph theory has been one of the great success stories in both the theory and practice of algorithm design. It has led to fundamental advances in graph partitioning, web search (notably including Google's PageRank algorithm), the understanding of random processes and the algorithms derived from them, the construction of error correcting codes, derandomization, convex optimization, machine learning, and many others.<br\/><br\/>While the eigenvalues and eigenvectors of the Laplacian capture a striking amount of the structure of the graph, they certainly do not capture all of it. Recent work by the principal investigators and other researchers suggests that theoretical computer scientists have only scratched the surface of what can be done if they are willing to broaden their investigation, extending it to study more general algebraic properties of the Laplacian than just its eigenvalue structure, and more general operators than just the Laplacian.<br\/><br\/>Under this award, the principal investigators will build a research program across the three universities involved in this proposal to develop such a theory and its applications. This initiative has the potential to provide transformative advances in a range of theoretical and applied areas of computer science, including:<br\/><br\/>* Faster algorithms for fundamental graph problems, such as Maximum Flow, Minimum Cut, Minimum Cost Flow, Multicommodity Flow, approximating Sparsest Cut, generating random spanning trees, and constructing low-stretch spaning trees.<br\/><br\/>* Better algorithms for the analysis of data, with potential applications to the Unique Games Conjecture.<br\/><br\/>* Faster algorithms for solving broad classes of important linear systems, both sequentially and in parallel.<br\/><br\/>* Faster distributed algorithms for information dissemination in networks.<br\/><br\/>* A spectral and algebraic graph theory for directed graphs, based on ideas from differential geometry.<br\/><br\/>* Novel quantum algorithms for a large class of problems that appear to be hard for classical computers.<br\/><br\/>* New techniques for problems in Quantum Physics based on ideas developed in Computer Science and Combinatorics.<br\/><br\/>The principal investigators will also work to disseminate these techniques by developing courses, training undergraduate and graduate students, and introducing these ideas to scientists in other fields.","title":"AF: Large: Collaborative Research: Algebraic Graph Algorithms: The Laplacian and Beyond","awardID":"1111109","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[483418],"PO":["565157"]},"181244":{"abstract":"This project develops (1) develops hardware platforms for persistent underwater observations, (2) develops adaptive sampling algorithms, (3) develops efficient data storage and access algorithms for sensor networks with slow broadcast rates, and (4) supports investigation of specific important environmental issues such as the interaction of rainfall events through the landscape to deliver sediment and nutrients to the near-shore and lagoon, ultimately affecting the coral reef. Specifically, the project contributes a new class of modular underwater robots and systems with increased agility in motion and effective data collection and retrieval and a science-base for coordinating underwater robots and sensors to provide a provably-correct foundation for applications to marine observations. Novel decentralized algorithms coordinate a group of robots and sensors for three related problems: sensor placement, event detection and tracking, and adaptive sampling, along with a unified framework for analyzing the stability and convergence of these algorithms.<br\/><br\/>Persistent underwater monitoring is deployable in any coastal environment and provides automation for collecting data in support of many environmental hypotheses. The same capabilities can also be used in the context of coastal and harbor protection operation, locating underwater mines and identifying intrusion. The underwater technology enables an unprecedented level of automation for environmental monitoring in water. The project impacts education through instructional and outreach activities aimed at developing and sharing a new curriculum that brings robotics technology together with marine biology through application, workshops, and tools. The project contributes designs and software for affordable and usable underwater robot and sensor platforms.","title":"RI: Small: Collaborative Research:Adaptive Sampling with Robots for Marine Observations","awardID":"1116221","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["517754"],"PO":["564069"]},"181365":{"abstract":"The improvements in manufacturing processes for silicon integrated circuits, through the reduction in transistor and interconnect sizes, also give rise to integrated circuits that will wear out if not designed and used properly. That is, they will fail to continue to work over a long period due to factors such as increased operating power and temperature, and un-ideal scaling effects as the sizes are reduced. The number of failures, when left uncompensated, is expected to grow exponentially. Thus, the increasing wear-out failure rates will require design-for-lifetime reliability methodologies for all systems, not just those with safety critical missions. <br\/><br\/>A novel design-for-reliability methodology to aid in the design of cost-effective lifetime-enhanced systems is being developed for embedded computing applications. The systems being designed are multiprocessors that are interconnected with a network on the chip. Network switches in the network are used to route information among the processors. The design methodology includes choosing the number of switches and their interconnection, choosing the types of processors and memories to be connected to the switches, selecting which processors the software programs will run on, and selecting the voltage and clock rate that each of the processors will operate at. Each of these design decisions can have a major impact on the lifetime of an integrated circuit. <br\/><br\/>The design methodology requires searching through an enormously large set of design alternatives, each requiring a computationally expensive calculation of the mean-time-to-failure for the system being designed. An ant colony based optimization technique is used to explore this large design space and hardware acceleration techniques, such as graphics processing units and field programmable gate arrays, are used to speed the mean-time-to-failure calculations. <br\/><br\/>The application of embedded single-chip multiprocessing systems will continue to grow across a broad spectrum of applications from personal computing devices, to biological monitoring systems, to consumer electronics. This continued growth in embedded computing applications is a major driver in the economy as it improves personal productivity. This research enables deeper scaling in the manufacturing process, and thus more capable systems, since these new integrated circuits will continue to be implementable even when individual components within them are expected to fail early or possibly are not fully working when manufactured. The research results will be disseminated through graduate courses and research articles, with some topics being introduced into a Junior\/Senior level course.","title":"SHF: Small: Lifetime Aware System Architecture Design of Single-Chip Embedded Multiprocessors","awardID":"1116856","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["507772"],"PO":["366560"]},"182696":{"abstract":"Researchers are seeking to understand the roles that school libraries, school librarians, and virtual peer networks (VPNs) can play in helping middle-school students become interested in STEM, imagine themselves in STEM careers, and see themselves as interested-in-science people. In four different schools, youngsters recruited by science teachers (those especially interested in science), English teachers (those especially interested in story telling and writing), and librarians (those who are especially inquisitive) are participating together in an after-school program to learn how to compose science-related stories and use a variety of media for that purpose. Members of each community support each other in writing and in learning. The software registers their \"collaborators\" and helps them keep track of the expertise of community members. Design of the socio-technical system (software, story-telling activities, mentors) is informed by the literature on identity formation, identity formation environments, and roles of social networking.<br\/><br\/>Non-white students are not choosing STEM careers; low-socio-economic-status students have limited access to resources and technology that can help them have imaginations about STEM interests and careers, and many of these same youngsters are also missing role models who could help them envision themselves in STEM careers. This project focuses on development of future scientists through development of after-school programming and an on-line virtual peer network (VPN) aimed toward helping participants think about themselves as science-interested people. Focusing on libraries as a venue for promoting STEM-identity formation and librarians as mentors offers a new and promising model for connecting formal and informal learning opportunities.","title":"EXP: Developing Science, Technology, Engineering, and Math ( STEM) Identities through Participation in Science-Infused Media and Virtual Peer Networks","awardID":"1124176","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":["552303",489476,"518152","547983"],"PO":["562669"]},"173632":{"abstract":"This project establishes a partnership between Santa Clara University (SCU) and several surrounding high schools with a high percentage of under-represented and economically disadvantaged students in the Santa Clara Valley of California. The goals of the project are to improve the communication, instruction, and teamwork skills of SCU graduate engineering students (fellows), to strengthen teachers' knowledge of computer science, to raise awareness of the societal and global context of computing among students, and to increase their interest and skill in computational thinking.<br\/><br\/>High school teachers and graduate student fellows will receive training for the Exploring Computer Science course, and fellows will be given instruction on pedagogy and the challenges of a high school classroom environment. The fellows will then work with the teachers in the high school classrooms, serving as role models to students and facilitating their engagement with the subject matter.<br\/><br\/>This three-year partnership between SCU and surrounding high schools broadens the education of graduate engineering students, strengthens high school teachers? expertise in computing, introduces high school students to the breadth of computing and its impact on their lives, and ultimately increases the supply and diversity of graduates ready to enter the IT workforce.","title":"New GK-12: A Symbiotic Exploration of Computer Science in High School Classrooms","awardID":"1045434","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":["555558",465871,465872,465873],"PO":["559975"]},"181376":{"abstract":"At the core of many of the tasks we need computers to solve lie a collection of important, though difficult, optimization problems. These problems can be hard to solve optimally, and as a result they have typically been attacked through two distinct approaches. The first is to construct algorithms with provable worst-case approximation guarantees. This approach has the advantage of provable guarantees but the disadvantage that these guarantees can be fairly poor. The second approach is to develop natural heuristics and to test them on benchmark problems. This approach has the advantage of producing techniques that can work well in practical settings similar to the benchmarks, but the disadvantage that the conditions needed for good performance are often not well understood. This project aims to bridge the gap between these approaches: to develop new theoretical foundations for the analysis of non-worst-case guarantees, as well as new tools for the design of formally-justified heuristics.<br\/><br\/>Specifically, this project will pursue four main directions. The first is the analysis of implicit assumptions in problem formulations. Often the objective function used in an optimization problem is a proxy for a goal that cannot be directly measured by the algorithm, and thus the instance already needs to have the property that these two are related. This relation is often not explicitly stated and yet can potentially provide usable structure an algorithm can use. The second is analysis of natural conditions on inputs due to how they are constructed. For example, if certain parts of the instance given to the algorithm are the result of noisy measurements, then the algorithm can be flexible to their exact values. The third is development of fast methods to test the \"niceness\" of an instance, which can then be used in the selection of an appropriate algorithm for that instance. Finally, the last direction is the development of algorithms that provide a smooth transition between their performance on stable and unstable instances with applications to privacy-preserving data analysis.","title":"AF: Small: Frameworks for Design and Analysis of Heuristics","awardID":"1116892","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["554195"],"PO":["565251"]},"181266":{"abstract":"A mobile health monitoring system generates and monitors data related to a patient?s health using a wireless or wired channel. It may also control dosages of medicine or alter the behavior of medical devices to preserve a patient?s health. Such continuous monitoring and control gives mobile health monitoring systems the promise of improving health for lower costs than traditional methods. The security of mobile health monitoring systems is critical because of the importance of their tasks and the vulnerability of the devices and their operating environments. Such devices are sometimes used in hospitals or other health care facilities, but more often in patients? homes, offices, and other ordinary environments whose physical and cyber security cannot be controlled. The security of widely used mobile health monitoring devices is badly flawed. This danger will be addressed by adding security mechanisms to the overall system and environment in which mobile medical health devices operate. While less effective and efficient than designing such devices properly in the first place, there are reasonable low-cost solutions that can substantially improve the safety and security of such devices.","title":"TC: Small: Protecting Wireless Medical Devices","awardID":"1116371","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["547185","485932"],"PO":["564223"]},"181387":{"abstract":"In this project, the PIs study secure computation outsourcing in cloud computing with the focus on widely applicable engineering computing and optimization problems. Their methodology is to explicitly decompose computations into public programs and private data and leverage the structures of specific computations for achieving desirable trade-offs among security, efficiency, and practicality. <br\/><br\/>The PIs propose to organize the mechanisms into a hierarchy where computation can be represented at various abstraction levels, and then explore a systematic methodology consisting of the following three methods: (1) problem transformations that encrypt the data such that the computation can be performed on the same abstraction level, (2) procedure transformations that leverage the mechanisms defined at a lower abstraction level as a subroutine for secure computation outsourcing, and (3) structural-preserving transformations that further improve the practical efficiency of mechanisms by maintaining favorable problem structures.<br\/><br\/>The PIs expect the outcomes of this research to be adopted by application developers, who will build applications to support secure computation outsourcing either privately for end-users within the same organization, or for public end-users resembling the practices of software-as-a-service (SaaS).","title":"CSR: Small: Collaborative Research: Engineering Secure Data Computation Outsourcing in Cloud Computing","awardID":"1116939","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["174082","174082","565164","565164"],"PO":["565255"]},"184665":{"abstract":"The electric grid in the United States has evolved over the past century from a series of small independent community-based systems to one of the largest and most complex cyber-physical systems today. However, the established conditions that made the electric grid an engineering marvel are being challenged by major changes, the most important being a worldwide effort to mitigate climate change by reducing carbon emissions.<br\/><br\/>This research investigates key aspects of a computation and information foundation for future cyber-physical energy systems?the smart grids. The overall project objective is to support high penetrations of renewable energy sources, community based micro-grids, and the widespread use of electric cars and smart appliances.<br\/><br\/>The research has three interconnected components that, collectively, address issues of computation architecture, information hierarchy, and experimental modeling and validation. On computation architecture, the framework based on cloud computing is investigated for the scalable, consistent, and secure operations of smart grids. The research aims to quantify fundamental design tradeoffs among scalability, data consistency, security, and trustworthiness for emerging applications of smart grids. On information hierarchy, temporal and spatial characteristics of information hierarchy are investigated with the goal of gaining a foundational understanding on how information should be partitioned, collected, distributed, compressed, and aggregated. The research also develops an open and scalable experimental platform (SmartGridLab) for empirical investigations and testing of algorithms and concepts developed in this project. SmartGridLab integrates the hardware testbed with a software simulator so that software virtual nodes can interact with physical nodes in the testbed. This research also includes a significant education component aimed at integrating frontier research with undergraduate and graduate curricula.","title":"CPS:Medium:Collaborative Research:Information and Computation Hierarchy for Smart Grids","awardID":"1135814","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["542417"],"PO":["565239"]},"183455":{"abstract":"The Global Environment for Network Innovations (GENI) is a suite of research infrastructure rapidly taking shape in prototype form across the United States. GENI aims to transform experimental research in networking and distributed systems, as well as emerging research into very large socio-technical systems, by providing a suite of infrastructure for at-scale experiments in future internets. Nationwide experiments began in summer 2010, and GENI now supports a wide range of interesting research experiments across the nationwide meso-scale GENI prototype, built from GENI-enabled commercial equipment, that spans 14 US campuses and the two national research backbones (Internet2, National Lambda Rail [NLR]). Research teams presented 9 major demonstrations of live, nationwide experiments at the 9th GENI Engineering Conference in November 2010. About 20 research experiments are now starting to drive GENI?s evolving design.<br\/><br\/>This project will fund the third round of development and prototyping for GENI, effectively completing the transition from building GENI to using GENI for at-scale research. This effort includes 1) enhancing the meso-scale build-out to include six major regional research networks across sixteen states, connecting campuses to Internet2 an NLR; 2) increasing the campus WiMAX deployments via multi-cell sites, android handsets and vehicular experiments; 3) creating, deploying and operating ~54 GENI racks within campuses, regional networks and national backbones; 4) deploying and operating two robust, complementary instrumentation and measurement systems; and 5) expanding the GENI experimenter community by creating educational materials, running workshops and summer schools and starting ongoing operations and helpdesk support.","title":"GENI Solicitation 3 D&P Proposal","awardID":"1128122","effectiveDate":"2011-09-15","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["521729"],"PO":["564993"]},"184786":{"abstract":"The Society for the Advancement of Chicanos and Native Americans (SACNAS), a non-profit organization, has been instrumental in improving and expanding opportunities for underrepresented groups in the science, technology, engineering and mathematics (STEM) workforce. At the core of the SACNAS' mission is the organization's marked focus on encouraging students to pursue advanced degrees in STEM through mentoring, exposure to cutting edge science, and professional development training offered at the SACNAS National Conference. In addition to attending scientific symposia, receiving information on various graduate and internship programs, student participants have the opportunity to submit abstracts on and present their academic research at poster sessions, which are judged by professional research scientists and engineers.<br\/><br\/>Funds will be utilized to support the attendance of students and post-doc in NSF-supported disciplines to attend the National conference as a vehicle to increase the diverse participation of students in STEM, particularly in the fields of the biological sciences, geosciences, mathematics, chemistry, physics, computer science,engineering and the social and behavioral sciences. The activity creates a unique opportunity for the National Science Foundation, in partnership with SACNAS, to meet goals aligned with the America Competes Act, as well as to assist in the development of the intellectual capital of young professionals in the quest to achieve excellence in STEM.<br\/><br\/>This award is funded by contributions from the Directorate for Biological Sciences, Directorate for Engineering, Directorate of Mathematics and Physical Sciences, Division of Earth Sciences, the Division of Human Resource Development, and the Office of Integrative Activities.","title":"SACNAS Multi-Discpline Student Support Activities","awardID":"1136444","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0106","name":"Office of INTEGRATIVE ACTIVITIES","abbr":"OIA"},"pgm":{"id":"142P","name":"SACNAS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"9134","name":"PHYSICS EDUC & INTERDISCIP RES"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1219","name":"SPECIAL PROGRAMS IN ASTRONOMY"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"7222","name":"OFFICE OF SPECIAL PROGRAMS-DMR"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1978","name":"PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0604","name":"Division of OCEAN SCIENCES","abbr":"OCE"},"pgm":{"id":"1690","name":"EDUCATION\/HUMAN RESOURCES,OCE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7680","name":"ENG DIVERSITY ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"8015","name":"BIO Innovation Activities"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1575","name":"EDUCATION AND HUMAN RESOURCES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1114","name":"Cellular Processes"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1260","name":"INFRASTRUCTURE PROGRAM"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1515","name":"MINORITY GRADUATE EDUC ACTIVIT"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1403","name":"Division of ANTARCTIC SCIENCES DIVISION","abbr":"ANT"},"pgm":{"id":"5294","name":"Antarctic Education"}}],"PIcoPI":["529846"],"PO":["552354"]},"181398":{"abstract":"The objective of this research is to enable more effective design and use of virtual worlds. The pervasiveness of visually-oriented online and interactive digital media allows people to represent themselves increasingly through surrogates in virtual worlds. These digital personae are called \"avatars,\" and when they closely represent the user, \"self-avatars.\" Self-avatars enable forms of learning, interaction, and skill development that can increase a user's effectiveness in a virtual world. This project will explore how self-avatars play a significant role through three key components of perception and action: the relationship between action and the perception of space and objects, active acquisition of spatial memory, and the planning and execution of actions themselves. <br\/><br\/>This research will consider three properties of self-avatars themselves, each likely to have an effect across a broad range of situations: (1) the virtual perspective from which the avatar is seen, (2) the nature of the coupling between user size and motion and avatar size and motion, and (3) the naturalness of the interface system by which the user controls the avatar. The work builds on a growing body of knowledge about the role of body ownership in perceptual and cognitive tasks. This framework provides a theory in which to ground the research, a body of empirical knowledge about perception and action in the real world, and established methodologies that can be used for assessing the results of the research. The ability to utilize work from cognitive and perceptual science to solve a problem in computer graphics and user interaction is a major strength of the research. <br\/><br\/>Virtual environments are important in many domains, including architecture, education, medicine, simulation, training, and visualization. The core impact of this research is to enable self-avatars to enhance user experience in virtual environments, which are a major category of computer simulations. A broad impact of this project is that enhancing the user experience will lead to more capable applications of virtual environments in the aforementioned domains. This research will also have utility in entertainment systems, the dominant environments for avatars. It advances discovery and understanding while training students in cross-disciplinary research methods in an innovative intellectual environment. The interdisciplinary nature of the research and its consequent applications, together with the close integration of two research groups, will aid in bringing new students to computer science, beyond the students traditionally attracted to that field.","title":"HCC: Small: Collaborative Research: The Influence of Self-Avatars on Perception and Action in Virtual Worlds","awardID":"1116988","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[486038],"PO":["564456"]},"184687":{"abstract":"The CrAVES project seeks to lay down intellectual foundations for credible autocoding of embedded systems, by which graphical control system specifications that satisfy given open-loop and closed-loop properties are automatically transformed into source code guaranteed to satisfy the same properties. The goal is that the correctness of these codes can be easily and independently verified by dedicated proof checking systems. During the autocoding process, the properties of control system specifications are transformed into proven assertions explicitly written in the resulting source code. Thus CrAVES aims at transforming the extensive safety and reliability analyses conducted by control system engineers, such as those based on Lyapunov theory, into rigorous, embedded analyses of the corresponding software implementations. CrAVES comes as a useful complement to current static software analysis methods, which it leverages to develop independent verification systems.<br\/><br\/>Computers and computer programs used to manage documents and spreadsheets. They now also interact with physical artifacts (airplanes, power plants, automobile brakes and robotic surgeons), to create Cyber-Physical Systems. Software means complexity and bugs - bugs which can cause real tragedy, far beyond the frozen screens we associate with system crashes on our current PCs. Software autocoding is becoming the de facto recommended practice for many safety-critical applications. CrAVES aims to evolve this towards higher standards of quality and reduced design times and costs. Rigorous, mathematical arguments supporting safety-critical functionalities are the cornerstone of CrAVES. Collaborative programs involving high-school teachers will encourage the transmission of this message to STEM education in high-schools through university programs designed for that purpose.","title":"CPS: Medium: Collaborative Research: Credible Autocoding and Verification of Embedded Software (CrAVES)","awardID":"1136008","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[495331],"PO":["565274"]},"186865":{"abstract":"This project addresses two of the grand challenges of the next decade: green wireless communication systems and spectrum efficiency, through a collaborative research and education plan utilizing optimization theory, and involving researchers from the U.S. and Finland. This project considers energy efficiency for cognitive radio networks and introduces a novel optimization-based methodology. It builds on existing results to establish a new focus on green cognitive networking. The way in which energy is consumed in cognitive networks provides unique opportunities for exploiting the cognitive process to save energy and for using energy reduction techniques to modify and improve the performance of cognitive networks. A unique feature of this project is the introduction of an optimization-based methodology for establishing and attaining ultimate performance limits. In this project, PIs develop energy performance bounds that yield insights for design of general networks, derive optimal tradeoffs between fundamental performance criteria, use optimization formulations for establishing and achieving ultimate performance limits, and design protocols that are optimal in the presence of temporal cognitive systems evolution. Research results of this work will be widely promulgated through the usual means of publication and dissemination and will have significant impact on energy efficiency of spectrum-efficient wireless systems.","title":"Collaborative Research: Energy-Efficient Cognitive Networking","awardID":"1147730","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[501350],"PO":["557315"]},"184698":{"abstract":"In many important situations, analytically predicting the behavior of physical systems is not possible. For example, the three dimensional nature of physical systems makes it provably impossible to express closed-form analytical solutions for even the simplest systems. This has made experimentation the primary modality for designing new cyber-physical systems (CPS). Since physical prototyping and experiments are typically costly and hard to conduct, \"virtual experiments\" in the form of modeling and simulation can dramatically accelerate innovation in CPS. Unfortunately, major technical challenges often impede the effectiveness of modeling and simulation. This project develops foundations and tools for overcoming these challenges. The project focuses on robotics as an important, archetypical class of CPS, and consists of four key tasks: 1) Compiling and analyzing a benchmark suite for modeling and simulating robots, 2) Developing a meta-theory for relating cyber-physical models, as well as tools and a test bed for robot modeling and simulation, 3) Validating the research results of the project using two state-of-the-art robot platforms that incorporate novel control technologies and will require novel programming techniques to fully realize their potential 4) Developing course materials incorporating the project's research results and test bed.<br\/><br\/>With the aim of accelerating innovation in a wide range of domains including stroke rehabilitation and prosthetic limbs, the project is developing new control concepts and modeling and simulation technologies for robotics. In addition to new mathematical foundations, models, and validation methods, the project will also develop software tools and systematic methods for using them. The project trains four doctoral students; develops a new course on modeling and simulation for cyber-physical systems that balances both control and programming concepts; and includes an outreach component to the public and to minority-serving K-12 programs.","title":"CPS: Medium: Collaborative Research: A CPS Approach to Robot Design","awardID":"1136104","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["526843"],"PO":["565239"]},"187723":{"abstract":"Speech enhancement and speaker recognition are, in principle, related tasks. Knowledge of the speaker can allow for better speech enhancement, while speech with less interference improves the ability to recognize the speaker. Statistical models for these two tasks can be coupled to yield a principled approach to performing both jointly, however the complexity of exact inference in the resulting statistical model, which must straddle a nonlinear feature calculation, is prohibitive. For this reason, approximate inference techniques that sacrifice some performance of exact inference for lower complexity are of interest. This Early Grant for Exploratory Research brings Gibbs sampling approximate inference techniques to bear on joint speech enhancement and speaker recognition for the sake of comparison with several variational approximate inference techniques. The ultimate aim of the research is to partition the attainable complexity and performance space into different regimes dictating which techniques should be used and the performance attainable as a function of complexity. To obtain this partitioning, a thorough empirical evaluation on several large speech corpora will be carried out.<br\/><br\/>Speech enhancement and speaker recognition technology finds multiple uses in defense, commercial, and medical technologies. Multiple technologies would benefit from performance improvement in speech enhancement and speaker recognition brought about by successfully integrating these two interdependent tasks. Potential applications include dialogue systems for controlling e.g. television sets using distant microphones where additive noise is a significant source of distortion. Additionally, speech enhancement is useful for hearing aids. Speaker dependent prior information gains the ability to improve the intelligibility of speech in these devises.","title":"EAGER: Approximate Inference Robust Speech Processing via Sampling","awardID":"1152288","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[503250,"539473"],"PO":["565215"]},"183015":{"abstract":"Retaining collected data and sharing it with the broader research community is necessary for developing a better understanding of the impact of urbanization on the global ecology and environment. The data intensive instrument to be installed at CUNY College of Staten Island will provide data analysis and data asset management capabilities to allow researchers to share, federate, and retain data and will provide for reproducibility and traceability. Researchers will be able to organize, analyze, manage and annotate metadata, and search and share their data sets. The proposed interface will use a service-\u00adoriented architecture based on an open standards framework to provide a library of core services for managing data and metadata. It includes a hierarchical storage system with at least a 1.4 petabyte disk farm and at least a 1.2 petabyte robotic tape system. <br\/><br\/>The instrument will enable the expanded use of computations for a large number of researchers in the biological, ecological, environmental, and economic disciplines. In environmental studies, it will facilitate the creation of a \"virtual\" urban-oceanographic-atmospheric\u00ad-land observatory allowing four significant Research Centers that are studying various aspects of the effects of urbanization to now retain and share their data. <br\/><br\/>The instrument will help to accelerate the research required to understand and forecast the impact of mega city and urban planning decisions on the local and global environment, on ecology and ecosystem services, on energy systems, and on economic systems. It will have similar benefits to researchers in other disciplines. The Research Centers are committed to use the instrument to share their data and the results of their research with each other and the broader research community. Each of the participating Research Centers is multi-\u00adinstitutional. Many of them are led by, and most include, Minority Serving Institutions. Consistent with NSF policy and CUNY traditions, each of these Research Centers has extensive internship and training programs that encourage women and minority student participation. <br\/><br\/>Fall 2009 enrollment statistics for the 23 institutions that comprise CUNY show that 53% of its 259.515 full-\u00adtime students were Black or Hispanic and 60% were female. Fall 2009 statistics showed 27,962 students enrolled in Science, Technology, Engineering, and Mathematics disciplines, including 65 American Indian\/Native American, 6,195 Asian\/Pacific Islander, 7,878 Black, 6,473 Hispanic, and 7,351 White students; 34% of the students were female. These statistics and CUNY's College Now, Teacher Academy, and Discovery Institute outreach programs attest to CUNY's commitment to broadening participation and to the outreach initiatives of the NSF.","title":"MRI: Instrumentation for Enabling Data Analysis, Sharing, Storage, and Preservation","awardID":"1126113","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1403","name":"Division of ANTARCTIC SCIENCES DIVISION","abbr":"ANT"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[490434,490435,"539708",490437,"536390"],"PO":["565272"]},"184588":{"abstract":"This award supports a one-and-a-half day early-career symposium focused on helping participants develop personal technology research agendas, to be held at the Annual Meeting of the Association for Education Communications and Technology (AECT). The organizing committee has selected three members of the learning sciences community to mentor advanced graduate students and pre-tenure faculty from this community, to help them focus on taking a theory-based approach to designing potentially-high-impact learning technologies.<br\/><br\/>The goals of this early-career workshop are (i) mentoring of advanced doctoral students into the social\/professional network as partners in idea-making, (ii) supporting advanced doctoral students and early career faculty in developing viable technology-oriented research agendas, (iii) providing specific feedback and guidance to advanced doctoral students and early career faculty about their research agendas, and (iv) further developing a community of researchers interested in ways technology can transform teaching and learning.","title":"Building a Technology Research Agenda - An Early Career Symposium","awardID":"1135361","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["538350"],"PO":["562669"]},"187976":{"abstract":"The Eleventh ACM SIGCOMM Internet Measurement Conference (IMC), sponsored by ACM SIGCOMM and ACM SIGMETRICS, in cooperation with USENIX, is to be held in Berlin, Germany, November 2-4, 2011. This award provides funding to assist approximately 8 graduate students from US institutions to attend this conference. IMC is the primary venue for presenting new research results on collecting and analyzing measurements of the Internet. Attending conferences such as IMC is of paramount importance for graduate students pursuing research in the field. Authors have the opportunity to present their work and all attendees have a chance to interact with many others performing leading-edge research in the field.<br\/><br\/>Intellectual Merit: This proposal will serve to widen the audience attending the Internet Measurement Conference (IMC), raising the level of interaction and the potential for new collaboration, new investigations, and higher quality research. Given the rising cost of international travel, the grant will enable students (who otherwise do not have sufficient funds) to attend the conference in Germany.<br\/><br\/>Broader Impact: This award, by enabling students to attend who might not otherwise be able, increases the dissemination of the conference?s research results to a larger and more diverse audience. It also integrates research and education of graduate students by allowing students to observe high-quality presentations and interact with senior researchers in the field. Giving preference in grant awards to women and minority students widens the participation among these underrepresented groups. Furthermore, by advertising to a wide range of colleges and universities, participants from a more diverse set of institutions should be able to attend and benefit from the conference.","title":"Student Travel Support for the 2011 Internet Measurement Conference","awardID":"1153562","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["563433"],"PO":["565090"]},"183159":{"abstract":"Proposal #: CNS 11-26739<br\/>PI(s): Ullmer, Brygg<br\/> Batzer, Mark A.; Brenner, Sussanne C.; Butler, Leslie G.; Parker, Rod<br\/>Institution: Louisiana State University<br\/>Title: MRI\/Dev.: Melete: An Interaction-oriented, Software-rich Compute Cluster with <br\/> Tangible Interface Support for Collaborative Research and the Classroom<br\/>Project Proposed:<br\/>This project, developing Melete, a new genre of interaction-oriented compute cluster instrument integrated with advanced interaction technologies, servicing research collaboration and training in computational science, technology, engineering, arts, and mathematics (STEAM), aims to advance the capabilities of batch processing systems. In decades past, batch processing meant turning over computation to a remote dispatcher, retrieving only the results of the isolated and distant computational process. As users have evolved to expect greater interactivity with their copious mobile devices and other forms of mobile computation, the evolution of the ?cloud? as a computational paradigm ha become much more interactive. Melete promises to extend this interactive paradigm to cluster computing in new and innovative ways. <br\/>The developed instrument will enable research in biology, visualization of computational materials, displaying configuration space for computational mathematics, mapping and displaying data from robot mapped locations (e.g. archeology sites, urban environments, etc), and architecture visualization.<br\/>Broader Impacts: <br\/>This proposal promises benefits to society by balancing activities between research and research training contexts. This approach is aligned with NSF priorities in cyberlearning, cyberinfrastructure, and beyond. The proposal's partnership with Southern University (an HBCU) in<br\/>both research and classroom impacts, building upon five years of successful collaboration in \"Cybertools,\" provides further potential and promise for broader impact.","title":"MRI: Development of Melete: an interaction-oriented, software-rich compute cluster with tangible interface support for collaborative research and the classroom","awardID":"1126739","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["550294",491084,491085,"531068",491087],"PO":["543539"]},"187537":{"abstract":"Systems that are capable of producing change in the environment require particular attention to the ethical ramifications of their behavior. The determination and mitigation of the ethical concerns of such systems has to date been charged to their designers and has largely been accomplished by simply preventing systems from engaging in ethically unacceptable behavior in a predetermined, ad hoc manner, which can unnecessarily constrain the set of possible behaviors. Although this may have been considered \"best practice\" in the past, the coupling of computational intelligence to such systems is likely to provide better options. This is especially true of autonomous systems, which not only produce change in the environment but are capable of monitoring this environment to determine the effect of their actions as well as what the next action should be. Ethical questions concerning the behavior of such complex and dynamic systems are likely to exceed the grasp of their designers and elude simple static solutions. Autonomous systems will therefore need tools and methodologies to help codify ethical principles pertinent to their behavior, principles which form the basis for the autonomous selection and justification of ethically preferable actions.<br\/><br\/>In this research, the PI and his team will develop and implement a general methodology for the discovery of ethical principles, abstracted from their previous work, which incrementally constructs representations that characterize ethical dilemmas and discovers decision principles necessary to resolve them. They will use this system to codify representation schemes and principles of ethical decision-making in domains that are of particular significance to autonomous systems in their interaction with human beings. And they will evaluate the discovered representations and principles through independent consultation. The PI expects project outcomes will provide evidence that ethical principles and decision-making can be computed and function effectively in domains where machines are likely to interact with human beings.<br\/><br\/>Broader Impacts: This research will lay the foundations for providing autonomous systems across multiple domains with the principles required to choose the most ethically correct actions and justify these choices. Thus, the work should alleviate concerns with autonomous systems and bolster society's support for their development in a wide range of domains. An important by-product of the research is that breakthroughs in ethical theory are likely to result as representations and principles for resolving ethical dilemmas are discovered.","title":"EAGER: A General Ethical Dilemma Analyzer","awardID":"1151305","effectiveDate":"2011-09-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["529182"],"PO":["565227"]},"187669":{"abstract":"Packet transmission is one of the primary operations conducted by Wireless Mesh Networks (WMNs). All the existing work for packet transmission in WMNs is based on the Deterministic Network Model (DNM), where a pair of nodes is assumed to be either connected or disconnected. However, this assumption is not always practical and reasonable. Mesh clients are usually connected wirelessly to mesh routers resulting in unstable links. This project seeks a new exploratory study on one-off\/continuous convergecast and broadcast scheduling under a more realistic Probabilistic Network Model (PNM), where a certain communication success probability is assigned to each link. Factors, such as different MAC protocols, pipeline technologies, and multi-radio multi-channel, are also taken into account for a comprehensive design and theoretical capacity analysis. For convergecast, the following four aspects are investigated: network model definition, network partition methods to identify non-inference zones, scheduling techniques for concurrent transmissions, and capacity analysis. For broadcast, Connected Dominating Set based schemes are developed. The efficiency of the proposed algorithms and the pipeline techniques are evaluated theoretically and through simulations and experiments. The success of this project provides a general framework for packet transmission in probabilistic WMNs with unstable links. Furthermore, this project also has great impacts on other kinds of wireless networks which similarly demonstrate the probabilistic characteristic. The research results will be integrated into education, and widely disseminated through conference\/journal publications.","title":"EAGER: One-off\/Continuous Convergecast and Broadcast Scheduling in Probabilistic Wireless Mesh Networks","awardID":"1152001","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["533838"],"PO":["557315"]},"186459":{"abstract":"Research on sentiment and emotion in textual and spoken language relies heavily on human annotation of corpora and human judgments of words in context to provide gold standard data and useful features for prediction. Current resources such as Whissell's Dictionary of Affect in Language (DAL) are of limited utility, due to their limited coverage. To provide richer gold standards, in recent years computational linguists have been making use se of crowd-sourcing websites such as Amazon Mechanical Turk to accomplish annotation tasks that previously would have been done by trained annotators or human subjects in laboratory experiments. Recently there has been some research on using social media websites for similar purposes (mining existing social exchanges for information and creating games to elicit new information). In this project the PI will explore the use of all three of these approaches to augment existing data on human judgments of the emotional content of lexical items to support her ongoing investigation into the classification of emotional text and speech (a major objective of which is to move beyond simple valence judgments relying upon acoustic and prosodic features by taking into account more nuanced aspects of affective text). She will examine the value of crowd-sourcing, social media mining and games implemented in social websites to ascertain what lessons can be learned about acquiring reliable annotations and judgments of emotional content.<br\/><br\/>Broader Impacts: This exploratory research has the potential to open up new sources of information about the affective connotations of lexical items that will be invaluable to researchers working in text and in speech affect. Advances in the automatic identification of affect in text and in speech would have major applications in fields such as business and medicine, inter alia. Business interests in assessing consumer opinion is rapidly moving from focus groups to analyses of product reviews, while medical informatics researchers similarly try to learn patient attitudes to diagnoses, drugs, and treatments by mining online forums. A major component of such endeavors is the use of affect dictionaries. New and better sources of affective connotations of lexical items should prove enormously helpful in these efforts, increasing our ability to learn useful, practical information from the data individuals provide freely online. The lessons learned through these experiments and results of subsequent data collection will be made available to the larger research community in the form of new affect lexicons.","title":"EAGER: Using Social Media and Crowdsourcing to Create a New Affect Dictionary","awardID":"1145505","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["511614"],"PO":["565227"]},"186118":{"abstract":"The ease of use of a human computer interface depends critically on the latency of the system and its ability to adapt to the environment. Differences in lighting, visual appearance and user behavior can significantly alter the input data. Furthermore, the reaction time must be less than 100 milliseconds to appear instantaneous to the user. Achieving high accuracy demands a system that adapts to these changing characteristics while processing a significant amount of data in a short amount of time.<br\/><br\/>We propose a computer architecture for adaptive real-time signal processing systems that combines a general purpose processor with custom hardware. The custom hardware performs the low-level, high-throughput signal processing on the raw signals and feeds them to the processor which performs the high level signal processing and decision making. The processor also executes machine learning algorithms that change the parameters of the low-level processing to adapt them to the current statistical properties of the data.<br\/><br\/>This project will develop a human-computer interface based on audio and video sensors that allows a user to interact with the computer through gestures and voice alone. This requires research advances in computer architecture, embedded systems, signal processing, machine learning and human-computer interaction. The major research challenge is in the integration of knowledge from the different areas to create a functional system. This system will serve as a prototype for novel human computer interactions and will be a foundation for future collaboration between the different fields.","title":"EAGER: Computer Architectures and Algorithms for Adaptive Human Computer Interfaces","awardID":"1143995","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560817","508515"],"PO":["562760"]},"180530":{"abstract":"How does a vision system recover the 3-dimensional structure of the world -- such as the layout of the environment, surface shape, or object motion -- from the dynamic 2-dimensional images received by the sensors in a camera, or the retinas in our eyes? This problem is fundamental to both computer and biological vision. Computer vision has developed a variety of algorithms for estimating specific aspects of a scene such as the 3-dimensional positions of points whose correspondence over time can be established, but obtaining complete and robust scene representations for complex natural scenes and viewing conditions remains a challenge. Biological vision systems have evolved impressive capabilities that suggest they have detailed and robust representations of the 3-dimensional world, but the neural representations that subserve this are poorly understood and neurophysiological studies thus far have provided little insight into the computational process. This project will pursue an interdisciplinary approach by attempting the understand the universal principles that lie at the heart of 3-dimensional scene analysis.<br\/><br\/>Specifically, the project will 1) develop a novel class of computational models that recover and represent 3-dimensional scene information, 2) collect high quality video and range data of dynamic natural scenes under a variety of controlled motion conditions, and 3) test the perceptual implications of these models in psychophysical experiments. The computational models will utilize non-linear decomposition - i.e., the ability to explain complex, time-varying images in terms of the non-linear interaction of multiple factors, such as the interaction between observer motion, the 3-dimensional scene layout, and surface patterns. Importantly, the components of these models will be adapted to the statistics of natural motion patterns that arise from observer motion through natural scenes and movement around points of fixation.<br\/><br\/>The project is a collaboration between three laboratories that have played a leading role in developing theoretical models of natural image statistics, visual neural representations, and perceptual processes. The investigators seek to combine their efforts to develop new models, data sets, and characterizations of 3-dimensional natural scene structure that go beyond previous studies of natural image statistics, and that can be tested in neurophysiological and psychophysical experiments. This project has the potential to bring about fundamental advances in neuroscience, visual perception, and computer vision by developing new classes of models that robustly infer representations of the 3-dimensional natural environment. It will create a set of high quality databases that will be made available to help other investigators study these issues. It will also open up new possibilities for generating realistic stimuli that can guide novel investigations of neural representation and processing.","title":"RI: Large: Collaborative Research: 3D Structure and Motion in Dynamic Natural Scenes","awardID":"1111765","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[483816],"PO":["564318"]},"182840":{"abstract":"CDI-Type I: Collaborative Research: Collaborative Multi-robot<br\/>Exploration of the Coastal Ocean (COMECO)<br\/><br\/>Overview: The coastal ocean is a complex environment driven by the interaction of atmospheric, oceanographic, estuarine\/riverine, and land-sea processes, which result in dynamic coastal features such as blooms, anoxic zones, and plumes (estuarine, oil, pollutant). Effective observation and quantification of these features require simultaneous, rapid measurement of diverse water properties to capture its variability. This project aims to synthesize and understand the basic principles of environmental sensing based on the integration of adaptive robotic sampling with human decision-making. The techniques being developed augment existing ocean models and aid coastal exploration to ensure that robots are present at the \"right place and time\" to provide the most effective measurements.<br\/><br\/>Technical Description: The absence of a single model assimilating all available physical and biogeochemical data to provide a reliable view of ocean features favors the combination of human expertise, model refinement, and analytical adaptive sampling adopted in this project. Human decision-making is coupled with probabilistic modeling and learning in a decision support system enabling environmental field model discovery and refinement. The project extends the state of the art in multirobot adaptive sampling by investigating the relationship between environmental field structure and sampling performance, developing improved field boundary tracking techniques, and creating methods for multi-resolution, multivariable sampling. These advances are being made by addressing two broad research challenges. The first, Model-Based Asset Allocation, involves synthesis of large-scale, low-resolution data with human scientific expertise to make timely, model-informed asset allocation decisions. The second, Sampling-Based Model Refinement, involves small-scale, high-resolution autonomous cooperative selection and execution of robot sampling trajectories. Both challenges involve the handling of multivariate, multi-resolution, temporally evolving fields. The project includes a feasibility and evaluation study in coastal ocean exploration using underwater robots.<br\/><br\/>Broader Impacts: Decision support with diverse data integrated in a form that is interpretable by a non-computer specialist will have a broader impact applicable to a range of domains, including ocean and space exploration, environmental disaster response and military andhomeland security. The ocean science community will have a new and powerful tool to augment their understanding of dynamic coastal phenomena and policy makers an important tool to aid decision making impacting coastal communities. It is expected that the methods developed will be broadly applicable to the general task of goal-driven exploration and characterization of large areas. The project will involve graduate students who will be trained in an interdisciplinary context. The project results will be disseminated in the peer-reviewed scientific literature as well as via the project website at: http:\/\/robotics.usc.edu\/comeco.html","title":"CDI-Type I: Collaborative Research: Collaborative Multi-robot Exploration of the Coastal Ocean","awardID":"1125015","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7750","name":"CDI TYPE I"}}],"PIcoPI":["560335"],"PO":["560586"]},"180420":{"abstract":"This project will exploit algebraic properties of operators associated with graphs in an integrated set of research and educational activities designed to develop new mathematical and algorithmic techniques; apply these to the solution of real-world problems and longstanding theoretical questions in mathematics, computer science, biology, and physics; and make these techniques broadly known and accessible to students, researchers, and practitioners in many fields. <br\/><br\/>This research has its origins in spectral graph theory, which studies how the eigenvalues and eigenvectors of the graph Laplacian (and other related matrices) interact with the combinatorial structure of the graph. Spectral graph theory has been one of the great success stories in both the theory and practice of algorithm design. It has led to fundamental advances in graph partitioning, web search (notably including Google's PageRank algorithm), the understanding of random processes and the algorithms derived from them, the construction of error correcting codes, derandomization, convex optimization, machine learning, and many others. <br\/><br\/>While the eigenvalues and eigenvectors of the Laplacian capture a striking amount of the structure of the graph, they certainly do not capture all of it. Recent work by the principal investigators and other researchers suggests that theoretical computer scientists have only scratched the surface of what can be done if they are willing to broaden their investigation, extending it to study more general algebraic properties of the Laplacian than just its eigenvalue structure, and more general operators than just the Laplacian. <br\/><br\/>Under this award, the principal investigators will build a research program across the three universities involved in this proposal to develop such a theory and its applications. This initiative has the potential to provide transformative advances in a range of theoretical and applied areas of computer science, including: <br\/><br\/>* Faster algorithms for fundamental graph problems, such as Maximum Flow, Minimum Cut, Minimum Cost Flow, Multicommodity Flow, approximating Sparsest Cut, generating random spanning trees, and constructing low-stretch spaning trees. <br\/><br\/>* Better algorithms for the analysis of data, with potential applications to the Unique Games Conjecture. <br\/><br\/>* Faster algorithms for solving broad classes of important linear systems, both sequentially and in parallel. <br\/><br\/>* Faster distributed algorithms for information dissemination in networks. <br\/><br\/>* A spectral and algebraic graph theory for directed graphs, based on ideas from differential geometry. <br\/><br\/>* Novel quantum algorithms for a large class of problems that appear to be hard for classical computers. <br\/><br\/>* New techniques for problems in Quantum Physics based on ideas developed in Computer Science and Combinatorics. <br\/><br\/>The principal investigators will also work to disseminate these techniques by developing courses, training undergraduate and graduate students, and introducing these ideas to scientists in other fields.","title":"AF: Large: Collaborative Research: Algebraic Graph Algorithms: The Laplacian and Beyond","awardID":"1111257","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[483529,483530],"PO":["565157"]},"181520":{"abstract":"Providing young children with opportunities to develop early literacy skills is important to their success in school, their success in learning to read, and their success in life. This project focuses on the creation of a new interactive reading primer technology on tablet computers that will foster early literacy skills and shared parent-child reading through the use of a targeted discussion-topic suggestion system aimed at the adult participant. The Cloud Primer will crowdsource the interactions and discussions of parent-child dyads across a community of readers. It will then leverage this information in combination with a common sense knowledge base to develop computational models of the interactions. These models will then be used to provide context-sensitive discussion topic suggestions to parents during the shared reading activity with young children. The work will be evaluated in week-long at-home studies.<br\/><br\/>Intellectual merit: The project will make fundamental theoretical contributions to models of human-human and human-computer interaction, and their use in fostering engagement and learning. The effort will also produce new insights into how common sense reasoning can be integrated with large-scale data collection to develop interactive technologies that deal gracefully with inconsistencies and noise to provide diverse and semantically meaningful responses in unconstrained, real-world environments.<br\/><br\/>Broader impacts: Research shows that one in three children in the United States enter kindergarten unprepared, and the majority of children who start behind typically stay behind. The Cloud Primer will counteract this trend by leveraging a community of readers to define a set of common discussion topics, actively exposing parents to these topics, and, through a simple touch interface, providing children of pre-reading age a mechanism for engaging adults in discussion. The new context and common sense aware interactive reading primer will be a fundamental advance over current digital reading technologies, which neither effectively achieve educational goals when used alone, nor support joint reading and adult engagement. The project will further contribute to education through undergraduate research, graduate thesis research, graduate course development, and outreach programs to women and under-represented minorities. To promote research in this area, the project will make all parent-child interaction data captured and annotated in the process of this research freely available to the research community, together with the Cloud Primer software. Furthermore, the computational methods developed through the course of this research will have applications in interactive domains beyond early literacy, such as foreign language learning.","title":"HCC: Small: Collaborative Research: Cloud Primer: Leveraging Common Sense Computing to Learn Parent-Child Interaction Models for Early Childhood Literacy","awardID":"1117584","effectiveDate":"2011-09-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["549619"],"PO":["565227"]},"182851":{"abstract":"An interdisciplinary team of computer scientists, statisticians, and ornithologists will develop novel computer science methods and apply them to the challenge of understanding the annual migration of birds across North America, which is one of the most complex and dynamic natural phenomena on the planet. While direct observation of migrating birds is limited to a handful of birds wearing tracking devices, other sources of data provide partial information about migration that, when appropriately combined, will provide insight into migration at a scale previously unimaginable. These sources include a continent-wide network of volunteer bird watchers, night flight calls captured by a network of acoustic monitoring stations, continent-scale weather patterns gathered by a network of weather stations, and clouds of migrating birds detected at night by WSR-88D weather radar stations. To analyze these data, the team will develop two innovative machine learning techniques-Collective Graphical Models (CGMs) and Semi-Parametric Latent Process Models (SLPMs). The resulting model will be able to identify the complex conditions governing the dynamics of migration behavior including the choice of migratory pathways, the factors that influence when birds migrate, and the speed and duration of each night's movements. CGMs greatly extend the scope of phenomena that can be captured with graphical models. Under suitable conditions, a CGM is able to recover a model of the behavior of individuals using only collective observations.<br\/><br\/>For BirdCast, it will construct a model of individual bird dynamics from the collective observations provided by birders, acoustic and weather stations, and weather radar. Once the model is constructed, it will be applied to live data feeds (bird sightings, acoustic detections, radar detections, and weather forecasts) to predict bird migration in real time. SLPMs are an extension of latent process models, such as the CGM for bird migration, in which the dynamics of a process is represented by latent variables that are observed only indirectly. In an SLPM, the conditional probability distribution of each variable is modeled using flexible, non-parametric methods from machine learning, such as boosted regression trees. Introducing such flexible methods such as CGMs and SLPMs into latent variable models raises difficult challenges for model fitting and validation. Preventing over-fitting will require the creation of novel information regularization and latent model cross-validation methods to enforce latent variable semantics.<br\/><br\/>The proposed work will allow, for the first time, real-time predictions of bird migrations: when they migrate, where they migrate, and how far they will be flying. Accurate models of migration have broad application for basic research by allowing researchers to understand behavioral aspects of migration, how migration timing and pathways respond to variation in climatic conditions, and whether linkages exist between annual variation in migration timing and subsequent inter-annual changes in population size.<br\/><br\/>BirdCast will expand opportunities for the public to participate in the gathering of data and its analysis. The existing data set has more than 60 million observations, and the size is growing exponentially. Last year, volunteers contributed more than 1.3 million hours observing birds. Student engagement in the research is significant as well.","title":"Collaborative Research: CDI-Type II: BirdCast: Novel Machine Learning Methods for Understanding Continent-Scale Bird Migration","awardID":"1125098","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[489926,"514003",489928],"PO":["565136"]},"181410":{"abstract":"It has become increasingly feasible to deploy wireless devices, systems, and networks at low cost for diverse applications such as data communications, sensing, and inference. Given the variety of complex wireless systems with different purposes operating over randomly fading channels, the question of how to compare the performance of these systems arises. System analysis and design can benefit from a unified approach to comparisons of such systems. This research uses the notion of stochastic ordering to provide such an approach. The results aid in performance analysis, and design of wireless systems across a wide range of random propagation conditions. The educational component of this research involves design of educational software modules to illustrate basic concepts in probability and communications using performance comparison of sensing systems through stochastic orders.<br\/><br\/>Unifying performance metrics also enables comparisons of complex wireless systems operating over fading channels. This enables performance comparisons of a vast range of systems on the basis of the analytical properties of the performance metric such as monotonicity, convexity, or complete monotonicity. When systems are combined, we can determine the conditions under which ordering of the constituent parts preserves the ordering of overall system performance. Specific topics of application include stochastic ordering of generalized relay networks, introduction of new stochastic orders induced by performance metrics of wireless systems, applying the theory of stochastic ordering of point processes to order wireless sensor network performance, and stochastic ordering of systems with multiple (possibly correlated) random channel coefficients such as MIMO systems, or systems operating over frequency-selective channels.","title":"CIF: Small: Stochastic Ordering of Wireless Systems","awardID":"1117041","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["544880"],"PO":["564924"]},"182862":{"abstract":"This project will advance understanding of complexity in climate-societal dynamics by applying cyber-enabled multiagent systems models integrated with evolutionary computation algorithms. The research will develop, validate, and analyze new computational agent-based models as transformative tools for simulating human societies spatially situated in regions with diverse ecosystems and explicit climate dynamics. The new suite of models will focus on two geographic regions where climate change has significant consequences for humans and ecosystems: Sub-Saharan Africa (over a billion people at high risk of displacement, disease, starvation) and the Arctic Circumboreal region (where the fastest ecological changes are now occurring with shifting patterns comparable to earlier major climate events). <br\/><br\/>The project forges interdisciplinary collaboration among anthropologists, political scientists, earth scientists, and computer scientists to advance the science of complex adaptive systems. The core intellectual merit of the project is its contribution to basic understanding of multiscale complexity in climate-society dynamics, by creating a cyber-enabled integrated computational framework for modeling, simulating, and exploring scenarios. Spatial multiagent systems will be created that include climate dynamics as well as other natural hazards and stressors with direct and indirect effects on social dynamics composed of households and governance institutions. <br\/><br\/>Broader impacts from this project will include (1) new cross-disciplinary understanding of climate-society dynamics, (2) new computational tools; (3) new policy-relevant insights derived via scenario analysis with such tools; (4) innovations in new advanced forms of hybrid computational modeling, enabling new collaborations across disciplines; (5) new support for innovative forms of teaching, training, and learning through computational modeling of complex socio-ecological systems; (6) and multi-institutional opportunities for students from underrepresented groups via classroom visits and museum exhibits. Perpetual archiving of all electronic materials (code and data) will be implemented through the Smithsonian data archiving initiative.","title":"CDI Type II: Cyber-Enabled Understanding of Complexity in Socio-Ecological Systems via Computational Thinking","awardID":"1125171","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7751","name":"CDI TYPE II"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1403","name":"Division of ANTARCTIC SCIENCES DIVISION","abbr":"ANT"},"pgm":{"id":"5221","name":"ARCTIC SOCIAL SCIENCES"}}],"PIcoPI":["511673","549627",489959,"511676"],"PO":["564456"]},"180442":{"abstract":"This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br\/><br\/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br\/><br\/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists \"in the loop\" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http:\/\/www.scidb.org\/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http:\/\/database.cs.brown.edu\/projects\/scidb).","title":"III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","awardID":"1111371","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[483585,"525076"],"PO":["563751"]},"182752":{"abstract":"This exploratory project, involving The University of Illinois at Chicago and Northwestern University, investigates the use of sensor-based technologies and general engineering approaches by fourth and fifth grade elementary students, and the effects of that use on how the students formulate research questions in environmental science and biological science and develop domain specific knowledge and concepts. <br\/><br\/>Teachers, students, and researchers are partnering with the research team to contribute to an iterative process that ensures a diversity of inputs to the approach and design, as they explore opportunities and challenges of using the sensing technologies while learning science. Several research questions are considered in this process and include: Which scientific characteristics are appropriate for elementary school students to grapple with, and which do they struggle with on a conceptual level? Which concepts or processes are more motivating for students? How can an already rich bounty of software technologies for gathering, storing, visualizing, and working with data in instrumented investigations of animal behavior be leveraged? What kinds of new tools are needed to extend those capabilities? How can activities be structured by educators to engage student interest and connect classroom work to field investigations? How can educators and technologists design instruction, materials, and learning technologies in ways that foster students' abilities to formulate scientific questions, choose measures, and plan effective investigations? What pragmatic and content area concerns need to be addressed for teachers to support engineering-enhanced ecological research? The research questions and analysis include observations of small group and classroom discourse, student work products, and reflective grounded interviews to investigate aspects of practice, operationalization of research questions, and examination of research designs, evidence-based argumentation, and explanatory processes. <br\/><br\/>For sensing technologies and their impact on learning to be fully understood, there are design factors that must be considered. This research is providing the field of learning sciences with some much needed information on design factors that involve sensor-based technologies and domain-based knowledge on scientific practices and engineering approaches to student learning. This interdisciplinary project makes contributions to the fields of learning technologies, engineering education, and biological sciences.","title":"EXP: Using Technologies to Engage Learners in the Scientific Practices of Investigating Rich Behavioral and Ecological Questions","awardID":"1124495","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":["552897","552898",489637,"533275","539435"],"PO":["560894"]},"181311":{"abstract":"This award is dedicated to the new research on the analysis of Boolean functions. Boolean functions (i.e., mappings from n bits to 1 bit) are one of the most basic objects of study in computer science: they arise in areas as diverse as cryptography, error-correcting codes, learning theory, and circuit design. One of the most effective tools for studying Boolean functions is by considering their Fourier transform and related analytic properties. <br\/><br\/>The PI has been at the forefront of research on analysis of Boolean functions over the last decade and will further develop theory and applications via an attack on three important unsolved problems:<br\/><br\/>1. The Fourier Entropy-Influence Conjecture on how \"spread out\" the Fourier coefficients of a Boolean function can be. Proving this conjecture would have important consequences for learning theory.<br\/>2. The Aaronson-Ambainis Conjecture on influences of low-degree Boolean functions. This conjecture has direct relevance to understanding the power of quantum computation.<br\/>3. The Gotsman-Linial Conjecture on functions computable by the sign of a low-degree polynomial. This is a major problem in the field of concrete complexity.<br\/><br\/>Analysis of Boolean functions has had broad application throughout computer science; it has also had interdisciplinary application through its use in mathematics, statistical physics, and economics. The PI will further develop and spread the impact of the area by writing the first textbook on analysis of Boolean functions. The textbook will be released freely, in installments on a blog. This will not only enhance the connection between research and education, it will foster learning for computer scientists (and aspiring computer scientists) regardless of status and geographic location. Finally, the PI will continue to make broader impact through advising and guiding graduate students and postdoctoral researchers, and through widely disseminating research results.","title":"AF: Small: Analysis of Boolean Functions","awardID":"1116594","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7928","name":"QUANTUM COMPUTING"}}],"PIcoPI":["550547"],"PO":["565157"]},"183973":{"abstract":"Proposal: OISE- 1131011<br\/>PI\/Institution: Hsieh, M. Ani, Drexel University<br\/><br\/>Dr. M. Ani Hsieh from Drexel University and Dr. Rafael Fierro from the University of New Mexico propose to organize an International Research Experience for Students (IRES) program with Brazilian collaborators Dr. Luiz Chaimowicz and Dr. Mario Campos both from the Federal University of Minas Gerais in Belo Horizonte, Brazil, to develop a multi-faceted approach to study multi-robot system for reliable execution of large scale cooperative tasks. The PIs will focus on four main topics related to multi-robot systems and cooperative control: (a) execution of complex task using robot swarms; (b) distributed autonomous assembly; (c) ensemble synthesis of distributed coordination strategies; and (d) intentional sensing via prioritized detection and active learning. <br\/><br\/>This three-year IRES program also provides undergraduate and graduate students with a unique opportunity to work with an interdisciplinary and international research on the design of multi-robot systems integrating theory and hardware. The students will also gain new perspectives on the use of autonomous robots to accomplish coordinated tasks within a complex environment and with limited resources.<br\/><br\/>This award is jointly funded by the Division of Information and Intelligent Systems of the NSF Directorate for Computer and Information Science and Engineering and the Office of International Science and Engineering.","title":"IRES: US-Brazil: Multi-Robot Systems for Large Scale Cooperative Tasks","awardID":"1131011","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7727","name":"IRES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["551322"],"PO":["559975"]},"181553":{"abstract":"Mobile devices such as smartphones, netbooks and laptops are increasingly beginning to store vast amounts of personal information, such as email, friend lists, current location, and passwords to online banking websites. They are therefore swiftly becoming prized bounties for malicious entities. This project is investigating new techniques to detect malicious software on mobile devices. <br\/><br\/>This project is investigating three key thrusts (1) energy-aware malware detection, (2) malware detector protection using a new hardware architecture called Limited Local Memory, and (3) collaborative mobile malware detection in a social network environment. The first thrust develops a framework to quantitatively investigate how the energy-constrained nature of mobile devices impacts their ability to run malware detection tools. It is then using the framework to explore energy-aware malware detection. The second thrust explores how emerging multicore technology on smartphones can be usefully leveraged for security if each core is equipped with a small amount of private memory. The third trend explores how the convergence of smartphones and social networking can enable better malware detection.<br\/><br\/>The primary contribution of the project is in acknowledging the need for novel approaches for mobile malware detection. As we increasingly rely on our smartphones to support our daily activities, their security becomes paramount. The outcomes of the project are being disseminated to increase public awareness of mobile malware and anti-malware. In addition, course material related to the project will be incorporated into the Master's degree curriculum at Rutgers.","title":"TC: Small: Exploring Malware Detection on Mobile Platforms","awardID":"1117711","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[486425,486426],"PO":["564223"]},"181201":{"abstract":"In the recent past, several application scenarios have emerged that require large-scale deployment of communication network infrastructure such as packet-switched wireline networks, mobile cellular wireless networks, and distributed sensor networks. In this project, the problem of efficient communication of information in multiterminal systems, where a multiuser channel must be shared among several users in the network is addressed. The new coding methods developed in this project shed light on intricate structural aspects of abstract groups. The development of efficient coding techniques has broad impact on the next generation of communication networks. <br\/><br\/>In this project, the development of a unified framework to address a class of network communication problems based on new multiuser code ensembles constructed from nested linear codes is studied. In particular, the problem of transmission of information over general discrete memoryless broadcast channels is considered. This problem has received a great deal of attention in the last thirty years. This approach is then applied to other multiuser channels such as the interference channel. For these problems, the average performance of nested linear code ensembles is strictly better than that of the standard unstructured code ensembles. The development of a methodology to compute the performance limits of such coding schemes (which are finite dimensional yet non-convex optimization problems) efficiently with current technology is considered. This project also considers the development of practical constructions of codes with computationally efficient encoding and decoding algorithms and procedures. This is accomplished by putting additional sparsity constraints on the generator and parity-check matrices of these codes.","title":"CIF: Small: A New Coding Paradigm for Communication Over Broadcast Channels Using Nested Linear Codes: A Duality of Structure and Randomness","awardID":"1116021","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[485560],"PO":["564924"]},"181322":{"abstract":"This interdisciplinary research seeks to understand how website design and content influence psychological processes and attitudinal and behavioral outcomes on violent and non-violent ideological websites. A content analysis study will be conducted to identify and compare the level and nature of website credibility, interactivity, and persuasion tactics for ideological websites (violent and non-violent) and for non-ideological websites. Relationships of these variables to website usefulness for ideology dissemination and psychological processes such as identity expression, and dehumanization will also be examined. Next, a series of experiments examining causal influences of key website characteristics (credibility, interactivity, and persuasion) on website users' knowledge, attitudes, and behavioral intentions will be conducted. These studies will compare the effects of these characteristics for ideological websites advocating violence versus non-violence. Relevant user characteristics (e.g., demographics, social identity, self-esteem, physiological arousal) will be captured for purposes of model building and testing for moderating influences. In these experiments, simulated websites will be developed to represent varying facets of credibility, interactivity, and persuasion. Human participants will be asked to navigate through these websites and respond to discussion threads, explore related links, fill out short questionnaires, and engage in other activities intended to assess key outcomes. Measures of knowledge, attitudes, and intentions will be assessed before and after website exposure for comparison. By leveraging an interdisciplinary approach to the growing number and presence of ideological groups online, this series of studies will lead to new theories and models for future research and dissemination of educational websites serving public interests. <br\/><br\/>New knowledge will be developed by examining the specific facets of credibility, interactivity, and persuasion, which have not previously been studied with respect to ideologically motivated attitudes and behavior. An important comparison of violent and non-violent ideological websites will also contribute uniquely to better understanding the perceptions of and responses to ideologies through human-centered computing. This collaborative effort will also develop and demonstrate methods for future integrated research, for team members and the broader research community. Although the investigation and findings will focus on ideological website design and communication, the framework developed will also be relevant to studying the impact of website design on outcomes in other areas such as online education. <br\/><br\/>The combination of theoretical and methodological backgrounds required to conduct the experiments will contribute to the research training of doctoral students and undergraduate research assistants in Psychology, Communication, and Management Information Systems. Findings from this research are likely to also have a number of practical implications for educating the general public about ideological websites and how they attempt to influence and persuade individuals who visit these sites. In addition, dissemination of the results through the professional channels of several sciences will achieve the broader impact of contributing to multiple academic fields.","title":"HCC: Small: Website Design, Content, and Ideological Communication","awardID":"1116653","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[485851,485852,485853],"PO":["564456"]},"180475":{"abstract":"This project addresses open questions and challenges in search theory, energy-efficient networked robotics, and fish biology. A network of robotic boats which can track many fish in shallow waters over extended periods of time are deployed in invasive carp infested waters. Provably correct cooperative search and tracking algorithms are developed, energy efficiency is studied at multiple levels including navigation, sensing, communication and complete system, communication protocols for controllable mobile entities are studied, and data analysis algorithms are developed.<br\/><br\/>The project provides a means to sustainably reduce invasive carp populations in US lakes without impacting other wildlife, thus solving a major environmental problem. Robots are shown to serve as a major scientific instrument for environmental scientists. The educational activities promote the results of this research to high school, undergraduate and graduate students, as well as educators across the country. A summer research experience is offered which blends mathematics, computer science and biology. Participation of students from under-represented groups is ensured through collaborations with predominantly Native American schools, as well as Central State University which has a 96% African-American student population. The project simultaneously raises awareness of environmental issues and attracts students to science and engineering.","title":"RI: Large: Collaborative Research: A Robotic Network for Locating and Removing Invasive Carp from Inland Lakes","awardID":"1111507","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["530045"],"PO":["564069"]},"181212":{"abstract":"In hospitals, technology has become pervasive and indispensable during medical crises. At home, technology proliferates as computerized health monitoring systems and, perhaps in the future, as assistive \"humanoid\" robots. Meanwhile, our everyday environments remain essentially conventional: low-tech and ill-adaptive to dramatic life changes. This social condition places strain on healthcare and family support systems, and represents a failure of scientists, engineers and architects to support independent living. <br\/>The overall aim of this effort is to enhance everyday environments with intelligent hardware promoting independent living. This project is focused on a discrete component of an envisioned suite of networked, robotic furniture integrated into existing living environments: an Assistive, Robotic Table [ART]. ART is the hybrid of a typical nightstand and the over-the-bed table found in hospital rooms, comprised of a novel \"continuum robotic\" table surface that gently folds, extends, and reconfigures to support work and leisure activities; a smart storage volume that physically manages and delivers personal effects; and an accessorized headboard. These components of ART recognize, communicate with, and partly remember each other in interaction with human users and with other components of the suite. <br\/>The key deliverable for this award is the full-scale, working ART prototype performing \"going-to-bed\" and \"awaking\" scenarios for three target groups. Our trans-disciplinary team will develop this complex physical-digital artifact by way of iterative design and evaluation activities that recognize engineering design, architectural design and human-centered design as inseparable. Key outcomes of the research are the \"continuum robotic\" surface as well as an innovative approach to human mobility and its metrics for intelligent, physical artifacts. The key broader impact of the research is intelligent \"architectural robotic\" ART, empowering people to remain in their homes for as long as possible, even as their physical capabilities alter over time; and, in more grave circumstances, affording people some semblance of feeling \"at home\" as user and ART move to assisted care facilities. This work is jointly funded by the Office of International Science and Engineering.","title":"SHB: Small: An Assistive, Robotic Table [ART] Promoting Independent Living","awardID":"1116075","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["563342","563341",485586],"PO":["564768"]},"181575":{"abstract":"This project addresses programming challenges posed by the new trend in multicore computing.<br\/><br\/>Multithreaded programs are difficult to write, test, and debug. They often contain numerous insidious concurrency errors, including data races, atomicity violations, and order violations, which we broadly define to be races. A good deal of prior research has focused on race detection. However, little progress has been made to help developers fix races because existing systems for fixing races work only with a small, fixed set of race patterns and, for the most part, do not work with simple order violations, a common type of concurrency errors.<br\/><br\/>The research objective of this project, LOOM: a Language and System for Bypassing and Diagnosing Concurrency Errors, is to create effective systems and technologies to help developers fix races. A preliminary study revealed a key challenge yet to be addressed on fixing races that is, how to help developers immediately protect deployed programs from known races. Even with the correct diagnosis of a race, fixing this race in a deployed program is complicated and time consuming. This delay leaves large vulnerability windows potentially compromising reliability and security.<br\/><br\/>To address these challenges, the LOOM project is creating an intuitive, expressive synchronization language and a system called LOOM for bypassing races in live programs. The language enables developers to write declarative, succinct execution filters to describe their synchronization intents on code. To fix races, LOOM installs these filters in live programs for immediate protection against races, until a software update is available and the program can be restarted.<br\/><br\/>The greatest impact of this project will be a new, effective language and system and novel technologies to improve the reliability of multithreaded program, benefiting business, government, and individuals.","title":"CSR: Small: LOOM: a Language and System for Bypassing and Diagnosing Concurrency Errors","awardID":"1117805","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["508314"],"PO":["551712"]},"181344":{"abstract":"Text-based passwords are the most commonly used mechanism for authenticating users to computer systems, but are often easy for attackers to compromise. To mitigate the danger of such attacks, system administrators use password-composition policies, which force newly created passwords to adhere to a set of requirements intended to make them harder to guess. Although it is generally believed that reasonable password-composition policies make passwords harder to guess, and hence more secure, research has not been able to precisely quantify the level of resistance to password guessing provided by different password-composition policies or the individual requirements of which they are comprised. Beyond their affect on the guessability of passwords, password-composition policies also affect users' behavior. For example, certain password-composition policies that lead to more-difficult-to-predict passwords may also lead users to write down their passwords more readily, reuse them across accounts, or forget them more often. Such behavior can both affect an adversary's ability to guess passwords, and raise the cost of administering a system.<br\/><br\/>This project will substantially contribute to the understanding of the effects of password-composition policies on the security and usability of text-based passwords. The results of this research will be applicable to almost all computer systems that use text-based passwords, and will allow administrators to better select suitable password-composition policies, thus rendering them less susceptible to account compromise. More specifically, this project will involve collecting sets of passwords (or data about passwords) created under different password-composition policies and data about the associated user behaviors, and analyzing them for security and usability. Sets of up to tens of thousands of passwords or statistics about them will be collected via online studies, actual field data from two institutions, and from paper-and-pencil surveys and lab studies. This data will be analyzed using several new methods, including an approach for calculating how long it would take for various state-of-the-art password-guessing tools or algorithms to guess the passwords, and a new method for approximating the entropy of passwords from smaller datasets than was previously feasible. Based on this methodology, this research will: (1) measure the guessability of passwords generated under multiple different password-composition policies more accurately than was previously possible; (2) empirically assess the usefulness of entropy approximations (a common, but questioned, measure of password strength) as a measure of password guessability by state-of-the-art password-guessing algorithms; and (3) compare the usability of and user sentiment engendered by each password-composition policy to develop a holistic understanding of the merits of policies. This will enable the development of a set of actionable guidelines for administrators that will help them select password-composition policies appropriate for their user populations and security requirements. Two graduate students will be directly involved in this research project.","title":"TC: Small: An Empirical Study of Text-based Passwords and Their Users","awardID":"1116776","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["563508","519675","553878"],"PO":["565136"]},"181465":{"abstract":"Multi-core processors are becoming prevalent and provide means for continuing to increase our computational capacity. These emerging platforms with multiple processing cores on chip offer the capability to run multiple programs simultaneously, thereby increasing the processing power of computing systems. However, since the running programs often share multi-core resources, execution interference effects between such programs can hurt their performance. Often times, software obliviousness to this underlying hardware behavior exacerbate the multi-core performance problem. Such adverse effects limit our computational progress in areas where interference can be detrimental such as high-performance computing and cloud computing, and could further complicate the predictability and deployment of these advanced processors in mission-critical domains such as avionics and automobiles. Therefore, understanding software behavior and Interference effects on multi-core processors is crucial to harnessing their full potential.<br\/><br\/>In this research the investigators do preliminary studies of the issues arising from execution interference between multiple software threads on multi-core processor platforms. This research involves revisiting how hardware resource management can account for application-level constraints (such as performance isolation, fairness, and priority) by enhancing the interface between hardware and the Operating System (OS), and studying the hardware and software overheads. This research lays the groundwork for the hardware-OS interaction based on active fine-grained monitoring of resources and a two-way adaptation between both the hardware and OS to tightly control the effects of interference between threads.","title":"SHF: Small: Software and Hardware Integration with Feedback and Transparency for Many-Core Computing","awardID":"1117243","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["502189","502137"],"PO":["565272"]},"180376":{"abstract":"Computer networks, in particular the Internet, represent critical infrastructure for business, government, military, and personal communication. Several recent trends in technology and network use have pushed the capabilities required of the Internet beyond what can be provided by the currently deployed infrastructure. This project develops a new architectural design for the Internet of the near future that represents a transformative shift to enable sustained innovation in the core of the network, using economic principles. The core idea of this new network architecture is to support choice as the central aspect of the architecture. A network built on these principles will be able to adapt to emerging solutions for current and future challenges. The network architecture designed and prototyped in this work aims to (1) encourage alternatives to allow users to choose from a range of services, (2) let users vote with their wallet to reward superior and innovative services, (3) provide the mechanisms to stay informed on available alternatives and their performances. Solutions are approached from different directions, reflecting the team's multidisciplinary expertise in computer networking, network systems, management science, and network economics.<br\/><br\/>The broader impact of this project contributes to enhancing the functionality and usability of the next-generation Internet, which is expected to become an important piece of infrastructure. The project also integrates research and education of graduate and undergraduate students at the participating organizations, where current efforts to integrate underrepresented minorities are continued. Results from this work are disseminated in the form of an open-source prototype and publications.","title":"NeTS: Large: Collaborative Research: Network Innovation through Choice","awardID":"1111040","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["530999",483390],"PO":["565090"]},"181245":{"abstract":"It is increasingly important to design cluster systems that efficiently support data-intensive computing. Parallel scientific and multimedia applications often perform large amounts of I\/O either indirectly, due to swapping, or directly, due to temporary file accesses. As the disparity between the speeds of magnetic disk and other hardware such as RAM, interconnection networks, and flash continues to grow, the cost of accessing disk will increasingly become the bottleneck to system performance. <br\/><br\/>The objective of our project is to design and implement a fast backing storage system for clusters and local area networks. Our system provides a single device interface on top of multiple heterogeneous cluster-wide physical storage, particularly targeting fast random-access storage such as Network RAM and flash. Our work will free the OS from requiring multiple device-specific policies in its paging and file systems for every combination of underlying physical storage devices. As new technologies are developed, the low-level part of our system will incorporate them into its set of heterogeneous physical storage, but the OS will continue to use the same high-level interface of our system, that of a single, fast, random-access device.<br\/><br\/>The main goals of our work are: to take advantage of all types of fast storage in a cluster; to provide a single device interface that is independent of the underlying physical storage; to create a storage system that can adapt to changes in resource utilization and capacity; and to develop and examine policies for data placement and data migration between underlying devices.","title":"CSR: Small: RUI: A Fast Backing Store System on top of Network RAM, Flash, and other Cluster-wide Storage","awardID":"1116224","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[485663],"PO":["565255"]},"182576":{"abstract":"The PIs are aiming to investigate how virtual world 3D technology can be used to address the limited opportunities adult immigrants and refugees have for exploring and practicing their English in authentic settings without the risk of seeming inarticulate. In partnership with WonderBuilders, Inc., Springfield Technical Community College is creating the 3D virtual environment to integrated into ELS (English as a Second Language) classes at the College. Using Open Wonderland, the PIs are creating a complete virtual campus in which students learning English can interact in virtual campus settings without being embarassed about their language capabilities. College students and personnel are also participating in the on-line community along with the English-language learners. Research is investigating development of confidence and improved competencies and experiences of engagement when the opportunity is given to practice and apply newly-learned grammar and vocabulary in real-world contexts. In addition to hypotheses about language learning, the PIs hypothesize that if engagement is in the context of campus activities, these students, who often hold full-time jobs and have families to take care of, will have more opportunities to engage in the life of the college community, therefore feeling and being more connected, and therefore being more apt to continue with their language learning and then to successfully matriculate and graduate.<br\/><br\/>This project addresses two educational challenges. First, helping adult immigrants and refugees learn English, prepare for, and matriculate in higher education is a national challenge. This project is creating a model for such learning and advancement. Second, there is much hype about the use of games and 3D virtual environments for promoting learning but not much research on the real possibilities of doing this and how to use such software effectively for education. This project is contributing to understanding of how to use 3D virtual technology effectively to promote learning.","title":"EXP: Exploring the Virtual World of Contextualized English Language Acquisition","awardID":"1123569","effectiveDate":"2011-09-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[489148,489149],"PO":["562669"]},"181487":{"abstract":"This award is devoted to the studies on the interface of computational and combinatorial geometry. Specifically, the relevant problems involve geometric arrangements, which are patterns formed, say, in the plane, when a number of geometric shapes are overlaid on top of each other. A surprising number of computational problems can be cast in terms of arrangements. Conversely, a significant number of combinatorial problems are equivalent to statements about arrangements. The PI will focus on the interplay of these two.<br\/><br\/>In slightly more technical detail, the PI will:<br\/>-- push the state of the art in the area of arrangements, solving some of the challenging open problems in the subject;<br\/>-- develop general techniques which will be of independent interest and which will find applications well beyond the set of problems listed in the proposal;<br\/>-- by looking at classical problems in a radically different way, find simple solutions and reveal connections between seemingly unrelated questions;<br\/>-- apply the machinery developed for dealing with arrangements of geometric objects to an entirely new set of problems.<br\/><br\/>The PI will supervise a PhD student and a postdoctoral fellow, guiding them in their research activities and acquainting them with the latest tools of combinatorial and computational geometry. The results obtained will be disseminated by participation in workshops and scientific conferences. Graduate and undergraduate students will be introduced to a number of current research problems in the subject.","title":"AF: Small: Mysteries of Geometric Arrangements","awardID":"1117336","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["518464"],"PO":["565157"]},"192377":{"abstract":"The wide proliferation of wireless services and applications with increasing bandwidth needs is rapidly creating a spectrum shortage. However, the problem is caused primarily by inefficient legacy spectrum allocation and utilization policies, so that even when some applications suffer from lack of bandwidth, there is idle capacity in the band they are using or other bands. This project develops and demonstrates a revolutionary approach for addressing spectrum scarcity and unlocking hidden communication capacity thereby increasing the reach and utility of wireless connectivity. The non-traditional communication technique studied in this research effort detects transmission opportunities that occur when incumbent primary users enjoy signal to noise ratio values that are higher than the minimum value required to maintain their quality of service. It then judicially exploits these opportunities while preserving the current quality of service of the primary users. <br\/><br\/>The project develops novel change detection methods that fuse goodness of fit tests and density estimation and similarity assessment using information theoretic methods to study network traffic and designs innovative distributed goodness of fit tests and density estimation and similarity assessment techniques implemented over an asynchronous communications network. It compares the performance of the distributed goodness of fit tests and density estimation and similarity assessment techniques with those of a new class of distributed cumulative sum (cumsum) change detection methods that it constructs generalizing cumsum methods that have been proposed in the literature in other application domains. Finally, it demonstrates experimentally the benefit of using these approaches to unlock hitherto hidden communication capacity and quantify the increase in local communication capacity created by using the new schemes.","title":"ProTOMAC: Proactive Transmit Opportunity Detection at the MAC Layer for Cognitive Radio Networks","awardID":"1212491","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[515560],"PO":["564898"]},"181135":{"abstract":"Today?s Internet runs Border Gateway Protocol (BGP), a complex inter-domain routing protocol. Over the past few years, there has been a growing consensus on the complexity and fragility of BGP routing. In addition to the problems of route oscillation and slow convergence, BGP has been shown to be susceptible to malicious attacks. Despite the wide range of proposed solutions to BGP's security vulnerabilities, there is currently a lack of a set of common tools for researchers to analyze, compare, and contrast the effectiveness of various schemes.<br\/><br\/>The goal of this project is to develop a unifying framework towards the design, analysis and implementation of provably secure Internet routing protocols. The first part of the project explores the use of Secure Network Datalog (SeNDlog), a declarative networking language for encoding secure Internet routing protocols. Language extensions to SeNDLog will be explored, in order to address practical deployments issues at Internet-scale, and facilitate formal analysis of a range of secure routing protocols. These extensions include customizable authentication, goal-oriented evaluation, key distribution and management, and modeling of adversaries. The second part of this project aims to identify security properties of Internet routing protocols, and formally specify them logically in terms of protocol execution traces. The third part of this project aims to design and implement a formal analysis methodology towards verifying SeNDlog programs for desired security properties specified in logic.<br\/><br\/>In terms of broader impact, this project will result a cleaner foundation towards the analysis and development of trustworthy routing protocols.","title":"TC: Small: Collaborative Research: Towards a Formal Framework for Analyzing and Implementing Secure Routing Protocols","awardID":"1115706","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550854"],"PO":["565327"]},"195424":{"abstract":"Abstract<br\/><br\/>The objective of this research is to address issues related to the platform revolution leading to a third generation of networked control systems. The approach is to address four fundamental issues: (i) How to provide delay guarantees over communication networks to support networked control? (ii) How to synchronize clocks over networks so as to enable consistent and timely control actions? (iii) What is an appropriate architecture to support mechanisms for reliable yet flexible control system design? (iv) How to provide cross-domains proofs of proper performance in both cyber and physical domains?<br\/><br\/>Intellectual Merit: Currently neither theory nor networking protocols provide solutions for communication with delay constraints. Coordination by time is fundamental to the next generation of event-cum-time-driven systems that cyber-physical systems constitute. Managing delays and timing in architecture is fundamental for cyberphysical systems. <br\/><br\/>Broader Impact: Process, aerospace, and automotive industries rely critically on feedback control loops. Any platform revolution will have major consequences. Enabling control over networks will give rise to new large scale applications, e.g., the grand challenge of developing zero-fatality highway systems, by networking cars traveling on a highway. This research will train graduate students on this new technology of networked control. The Convergence Lab (i) has employed minority undergraduate students, including a Ron McNair Scholar, as well as other undergraduate and high school researchers, (ii) hosts hundreds of high\/middle\/elementary school students annually in Engineering Open House. The research results will be presented at conferences and published in open literature.","title":"CPS: Small: Delays, Clocks, Timing and Reliability in Networked Control Systems: Theories, Protocols and Implementation","awardID":"1232602","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["541861"],"PO":["561889"]},"182356":{"abstract":"Virtual organizations are groups of individuals whose members and resources may be distributed geographically and structurally, yet who function as a coherent unit through the use of collaborative technology. In the context of business, virtual organizations offer the promise of growth and innovation through flexible and fluid structures, yet employees face the challenge of managing coordination costs as a result of the dynamic and evolving work. New collaborative technologies, such as those that facilitate communication and knowledge sharing as well as social media and task integration capabilities, offer coordination benefits that could counter, and possibly exceed, the coordination costs that arise from working in virtual organizations.<br\/><br\/>Through qualitative interviews of individuals and an online survey of working groups, this project will: (a) define and measure features of organization structure, collaborative technology, and workflow outcomes in a range of structures (including virtual organization structures) within a business organization adopting a new and emergent organizational structure, (b) describe the consequences (positive and negative) of different organization structures and collaborative technologies in terms of their impact on workflow outcomes, and (c) create a public web-based resource that can be used by the organizational and technology communities to better understand the kinds of structures and technologies that affect workflow outcomes.<br\/><br\/>Research on the intersection of virtual organization structures and collaborative technology is still in its infancy. Data collected from this unique empirical setting will provide critical insight into how new structures and new technologies influence each other as well as workflow outcomes. In addition to furthering scientific understanding of virtual organizations, a potentially transformative outcome of this research is facilitating understanding of virtual organizations for science, education, healthcare, and other types of organizations. Moreover, study results can be incorporated into the design and testing of collaborative technology, which could contribute to new advances in tools to support distributed work.","title":"VOSS: Virtual organizations in action: Understanding socio-technical systems through changes in structure and technology","awardID":"1122286","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["499499",488536],"PO":["565342"]},"181146":{"abstract":"This research will advance the state of the art in conversational character systems (Intelligent Virtual Agents) in two ways. First, it seeks to better understand the interplay of gesture and language in both generating the perception of personality and allowing participants to adapt to the ongoing conversational context. Second, it will use this understanding to build novel computational models for gesture and language generation that provide fine grained control over the perception of personality and support agent adaptation in response to the conversational context. The theoretical basis for the personality-based modeling in this project is the well-established \"Big Five\" model of personality, which consists of five orthogonal dimensions of individual variation.<br\/><br\/>The work on adaptation will be couched in the collaborative theory of language use and communication accommodation theory, which predict that communicative behavior varies based on partner specificity. Initial work will form a motion capture, video and audio corpus of three kinds of exchanges. This will be used to both study gestural entrainment during human interactions, determining if audio-based findings extend to the gestural domain, and to enhance scientific understanding of the relationship between gesture and personality. This will inform the modeling work which will build a joint model for personality-based language and gesture production. The model will extend a pilot study on gesture generation for extraversion to three Big Five traits and integrate it with personality-based language generation. An experimental stage will validate these models and study the interactions of movement and language. The research will also study the role of adaptation. Questions to be answered include: (1) whether people gesturally entrain with computers, or indeed produce any gestures while communicating with a computer, (2) whether computers? gestural entrainment promotes similar levels of affiliation as observed with vocal entrainment, and (3) whether changing gestural entrainment over the course of an interaction is more powerful than aligning gestures from the outset of an interaction. <br\/><br\/>Character systems are becoming increasingly important for a range of applications, from virtual worlds to tutoring systems. There is growing evidence that the way personality is presented through these characters, and how well they mimic expected human behavior like entrainment, has a direct impact on the effectiveness of the applications in which they are used. For example, it will have a direct impact on student learning. As these applications become more ubiquitous in society, particularly among children, it is important to be able to harness their full benefit, and indeed, avoid unintended negative consequences. This involves both advances in computational models that allow an agent to reflect a given personality and adapt to a human user, and also a deeper understanding of the role of personality and adaptation in effective human-agent interactions.","title":"HCC: Small: Collaborative Research: Gestural and Linguistic Expressivity and Entrainment in Dialogue","awardID":"1115742","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["542062","542063"],"PO":["564456"]},"181267":{"abstract":"The increase in processor clock frequencies from 1980-2003 has slowed down significantly in recent years. To improve computer performance computer architects are exploring parallel architectures including many-core architectures. In a many-core or multi-core architecture, processor cores with relatively low complexity are connected to memory and to each other via high-bandwidth on-chip interconnect. The most popular programming model for multi-cores is that of shared memory. In this memory model, programmers write different threads that can run on different processors all of which can share a single memory space. This means that the on-chip cache memory on the multi-core chip should behave like a large shared cache. Unfortunately, current schemes for cache coherence either suffer from lack of scalability or require large directories at each core significantly increasing chip area and power.<br\/><br\/>A directoryless cache coherence scheme is being investigated in this project that relies on the mechanism of execution migration. In execution migration, a thread?s context or state moves to the processor in whose cache the data resides. An important advantage of an execution migration architecture is that only a one-way trip is required to access data, since the thread moves to access data. In conventional data migration architectures, a round-trip is required to access data ? a request is sent to the location where the data resides and then the data is sent to the requesting thread. Further, only one copy of data need be present on chip if execution migration is used, since threads can move. This means that cache coherence is trivially ensured. Moreover, the chip can store more distinct data, since data is not replicated and this reduces off-chip access rates. Finally, an execution migration architecture can exploit the plentiful on-chip bandwidth available to speed up thread migration, thereby reducing data access latency.<br\/><br\/>There are challenges associated with this architecture corresponding to contention for shared data across multiple threads, and the energy required to move thread contexts. The first challenge is being met through judicious replication of data at the program source level or compiler level. In particular, limited read copies of data are created across multiple threads. Since these copies only exist in between two writes to the data, coherence is ensured as before without need for complex coherence logic. However, contention for shared data is significantly reduced. The second challenge of energy consumption is being met through migration of partial thread contexts ? if a stack machine is used as the processor core, energy consumption can be reduced by migrating a subset of the thread context corresponding to the top part of the stack instead of the entire stack.<br\/><br\/>In this project, an Execution Migration Machine with over 100 cores is being designed, and being evaluated using cycle-accurate simulation, and critical elements of the machine are being built on a Field Programmable Gate Array (FPGA). This project has the potential to meet the scalability and programmability challenges that face shared memory multi-core architectures. The Execution Migration Machine design will shed insight into how best thread migration can be used to enhance multi-core performance, possibly in combination with data migration. If successful, the project will impact the design of future multi-core processors through intelligent use of program and data migration.","title":"SHF: Small: Directoryless Shared Memory Using Execution Migration","awardID":"1116372","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["561979"],"PO":["366560"]},"181399":{"abstract":"Data is a key resource in this information age. The availability of data, however, often causes privacy concerns. Many data sharing scenarios require data be anonymized for privacy protection. Most existing data anonymization techniques, however, satisfy only weak privacy notions that rely on particular assumptions about the adversaries, and provide inadequate protection. In recent years, the elegant notion of differential privacy has gradually been accepted as the privacy notion of choice for answering statistical queries. Most research on differential privacy, however, focuses on answering interactive queries, and there are several negative results on publishing microdata while satisfying differential privacy. Regardless, many data sharing scenarios require sharing of microdata, and research is needed to bridge this gap.<br\/><br\/>This project aims at bridging the gap between the elegant notion of differential privacy, and the practical difficulty of publishing microdata while preserving utility. Building on the preliminary results of the PI on using random sampling together with \"safe\" k-anonymization to satisfy differential privacy, this project aims at advancing the state of the art of both scientific understanding and specific techniques for privacy-preserving microdata publishing. Research activities include developing (1) Practical anonymization methods that can be proven to satisfy differential privacy, while capable of handling high-dimensional data; (2) Relaxations of differential privacy that are more suitable for microdata publishing; (3) Privacy theory and techniques that are easily applied to a family of data sanitization algorithms called localized algorithms, enabling the usage of input perturbation techniques for provably-private microdata publishing; (4) Privacy notions and techniques for publishing social network data and network trace data.<br\/><br\/>Advances in data anonymization techniques will benefit the society by providing a better balance between the need to release data to serve public interest and the need to protect individuals' privacy. This project also involves developing a graduate seminar course on data privacy, and supports two graduate students.","title":"TC: Small: Provably Private Microdata Publishing","awardID":"1116991","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548254"],"PO":["565136"]},"183225":{"abstract":"Proposal #: 11-27084 <br\/>PI(s): Wang, Lei; Cui, Jun-Hong (June); Li, Baikun; O?Donnell; Wang, Bing <br\/>Institution: University of Connecticut<br\/>Title: MRI\/Dev.: Instrumentation for Sustainable Distributed Cyber-Aquatic Systems<br\/>Project Proposed:<br\/>This project, called DiCAS, developing a novel instrument and testbed environment based on an underwater sensor network platform that harvests energy underwater and incorporates power metering and power\/performance tradeoff-aware schemes and protocols for longer network life, considers specific underwater characteristics, such as underwater faults and communication link conditions. Adaptive strategies to save energy will be built as part of the work. The instrument enables research in\/with:<br\/>- Advanced instruments and tools that enable researchers to observe physical, chemical, and biological processes and monitor the aquatic environments in real time, across broad physical expanses and durations, continuously and reliably;<br\/>- Novel hardware and software for the cyber-aquatic system; <br\/>- Two types of testbeds: <br\/>-- Lake field testbed;<br\/>-- Sea field testbed, <br\/>with specific applications using the testbed for: <br\/>--- Resolving vertical mixing in the ocean;<br\/>--- Identifying\/predicting harmful algae; and <br\/>--- Monitoring distributed offshore oilfield infrastructure.<br\/><br\/>Broader Impacts: <br\/>This project, unique in its goals and expected results, exhibits potential for large broader impacts in the area of sustainable aquatic observation and exploration systems. The instrument will enable a wide range of research activities, from aquatic scientific research (such as oceanography, limnology, and hydrology) and pollution detection, to offshore oil\/gas exploration and coastal and harbor\/port protection. Planned is a unique hands-on learning environment for undergraduate and graduate students, as well as a program engaging K-12 students and teachers, particularly in underserved communities. The PIs have prior track record of involving women, minority, and undergraduate students in their research.","title":"MRI: Instrumentation Development for Sustainable Distributed Cyber-Aquatic Systems","awardID":"1127084","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":["511703","526410","564059",491358,"559204"],"PO":["557609"]},"184677":{"abstract":"The electric grid in the United States has evolved over the past century from a series of small independent community-based systems to one of the largest and most complex cyber-physical systems today. However, the established conditions that made the electric grid an engineering marvel are being challenged by major changes, the most important being a worldwide effort to mitigate climate change by reducing carbon emissions.<br\/><br\/>This research investigates key aspects of a computation and information foundation for future cyber-physical energy systems?the smart grids. The overall project objective is to support high penetrations of renewable energy sources, community based micro-grids, and the widespread use of electric cars and smart appliances.<br\/><br\/>The research has three interconnected components that, collectively, address issues of computation architecture, information hierarchy, and experimental modeling and validation. On computation architecture, the framework based on cloud computing is investigated for the scalable, consistent, and secure operations of smart grids. The research aims to quantify fundamental design tradeoffs among scalability, data consistency, security, and trustworthiness for emerging applications of smart grids. On information hierarchy, temporal and spatial characteristics of information hierarchy are investigated with the goal of gaining a foundational understanding on how information should be partitioned, collected, distributed, compressed, and aggregated. The research also develops an open and scalable experimental platform (SmartGridLab) for empirical investigations and testing of algorithms and concepts developed in this project. SmartGridLab integrates the hardware testbed with a software simulator so that software virtual nodes can interact with physical nodes in the testbed. This research also includes a significant education component aimed at integrating frontier research with undergraduate and graduate curricula.","title":"CPS:Medium:Collaborative Research:Information and Computation Hierarchy for Smart Grids","awardID":"1135872","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["554417"],"PO":["565239"]},"184688":{"abstract":"This project develops a framework for design automation of cyber-physical systems to augment human interaction with complex systems that integrate across computational and physical environments. As a design driver, the project develops a Body\/Brain Computer Interface (BBCI) for the population of functionally locked-in individuals, who are unable to interact with the physical world through movement and speech. The BBCI will enable communication with other humans through expressive language generation and interaction with the environment through robotic manipulators. <br\/><br\/>Utilizing advances in system-level design, this project develops a holistic framework for design and implementation of heterogeneous human-in-the-loop cyber-physical systems composed of physically distributed, networked components. It will advance BBCI technology by incorporating context aware inference and learning of task-specific human intent estimation in applications involving semi-autonomous robotic actuators and an efficient wireless communication framework.<br\/><br\/>The results of this project are expected to significantly speed up the design of complex cyber-physical systems. By accelerating the path from idea to prototype, this work shortens the time frame of and cost of development for assistive technology to improve the quality-of-life for functionally locked-in individuals. This project establishes an open prototyping platform and a design framework for rapid exploration of other novel human-in-the-loop applications. The open platform will foster undergraduate involvement in cyber-physical systems research, building confidence and expertise. In addition, new activities at the Museum of Science in Boston will engage visitors to experiment with systematic design principles in context of a brain computer interface application, while offering learning opportunities about basic brain functions.","title":"CPS: Medium: Collaborative Research: Holistic Design Methodology for Automated Implementation of Human-in-the-Loop Cyber-Physical Systems","awardID":"1136027","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["506513","540006","550436"],"PO":["564778"]},"186877":{"abstract":"Cognitive radio is a promising paradigm for dramatically increasing the utilization of wireless spectrum to support the continuing exponential growth in wireless traffic. Research on cognitive networks has mainly focused on sensing of spectrum opportunities and managing radio resources such that the primary users' quality of service is not compromised. Much less attention has been paid to the coexistence of secondary users, which may be associated with different cognitive networks and seek to operate in the same frequency bands. Effective coexistence of such users is essential for the success of future cognitive networks, and is the main objective of this project. In addition, the particularly open nature of cognitive radio raises significant new issues for the security and privacy of the transmitted data, as well as new opportunities for malicious behavior among cognitive or outside entities. The project addresses all of these issues in a holistic framework.<br\/><br\/>Coexistence requires effective allocation of radio resources in time, frequency, and space among multiple cognitive secondary users, while respecting primary interference constraints. The investigators are developing theoretical bounds for such radio resource management schemes and designing low-overhead distributed algorithms, which account for the incentives of competing secondary service providers as well as the stronger security and privacy measures needed in a cognitive environment. Information-theoretic physical-layer security techniques are being utilized to develop provably secure paradigms for secondary cognitive users and game-theoretic models are being adapted to study the robustness of these networks to various jamming attacks and other malicious behavior.","title":"Collaborative Research: Robust and Secure Cognitive Radio Networks","awardID":"1147786","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["560218"],"PO":["557315"]},"183149":{"abstract":"Proposal #: 11-26688<br\/>PI(s): Yang, Mei<br\/> Jiang, Yingtao; Qi, Minghao<br\/>Institution: University of Nevada, Las Vegas<br\/>Title: MRI\/Dev.: Highly Scalable and Reconfigurable Testbed in Support of Future Many-Core and System-on-Chip Research and Design Exploration<br\/>Project Proposed:<br\/>This project from an EPSCoR state, aiming to develop a highly scalable and reconfigurable multi-board-based testbed which can emulate and validate future large-scale many-core and system-on-chip systems, enhances the future for design of multi-core systems. Specifically, this testbed efficiently and effectively emulates all the functionalities that are perceived at both the network-on-chip (NoC) and the full-system levels. The proposed work establishes a high performance, multi-core testbed in Nevada, enabling the following research projects in system-on-chip design:<br\/>- Emulation of new computer architecture designs,<br\/>- Design space exploration for NoC-based many-core designs,<br\/>- Emulation of hybrid photonic-electronic NoC architectures, and<br\/>- Traffic modeling and benchmark development.<br\/>The work aims to develop a flexible testbed for NoC architectures seen to be key to the future of multiprocessor design. In recent years, computer architecture speed-ups have begun to rely exclusively on multi-core paradigms instead of faster cores. There is a general consensus that these many cores have to be linked together through a functionally correct, power-efficient, and reliable on-chip communication architecture, now widely known as network-on-chip. Testbeds of this type are critical to economic vitality in the computer industry.<br\/>Broader Impacts: <br\/>This instrumentation should provide a unique research facility for faculty and graduate students to conduct research on NoC architecture technology and education. The testbed will be made available to researchers around the country through a cyberinfrastructure remote access mechanism. The proposed testbed enhances Ph.D. production in an EPSCoR state and solidifies UNLV?s position in NoC architecture research.","title":"MRI: Development of a Highly Scalable and Reconfigurable Testbed in Support of Future Many-Core and System-on-Chip Research and Design Exploration","awardID":"1126688","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[491030,491031,491032],"PO":["543539"]},"187659":{"abstract":"The workshop aims to identify the research challenges and opportunities for transforming the scientific discovery process through advances in computing and information sciences in general, and intelligent systems in particular. It seeks to define a research agenda in Discovery Informatics. The workshop is organized around three themes: (1) efficient experimentation and discovery processes, (2) practical issues in building and refining predictive models from scientific data, and (3) social computing for science.<br\/><br\/>The participants include experts and visionaries in the areas of knowledge representation and inference, machine learning and data mining, experiment design and planning, information integration, computational models of discovery, collaborative technologies, robotics, social networks, visualization, and representative application (science) domains. <br\/><br\/>Research in Discovery Informatics is expected to integrate advances in multiple subdisciplines of artificial intelligence and cognitive science to develop the next generation informatics driven exploratory apparatus for scientific discovery. The resulting formal frameworks and computational tools have the potential to not only accelerate discovery but enable new modes of discovery by providing the tools that empower scientists to reach across disciplinary boundaries. Such tools can also contribute to enhanced modes of teaching and learning in science, technology, engineering, and mathematics (STEM) disciplines.<br\/><br\/>The results of the workshop (including the workshop report) will be freely disseminated to the larger scientific research and educational community.","title":"IIS: III: Workshop on Discovery Informatics","awardID":"1151951","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563687"],"PO":["560586"]},"186119":{"abstract":"The traveling salesperson problem (TSP) is a benchmark problem for combinatorial optimization that asks for a shortest tour that visits all the cities in a given network. The graph version where the distances arise from an underlying undirected graph captures a significant portion of the difficulty of designing good algorithms for solving this problem. This proposal will develop a consolidated understanding of the new techniques used in recent developments in the design of improved approximation algorithms for the graph-TSP problem and suggest new ones to move towards optimal performance guarantees. It will also examine carefully which of these will apply to the more general metric version of the problem, as well their relation to the well-known subtour elimination linear programming relaxation for the problem.<br\/><br\/>Designing better heuristic methods for solving prototypically hard optimization problems can improve our ability to solve larger real-scale instances arising in a variety of practical applications. This project will develop methods for improving the mathematically provable quality of the heuristic solutions for the fundamental traveling salesperson problem. New methods developed by the proposal will find applications to broader classes of problems in designing fault-tolerant minimum-distance networks, and also lead to new insights in graph theory and combinatorial optimization.","title":"EAGER: New Techniques for Graph-TSP","awardID":"1143998","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["561985"],"PO":["565251"]},"181631":{"abstract":"Because of operational malpractice or security attacks, every Internet IP prefix (i.e., every block of IP addresses) can undergo various routing anomalies, causing business loss, identity theft, or many other devastating effects. For example, in prefix hijacking, an attacker can hijack traffic toward legitimate users of a prefix. However, a solution that is both effective in monitoring anomalies and resilient against attacker circumvention is yet to be seen. This research will investigate, design, and evaluate a new approach to reliable monitoring of IP prefixes. Dubbed Buddyguard, it surrounds a prefix with a buddy system composed of buddy prefixes, or buddies, and monitors the behavior of the prefix against its buddies. The scientific contributions will include: (i) A Buddyguard architecture for monitoring routing anomalies of IP prefixes, including various difficult prefix hijacking cases; (ii) A buddy discovery, selection and maintenance algorithm to choose buddies for a monitored prefix, including a rigorous analysis on what and how many buddies are needed to effectively detect routing anomalies and be resilient against attackers? circumvention; (iii) A scalable and easy-to-deploy algorithm to use a prefix?s buddies to detect routing anomalies reliably, quickly, and resiliently; and (iv) A deep and thorough understanding on the feasibility, advantages, performance, and limitations of using a buddy system for prefix monitoring. Once deployed, Buddyguard will be offered as a service to the public. The results as well as tools, software code, and documents from this research will also be disseminated. This research also incorporates a solid curriculum and education plan.","title":"NeTS: Small: Buddyguard - A Buddy System for Reliable IP Prefix Monitoring","awardID":"1118101","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["446168"],"PO":["565303"]},"181543":{"abstract":"In this project, we are exploring the association between computing tasks (jobs) and the computing resources assigned to run those jobs to improve the ability to deploy tasks to satisfy security requirements. Historically, the owners of the computing tasks also owned their computing resources, so they configured their resources to run their tasks efficiently and securely. However, configuring tasks to run securely has become so complex that the key knowledge is now distributed among several parties: cloud vendors configure host systems, OS distributors configure cloud instances, customers configure their application programs and network policies. The goal is to be able to collect this expertise into a single model to reason about how to deploy computing tasks to satisfy their security requirements. To do this, we are integrating the myriad of integrity measurement mechanisms into a comprehensive integrity measurement framework to enable reasoning about the satisfaction of a computing task's data security from installation to completion. Using this model, we are building a customer-centric utility computing service to choose an assignment of resources for computing tasks that satisfies data security requirements. When a customer deploys a computing task via such a service, the service will construct integrity-verified channels to her running jobs, which are secure communication channels that guarantee that the data sender adheres to a data security policy. Using such services, customers will be able to deploy computing jobs among cloud resources managed by several parties, while assuring that their data security requirements are satisfied automatically.","title":"TC: Small: Towards Customer-Centric Utility Computing","awardID":"1117692","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["547471"],"PO":["565327"]},"181664":{"abstract":"We will explore in this EAGER proposal new methodologies for matching algorithms and code to architecture, allowing the efficient execution of large complex workflows using an ensemble of available computing architectures ranging from distributed memory multi-core supercomputers to graphic processing units and high performance data intensive computing devices. In this exploratory work we will focus on the matching of computer architectures to computational needs and a tuning of the methodology of Uncertainty Quantification to the architectures at hand. We will first instrument our suite of tools to record computational, memory, data and energy usage. This data will then be analyzed and modeled to create guidelines for prediction of effective and efficient usage. The facilities available to us at the University at Buffalo, Center for Computation Research (CCR) and on the xD framework of resource providers will allow us to conduct this investigation.","title":"EAGER: Innovative Methods for Computational Workflow Optimization","awardID":"1118260","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["361346"],"PO":["565247"]},"181312":{"abstract":"Explosive growth in volume and complexity of data exacerbates the key challenge facing the management of massive data in a way that fundamentally improves the ease and efficacy of their usage. Exascale storage systems in general rely on hierarchically structured namespace that leads to severe performance bottlenecks and makes it hard to support real-time queries on multi-dimensional attributes. Thus, existing storage systems, characterized by the hierarchical directory tree structure, are not scalable in light of the explosive growth in both the volume and the complexity of data. As a result, directory-tree based hierarchical namespace has become restrictive, difficult to use, and limited in scalability for today's large-scale file systems.<br\/><br\/>This project investigates a novel semantic-aware namespace scheme to provide dynamic and adaptive namespace management and support typical file-based operations in Exascale file systems. The project leverages semantic correlations among files and exploits the evolution of metadata attributes to support customized namespace management, with the end goal of efficiently facilitating file identification and end users data lookup. This project provides significant performance improvements for existing file systems in Exascale file systems. Since Exascale file systems constitute one of the backbones of the high-performance computing infrastructure, the semantic-aware techniques also benefits a great number of scientific and engineering data-intensive applications. This project strengthens the ongoing development of high performance computing infrastructures at both UNL and UMaine. The project enhances undergraduate and graduate education at both participating institutions and outreach to K-12 in UMaine via an ongoing NSF-funded ITEST program.","title":"CSR: Small: Collaborative Research: SANE: Semantic-Aware Namespace in Exascale File Systems","awardID":"1116606","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["557136",485826,"366560",485828],"PO":["565255"]},"181433":{"abstract":"Risk analysis and monitoring of continuously arriving data are required by a wide range of domains critical to our individual and societal well-being, from the military to the financial sector, from medicine to homeland security, from man-made to natural disasters. These application areas use patterns or models to differentiate behavior of varying degrees of importance or risk, both in terms of the value for a particular variable, relationships between different variables, and changes across time. The objective of this project is the design, development, and assessment of visual analytics technology to support the real-time interactive analysis of data streams that focuses on creating and using models of stream behavior to identify instances of potentially important activities and risks in the data. <br\/><br\/>The research breaks new ground in the design of innovative exploration techniques of high-volume streaming data, with a focus on visualization and interactions of competing and complementary models extracted from the stream data and of change descriptions derived from each. Novel technology includes computational and visual methods for model formation, management, and model change analysis. Efficient indexing and compression of the history of how data and models change provide analysts with the ability to compare and contrast similar events over long periods of time. Linked views of the different information spaces (data, model, change, and history), and powerful interaction tools to support exploration and model building enable analysts to confirm the expected and uncover the unexpected. <br\/><br\/>The results of this project are expected to have significant impact is a wide range of domains that rely on extracting information from real-time digital data, including finance, medicine, and homeland security. In particular, tools are developed for solving financial risk and fraud detection problems critical to the economic well-being of individuals and organizations. Educational material from using the technology in courses are freely available, along with source code and data sets, via the project web page (http:\/\/davis.wpi.edu\/~xmdv).","title":"CGV: Small: Model-Driven Visual Analytics on Streams","awardID":"1117139","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["543519","543520",486121],"PO":["563751"]},"182764":{"abstract":"This project is investigating the use of head-mounted augmented reality (AR) to improve learning outcomes among deaf and hard of hearing learners in situations that make learning logistically-challenging for them, specifically presentation situations where there is also some scenario that needs to be focused on visually. The work is being carried out in planetaria, where learners wear a monocle that displays a signer in a way that allows the learner to look at both the signed interpretation of the presentation and the scenario of interest at the same time. The design of the technology and way it is being used is informed by the literature on cognitive load and by literature on multimedia learning theory (Mayer, 2005). Results are applicable to a wide variety of logistically-challenging situations for deaf\/hoh learners, including the kinds of informal learning venues that often excite the passions of hearing learners and perhaps in classrooms as well.<br\/><br\/>Presentations, even when a signer is available, are often logistically-difficult for the deaf and hard-of-hearing population to take advantage of well. Moving attention back and forth between the interpreter to the objects or scenarios being described makes it difficult to follow a presentation and get everything out of it that a hearing person can get. This project is aiming to ameliorate this problem by designing technology that will project the interpreter's signs in the same field of vision as the object or scenario being discussed and learning how to use that technology well.","title":"EXP: Exploring augmented reality to improve learning by deaf children in planetariums","awardID":"1124548","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1545","name":"RES IN DISABILITIES ED"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7259","name":"INFORMAL SCIENCE EDUCATION"}}],"PIcoPI":[489672,489673,489674,489675],"PO":["562669"]},"181554":{"abstract":"To apply machine learning to problems in the physical world, one needs models\/algorithms that are faithful to physics. We consider understanding how the anatomical structure of the body and ears leads to the remarkable ability to localize a sound source in a complex and noisy environment that is innate in most animals and humans. The cues used in localization arise from the process of the acoustic wave scattering off the complex-shaped listener's body and ears. Numerically, these changes in the sound spectrum are characterized by the head-related transfer function (HRTF). Every person's body is unique, and the HRTF is highly individual. It is possible to measure the HRTF; however, the measurement requires specialized hardware and is tedious. There has been considerable interest in convenient methods to obtaining the HRTF. We propose to develop a framework to perform machine learning to establish a relationship between the anatomy and HRTF. An HRTF database with 100 subjects, along with their anthropometric measurements, is available. A novel LMA (Learning of Multiple Attributes) algorithm will be developed. The key properties of this algorithm are that it can incorporate physical constraints into the learning and predict complex structured outputs in continuous spaces. The algorithm will find the low-dimensional manifold in high-dimensional HRTF space and to map the manifold structure to anatomical parameters. <br\/><br\/>The research will create novel machine learning algorithms that are able to incorporate physics based constraints, and these will find application in other problems. HRTF generation from simple body measurements will allow introduction of personalized spatial audio into fields such as human-computer interaction, consumer electronics, auditory assistive devices for the vision-impaired, robotics, entertainment, education, and surveillance. Training of K-16 and graduate students in the proposed research will add to the nations talent pool.","title":"RI: Small: Learning the Relationship between the Anatomy and Spatial Hearing","awardID":"1117716","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550878","532931",486430],"PO":["562760"]},"182412":{"abstract":"The PIs are designing, developing, and testing a software tool, called Idea Threads Mapper (ITM) that helps young learners (grades 4 and 5) sustain inquiry and discussion more regularly in their classrooms. The tool allows them to visualize the ways the class's ideas are taking shape and being improved over time and help them analyze the on-line discourse (e.g., threaded discussions, notes) of other classes or communities and use the ideas of others to move forward their own ideas. The tool helps learners examine on-line discourse and index the pieces in new ways. The tool and learners work together to examine discourse and index it, with the tool providing scaffolding for the examination of discourse that learners do. ITM is being added to Knowledge Forum, a platform for community knowledge building that is used extensively in elementary-school classrooms. It is being designed as an open-source tool that will be usable within other collaborative learning platforms as well in which students contribute, examine, refine, and build upon their own ideas and those of others through sustained discourse (e.g., WISE, Blackboard). <br\/><br\/>Along with design and development of innovative technology in support of sustained inquiry, PIs are conducting research that investigates how to foster reflective awareness of and monitoring of community knowledge. This research is expected to produce conceptual, pedagogical, and technological advances that will make sustained, progressive inquiry more achievable among young students, whether they are working together in small groups, as a class, or across a network of classrooms. It is expected that pedagogical designs enabled by this tool will foster students' collective responsibility to monitor, build on, and advance community knowledge for deep understanding at the same time they are contributing to and gaining support from the shared knowledge of the knowledge building communities they are participating in. Because teachers will use the same system to collaboratively plan across classrooms, it is expected that the project will also contribute ideas about effective planning tools for teachers and teacher professional development.<br\/><br\/>A key to creative productivity is a sustained, progressive trajectory of inquiry by a collaborative group in which ideas are continually generated, refined, and further built upon to formulate more advanced ideas and problems, expanding the community's shared knowledge and using that knowledge to continually inform further initiatives. Inquiry-based learning requires similar sustained efforts of students to be productive in developing deep understanding and creative\/adaptive capabilities. Such a sustained, progressive trajectory of inquiry is rare in classrooms; but it is achievable. This project is focusing on how to make sustained, progressive inquiry more achievable among young students and in the classrooms of more teachers. Cultivating collaborative, inquiry-based practices that expand the knowledge of a community is expected to prepare students for careers in our knowledge-based society in which they play key roles in expanding our society's knowledge.","title":"EXP: Fostering Collective Progress in Online Discourse for Sustained Knowledge Building","awardID":"1122573","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[488689,488690,488691,488692],"PO":["562669"]},"181323":{"abstract":"Determining the perceptual quality of video transmitted through complex networks and viewed on heterogeneous platforms, from cell phones to Internet-based television, is a key problem for the YouTube generation. It is also central to a variety of vision applications including face detection, face recognition and surveillance. Video is subject to numerous distortions: blur, noise, compression, packet\/frame drops, etc. Quality assessment is non-trivial when an undistorted video is not available, and unsolved for multiple distortion types and in distributed, non-stationary viewing environments.<br\/><br\/>This project designs and creates intelligent video \"quality agents\" that learn how to determine perceptual video quality in heterogeneous networks, and assesses its impact on decision tasks such as face detection and recognition, all without the benefit of reference videos. It uses statistical properties of natural scenes, perceptual principles, machine learning, and intelligent adaptive agent collectives to handle videos simultaneously impaired by multiple distortion types. A primary application is novel face-salient quality assessment agents and quality-aware face detection algorithms. Multiple, co-operative video and face quality agents are trained using active learning based feedback mechanisms on mobile devices. This project yields adaptive, robust video Quality of Service assessment in real-life networks and provides new insights into human visual quality perception and visual distortion detection. The research team also creates two large, unique video quality databases: (a) A Mobile Video Quality Database of raw and distorted mobile videos and (b) A Distorted Face Database of undistorted and distorted face images, as gold standards for research and development in this area.","title":"RI: Small: Intelligent Autonomous Video Quality Agents","awardID":"1116656","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[485855,485856],"PO":["564316"]},"182654":{"abstract":"This project is investigating the potential that the combination of mobile devices and cloud computing offers to engage middle school children in scientific exploration using the same simulations and other tools that scientists employ to decompose, visualize, and understand complex systems, e.g. the spread of infectious disease or the sourcing, production, and use of energy across the globe. Drawing on Learner-centered Design (LCD) guidelines and research on motivation and learning, the project team is developing the Participatory Simulations Software Factory (PSimSF) which would produce Participatory Simulations (PSims) for various science processes that run on a broad range of mobile devices. The investigators posit that personal participation in the simulation, where a broad range of visualizations are employed, increases student engagement - with greater time on task and real-time conversation amongst the students, which in turn increases student achievement. The intellectual merit of the project rests in its team's combination of expertise and experience in working with emergent technologies, cutting-edge science methodology, and inquiry-based learning. Moreover, in creating and testing a number of prototype PSims, the project is helping the larger educational community to understand better what is the potential for these new technologies to support active, project-based learning. Finally, the mobile learning environment with its multi-player, game-like interactions builds on the characteristics of today's digital natives. The broader impacts of the project lie in the freely distributed PSims that the project is creating along with grade-level appropriate curriculum materials. The project is also aiming to make the work scalable and sustainable, with a specific focus on potential commercialization.","title":"EXP: Collaborative Research: Using Smartphone-Based Participatory Simulations to Engage Children in Scientific Thinking","awardID":"1123965","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["557624","553725","549235","561136"],"PO":["560894"]},"181565":{"abstract":"The goal of this project is to research and develop techniques for the correct conceptual evaluation, processing, and optimization of multi-predicate spatial (MPS) queries in support of location-based services. The project achieves its goal using the following approaches: (1) Study the characteristics of MPS queries and develop a new consistent and provably correct conceptual evaluation strategy for MPS queries similar to the one for relational SQL queries; (2) Develop various query transformation rules that not only retain correctness but also transform MPS query execution plans into more efficient ones; (3) Investigate the validity of well-known relational optimization heuristics in the context of MPS queries and develop innovative optimization algorithms unique to MPS queries; (4) Develop a cost model to aid the query optimizer in selecting the best query execution plans for MPS queries and study the impact of the variation on temporal and spatial moving object distributions on MPS query execution plans; (5) Develop new adaptive spatiotemporal query processing techniques that can cope with the dynamic nature and scale of moving object environments; (6) Prototype an MPS location server that reflects the correct evaluation and efficient optimized execution of continuous and adaptive MPS operators; and (7) Develop simulators and analytical models to evaluate the performance of the developed techniques. The research results are beneficial to many applications including location servers, intelligent transportation systems, smart cities, supply chain management, and emergency response and recovery.<br\/><br\/>This project supports Ph.D. students to pursue research in the areas of spatiotemporal data management systems and advanced location servers, and involves undergraduate students in related research projects. The project develops and introduces a new entry-level undergraduate programming course around 2D and 3D map operations and queries that utilizes MPS queries and integrates the research results from the project to increase the interest in programming of students from Computer Science as well as from other Science disciplines. The project involves minority students through the Discovery Learning Center at Purdue Discovery Park and the Louis Stokes Alliance for Minority Participation (LSAMP) project and Alliances for Graduate Education Program (AGEP). Publications, technical reports, software and experimental data from this research are available at the project web site (http:\/\/www.cs.purdue.edu\/~aref\/MPS).","title":"III: Small: On the Conceptual Evaluation and Optimization of Queries in Spatiotemporal Data Systems","awardID":"1117766","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[486458,486459],"PO":["563727"]},"181455":{"abstract":"Existing 802.11n is inefficient whenever nodes with a different number of antennas share the medium. This research aims to develop an advanced 802.11n design that delivers as many concurrent transmissions as permitted by the MIMO transmitter with the maximum number of antennas. Such a design delivers performance gain while maintaining the fully distributed random access nature of today's 802.11n, i.e., its ability to support bursty traffic, distributed decisions, and ad hoc deployment. The research develops a novel carrier sense mechanism that enables MIMO nodes to detect whether they can transmit in the presence of an ongoing transmission without interfering with it. It then builds on this mechanism to deliver a random access protocol where MIMO nodes contend for both time and degrees of freedom, without any form of centralized coordination. Finally, it implements its design and evaluates it in a wireless testbed. By delivering a higher throughput for the same resource, this research advances the design of MIMO 802.11 networks and the corresponding industry.","title":"NeTS: Small: Random Access Heterogeneous MIMO Networks","awardID":"1117194","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560189"],"PO":["557315"]},"181345":{"abstract":"Unfortunately, cyber crime has become a business today. In contrast to the Internet security situation ten years ago, most of the significant Internet attacks today aim to make a financial profit. A popular and effective choice of criminals today for sending spam, stealing data, and launching attacks are so called bots -- a type of malware that is written with the intent of compromising and taking control of hosts on the Internet. The main distinguishing characteristic of a bot compared to other types of malware is that a bot is able to establish a command and control (C&C) channel.<br\/><br\/>The goal of this project is to develop novel techniques and tools to detect malicious connections from compromised machines to the C&C servers of botnets. The key insight is that when looking at very large volumes of netflow and DNS data over an extended period of time, connection attempts to benign and malicious addresses should exhibit enough differences in behavior so that they can be automatically distinguished. A key challenge in this project is to identify behavioral features that will allow the detection of connections that exhibit botnet-like behavior.<br\/><br\/>The ability to identify malicious C&C connections and to potentially block and disrupt the communication of the attackers with their bots presents rich opportunities for industrial and societal impact. Furthermore, the research will have a broad effect though education and outreach. The PI will seek broad dissemination of research results through both top publications and industry connections.","title":"TC: Small: Automatically Identifying Botnet Command and Control Infrastructures","awardID":"1116777","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[485910],"PO":["564223"]},"181466":{"abstract":"Rapid advances in DNA sequencing technologies are providing scientists with the ability to rapidly and cost-effectively decode the genomes of organisms. Current technologies, however, can only reconstruct a fragmented picture of a genome's chromosomes. Stitching the resulting fragments together into a complete genome currently requires costly and time-intensive laboratory experiments. The goal of this proposal is to develop new computational approaches that combine sequencing data with the data generated by modern high-throughput mapping technologies in order to enable the automated reconstruction of much larger genomic segments, up to whole chromosomes, than currently possible. The proposed research will be closely integrated with educational activities at the University of Maryland, College Park through the mentoring of undergraduate and graduate students and of a postdoctoral fellow. <br\/><br\/>Despite tremendous advances over the past 20+ years, both in sequencing technologies, and in computational algorithms for genome assembly, the genomes of the majority of organisms cannot be completely reconstructed through fully-automated processes. The best sequencing technologies can only \"read\" up to a few 1000s of letters yet most organisms contain millions to billions of letters in their genomes. At the same time, genome assembly is a difficult computational problem and even the best assembly software can only generate fragmented reconstructions of the genomes being sequenced, primarily due to repetitive sequences found in the genomes of most organisms. The full completion of highly-repetitive genomes requires time- and labor-intensive processes that often last multiple years. High-throughput optical mapping technologies provide a promising source of information that could be used to disambiguate genomic repeats and automatically reconstruct much larger segments of an organism's genome than possible through the sole use of current sequencing data. Optical mapping data describe the relative placement of multiple genomic landmarks (e.g. restriction enzyme recognition sites) along large stretches of a genome, spanning hundreds of thousands of letters and even whole chromosomes. To date, however, there is no algorithmic framework that allows the incorporation of this rich source of information in the assembly process. Specifically, genome assembly can be formulated as a graph traversal problem, finding a path through a complex graph that satisfies the constraints imposed by the data provided to the assembler. Optical mapping data encode a new type of constraint on the possible traversals of a graph, potentially leading to a more complete reconstruction of genomes. <br\/><br\/>The main goal of this proposal is to develop an algorithmic framework and associated software tools, that enable the use of optical mapping and optical sequencing data during the assembly process. It is important to note that constrained graph traversal problems are generally computationally intractable. We propose several heuristic traversals algorithms that can use optical mapping information and are likely to perform well in practice. In addition, computational analyses will be used to determine the combination of parameters for the mapping experiment that generate data that is most informative for the assembly process. These computational predictions will be validated in an experimental setting.<br\/><br\/>In addition to the main research objective, this proposal will directly contribute to the education of future generations of scientists, both through the mentoring of graduate students and post-doctoral fellows, and through the continuation of a summer research internship for undergraduate and highschool students. The software developed in this proposal, as well as the scientific publications arising from this work, will be freely and broadly disseminated through open licensing.","title":"III: Small: Genome Assembly Using Sparse Sequence Information","awardID":"1117247","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[486198,486199],"PO":["565136"]},"181587":{"abstract":"Collaboration is essential to software development. As software engineers develop and evolve software, they need to analyze past and present software modifications implemented by other developers in various tasks such as peer code reviews, bug investigations, and change impact analysis. Developers are often overwhelmed with a large amount of awareness information about software modifications. Auto-generated emails about check-ins, builds, and regression tests often flood developers' mail boxes, yet it is very difficult for developers to identify significant and relevant change-events. Existing software engineering tools do not easily allow developers to search software modifications relevant to their tasks, focus, and interests.<br\/><br\/>This research project will produce analytical support for investigating software modifications in collaborative development environment called CHIME. First, CHIME will provide an extensible, logical change analysis framework that identifies software modifications relevant to one's own code modification according to various kinds of delta relationships. The users of the framework can import, select, and extend various notions of interference, dependence, similarity, and co-occurrence relationships among individual software modifications. Second, CHIME will provide a search interface to empower users to ask and answer questions about the content, structure, and context of code changes across multiple revisions. In order to reduce programmers' burden on formulating search queries, we will conduct empirical studies with professional developers to identify frequently asked questions about past and present software modifications. The resulting list of the questions will be provided as template queries that the developers can use or refine. Third, CHIME will provide targeted notifications about others' software modifications by monitoring other developers' change-events that are relevant to the developer's own modification. The impact of this research will be substantially improved developer productivity in a rapidly-evolving, collaborative and parallel software development. CHIME will reduce awareness information overload and will help users manage the impact of others' code changes on their code, detect and resolve merge conflicts early, and coordinate shared tasks, contributing toward early detection and removal of integration and interference failures.","title":"SHF: Small: Analytical Support for Investigating Software Modifications in Collaborative Development Environment","awardID":"1117902","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[486519,"527053"],"PO":["564388"]},"180377":{"abstract":"Crowdsourcing is a powerful way to marshal small contributions from large numbers of people to solve real-world problems. Success stories range from classifying craters on Mars' surface (ClickWorker) to labeling images (the ESP Game, now Google Image Labeler) to task marketplaces (Amazon's Mechanical Turk). This project moves towards a vision of crowdsourcing that extends it to support complex, creative, and interdependent tasks, and embeds it into computing systems as part of our everyday lives. The project will focus on two application areas for complex crowdsourcing: science journalism and software development.<br\/><br\/>The intellectual merits of the project include the uncovering of new scientific knowledge about how to model online crowd behavior, and the development of new methods and tools for using crowds as part of computer system designs, particularly for complex, interdependent, real time work. The project will also show that these methods can be used for real-world problems. <br\/><br\/>The potential broader impacts include those specifically having to do with the two application areas, which could have significant impacts on society. Crowdsourcing science journalism will directly involve citizens in the process of science dissemination, making scientific information more accessible to the general public, and promoting greater awareness of science and the scientific process. Crowdsourcing software development can transform the way that software is created, lowering barriers and broadening participation in open source software development, and helping larger masses of people use and improve their programming skills. Other impacts will flow from the researchers' plans to publically share the infrastructure that they develop to facilitate complex crowdsourcing in many other areas. They also plan to integrate their research results into undergraduate courses.","title":"Collaborative Research: Programming with Crowds: Models and Tools for General Purpose Crowdsourcing","awardID":"1111044","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["549925"],"PO":["563324"]},"181356":{"abstract":"The algorithms and techniques used to find useful patterns in large sets of data, collectively known as data mining and information visualization, have become vital to researchers making discoveries in diverse fields. The goals of data mining (and computing in general) at the Exascale have introduced fundamental challenges at the architectural level, and even though the evolution of GPU architecture has partly been driven by these challenges, overall computing system performance is not increasing at an equal rate as that of data generation and collection, thus widening the gap between the capabilities of mining algorithms and the performance of real-world data mining systems. This project investigates the design of new hardware\/software platforms that will enable existing data mining algorithms to scale with increasingly large and complex datasets. In doing so, this project builds upon current understanding of the characteristics of data mining applications that differ from those for which modern processors are currently designed, similar to what already has been done in the signal processing and network processing domains. This project also studies a variety of design methodologies and models of computation that could lead to performance improvements. Finally, this project analyzes the inherent tradeoffs between algorithmic accuracy and architecture overhead in an attempt to generalize the accuracy and performance tradeoff. The expected impact is that these research tasks will contribute to the growing body of work in embedded system design at the hardware\/software interface, and will help to develop a part of future hybrid multi-core computing platforms.","title":"CSR: Small: Hardware Architectures for Data Mining at the Exascale","awardID":"1116810","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["502125"],"PO":["565255"]},"181477":{"abstract":"This project will investigate a new generation of provenance-rich social knowledge collection systems that will greatly improve the ability of people to create online communities of interest and share information. The research will transform the state of the art in social content collection in several important ways. First, social knowledge collection systems will be augmented to support contributors to structure factual content, so that information can be aggregated to answer reasonably interesting albeit simple factual queries. We will build on a semantic wiki framework to allow users to create structured factual content as object-property-value triples. It will not assume pre-defined ontologies, but rather develop algorithms that analyze current content and suggest opportunities for structuring contributions so they can be aggregated to answer simple queries. Second, they will include detailed provenance records that reflect how the content was created, allowing contributors to enter alternative viewpoints and enabling consumers to make quality and trust judgments. The research will include developing algorithms that derive trust metrics from the provenance records, and to allow users to define views on the content based on provenance criteria. It will create novel approaches to propagate trust across content topics and categories and complement existing algorithms that propagate trust in social networks. Third, the systems will proactively guide contributors to invest effort where it is most needed, developing novel algorithms to detect knowledge gaps, and by allowing users to define queries that will be used to drive further contributions.<br\/><br\/>This work has the potential for a broader impact in many areas where social content collection is already widely used, not only in scientific communities but also for societal issues, such as citizen participation in local communities, health, and governance. All these communities would benefit from further structure, provenance models, and guided knowledge collection. Despite their popularity, social content collection sites currently have important limitations. First, because the content has very little structure they cannot aggregate information and answer many simple questions. Second, contributors have uneven expertise and skills and therefore the content is of very varying quality, yet there is no assistance for consumers to tell apart the valuable from the dubious. Third, these sites depend on the initiative of contributors to figure out how the content needs to grow, and there is no systematic analysis to expose knowledge gaps and guide contributors proactively. This research project addresses all three of those issues.","title":"HCC: Small: An Analytical Framework for Provenance-Rich Social Knowledge Collection","awardID":"1117281","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["563687"],"PO":["564456"]},"181488":{"abstract":"Data-intensive real-time applications, such as transportation management, military surveillance, and network monitoring, need to handle massive amounts of stream data in a timely fashion. It is challenging to support real-time stream data services (RTSDS) due to stringent timing constraints, potentially unbounded continuous stream data, bursty stream data arrivals, and workload variations due to data value changes. This project will develop cost-effective methods and a runtime system for RTSDS. The project will systematically investigate methods and tools to support real-time continuous queries for RTSDS even in the presence of dynamic workloads. Specifically, the project will study a) real-time continuous query modeling, b) new performance metric design c) adaptive query scheduling design, d) tardiness control and load shedding, for both single node and clustered RTSDS. The project will also have prototype implementation and testbed evaluations. The results and findings of this project will advance and seamlessly integrate real-time computing and stream data management.<br\/><br\/>Real-time stream data services (RTSDS) play an important role in many emerging application including intelligent transportation, green buildings, smart grid management, military surveillance, and network monitoring. Our everyday lives are highly dependent on these applications. RTSDS is a fundamental technology for developing critical data-intensive real-time applications with great socio-economic impacts. The project will develop the scientific foundations and associated engineering principles for building RTSDS. <br\/><br\/>The project will provide excellent opportunities for undergraduate and graduate students to acquire hands-on experience as well as theoretical backgrounds in RTSDS. The PIs will work closely with students to carry out the research in this project. Through this project, the PIs will train students to become strong in both analytical and implementation skills, and help them solve challenging problems in RTSDS.","title":"CSR: Small: Collaborative Research: Systematic Approaches for Real-Time Stream Data Services","awardID":"1117352","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[486254],"PO":["564778"]},"181257":{"abstract":"Emerging ubiquitous computing systems require numerous small wireless nodes to be integrated into our surroundings. In order to provide both a small size and a long lifetime on limited energy, these nodes must use circuits that are ultra low power (ULP), offer substantial processing capabilities, provide flexibility to meet different application needs, and allow for low development and deployment costs. Existing approaches to circuit design such as ASICs, off the shelf parts, or sub-threshold processors fail to provide all of these traits at once. This project is developing an energy efficient field programmable gate array (FPGA) capable of operating into the sub-threshold voltage region to provide a computational platform that meets the needs of ubiquitous computing systems. Commercial FPGAs are usually designed to compete with high performance processors, so they operate at high voltages and use circuit structures that do not permit low voltage sub-threshold operation. To re-target FPGAs for energy efficient operation at low voltage, this project replaces conventional programmable interconnect circuits with non-buffered single pass-transistor switches. These switches create a voltage drop in the interconnect lines that is recovered using asynchronous sense amplifiers at the inputs to configurable logic blocks. Furthermore, the voltage of the configuration bit cells that turn on the interconnect switches is boosted. This new knob increases the speed exponentially and reduces variations in the sub-threshold region and does not incur substantial energy overhead since the configuration bit cells only switch rarely when the FPGA is reprogrammed. The configurable logic blocks are re-designed to take advantage of this new interconnect fabric. <br\/><br\/>This project will result in an FPGA capable of energy efficient low voltage operation. The FPGA device will be demonstrated in ubiquitous computing applications. Since it is both low energy and reconfigurable, it will allowubiquitous computing nodes to employ substantial processing to extract information from locally sensed data and then make decisions based on that information, reducing use of power intensive radio communication to extend the node lifetimes. The flexibility of the FPGA allows rapid re-targeting of the energy efficient hardware for different application or contextual requirements, providing a new computing platform to enhance the ability of software and hardware developers to create ubiquitous computing systems.","title":"SHF: Small: Energy Efficient Reconfigurable Logic for Ultra Low Power Ubiquitous Computing Systems","awardID":"1116297","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[485695],"PO":["366560"]},"182588":{"abstract":"Investigators from Rice University and Duke University will build a Personalized Cyberlearning System, designed around three principles from cognitive science (retrieval practice, spacing, and enhanced feedback), that leverages advances in machine learning and makes use of an existing instructional content material and problem set database aimed at undergraduate engineering students. The system will use artificial intelligence methods to optimize practice and feedback for students. Research will seek to advance knowledge, in a real-world setting, about a range of issues concerning how feedback facilitates learning, how individual differences come in to play, as well as those more specifically aimed at the development of the learning technology system itself.<br\/><br\/>The project is important as part of the effort to harness the vast quantities of information on the web to personalize instruction for a wide range of learners. Moreover, the development of such cyberlearning technologies holds promise for opening up STEM education for motivated self-learners while also allowing access to a large volume of material for a range of students who might not otherwise have it.","title":"DIP: Collaborative Research: A Personalized Cyberlearning System Based on Cognitive Science","awardID":"1123617","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[489182],"PO":["562669"]},"181158":{"abstract":"Nearly all modern processors now contain multiple cores and almost all modern computer systems contain multiple processors. Thus future software is likely to be both multithreaded (in which threads of a process communicate using shared memory) and distributed (in which processes in a system communicate using messages). Ensuring that a program works correctly under all possible scenarios is a very dif&#64257;cult task. Most real-world programs contain a large number of components which makes their formal veri&#64257;cation infeasible. Effective tools for testing and debugging programs prior to their deployment are indispensable. Bugs persist even after extensive testing and debugging especially those that manifest under rare circumstances. Monitoring programs at runtime and possibly controlling their execution to avoid bad states is an important way to tolerate residual software bugs. <br\/>In this project, we are working on developing a theory and algorithms for monitoring, analyzing and controlling a multithreaded distributed computation. Specifically, we are developing (i) a unifying framework for modeling synchronization in multicore distributed systems resulting from messages, locks and other synchronization primitives (e.g., wait\/notify), (ii) offline and online algorithms for detecting and controlling predicates, expressed as temporal logic formulas, using slicing and other approaches, and (iii) scalable approaches for tracking dependency among events.<br\/>Besides multicore computing, the work has applications in a variety of other areas including cloud computing, distributed databases, recovery, replica consistency and resource management. We are also developing educational tools that can be used in courses to enhance the learning experience of students working with multicore distributed systems.","title":"CSR: Small: Collaborative Research: Improving Dependability of Multithreaded Distributed Programs","awardID":"1115808","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["561475"],"PO":["565255"]},"186845":{"abstract":"This project aims to provision energy-efficient communications by powering wireless access networks with renewable energy. Wireless access networks and the power grid are envisioned to be deployed in a distributed manner in which a distributed base station consumes less amount of power that can be generated by renewable energy. Optimization theory and game theory are applied to study the interaction between the wireless access networks and the power grids, to optimize the operation of wireless access networks by integrating the power distribution of the micro grid into the design and optimization of the wireless access networks, and to design the operation of the micro grid by considering characteristics of both the power demand of the consumers (wireless access networks) and the distributed energy resources (renewable power generators). The research explores the potential of applying renewable energy into powering wireless networks, and stimulates the large scale application of renewable energy in helping green the society and reduce the carbon footprint of the environment. Two major results are anticipated: 1) the algorithms that optimize the operation of renewable energy powered wireless networks (REPWiNet), and 2) the communication protocols that coordinate the wireless access network with the underlying power grids. The insights and results derived from designing REPWiNet will provide guidelines not only for designing wireless access networks but also for designing the power distribution and coordination in micro grids. Research results will be posted on a website as well as submitted for publications in journals and presentations at premium conferences.","title":"EAGER: REPWiNet: Renewable Energy Powered Wireless Networks - Architecture, Protocols and Implementations","awardID":"1147602","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550852"],"PO":["557315"]},"184678":{"abstract":"The computing landscape is a richly-heterogeneous space including both fixed and mobile nodes with a large variety of sensing, actuation and computational capabilities (including mobile devices, home electronics, taxis, robotic drones, etc.). Cyber-physical applications built on these devices have the potential to gather data on, analyze, and adapt to or control a range of environments. The challenge, however, is that Cyber-Physical Systems (CPSs) are difficult to program, and even more difficult to incorporate from one deployment to another, or to dynamically manage as nodes availability changes. Thus, CPS applications are too often programmed in a brittle fashion that impedes their ability to efficiently use available compute\/sense\/actuate resources beyond a one-shot deployment. In response, this project is improving CPS design and control in four primary thrusts. First, the project is developing CPSISA, an abstraction layer or intermediate representation to facilitate CPS applications expressing their compute\/sense\/actuate requirements to lower-level mapping and management layers. Second, the project is exploring methods of providing a Device Attribute Catalog (DAC) that summarizes a region?s available CPS nodes and their capabilities. Third, this research is improving and exploiting the ability to model, predict, and control the mobility of CPS nodes. When some CPS nodes are mobile, the accuracy and performance of a CPS application fundamentally is a function of where nodes will be positioned at any moment in time. This work exploits both static statistical coverage analysis and dynamic prediction and interpolation. Fourth, using CPSISA, DAC, and other resources as input, the team is developing tools to statically or dynamically optimize mappings of CPS applications onto available resources. To test ideas in a detailed and concrete manner, two applications are being studied and deployed. First, the FireGuide application for emergency response assistance uses groups of mobile\/robotic nodes for guiding first responders in building fires. Second, a Regional Traffic Management (RTM) application demonstrates ideas at the regional level and will explore CPS scenarios for automobile traffic sensing and dynamic toll pricing. <br\/><br\/>The proposed research program has the potential for broad societal impact. Studies that improve how building emergencies are handled will improve emergency response safety both for occupants and for first responders around the country. Likewise, the deployment plans regarding regional traffic management will improve traffic patterns, fuel efficiency and quality-of-life for commuters across the United States. The research team is distributing the CPSISA, CPSMap, and CPSDyn software frameworks to allow other researchers and developers to make use of them. Extensive industry collaborations foster effective technology transfer. Finally, the project continues and broadens the PIs? prior track records for undergraduate research advising and for mentoring women students and members of under-represented minority groups.","title":"CPS: Medium: Collaborative Research: Efficient Mapping and Management of Applications onto Cyber-Physical Systems","awardID":"1135874","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["429041"],"PO":["565136"]},"184568":{"abstract":"Are computing professionals adequately prepared for the ethical challenges that they will face in an increasingly global and interdisciplinary workplace? In this multi-institutional research\/education project, the PIs will investigate the gap between the need for ethical computing professionals and the ethical learning that occurs in graduate computing programs. They will then apply these insights to develop and disseminate best practices in graduate ethics education. The mixed-method research combines surveys, interviews, focus groups, content analysis, and experimental design, and will be conducted in partnership with ACM's SIGCAS and the IEEE's SSIT. The project will begin with an investigation of computing programs and courses at four diverse institutions: a traditional research 1 university, a rural polytechnic, an urban liberal arts college, and a leading institution for online education. What are the existing goals and strategies used in graduate computing ethics education at these sites? What ethical issues are covered? What pedagogical approaches and materials are used? Faculty and students will be surveyed and interviewed about their perspectives on computing ethics education. Observations of teaching ethics across the courses will be conducted at each institution by the project team and the evaluation team. With baseline data from these four institutions, the PIs will survey members of leading professional associations to gauge alignment between industry practice and interests and the education in ethics provided by postsecondary institutions. Finally, the PIs will refine a set of best practices and pedagogical recommendations for CS ethics education, and disseminate their findings along with examples of teaching materials designed to be applicable across a range of institutional settings. Specific research questions to be addressed include:<br\/><br\/>1. What specific ethical issues are CS instructors currently teaching and what pedagogies are currently being used in graduate-level computing courses?<br\/>a. What are the similarities and differences in computing ethics issues covered within curricula across different institutions?<br\/>b. What materials (texts, readings, videos, simulations, social media, etc.) are used in classes?<br\/>2. How can professionals? experience in the computing industry enrich teaching about ethical challenges in the workplace?<br\/>a. What do computer professionals think students should know about ethics before entering the workplace?<br\/>b. How do computer professionals think this information can best be conveyed?<br\/>3. How can computing ethics education be improved?<br\/>a. What do CS students need to learn about ethics that they are not currently learning?<br\/>b. What are the best pedagogical approaches for teaching students these ideas?<br\/><br\/>Project outcomes will include a report on the state of ethics education in graduate computer science\/technology, a report on industry needs for an ethically knowledgeable workforce, and recommendations for best practices in ethics education effective in graduate education and the workplace. The project will ultimately result in computing professionals who are more attuned to their ethical responsibilities to the public, leading to more reliable computing systems.<br\/><br\/>Broader Impacts: This work will fill an important gap in the research literature about the appropriateness and effectiveness of pedagogical approaches currently used to increase graduate computing students' awareness of ethical issues relative to the challenges that they will face in the workplace. Results of the study will be based on, and thus applicable to, a broad range of stakeholders in graduate computing ethics education, and thus could transform curricular standards promulgated by professional societies such as the ACM and IEEE. The innovative mixed-method approach that will be used has merit not only for this study but could also be applied to future studies in other domains.","title":"EESE: Collaborative Research: Understanding and Preparing Future Computer Professionals for the Ethical Complexities of a Diverse World","awardID":"1135163","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":["505732"],"PO":["565227"]},"184689":{"abstract":"Holonic Multi-Agent Control of Intelligent Power Distribution Systems <br\/>This project will demonstrate a Holonic Multiagent System Architecture capable of adaptively controlling future electrical power distribution systems (PDS), which are expected to include a large number of renewable power generators, energy storage devices, and advanced metering and control devices. The project will produce a general, extensible, and secure cyber architecture based on holonic multiagent principles to support adaptive PDS. It will produce new analytical insights to quantify the impact of information delay, quality and flow on the design and analysis of the PDS architecture. Finally, it will develop a novel approach to automating PDS with high penetration of distributed renewable resources for higher efficiency, reliability, security, and resiliency.<br\/>The complex nature of future PDS will require them to adapt reactively and proactively to normal and anomalous modes of operation. The architecture produced by this project will be capable of optimizing performance and maintaining the system within operating limits during normal and minor events, such as cloud cover that reduces solar panels output. The architecture will also allow the operation of a distribution system as an island in emergencies, such as hurricanes\/earthquakes, grid failures, or terrorist acts. <br\/>The project will inspire future engineers via a simulation that will allow students to inject faults, failures, and weather events to see how an intelligent PDS will respond. These activities will combine cyber- and physical expertise, thus creating a workforce prepared for tomorrow?s cyber-physical system challenges. Existing university programs will be used to involve under-represented minorities and U.S. veterans in the project.","title":"Components, Run-time Substrates, and Systems: Medium: Holonic Multi-Agent Control of Intelligent Power Distribution Systems","awardID":"1136040","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["544840",495338,"528449",495340,"548367"],"PO":["564728"]},"183127":{"abstract":"Proposal #: 11-26570<br\/>PI(s): Kong, Jun<br\/> Cook, John R.; Shi, Jing; Yu, Nan<br\/>Institution: North Dakota State University<br\/>Title: MRI\/Dev. : A Cross-Platform Infrastructure for Natural Interaction Research<br\/>Project Proposed:<br\/>This project from an EPSCoR state, aiming to develop a cross-platform infrastructure that supports natural interaction research by providing automatic modality adaptation, radically alters the paradigm for human\/computer interaction (HCI). Distinct from previous approaches, the proposed approach quantifies the usability of each modality and then formalizes the adaptation issue as searching for a set of input\/output modalities that produce the highest usability, i.e., an optimization issue. In addition to the interaction context, our approach also considers the effects of computing infrastructures (e.g., system resources and networking) on the modality adaptation. The proposed work establishes the first Natural Interaction Laboratory in North Dakota, enabling the following research projects in Adaptive Natural Interaction:<br\/>- Establishing common interaction context across multiple scenarios,<br\/>- Device-aware establishment of modality space,<br\/>- Device-aware establishment of usability space, and<br\/>- Quality of service in the human\/computer interaction context.<br\/>The work aims to develop a unifying infrastructure for research by providing a common programming interface across multiple devices. <br\/>Broader Impacts: <br\/>This instrumentation should provide a unique research facility for faculty and graduate students to conduct research on user interaction-enhancing technology and education. The proposal enhances PhD production in an EPSCoR state, encourages underrepresented students into research via the NATURE (Nurturing American Tribal Undergraduate Research and Educations) and WISMET (Women in Science, Math, Engineering, and Technology) programs, provides research opportunities to undergraduate students, and impacts industry and economic development in North Dakota.","title":"MRI: Development of a Cross-Platform Infrastructure for Natural Interaction Research","awardID":"1126570","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[490932,"509677",490934,"544833"],"PO":["543539"]},"183138":{"abstract":"Proposal #: CNS 11-26619 <br\/>PI(s): Rishe, Naphtali D.; Chen, Shu-Ching; Christidis, Evangelos; Li, Tao; Zhao, Ming<br\/>Institution: Florida International University<br\/>Title: MRI\/Dev.: An Integrated, Geospatial Analytics Research Instrument<br\/>Project Proposed: <br\/>This project, developing an integrated, high performance instrument designed for the domain experts, focuses its domain on environment from which researchers can easily process and store spatial and related data, visualize and explore data relevant to their domains, and analyze data of interest via analytics of their choosing. This instrument will provide a suite of cloud services and user-centric analytic technologies via a Disaster Dataspace Services Cloud (DDSC), open-standard APIs, and cutting-edge data visualization capabilities. The Instrument will utilize a large-scale, optimized infrastructure to deliver high levels of throughput and responsiveness, including an improved Hadoop\/MapReduce architecture to enable decision-support and information discovery queries on massive amounts of structured and unstructured data. The proposed multidisciplinary research includes: <br\/>- Several areas of Computer Science research, including query and data quality control algorithms on heterogeneous, multisource streaming data, automated discovery approaches, intelligent query\/search modeling, GIS, data mining, moving objects, and scientific data visualization; <br\/>- Algorithms in data quality control and indexing on heterogeneous, multisource streaming data, and knowledge discovery algorithms with spatially aware information, such as rare event and spatio-temporal change and trend detection; and<br\/>- Instrument?s applicability in the decision-making process in various fields, especially in disaster mitigation. <br\/>Broader Impacts: <br\/>This project, in a minority-serving institution, exhibits strength in broader impacts that may be found In leveraging a number of successful ongoing projects, most notably in computer science and geo-spatial sciences. The instrument carries potential to transform the decision-making process in disaster mitigation. The enabled research should benefit applications in environmental monitoring, transportation, education, public health and safety. The instrument would be used in classroom. Planned is recruitment that targets underrepresented minority students (Hispanics) through innovative research and quality education programs.","title":"MRI: Development of an Integrated, Geospatial Analytics Research Instrument","awardID":"1126619","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["558108","497035","550720","534488","516939"],"PO":["557609"]},"186526":{"abstract":"This research considers a scenario in which a piece of software needs to be protected against an attacker (the man-at-the-end, MATE) who has physical access to the software and so is able to inspect, modify, and execute it. The goal is to prevent the attacker from extracting sensitive information from the software, to prevent him from making changes to the behavior of the software, or, at least, to detect and report when such attacks are underway.<br\/><br\/>Man-at-the-end attacks can have serious consequences. For example, on an individual scale they can violate the privacy and integrity of medical records and other sensitive personal data; on a larger scale, such attacks can cripple national infrastructure (such as the power grid and the Internet itself).<br\/><br\/>This project explores innovative approaches to protect distributed systems from MATE attacks. To accomplish comprehensive defenses, the project develops MATE attack models and security metrics that formally characterize the process of device compromise, provides attack tools to allow easy testing of defense algorithms, and devises community standards for defense evaluation. Rigorously defined security metrics are necessary for research outcomes to be compared to existing and future approaches. A primary goal of this research is therefore to develop evaluation procedures for MATE defense mechanisms. This includes both universal obfuscation metrics and detailed red-team exercise protocols.","title":"EAGER: Man-at-the-End Attacks: Defenses and Evaluation Techniques","awardID":"1145913","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550173","550175","561905"],"PO":["564223"]},"187857":{"abstract":"This project will address the \"frontier problem-solving\" aspect missing in interdisciplinary research, and create a model of a course where experts from several disciplines collaborate on a complex project, particularly a field project. Today's science is increasingly an interdisciplinary endeavor, with researchers from several disciplines collaborating on a project. Yes, current graduate (and undergraduate) education is discipline-centered, with few opportunities for team projects, especially from outside the field. As a result, students are unprepared for the realities of cutting edge research. This problem is starting to be addressed by many institutions in a variety of ways. This work will design a highly integrated interdisciplinary field course, centered around computational and field biology research. The proposed course will be offered by the University of Illinois - Chicago, Princeton, and University of Nairobi where graduate students in biology (primarily ecology and evolutionary biology) and engineering (primarily in computer science and bioinformatics) work with faculty in both disciplines to learn how to ask questions, frame hypotheses and understand how and why the disciplines and cultures do this differently. Fieldwork will be conducted in Kenya.","title":"EAGER: Field Computational Ecology Course","awardID":"1152895","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":["533275","522280"],"PO":["565292"]},"178948":{"abstract":"In analogy to the fundamental role that random numbers play in classical information theory, random quantum states and unitary operators are a key resource in quantum information science. Unfortunately, generating a random unitary transformation is intractably inefficient, motivating the investigation of a weaker notion of quantum pseudorandomness that may be achieved efficiently while remaining practically useful. In this program, fundamental properties and implications of quantum pseudorandomness will be explored from a mathematical, information-theoretic, and physical standpoint, by focusing on the generation of pseudorandomness using so-called random quantum circuits. Primary emphasis will be placed on (i) characterizing the behavior of random circuits under more general conditions than considered thus far; and (ii) performing a dedicated study of the effect of implementation errors and decoherence. In doing so, the bigger goal of understanding whether random quantum circuits may serve to model the dynamics of generic many-body quantum systems will be kept in mind, with anticipated connections to the field of quantum chaos.<br\/><br\/>The scientific impact of this program will be twofold. First, a substantially improved understanding of the complexity involved in generating pseudorandom states and operators using random quantum circuits is expected to emerge. Beside providing a firm theoretical foundation for quantum information protocols that presume randomness as a resource, this could eventually find application in enhanced quantum algorithm design. Second, additional fundamental insights will also be gained on the emergence and characterization of apparent randomness in the properties of complex quantum systems. Intensive training on subjects at the cross-disciplinary boundary between quantum information theory, applied mathematics, and many-body physics will be provided to the graduate student supported by this grant.","title":"Explorations in Quantum Pseudorandomness","awardID":"1104403","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7281","name":"QUATM INFO & REVOLUTIONARY COM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[479826],"PO":["564326"]},"176407":{"abstract":"The Lehman College Computer Science and Mathematics Scholarship Program is designed to retain under-represented minorities and women in mathematics and computer-related fields. The program has four key components: funding through scholarships and equipment; advising and mentoring; career planning; and building a community of scholars. Scholarship recipients receive support for professional development and career planning which emphasizes collaboration and communication skills for success in the workplace. The program nurtures an active learning community which includes scholarship recipients who have graduated and entered the workforce.<br\/><br\/>This project is based on research on the recruiting and retention of under-represented minorities in STEM fields. The project encourages women and members of under-represented groups to complete computer science and mathematics majors and to join the STEM workforce. Data collected by the project will add to the body of literature which describes successful approaches to recruiting and retaining women and minorities in STEM degree programs.","title":"S-STEM: Lehman College Mentoring and Scholarship Program","awardID":"1060598","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1536","name":"S-STEM:SCHLR SCI TECH ENG&MATH"}}],"PIcoPI":["545221","485997",472891,472892],"PO":["552363"]},"182710":{"abstract":"This project is awarded under the Nanoelectronics for 2020 and Beyond competition, with support by multiple Directorates and Divisions at the National Science Foundation as well as by the Nanoelectronics Research Initiative of the Semiconductor Research Corporation. In the last decade, the scaling of electronics has slowed due to limitations in underlying technologies as nanoscale dimensions are approached, including leakage, power dissipation, lithography, interconnect, and noise. Thus, fundamentally new paradigms for efficient and high-performance computation are needed to enable important applications such as studying complex biological systems. The research objective of this proposal is to breakthrough the scaling limits of conventional electronics with a hybrid analog-digital computational platform that integrates heterogeneous biological and nanoelectronic systems. The hypothesis that will be explored is that heterogeneous integration of electronic computation and biological computation is desirable since the former contributes precision, programmability, and speed while the latter yields highly parallel and efficient processing. These systems will be implemented in bio-inspired subthreshold electronics and living cells using synthetic biology; they shall be integrated with each other via microfluidics and biological nanomaterials.<br\/><br\/><br\/>This research has the potential to have broad impacts on a wide range of fields including computational science, synthetic biology, electrical engineering, nanomaterials research, infectious diseases, and biomedical science. Our experiments with novel forms of biological processing will enhance the breadth of computational platforms and provide insights into how biology achieves robust and efficient computation. Our biological circuits will advance the field of synthetic biology via new devices and architectures for engineering biological systems. By mimicking biological networks with subthreshold electronics, we can discover new high-performance electrical circuit designs. Our research into biologically synthesized and organized nanowires will inform our understanding of how biological systems are self-organized and shall enable new nanoelectronics, sustainable and environmentally friendly nanomaterial synthesis, and self-healing structures in the future. We will validate our computational platform on currently intractable problems in biomedical research, including modeling, simulating, and understanding how emergent properties, such as antibiotic resistance in bacteria and yeast, arise from large-scale networks. This computational platform will enable the unprecedented modeling of large-scale biological systems for hypothesis-driven biomedical research. <br\/><br\/> This project also aims to advance education and outreach efforts in the highly interdisciplinary disciplines involved in this research. This project shall create a new course, \"Molecular Circuits Engineering\", to train undergraduates and graduates in both computational and experimental techniques for molecular computation. The team will also supervise students in the International Genetically Engineered Machines (iGEM) competition to provide hands-on experimental training. A key priority is to work with MIT and the MIT Center for Integrative Synthetic Biology to actively recruit under-represented minorities and women into computational, synthetic biology, and bio-inspired electronics research via the Saturday Engineering Enrichment and Discovery Academy, the MIT Summer Research Program, and the Society of Women Engineers.","title":"NEB: Integrated Biological and Electronic Computation at the Nanoscale","awardID":"1124247","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1991","name":"CHEMISTRY PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7681","name":"ENG NNI SPECIAL STUDIES"}}],"PIcoPI":["562496","554714","562911"],"PO":["562984"]},"181500":{"abstract":"Understanding the physical and chemical processes of Earth's atmosphere, land, and ocean presents significant scientific challenges. Due in part to the societal impact of addressing these challenges, recent years have seen significant investments in a large number of satellite and ground-based sensors dedicated to Earth observation. The observations from these sensors are used to estimate important geophysical properties such as temperature, clouds, aerosols, greenhouse gases, snow and ice, and used in scientific studies aimed at climate modeling, weather forecasting, air quality monitoring, and disease management. Current techniques from spatial statistics and data fusion fall short of what is needed because of computational constraints, difficulties in modeling and parameter estimation, or inability to provide uncertainty estimates. The objective of this project is to develop methods that help best utilize large quantities of multi-source observations from satellite and ground-based instruments for Earth observation having different capabilities regarding coverage, resolution, and quality. <br\/><br\/>This project develops a novel discriminative modeling framework for fusion of multi-sensor remote sensing data based on the Gaussian conditional random field model. The framework is designed to be flexible, robust, and computationally efficient, and hence suitable for use on large spatio-temporal data sets. It allows learning from a mixture of labeled and unlabeled data with partially observable attributes, in the presence of sampling bias. The methods will be implemented in an open source, user-friendly, software tool for use by practitioners. The resulting tools will be evaluated on the problems of atmospheric aerosol and surface level pollution estimation, which are some of the important problems in climate research and environmental science. <br\/><br\/>The broader impacts of this project include methodological advances in the current state of the art in spatio-temporal data mining and geostatistics as well as Earth remote sensing. It will enable improved characterization of the effects of aerosols on the Earth's radiation budget and climate. The data fusion framework is directly applicable to estimations of many other atmospheric, land, and ocean properties. The research activities in this project are integrated with education. They will help broaden the participation of students ranging from doctoral to K-12 level and increasing diversity in Computer Science through already established channels at Temple University for engaging students from underrepresented groups. <br\/><br\/>Additional details about the project can be found at: http:\/\/www.dabi.temple.edu\/~vucetic\/nsf_fusion.htm","title":"III: Small: A Discriminative Modeling Framework for Mining of Spatio-Temporal Data in Remote Sensing","awardID":"1117433","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[486283,486284],"PO":["565136"]},"181621":{"abstract":"Large-scale image data analysis has in recent years become a key bottleneck in natural science research, particularly in the field of neuroscience. Technological advances in automated data acquisition have enabled the collection of terabyte and petabyte-size datasets. Extracting the rich information contained in these datasets manually would require an inordinate amount of human labor; reconstructing the neural connectivity in a complete fruitfly brain or cortical column of a mouse from electron microscopy data, key tasks of interest, would require ten thousand years of human labor using current state-of-the-art manual and semi-automated approaches. Improved automated image analysis tools are likely to be directly useful to the neuroscience community, enabling large-scale dense reconstruction of neural circuits from microscopy data, in which the morphology of every neuronal process is traced and all chemical synaptic connections between cells are identified, thereby mapping the complete \"wiring diagram\" of the circuit contained in the neural tissue. Such reconstructions have the potential to fundamentally impact the understanding of neural circuits by enabling competing models of brain architecture to finally be rigorously verified or falsified experimentally.<br\/><br\/>The large size of the datasets, the need for high accuracy to avoid incorrect scientific conclusions being drawn about the data, and the need for well-calibrated confidence measures in order to limit the time that must be spent manually verifying the output of algorithms, are all substantial challenges not well-addressed by existing segmentation methods. The investigators propose to (i) Develop efficient algorithms for convolutional locality-sensitive hashing, a novel generalization of locality-sensitive hashing techniques to the highly applicable setting of dense overlapping patches from a larger data volume. (ii) Develop efficient algorithms for the overlapping patch and convolutional variants of sparse coding designed to scale to very large datasets, filter sizes and numbers of filters. The proposed convolutional locality-sensitive hashing approach will be employed to enable this. (iii) Develop algorithms that leverage (i) and (ii) to segment electron microscopy data, and compare empirically to existing segmentation methods. All of the proposed methods are highly scalable to executions on large compute clusters in order to handle large training and test datasets. Furthermore, since the proposed methods allow explicit representation of the data, they are expected to be better calibrated than parametric methods such as the existing neural network-based methods for segmentation of electron microscopy data that currently achieve the best accuracy.","title":"RI: Small: Large-Scale Machine Learning for Connectomics","awardID":"1118055","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["520938"],"PO":["564318"]},"180433":{"abstract":"How does a vision system recover the 3-dimensional structure of the world -- such as the layout of the environment, surface shape, or object motion -- from the dynamic 2-dimensional images received by the sensors in a camera, or the retinas in our eyes? This problem is fundamental to both computer and biological vision. Computer vision has developed a variety of algorithms for estimating specific aspects of a scene such as the 3-dimensional positions of points whose correspondence over time can be established, but obtaining complete and robust scene representations for complex natural scenes and viewing conditions remains a challenge. Biological vision systems have evolved impressive capabilities that suggest they have detailed and robust representations of the 3-dimensional world, but the neural representations that subserve this are poorly understood and neurophysiological studies thus far have provided little insight into the computational process. This project will pursue an interdisciplinary approach by attempting the understand the universal principles that lie at the heart of 3-dimensional scene analysis.<br\/><br\/>Specifically, the project will 1) develop a novel class of computational models that recover and represent 3-dimensional scene information, 2) collect high quality video and range data of dynamic natural scenes under a variety of controlled motion conditions, and 3) test the perceptual implications of these models in psychophysical experiments. The computational models will utilize non-linear decomposition - i.e., the ability to explain complex, time-varying images in terms of the non-linear interaction of multiple factors, such as the interaction between observer motion, the 3-dimensional scene layout, and surface patterns. Importantly, the components of these models will be adapted to the statistics of natural motion patterns that arise from observer motion through natural scenes and movement around points of fixation.<br\/><br\/>The project is a collaboration between three laboratories that have played a leading role in developing theoretical models of natural image statistics, visual neural representations, and perceptual processes. The investigators seek to combine their efforts to develop new models, data sets, and characterizations of 3-dimensional natural scene structure that go beyond previous studies of natural image statistics, and that can be tested in neurophysiological and psychophysical experiments. This project has the potential to bring about fundamental advances in neuroscience, visual perception, and computer vision by developing new classes of models that robustly infer representations of the 3-dimensional natural environment. It will create a set of high quality databases that will be made available to help other investigators study these issues. It will also open up new possibilities for generating realistic stimuli that can guide novel investigations of neural representation and processing.","title":"RI: Large: Collaborative Research: 3D Structure and Motion in Dynamic Natural Scenes","awardID":"1111328","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[483563],"PO":["564318"]},"182512":{"abstract":"This project is leveraging emerging technologies in social robotics with recent findings from social, developmental, and cognitive psychology to design, implement, and evaluate a new generation of robots that is capable of interacting with and instructing young learners (ages 3 through 6) in a truly social way. The robot incorporates signals that the mind implicitly uses to ascertain another's intentions, motivations, and affiliations (e.g., motor mimicry and synchrony, affective cues, gaze direction), making it capable of serving as a true embodiment of a human instructor. The robotic platform can be controlled remotely, through a direct and proximate connection or a remote, Internet-based operator interface. As such, the system can be placed in several different environments, ranging from a child's home to medical areas where issues of mobility or immunosuppression make it difficult for direct interaction with instructors. Research is aimed at better understanding children's concepts of robot mind and of robots as agents, uncovering mental operations behind learning new words, and adding to what is known about the added value (if any) of non-verbal utterances to understanding, communication, and collaboration.<br\/><br\/>Emerging research has identified the acquisition of early language and vocabulary skills primary predictors of later academic success. Impoverished vocabulary upon entering kindergarten strongly predicts poor subsequent academic performance. Accordingly, the use of technologies designed to build vocabulary during the preschool years is key to facilitating many types of learning. Interactions with a robotic language partner are expected to have particularly important ramifications for children with compromised opportunities to interact regularly with attentive, nurturing caregivers willing and able to foster their vital socio-intellectual developmental needs. In addition, the rationales, artifacts, and cyber platforms and infrastructure created for this project could lend themselves to a broad range of design extensions, such as providing opportunities for children who are learning English as a second language to participate in English-language-based social activities, outreach to rural areas where children have infrequent access to social activities, supporting children of deaf parents, and assessing\/assisting children with pragmatic language impairments.","title":"DIP: Collaborative Research: Social Robots as Mechanisms for Language Instruction, Interaction, and Evaluation in Pre-School Children","awardID":"1123085","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[488972],"PO":["562669"]},"183843":{"abstract":"Functional magnetic resonance imaging (fMRI) has become the most common tool for cognitive neuroscience, because it provides a safe, non-invasive, and powerful means to image human brain function. Based on recent rates of publication, there are currently more than 2000 fMRI studies being performed every year worldwide. The aggregation of data across multiple studies can provide the ability to answer questions that cannot be answered based on a single study. For example, using datasets from multiple domains one can start to investigate to what degree a region is selectively engaged in relation to a particular mental process, as opposed to being generally engaged across a broad range of tasks and processes. In addition, it provides the ability to integrate across specific tasks to obtain stronger empirical generalizations about mind-brain relationships, and to better understand the nature of individual variability across different measures. Recent work in neuroimaging analysis has focused on the application of methods such as machine learning techniques to understand the coding of information at the macroscopic level, and network analysis techniques to understand the interactions inherent in large-scale neural systems. The availability of a large testbed of high-quality fMRI data from published studies would also provide an important resource for the development of these and other new analytic techniques for fMRI data. However, sharing of raw fMRI data is challenging due to the large size of the datasets and the complexity of the associated metadata, and there is currently no infrastructure for the open sharing of new fMRI datasets.<br\/><br\/>This project, OpenfMRI, will provide a new infrastructure for the broad dissemination of raw data within cognitive neuroscience, addressing a critical need by providing an open data sharing resource for neuroimaging. The initial project is already online at http:\/\/www.openfmri.org with a limited number of datasets. The full project will greatly expand this repository by providing access to a large number of fMRI datasets from several prominent neuroimaging labs, spanning across a broad range of cognitive domains. Utilizing the substantial computational resources of the Texas Advanced Computing Center, the project will also perform standard fMRI analyses on all data in the repository using a common analysis pipeline, thus providing directly comparable analysis results for all of the studies in the database. The OpenfMRI project will support the development of infrastructural elements to make sharing of data by additional investigators more straightforward.<br\/><br\/>The repository of data that will be created by the OpenfMRI project will also serve as an important resource for teaching by providing students with the ability to replicate the analyses from published studies using the same data. By providing any researcher in the world with the ability to acquire large fMRI datasets, it will also provide all researchers with the ability to work with the same state-of-the-art datasets, regardless of institution. By creating the infrastructure for open sharing of research data, the project will also enhance the impact of other NSF-funded neuroimaging research projects by providing an infrastructure that can be used to make their data available. The planned work has the potential to benefit society by improving education, health, and human productivity through an increased understanding of mental function and its relationship to brain function.","title":"CRCNS Data Sharing: An open data repository for cognitive neuroscience: The OpenfMRI Project","awardID":"1130086","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[493026],"PO":["565292"]},"181544":{"abstract":"The last decade has seen the tremendous growth of the so-called Social Web and this trend is expected to continue in the years to come. As the distinction between the Web and the Social Web disappears, more and more people turn to them daily for information related to important medical, financial and political decisions. Therefore, there is an indisputable need for reliable information in the online world. In the years to come, there will be an increase in interaction with real-time information channels (R-TICs), such as the instant interaction, commenting and notification systems that every social network is developing . R-TICs will put new stress to human abilities to act under time pressure in making decisions and determine the quality of the information received. Technology can assist acting with confidence, by maintaining a personalized network of trusted sources and understanding the reasons for trust or distrust of information. The overall aim of this research is to lay the foundation of a comprehensive approach to support critical thinking and increase security while maintaining privacy in a trusted cyber-world. It proposes the design and implementation of an application that can maintain trails of trustworthiness for information propagated through Twitter, but is applicable to other R-TICs. When confronted with information that requires fast action, these applications will enable its users to evaluate its provenance, its trustworthiness and the independence of the multiple sources that provide this information. In addition this proposal will develop an online course for undergraduates and high school students that discuss the epistemological questions of knowledge and explains what critical thinking means in our highly interconnected world, interacting regularly with people we may never meet. In all of the phases of this proposal, undergraduates, under-represented minorities and women will be actively involved.<br\/><br\/>The core design envisions the testing of these ideas by developing a personalized Twitter client that keeps privately the trust values of its owner. Trustworthiness of a message received is calculated based on implicit and explicit rules: the user may explicitly mark a message as trustworthy or not, and her decisions affect the trust value of its sender in her personal client; or the system will determine a trust value based on the actions of those who have seen and propagated the message to the user, and whose trust values are already known to the user. Message independence is computed based on content search on Twitter and grouped by the inverse distance of the original senders. Privacy of the client's trust values is enhanced by the separation of the global R-TIC network (Twitter) and the user's trust network (the client). Additional research questions can be answered through the use of simulation and is expected that they will be adopted by the R-TIC operators once they see the benefits of the proposed features.","title":"TC: Small: RUI: Trails of Trustworthiness, Understanding and Supporting Quality of Information in Real-Time Streams","awardID":"1117693","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[486402,"520289"],"PO":["565136"]},"180455":{"abstract":"This collaborative research project leverages expertise of four research teams (IIS-1111415, Massachusetts Institute of Technology; IIS-1110955, Harvard University; IIS-1111398, Washington University; and IIS-1111534, Cornell University). Understanding time-varying processes and phenomena is fundamental to science and engineering. Due to tremendous progress in digital photography, images and videos (including images from webcams, time- lapse photography captured by scientists, surveillance videos, and Internet photo collections) are becoming an important source of information about our dynamic world. However, techniques for automated understanding and visualization of time-varying processes from images or videos are scarce and underdeveloped, requiring fundamental new models and algorithms for representing changes over time. This research involves creating systems that enable modeling, analysis, and visualization of time-varying processes based on image data. These models and algorithms will form the basis for a new set of tools that can help answer important questions about how our environment is changing, how our cities are evolving, and what significant events are happening around the world.<br\/><br\/>Analyzing images over time poses fundamental new technical challenges. This project focuses on developing and demonstrating end-to-end systems consisting of (1) novel representations necessary to model time-varying image datasets; (2) algorithms for estimating long-range temporal correspondence in image datasets; (3) algorithms for decomposing image datasets into intuitive primitives such as shading, illumination, reflectance, and motion; (4) analysis tools for deriving higher level information from the decomposed representations (e.g., trends, repeated patterns, and unusual events); and (5) tools for visualization of the high-level information and methods for re-synthesis of image data.<br\/><br\/>This work has the potential to have significant impact in a broad range of areas where images are generated over time, e.g., in ecology, astronomy, urban planning, health, and many others. The results of this research will be broadly disseminated by making source code and datasets publicly available via the project web site (https:\/\/groups.csail.mit.edu\/vision\/image_time\/) and offering tutorials and organizing workshops at significant conferences. The project provides educational opportunities and offers hands-on collaborative research experience to students at both the undergraduate and graduate levels and the four institutions.","title":"CGV: Large: Collaborative Research: Analyzing Images Through Time","awardID":"1111415","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["515737","497067"],"PO":["563751"]},"182402":{"abstract":"The PIs are investigating the design of intelligent tutoring systems (ITSs) that are aimed at learning in unstructured domains. Such systems are not able to do as much automatically as ITSs working in traditionally narrow and well-structured domains, but rather they need to share responsibilities for scaffolding learning with a teacher and\/or peers. In the work proposed, the three PIs, who share expertise in automated natural language understanding, intelligent tutoring systems, machine learning, argumentation (especially in law), complex problem solving, and engineering education, are integrating intelligent tutoring, data mining, machine learning, and language processing to design a socio-technical system (people and machines working together) that helps undergraduates and law students write better argumentative essays. The work of helping learners derive an argument is shared by the computer and peers, as is the work of helping peer reviewers review the writing of others and the work of learners to turn their argument diagrams into well-written documents. Research questions address the roles computers might take on in promoting writing and the technology that enables that, how to distribute scaffolding between an intelligent machine and human agents, how to promote better writing (especially the relationship between diagramming and writing), and how to promote learning through peer review of the writing of others. <br\/><br\/>This project is bringing together outstanding researchers from a variety of different disciplines -- artificial intelligence, law education, engineering and science education, and cognitive psychology -- to address an education issue of national concern -- writing, especially writing that makes and substantiates a point -- and to explore ways of extending intelligent tutoring systems beyond fact-based domains. It fulfills all aims of the Cyberlearning program -- to imagine, design, and learn how to best design and use the next generation of learning technologies, to address learning issues of national importance, and to contribute to understanding of how people learn.","title":"DIP: Teaching Writing and Argumentation with AI-Supported Diagramming and Peer Review","awardID":"1122504","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":[488661,488662,"558235"],"PO":["562669"]},"181313":{"abstract":"This project examines the art and science of co-designing compilers and hardware for circuit-level timing speculation thereby enabling reliable, high-performance computer systems. Timing speculation, an exciting, forward-looking hardware design alternative, allows designers to abandon pessimistic design guidelines and consequently extract more performance from the silicon. Unfortunately, timing speculation has been under-served by contemporary compiler technologies. This research develops novel design paradigms that allow the compiler and architecture to be jointly optimized to build highly effective timing speculative systems, a significant industrial and societal benefit. Outreach efforts motivate students to pursue graduate study in computer science and engineering. <br\/><br\/>Given the promise of timing speculation but the prevailing downward focus of existing work, targeted code generation addresses neglected portions of the system stack and offers enticing possibilities. This research develops timing-aware compilation that applies instruction-level error rate models to analyze and optimize instruction sequences. By generating binaries specifically targeted for timing speculation, the compiler aims to significantly reduce incidence of timing errors which demand dynamic correction. This extends the reach of timing speculation by reducing recovery cost. This allows systems to operate at higher clock frequencies or enables better energy-efficiency through lower supply voltages. The research develops compact timing error rate models through machine learning techniques and determines how existing flow analysis present in modern compilers could be used to drive these error rate models. The compiler extends existing code optimizations to include the estimated impact of timing errors generated during analysis phases. The compiler technology is being used to examine new design paradigms for integrated timing speculative systems which include co-designed and co-optimized architectures and compilers.","title":"SHF: Small: Integrating Compiler and Architecture Design to Boost Timing Speculation","awardID":"1116610","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["518591",485831],"PO":["565272"]},"181324":{"abstract":"Networks-on-chip (NoCs) are an on-chip interconnection fabric of choice for general-purpose chip multiprocessors and application-specific multiprocessor systems-on-chip. This project focuses on network-on-chip modeling and optimization to enable early-stage design exploration that fully elaborates the achievable envelope of NoC power, area, speed, reliability and cost. An architectural estimation thrust develops new architecture-level estimation methods that are portable to different router microarchitectures and that can accurately capture implementation effects. The thrust addresses the automatic generation of architectural estimation models, the modeling of chip design implementation flow choices and their impacts, and new trace-aware and workload-dependent estimations. An architectural optimization thrust develops new methodologies for trace-driven optimization of router configurations, packet routing and network topology, with consideration of runtime network resource contentions. <br\/><br\/>Successful completion of this project will help network-on-chip and multiprocessor system-on-chip designers reduce design effort while improving chip area, delay and power metrics. This will be enabling to the efficient design of more complex, higher-functionality integrated-circuit products within given cost and power limits. The research will also produce software tools to establish a foundation for further work by other research groups. Through research participation, both graduate and undergraduate students will be trained in this emerging aspect of system-on-chip design.","title":"SHF: Small: Research on Architecture-Level Estimation and Optimization for Networks-On-Chip Building Blocks","awardID":"1116667","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["522496","531923"],"PO":["366560"]},"182655":{"abstract":"In this Cyberlearning Design and Implementation Project, the University of Massachusetts Lowell (UML) and a non-profit collaborator, Machine Science Inc. of Cambridge,Massachusetts, are studying classroom implementations of a web platform that helps middle school and high school teachers engage their students in collaborative scientific inquiry. This technology -- the Internet System for Networked Sensor Experimentation (iSENSE) -- provides a shared repository of user-contributed classroom activities, such as tabletop science experiments, environmental analyses, engineering projects, and surveys, together with the data generated by these activities. The system features tools that enable teachers and students to create their own experiments, upload and tag data, and configure and share dynamic visual representations of the data.<br\/><br\/>School districts in Massachusetts and New Hampshire are participating in the four-year study. Teachers from each district attend annual summer professional development workshops at UML and receive ongoing support from the project team in integrating iSENSE into their science teaching. Educators participate in follow-up meetings during the academic year to report their experiences and exchange best practices. The most promising approaches are documented as lesson plans and shared with the larger iSENSE community. Throughout the project, researchers from UML's Graduate School of Education are collecting formative data to inform system refinement and curriculum development and to answer questions about integration and use of cyber-enabled learning technologies in classrooms, and conducting a summative assessment to determine the project's impact on student learning and science teaching practice.<br\/><br\/>Project deliverables include a set of iSENSE lesson plans, developed in close consultation with participating educators, together with several significant enhancements to the iSENSE data collection and visualization technology and a set of guidelines and justifications for those guidelines pertaining to developing data scientists and to integrating cyber-enabled learning technologies into classrooms. In particular, the project partners are developing data collection and visualization apps for Android and iOS mobile devices. On the iSENSE website, community-building features are being integrated into the system, giving users the ability to \"follow\" each other's system activity, in the manner of Twitter or Facebook. To foster a sense of community, students and teachers are encouraged to append comments to experiments, data sets, and saved visualizations. This enables them to ask questions relating to ongoing experiments,share resources, suggest further investigations, and critique one another's work.<br\/><br\/>Because iSENSE incorporates many emerging cyberlearning technologies, including interactive data visualizations, on-line community-building features, and the use of mobile computing platforms, the project has broad potential implications for the cyberlearning field. The project team is investigating how interacting with cyberlearning technologies and collaborating on-line changes the way students think about scientific data and the nature of science. The team is also examining how cyberlearning resources, such as user-contributed web content, web-based software tools, and mobile computing platforms, can enhance science teaching practice. At the same time, the investigators seek to identify what resources are needed, in terms of technology, professional development, and curriculum, to effectively support incorporation of sophisticated learning technologies in support of science practice and learning in the classroom.","title":"DIP: Collaborative Research: Transforming Science Learning with an Interactive Web Environment for Data Sharing and Visualization","awardID":"1123972","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":["520030",489359],"PO":["562669"]},"181566":{"abstract":"One of the most critical challenges in todays nanoscale VLSI design is the lack of predictability in analysis and optimization. As VLSI technology continues scaling in the nanometer domain, VLSI systems are subject to increasingly significant parametric variations coming from not only the manufacturing process but also the system runtime environment. Increasingly significant parametric variations lead to increasingly significant variations in IC timing performance, power consumption, and other product metrics. Existing VLSI statistical analysis techniques cannot accurately and efficiently capture such variations; this greatly compromises design optimization and design convergence, affecting product quality and time-to market.<br\/><br\/>In this work the PIs plan to develop techniques for signal probability-based statistical timing analysis (SPSTA), which would achieve accurate performance estimates for different inputs, rather than input-oblivious pessimistic delay bounds. In this project, the PIs propose to build on the foundation of SPSTA to enable a new, predictive and less-pessimistic VLSI implementation methodology. Core techniques will span VLSI statistical analysis, delay test ATPG, and optimization techniques that exploit improved predictability. Specifically, there are three thrust areas in this project, and it is expected that that these techniques will outperform existing alternative techniques. <br\/><br\/>The outcome of this project is critical to the cost-effective continuation of semiconductor technology scaling (i.e., Moore's Law), and to maintaining growth of the semiconductor industry's economic engine in the coming years. The broader impacts of the proposed project can be further measured by a strong education program including curriculum development and research training which incorporate statistical VLSI analysis and optimization techniques into the computer engineering programs at the PIs? institutions, and into course infrastructure that is broadly and openly available to others online.<br\/><br\/>Following their established practices of well over a decade, the PIs will broadly disseminate their research results by publication, industry collaboration, and online posting of open-source software. This project will also allow the PIs to broaden participation of students from under-represented groups based on the minority institute status of UT San Antonio; it will help educational initiatives that are aimed at preparing the San Antonio regional economy to transform into a technology-oriented one.","title":"SHF: Small: Collaborative Research: VLSI Design Predictability Improvement By New Statistical Techniques in Timing Analysis, Delay ATPG, and Optimization","awardID":"1117770","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["522496"],"PO":["562984"]},"182897":{"abstract":"The Global Environment for Network Innovations? GENI ? is a suite of research infrastructure rapidly taking shape in prototype form across the United States. GENI aims to transform experimental research in networking and distributed systems, as well as emerging research into very large socio-technical systems, by providing a suite of infrastructure for ?at scale? experiments in future internets.<br\/><br\/>GENI supports two types of experiments: (a) controlled and repeatable experiments, which will greatly help improve our scientific understanding of complex, large-scale networks; and (b) ?in the wild? trials of experimental services that ride atop or connect to today?s Internet and that engage large numbers of human participants. GENI will provide excellent instrumentation for both forms of experiments, as well as the requisite data archival and analysis tools.<br\/><br\/>GENI entered its prototyping phase in mid 2007 as NSF awarded the GENI Project Office (GPO) role to BBN Technologies. Now, after several years of community prototyping, a number of interesting research experiments are running across the nationwide ?meso-scale? GENI prototype, built from GENI-enabled commercial equipment, that spans 14 US campuses and the two national research backbones (Internet2, NLR). GENI is being built by GENI-enabling existing testbeds, campuses, regional and backbone networks, cloud computation services, and commercial equipment. GENI can then incorporate these networks and services by federation, rather than constructing and operating a separate set of infrastructure for experimental research.<br\/><br\/>This award will fund the GENI project through its completion. During this period, the GENI Project Office will: Complete the transition from building GENI to using GENI for research experimentation;<br\/>Phase in full-time, federated GENI operations to support this rising experimentation; Grow to an ?at scale? suite of infrastructure in hundreds of campuses and networks, and perhaps even one or more cities; Transition to community governance; and Wind down the GENI Project Office.","title":"GENI Project Office, Phase 2","awardID":"1125515","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"8077","name":"Science Across Virtual Instits"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["521729"],"PO":["564993"]},"180356":{"abstract":"Nanotechnologies are providing a new set of tools to the engineering community to design and manufacture devices in a scale ranging from one to a few hundred nanometers. At this scale, a nanomachine is defined as the most basic functional unit, which is able to perform only very simple tasks, such as computing, data storing, sensing and actuation. Nanonetworks, i.e., the interconnection of nanomachines in networks, will expand the capabilities of single nano-devices by providing them a way to cooperate and share information. Traditional communication technologies based on electromagnetic waves need to undergo a profound rethinking in order to meet the requirements of these networks. Moreover, there are specific applications of nanonetworks in which the utilization of electromagnetic waves is not feasible, such as in intra-body applications. Alternatively, molecular communication, i.e., the use of molecules to encode and transmit information among nanomachines, represents a radically new communication paradigm that demands novel solutions, including the identification of existing molecular communication mechanisms, the establishment of the foundations of molecular information theory, or the development of architectures and networking protocols for nanomachines. This project will address the above challenges to realize this new communication paradigm.<br\/><br\/>Intellectual Merit: This project seeks to develop a research area spanning across diverse fields, which include communication and information theory, computer science and biology. Specifically, this project will make contributions along four broad directions. First, the researchers will develop Theoretical Foundations of Molecular Nanonetworks, which include the definition and modeling of the attenuation, delay and noises affecting the emission, propagation, and reception processes in molecular communication. In addition, they will analyze the information capacity of nanonetworks first for a network with only two nodes and then for a network with N nodes, for which the effect of interference and collaborative communication will be taken into account. Second, the researchers will design Protocols for Molecular Nanonetworks based on the development of novel principles, primitives and services. Third, the researchers will implement a Simulation Tool for Molecular Nanonetworks in order to validate the information theoretical results as well as to evaluate the performance of the proposed protocols, by accounting for the interactions in the network molecule by molecule. Finally, the researchers will develop an Experimental Validation Platform for Molecular Nanonetworks by using a concrete testbed based on bacteria communication to verify the correctness of the information theoretical results and the protocols developed within the project.<br\/><br\/>Broader Impact: The project will pave the way for research in nanoscale communication. The outcomes of this work is expected to have a significant impact on research in nanotechnology, biology and information and communication technologies, since this project will represent the entrance of these three main communities to this converging field and will follow a realistic and integrated approach. The range of potential applications of nanonetworks is astonishingly wide, covering from intra-body networks for health monitoring, cancer detection or drug delivery, amongst others, to chemical attack prevention systems. The principal investigators teach a variety of classes in Georgia Tech spanning information theory, network algorithms, communication protocols and biology. They will immediately incorporate output from the proposed research into their classes. The team will develop an open source simulation tool to test the solutions developed and the tool will be made available for public use. This tool will represent the first simulation tool for molecular nanonetworks and will also be used in class projects as an educational tool to provide insights and deep understanding of nanosensor\/actuator networks. Scientific results will be disseminated at international conferences, journals and magazines in the field.","title":"NetSE:Large: MONACO: Fundamentals of Molecular Nano-Communication Networks","awardID":"1110947","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["562752","485126","560261",483330,"502298"],"PO":["565090"]},"185933":{"abstract":"The 2011 IEEE International Conference on Bioinformatics and Biomedicine provides an open, interactive forum to promote multi- and interdisciplinary research and education in bioinformatics, computing science and biomedicine, facilitating development of new ideas for bridging gaps. In addition to contributed talks and special publication in top scientific journals, the meeting provides focused workshops, tutorials and posters. BIBM has made a significant effort to engage your researchers in the meeting organization and also provides mentoring activities in the program. In the past BIBM conferences, many authors of accepted papers have requested travel support; a good number of them are handicapped, women and minorities. The committee feels obligated to support these students. The committee would like to provide support for both early career researchers and graduate students, providing both training and broadening the overall scientific impact of the conference.","title":"Travel Awards for The 2011 IEEE International Conference on Bioinformatics & Biomedicine","awardID":"1142717","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["37090","554592"],"PO":["565223"]},"181214":{"abstract":"The project is focused on developing coordination policies for large-scale multi-agent systems operating in uncertain environments through the use of multi-agent reinforcement learning (MARL). Existing MARL techniques do not scale well. This research addresses the scaling issue by using coordination technology to \"coordinate\" the individual agent learning so as to speed up convergence and lead to learned policies that better reflect overall system objectives. This novel idea is being implemented using an emergent supervisory organization with low overhead that exploits non-local information to dynamically coordinate and shape the learning processes of individual agents while still allowing agents to react autonomously to local feedback. A key question is how to automate the development of the supervisory control process (including supervisory information generation and organization formation). One approach to automation is using a formal model of interactions among agents that also includes a model of global system objectives and policy space of agents to derive the information necessary for appropriate supervisory control. Another approach is the formulation of the supervision problem as a distributed constraint optimization problem. The results of this work provide a necessary component for the development of a wide variety of next-generation adaptive applications, such as smart power grids, cloud computing, and large-scale sensor networks. The broader impact stems from the wide applicability of the resulting learning technology for distributed control, undergraduate and graduate educational activities at UMass, dissemination efforts that make the experimental domain and algorithms publically available, and the development of international collaborations.","title":"RI: Small: Coordinating Multi-Agent Learning through Emergent Distributed Supervisory Control","awardID":"1116078","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[485591],"PO":["565035"]},"181335":{"abstract":"Ambulatory health monitoring has been demonstrated to provide significant benefits to patients in a number of studies. The biggest promise for improved results for patients lies in the long-term, ambulatory monitoring of patients with chronic illnesses to help doctors and patients identify health issues before they reach a crisis stage. This project pursues the design of garments for ambulatory health monitoring that have the look and feel of every day clothing, together with an approach to monitoring that removes some of the barriers to patient compliance by automatically annotating physiological data with activities and motions, collecting data only during specific conditions, and having minimal impact on daily routine. The intellectual merits lie in the algorithms, design methodologies, and evaluation methodologies that enable wear-and-forget garments for ambulatory health monitoring. The approach developed by this project uses a computationally intensive pose estimation algorithm that automatically adapts a more computationally efficient algorithm for activity classification. This project addresses the challenges of providing garments that look and feel like everyday clothing by developing design and evaluation methodologies for incorporating fiber-based sensors into garments. These have significant advantages over discrete sensors by being woven or sewn into the fabric, covering much larger areas of a garment, and draping naturally. The broader impacts of the research lie in the potential to remove barriers that prevent the effective use of ambulatory health monitoring to improve the quality of life for patients and their families.","title":"SHB: Small: Collaborative Research: Electronic Textiles for Ambulatory Health Monitoring","awardID":"1116719","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["534368"],"PO":["564768"]},"180488":{"abstract":"This project addresses open questions and challenges in search theory, energy-efficient networked robotics, and fish biology. A network of robotic boats which can track many fish in shallow waters over extended periods of time are deployed in invasive carp infested waters. Provably correct cooperative search and tracking algorithms are developed, energy efficiency is studied at multiple levels including navigation, sensing, communication and complete system, communication protocols for controllable mobile entities are studied, and data analysis algorithms are developed.<br\/><br\/>The project provides a means to sustainably reduce invasive carp populations in US lakes without impacting other wildlife, thus solving a major environmental problem. Robots are shown to serve as a major scientific instrument for environmental scientists. The educational activities promote the results of this research to high school, undergraduate and graduate students, as well as educators across the country. A summer research experience is offered which blends mathematics, computer science and biology. Participation of students from under-represented groups is ensured through collaborations with predominantly Native American schools, as well as Central State University which has a 96% African-American student population. The project simultaneously raises awareness of environmental issues and attracts students to science and engineering.","title":"RI: Large: Collaborative Research: A Robotic Network for Locating and Removing Invasive Carp from Inland Lakes","awardID":"1111542","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["527920","518302"],"PO":["564069"]},"181225":{"abstract":"This project targets a number of challenging problems in Algorithms and Complexity that are amenable to an algebraic approach. Research is organized around three major goals: <br\/><br\/>1. Algorithms for matrix multiplication with the aim of achieving nearly-linear running time (i.e., proving that the matrix multiplication exponent equals 2).<br\/><br\/>2. Algorithms for polynomial factorization with the aim of achieving nearly-linear running time, and <br\/><br\/>3. Explicit constructions of randomness extractors with the aim of achieving logarithmic seed length and optimal output length. <br\/><br\/>A secondary aim of this project is to explicitly cultivate novel algebraic methods with broader applicability, and the choice of problems and approaches is made with this in mind. <br\/><br\/>Matrix multiplication is a central open problem in theoretical computer science, and improved algorithms for this important problem would have immediate consequences for a broad array of related problems. Univariate polynomial factorization is a similarly fundamental operation on polynomials, and it stands out as one of a very few such problems for which nearly-linear time algorithms are not yet known. Randomness extractors are unbalanced bipartite graphs with random-like properties that have emerged as a fundamental object in theoretical computer science (and beyond) with a huge array of applications spanning Complexity, Algorithms, Distributed Systems, Cryptography, Coding Theory, Compressed Sensing, and other areas. Resolving fundamental open problems such as those targeted in this project enhances our understanding and mastery of efficient computation.","title":"AF: Small: Algebraic Methods for Core Problems in Algorithms and Complexity","awardID":"1116111","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[485618],"PO":["565251"]},"181236":{"abstract":"The objective of the research is to develop design technologies that can alleviate the general robustness issues of the next-generation nonvolatile memories while maintaining and even improving the generic memory specifications such as density, power and performance. Comprehensive solutions are integrated from architecture, circuit and device layers for the improvement on the density, cost and reliability of emerging nonvolatile memories. <br\/><br\/>The design techniques include 1) a new write endurance improvement technique for multi-level cell devices to prolong the lifetime of the new nonvolatile memories by applying the coding and wear-leveling techniques that are monitored and controlled by self-contained circuits; 2) self-reference and other adaptive sensing techniques to overcome the impacts of process variations and device wear-out mechanisms for yield improvement.; and 3) a new interleaved 3D-stacking memory integration scheme and peripheral circuit design to increase the number of stacks integrated within a certain height. <br\/><br\/>The broader impact of the research lies in revealing the importance of applying cross-layer design techniques to resolve the robustness issues of the next-generation NVMs and the attentions to the robust design context. The system architects, the circuit designers and the device integration engineers can be well bridged and educated by the research innovations. The developed techniques can be directly transferred to industry applications under the close collaborations with several industry partners, and directly impact the future computing systems. The activities in the collaboration also include the tutorials in the major conferences on the technical aspects of the projects and new course development.","title":"CSR: Small: Collaborative Research: Cross-Layer Design Techniques for Robustness of the Next-Generation Nonvolatile Memories","awardID":"1116171","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["556667"],"PO":["565255"]},"181357":{"abstract":"Digital communication pervades our daily lives while digital storage devices have become the principal means of preserving our information. During the \"information age,\" in which we now live, the need for reliable transmission and storage of digital data is of paramount importance. What makes such reliable transmission and storage possible are error- correcting codes, first conceived by Claude Shannon over 50 years ago. The recent invention of polar codes is, without doubt, the most original and profound development in the theory of error-correcting codes in the past decade. Polar codes provably achieve the capacity of any memoryless symmetric channel, with low encoding and decoding complexity, thereby providing the first deterministic and constructive solution to the problem posed by Shannon in 1948. Nevertheless, the impact of polar codes in practice has been, so far, negligible. The objective of this project is to advance the theory of polar codes on one hand, and to bring polar codes much closer to practice on the other hand. If successful, the outcome of this research is likely to become an enabling technology for numerous communications applications, both commercial and for national security.<br\/><br\/>In order to make polar codes practical, major obstacles must be resolved. The first key problem in the field is how to efficiently construct polar codes. This project aims to develop a linear-time construction algorithm, with explicit guarantees on the quality of its output. The investigators also study algebraic and combinatorial structure of polar codes, with the goal of developing a good analytical handle on the rate of channel polarization. Currently available empirical results indicate that the rate of channel polarization is too slow for many applications. Thus the investigators intend to drastically improve the performance of polar codes, at short to moderate code lengths, by introducing certain key modifications in the successive-cancellation decoding algorithm. One especially promising idea in this regard is list decoding. A concerted effort is devoted to the analysis of list decoding algorithms for polar codes. Furthermore, a full implementation of such decoding algorithms in high-speed and low-power VLSI is pursued. This part of the research involves algorithmic transformations for the key steps of the decoder, effective high-throughput design techniques, careful VLSI complexity\/area analysis, and new computation scheduling ideas. Finally, applications of polar codes and channel polarization beyond point-to-point communications are considered. Such applications include multiple-access channels, relay channels, Slepian-Wolf coding, and information-theoretic security.","title":"CIF: Small: Polar Codes --- From Theory to Practice","awardID":"1116820","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[485936],"PO":["564924"]},"181478":{"abstract":"A critical impediment to taking full advantage of electronic health record (EHR) systems is the human computer interface (HCI). The project's core aim is to design, implement, and evaluate several new HCI features for clinical decision support (CDS) systems that have the potential for directly impacting point-of-care treatment and improving care for patients suffering from long-term illness. Some of the primary HCI features proposed include: 1) Visually enhanced interactive functions for EHR systems such as treatment trend maps and data indicators, 2) Patient data summary of critical data elements in a dashboard format, 3) Access to evidence-based recommendations relevant to individual patients, and, 4) Display of co-morbid conditions explicitly to encourage review and analysis in the context of routine patient care. The proposed work will explore the use of visual analytics to process patient and comparative population medical profile data to generate data summaries in the form of interactive visualizations (data views). The data views will be designed to provide physicians with the capability to filter patient data based on key data elements such as medications and co-morbid conditions, and to compare patient treatment trends with established evidence-based guidelines to identify treatment gaps and options. As part of the usability evaluation, the proposed work will engage end-users (i.e., care providers) directly in requirement generation, implementation, evaluation, and refinement of the CDS HCI. The broad impact of the proposed work include disseminating the outcome and findings through the network of Clinical Translational Science Awardees (60 academic medical centers) that are involved in developing novel informatics solutions to accelerate the translation of medical treatments and prevention strategies. Additionally, the MindsEye software will be distributed with appropriate documentation to contribute to health IT education and training and to spur practical IT engagements and new research activities.","title":"SHB: Small: Project MindsEye: Development and Evaluation of a Human Computer Interface for the MindLinc Clinical Decision Support System","awardID":"1117286","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[486226,486227],"PO":["565136"]},"180389":{"abstract":"This collaborative research leverages expertise of researchers at Wright State University (IIS-1111182) and Ohio State University (IIS-1111118). Online social networks and always-connected mobile devices have created an immense opportunity that empowers citizens and organizations to communicate and coordinate effectively in the wake of critical events. Specifically, there have been many isolated examples of using Twitter to provide timely and situational information about emergencies to relief organizations, and to conduct ad-hoc coordination. However, there are few attempts that try to understand the full ramifications of using social networks in a more concerted manner for effective organizational sensemaking. This project aims to conduct multidisciplinary research involving computer and social scientists fill this gap.<br\/><br\/>This project seeks to leverage Twitter posts (tweets) as the primary source of citizen inputs and couple relevant content and network information along with microworld simulations involving human role players to measure effectiveness of various organized sensemaking strategies. To arrive at meaningful summaries of citizen input, tweet content is analyzed using a semantic content analysis by combining natural language techniques that are suitably fused with existing knowledge bases (GeoNames, Wikipedia). Content analysis is further enhanced by innovatively combining it with the dynamic analysis of the twitter network to realize concise and trustworthy information nuggets of potential interest to organizations and citizens. The resulting summaries will be fed to a suitably designed microworld simulation involving human actors to derive realistic settings for modeling disaster situations and typical organizational structures.<br\/><br\/>This project is expected to have a significant impact in the specific context of disaster and emergency response. However, elements of this research are expected to have much wider utility, for example in the domains of e-commerce, and social reform. From a computational perspective, this project introduces the novel paradigm of people-content-network analysis whose application is not just limited to organized sensemaking. For social scientists, it provides a platform that can be used to assess relative efficacy of various organizational structures using microworld simulations and is expected to provide new insights into the types of social network structures (mix of symmetric and asymmetric) that might be better suitable to propagate information in emergent situations. From an educational standpoint, the majority of funds will be used to train the next generation of interdisciplinary researchers drawn from the computational and social sciences. Research activities will also be integrated with graduate course work. Participation of underrepresented groups will be encouraged. Datasets and software developed as part of this project will be made available to the broader research community via the project page (http:\/\/knoesis.org\/research\/semspc\/projects\/socs).","title":"SoCS: Collaborative Research: Social Media Enhanced Organizational Sensemaking in Emergency Response","awardID":"1111118","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["527873"],"PO":["563751"]},"181368":{"abstract":"This project will aid understanding of the emergence of computer security. It will examine key computer-security concepts and approaches in the domains of government, universities, industry, and criminal justice. Project activities include: [A] Conducting 30 detailed \u00d2research grade\u00d3 oral histories with key figures in the field. Transcripts will be publicly available on the website of the Charles Babbage Institute. [B] Collecting and archiving valuable documentary materials, including reports, correspondence, and grey literature, again to be accessible at CBI. [C] A knowledge networking wiki will describe and discuss key computer-security concepts, approaches, institutions, and frameworks, with input from experts in the computer-security field. The wiki will benefit computer security professionals, policymakers, scholars, students, and the broader society. [D] Publication of peer-reviewed scholarly articles will stimulate further historical attention of this vital area of computing. Collectively these four components will create a much-needed research infrastructure for computer security history. Work has been planned and will be done in close cooperation with an Advisory Committee of recognized leaders in the computer security field. With regard to training, we will carefully mentor a GSRA in the craft of conducting research-grade oral histories. The project team is attuned to documenting and analyzing the role of underrepresented groups in computer security, and disseminating narratives of role models to inspire future scientists. The chief result of the project will be the creation of a public, accessible, and permanent infrastructure of historical materials for better understanding the emergence of computer security.","title":"TC: Small: Building an Infrastructure for Computer Security History: Phase One -- Mainframes to the Advent of the World Wide Web, 1965-early 1990s","awardID":"1116862","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[485962,485963],"PO":["565327"]},"181489":{"abstract":"The FCC released its National Broadband Plan citing the exponentially growing demand for mobile data services and the critical need to better utilize the radio spectrum. Beyond retargeting certain frequency bands, the FCC is considering a paradigm shift of dynamic spectrum access (DSA) technology and policy. DSA allows 'secondary' radios to transmit in underutilized 'white space' provided they create minimal interference to 'primary' radios. Significant white space, as much as 85%, has been observed across time, frequency, and location. However, even in the TV bands, the challenge of inconspicuous utilization of white spaces has not yet been achieved by the two leading solutions, distributed spectrum sensing and centralized emitter databases.<br\/><br\/>This project focuses on a comprehensive approach to DSA based upon spectrum sensing that combines the following in a feedback loop: novel modeling of primary and secondary transmissions; design of optimal spectrum sensing algorithms and secondary access protocols based upon these models; and experimental validation within a testbed of software-defined radios. Preliminary results develop primary Markov models and optimal sequence detection algorithms for spectrum sensing that build upon the well-known Viterbi and forward-backward algorithms and expose fundamental limitations due to primary mismatch for the commonly used energy detector. The connections to trellis- and graph-based algorithms from the channel coding community should introduce a sizable new toolbox to DSA researchers. Secondary access protocols that take advantage of Markov process models for the primary users similarly exhibit improved performance tradeoffs between primary interference and secondary throughput. Collaborators in industry and regulatory bodies will be kept informed of the research results with an aim toward impacting DSA technology and policy development at national and international levels.","title":"CCF: Small: Sensing-Based Dynamic Spectrum Access Networks: Modeling, Algorithms, and Experimental Validation","awardID":"1117365","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["540625"],"PO":["564924"]},"181258":{"abstract":"Optimization can be used for designing lower cost or more efficient strategies and selecting model parameters so that models can accurately predict system behavior. However, for computationally expensive simulation models, conventional optimization can require infeasibly long computation times (months or years) The focus of this research is to develop a method (called POARS) to use parallel processors to find the global minimum of a function with relatively few simulations. Examples of such computationally expensive simulation models are systems of nonlinear partial differential equations used to describe fluid flow and reactive chemistry transport that arise in many applications including groundwater and atmospheric modeling. Because such models can take hours or even days to complete a single simulation, it is important to have algorithms that find good optimal solutions with few simulations, which the proposed research achieves by integrating surrogate response surfaces into the optimization. The algorithm will be applied to real models (based on field data) including a groundwater model (partial differential equations) and two watershed models (spatially distributed difference equations). <br\/><br\/>The POARS algorithm incorporates multiple novel features including Ensembles, Asynchronous Parallelism with Adaptive Re-planning and the use of multiple optimization methods on the response surface, where many evaluations can be made cheaply. The asynchronous aspect enables new simulations to start before simulations on other parallel processors are complete. The response surface is based on an ensemble of response surfaces including mixture models based on Dempster-Schafer theory. A proof of almost sure convergence of POARS will be given. The research will couple the optimization method on M processes with parallel simulations each on N processes to efficiently use MN processors.","title":"AF: Small: Parallel Global Optimization Algorithms with Asynchrony, Adaptive Re-Planning, and Response Surfaces for Costly Simulations","awardID":"1116298","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["550886"],"PO":["565251"]},"187913":{"abstract":"The term presence refers to a user's level of involvement in, or feeling of actually being part of, an immersive virtual environment (VE), or virtual reality (VR) as it is commonly called. Although researchers have been empirically studying presence for over 15 years, they have typically only focused on persons without disabilities. So whether the findings from these studies hold true for persons with mobility impairments is unknown. Based in part on his personal experiences, the PI hypothesizes that in fact many of these prior results may not be relevant to persons with mobility impairments deriving, for example, from stroke, Multiple Sclerosis, or Parkinson's disease. Many of these individuals have sensory deficits (e.g., numbness in the legs and feet), and use assistive devices (e.g., canes, walkers, or wheelchairs), which impact the way they navigate through a virtual space. This, in turn, could affect their experience of presence.<br\/><br\/>VR games are intended to enable users to perform rehabilitation exercises (e.g., to practice walking in good form) as part of an immersive game. They aim to engage the user's senses with graphics, audio, and 3D user interfaces, and when properly designed have been shown to enhance motivation, which is a key factor in successful rehabilitation. However these games are not yet in widespread use for physical rehabilitation, most likely due to the many unanswered basic questions about how persons with mobility impairments navigate within a VE and how this affects their experience of presence. In this exploratory research the PI seeks to gain a better understanding of such issues, as well as their potential impact upon the user's motivation for rehabilitation. To these ends the PI will conduct a series of empirical studies in collaboration with the Neurology Institute of San Antonio (NISA). As preliminary work, he is currently studying how alternative navigation methods such as real walking, virtual walking, and flying impact presence for people who walk with canes.<br\/><br\/>Although the preliminary study is still underway, initial results suggest that people who walk with canes experience lower presence than persons without mobility impairments. The PI plans to focus next on a number of fundamental aspects of VR that may affect navigation and presence, especially avatars (virtual representation of the body as well as of assistive devices such as a virtual cane) and field of view (the typical human field of view in the real world is about 120 degrees but it is much lower in a typical VE, which may complicate navigation for some mobility impaired persons). Through these studies, the PI will develop a new presence questionnaire that is tailored to mobility impaired persons and which can be integrated into existing presence questionnaires. The outcomes of this research will be potentially transformative, in that the findings will challenge and potentially disrupt accepted theories and perspectives of presence in the fields of VR and rehabilitation games.<br\/><br\/>Broader Impacts: This exploratory research will lay the foundations for a better understanding of presence in VR for the mobility impaired that may enable more effective immersive experiences for this underrepresented population, thereby resulting to higher motivation and more effective VR games for rehabilitation. This, in turn, could ultimately improve rehabilitation adherence, thereby leading to an improved quality of life for mobility impaired persons. Moreover, The University of Texas at San Antonio (UTSA) is a minority serving institution. The PI has initiated a UTSA Game Development Club, which he plans to expand as a gateway for minority student involvement in VR games research.","title":"EAGER: Presence and Navigation in Virtual Reality Rehabilitation Games for Mobility Impaired Persons","awardID":"1153229","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["562961"],"PO":["565227"]},"186703":{"abstract":"Synthetic Biology is a nascent field with applications that range from bio-fabrication to alternative energy. Despite its significance, engineering of biological circuits still relies on trial-and-error tinkering techniques, with limited computational support. If Synthetic Biology is to advance to more complex synthetic systems that go beyond a handful of interacting parts, a scalable, integrative, methodological approach is necessary. In an analogy to integrated circuits, when it comes to circuit engineering, the role of detailed computer models, optimization methods, simulators and design tools is paramount.<br\/><br\/>Intellectual Merit: This project aims to pave the way towards an optimization-based, automated design framework for synthetic gene circuits that adhere to user-defined constraints. A synthetic gene circuit is a collection of one or more genes, together with elements (promoters, ribosome binding sites, etc.) that influence gene expression. The wiring, i.e. the order and position of every element, within a synthetic gene circuit determines the gene expression pattern, and overall behavior of the circuit. These circuits are introduced, usually as part of a plasmid(s), in a host organism that can be readily manipulated in order to achieve a desired outcome (e.g. specific temporal behavior, or production of an enzyme). <br\/><br\/>To facilitate faster time-to-market solutions and more robust, predictable designs, PIs will develop a design and optimization tool prototype. To that end, PIs propose a new optimization formulation that encompasses multiple biological models relevant to synthetic genetic circuit design. In addition, they propose a hybrid optimization-simulation technique to capture additional effects related to cell division, noise, and evolutionary processes. The investigation will focus on how state-of-the-art techniques from combinatorial optimization can be applied to find the optimal circuit for a specific task. Since the tool will need a library of well-characterized components to operate, PIs will create a mutant library of three widely-used regulators, then quantitatively characterize them, and store this information in a publicly available database. As a proof-of-concept experiment, they will assess their integrative approach by constructing an automatically-designed synthetic circuit, measuring its output and deviation from the desired goal, and then comparing it to other similar designs that have been already available in literature. <br\/><br\/>Broader Impact: An optimization-based, design tool for synthetic biology has the potential to provide a service to the academic community by reducing drastically the time-to-market aspect of synthetic designs, and providing insight on biological function, thus accelerating research in an exponentially growing field. All components and characterized libraries that will be developed as part of this award will be publicly available, deposited in the synthetic biology community?s standard Parts Registry. Furthermore, this award will partially support the work and training of the UC Davis IGEM team, a synthetic biology undergraduate team who competes in the annual IGEM competition. Knowledge from this project will be directly transferred into classrooms through the course ECS 289K \"Computational Challenges in Systems and Synthetic Biology\" (UC Davis), and the course CSC 450\/550 \"Algorithms for Bioinformatics\" (U. Arizona).","title":"Collaborative:EAGER: A Model Based System for the Automated Design of Synthetic Genetic Circuits by Mathematical Optimization","awardID":"1146926","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["550693","534568"],"PO":["565223"]},"187803":{"abstract":"This EAGER project will carry out three classes of experiments on GENI, all related to security and privacy and all involving low-level network facilities. Of particular interest is the issue of adoptability: will real users (system administrators) accept novel security solutions and under what circumstances? Three experiments are proposed to address these challenges.<br\/><br\/>The first experiment focuses on a monitoring system to detect infrastructure attacks: Currently, the protocol WATCHERS is known to be able to detect almost all attacks on routers, but its behavior under realistic network traffic is unknown. This experiment will ask questions like: What is the effect of monitoring on the infrastructure itself? How do the benefits of monitoring weighed against the cost of monitoring affect the adoption of the service by autonomous network entities?<br\/><br\/>The second experiment is focused on attack mitigation with modified infrastructure services. Specifically, they will investigate how incremental adoption of a DNS protocol modification might affect the global domain name service when both standard and modified protocols operate simultaneously. Key questions are: Does a new infrastructure attack mitigation scheme interfere with the vulnerable service in widespread use? How do the new and old services compete with one another during the adoption phase?<br\/><br\/>The third experiment focuses on distributed private online social networking. The PIs propose to explore deployment of secure and privacy-flexible p2p-client platforms for migrating from a centralized to a decentralized peer-to-peer social on-line network. The PIs are proposing to develop a social caching\/name-resolution server, analogous to DNS for IP networks, to assist the p2p clients (or super peers) connected through GENI as they manage their privacy settings for their communities of interest. Key questions are: how can superpeers identify communities of interest and other social groups? Can they interface with centralized social networking frameworks, like facebook? Can they aid in the protection of privacy of their constituent clients?<br\/><br\/>As for the broader impacts, GENI will be used for experimentation in six security-related university classes. The PIs also participate in the UC Davis COSMOS (Computer Security, Privacy, and Cybervillainy) program, which provides high achieving high school students the opportunity to explore advanced topics in math and science in a university setting. Laboratory experimentation is 30% of the COSMOS program curricula for which GENI will serve as an ideal platform.","title":"GENI: EAGER: GENI Experiments to Explore Adoption of New Security Services","awardID":"1152664","effectiveDate":"2011-09-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["507838","521752"],"PO":["564993"]},"184668":{"abstract":"The national transmission networks that deliver high voltage electric power underpin our society and are central to the ongoing transformation of the American energy infrastructure. Transmission networks are very large and complicated engineering systems, and \"keeping the lights on\" as the transformation of the American energy infrastructure proceeds is a fundamental engineering challenge involving both the physical aspects of the equipment and the cyber aspects of the controls, communications, and computers that run the system. The project develops new principles of cyber-physical engineering by focusing on instabilities of electric power networks that can cause blackouts. It proposes novel approaches to analyze these instabilities and to design cyber-physical control methods to monitor, detect, and mitigate them. The controls must perform robustly in the presence of variability and uncertainty in electric generation, loads, communications, and equipment status, and during abnormal states caused by natural faults or malicious attacks.<br\/><br\/>The research produces cyber-physical engineering methodologies that specifically help to mitigate power system blackouts and more generally show the way forward in designing robust cyber-physical systems in environments characterized by rich dynamics and uncertainty. Education and outreach efforts involve students at high school, undergraduate, and graduate levels, as well as dissemination of results to the public and the engineering and applied science communities in industry, government and universities.","title":"CPS: Medium: Collaborative Research: The Cyber-Physical Challenges of Transient Stability and Security in Power Grids","awardID":"1135819","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[495278],"PO":["565239"]},"186846":{"abstract":"This project addresses two of the grand challenges of the next decade: green wireless communication systems and spectrum efficiency, through a collaborative research and education plan utilizing optimization theory, and involving researchers from the U.S. and Finland. This project considers energy efficiency for cognitive radio networks and introduces a novel optimization-based methodology. It builds on existing results to establish a new focus on green cognitive networking. The way in which energy is consumed in cognitive networks provides unique opportunities for exploiting the cognitive process to save energy and for using energy reduction techniques to modify and improve the performance of cognitive networks. A unique feature of this project is the introduction of an optimization-based methodology for establishing and attaining ultimate performance limits. In this project, PIs develop energy performance bounds that yield insights for design of general networks, derive optimal tradeoffs between fundamental performance criteria, use optimization formulations for establishing and achieving ultimate performance limits, and design protocols that are optimal in the presence of temporal cognitive systems evolution. Research results of this work will be widely promulgated through the usual means of publication and dissemination and will have significant impact on energy efficiency of spectrum-efficient wireless systems.","title":"Collaborative Research: Energy Efficient Cognitive Networking","awardID":"1147603","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["434241"],"PO":["557315"]},"188914":{"abstract":"This project establishes a new virtual institute, Wireless Innovation between Finland and US (WIFIUS), for promoting and sustaining mutually-beneficial research and education collaborations between US and Finland in the area of wireless networks. The institute provides an environment for creative international collaboration that leverages the synergies and resources for research and education in the two countries in order to accelerate the rate of development of research innovations and the development of talent and work-force capable of excelling in the a new highly interconnected world. The objectives of the institute are to: (1) facilitate and support existing and new international research and education activities in the broad area of wireless networks, (2) enable sharing of knowledge and cross-fertilization among the participants of various relevant international projects, (3) enable sharing of expertise with emerging experimental platforms, standards and wireless technology policies in the two countries, and (4) facilitate and support interaction between academia, industry and government agencies of the two countries. The proposal also describes the activities and mechanisms that will be adopted in order to achieve these objectives. The technical focus of the institute is on wireless spectrum efficiency technologies, which intellectually aligns along the interests of researchers in the two countries, as well as the countries' national priorities. The institute employs a number of activities including: (a) a web portal that provides services and content to participants, (b) physical and virtual PI meetings, (c) physical and virtual student investigator meetings, (d) yearly summer schools and (e) graduate student exchange.","title":"EAGER: WI-FI-US: Virtual Institute for Wireless Research Between Finland and USA","awardID":"1158411","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["434241"],"PO":["557315"]},"186505":{"abstract":"Since 2003, the ACM International Conference on Embedded Networked Sensor Systems (SenSys) has served as a high caliber, cross disciplinary forum for research on systems issues in embedded and networked sensors. SenSys, a single track forum, addresses issues that span multiple research areas, including wireless communication, networking, operating systems, architecture, low power circuits, distributed algorithms, data processing, scheduling, sensors, energy harvesting, and signal processing. Student participation in top research venues, such as SenSys, is critical for a vibrant research community. Further, students often have limited sources of funds to travel to conferences. Bringing students together with experienced practitioners enriches existing research projects and creates new collaborations. Travel grants will be awarded based on need. This award will support to cover travel and conference registration expenses for twenty students and help increase the representation and participation of graduate students in SenSys.","title":"Student Travel Award for SenSys 2011","awardID":"1145828","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["561708"],"PO":["565136"]},"186879":{"abstract":"Increased capacity in wireless networks has largely come from shrinking cell sizes, but continuing this trend has become impractical for large operators. Small wireless networks are also straining in overcrowded spectrum bands. The problems are particularly acute in high-density 802.11 deployments. It is clear that a collaborative approach, taking advantage of both large infrastructure deployment by operators and distributed deployments of 802.11 and femtocell networks could be extremely beneficial. This project focuses on three major problems related to heterogeneous wireless networks. First, models are developed that quantify the gains from cooperation between large operators and small-scale operators and end users deploying their own wireless access networks. Second, game theoretic and pricing models are developed to study incentive structures to support collaboration in heterogeneous wireless networks. Third, a threat model is developed to specifically model security threats that would impact a heterogeneous wireless network through a holistic vulnerability assessment. These three tasks are all complemented by frequent prototyping and experimentation.<br\/><br\/>This work will be immediately applicable to real networks and will quantify the benefits of collaboration for network operators. In addition, the collaborative project will deepen technological collaboration between the United States and Finland. The models developed in this project will all be available and published in the scientific literature, providing a holistic understanding of heterogeneous wireless networks. These models will catalyze the further technical development of protocols and standards to support open, heterogeneous wireless networks.","title":"Economic Models for Collaborative Access Network Provisioning: US-Finland Collaboration","awardID":"1147790","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["540088","540078"],"PO":["557315"]},"186648":{"abstract":"The substantial increase of energy consumption has brought up many serious engineering problems and economic concerns to our society. Many energy-saving scheduling algorithms have been proposed in the past decade to manage power consumption. However, energy-saving algorithms' impact on chip lifetime reliability, an important factor affecting overall system sustainability, has not been carefully examined by computer science theorists.<br\/><br\/>The goal of this EAGER proposal is to explore the theoretical groundwork of incorporating chip reliability in designing energy efficient scheduling algorithms for modern computing facilities. The PI proposes a new model that augments the existing energy-aware schedulers by enforcing additional chip lifetime reliability constraints which are modeled as functions of processor frequency changes. Novel scheduling algorithm design and analysis techniques are investigated to solve this problem.<br\/><br\/>The project outcome may potentially be transformative to a spectrum of related scheduling problems. In addition to studying the proposed theoretical problems, the PI empirically measures the performance of the developed algorithms by utilizing the FreeBSD operating system. This research suggests that through operating system kernel development, the practical implications of theoretical findings can be demonstrated.","title":"EAGER: Integrating Chip Reliability in Designing Energy-Saving Scheduling Algorithms","awardID":"1146578","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["485283"],"PO":["565251"]},"188728":{"abstract":"This award, co-funded by the Catalyzing New International Collaboration and Smart Health programs, supports a workshop organized by Naphtali Rishe of Florida International University and <br\/>Ann Liebschutz of the U.S.-Israel Science and Technology Foundation. The workshop on Knowledge Mining and Bioinformatics Techniques to Advance Personalized Diagnostics and Therapeutics is to be held in conjunction with the Up Close and Personalized - Personalized Medicine Congress in Florence, Italy, February 2012. <br\/><br\/>The workshop will foster collaboration in the design and development of bioinformatics tools to analyze and process large quantities of clinical and genomic data. This topic is at the intersection of clinical data-mining, algorithms design and bioinformatics. As it is well known that one drug does not deliver the same results to all patients, this workshop seeks to spur international collaborations to enable identification of individual genetic differences affecting drug effectiveness, making possible personalized treatment plans that can both improve the quality of healthcare while reducing its cost.<br\/><br\/>In particular, the workshop will seed collaborations between U.S., Israeli, Turkish and Palestinian scientists. Through the auspices of the Turkish Embassy and Israeli-Palestinian Science Organization, the workshop is intended to bring together a multidisciplinary group of scientists from the fields of computer science, pharmacology, neuroscience, public health, medical informatics and bioinformatics. These future endeavors will build on diverse areas of expertise and technologies in development to improve health care delivery internationally.","title":"Knowledge Mining and Bioinformatics techniques to Advance Personalized Diagnostics and Therapeutics","awardID":"1157372","effectiveDate":"2011-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["558108",506076],"PO":["525681"]},"180401":{"abstract":"This collaborative research leverages expertise of researchers at Wright State University (IIS-1111182) and Ohio State University (IIS-1111118). Online social networks and always-connected mobile devices have created an immense opportunity that empowers citizens and organizations to communicate and coordinate effectively in the wake of critical events. Specifically, there have been many isolated examples of using Twitter to provide timely and situational information about emergencies to relief organizations, and to conduct ad-hoc coordination. However, there are few attempts that try to understand the full ramifications of using social networks in a more concerted manner for effective organizational sensemaking. This project aims to conduct multidisciplinary research involving computer and social scientists fill this gap.<br\/><br\/>This project seeks to leverage Twitter posts (tweets) as the primary source of citizen inputs and couple relevant content and network information along with microworld simulations involving human role players to measure effectiveness of various organized sensemaking strategies. To arrive at meaningful summaries of citizen input, tweet content is analyzed using a semantic content analysis by combining natural language techniques that are suitably fused with existing knowledge bases (GeoNames, Wikipedia). Content analysis is further enhanced by innovatively combining it with the dynamic analysis of the twitter network to realize concise and trustworthy information nuggets of potential interest to organizations and citizens. The resulting summaries will be fed to a suitably designed microworld simulation involving human actors to derive realistic settings for modeling disaster situations and typical organizational structures.<br\/><br\/>This project is expected to have a significant impact in the specific context of disaster and emergency response. However, elements of this research are expected to have much wider utility, for example in the domains of e-commerce, and social reform. From a computational perspective, this project introduces the novel paradigm of people-content-network analysis whose application is not just limited to organized sensemaking. For social scientists, it provides a platform that can be used to assess relative efficacy of various organizational structures using microworld simulations and is expected to provide new insights into the types of social network structures (mix of symmetric and asymmetric) that might be better suitable to propagate information in emergent situations. From an educational standpoint, the majority of funds will be used to train the next generation of interdisciplinary researchers drawn from the computational and social sciences. Research activities will also be integrated with graduate course work. Participation of underrepresented groups will be encouraged. Datasets and software developed as part of this project will be made available to the broader research community via the project page (http:\/\/knoesis.org\/research\/semspc\/projects\/socs).","title":"SoCS: Collaborative Research: Social Media Enhanced Organizational Sensemaking in Emergency Response","awardID":"1111182","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[483465,"560054",483467],"PO":["563751"]},"181501":{"abstract":"Developers of networked embedded systems often find it difficult to diagnose bugs. A key observation is that in such systems, it can be beneficial to exploit domain knowledge about events in the physical world to detect failures. For example, in a sensor network deployment, knowing that the received signal strength of a radio transmission will normally decrease over distance, the application developer can enforce runtime checks to detect faulty nodes based on their relative distances to the source and the orderings of their received signal strength.<br\/><br\/>Based on this intuition, this project addresses the challenge of developing correct, resilient, and reliable networked embedded systems by (i) proposing, developing, and evaluating a methodology of using physical events to detect software bugs, (ii) developing software libraries and APIs to facilitate easy access to physical event constraints by application developers, and (iii) evaluating the effectiveness of the software libraries using real-world applications. <br\/><br\/>The completed framework could significantly reduce the debugging and maintenance costs for complicated networked embedded systems, and improve their reliability. Beyond such direct social and economic benefits, the broader impacts of this work include: (i) improving curriculum with hands-on debugging sessions; (ii) raising interest in technology among high school seniors through a Pre-Collegiate Research Scholars Program; (iii) supporting talented female and under-represented minority PhD students to successfully accomplish their doctoral studies; (iv) disseminating research results through high-quality publications, high-profile tutorials, and open-source sites.","title":"CSR: Small: Collaborative Research: Autonomous Failure Detection and Recovery in Networked Embedded Systems","awardID":"1117438","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526936"],"PO":["564778"]},"182832":{"abstract":"CDI-Type I: Collaborative Research: Collaborative Multi-robot<br\/>Exploration of the Coastal Ocean (COMECO)<br\/><br\/>Overview: The coastal ocean is a complex environment driven by the interaction of atmospheric, oceanographic, estuarine\/riverine, and land-sea processes, which result in dynamic coastal features such as blooms, anoxic zones, and plumes (estuarine, oil, pollutant). Effective observation and quantification of these features require simultaneous, rapid measurement of diverse water properties to capture its variability. This project aims to synthesize and understand the basic principles of environmental sensing based on the integration of adaptive robotic sampling with human decision-making. The techniques being developed augment existing ocean models and aid coastal exploration to ensure that robots are present at the \"right place and time\" to provide the most effective measurements.<br\/><br\/>Technical Description: The absence of a single model assimilating all available physical and biogeochemical data to provide a reliable view of ocean features favors the combination of human expertise, model refinement, and analytical adaptive sampling adopted in this project. Human decision-making is coupled with probabilistic modeling and learning in a decision support system enabling environmental field model discovery and refinement. The project extends the state of the art in multirobot adaptive sampling by investigating the relationship between environmental field structure and sampling performance, developing improved field boundary tracking techniques, and creating methods for multi-resolution, multivariable sampling. These advances are being made by addressing two broad research challenges. The first, Model-Based Asset Allocation, involves synthesis of large-scale, low-resolution data with human scientific expertise to make timely, model-informed asset allocation decisions. The second, Sampling-Based Model Refinement, involves small-scale, high-resolution autonomous cooperative selection and execution of robot sampling trajectories. Both challenges involve the handling of multivariate, multi-resolution, temporally evolving fields. The project includes a feasibility and evaluation study in coastal ocean exploration using underwater robots.<br\/><br\/>Broader Impacts: Decision support with diverse data integrated in a form that is interpretable by a non-computer specialist will have a broader impact applicable to a range of domains, including ocean and space exploration, environmental disaster response and military andhomeland security. The ocean science community will have a new and powerful tool to augment their understanding of dynamic coastal phenomena and policy makers an important tool to aid decision making impacting coastal communities. It is expected that the methods developed will be broadly applicable to the general task of goal-driven exploration and characterization of large areas. The project will involve graduate students who will be trained in an interdisciplinary context. The project results will be disseminated in the peer-reviewed scientific literature as well as via the project website at: http:\/\/robotics.usc.edu\/comeco.html","title":"CDI-Type I: Collaborative Research: Collaborative Multi-Robot Exploration of the Coastal Ocean","awardID":"1124941","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7750","name":"CDI TYPE I"}}],"PIcoPI":[489879],"PO":["560586"]},"181985":{"abstract":"This award sponsors undergraduate and graduate student attendance at the 27th ACSAC, to be held December 5-9 2011 in Orlando, Florida. The ACSAC conference is a top-tier academic security conference which attracts about 200 highly skilled security professional attendees per year. ACSAC regularly brings together leading minds in academic, governmental and commercial computer security to address the most pressing problems in applied computer security and to discuss seminal works in Computer Security. In addition to keynote Invited Essays and Distinguished Practitioner talks), ACSAC includes a \"Classic Papers\" series, in which two or three authors of seminal papers in computer security are invited to update those papers and present lessons learned. These papers, available free on the ACSAC web site, familiarize a new generation of students with key security research developments of the past, and provide a valuable resource for undergraduate and graduate instruction. Supported students have an opportunity to meet and interact with notable figures at the conference.","title":"ACSAC 2011 student support","awardID":"1120038","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["565327","529389"],"PO":["497499"]},"181633":{"abstract":"The need for more powerful and efficient query languages to find complex patterns in stored sequences and data streams is shared by a wide spectrum of applications, including software analysis, complex event processing, identification of RNA structures, temporal databases and XML queries. The goal of this project is to develop a unified framework to support very powerful pattern languages and their query optimization techniques for different application domains. To achieve this goal, the project follows the approach of using (i) nested Kleene-closure (K*) constructs to achieve greater levels of expressive power for the query languages, and (ii) Nested Words and Visibly Pushdown Automata as the basis for their unified implementation and query optimization over different application domains. This K*-based approach was previously applied successfully to relational sequences and are now generalized to different computing environments and application domains. Through the unified framework, the project designs and demonstrates XML and temporal query languages that compare favorably in terms of expressive power and performance with existing ones. It then demonstrates the use of the unified framework in new application areas. In particular, it develops efficient query languages for RNA structures and software analysis. These research results will have great impacts on many applications, such as software analysis, genomic databases, complex event processing, digital government and scientific studies. This project supports Ph.D. students to pursue research in the areas of advanced query languages and data stream management systems. A new graduate-level course covering these areas and integrating the research results from the project are introduced into the curriculum. Publications, technical reports, software and experimental data from this research are available via the project web site at: http:\/\/yellowstone.cs.ucla.edu\/nsf-projects\/RegExpr2NestedWords.html.","title":"III: Small: From Regular Expressions to Nested Words in Complex Event and Semistructured Information Processing","awardID":"1118107","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["542091"],"PO":["563727"]},"180423":{"abstract":"This project will exploit algebraic properties of operators associated with graphs in an integrated set of research and educational activities designed to develop new mathematical and algorithmic techniques; apply these to the solution of real-world problems and longstanding theoretical questions in mathematics, computer science, biology, and physics; and make these techniques broadly known and accessible to students, researchers, and practitioners in many fields. <br\/><br\/>This research has its origins in spectral graph theory, which studies how the eigenvalues and eigenvectors of the graph Laplacian (and other related matrices) interact with the combinatorial structure of the graph. Spectral graph theory has been one of the great success stories in both the theory and practice of algorithm design. It has led to fundamental advances in graph partitioning, web search (notably including Google's PageRank algorithm), the understanding of random processes and the algorithms derived from them, the construction of error correcting codes, derandomization, convex optimization, machine learning, and many others. <br\/><br\/>While the eigenvalues and eigenvectors of the Laplacian capture a striking amount of the structure of the graph, they certainly do not capture all of it. Recent work by the principal investigators and other researchers suggests that theoretical computer scientists have only scratched the surface of what can be done if they are willing to broaden their investigation, extending it to study more general algebraic properties of the Laplacian than just its eigenvalue structure, and more general operators than just the Laplacian. <br\/><br\/>Under this award, the principal investigators will build a research program across the three universities involved in this proposal to develop such a theory and its applications. This initiative has the potential to provide transformative advances in a range of theoretical and applied areas of computer science, including: <br\/><br\/>* Faster algorithms for fundamental graph problems, such as Maximum Flow, Minimum Cut, Minimum Cost Flow, Multicommodity Flow, approximating Sparsest Cut, generating random spanning trees, and constructing low-stretch spaning trees. <br\/><br\/>* Better algorithms for the analysis of data, with potential applications to the Unique Games Conjecture. <br\/><br\/>* Faster algorithms for solving broad classes of important linear systems, both sequentially and in parallel. <br\/><br\/>* Faster distributed algorithms for information dissemination in networks. <br\/><br\/>* A spectral and algebraic graph theory for directed graphs, based on ideas from differential geometry. <br\/><br\/>* Novel quantum algorithms for a large class of problems that appear to be hard for classical computers. <br\/><br\/>* New techniques for problems in Quantum Physics based on ideas developed in Computer Science and Combinatorics. <br\/><br\/>The principal investigators will also work to disseminate these techniques by developing courses, training undergraduate and graduate students, and introducing these ideas to scientists in other fields.","title":"AF: Large: Collaborative Research: Algebraic Graph Algorithms: The Laplacian and Beyond","awardID":"1111270","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[483541],"PO":["565157"]},"180555":{"abstract":"This research project addresses the important problem of improving and maintaining peoples' healthy lifestyles by inventing smart technology based on fundamental scientific principles. The approaches are economically feasible and socially compelling approaches, with a focus on maintaining the health and independence of older adults in a home environment. The project uses a mix of networking and monitoring technologies to connect older adults with a remote health coach (real person facilitated by a semi-automated program) and remote family members. One of the key design issues is how best to preserve privacy and enable the participants to control the distribution and sharing of their data. The intervention is designed to provide coordinated and continuous health management.<br\/><br\/>The research for this project uses the integration of data from a variety of sensors in the home, yielding information for activity monitoring, sleep monitoring, gait and movement analysis, socialization measures, as well as a variety of cognitive metrics derived from computer interactions with adaptive games. Rigorous computational engineering models of the cognitive and physical functions of the patient, as well as context and environment, are used to infer patient state and provide feedback for the patient and the remote health coach. The modeling techniques include Partially Observable Markov Process and Hybrid Control Modes. User models that incorporate behavior change principles are then used to drive algorithms to optimize automated feedback and recommendations that serve as prompts for a health coach managing a large number of patients. These approaches to remote health management are evaluated by leveraging an existing prototype platform with the capability of collecting data from the homes of elderly participants.","title":"SHB: Large: Collaborative Research: Integrated Communications and Inference Systems for Continuous Coordinated Care of Older Adults in the Home","awardID":"1111965","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["563532",483881],"PO":["564898"]},"181413":{"abstract":"Today's Internet runs Border Gateway Protocol (BGP), a complex inter-domain routing protocol. Over the past few years, there has been a growing consensus on the complexity and fragility of BGP routing. In addition to the problems of route oscillation and slow convergence, BGP has been shown to be susceptible to malicious attacks. Despite the wide range of proposed solutions to BGP's security vulnerabilities, there is currently a lack of a set of common tools for researchers to analyze, compare, and contrast the effectiveness of various schemes.<br\/><br\/>The goal of this project is to develop a unifying framework towards the design, analysis and implementation of provably secure Internet routing protocols. The first part of the project explores the use of Secure Network Datalog (SeNDlog), a declarative networking language for encoding secure Internet routing protocols. Language extensions to SeNDLog will be explored, in order to address practical deployments issues at Internet-scale, and facilitate formal analysis of a range of secure routing protocols. These extensions include customizable authentication, goal-oriented evaluation, key distribution and management, and modeling of adversaries. The second part of this project aims to identify security properties of Internet routing protocols, and formally specify them logically in terms of protocol execution traces. The third part of this project aims to design and implement a formal analysis methodology towards verifying SeNDlog programs for desired security properties specified in logic.<br\/><br\/>In terms of broader impact, this project will result a cleaner foundation towards the analysis and development of trustworthy routing protocols.","title":"TC: Small: Collaborative Research: Towards a Formal Framework for Analyzing and Implementing Secure Routing Protocols","awardID":"1117052","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["518109"],"PO":["565327"]},"180445":{"abstract":"Quantum information science has yielded deep theoretical insights into the nature of information and communication, while raising the hope of dramatically more capable computers and communication networks. But the achievement of these practical goals is hindered by the inherent fragility of quantum information. Traditional approaches for obtaining reliability through simple redundancy do not work; instead, fault tolerance must, and can, in principle, be obtained through subtler techniques that contrive to measure and correct errors without learning anything about the encoded data.<br\/><br\/>Unfortunately present methods for fault-tolerant quantum computation require significant overhead, and present understanding of quantum channel capacities remain very limited. For example, no quantum code is known on which arbitrary fault-tolerant quantum computation can be performed without leaving the code space. And only very recently was it discovered that classical information can be sent at rates exceeding the long-conjectured Holevo bound.<br\/><br\/>This project will attempt to develop new methods for reliable quantum communication and computation in the presence of noise. First, the research will push the capabilities and boundaries of quantum error-correction techniques, both by extending and delineating the types of correctable errors, and by determining the scenarios under which such error correction is or is not possible. The second goal is to develop the deep but heretofore largely unexplored connections between quantum codes, entanglement, and many-body physics, complexity theory, cryptography and high-dimensional geometry. The objective is to advance our understanding both of quantum codes as well as the related areas of mathematics, physics and computer science. Finally the team will seek to elucidate the subtle differences between quantum communication and its closest classical analog---private communication.<br\/><br\/>This research endeavors to contribute definitively to realistic embodiments of large-scale quantum computers, which would dramatically improve mankind's ability to process and communicate information. And the research program itself is deeply interdisciplinary, bringing together physicists, computer scientists and mathematicians from industry and academia, and training students and postdocs.","title":"AF: Large: Collaborative Research: Reliable Quantum Communication and Computation in the Presence of Noise","awardID":"1111382","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7281","name":"QUATM INFO & REVOLUTIONARY COM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["517581","499728",483594,"499728"],"PO":["565157"]},"181424":{"abstract":"With the increasing popularity of third-party services integrated in hybrid web applications, come new security challenges posed by the complexity in coordinating these individual services and the web client. Such complexity often brings in program logic flaws that can be exploited to induce inconsistencies among different services' internal states, causing the security control within these applications to fail. A preliminary study of this research investigated the security implications of the problem to online merchants that accept payments through third-party cashiers (e.g., PayPal, Amazon Payments and Google Checkout). It revealed stunning logic loopholes within leading merchant applications, popular online stores and a prestigious payment service provider, which can be exploited to purchase an item at an arbitrarily low price, shop for free after paying for one item, or even completely avoid payment. These findings point to a disturbing lack of understanding of the logic flaws within the integrations of web services, and an urgent need for significant research efforts on this important problem. <br\/><br\/>This project endeavors to gain an in-depth understanding about the scope and the magnitude of the security threat posed by the logic flaws in hybrid web applications and the common design pitfalls that lead to such vulnerability. Based upon this understanding, it will study novel technologies to facilitate detection and patching of these flaws when developing merchant software, security analysis of other parties' applications and black-box testing of merchant websites. New techniques will also be developed to enable web-service providers to better support secure integrations of their services into merchant systems, and to automatically detect the attempts to exploit these logic flaws in web transactions. This research involves industry collaborators and will also contribute to the improvement of security protection in other domains that utilize hybrid web applications.","title":"TC: Small: Plugging Logic Loopholes in Hybrid Web Applications to Secure Web Commerce","awardID":"1117106","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[486098],"PO":["564388"]},"181545":{"abstract":"Crystallographic lattices are nature's way to partition space into uniform cells with high symmetry. The equilateral triangulation of the plane, the face-centered and the body-centered cubic lattice in 3D and the lattice based on the 24-cell in 4D, all partition space more isotropically than the commonly-used Cartesian grid. Higher isotropy means higher efficiency, in that sparser data allows reproducing the same functions as data on the Cartesian grid. To take advantage of this increased efficiency, for material, medical, biological and even algebraic computations, we need to explore and make practically accessible multi-variate `crystallographic' splines that honor the structure of the crystallographic lattices. <br\/><br\/>With emphasis on dimensions 3 through 8, where the number of spline coefficients is still manageable, this research seeks to derive efficient analogues of the computational tools, data structures and algorithms that are currently available only for tensor-product splines on Cartesian grids. This includes algorithms and data structures to support quasi-interpolation for reconstruction, evaluation of functionals, refinement and adaptive subdivision, multi-resolution in the presence of singularities, conversion to localized polynomial form, and treatment of structural singularities. As proof of concept and extensions in their own right, these tools will be tested on multi-variate algebraic real-root finding, error-bounded approximation of level-sets, generalized subdivision and the computational formulation of partial differential equations.<br\/><br\/>Dissemination of the underlying theory, algorithms and coded examples will lower the barrier for the use of crystallographic splines and thereby enable more efficient computing for simulation and modeling. Progress in real root finding will benefit applications from geometric constraint solving to charting molecular conformation spaces. Finite elements based on crystallographic splines will honor boundary data when solving differential equations on crystallographic lattices. The impressive structure of crystallographic lattices <br\/>will engage undergraduate and graduate students in digital arts and computer graphics classes; and videos of volumetric fly-throughs and projections from higher dimensions will make this research accessible to the wider public.","title":"AF: Small: Splines on Optimal Crystallographic Lattices","awardID":"1117695","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[486405],"PO":["565251"]},"181314":{"abstract":"The project's main objective is devising a means to meet the challenge of excessive alcohol use by college students. The transition to the first year of college, in particular, is a critical age and life period when health and wellbeing are put to the test by the convergence of opportunity and peer pressure to drink heavily. Specifically, the project hypothesizes that adding the opportunity for role play in a web-based required online alcohol prevention program will improve the results compared to the web-based program only in a secondary prevention trial. All participants receive the standard alcohol prevention program required at the University of Central Florida (UCF), AlcoholEdu. Half of the randomly assigned participants have the opportunity to practice cognitive-behavioral skills through role plays. These immersive practice sessions are realistic in presenting situations that college students face in the real world. Armed with these skills and practice it is expected they will engage in less excessive alcohol use than those participants lacking this experience.<br\/><br\/>A unique aspect of the proposed treatment is the use of a state-of-the-art interactive role play experience based on digital puppetry of virtual characters. Here, digital puppetry refers to the use of a human to control the actions of animated characters in real-time. Such artistry has been employed for several decades in a number of venues including television and location-based entertainment. Digital puppetry is currently employed by one of the PIs in education and peer-pressure resistance programs. By affording natural and highly versatile behaviors, puppetry greatly increases interactivity and immersion while affording flexibility in the appearance and traits of the characters and choices for the interactive scenes.<br\/><br\/>An evaluation of this type of alcohol secondary prevention technique with college students is an advance in the field. Specifically, it allows the investigation of whether one-on-one virtual role-plays (e.g., a party scene in which college students can practice refusing to join a drinking game) can help students avoid difficult peer pressure situations. It could provide a new method to enhance and complement the programs currently used for alcohol secondary prevention.","title":"SHB: Small: Collaborative Research: Reducing Alcohol Use Among College Students Using Virtual Role Playing","awardID":"1116615","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["513513"],"PO":["549626"]},"181435":{"abstract":"Over the past decade or more, microprocessors have faced increasing challenges in achieving high-performance for current and emerging software applications while abiding by severe power and thermal limits. In response, industry has turned to approaches that use specialized graphics and computational hardware and complex memory organizations. The end result is that computer systems have become more heterogeneous and complex, in ways that make it difficult for programmers to write efficient and high-performance software. Software tuned to run on one implementation will often not run at all or will perform poorly or unpredictably when ported to even a different implementation in the same chip family. <br\/><br\/>The objective of this research effort is to design and evaluate system and hardware support that tailors memory and data access\/movements to improve performance and power efficiency, while also easing the issues of programmability and of tuning software for individual chip characteristics.<br\/>The two key themes of this work are Shape Shifting and PubSub data abstractions. ShapeShifting refers to optimizations and hardware support structures that allow data to be transformed in layout, in order to support faster access, more efficient use of memory, and other attributes that improve power and performance. In some preliminary experiments, even a software-only implementation of Shape Shifting improves performance by 15%. Pub Sub data abstractions offer methods for individual processors to indicate interest (or disinterest) in updates regarding other program variables. These abstractions form the underpinning for memory optimizations that are tailored to the application?s memory usage patterns. By mitigating false sharing, encouraging coarse-grained fetches, and reducing coherence broadcasts to uninterested cores, PubSub has the potential to improve the power and performance efficiency of multi-core implementations by a factor of 2X or more.<br\/><br\/>The research program is targeting several types of broad impact. First, the simulators and tools developed by this project will be released as free, open-source software. Second, the results can enhance performance and energy efficiency of future parallel hardware. Energy-efficiency is of particular concern from a national economic and strategic standpoint, given the growing electricity consumption of computer systems and the important role of the memory hierarchy in influencing computer power consumption.","title":"SHF: Small: Collaborative Research: ShapeShifting and PubSub for Tailoring Memory Accesses and Communication in Heterogeneous Multiprocessors","awardID":"1117147","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["495323"],"PO":["366560"]},"182766":{"abstract":"This research project is investigating how networked technologies can generate excitement and expertise development among middle school students learning to become citizen scientists. The investigators are partnering with \"Vital Signs,\" a citizen science networked system located in the State of Maine, linked statewide to schools and accessible not only to the focal participants (teachers and students in seventh and eighth grade classrooms), but to anyone who wants to learn and contribute. Outcomes of this project include 1) a set of case studies of learners and teachers that that represent pathways of engagement that utilize cyberlearning enabled resources; 2) a set of recommendations about new learning resources and tools that can advance personalized learning for students, teachers, and other learners; and 3) a set of ideas about ways to automate the assessment of uploaded data from learners that can be linked to recommendations about resources that can advance learning.<br\/><br\/>\"Vital Signs\" has high potential to generate excitement, interest, and a desire to learn about the natural world by engaging learners directly in observing, documenting, and sharing information about real world phenomena, specifically participating in learning activities designed around scientific issues in their local communities using authentic tools and collaborating with scientists. The Vital Signs program engages teachers and students in seventh and eighth grade science classrooms in inquiry-based science education around activities designed to study and intervene in habitat invasion by non-native species. The STEM content they focus on includes understanding of ecologies, processes of species proliferation, and strategies for intervening in damaged ecosystems. The state of Maine serves a diverse group of learners. Across the state, though average indicators of socio-economic status (home income, poverty level, school lunch qualification, English as a second language, and level of adult education) are close to national averages, there are regional differences. The highest poverty rates in Maine are routinely found in the counties on the west, north, and east borders of the state, where in 2008 rates of child poverty ranged from 24-28%, while in more affluent counties, they were less than half of that. Because all middle school students are involved in the laptop program, this research is able to compare cyberlearning processes and outcomes in relation to economic profiles of communities. Further, the statewide laptop program is unique in the United States and it creates a powerful opportunity to understand how communities who vary in their economic profile, sources of livelihood and technological immersion choose to engage in cyberlearning and what barriers they face.","title":"EXP: Developing Citizen Scientists Through Face-to-Face and Networked Learning Opportunities","awardID":"1124568","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":["527102"],"PO":["562669"]},"181204":{"abstract":"Transitioning an infrastructure of the size of the Internet to a newer technology is no small feat. We are in the midst of such a transition, i.e., from the Internet Protocol version 4 (IPv4) to its version 6 (IPv6). IPv6 was standardized 15 years ago, but until recently there were few incentives to adopt it. The recent allocation of the last large block of IPv4 addresses changed that, and migrating to an IPv6 Internet has become more urgent. This migration is, however, still rife with uncertainties and challenges, and our ability to overcome them can play a major role in both the duration and the cost of a transition that many view as vital to the continued growth of the Internet. In this context, the goals of this research are two-fold. <br\/><br\/>First, it seeks to provide insight into some of the obstacles that the Internet's transition to IPv6 still faces, and propose possible remedies. The intent is to identify where major roadblocks remain, so as to focus efforts on eliminating them. In particular, the impact of IPv6 connectivity quality on the decisions of content providers, i.e., the likes of Google, YouTube, Yahoo, Hulu, etc., to become directly accessible over IPv6 is critical to a viable IPv6 Internet. Delays in those decisions will not only extend the duration of the transition to an IPv6 Internet, it will make it much more onerous because of the need for expensive gateways. As a result, ensuring that there is no or as few as possible obstacles to adopting IPv6 is of critical importance to the future of the Internet. To realize this goal, the project follows a two-prong approach. The first relies on an extensive set of measurements for characterizing IPv6 adoption across the Internet; in particular in as much as it relates to access to content. The second involves analyzing these measurement data to extract common attributes that contribute to differences in performance between IPv4 and IPv6. Identifying those common attributes will help pinpoint causes of poorer IPv6 performance, when present. Hence, enabling remedies to foster a more complete and more rapid adoption of IPv6.<br\/><br\/>The second goal of this research is to develop 'models' that can help us better understand and eventually plan future Internet migrations to newer technologies. Those models seek to connect the adoption of a new network technology to the benefits and costs of adopting it, while accounting for the effect of an often dominant incumbent technology. The models that will be investigated rely on methodologies from marketing science and economy, but a key aspect of the research will be to validate those models using the measurement data obtained in the first part of the project. The validation will, therefore, be cast in the context of a migration to IPv6, but the results should have implications for future migrations, including migrations to technologies that offer new and additional capabilities not available from current Internet versions, be they IPv4 or IPv6.<br\/><br\/>The broader impact of the project is along two fronts. Ensuring that the Internet's migration to its newer version, IPv6, proceeds smoothly can have a significant societal and economical impact. It can facilitate a faster integration of the many devices that are now becoming Internet enabled, and that in the process are fueling the growing need for new Internet addresses, and therefore IPv6. This 'Internet of Things' extends to devices like cars, smart utility meters, sensors monitoring the health of bridges, water supply, etc., that all have a tremendous potential for a safer and cleaner environment. Realizing this potential is, however, heavily depend on a successful migration to IPv6; something that the project hopes to facilitate. Additionally, the development of models to better understand the forces that shape migrations to newer network technologies represents an instance of multi-disciplinary research whose success can foster further collaboration and interactions across disciplines. It can also help train doctoral students better equipped to tackle modern research problems.","title":"NeTS: Small: Exploring the Challenges of Network Migration - An IPv6 Case Study and its Consequences","awardID":"1116039","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564485"],"PO":["565090"]},"181325":{"abstract":"Ambulatory health monitoring has been demonstrated to provide significant benefits to patients in a number of studies. The biggest promise for improved results for patients lies in the long-term, ambulatory monitoring of patients with chronic illnesses to help doctors and patients identify health issues before they reach a crisis stage. This project pursues the design of garments for ambulatory health monitoring that have the look and feel of every day clothing, together with an approach to monitoring that removes some of the barriers to patient compliance by automatically annotating physiological data with activities and motions, collecting data only during specific conditions, and having minimal impact on daily routine. The intellectual merits lie in the algorithms, design methodologies, and evaluation methodologies that enable wear-and-forget garments for ambulatory health monitoring. The approach developed by this project uses a computationally intensive pose estimation algorithm that automatically adapts a more computationally efficient algorithm for activity classification. This project addresses the challenges of providing garments that look and feel like everyday clothing by developing design and evaluation methodologies for incorporating fiber-based sensors into garments. These have significant advantages over discrete sensors by being woven or sewn into the fabric, covering much larger areas of a garment, and draping naturally. The broader impacts of the research lie in the potential to remove barriers that prevent the effective use of ambulatory health monitoring to improve the quality of life for patients and their families.","title":"SHB: Small: Collaborative Research: Electronic Textiles for Ambulatory Health Monitoring","awardID":"1116669","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[485861,"553340"],"PO":["564768"]},"181567":{"abstract":"Maintaining high parallelism is critical for efficient use of multicore- and cluster-based parallel systems, but this can be at odds with I\/O efficiency, resulting in suboptimal performance of I\/O-intensive parallel applications. The efficiency of request-processing policies at different levels of the I\/O stack relies on the locality of requests from various processes. Processes are the producers of I\/O requests, and their scheduling determines the timing of request issuance and the locality among requests from different processes. When a program is I\/O bottlenecked the scheduling of its processes directly affects the storage system?s efficiency, and thus the program?s execution time. In such scenarios, a scheduling policy designed to improve request locality, in preference to the usual objectives such as load balance and fairness, is expected to improve the overall efficiency of the I\/O stack and ameliorate I\/O bottlenecks.<br\/><br\/>The investigator proposes a dual-mode execution, incorporating a new data-driven mode to complement the normal statement-driven mode. In the data-driven mode processes are scheduled such that they will issue requests with improved locality, and will consume data that has been efficiently pre-fetched. The research focus of this 12-month project is the investigation and understanding of the extent to which process scheduling can positively affect I\/O performance. It takes into account variance of I\/O intensity, I\/O access pattern of individual processes, and the ratio of reads and writes. The investigator will perform an extensive examination of I\/O performance behaviors at different I\/O layers, including the I\/O library, system buffer, and I\/O scheduler, with various hypothetical I\/O-aware process scheduling strategies. This research will reveal the potential merits of the proposed dual-mode execution, and delineate the design space for algorithms supporting it. It will also identify pitfalls and limits of potential designs and their implementations. By so doing, this project is expected to pave the road to the introduction of a disruptive technique for mitigating I\/O bottlenecks.","title":"CSR: Small: Enabling Dual-mode Execution for Removing I\/O Bottleneck: A Highly Applicable Design and Implementation","awardID":"1117772","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518050"],"PO":["551712"]},"180357":{"abstract":"This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br\/><br\/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br\/><br\/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists \"in the loop\" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http:\/\/www.scidb.org\/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http:\/\/database.cs.brown.edu\/projects\/scidb).","title":"III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","awardID":"1110948","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["533271"],"PO":["563751"]},"186902":{"abstract":"This NSF collaboration project investigates the design and optimization of dynamic resource allocation and interference management strategies for spectrally efficient wireless heterogeneous networks that provide multi-level coverage and services. This research project is motivated by the recent advances in 4G wireless systems on the deployment and standardization of heterogeneous networks (HetNet). Such networks provide services to mobile subscribers of different priorities and dynamic quality needs. As more and more advanced physical layer schemes and medium access protocols are being integrated into wireless standards, future performance gain and progress in wireless networks have to rely more on intelligent resource allocation and interference management strategies that are dynamical and are adaptively responsive to location-and-time specific environment. In this project, the research team will address critical deployment issues that arise in HetNet by focusing on the development of distributed and effective mechanisms for resource allocation and interference management in order to facilitate low complexity and decentralized network operation in heterogeneous environments. The project methodology is based on novel optimization frameworks for interference control and suppression in HetNet. The research goal is to develop robust and reliable solutions for practical implementations of HetNet. The project results will facilitate novel technological directions that transcend multiple networks and multiple network layers. In particular, the results will assist the near term deployment of wireless HetNet, including the broad application of femtocell deployment. <br\/><br\/>The technical impacts of this international collaboration project are broad both domestically and internationally. Results from successful execution of the project are expected to significantly impact the design, deployment, and operation of future wireless networks. The plan to disseminating research findings at quality journals and technical conferences will contribute directly to the wireless industry by providing critical information on interference control and management for high spectral efficiency and user satisfaction. The project outcomes can also establish new research directions for the international telecommunications community. The project activities will lead to new analytical tools and discoveries that can impact other science and engineering research fields. The project will further contribute to the training of highly qualified personnel for the hi-tech industry.","title":"Distributed Resource Allocation and Interference Management for Dense Heterogeneous Wireless Networks","awardID":"1147930","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["436918","551148"],"PO":["557315"]},"180489":{"abstract":"This collaborative research investigates a new class of dialog-based, home robotic healthcare assistants to facilitate a new level of in-home, real-time care to elderly and depressed patients, providing lower total costs and higher quality of life. An emotive, physical avatar, called a companionbot, which possesses the ability to engage humans in a way that is unobtrusive and suspends disbelief will be built in this project. The companionbot will be an integration of human language technology, vision, other sensory processing and emotive robotic technology to proactively recognize and dialog with isolated and elderly patients suffering from depression. The companionbot will utilize proactive or companionable dialog based on the context with users suffering from depression. This will require the first multimodal integration of a user model, environment model, and temporal processing with spoken dialog understanding and generation to produce dynamic dialog and emotive interaction, beyond the traditional scripted dialog and emotion. Object recognition, facial expression recognition, and human activity recognition will augment natural language processing to provide current and historical context important to dynamic dialog. <br\/><br\/>A team of skilled researchers, assembled from the University of Colorado Boulder, University of Denver, CU Anschutz Medical Campus, and Boulder Language Technologies, will work together to achieve the project goals. The investigators will use the companionbots as a tool to run clinical trials to monitor and dialog with their partners to detect signs of physical and emotional deterioration. The companionbots can then notify remote caregivers, as necessary, provide warnings, reminders, life coaching and therapeutic dialog, extending independence and quality of life, and even saving lives. The other benefits of such a system include continuous, annotated data to improve doctor-patient interaction and analysis, real-time monitoring of mental state for remote healthcare providers and, ultimately, real-time intervention as part of a comprehensive treatment strategy.<br\/><br\/>In addition, this research will promote both STEM practice and research education at the graduate and the undergraduate levels of the affiliated institutions. The companionbots are ideal for teaching the next generation of engineers and scientists in critical emerging technologies, as they permit either a deep focus on specific topics or an interdisciplinary perspective while providing a simple high-level interface to manage everything else. Furthermore, the project will develop related educational material to support others and will provide public outreach to K-12 classes in the area.","title":"SHB: Large: Collaborative Research: Companionbots for Proactive Therapeutic Dialog on Depression","awardID":"1111544","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["551123",483710],"PO":["565136"]},"181347":{"abstract":"This project uses statistical models and human judgment to determine dynamic, probabilistic representations of extensible usages of words; these representations are suitable for incorporation into VerbNet, a lexical resource widely used in the Natural Language Processing (NLP) community. Existing lexical resources reflect a binary notion of usages as grammatical or not. However, in actual language use, forms vary in acceptability; moreover, the process of coercion extends words beyond their standard usages. For example, a strictly intransitive action verb such as 'sneeze' may be used as in 'She sneezed the foam off the cappuccino', expressing manner of motion. This research has a two-pronged approach involving extensive use of machine learning and a fundamental shift in the development and use of VerbNet. Specifically, the research develops probabilistic methods for: (1) analyzing usages of verbs in large corpora and incorporating the resulting probabilistic information into VerbNet classes; and (2) representing information about the likelihood of potential constructional coercions and the productivity of such extensions. These developments use the Hierarchical Bayesian Model of Parisien and Stevenson, which are an ideal framework for marrying probabilistic reasoning about complex, real-world data within the hierarchically-organized VerbNet lexicon. In addition to statistical models, the representations are also informed by human judgments with respect to the use of such constructions. Thus, this research enriches the current symbolic verb representations in VerbNet with probabilistic distributional information, which becomes salient through the influence of construction grammar. <br\/><br\/>Encoding verb knowledge probabilistically provides the necessary flexibility to represent extensional constructions and support their appropriate interpretation by NLP systems. This is especially useful for interpretation in new domains and genres, leading to advances in NLP technologies, such as question answering and machine translation, thus improving information access. Additionally, insights into statistical properties of constructions gained through this research are valuable for psycholinguistic models of language acquisition and second language learning.","title":"RI: Small: A Bayesian Approach to Dynamic Lexical Resources for Flexible Language Processing","awardID":"1116782","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["511542"],"PO":["565215"]},"182678":{"abstract":"Continuing increases in computer power have led to significant advances in iteractive software-development environments (IDEs) that aim to help programmers plan, write, test, and fix programs efficiently. Learning management systems (LMSs), which make available learning resources and activities, have similarly evolved to support good pedagogical practice, such as collaborative work and embedded assessments, over the entire course of a discipline. This project is investigating practices for linking an LMS to an IDE in ways that will enable computer instructors to better support their students' learning. It is expected that this investigation, aimed at undergraduate and advanced high-school students, will result in better learning not only of computing concepts but of programming practices required for designing and implementing sophisticated software. Research and evaluation activities are aimed at investigating student learning and engagement and the ways that teachers change their practice in supporting students. The project findings, along with the tools and packaged curricular activities, are to be widely disseminated to technical and educational communities through professional meetings and online repositories. While the integrated software environment and guidelines about effective use for promoting learning will be broadly useful for computer science education, it is expected that this effort will also provide more general guidelines about integrating learning management systems with productivity-support systems in other domains and disciplines.<br\/><br\/>New curricular activities enabled by this integration, along with the increased support and feedback that students will receive from both instructors and classmates, are expected to provide valuable support to all students learning computing and software engineering but especially to students who are traditionally underrepresented in computing courses or who might otherwise drop out. Results of research will inform design of software systems that integrate learning-management systems with productivity-support systems to allow students across a variety of disciplines better gain insight into the big challenges of the disciplinary practice, better gain practice addressing those types of challenges, and better gain knowledge and skills needed to address those challenges.","title":"EXP: Enabling Pedagogical Communication Between Learning and Programming Environments","awardID":"1124087","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":[489422],"PO":["562669"]},"181237":{"abstract":"Algorithms for Reconstructing Complex Evolutionary History with Discordant Phylogenetic Trees<br\/><br\/>PI: Yufeng Wu, University of Connecticut<br\/><br\/>Many important computational formulations in biological data analysis are inherently intractable. Many existing computational approaches are either too slow or not able to grasp biological complexity needed for more faithful modeling of the underlying biology. In the meantime, the size of biological data is growing rapidly. Therefore, currently there is a need to develop more efficient and accurate algorithms for analyzing large amount of data and solving more complex computational formulations. The study of the complex evolutionary history of species and populations is the main theme of this project. Evolutionary history is often modeled by phylogenetic tree, the so-called ?tree of life?, which has been studied extensively. Recently, a more complex model, phylogenetic network, has been proposed and studied to accommodate various evolutionary processes, including horizontal gene transfer, recombination and hybrid speciation. As a generalization of the phylogenetic tree model, phylogenetic network is a directed graph with nodes with two or more parents (in addition to nodes with a single parent as in the tree model). There are also other less studied computational formulations for a complex evolutionary process called incomplete lineage sorting. Roughly speaking, incomplete lineage sorting causes discordance of evolutionary histories in different parts of genomes. This can greatly complicate phylogenetic study.<br\/><br\/>This project is focused on developing new algorithms for hard optimization problems arising in reconstructing complex evolutionary histories, such as those modeled by phylogenetic networks. These algorithms consider multiple discordant phylogenetic trees, which model the evolutionary histories of different genomic regions. This project will develop algorithms to compare two or more correlated phylogenetic trees and infer the plausible phylogenetic networks that explain the given trees. Although this formulation is generally intractable, this project will develop practical algorithms that can give optimal solutions for data within certain range. One approach to be taken in this project is finding efficiently computable close lower and upper bounds of optimal solutions. This may help to quantify the range of solutions when the optimal solutions are difficult to compute directly. This project will also explore related computational problems arising in the study of incomplete lineage sorting. The expected project outcome will include efficient algorithms for the above computational problems, related open-source software tools that are readily usable by biologists, and rigorous methodologies for both theoretical and empirical evaluation of the algorithms. <br\/><br\/>Developed software tools will be made available freely to the multi-disciplinary research community, and are expected to enable novel biological applications in studying complex evolution. Research results will be integrated into classroom teaching. The proposed educational and outreach activities include reaching out to students with various backgrounds, and training of future researchers with interdisciplinary skills.","title":"AF: Small: Algorithms for Reconstructing Complex Evolutionary History with Discordant Phylogenetic Trees","awardID":"1116175","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[485645],"PO":["565223"]},"181479":{"abstract":"The objective of the proposed research is to systematically understand, evaluate and contribute towards the problem of membership inference in aggregate data publishing, a generic, novel, and dangerous privacy threat in a wide variety of real-world applications. The main idea proposed to address the problem of membership inference is an information-theoretic model of privacy disclosure as a noisy communication channel. Based on the channel coding theory and the recent advance in multi-input multi-output (MIMO) communication channels, the proposed research studies novel techniques for membership inference and explores the corresponding privacy-preserving mechanisms.<br\/><br\/>Intellectual Merit: The following salient features distinguish the proposed work from existing studies: (1) the proposed research studies a novel problem of membership inference in aggregate data publishing which stands in sharp contrast to the traditional inference control problem. In particular, the sensitive information in danger of disclosure in the proposed problem definition is the selection attributes of an aggregate query instead of its measure attributes which is the focus on traditional inference control. (2) This novel problem also leads to a set of novel solutions based on information theory. In particular, the propose research studies a model of membership inference attacks as modulation techniques in time and frequency domains for various types of communication channels, e.g., single-input single-output (SISO), multiple-input and single-output (MISO), single-input and multiple-output (SIMO), and multiple-input and multiple-output (MIMO) channels. This proposed channel model enables a uniform evaluation of the effectiveness of both membership inference and privacy-preserving techniques.<br\/><br\/>Broader Impact: The outcome of this research has broader impacts on the nation's higher education system and high-tech industries. The prospect of sensitive membership information disclosure techniques and privacy-preserving techniques can help the providers of aggregated data publishing, including national health organizations, Internet security service providers, etc., to secure their published data. The broader impact of this project also extends to academia. Parts of this project is carried out by students of George Washington University (GWU), Towson University (TU), and University of Massachusetts, Lowell (UML) as part of advanced class projects or individual research projects.","title":"TC: Small: Collaborative Research: Membership Inference in a Differentially Private World and Beyond","awardID":"1117297","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560587","464575"],"PO":["562974"]},"181248":{"abstract":"This research effort is developing new electronic devices and mapping software to improve the speed, power-efficiency, and cost of digital electronics. They start with the concept of the Field-Programmable Gate Array (FPGA), logic chips that can be programmed and reprogrammed to implement complex digital circuits. FPGAs are an important driver for the semiconductor industry, reaching almost $3B in annual worldwide sales. Current FPGAs are essentially seas of 1-bit compute units, each configured to do one function over and over. To support more complex operations modern devices have a sprinkling of more complex units, including multipliers and memories, which have a more multi-bit flavor. All the components of these devices are interconnected via a static, single-bit routing network, and are primarily programmed in hardware description languages such as Verilog or VHDL. An FPGA single-bit programmability provides a great deal of flexibility for creating arbitrary logic, but has significant inefficiencies as well.<br\/>Word-based architectures, that compute and route multi-bit values simultaneously, can be much more efficient than standard FPGAs. Word-based alternatives to FPGAs exist, such as CGRAs and MPPAs, but limitations in their control systems significantly reduce their quality and usefulness for many applications.<br\/>One of the major thrusts of this work is to merge together the customizable logic of FPGAs with the time-multiplexing ability of MPPAs and CGRAs, as well as the complex control flow supported by modern multi-core CPUs. Unlike a standard FPGA, that statically configures all of its resources to do a single task, this system allows each compute element in the device to run a small program. This provides a significantly greater compute density in these devices. However, to boost this even further, they are exploring mechanisms to make use of branching and conditional operation. Specifically, where a microprocessor might take a branch based upon a loop condition or as part of an if-then-else construct, their hardware system can either change the instructions loaded during that cycle, or branch to a different portion of the overall operation. However, unlike MPPAs and CGRAs, their system can perform data-dependent instruction selection within a large, automatically mapped computation region operating in lock-step. Alternatively, for control-heavy portions of a computation they can embed complete, simple VLIW processors into the fabric of their system.<br\/>To support these efforts, they are developing new compilation strategies to convert computations into efficient implementations on these architectures. They are also looking at the hardware resources required to support these operations. This includes methods for stalling portions of the array when their communication demands temporarily cannot be met, as well as mechanisms to synchronize the program counters of regions of the array operating in lock-step.<br\/>When combined, they estimate these systems will provide an order of magnitude improvement in area-power product, and at least a factor of 2 performance improvement, over FPGAs. The resulting hardware and software systems should be able to significantly reduce the power consumption, lower the cost, and increase the speed of a large swath of electronic systems. Also, their improved programming models will make these systems easier to develop and maintain.<br\/>This effort also includes a focus on improving the diversity of the engineering workforce at both the graduate and undergraduate level, with mentoring and research opportunities at each level. All of these activities are done within an overall effort towards outreach to underrepresented groups.","title":"SHF: Small: CGRAs - Control and Architecture for Next-Generation FPGAs","awardID":"1116248","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[485670,485671],"PO":["366560"]},"182579":{"abstract":"This project is exploring possibilities in promoting learning activities among urban families in the informal setting of their homes. The investigation is in the context of energy management. The PIs are building a tablet-based simulation and supporting resource materials that are being integrated with smart programmable thermostats in the homes of participating families. The software is designed to promote curiosity about scientific issues related to home energy management. The PIs are following the ensuing interactions of the family -- their discussions with each other and their interactions (individual and joint) around the thermostat and the tablet-based software -- to understand family behavior around energy management and the opportunities for promoting learning activities, the challenges and possibilities of promoting science learning around energy management as a family activity, how to design software for family education around energy management and the ensuing learning, and what the implications are for promoting family education in other disciplinary domains. <br\/><br\/>Informal learning, especially learning that happens outside of formal institutions, is understudied. But learning happens regularly in the everyday contexts in which people live. Understanding better the possibilities for more systematically promoting learning in such environments will open up new ways of helping people of all ages learn science relevant to their lives and come to appreciate the role science plays in the world around us. Focusing the effort specifically on energy management issues may also lead to more sustainable energy use behaviors and greater understanding of local and global energy and climate challenges, opening the way for more of the citizenry to be informed about and become involved in policy considerations and debates.","title":"EXP: Augmenting Household Technologies for Learning and Whole Family Participation: Heating and Cooling Control as an Exploratory Case","awardID":"1123574","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":["562575","496807"],"PO":["562669"]},"181369":{"abstract":"Wireless communication has become an intrinsic part of modern implantable medical devices (IMDs). Recent work, however, has demonstrated that wireless connectivity can be exploited to compromise the confidentiality of IMDs' transmitted data or to send unauthorized commands to IMDs. The key challenge in addressing these attacks stems from the difficulty of modifying or replacing already-implanted IMD.<br\/><br\/>This research explores the feasibility of protecting an implantable device from such attacks without modifying the device itself. It develops a solution that delegates the security of an IMD to a personal base station called the shield. The shield introduces a novel radio design that allows it to jam the IMD's messages, preventing others from decoding them while being able to decode them itself. It can also jam unauthorized commands --even those that try to alter the shield's own transmissions. <br\/><br\/>The research delivers a novel full-duplex radio design that, in contrast to past work, has no requirements on antenna separation and hence can be built into a wearable device. It also delivers the first non-invasive security mechanism for securing IMDs? communications without modifying them. Finally, it increases the resilience of wireless medical devices to jamming attacks, bad channel conditions, and interference.<br\/><br\/>By enabling medical devices to leverage wireless communication without incurring security risks, the research can improve the quality of life for patients and reduce the cost of healthcare systems. The broader impact plan also includes academic publications, integration in educational programs, and working with the medical device industry.","title":"NeTS: Small: Encryption on the Air: Non-Invasive Security for Wireless Medical Devices","awardID":"1116864","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560189"],"PO":["565303"]},"185747":{"abstract":"There is important need for a synergistic combination of (i) software development that provides rapid development of the experimental DNA nanosystems and (ii) experiments of novel DNA nanosystems, which will guide and provide feedback to the software development efforts. The project will develop software that will provide an integrated design\/specification\/simulation\/optimization environment for designing molecular devices that self-assemble as DNA nanostructures and change state in reaction to their environment, based on a programmable series of hybridization reactions. The integrated methodology will include a molecular programming language that allows high-level specification of states of DNA nanostructures and their state-transitions (involving key hybridization and strand displacement reactions), without fully specifying underlying strand sequences or nanostructures, and provide a WYSIWYG (visual) method for input. A molecular compiler will compile the molecular program into a detailed specification of component DNA stands and hybridization reactions. A thermodynamic and kinetic simulator will calculate equilibrium densities of assembled nanostructures and key kinetic reaction properties; speeding its computations by novel use of decompositions of the strands into component subsequence domains and tensor product decompositions of the state space. Specification (sequence domain-level) and sequence compilation tools will be integrated with thermodynamic and kinetic simulators, so simulations can be done at sequence-domain level, rather than base-pair level, resulting in considerable speedups. A novel experiment design subsystem will give suggested design of experimental demonstrations for verifying assembly of the intended nanostructures, and key reaction steps. Support by the EAGER program will allow a two-year early development phase to test and demonstrate novel concepts and designs. <br\/><br\/>Educational Objectives include cross-disciplinary training of graduate students, carefully supervised mentoring for undergraduates, and summer internships for high school students and teachers. There is substantial multidisciplinary impact to nanoscience, biochemistry and chemistry, which will profit from the introduction of key methodologies derived from mainstream computer science, such as programming languages and compilers, and compiler optimization, particularly since these will be highly specialized and tailored for the specific needs of DNA nanostructures and hybridization reactions. The integration of a molecular programming language, with a molecular compiler, and simulator, with feedback to provide optimization will provide unique enhanced design capabilities for these science disciplines. To maximize impact and use of this software, there is a planned staged external distribution of prototype software system that will incorporate feedback from users.","title":"EAGER: Exploratory Software Development & Experiments of Dynamic DNA Nanosystems","awardID":"1141847","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["550822"],"PO":["565223"]},"183019":{"abstract":"Proposal #: 11-26120<br\/>PI(s): El-Araby, Esam; Chang, Lin-Ching; Kilic, Ozlem<br\/>Institution: Catholic University of America (CUA)<br\/>Title: MRI\/Acq.: High Performance Instrument for Heterogeneous and Biologically Inspired Architectures Research <br\/>Project Proposed:<br\/>This project, acquiring and integrating an SRC-7 system and a GPU cluster into one High Performance Heterogeneous Computing instrument, aims to investigate, model, design, and potentially prototype new heterogeneous architectures that are inspired from biology. The instrument will contribute to expand some of the available hardware accelerators such as reconfigurable Field Programmable Gate Arrays (FPGAs) and graphical (GPGPU) processors currently utilized for research in the fields of high-performance computing, computational neuroscience and medical informatics, and electromagnetic and remote sensing. It will facilitate research towards designing\/discovering new heterogeneous architectures that are easy-to-use and highly productive. Moreover, the instrument will also allow investigating the use of new processor technologies through interdisciplinary collaborations with other research groups inside and outside the institution. In computational neuroscience and medical informatics, the high-performance cluster (HPC) will help in designing and developing new computational methods to process and analyze medical imaging data such as diffusion tensor magnetic imaging (DT-MRI). Although DT-MRI is used increasingly in clinical research for its unique ability to depict white matter tracts and for its sensitivity to microstructural and architectural features of brain tissue, it suffers a number of image artifacts that can corrupt diffusion weighted images (DWIs) which in turn affect DTI derived quantities. Although ideal for parallel computation, the post-processing DT-MRI data is very difficult and time consuming. The new instrument will help test new post-processing algorithms, explore the limitations of the existing technology, and develop solutions. In electromagnetic and remote sensing applications, the new instrument will help enhance the computation times of the numerically intensive problems faced by the research community for commercial and military applications. Design and optimization of metamaterials, performance analysis and optimization of antennas on platforms, and target detection behind clutter (e.g., soil, foliage, fog) represent some examples of the latter.<br\/>Broader Impacts: <br\/>This instrumentation enables realistic computational problems that can integrate research and teaching as well as promote learning through discovery. Hence, it is expected to contribute in producing a new generation of students and postdocs with the ability to face the current changes in computing technology. Moreover, the instrument enables the creation of a new interdisciplinary HEterogenous and Biologically Inspired Architectures research lab (HEBA). The project includes an outreach program, open house events that include community colleges, high school, and middle school students, and K-12 teachers. Increasing women and minorities is also targeted. Results will be shared and disseminated.","title":"MRI: Acquisition of a High-Performance Instrument for Heterogeneous and Biologically Inspired Architectures Research at CUA","awardID":"1126120","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[490455,490456,490457],"PO":["543539"]},"181601":{"abstract":"One of the most critical challenges in todays nanoscale VLSI design is the lack of predictability in analysis and optimization. As VLSI technology continues scaling in the nanometer domain, VLSI systems are subject to increasingly significant parametric variations coming from not only the manufacturing process but also the system runtime environment. Increasingly significant parametric variations lead to increasingly significant variations in IC timing performance, power consumption, and other product metrics. Existing VLSI statistical analysis techniques cannot accurately and efficiently capture such variations; this greatly compromises design optimization and design convergence, affecting product quality and time-to market. In this work the PIs plan to develop techniques for signal probability-based statistical timing analysis (SPSTA), which would achieve accurate performance estimates for different inputs, rather than input-oblivious pessimistic delay bounds. In this project, the PIs propose to build on the foundation of SPSTA to enable a new, predictive and less-pessimistic VLSI implementation methodology. Core techniques will span VLSI statistical analysis, delay test ATPG, and optimization techniques that exploit improved predictability. Specifically, there are three thrust areas in this project, and it is expected that that these techniques will outperform existing alternative techniques. <br\/><br\/>The outcome of this project is critical to the cost-effective continuation of semiconductor technology scaling (i.e., Moore's Law), and to maintaining growth of the semiconductor industry's economic engine in the coming years. The broader impacts of the proposed project can be further measured by a strong education program including curriculum development and research training which incorporate statistical VLSI analysis and optimization techniques into the computer engineering programs at the PIs? institutions, and into course infrastructure that is broadly and openly available to others online. Following their established practices of well over a decade, the PIs will broadly disseminate their research results by publication, industry collaboration, and online posting of open-source software. This project will also allow the PIs to broaden participation of students from under-represented groups based on the minority institute status of UT San Antonio; it will help educational initiatives that are aimed at preparing the San Antonio regional economy to transform into a technology-oriented one.","title":"SHF: Small: Collaborative Research: VLSI Design Predictability Improvement By New Statistical Techniques in Timing Analysis, Delay ATPG, and Optimization","awardID":"1117975","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[486553],"PO":["562984"]},"181513":{"abstract":"With the wide adoption of smart phones and other mobile devices, cellular mobile data traffic has grown tremendously in the past few years. This rapid growth in cellular data traffic, coupled with the increasing demands for mobile data services, has exerted enormous competitive pressure on cellular network service providers. How to effectively manage a large-scale cellular data network is therefore a daunting challenge that is not only important to cellular network service providers, but also to mobile data users and emerging mobile applications and services. In this project, the PI sets out to develop a data-driven, statistical machine learning-based framework to identify, analyze and understand various challenging issues in cellular data networks, and develop mechanisms and tools for effectively managing and trouble-shooting constantly evolving cellular data networks. The PI leverages vast amounts of heterogeneous sources of data obtained from operational cellular data networks, and designs statistical inference techniques to analyze, mine and correlate various sources of real-world data to uncover and identify various key factors that contribute to network performance issues and affect user experiences.<br\/><br\/>This research project brings benefits not only to cellular service providers, but also to millions of users who are increasingly dependent on mobile voice and data services. It also provides valuable insights to inform further development of emerging mobile and cloud computing. Research outcomes will be disseminated through publications and outreach activities, as well as technology transfer.","title":"NeTS: Small: Understanding, Managing and Trouble-Shooting the Evolving Cellular Data Networks","awardID":"1117536","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543509"],"PO":["565303"]},"181403":{"abstract":"The rich information generated by computer and human networks creates exciting opportunities for network analytics, namely, the process of gaining knowledge and insights by mining a large amount of network data collected by a diverse set of monitors. To enable effective network analytics, several significant challenges must be addressed:<br\/>--- (i) Scalability. The enormous scale of computer and human networks makes it challenging to analyze massive network datasets in a scalable fashion. <br\/>--- (ii) Complexity. Real-world network datasets are complex and often violate the operational conditions of existing analysis techniques. <br\/>--- (iii) Robustness. Anomalies and imperfections are common in real-world network datasets. <br\/>--- (iv) Diversity. Network analytics often requires mining information from diverse data sources with different characteristics and data quality.<br\/><br\/>This research addresses the above challenges by developing a series of novel compressive sensing techniques to effectively exploit the presence of structure and redundancy in real-world network datasets, including:<br\/>--- (i) clustered spectral graph embedding, a novel technique for reducing a massive graph to a much smaller graph while preserving essential clustering and spectral information of the original graph,<br\/>--- (ii) LENS decomposition, a novel method for accurately decomposing a network data matrix into a Low-rank matrix, an Error term, a Noise matrix, and a Sparse matrix, and <br\/>--- (iii) multi-source spectral learning, a novel framework for effectively integrating information from diverse data sources. The research promises to significantly enhance the ability to analyze massive network datasets. <br\/>The resulting tools and techniques have potential applications in business, information technology, networking and cyber security. Finally, the research includes a significant education and training component. The research results will be integrated into both undergraduate and graduate curricula as well as outreach activities.","title":"CIF: Small: Compressive Network Analytics","awardID":"1117009","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["266247","560223"],"PO":["564924"]},"180435":{"abstract":"Quantum information science has yielded deep theoretical insights into the nature of information and communication, while raising the hope of dramatically more capable computers and communication networks. But the achievement of these practical goals is hindered by the inherent fragility of quantum information. Traditional approaches for obtaining reliability through simple redundancy do not work; instead, fault tolerance must, and can, in principle, be obtained through subtler techniques that contrive to measure and correct errors without learning anything about the encoded data. <br\/><br\/>Unfortunately present methods for fault-tolerant quantum computation require significant overhead, and present understanding of quantum channel capacities remain very limited. For example, no quantum code is known on which arbitrary fault-tolerant quantum computation can be performed without leaving the code space. And only very recently was it discovered that classical information can be sent at rates exceeding the long-conjectured Holevo bound. <br\/><br\/>This project will attempt to develop new methods for reliable quantum communication and computation in the presence of noise. First, the research will push the capabilities and boundaries of quantum error-correction techniques, both by extending and delineating the types of correctable errors, and by determining the scenarios under which such error correction is or is not possible. The second goal is to develop the deep but heretofore largely unexplored connections between quantum codes, entanglement, and many-body physics, complexity theory, cryptography and high-dimensional geometry. The objective is to advance our understanding both of quantum codes as well as the related areas of mathematics, physics and computer science. Finally the team will seek to elucidate the subtle differences between quantum communication and its closest classical analog---private communication. <br\/><br\/>This research endeavors to contribute definitively to realistic embodiments of large-scale quantum computers, which would dramatically improve mankind's ability to process and communicate information. And the research program itself is deeply interdisciplinary, bringing together physicists, computer scientists and mathematicians from industry and academia, and training students and postdocs.","title":"AF: Large: Collaborative Research: Reliable Quantum Communication and Computation in the Presence of Noise","awardID":"1111337","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[483569],"PO":["565157"]},"180556":{"abstract":"In this project, the researchers focus on the challenges of designing a real-time networked sensing and actuation platform for future 'intelligent' metropolitan traffic management with the aim of simultaneously reducing congestion, pollution, and traveler delays. Today, most urban traffic control is rudimentary: in smaller cities many traffic signals remain isolated, and while most larger cities have integrated systems of signals, they for the most part, are not dynamically timed in response to real-time vehicle information. Congestion fees, which are increasingly popular as a traffic management and revenue-generating tool, are usually based on historical traffic data rather than varying dynamically to reflect instantaneous conditions. Recent advances in communication, navigation, and sensor technologies present far more opportunities to increase the intelligence and efficiency of metropolitan streets than are in place today.<br\/><br\/>The pivotal element of the proposed Green City intelligent transport architecture will be the ability to 'close the loop' between traffic\/pollution sensing and traffic control; a system achieved through an incentivized collaboration between the central traffic management and the drivers. In this collaboration, the 'intelligent' traffic signals, the Navigator Server and the on-board navigators play key roles. In addition to the traditional control of vehicular flow at signalized intersections, future traffic signal systems will sense traffic characteristics and vehicular emissions, collect data from vehicle sensors (pollution, emission, position, etc.), and broadcast traffic advisories, routings, and restrictions to on-board navigators. The Navigator Server interacts with central traffic controllers, and proposes optimal routes to the on-board navigators. Finally, the on-board navigators, incentivized by congestion\/pollution fees and\/or 'good navigation' credits, propose optimal routings based on drivers' preferences, local perceived traffic, and signal timing. All this is enabled by efficient vehicle to roadway infrastructure communications, from 3G channels to DSRC radios (roadside and on-board) that enable real-time, low cost, scalable information exchanges among the various architecture components.<br\/><br\/>Broader Impact: This project will be highly interdisciplinary; it will benefit from the collaboration and expertise of computer science, atmospheric science, and urban planning faculty and students. The efficacy of our solution will be demonstrated via simulation, emulation, and experimentation. New education opportunities will result from the multidisciplinary nature of the project.","title":"NeTS:Large: Collaborative Research: Closing the loop between traffic\/pollution sensing and vehicle route control using traffic lights and navigators.","awardID":"1111971","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["558959",483884,"497047","531473",483887],"PO":["565090"]},"181414":{"abstract":"Many systems take the form of massive networks, i.e., a set of nodes joined together in pairs by links. Examples include social, communication and biological networks. Research on such complex networks has attracted broad scientific disciplines. While many sophisticated mathematical tools for network analysis have been developed, many such tools are not directly applicable due to the sheer size of modern-day networks. In addition, these networks may be dynamically evolving and may have extra node information and\/or auxiliary links between the same group of nodes obtained from heterogeneous data sources. Our proposed research aims to develop mathematical ideas novel to the analysis of massive networks. In particular, we plan to develop a novel dimensionality reduction method that proceeds by conducting a very fast clustering of the graph, extracting local latent subspaces of the graph, and then \"gluing\" together these subspaces to get a dimensionality reduction scheme for the entire network. Building on our new method, we plan to develop methods for handling time-evolving networks, multiple sources of information, supervised dimensionality reduction of networks and hierarchical schemes for dimensionality reduction as well as prediction. Our methods are eminently suitable for parallel computation, and we propose to further address the scalability problem by developing parallel versions of our methods on modern multi-core architectures.<br\/><br\/>The proposed research will enable important inference tasks, such as link prediction, collaborative filtering and semi-supervised classification to be efficiently carried out on massive networks. We expect the resulting algorithms to have the following properties: (1) computationally faster than current state-of-the-art methods for dimensionality reduction; (2) much more memory-efficient than the globally and rank-wise optimal SVD method; (3) scalable to extremely large data sets, such as online social networks, e.g., MySpace and Facebook, communication networks and virtual networks; (4) flexible enough to integrate auxiliary information of various types and different levels of uncertainty; and (5) effective enough to discover the task-oriented low-dimensional structure of the network. The proposed project will have broad impact on research in a variety of disciplines, including applied mathematics, computer science and social sciences. We plan to share the software developed under the project with the scientific community via a public web site, as well as the data and results that arise from our studies. The project will make a conscious effort to involve students in inter-disciplinary research.","title":"AF: Small: Fast and Memory-Efficient Dimensionality Reduction for Massive Networks","awardID":"1117055","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["550986"],"PO":["565251"]},"181535":{"abstract":"Finding and quantifying differences between shapes is important in many areas of the biological sciences. This methodological research will contribute to ongoing research in two areas, neuroscience and paleontology. In neuroscience, the interest is mainly in tracking the progress of Alzheimer's disease and normal aging processes in the brain, and relating the 3D shape changes seen in MRI scans to cognitive measurements and other variables. NIH studies provide access to large amounts of such data. In paleontology, the only information on many extinct species comes from fossils, and estimates of the relationships between these fossil species and human ancestors is based largely on differences and similarities of shape. The goal is to put fossil shape data into the context of much larger sets of data collected from existing species, both morphological and genomic data from earlier research. <br\/><br\/>This collaboration is interested in defining and computing what it means for three-dimensional biological shapes to resemble each other; as specific examples, they consider the shapes of fossil primate bones and of regions in the brain such as the hippocampus. Current practical measures of shape difference are based on sets of corresponding point samples on the object surfaces. The team will add a surface mesh connecting these corresponding points, and represent a shape by the vector of the lengths of the edges in its copy of the mesh. The distance between two shapes is then the Euclidean distance between their corresponding edge vectors. This representation has some attractive mathematical properties. With a few simple additional requirements on the mesh, the edge-length vectors form a high-dimensional Euclidean space, within which standard statistical analyses can be performed. Second, the measure is invariant to rotations and translations not only of the entire object, but to a large extent to transformations of one part of the object with respect to the rest. <br\/><br\/>The research will include experimental work to compare the proposed metric and<br\/>current methods in both neurobiology and in physical anthropology. They also intend to work on methods to simplify finding and optimizing corresponding points and meshes connecting them on input specimens, a perennial problem in three-dimensional data analysis. Not only is this important to facilitate experiments, but having a good practical shape metric will help improve techniques in this area. Finally, the team plans work on interesting related mathematical problems, specifically the convergence of the metric to property of smooth surfaces as the sampling density is increased <br\/><br\/>There are plans to release both software for the use of practitioners and ensembles of data annotated with corresponding meshes for the use of other researchers into the methodology of shape differences. In this way the research should benefit many others who analyze shape differences: our colleagues in paleontology and neuroscience, people who study the anatomy of humans, other animals and even plants, forensic scientists, and others.","title":"III: Small: Collaborative Research: Shape Differences in the Biological Sciences","awardID":"1117663","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[486372,"538707","521295"],"PO":["565136"]},"185902":{"abstract":"The project provides a systematic means to modify the activity in a specific group of muscles by using a robot, which is expected to lead to wider diagnosis and treatment options for patients than conventional approaches which rely solely on therapists' knowledge and experience. This EAGER project tests this potentially transformative concept in a collaboration between Georgia Institute of Technology (GT) and two institutions in Japan, Nara Institute of Science and Technology (NAIST) and the University of Tokyo Hospital (U-Tokyo) through the support of NSF-JST (Japan Science and Technology Agency) Strategic International Cooperative Program. The primary objective of the US-Japan collaborative research is to develop methodologies to computationally plan and execute various motor-tasks for neuromuscular function test by using an exoskeleton-type robot and quantitatively evaluate the efficacy by measuring various biosignals.<br\/><br\/>The project produces results that are useful in rehabilitation science, robotics, physical therapy, neuro-muscular science, and athletic training. In addition, international collaboration with Japanese researchers exposes graduate students and faculty to the global research opportunities and capabilities. Moreover, results have the potential to significantly lower health care costs in these domains, which occur quite frequently in the aging population.","title":"EAGER: Muscle Adaptation Induced by the Physical Interaction with an Exoskeleton and its Application to Motor-Task Planning for Neurorehabilitation","awardID":"1142438","effectiveDate":"2011-09-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["549592","549593"],"PO":["564318"]},"180457":{"abstract":"This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br\/><br\/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br\/><br\/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists \"in the loop\" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http:\/\/www.scidb.org\/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http:\/\/database.cs.brown.edu\/projects\/scidb).","title":"III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","awardID":"1111423","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[483625,483626],"PO":["563751"]},"181436":{"abstract":"This proposal explores a robust quantum cryptography protocol for securing optical burst switching (OBS) networks, providing a means to make the OBS-based future Internet trustworthy from the ground up. Since the OBS network has a one-to-one correspondence between the header and its associated burst, the same relationship can be exploited for encryption. The quantum-based methodology makes it possible to distribute keys securely so that each burst is encrypted and decrypted with a unique key. As the well-known BB84 quantum cryptography protocol is susceptible to siphoning attacks on the multiple photons emitted by practical sources, we use a new 3-stage quantum cryptography protocol which is immune to such siphoning attacks, for it is based on random rotations of the polarization vector. The new 3-stage quantum cryptography protocol allows practical photon sources to be used in the quantum key exchange, making it feasible to extend quantum cryptography services beyond trusted routers. The 3-stage all quantum protocol is being investigated for its performance in different noise situations for different key generation rates. The implementation of the protocol uses quantum phase modulation rather than polarization modulation which is not stable in the long transmission over fiber. The research conducted in this proposal includes the design of an integrated secure router and investigation of quantum cryptography protocols for specific services. This research will be verified on a reconfigurable optical burst switching test bed.","title":"TC: Small: Collaborative Research: Exploring a Robust Quantum Cryptography Protocol for Securing Optical Burst Switching Networks","awardID":"1117148","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[486128],"PO":["565327"]},"180347":{"abstract":"In the face of the vast scale of software-intensive systems needed today, modern development environments fail dramatically, typically leading to information overload, an inability to deal with the highly dynamic nature of both the systems and the organizations that develop them, and failure to support collaboration across organizational boundaries. The overarching aim of this project is to provide a scientific foundation for human-centered environments that make large-scale and distributed project awareness, communication, and coordination as effortless as in a small team. It accomplishes this by (a) performing empirical studies of real-world large-scale high-complexity software projects to understand how task coordination occurs in and contributes to organizational context, (b) developing an underlying theory of coordination in context, which will motivate and guide (c) the design of new coordination technology that explicitly addresses information overload, dynamism, and organizational boundaries. <br\/><br\/>Intellectual merit: The research will result in four contributions: (a) a sound theoretical basis that captures how task coordination and organizational context interplay at scale; (b) theory-driven empirical studies of in-context coordination; (c) knowledge about how to achieve improvements in productivity, quality, and development speed; and (d) a suite of design principles, tool prototypes, and interaction techniques for collaboration at a very large scale. These outcomes will transform the landscape of coordination technology by squarely addressing the issue of scale, moving from coordination within a team to coordination across many developers, across many teams, and across multiple geographical and organizational boundaries.<br\/><br\/>Broader Impacts: As society enters the era of \"ultra large scale\" software-intensive systems, coordination at such scales is a major unsolved problem, persistently hampering development and advances in vital domains such as healthcare, security, defense, eGovernment, and energy. The outcomes of this project will not only provide major economic benefits, but also major societal benefits in the form of the new systems that now can be developed. Through close collaboration with industry partners, the results will quickly find their way into practice. The project will also increase involvement of women in computer science through workshops and mentoring activities.","title":"HCC: Large: Collaborative Research: Large-Scale Human-Centered Coordination Systems to Support Interdependent Tasks in Context","awardID":"1110916","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["548131"],"PO":["565342"]},"181205":{"abstract":"To meet the ever increasing demands of Information Technology, the development of terahertz (THz) transmission and interface technology is expected to bring about on-chip convergence of optical communication and digital computing in the future-generation VLSI chips. The proposed research envisages studying Plasmon propagation through meta-material structures with periodic array of grooves in order to develop THz switch\/waveguide technology which may enhance the computational capabilities in the Beyond-Moore's-Law (BML) era when charge-based CMOS transistors cannot be scaled down anymore.<br\/><br\/>The proposed research involving EM theory, photonics, SPICE circuit simulation, and numerical analysis, encompasses several ideas that define its core intellectual merits. For example, new spoof surface Plasmon polar ton (SSPP) transport mechanism may enable THz signal propagation on global interconnect, dispersion engineering will develop dynamically-controlled SSPP tri-state buses by fine tuning materials to modulate their refractive index, and compact SSPP wave-guide-cavity-waveguide structures may lead to THz digital and mixed-signal circuits. Theoretical modeling and simulation methods to be developed in this project in conjunction with concomitant on-going research in new materials may potentially lead to the design of THz computing, ultrafast Boolean logic circuitry, and biological sensor networks. Furthermore, the proposed dynamically-controlled SSPP waveguide capable of transmitting information at THz speed can potentially be adopted to solve the ?communication bottleneck? problem in future multicore VLSI chips. <br\/><br\/><br\/>The educational objectives of this research project will involve interdisciplinary training for undergraduate and graduate students, thereby enabling them to meet the challenges of electronic, photonic and computer product design in a fiercely competitive global market. Promotion of women and minority students in the doctoral degree program in electrical and computer engineering will be given high priority in this research to fulfill its education and societal objectives. The PI will develop computer animation and colorful images for K-12 students in local schools thereby stimulating their interest in Science and Engineering. The audio visuals, instruction materials, and laboratory courseware will be made available to other universities through the Internet and will be uploaded at the Nano Hub website.","title":"AF: Small: (Nano) Tera Hertz (THz) Plasmonic Technologies for the Beyond Moore's Laws Era","awardID":"1116040","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["521045",485569],"PO":["562984"]},"181326":{"abstract":"Over the past decade or more, microprocessors have faced increasing challenges in achieving high-performance for current and emerging software applications while abiding by severe power and thermal limits. In response, industry has turned to approaches that use specialized graphics and computational hardware and complex memory organizations. The end result is that computer systems have become more heterogeneous and complex, in ways that make it difficult for programmers to write efficient and high-performance software. Software tuned to run on one implementation will often not run at all or will perform poorly or unpredictably when ported to even a different implementation in the same chip family. The objective of this research effort is to design and evaluate system and hardware support that tailors memory and data access\/movements to improve performance and power efficiency, while also easing the issues of programmability and of tuning software for individual chip characteristics.<br\/>The two key themes of this work are ShapeShifting and PubSub data abstractions. ShapeShifting refers to optimizations and hardware support structures that allow data to be transformed in layout, in order to support faster access, more efficient use of memory, and other attributes that improve power and performance. In some preliminary experiments, even a software-only implementation of ShapeShifting improves performance by 15%-2.8X. PubSub data abstractions offer methods for individual processors to indicate interest (or disinterest) in updates regarding other program variables. These abstractions form the underpinning for memory optimizations that are tailored to the application?s memory usage patterns. By mitigating false sharing, encouraging coarse-grained fetches, and reducing coherence broadcasts to uninterested cores, PubSub has the potential to improve the power and performance efficiency of multi-core implementations by a factor of 2X or more.<br\/>The research program is targeting several types of broad impact. First, the simulators and tools developed by this project will be released as free, open-source software. Second, the results can enhance performance and energy efficiency of future parallel hardware. Energy-efficiency is of particular concern from a national economic and strategic standpoint, given the growing electricity consumption of computer systems and the important role of the memory hierarchy in influencing computer power consumption.","title":"SHF: Small: Collaborative Research: ShapeShifting and PubSub for Tailoring Memory Access and Communication in Heterogeneous Multiprocessors","awardID":"1116673","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["489873"],"PO":["565272"]},"181447":{"abstract":"The objective of the proposed research is to systematically understand, evaluate and contribute towards the problem of membership inference in aggregate data publishing, a generic, novel, and dangerous privacy threat in a wide variety of real-world applications. The main idea proposed to address the problem of membership inference is an information-theoretic model of privacy disclosure as a noisy communication channel. Based on the channel coding theory and the recent advance in multi-input multi-output (MIMO) communication channels, the proposed research studies novel techniques for membership inference and explores the corresponding privacy-preserving mechanisms.<br\/><br\/>Intellectual Merit: The following salient features distinguish the proposed work from existing studies: (1) the proposed research studies a novel problem of membership inference in aggregate data publishing which stands in sharp contrast to the traditional inference control problem. In particular, the sensitive information in danger of disclosure in the proposed problem definition is the selection attributes of an aggregate query instead of its measure attributes which is the focus on traditional inference control. (2) This novel problem also leads to a set of novel solutions based on information theory. In particular, the propose research studies a model of membership inference attacks as modulation techniques in time and frequency domains for various types of communication channels, e.g., single-input single-output (SISO), multiple-input and single-output (MISO), single-input and multiple-output (SIMO), and multiple-input and multiple-output (MIMO) channels. This proposed channel model enables a uniform evaluation of the effectiveness of both membership inference and privacy-preserving techniques.<br\/><br\/>Broader Impact: The outcome of this research has broader impacts on the nation?s higher education system and high-tech industries. The prospect of sensitive membership information disclosure techniques and privacy-preserving techniques can help the providers of aggregated data publishing, including national health organizations, Internet security service providers, etc., to secure their published data. The broader impact of this project also extends to academia. Parts of this project is carried out by students of George Washington University (GWU), Towson University (TU), and University of Massachusetts, Lowell (UML) as part of advanced class projects or individual research projects.","title":"TC: Small: Collaborative Research: Membership Inference in a Differentially Private World and Beyond","awardID":"1117175","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["84633"],"PO":["562974"]},"181568":{"abstract":"The goal of this project is to develop methods to acquire real-world images and video from far fewer measurements than is possible in the current state-of-the-art. Such methods could be used to greatly reduce the cost of imaging in situations where taking measurements of an image\/video is currently very expensive. This is the case, for example, in magnetic resonance imaging (MRI), commonly used in both medicine and neuroscientific research. These methods could also make possible the acquisition of much more detailed information from the same imaging resources in areas such as remote sensing, geoscience, or astronomy.<br\/><br\/> To achieve this goal, the project will exploit manifold models for signal structure that have previously proved intractable in the compressive sensing literature. While manifold models can efficiently express many signals in terms of dramatically fewer parameters than the usual Fourier\/wavelet models, allowing for complete reconstruction of these signals from dramatically fewer measurements, the complexity of manifold models has to date stood as an obstacle to their use in efficient data acquisition. This project will employ an elegant framework, based on the kernel trick commonly used in kernel methods in machine learning, to permit the use of manifold models for compressive sensing with little to no increase in computational complexity.","title":"CIF: Small: Kernel Trick Compressive Sensing","awardID":"1117775","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[486465],"PO":["564898"]},"182899":{"abstract":"Proposal #: 11-25520<br\/>PI(s): Norton, Roger; Coleman, Ron G.; Lauria, Eitel<br\/>Institution: Marist College<br\/> Poughkeepsie, NY 12601-1387<br\/>Title: MRI\/Acq.: An Enterprise System for Research and Research Training<br\/>Project Proposed:<br\/>This project from a mainly undergraduate-serving institution, acquiring an enterprise computing<br\/>processor and associated storage and network peripherals, aims to introduce research training in enterprise<br\/>computing to faculty, undergraduates, and K-12 teachers and students and to bring existing and new<br\/>research applications onto the new system. Enterprise computing (EC) research and research training has<br\/>steadily declined at universities for over three decades. Although enterprise systems and data are vital to national security and economic growth, many CS and ITS faculty are ill equipped to train the next generation of instrumentalists. This new equipment will be used to fill a major gap in computer science research and research training. Also, since many technological advances in systems hardware and software appear first on enterprise systems and are later adopted by smaller systems, access to an enterprise system will allow faculty researchers and students to explore technologies only encountered on large systems and to explore them earlier. This proposal focuses on research training of faculty and students on the system itself and its use by individual researchers to consolidate and upscale their projects from smaller systems to this larger system. Research projects in computer science, information technology, and mathematics will be moved to the new equipment where a wide scope of applications in different disciplines can be run simultaneously. The work consists of three primary activities:<br\/>- Business analytics as a solution to the problems associated with manual medical coding. The new equipment will allow analysis of much larger datasets than are currently feasible. As medical records expand and become more complex, the equipment will be able to accommodate the growth.<br\/>- Location aware mobile devices for historical sites will be dependent on the ability to rapidly deploy virtual Linux environments for new historical sites as well as high-speed access to large data stores that house the archives and artifacts associated with his system.<br\/>- Research training for faculty and students will prepare the next generation of instrumentalists and improve the computer science, information technology, and mathematics curriculum and introduce researchers in other disciplines to a technology that can benefit their research.<br\/>Business analytics and data mining have broad applications in correcting errors in medical diagnoses. The instrument would contribute to a model for data cleansing in large complex data sets. In location-aware mobile devices, the instrumentation would contribute in modeling other research projects to explore ways to give users in-depth information and navigation in large geographical areas.<br\/>Broader Impacts: <br\/>The institution seeks to revitalize research and research training within a predominantly undergraduate setting. Faculty engaged in applied research and the 800 plus members of the NSF-funded Enterprise Computing (EC) Community have expanded training opportunities and provided resources to support their research. Although some of the research proposed has broad application in the medical field, the methodology under development can be applied wherever there is a need to detect errors and ensure greater accuracy in large complex data sets. Other research, digital information from an enterprise system to common handheld GPS devices, aims to prepare the next generation of researchers and industry professionals who will be responsible for the design and operation of the technology infrastructure that provides the rapid, reliable and secure backbone required by the national economy, the US, state and local governments, and academic researchers. This proposal aims to counter the decline trend in researchers by retraining current faculty and introducing a new generation of undergraduates and, through the Greystone Consortium, K-12 teachers and students to EC research and research training. Research conducted on the requested equipment will be made available to the broader community through a new website and online collaboration site that Marist will host.","title":"MRI: Acquisition of an Enterprise Level System for Research and Research Training","awardID":"1125520","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["537212",490075,"537210"],"PO":["543539"]},"180358":{"abstract":"This collaborative research project leverages expertise of four research teams (IIS-1111415, Massachusetts Institute of Technology; IIS-1110955, Harvard University; IIS-1111398, Washington University; and IIS-1111534, Cornell University). Understanding time-varying processes and phenomena is fundamental to science and engineering. Due to tremendous progress in digital photography, images and videos (including images from webcams, time- lapse photography captured by scientists, surveillance videos, and Internet photo collections) are becoming an important source of information about our dynamic world. However, techniques for automated understanding and visualization of time-varying processes from images or videos are scarce and underdeveloped, requiring fundamental new models and algorithms for representing changes over time. This research involves creating systems that enable modeling, analysis, and visualization of time-varying processes based on image data. These models and algorithms will form the basis for a new set of tools that can help answer important questions about how our environment is changing, how our cities are evolving, and what significant events are happening around the world.<br\/><br\/>Analyzing images over time poses fundamental new technical challenges. This project focuses on developing and demonstrating end-to-end systems consisting of (1) novel representations necessary to model time-varying image datasets; (2) algorithms for estimating long-range temporal correspondence in image datasets; (3) algorithms for decomposing image datasets into intuitive primitives such as shading, illumination, reflectance, and motion; (4) analysis tools for deriving higher level information from the decomposed representations (e.g., trends, repeated patterns, and unusual events); and (5) tools for visualization of the high-level information and methods for re-synthesis of image data.<br\/><br\/>This work has the potential to have significant impact in a broad range of areas where images are generated over time, e.g., in ecology, astronomy, urban planning, health, and many others. The results of this research will be broadly disseminated by making source code and datasets publicly available via the project web site (https:\/\/groups.csail.mit.edu\/vision\/image_time\/) and offering tutorials and organizing workshops at significant conferences. The project provides educational opportunities and offers hands-on collaborative research experience to students at both the undergraduate and graduate levels and the four institutions.","title":"CGV: Large: Collaborative Research: Analyzing Images Through Time","awardID":"1110955","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["489920"],"PO":["563751"]},"181469":{"abstract":"Geometric retrieval is the problem of preprocessing multi-dimensional<br\/>geometric data for rapid access. Efficient geometric search and<br\/>retrieval are of fundamental importance in engineering and science, and<br\/>have numerous applications in areas as diverse as knowledge discovery<br\/>and data mining, pattern recognition and classification, machine<br\/>learning, data compression, multimedia databases, document retrieval,<br\/>and statistics. Given the high complexity of exact solutions to these<br\/>problems, researchers have been led to consider these problems in the context<br\/>of approximation, where small errors in distance are tolerated.<br\/><br\/>Over recent years, there have been many advances in our understanding of<br\/>the computational complexity of approximation algorithms for proximity<br\/>searching. This has ranged from the development of a theory of the best<br\/>space-time tradeoffs achievable for these problems to practical software<br\/>systems. Nonetheless, there are still many important, challenging<br\/>problems that remain. Research under this award will both deepen and broaden<br\/>our understanding of the computational complexity of approximate<br\/>proximity searching. In particular, PI will study new data<br\/>structures for polytope membership queries, polytope-based approaches to<br\/>approximate nearest neighbor searching, simplification and unification<br\/>of proximity data structures, dynamic data structures for proximity<br\/>searching, and software implementations of these algorithms and data<br\/>structures.<br\/><br\/>In addition to the contributions of new algorithms and data structures,<br\/>software systems and libraries will be developed as part of this<br\/>research, which will be made freely available over the Web to help<br\/>scientists and engineers in other disciplines solve their own<br\/>application problems that involve nearest neighbor and range searching.<br\/>The geometric retrieval algorithms, developed as a part of this<br\/>research, will be incorporated into a graduate-level course in<br\/>computational geometry. Course materials will be made available over the<br\/>Web as a resource for researchers interested in learning about this<br\/>area.","title":"AF: Small: New Challenges in Geometric Search and Retrieval","awardID":"1117259","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[486206],"PO":["565157"]},"181238":{"abstract":"The project's main objective is devising a means to meet the challenge of excessive alcohol use by college students. The transition to the first year of college, in particular, is a critical age and life period when health and wellbeing are put to the test by the convergence of opportunity and peer pressure to drink heavily. Specifically, the project hypothesizes that adding the opportunity for role play in a web-based required online alcohol prevention program will improve the results compared to the web-based program only in a secondary prevention trial. All participants receive the standard alcohol prevention program required at the University of Central Florida (UCF), AlcoholEdu. Half of the randomly assigned participants have the opportunity to practice cognitive-behavioral skills through role plays. These immersive practice sessions are realistic in presenting situations that college students face in the real world. Armed with these skills and practice it is expected they will engage in less excessive alcohol use than those participants lacking this experience.<br\/><br\/>A unique aspect of the proposed treatment is the use of a state-of-the-art interactive role play experience based on digital puppetry of virtual characters. Here, digital puppetry refers to the use of a human to control the actions of animated characters in real-time. Such artistry has been employed for several decades in a number of venues including television and location-based entertainment. Digital puppetry is currently employed by one of the PIs in education and peer-pressure resistance programs. By affording natural and highly versatile behaviors, puppetry greatly increases interactivity and immersion while affording flexibility in the appearance and traits of the characters and choices for the interactive scenes.<br\/><br\/>An evaluation of this type of alcohol secondary prevention technique with college students is an advance in the field. Specifically, it allows the investigation of whether one-on-one virtual role-plays (e.g., a party scene in which college students can practice refusing to join a drinking game) can help students avoid difficult peer pressure situations. It could provide a new method to enhance and complement the programs currently used for alcohol secondary prevention.","title":"SHB: Small: Collaborative Research: Reducing Alcohol Use Among College Students Using Virtual Role Playing","awardID":"1116186","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[485647],"PO":["549626"]},"186826":{"abstract":"The objective of this workshop is to explore in a transdisciplinary fashion how models of the individual, his or her social network, and of societal decision making derived from psychology, sociology, decision sciences, economics, can be applied to create intelligent applications that empower patients. Empowerment of patients and healthy individuals is a critical aspect of individualized medicine and includes concepts of self-efficacy and self managed behavioral change, supported by healthcare providers and payers. Technology plays a role in patient empowerment but will be most successful if implemented within through scientifically based, theory-driven systems that address the barriers that patients face to empowerment within themselves and across the health system. To achieve this, intelligent systems need useful, computable models of patients reasoning and their social relationships and social networks. The workshop is focused on identifying the key questions underlying empowerment with a particular emphasis on the role of networking and information technology in the empowering processes. The results of this workshop are expected to have significant impact on the practical ability to empower individuals as well as on fundamental understanding of the empowerment process.","title":"Workshop on Patient Empowerment: A Transdisciplinary Informatics-Based Approach","awardID":"1147505","effectiveDate":"2011-09-01","expirationDate":"2012-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[501250],"PO":["564768"]},"194108":{"abstract":"In this project, the principal investigator and his assistants are working on a framework for achieving<br\/>scalability and sustainability in three-dimensional wireless sensor network deployments. The objective is<br\/>to study the design of energy-efficient three-dimensional k-covered wireless sensor networks, where each<br\/>point in a field of interest is covered by at least k heterogeneous sensors, in the presence of obstacles<br\/>and mobile events in the field. This study is based on Baxter's factorization of Ornstein-Zernike equation,<br\/>the pair-connectedness theory, and potential fields to solve the problem of joint k-coverage, duty-cycling,<br\/>and data forwarding in three-dimensional heterogeneous wireless sensor networks with a goal to achieve<br\/>sustainable and scalable deployments. The principal investigator plans to evaluate the performance of this<br\/>framework through simulation using a network simulator, such as TOSSIM, and implementation using a test-bed of sensors, such as MICAz motes.<br\/><br\/>This project has significant impact on its field and the society. It has a rich plan for the integration<br\/>of research and education through the development of curriculum and resources for teaching to a wide range of undergraduate and graduate students. Based on the results of this project, the principal investigator plans to develop a set of networking courses. Also, the principal investigator has a plan to recruit, train, and mentor graduate and undergraduate students including women and members of underrepresented minority groups. Furthermore, this project allows the principal investigator mentor K-12 teachers and high-school students through research seminars. It helps the principal investigator attract and recruit students to pursue science careers.","title":"CAREER: A Theoretical Foundation for Achieving Sustainability and Scalability in 3D Wireless Sensor Network Deployments","awardID":"1224628","effectiveDate":"2011-09-01","expirationDate":"2016-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[519845],"PO":["565303"]},"186518":{"abstract":"This is an EAGER proposal to support 2 graduate students in research which responds to an immediate need concerning critical questions focused on transferring, managing, and the organizational issues of large digital datasets. The basis of the project capitalizes on a very important event: The Sloan Digital Sky Survey (SDSS) scientific dataset is being transferred from one repository to two others, from a national laboratory to a university library and also to a university-based group of astronomers - from one kind of workforce to two others. This is a pivotal moment to study in the organization of digital knowledge in astronomy and how that knowledge will be developed. <br\/><br\/>The transfer of the database between the three workforces, although highly planned, will face multiple strategic difficulties that will require members of all workforces to develop a new form of knowledge at the interface of their different practices. Those who become adept at this interface of knowledge and data transfer will possess knowledge crucial to the designers of data repositories and those who make use of them. Understanding changes, organizational structures, identifying differences and managing cultural and technical issues can be extremely informative to proposed approaches in the cross-disciplinary\/cross-workforce science of the future.","title":"EAGER: Knowledge and Data Transfer: the Formation of a New Workforce","awardID":"1145888","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":["517365",500489],"PO":["565292"]},"180524":{"abstract":"Exponential progress in Complementary Metal Oxide Semiconductor (CMOS) miniaturization (Moore's Law) over decades has increased computing power to the point that it has transformed science and engineering and touched every aspect of modern society. Continuing progress in computing at the same rate for several more decades is likely to have an even greater impact than that seen so far. Unfortunately, over the last decade, Moore's Law has become increasingly threatened by fundamental design and manufacturing limitations that are being reached. In particular, as individual CMOS logic elements have become smaller, they have also become more sensitive to noise and interference. Moreover, CMOS elements consume power disproportionate to their size; supplying this power, dissipating the heat generated, and containing the adverse effects of high temperatures all constitute serious roadblocks to Moore's Law.<br\/><br\/>This project on PHase based LOGic using Oscillatory Nano-systems (PHLOGON) aims to circumvent these problems via a fundamentally different physical paradigm for computing: the bits and bytes that constitute digital information are encoded using the phase (or timing) of oscillatory (i.e., undulating) signals, not as voltage levels as in conventional computing. Phase encoding has inherent noise immunity advantages over level encoding; PHLOGON exploits this feature fully within the most basic elements that store and manipulate data bits. The core of PHLOGON is logic made of self-sustaining nonlinear oscillators (i.e., elements that generate their own undulating signals, like pendulum clocks). Such oscillatory logic elements can be realized easily using not only CMOS transistors, but also devices from biology such as neurons and intracellular oscillators, from nanotechnology such as Spin Torque Nano Oscillators (STNO) and Micro\/Nano-Electro-Mechanical (M\/NEMS) resonators, and from optics such as lasers. Thus, PHLOGON enables a wide variety of novel \"substrates\" for computing. Importantly, several of these (e.g., CMOS and STNOs) offer the promise of dramatically lower power\/energy consumption than conventional level-based logic. By developing the core knowledge required for phase-based alternatives to level-based computing to be viable, the PHLOGON project can have significant and wide-ranging impact, potentially reversing the slow-down in Moore's Law and enabling progress in the physical mechanisms that underlie computing for decades to come.","title":"SHF: Large: Phase-Based Logic Realized Using Oscillatory Nanosystems (PHLOGON)","awardID":"1111733","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["502253","520671"],"PO":["562984"]},"180425":{"abstract":"Computer networks, in particular the Internet, represent critical infrastructure for business, government, military, and personal communication. Several recent trends in technology and network use have pushed the capabilities required of the Internet beyond what can be provided by the currently deployed infrastructure. This project develops a new architectural design for the Internet of the near future that represents a transformative shift to enable sustained innovation in the core of the network, using economic principles. The core idea of this new network architecture is to support choice as the central aspect of the architecture. A network built on these principles will be able to adapt to emerging solutions for current and future challenges. The network architecture designed and prototyped in this work aims to (1) encourage alternatives to allow users to choose from a range of services, (2) let users vote with their wallet to reward superior and innovative services, (3) provide the mechanisms to stay informed on available alternatives and their performances. Solutions are approached from different directions, reflecting the team's multidisciplinary expertise in computer networking, network systems, management science, and network economics.<br\/><br\/>The broader impact of this project contributes to enhancing the functionality and usability of the next-generation Internet, which is expected to become an important piece of infrastructure. The project also integrates research and education of graduate and undergraduate students at the participating organizations, where current efforts to integrate underrepresented minorities are continued. Results from this work are disseminated in the form of an open-source prototype and publications.","title":"NeTS: Large: Collaborative Research: Network Innovation through Choice","awardID":"1111276","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[483545,"485542"],"PO":["565090"]},"180436":{"abstract":"CIF: Large: Collaborative Research: Controlled Sensing, and Distributed Signal Processing and Decision Making in Networked Systems<br\/><br\/>PIs: Demosthenis Teneketzis (Michigan) and Venugopal Veeravalli (Illinois) <br\/><br\/>Abstract:<br\/><br\/>Many modern technological systems are networked systems. Networked systems are informationally decentralized, comprise many nodes carrying disparate information, and are subject to constraints on energy, data storage and computational capabilities. This research project entails a comprehensive study of fundamental issues that arise in networked systems, pertaining to controlled sensing, distributed signal processing, and distributed decision making, whose resolution will lead to substantial improvements in network performance. The project aims at (i) improving our understanding of the role of information in sensing, signal processing and decision making for networked systems under various architectures, in controlled and distributed settings; (ii) improving our understanding of coordination of networked systems, by evaluating the performance of the different architectures; and (iii) generating novel algorithms that will lead to networked systems that exhibit superior performance over current ones. The problems underlying these objectives cannot be adequately tackled using standard approaches in signal processing or stochastic and deterministic control theory. The investigators use key tools from stochastic optimization, distributed computation, and probability theory to develop novel methodologies that address the underlying challenges. <br\/><br\/>This project has broader impact on several fronts. It provides systematic design methodologies that are essential in many modern networked systems, and in particular, in systems for environmental (e.g., soil moisture) monitoring with distributed sensors. In addition, the research output of this project is expected to be useful to NSF's NEON program, to NASA's earth science program, and to NOAA's monitoring program. The research activities are expected to have an impact on technology transfer and graduate education through course development and training of students, with a special emphasis on including women and under-represented minority students through a strong mentorship program.","title":"CIF: Large: Collaborative Research: Controlled Sensing, and Distributed Signal Processing and Decision Making in Networked Systems","awardID":"1111342","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["223414",483572,"547412"],"PO":["564898"]},"181536":{"abstract":"Data-intensive real-time applications, such as transportation management, military surveillance, and network monitoring, need to handle massive amounts of stream data in a timely fashion. It is challenging to support real-time stream data services (RTSDS) due to stringent timing constraints, potentially unbounded continuous stream data, bursty stream data arrivals, and workload variations due to data value changes. This project will develop cost-effective methods and a runtime system for RTSDS. The project will systematically investigate methods and tools to support real-time continuous queries for RTSDS even in the presence of dynamic workloads. Specifically, the project will study a) real-time continuous query modeling, b) new performance metric design c) adaptive query scheduling design, d) tardiness control and load shedding, for both single node and clustered RTSDS. The project will also have prototype implementation and testbed evaluations. The results and findings of this project will advance and seamlessly integrate real-time computing and stream data management.<br\/><br\/>Real-time stream data services (RTSDS) play an important role in many emerging application including intelligent transportation, green buildings, smart grid management, military surveillance, and network monitoring. Our everyday lives are highly dependent on these applications. RTSDS is a fundamental technology for developing critical data-intensive real-time applications with great socio-economic impacts. The project will develop the scientific foundations and associated engineering principles for building RTSDS. <br\/><br\/>The project will provide excellent opportunities for undergraduate and graduate students to acquire hands-on experience as well as theoretical backgrounds in RTSDS. The PIs will work closely with students to carry out the research in this project. Through this project, the PIs will train students to become strong in both analytical and implementation skills, and help them solve challenging problems in RTSDS.","title":"CSR: Small: Collaborative Research: Systematic Approaches for Real-Time Stream Data Services","awardID":"1117664","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["557136","486378",486378],"PO":["564778"]},"181426":{"abstract":"While there has been progress in recent years in solving numerous wireless sensor networking challenges, the key problem of enabling real-time quality-aware video streaming in large-scale wireless networks of resource-constrained devices is still open and largely unexplored. Existing wireless networking protocol stacks based on transmitting predictively-encoded video are computationally expensive, have limited resilience to wireless channel errors, and use available network resources inefficiently. This project is attempting a new approach based: (a) On the development of a novel wireless streaming framework for resource-constrained devices rooted in the theory of compressed sensing (CS) and (b) co-design\/optimization of the video encoder and key wireless networking functionalities. <br\/><br\/>The new networked wireless streaming system being developed is referred to as Compressive Video Streaming (CVS) and has the potential to significantly reduce power consumption for a given target video quality for resource-constrained sensing devices. New network control algorithms are designed and integrated with the video encoder that, unlike TCP and TCP-friendly approaches, use the estimated received video quality as the basis for resource allocation decisions. Project implementation and extensive testing is being carried out on several experimental platforms.<br\/><br\/>The technology to be developed has the potential to strongly impact the state of the art in resource-constrained wireless video sensor networks. Important educational objectives of the program include mentoring of minority graduate and undergraduate students, and development of new interdisciplinary course materials.","title":"NeTS: Small: Towards Ubiquitous Multimedia Sensing through Compressive Video Streaming","awardID":"1117121","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["490695","555021"],"PO":["565303"]},"180458":{"abstract":"Innovation in public health is often bottom up: new processes and technologies are often identified by grassroots and non-governmental organizations and deployed locally before achieving broader use. Mobile technologies have a vast potential to strengthen health systems for under-served populations, but innovation is hindered by the difficulty and expertise required to create robust and deployable solutions. This work seeks to change this state of affairs by providing a set of tools based on commonly available mobile devices that will permit these organizations to easily deploy new health services, supervise their delivery, improve logistics, evaluate their programs' effectiveness, and disseminate their learning and tools to others around the world. The approach is based on cost-realism, namely, the appropriate mix of technology elements to tackle a problem based on a realistic assessment of the solution's sustainability in the community where it will be deployed. Thus, the focus is on using a mix of communication devices that are already likely to be in the possession of a large percentage of the target population such as mobile phones. There will also be experimentation with adding new sensor devices to mobile phones for physiological measurements. This collaborative work includes PATH, an organization uniquely suited to realizing scalable technology solutions in the public health space.<br\/><br\/>The goal of the research is to understand how mobile and cloud software can be constructed to make it easier to deploy modular applications that take advantage of components designed by a large community rather than a monolithic solution that is difficult to extend. In this way, a flourishing ecosystem will be created, much like application markets today, with the added capability of composing modules into larger systems. Evaluation will include both the use of the tools in a public health context as well as the ease with which new information services and systems are built and deployed. Given the wide range of potential applications students will be recruited from a wide variety of disciplines including the University of Washington Medical School, School of Public Health, and Information School and inter-disciplinary projects will be introduced into undergraduate capstone courses.<br\/><br\/>As the work is multi-disciplinary, research results will be as well. The focus is on human-computer interaction, mobile systems, communication, and software engineering. The primary technical challenges are in management of mobile data collection, expanding the sensing\/perception capabilities of mobile phones for health, and architecting distributed information services. Improved methods for organizing data collection campaigns and their sustainable management in terms of both the deployment of instruments on mobile devices and tools to supervise the data collectors themselves will be foremost. Connecting mobile phones and their sensors in a structured arrangement that will allow use of everything from paper and cheap voice\/SMS phones on one end of the spectrum to smartphones and tablets on the other will be a significant contribution to data collection methods. Exploiting standard interfaces and internet protocols between cloud-based modules will formalize the development of data architectures (above basic databases) that embody work processes and sustain management feedback loops.","title":"SHB: Large: Collaborative Research: From the Ground Up -- Mobile Tools for Grassroots Programs in Public Health","awardID":"1111433","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[483628,"24192",483630],"PO":["565136"]},"184704":{"abstract":"A CPS is a system in which computer-based (?cyber?) technology is combined with all kinds of physical systems, such as planes and robotic-surgeons. CPSs require integration (in industry and academia) of different types of knowledge from many different domains. CPSs are built from often inaccurate, undependable components, and operate in harsh and unpredictable environments. The cyber domain, interfaces, and the physical domain are tightly interwoven and networked (distributed) and hence cannot be designed and optimized individually. The goal of this project is to create a general CPS design-science that makes the design of every CPS simpler, faster, and more dependable, while at the same time reducing the cost and the required expertise level. This project gives rise to a unified theory that can allow for specification, modeling, design, optimization, and verification of CPSs on different levels of design abstraction and different steps of projection, even across boundaries between varied technologies. The project does bridge the gap between the continuous-time physical domain and the discrete timed cyber system.<br\/><br\/><br\/>This project has a broad and profound impact in scientific, engineering, industrial, and academic communities. By enabling a fundamentally efficient design of CPSs, the most limiting bottleneck in design technology is eliminated, paving the way for many new applications and jobs with significant economic and social impact. This project contributes to the on-line educational endeavors currently underway, allowing cross education in different disciplines of complex CPS and speeding up development of new CPS programs in engineering and computer science.","title":"CPS: Medium: Collaborative Research: Design Science for CPS","awardID":"1136146","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[495391,495392],"PO":["562984"]},"181437":{"abstract":"New large-scale DNA sequencing and array technologies now provide a promising way to study the molecular mechanisms of cancer by generating enormous information measuring aberrations in cancer genome. The genomic information can potentially guide drug design on targeted molecules, and improve clinical decisions in cancer treatment. One of the main obstacles to further progress is to elucidate multiple complex molecular indicators of cancers from the enormous genomic data. This proposal tackles the problem with network-based machine-learning theoretical frameworks and methods that can model the underlying biological mechanisms for an integrative study of cancer genomic information and relevant biomedical knowledge. As a proof of concept, the developed methods will be applied to study chemoresistance in ovarian cancer treatment. <br\/><br\/>This proposal aims at creating a general computation-driven approach for guiding cancer genomics research and improving genomics-based clinical decisions in cancer treatment. The research activities described in the proposal will deliver a collection of effective and efficient computational tools to utilize heterogeneous genomic data combined with biomedical knowledge for clinical practices. The study of the ovarian cancer data will help reveal the crucial pathways driving chemoresistance, and provide useful prediction tools and drug targets for ovarian cancer treatment. This proposal will also integrate the latest research development in computational cancer genomics into new courses in several training programs to prepare students for their future professions to meet the need of workforce in the growing biomedical and health informatics industry in the upper midwest region. The education plan will also have a focus on recruiting students in minority and under-represented groups in computer science and information technology.<br\/><br\/>To achieve the goals, the components of the research plan are 1) to formulate graph kernels and subgraph mining algorithms that can integrate various types of cancer genome aberrations to improve cancer outcome predictions and to discover cancer-causative genome aberration patterns; 2) to formulate semi-supervised matrix factorization methods with Laplacian constraints for predicting novel cancer phenotype and gene associations for identifying potential drug targets, utilizing known relations in phenotype, gene and their association networks; 3) to study the chemoresistance in ovarian cancer treatment to reveal the crucial pathways driving the resistance, and develop useful prediction tools and drug targets for ovarian cancer treatment; 4) to release the developed methods in both software packages and webtools for public use in academia. The two major components of the education plan are: 1) to offer a two-week course, titled Cure Cancer with Computers, in the summer academy of the BioSMART program for Minnesota high school students, and 2) to create a new course Computational Genomics in Biomedical Informatics to support two graduate programs for training students in biomedical\/health informatics with knowledge in genomics and computer science.","title":"III: Small: Network Learning for Integrative Cancer Genomics","awardID":"1117153","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["502199"],"PO":["565136"]},"181558":{"abstract":"Shannon's source-channel separation theorem states that separating the source coder (compressor\/decompressor) and the channel coder (error correction coder\/decoder) via the universal digital interface of \"bits\" is optimal for point-to-point communication of a single data source. While this modular design principle has inspired the basic architecture for most of today's communication systems, it is outperformed by more complex \"joint\" source-channel coders for communication of multiple sources over networks---an important task in today's explosive demand and supply of distributed information sources. At the same time, many emerging applications involve computing a summary of data from multiple nodes, making a coordinated decision, and performing a joint action among these nodes, rather than merely communicating sources. This research establishes a hybrid source-channel coding architecture for these applications that is as simple as Shannon?s separation architecture, yet achieves much improved performance. The new architecture will eventually lead to the discovery of practical algorithms for distributed computation, sensing, decision making, and coordination over networks.<br\/><br\/>Specifically, this research focuses on and develops new approaches for tackling the following problems: 1) hybrid coding for communicating correlated sources over multiuser channels (a unified approach for joint source-channel coding), 2) hybrid coding for network communication (a new relaying scheme based on joint source-channel coding), 3) implementation issues for hybrid coding (design of a practical code that is a good channel code and a good source code simultaneously), and 4) a mathematical framework for performance analysis and code design (information theoretic tools when the codebook and the message are entangled).","title":"CIF: Small: Collaborative Research: A New Approach to Joint Source-Channel Coding","awardID":"1117728","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[486443],"PO":["564924"]},"180348":{"abstract":"This collaborative project brings together expertise of five research teams at Brown University (IIS-1111423), University of Washington (IIS-1110370), Massachusetts Institute of Technology (IIS-1111371), Portland State University (IIS-1110917) and University of Wisconsin-Madison (IIS-1111423). Scientific data management has traditionally been performed using the file system, at best using files structured according to a low-level data format. Higher-level data management infrastructure has been task-specific and not reusable in different domains, resulting in millions of dollars of duplicated implementation effort by scientists to manage their data. The goal of this project is the development of a scientific database (SciDB), a system designed and optimized for scientific applications. The aim of SciDB is to do for science what relational databases did for the business world, namely to provide a high performance, commercial-quality and scalable data management system appropriate for many science domains.<br\/><br\/>In contrast to existing database systems, SciDB is based on a multidimensional array data model and includes multiple features specific to science and critical for science: provenance, uncertainty, versions, time travel, science-specific operations, and in situ data processing. No existing system offers all these features in a single, highly scalable engine. SciDB thus significantly advances the state-of-the-art in data management in addition to supporting domain scientists in data-driven knowledge discovery. The intellectual merit of SciDB is in exploring novel, high performance solutions to nested array storage, parallel array query optimization and execution, array language design, and time travel.<br\/><br\/>The primary broader impact of SciDB is on the community of scientists who benefit from the tool. By keeping scientists \"in the loop\" in the design of the system from the outset, the project delivers software that is broadly usable to the community. The proposal also funds participation in a series of workshops that seek to engage even more of the science community. SciDB is an open-source effort, with an initial prototype (http:\/\/www.scidb.org\/) already downloaded by hundreds of users. Finally, the PIs have a strong track record of delivering robust data management software that is widely used and involving students in the process, including students from under-represented groups. Further information can be found on the project web page (http:\/\/database.cs.brown.edu\/projects\/scidb).","title":"III: Large: Collaborative Research: SciDB - An Array Oriented Data Management System for Massive Scale Scientific Data","awardID":"1110917","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[483300],"PO":["563751"]},"181448":{"abstract":"This project develops (1) develops hardware platforms for persistent underwater observations, (2) develops adaptive sampling algorithms, (3) develops efficient data storage and access algorithms for sensor networks with slow broadcast rates, and (4) supports investigation of specific important environmental issues such as the interaction of rainfall events through the landscape to deliver sediment and nutrients to the near-shore and lagoon, ultimately affecting the coral reef. Specifically, the project contributes a new class of modular underwater robots and systems with increased agility in motion and effective data collection and retrieval and a science-base for coordinating underwater robots and sensors to provide a provably-correct foundation for applications to marine observations. Novel decentralized algorithms coordinate a group of robots and sensors for three related problems: sensor placement, event detection and tracking, and adaptive sampling, along with a unified framework for analyzing the stability and convergence of these algorithms.<br\/><br\/>Persistent underwater monitoring is deployable in any coastal environment and provides automation for collecting data in support of many environmental hypotheses. The same capabilities can also be used in the context of coastal and harbor protection operation, locating underwater mines and identifying intrusion. The underwater technology enables an unprecedented level of automation for environmental monitoring in water. The project impacts education through instructional and outreach activities aimed at developing and sharing a new curriculum that brings robotics technology together with marine biology through application, workshops, and tools. The project contributes designs and software for affordable and usable underwater robot and sensor platforms.","title":"RI: Small: Collaborative Research: Adaptive Sampling with Robots for Marine Observations","awardID":"1117178","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["527733"],"PO":["564069"]},"181459":{"abstract":"In the past six decades error control codes have been extensively used to improve the reliability in computer, communication and VLSI systems. Without the use of appropriate coding methods several of the common electronics devices (cell phones, computers, medical electronics, GPS, etc.) will not function in a reliable manner.<br\/><br\/>In this proposal, first, some error control codes for multilevel flash memories are investigated. Even though the use of multilevel cells increases the density of the flash memories compared to single level cells it also imposes two major challenges. The first one is that the voltage difference between the states is narrowed and hence there is a high probability of errors due to noise. The error nature in such cases can be considered as symmetric errors of limited magnitude. The second challenge is that, in order to program a cell from an higher value to a lower value an entire block of data needs to be erased and then each and every cell needs to be carefully programmed to the desired values. In order to do this, electrons are injected to the floating gates using many iterations. Thus, this is a very time consuming operation. The overshoot of levels while writing can be considered as asymmetric errors of limited magnitude. Thus, by using asymmetric error correcting codes of limited magnitude the speed and reliability of the flash memories can potentially be improved. The concept of limited magnitude error correction and detection is new in coding theory area. <br\/><br\/>Some fundamental theory and efficient code design methods are investigated for these types of limited magnitude errors. The other research problems are related to efficient design of unordered codes and balanced codes.<br\/><br\/>Flash memories find wide applications in cell phones, cameras, computer systems, embedded systems, etc. The market value of the flash memory is in the order of tens of billions of dollars and will continue to grow in the coming years. The proposed codes is expected to help improve speed and reliability of these memory and computer systems.","title":"CCF SHF(Small): Some Codes Applicable to Flash Memories and Computer Systems","awardID":"1117215","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[486183],"PO":["562984"]},"184979":{"abstract":"Fueled by the ubiquity of communications access, networked systems have become pervasive and given rise to behaviors whose evolution depends on both individual decisions and the interactions on the network. Examples of such behaviors include media sharing websites, where user recommendations influence product adoption decisions of other users, or more generally public discussion forums where past voting records of users provide indications on how they may influence each other and, therefore, how initial opinions may determine the outcome of future votes. Understanding the evolution of decisions in such connected settings can, therefore, be of significant social and economic benefit. For example, this can help predict the adoption of new social policies, or more pragmatically the commercial success of a new shared application. The importance of those questions has attracted much recent attention, but due to the complexity of networked interactions, much remains to be done. This project takes a multi-disciplinary approach to tackling these challenging questions, and seeks to build on models from statistical physics developed to capture the interactions of charged particles, which interact with each other in a manner akin to how users influence each other in a social network. If successful, the work can both expand the set of tools available to explore the behavior of networked systems, and offer insight into specific problems of interest.<br\/><br\/>This project explores two fundamental aspects of networked systems, namely, the formation of opinions in networks, and how adoption decisions are made when they are influenced by network neighbors. Networked systems can be of many different forms, including communication networks, social networks, political networks, geographical networks, etc., and are characterized by the fact that connections between network members influence their interactions. Characterizing these interactions is a complex task. The two main goals of the project are to (i) extend models from statistical physics to apply them to fundamental problems in networked systems; and (ii) empirically validate the predictive abilities of these models. Specifically, the project seeks to leverage and extend the Ising spin glass model, and apply these extensions to problems of opinion formation and adoption decisions in networked systems. Empirical validation of the results will then be sought through comparison to data collected from social media websites.","title":"EAGER: Collaborative Research: Information Diffusion and Opinion Formation in Networked Systems","awardID":"1137519","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[496297,"564485",496299],"PO":["565251"]},"181019":{"abstract":"Reputation and recommender systems have widespread use in online marketing, web services, P2P computing, e-commerce, social settings, and education. The objective of this research is to develop reliable, scalable and dependable schemes that are also resilient to malicious behaviors. <br\/><br\/>The approach is based on viewing both reputation and recommender systems as solving for marginal probability distribution functions from complicated global (joint-distribution) functions of many variables (users, items or service providers, and ratings). These marginal probability distributions are functions of the variables representing the reputation values (in reputation systems) and the ratings to be predicted to the users (in recommender systems). However, computing these marginal distributions are computationally prohibitive (i.e., exponential with the number of variables) for large scale reputation and recommender systems. Therefore, this research represents the reputation and recommender systems using factor graphs or Pairwise Markov Random Fields, and utilizes the Belief Propagation (BP) algorithm to efficiently (in linear complexity) solve for these marginal distributions. In particular, the project includes research to: (1) study the general theories of BP-based reputation management and recommender systems on various graphical models and develop novel algorithms; (2) study the convergence, scalability, and robustness of the developed algorithms via mathematical analysis and intensive simulations; (3) develop a Belief Propagation based Iterative Trust and Reputation Management (BP-ITRM) system and compare it with the current state of the art using real-life datasets and conducting user studies; and (4) adaptively learn various attack strategies against the reputation and recommender systems, determine the impacts of such attacks, and decrease their impact. <br\/><br\/>The project is expected to make contributions to both theory and practice by developing a new reputation management framework for recommender systems, and algorithms that provide effective ways to deal with information overload and access to relevant information. It is anticipated that the work will drive the technology for effective online products and information services. Technologies resulting from this research will bring a broad range of benefits in many areas including online services, P2P and distributed computing systems, e-commerce, business, social settings, education, national security and the economy. The research results are expected to make theoretical contributions relevant to computer science, information theory and statistical inference. This project offers a unique opportunity to train graduate students and expose undergraduate students to cross-cutting research in different fields (computer science, information theory, statistical inference). The project website (http:\/\/www.ece.gatech.edu\/research\/labs\/WCCL\/Security6.html) is used to disseminate resulting publications, datasets (obtained from user studies and mathematical models), and course materials to broad communities of researchers, students and industry practitioners.","title":"III: Small: Robust and Scalable Reputation Management and Recommender Systems Using Belief Propagation","awardID":"1115199","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[485126],"PO":["563751"]},"184418":{"abstract":"The Board on Physics and Astronomy (BPA) serves as the focal point in the National Research Council (NRC) for activities related to physics and astronomy and their interactions with engineering, medicine, chemistry, biology, and other sciences. The BPA's principal objectives are to maintain an awareness of the status of research in physics and astronomy, to identify emerging needs, and to initiate studies that address these problems and that foster continued progress. The BPA fulfills these objectives by working closely with the physics and astronomy communities in academia, federal agencies and their advisory committees, government laboratories, industry, relevant scientific and technical societies, and other boards and committees of the NRC.","title":"Partial Core Support of the Board on Physics and Astronomy","awardID":"1134011","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"9134","name":"PHYSICS EDUC & INTERDISCIP RES"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1798","name":"SPECIAL PROJECTS (AST)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}}],"PIcoPI":["529598"],"PO":["561720"]},"186607":{"abstract":"This project, investigating formal languages as a general methodology for task transfer between distinct cyber-physical systems such as humans and robots, aims to expand the science of cyber physical systems by developing Motion Grammars that will enable task transfer between distinct systems. <br\/><br\/>Formal languages are tools for encoding, describing and transferring structured knowledge. In natural language, the latter process is called communication. Similarly, we will develop a formal language through which arbitrary cyber-physical systems communicate tasks via structured actions. This investigation of Motion Grammars will contribute to the science of human cognition and the engineering of cyber-physical algorithms. By observing human activities during manipulation we will develop a novel class of hybrid control algorithms based on linguistic representations of task execution. These algorithms will broaden the capabilities of man-made systems and provide the infrastructure for motion transfer between humans, robots and broader systems in a generic context. Furthermore, the representation in a rigorous grammatical context will enable formal verification and validation in future work.<br\/><br\/>Broader Impacts: The proposed research has direct applications to new solutions for manufacturing, medical treatments such as surgery, logistics and food processing. In turn, each of these areas has a significant impact on the efficiency and convenience of our daily lives. The PIs serve as coordinators of graduate\/undergraduate programs and mentors to community schools. In order to guarantee that women and minorities have a significant role in the research, the PIs will annually invite K-12 students from Atlanta schools with primarily African American populations to the laboratories. One-day robot classes will be conducted that engage students in the excitement of hands-on science by interactively using lab equipment to transfer their manipulation skills to a robot arm.","title":"EAGER: Linguistic Task Transfer for Humans and Cyber Systems","awardID":"1146352","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["508256",500707],"PO":["543539"]},"183109":{"abstract":"PI(s): Knightly, Edward; Reed, William S; Sabharwal, Ashutosh; Zhong, Lin;<br\/>Institution: William Marsh Rice University<br\/>Title: MRI: Development and Deployment of an Operational and Programmable<br\/> Diverse-Spectrum Access Network<br\/>Project Proposed:<br\/>This project, SPAN, a system for Spectrum-Programmable Access for Next-generation Deployments, proposes a novel instrument and testbed environment with wireless access in diverse spectral ranges, which is open, disruptive and unconstrained by any standard. This project will yield three key developments, including the SPANnode, SPANscope, and SPANnet, which include the wireless node, unique network scale monitoring systems, and a wireless networks, respectively. SPANnode is a programmable wide-band node, with a unique level of high performance, spanning 100 times more spectrum and aggregate multiple bands to yield 4 times greater transmission bandwidth than any currently available open-source platform. SPANnode will yield the world?s first full-duplex transit node and first multi-user beam-forming gateway. SPANscope is a unique network-scale monitoring tool across vast spectral, spatial, and temporal scales. Finally, SPANnet is a wireless network comprising SPANnodes, SPANscope monitors, SPANscope-compliant smartphones, and community-owned legacy 802.11 clients. <br\/>SPAN enables research in<br\/>- Spectrum Aggregation: The project will develop and experimentally evaluate an algorithmic toolkit that enables network operators to aggregate diverse spectral bands to best meet their service objectives. <br\/>- Networked Multi-antenna Services: The project will exploit a novel multi-antenna features to develop new communication modes including multi-user beam-forming backhaul, full-duplex transit nodes, and enhanced security via a managed spatial footprint. <br\/>- Network-Scale Energy Optimization: The project will study energy efficiency performance tradeoffs brought by dynamic spectrum access and multi-antenna transceivers to reduce the operational cost of high-performance wireless network infrastructure and improve the battery lifetime.<br\/>Broader Impacts: <br\/>This project, unique in its goals and expected results, carries potential for large broader impacts in the areas of spectrum policy, standards, industry, and the research community. The measured data sets collected by in the project will be shared with the broader research community. The researcher is potentially transformational. SPANnet will serve primarily Hispanic community, and the project includes outreach to high schools in the underserved community. The project team actively engages multiple Hispanic and under-represented Ph.D. students. All code will be open-source and proposed are the community events that will promote wide usability of the SPANnodes which will be made available to the research community.","title":"MRI: Development and Deployment of an Operational and Programmable Diverse-Spectrum Access Network","awardID":"1126478","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":["548310","548311","548312",490853],"PO":["557609"]},"180503":{"abstract":"This project addresses open questions and challenges in search theory, energy-efficient networked robotics, and fish biology. A network of robotic boats which can track many fish in shallow waters over extended periods of time are deployed in invasive carp infested waters. Provably correct cooperative search and tracking algorithms are developed, energy efficiency is studied at multiple levels including navigation, sensing, communication and complete system, communication protocols for controllable mobile entities are studied, and data analysis algorithms are developed.<br\/><br\/>The project provides a means to sustainably reduce invasive carp populations in US lakes without impacting other wildlife, thus solving a major environmental problem. Robots are shown to serve as a major scientific instrument for environmental scientists. The educational activities promote the results of this research to high school, undergraduate and graduate students, as well as educators across the country. A summer research experience is offered which blends mathematics, computer science and biology. Participation of students from under-represented groups is ensured through collaborations with predominantly Native American schools, as well as Central State University which has a 96% African-American student population. The project simultaneously raises awareness of environmental issues and attracts students to science and engineering.","title":"RI: Large: Collaborative Research: A Robotic Network for Locating and Removing Invasive Carp from Inland Lakes","awardID":"1111638","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"6892","name":"CI REUSE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[483742,"553283","551321"],"PO":["564069"]},"181515":{"abstract":"Most natural signals are inherently sparse in certain bases or dictionaries where they can be <br\/>approximately represented by only a few significant components carrying the most relevant <br\/>information. In other words, the intrinsic signal information usually lies in a low-dimensional <br\/>subspace and the semantic information is often encoded in the sparse representation. <br\/>Processing of such signals in the sparsified domain is much faster, simpler, and more robust <br\/>than doing so in the original domain, making sparsity an extremely powerful tool in many <br\/>classical signal processing applications. Recently, with the emergence of the Compressed <br\/>Sensing (CS) framework, sparse representation and related optimization problems involving <br\/>sparsity as a prior called sparse recovery have increasingly attracted the interest of researchers <br\/>in various diverse disciplines, from statistics, to information theory, applied mathematics, <br\/>signal processing, coding theory and theoretical computer science.<br\/><br\/>This research involves the analysis, development, and application of robust sparsity-driven <br\/>algorithms for already-collected highly-correlated data sets where signals often exhibit a high <br\/>level of joint-sparsity and rich correlation structure. Examples of such data include natural video <br\/>sequences, volumetric medical images, huge image database, hyperspectral imagery (HSI), <br\/>and raw synthetic aperture radar (SAR) signals. The research develops a novel unifying robust <br\/>sparse-recovery framework based on context-aware and observable data-adaptive dictionaries,<br\/>focusing on two classes of practical applications of sparse recovery: (i) Representative -- <br\/>denoising, concealment, inpainting, enhancement; and (ii) Discriminative -- clustering, detection, <br\/>classification, and recognition. Recovery\/Discrimination accuracy is greatly improved by taking <br\/>into account inter-patch spatial correlation, inter-frame temporal correlation, and by adapting <br\/>algorithms dynamically based on local signal contents as well as by maximizing the level of <br\/>discrimination within the sparse recovery process.","title":"CIF: Small: Robust Sparse Recovery for Highly Correlated Data","awardID":"1117545","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[486320],"PO":["564898"]},"181636":{"abstract":"Recent cyber attacks have shown the degree of vulnerability on the individual to the corporate to national level. Everyone is vulnerable, from the consumer using a credit card to make an online purchase, to the multi-national corporation whose systems are hacked, to national infrastructure and defense networks. <br\/><br\/>Recent criminal attacks on computing devices and computer systems allow criminals to access private data without actually breaking the paradigm of provable-security, by exploiting some alternative and subtle weaknesses of the implemented systems (for instance through physical attacks mounted on computing devices or through clever internet-based attacks via exploiting concurrency of the communication). Examples of such attacks include measuring the power consumption of a computing device or manipulating its randomness generation process, or attacking multiple instances of the same protocol simultaneously on the internet. Moreover, the spread of light-weight (and extremely cheap) devices such as smart-cards and RFID chips makes evident that physical leakage of information must be prevented even when criminals are capable of physical reset of a device as well as manipulating network messages of computing artifacts. <br\/><br\/>While the theory of many of the above attacks has been recently developed in cryptography, the ongoing research of security of network attacks and reset attacks so far produced very limited results. We address challenges posed by such sophisticated criminal attacks with the goal of making such attacks computationally much harder to perpetrate. Our objectives include designing stronger security defenses for an important class of attacks on computational devices, including information-theoretic guarantees even during reset and network attacks on weak computational devices. The goals of this research includes obtaining feasibility and impossibility results for multiple cryptographic tools, and developing novel security techniques that when combined together, provide much stronger defenses for deployed systems.","title":"TC: Small: Towards Resettable & Statistical Security in Zero Knowledge","awardID":"1118126","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["533831"],"PO":["565239"]},"181405":{"abstract":"Despite great advances in computer recognition of conventional speech, automatic recognizers have enormous trouble with speech that deviates from speech norms in pitch range, speaking style, and timing.<br\/>Unconventional speech includes the \"motherese\" used to speak to young children, certain kinds of dysarthric speech, and singing. Current speech recognizers draw their power from statistical models of very large collections of real speech, but the corollary of this power is that speech that differs from this norm cannot be handled nearly so well.<br\/><br\/>The goal of this project is to create a speech recognition system able to handle a broad range of non-canonical speaking and voicing styles. As a motivating basis, we will target the transcription of singing.<br\/>Sung speech poses a number of significant challenges with implications in broader speech scenarios: In comparison with conventional speech, the speech timing is highly distorted; the pitch level, range, and dynamics are very different; and there are frequently simultaneous sound sources (i.e., accompanying instruments) whose signals must be distinguished from the voice.<br\/><br\/>The approach is to make a best-effort separation of the voice, e.g., by closely filtering the predominant pitch in a mixed signal. This candidate voice is then transformed and normalized to resemble conventional speech: The pitch harmonics are interpolated to achieve a more pitch-invariant spectrum, and the time axis is warped to achieve a more uniform rate of change (eliding over sustained, unchanging sounds). Then, a conventional speech recognizer is adapted to recognize this normalized speech. To train the recognizer for the target domain, a substantial collection of music audio is manually aligned with phoneme-level transcriptions of the singing. This corpus will be freely available to other researchers in music and non-canonical speech.<br\/><br\/>This work will develop techniques to make current speech recognition applicable to a much broader range of speech material and speakers.","title":"RI: Small: Automatic Speech Recognition of Unconventionally-Vocalized Speech","awardID":"1117015","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["554699"],"PO":["565215"]},"181416":{"abstract":"Cloud computing involves use of a hosted computational environment that can provide elastic compute and storage services on demand. Virtualization is a technology that allows multiple virtual machines (VMs) to run on a single physical machine and share its resources. Virtualization is increasingly being used in cloud computing to provide economies of scale, customized environments, fault isolation, and reliability. To address performance concerns with the use of cloud computing for scientific computing, the PAPI-V project is developing a system for hardware performance monitoring in virtualized environments to enable software developers to understand and optimize system and application performance and adapt to changing conditions. To accomplish this goal, the project is extending the widely used Performance API (PAPI) cross-platform library for accessing hardware performance counters.<br\/><br\/>The PAPI-V project is addressing the following aspects: <br\/>1. Timing: The PAPI timing routines are being extended to provide standard real and virtual timers across different Virtual Machine Monitors (VMMs). <br\/>2. Component measurements: The existing PAPI I\/O, network, and other shared resource components are being extended to provide relevant information in virtualized environments. <br\/>3. Virtualization of selected processor hardware counters: A selected set of processor counters considered being most relevant for application performance analysis and tuning in virtualized environments is being implemented across VMMs. <br\/>4. Interpretation of data: A mechanism for defining metrics that correctly quantify the contributions of various factors to overall performance is under development.<br\/><br\/>The research results will be implemented in the publically available and widely used PAPI library. The PAPI-V extension will allow application and tool developers to use a familiar interface to obtain relevant information for achieving the best possible performance in cloud computing environments.","title":"SHF: Small: PAPI-V Hardware Performance Monitoring for Virtualized Environments","awardID":"1117058","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[486078,"486080",486080],"PO":["565272"]},"181537":{"abstract":"Age-related cognitive impairments, including Alzheimer's disease, are among the most common diseases in the United States. Prevention through delay is currently considered the best way to tackle Alzheimer's disease and related disorders (ADRD). Early detection is crucial, as screening individuals with Mild Cognitive Impairment (MCI) may delay its progression and prevent it from developing. This research investigates the role of technologies for senior citizens with potential MCI at-risk factors and for medical practitioners, such as neurologists or neuropsychologists, to make data-driven clinical decisions.<br\/><br\/>The Clock Drawing Test, in which the patient is asked to draw a clock showing a certain time, is one of the easiest and most frequently used instruments for dementia screening. Current practice requires medical practitioners to administer and assess each individual paper-and-pencil test. It requires tedious effort and is prone to errors and inconsistent scoring among different clinicians. To address these difficulties, previous work by this research group has resulted in a computer-based version of the Clock Drawing Test that records a patient's freehand drawing on a tablet computer, then analyzes the drawing for evidence of cognitive imparment.<br\/><br\/>The current project is extending the computer-based system to acquire additional data associated with the Clock Drawing Test. This data includes timing of drawing and pausing phases, and pressure applied during drawing. The data can be used in evaluating drawings under several different scoring critera that can be chosen by the clinician. Through analysis of data and focus group discussions, the clinical utility of the new features are being evaluated with a goal of further improvement.","title":"SHB: Small: InteCog System: ClockReader+ and CogStim Game for Screening and Preventing Cognitive Impairment","awardID":"1117665","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[486380,"496304"],"PO":["549626"]},"182868":{"abstract":"This project focuses on Land Change Science (LCS).<br\/><br\/>Land Change Science is an emerging field of study, aimed at understanding interactions among human systems and the terrestrial biosphere, atmosphere and other Earth systems as mediated through human use of land. Advances in LCS are needed to better quantify, predict, mediate, and adapt to global climate change, biodiversity loss, and other consequences of land use and land cover change.<br\/><br\/>Despite vigorous efforts by a broad array of social and natural scientists, the cross-scale synthesis of multidisciplinary observations, models and theories on coupled human and natural systems (CHANS) that are required to advance LCS has yet to emerge. A major obstacle is the tremendous challenge in global integration and synthesis of local and regional CHANS case studies. This project will accelerate the emergence of new global workflows in land change science through GLOBE: an online collaboration environment combining quantitative real-time global relevance assessment, geovisualization, social-computational structures and machine learning algorithms. This will be accomplished in collaboration with international LCS institutions and experts, enabling researchers and institutions to rapidly share, compare, and synthesize local and regional studies by combining these with global datasets for human and environmental variables using a combination of machine learning, advanced visualization, semantic analysis and social networking. <br\/><br\/>The project has four core objectives that will be achieved through three integrated activities, as follows: <br\/><br\/>Objective 1: Create an online collaboration environment leveraging real-time global relevance analysis, geovisualization and social-computational knowledge generation towards the generation and sharing of new global workflows for land change science.<br\/>Objective 2: Understand how to build effective social media tools organized around structured and informal scientific workflows.<br\/>Objective 3: Develop evaluation methods and metrics and use them to demonstrate the utility of workflow-based social media tools in the context of scientists testing LCS hypotheses.<br\/>Objective 4: Leverage GLOBE to characterize and optimize global knowledge generation in LCS.<br\/><br\/>To achieve these goals, this team will engage in the following activities:<br\/><br\/>Activity 1: Develop the social-computational infrastructure for GLOBE.<br\/>Activity 2: Establish GLOBE as a means for social-computational knowledge generation. Characterize, share and optimize knowledge generation workflows for global synthesis and collaboration across CHANS studies and data collections.<br\/>Activity 3: Test hypotheses and identify new research opportunities.<br\/><br\/>To understand anthropogenic global changes in the Earth system, scientists must generalize globally from observations made locally and regionally. This project will make fundamental hypotheses on the nature of human interactions with earth systems more readily testable by scientific methods, enabling major advances in land-change science and theory. Moreover, this project will engage the computing and social sciences in developing interactive online tools for scientific collaboration and data synthesis that will help identify knowledge gaps in LCS science. The tools will result in new ways of visualizing, communicating, connecting, comparing and synthesizing observations and models of land change processes at global, regional and local scales. Empirical investigation of GLOBE in use will advance our understanding of scientific collaboration more generally.<br\/><br\/>Broader impacts<br\/>This project will develop, enhance and support long-term research collaborations across a broad set of scientific disciplines. It will support education and skill building for interdisciplinary collaboration by seasoned faculty, postdoctoral researchers, graduate students and undergraduate students. The project will design, host and disseminate advanced tools for cross-scale data and knowledge sharing, synthesis, and design of globally representative observing systems. By creating a new environment for sharing and integrating local knowledge, data and ideas across the social, biological and geophysical sciences, land change science will have greater potential to inform the sustainable stewardship of earth systems.","title":"CDI-Type II: GLOBE: Evolving New Global Workflows for Land Change Science","awardID":"1125210","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["518236","264837","501035","563576","507476"],"PO":["551712"]},"181427":{"abstract":"We develop novel and provably stable polynomial time solutions for solving the recursive robust principal component analysis (PCA) problem. Here, \"robust\" refers to robustness to both independent and correlated sparse outliers. The goal of PCA is to find the principal component (PC) space, which is the minimum-dimension subspace that spans (or, in practice, approximately spans) a given dataset. Computing the PCs in the presence of outliers is called robust PCA. If the PC space changes over time, there is a need to update the PCs. Doing this recursively is referred to as recursive robust PCA. Key potential applications include automatic foreground extraction from similar-looking backgrounds in video; sensor-network-based detection and tracking of abnormal events such as forest fires; online detection of brain activation patterns from functional MRI sequences; and speech\/audio extraction from large but correlated background noise.<br\/><br\/>The key idea is to reformulate this as a problem of recursively recovering a time sequence of sparse signals in the presence of large but correlated noise. The noise must be correlated enough to have an approximately low rank covariance matrix that is either constant or changes slowly. The change in the support of the sparse signal sequences may or may not be slow, but it is highly correlated; e.g. the support can move, expand or deform over time. We ask the following practically relevant questions about performance guarantees of the proposed algorithms. (a) Under what conditions can we prove exact recovery? (b) When can be obtain time-invariant and small error bounds (i.e., show stability)? <br\/><br\/>The research will be included in the curriculum at various levels and in undergraduate senior design and summer research projects.","title":"CIF: Small: Recursive Robust Principal Components' Analyis (PCA)","awardID":"1117125","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[486105,"486306"],"PO":["564898"]},"180338":{"abstract":"Using the global female Muslim blogosphere, this research aims to understand the complexity of cyber-collective action and factors contributing to its success or failure. Despite the exponential growth of Internet users in Muslim countries, there is a lack of empirical study of socio-political uses of the technology for expressing opinions and mobilizing individuals in these countries. The female Muslim blogosphere was selected as a test-bed for two reasons: First, while research shows that three of four females online are active social media users, very little research attempts to understand social, cultural and political roles of female bloggers and collectivity among female social groups. Second, the domain epitomizes an important contrast deserving attention, between socio-political systems where women are frequently denied freedom of expression and active political uses of social media by female Internet users. Female Muslim bloggers find the blogosphere as a digital recourse to exercise their freedom of speech if compared to their physical and repressively controlled spaces.<br\/><br\/>This longitudinal study will develop the theoretical underpinnings and experimental tools to examine the factors that govern the success and failure of cyber-collective movements more generally. It will develop novel algorithms modeling cyber-collective movements by utilizing existing social theories on collective action and computational social network analysis and basing the analysis upon three central tenets of individual, community, and transnational perspectives. Essential questions to be addressed in this study are: What transforms individual sentiments into collective sentiments? What are the dynamics of various socio-cultural dimensions in the evolution of opinion leaders? What social or organizational factors help transcend the nation-state barriers? Several independent validation strategies will be investigated, including monitoring the manifestation of cyber-collective movements as physical social movements, human evaluation, and crowdsourcing initiatives to bridge the gap between qualitative and quantitative evaluation measures.<br\/><br\/>The lessons learned from this research will create greater synergies between social science and computational science. Data collected from this research will be made publicly available due to its efficacy for various interdisciplinary research endeavors, especially in human-computer interaction, game theory, political communication, social network analysis and mining, and social computing, among others. Members of underrepresented groups, especially female bloggers will play an essential role in the project, lending insights into the idiosyncrasies of their socio-technical behavior advancing our understanding of the female demographics, thus making a significant impact on society at large. Educational impacts include the creation of much-needed interdisciplinary courses and training undergraduate, graduate and doctoral students by involving them at all stages of the research.","title":"Collaborative Research: Cyber-Collective Movements: Novel Socio-Computational Approaches in Studying the Blogosphere","awardID":"1110868","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["520192",483279],"PO":["564456"]},"184705":{"abstract":"Cyber-physical systems regulating critical infrastructures, such as electrical grids and water networks, are increasingly geographically distributed, necessitating communication between remote sensors, actuators and controllers. The combination of networked computational and physical subsystems leads to new security vulnerabilities that adversaries can exploit with devastating consequences. A synchronized attack on the interdependent network components and physical plants can create complex and new security vulnerabilities that cannot be addressed by securing the constituent systems individually.<br\/><br\/>This project takes a holistic view by utilizing the properties of physical systems to design new secure protocols and architectures for cyber-physical systems (CPS) through a unified conceptual framework, which uses models for the physical system and the communication\/computation network to define precise attack models and vulnerabilities. These mathematical models are used to design algorithms and protocols with provable operational security guarantees, thus enabling the design of more trustworthy architectures and components. The algorithms, protocols, and architectures are validated on CPS testbeds targeting building, automobile, and smart-grid applications. Additionally, the research is being integrated into the curriculum via the creation of novel coursework combining the underlying control, information theory, cryptography, and embedded system concepts.<br\/><br\/>By improving the protection of critical cyber-physical infrastructure against emerging threats, this research is expected to provide direct socio-economic benefits, ranging from individual organizations to a national scale. The inter-disciplinary team of this project will integrate teaching and curriculum development with the research, contributing to the training of a new generation of engineers well versed in the design of trustworthy cyber-physical systems.","title":"CPS:Medium:Foundations of Secure Cyber Physical Systems","awardID":"1136174","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521734","551137","515835","526859","533831"],"PO":["564778"]},"182659":{"abstract":"1123982<br\/>Sheaff<br\/><br\/>This Pan-American Advanced Studies Institutes (PASI) award, jointly supported by the NSF and the Department of Energy (DOE), will take place March 5-16, 2012 at the Universidad de Buenos Aires (UBA) in Buenos Aires, Argentina. Organized by Dr. Marleigh Sheaff of the University of Wisconsin-Madison, Dr. Marcela Carena of the University of Chicago, and Dr. Daniel Chung of the University of Michigan, the institute will focus on the exploration of the Terascale, covering topics in particle physics, cosmology, and astrophysics. The program will give students a broad picture of the three frontiers along which particle physics must advance to solve some of the crucial mysteries of our universe such as: the origin of mass, the nature of the dark matter, the generation of the matter-antimatter asymmetry, and the possible unification of forces. The three frontiers have been identified as the Energy Frontier, the Intensity Frontier and the Cosmic Frontier. The PASI will also explore how current and planned future experiments in physics will advance our understanding of these frontiers.<br\/><br\/>Participation of young U.S. physicists along with their peers from a number of other countries in the Americas will provide them with international experience early-on in their careers. This will help them prepare for the large global collaborations that involve people from very diverse backgrounds, which have now become frequent in these areas. The organizers will develop and widely advertise web pages to disseminate the materials presented at the institute to the wider community.","title":"PASI2012 - Exploring the Terascale and Beyond; Buenos Aires, Argentina; March 5-16, 2012","awardID":"1123982","effectiveDate":"2011-09-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"KX13","name":"Department of Energy Chicago O"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"KX14","name":"Department of Energy Chicago O"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560342",489369,489370],"PO":["531406"]},"181449":{"abstract":"This proposal explores a robust quantum cryptography protocol for securing optical burst switching (OBS) networks, providing a means to make the OBS-based future Internet trustworthy from the ground up. Since the OBS network has a one-to-one correspondence between the header and its associated burst, the same relationship can be exploited for encryption. The quantum-based methodology makes it possible to distribute keys securely so that each burst is encrypted and decrypted with a unique key. As the well-known BB84 quantum cryptography protocol is susceptible to siphoning attacks on the multiple photons emitted by practical sources, we use a new 3-stage quantum cryptography protocol which is immune to such siphoning attacks, for it is based on random rotations of the polarization vector. The new 3-stage quantum cryptography protocol allows practical photon sources to be used in the quantum key exchange, making it feasible to extend quantum cryptography services beyond trusted routers. The 3-stage all quantum protocol is being investigated for its performance in different noise situations for different key generation rates. The implementation of the protocol uses quantum phase modulation rather than polarization modulation which is not stable in the long transmission over fiber. The research conducted in this proposal includes the design of an integrated secure router and investigation of quantum cryptography protocols for specific services. This research will be verified on a reconfigurable optical burst switching test bed.","title":"TC: Small: Collaborative Research: Exploring a Robust Quantum Cryptography Protocol for Securing Optical Burst Switching Networks","awardID":"1117179","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[486156],"PO":["565327"]},"186916":{"abstract":"Real-world social events provide a convenient and intuitive way to organize social media content for individuals. Current approaches to event detection from social media: assume that the events to be monitored (and their social media signatures) are known a priori; focus largely on text data and fail to take advantage of other forms of media e.g., images. <br\/><br\/>Against this background, this project explores a novel approach to discovering spontaneous, a priori unspecified, social events through joint Bayesian non parametric modeling of multi-modal data (including text and images) and using the events thus discovered to foster new social links. The resulting tools for event discovery will be tested in an application involving discovery of wild animal disease outbreaks from twitter text messages and images posted by individuals. <br\/><br\/>The project brings together an interdisciplinary team of researchers with expertise in image analysis, text mining, and machine learning to advance the state of the art in detection of spontaneous, a priori unspecified events (as they emerge) from social media data. It is expected to yield new scalable nonparametric Bayesian approaches to joint modeling of image and text data, and more generally multi-modal social media data. The resulting tools could potentially transform the way in which people use social media data by empowering them to discover and participate in real world events even as they emerge.","title":"III: EAGER: Discovering Spontaneous Social Events","awardID":"1148012","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[501477,"560208"],"PO":["565136"]},"181229":{"abstract":"SHB: Small: Cell Phone-Based Activity Monitoring for Telehealth<br\/><br\/>Abstract<br\/><br\/>Contemporary smart cell phones contain a tri-axial accelerometer, which makes it possible to measure the acceleration of a smart phone user in all three spatial dimensions. Modern data mining methods permit the construction of an activity recognition classifier from this acceleration data, so that a user's physical activity (e.g., walking, jogging, standing, etc.) can be automatically inferred from the accelerometer values. This research project will build an activity recognition system that can be deployed as a downloadable cell phone application. Users will then be able to access a description of their activities via a web interface and can use this information to monitor and change their behavior. Thus this research can be used to address the many health-related problems that result from physical inactivity. It can also assist with other health-related problem, such as falling in the elderly, by detecting falls and providing automatic notification to caregivers. The data generated via the cell phone activity recognition system will also enable large scale epidemiological studies of activity levels and health that, due to prohibitive costs, were not previously possible.<br\/><br\/>Building a successful activity recognition system will require addressing many technical challenges. This research will require improved feature construction methods for transforming time-series data into representations suitable for example-oriented classification algorithms. It will also require the evaluation of alternate architectures for performing wide-scale real-time data mining, in order to determine how much of the activity recognition work should be performed on the client (i.e., smart phone) versus a centralized server. The adequacy of smart cell phones for performing reliable activity recognition will also be evaluated given the many constraints (e.g., limited battery life) imposed by these devices.","title":"SHB: Small: Cell Phone-Based Activity Tracking for Telehealth","awardID":"1116124","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[485627,485628],"PO":["564898"]},"192912":{"abstract":"Abstract<br\/><br\/>Title: CAREER: Object Recognition with Hierarchical Models<br\/><br\/>PI: Pedro Felzenszwalb<br\/><br\/>Institution: University of Chicago<br\/><br\/>CAREER: Object Recognition with Hierarchical Models<br\/><br\/>Object recognition is one of the most important problems in computer vision. While researchers have worked on this problem for over thirty years, vision systems are still unable to recognize many common objects in cluttered images. The PI proposes to address this problem by developing new hierarchical models and efficient search algorithms for recognition.<br\/><br\/>Hierarchical models represent objects using parts which are themselves defined in terms of subparts. Moreover, the subparts may be recursively defined in terms of smaller components. This hierarchical organization can efficiently encode important relationships among the components that make up an object. Another important property of hierarchical models is that components can be shared among different object models. This is useful for being able to quickly recognize which of many possible objects are present in an image. It is also important for learning models from small datasets. Finally, in the most general types of models the structure of an object may be specified by a grammar instead of being fixed in advance. The number of parts that make up an object may be variable and there may be choice among different parts that can go in a particular place. All of these aspects make hierarchical models incredibly expressive.<br\/><br\/>Algorithms for object recognition typically search over large spaces encoding the pose of an object, or over correspondences between model features and features extracted from an image. The PI will develop efficient optimization algorithms for solving these problems. This will be accomplished by exploiting the structure of the search spaces defined by general classes of hierarchical models.<br\/><br\/>Broader significance and importance: Object recognition has many important practical applications, including in robotics, human-computer interaction, image retrieval, security systems and medical image analysis. Research in object recognition can also play an important role in our understanding of human perception and <br\/>intelligence. The proposed research will draw upon ideas from diverse areas such as computer vision, theoretical computer science, natural language understanding and mathematics.<br\/><br\/>URL: http:\/\/people.cs.uchicago.edu\/~pff\/hierarchical","title":"CAREER: Object Recognition with Hierarchical Models","awardID":"1215812","effectiveDate":"2011-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[516805],"PO":["564316"]},"181516":{"abstract":"This research addresses the theory and design of algorithms for an efficient local computation by multiple network terminals of shared functions of all their observed correlated data. Efficient communication among the terminals facilitates efficient computation. Applications include: computing the average, variance, maximum, minimum and parity of observed data in a colocated network of wireless sensors that make correlated measurements. This objective is connected closely to the design of algorithms for the efficient compression of data for storage and transmission purposes, as well as of algorithms for assuring data security. A main goal of the project is to characterize explicitly these connections, thereby leading to the development of new and efficient algorithms for data compression, function computation and network security.<br\/><br\/>The technical approach involves a formulation of the underlying problems and their analysis, using an information theoretic framework. This will enable the development of a principle of \"entropy decomposition of total shared randomness\" in a network model to address difficult problems in multiuser information theory of which rate-efficient function computation is a leading example. In particular, an application of source coding algorithms in distributed function computation will be studied. Specific groups of open problems chosen for investigation address a general class of multiterminal models for function computation and data compression. This choice is motivated by, and is of compelling interest to, the theory and engineering practice of network function computation and source coding, as well as network security.","title":"CIF: Small: Distributed Function Computation and Multiterminal Data Compression","awardID":"1117546","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["561385"],"PO":["564924"]},"181307":{"abstract":"Time series analysis is central to the study of computer vision, signal processing, computer graphics, machine learning, and social sciences, among other fields. This project entails original contributions towards algorithms for unsupervised pattern discovery and temporal alignment of time series, and its applications to model human motion. In particular, the PI proposes three new methods: (1) a discriminative temporal clustering that factorizes a set of time series into segments belonging to one of k temporal clusters, (2) a method for discovering the set of most discriminative segments between two sets of time series, and (3) an unsupervised algorithm for temporally aligning multi-modal time series. The PI proposes an energy minimization framework to encompass these three problems. This framework should provide researchers with a thorough understanding of a large number of existing time series techniques, and it may serve as a tool for dealing with other problems in time series as they arise.<br\/><br\/>Enabling computers to understand human behavior has the potential to revolutionize many areas that benefit society such as clinical diagnosis, human computer interaction, and social robotics. Advances in time series to model human actions and events from sensory data have been critical to the success of systems that can recognize and characterize human behavior. However, most existing algorithms have been supervised in nature. Supervised learning typically requires large amounts of human annotation, that is typically labor intensive and is difficult to standardize across coders. In this proposal the PI explores the use of unsupervised learning techniques for aligning and discovering patterns in time series of human motion that have been captured with accelerometers, video or motion capture technologies. The PI will show how the proposed algorithms outperform state-of-the-art techniques in several human sensing tasks such as temporal alignment of human motion, temporal clustering of human activities from video, learning motion primitives, and joint segmentation and classification of human behavior. In the educational aspect, the PI will continue to provide support to the Carnegie Science Center to demonstrate human sensing technologies, as well as incorporate a large number of undergraduates in his research. The research source code will be made available to the scientific community.","title":"RI: Small: Clustering, Classification and Alignment of Time Series for Human Sensing","awardID":"1116583","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[485815],"PO":["562760"]},"181428":{"abstract":"There has been no shortage of headline news on Internet access pricing in 2010 and 2011. From AT&T and Verizon shifting to usage-based pricing for wireless access to FCC's revealing the National Broadband Plan, and from Comcast-Netflix\/Level3 battle on two-sided pricing to FCC's 2010 December statement on pricing innovations, the Internet is witnessing the start of a transformative period in the interplay between access pricing and the technology of networking. <br\/><br\/>The technical core of this project is organized around four fundamental questions: (1) How much to charge? The debate between flat-rate and usage-based pricing renews with fresh perspectives. (2) How to charge? Should the price charged depend on the time of bandwidth consumption or congestion condition of the network? (3) Whom to charge? When will content\/application producers find incentives to pay for higher data rate or heavier bandwidth consumption by consumers? (4) What to charge? What kind of new service classes can be invented, especially in heterogeneous wireless networks with multiple platforms co-existing? <br\/><br\/>The unique features of this project include extensive participation from diverse sectors in the networking industry, implementation of prototypes and trials, and access to and dissemination of data. It combines the collection of fresh, large-volume of empirical data with rigorous design and prototype implementation. The project goes all the way from data analysis through optimization algorithms, to proof-of-concept demos and trials, eventually to practical impact on public policy and ISP business decisions, thus closing the loop in the study of network pricing.<br\/><br\/>Intellectual Merits: While we sharpen and apply a variety of tools from optimization theory, microeconomics, game theory, and statistics, the challenges arising out of these social issues also demand the development of new methodologies, such as supply chain contracts for multi-platform, two-sided pricing with conflicting interests of content providers and Internet service providers (ISPs). Furthermore, the interactions between technology evolution and economic policies are mutual: new enabling technologies such as femtocell raises new questions on the interaction between engineering artifacts and pricing structures.<br\/><br\/>Broader Impacts: The proposal is driven by timely and important questions faced by policy-makers, networking industry, and broadband consumers: (1) Who will pay for the estimated cost of $350B in the next decade to enable universal coverage of broadband services in this country? (2) Can pricing mechanisms be leveraged by the ISP as a practical approach to network management and new service class be created that is net-neutrality compatible? (3) How to regulate the nonstop surge of bandwidth demand to create win-win for both the ISPs and consumers? Furthermore, the project presents unique opportunities for undergraduate curriculum development, extensive industry participation and impact, and unconventional community outreach, both within US and across the world.","title":"NeTS: Small: Innovating Internet Access Pricing: From Theory to Deployment","awardID":"1117126","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["561963"],"PO":["565090"]},"182759":{"abstract":"Investigators from Rice University and Duke University will build a Personalized Cyberlearning System, designed around three principles from cognitive science (retrieval practice, spacing, and enhanced feedback), that leverages advances in machine learning and makes use of an existing instructional content material and problem set database aimed at undergraduate engineering students. The system will use artificial intelligence methods to optimize practice and feedback for students. Research will seek to advance knowledge, in a real-world setting, about a range of issues concerning how feedback facilitates learning, how individual differences come in to play, as well as those more specifically aimed at the development of the learning technology system itself.<br\/><br\/>The project is important as part of the effort to harness the vast quantities of information on the web to personalize instruction for a wide range of learners. Moreover, the development of such cyberlearning technologies holds promise for opening up STEM education for motivated self-learners while also allowing access to a large volume of material for a range of students who might not otherwise have it.","title":"DIP: Collaborative Research: A Personalized Cyberlearning System Based on Cognitive Science","awardID":"1124535","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":["142498",489657,"565263","497441",489660],"PO":["562669"]},"181549":{"abstract":"Balance disorders are a common problem following stroke, and the restoration of balance represents a key return to normalcy that can make the critical difference between returning home and remaining in long-term care. Current balance rehabilitation practice in the acute phase of recovery, however, is often driven by subjective feedback and experience, rather than by objective observation\/analysis because of cost and time constraints. This study plans to investigate how gaming peripherals can be used as an inexpensive means to enhance balance rehabilitation by providing real-time, quantitative visual feedback to both the patient and the therapist. Specifically, the project is planning to 1) develop a low-cost instrumentation and visualization platform centered around the Nintendo Wii Balance Board, 2) use this platform to quantify the effects of visual feedback on both patients and therapists during balance retraining, and 3) develop the ability to predict patient functional outcomes in real time from data collected during typical rehabilitation activities. The effort includes the development of a clinically appropriate control interface and quantification of the performance of a system consisting of multiple Wii Balance Boards, multiple web cams, and other devices to provide real-time visual feedback based on fused data from all of these sources. <br\/><br\/>Balance recovery is assessed between matched groups who receive therapy with and without feedback. Comparisons of self-awareness in the same groups is used to examine the role of feedback in developing a patient?s metacognitive knowledge. Therapists? interaction styles and treatment plans are compared between the groups to identify the effects of the feedback on their work. Finally, the investigators plan to identify which instrumented activities provide data that best predict a patient?s score on established functional assessment tools. Ultimately, this project seeks to enhance quality of life post-stroke by helping to optimize therapy during the acute phase, which is the most critical stage of recovery. The results will also be directly applicable to balance rehabilitation in chronic stroke and other neurotrauma and more broadly applicable to amputees and sports medicine patients. Most critically, the low cost of the instrumentation platform is designed to remove financial adoption barriers, allowing virtually any rehabilitation facility to leverage the results of the research.","title":"SHB: Small: Use of Gaming Peripherals in Acute Rehabilitation of Balance Following Stroke","awardID":"1117706","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[486414,"524608","540626"],"PO":["564768"]},"182528":{"abstract":"Proposal #: 11-23220<br\/>PI(s): Xu, Dianxiang; Pauli, Joshua; Tu, Michael<br\/>Institution: Dakota State University<br\/>Title: MRI\/Acq.: Online Banking System for Information Assurance Research<br\/>Project Proposed:<br\/>This project from an EPSCoR state, aiming to acquire hardware and software to create a banking testbed to explore issues of computer security of banking systems, enhances the future of security research for the global banking infrastructure. While online banking makes it more convenient to manage financial activities, security threats are becoming even greater because the money is stored on and moved around an untrustworthy Internet environment with increasing use of mobile, wireless devices. The proposed acquisition will enable various activities for promoting information assurance research and education in the banking sector. The proposed online banking system for South Dakota enables the following research projects in security:<br\/>- Threat modeling and verification, aiming at a rigorous techniques with proof \/disproof capability,<br\/>- Security testing, aiming at cost-effective, automated security testing with threat models,<br\/>- Forensic readiness, aiming at better investigation of intrusions and frauds, and<br\/>- Security requirements analysis, aiming at consistent and testable specification.<br\/>The work establishes a flexible research instrument for a key element of the nation?s financial infrastructure. The research enabled by the online banking system will lead to novel techniques for the defense, in-depth, of online banking applications.<br\/>Broader Impacts: <br\/>This instrumentation increases DSU?s capacity to conduct cutting-edge research on online banking security. The online banking system expands critical infrastructure in the new National Center for the Protection of the Financial Infrastructure. It also broadens the participation of students in research by providing a rich variety of research topics for the NSF REU (Research Experience for Undergraduate) Site in Information Assurance and Security, which places emphasis on recruitment of minority students. In terms of training the next generation workforce, far-reaching impacts are envisioned through improvements to the information assurance curriculum. The proposed system will be used to teach cyber security in computer classes at eight high schools through collaboration with the NSF project ?GK-12 Fellows in Cyber Security?. Two of these schools serve mainly Native-Americans. Finally, the instrument enhances PhD production in an EPSCoR state and solidifies DSU?s position in online banking research.","title":"MRI: Acquisition of an Online Banking System for Information Assurance Research","awardID":"1123220","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["564245",489023,"548797",489025],"PO":["543539"]},"181318":{"abstract":"Over the past five years, the network neutrality debate involving for-profit ISPs and \"content\" providers, together with security-related issues, has figured most prominently in the Western media's coverage of the Internet and in government regulatory hearings in both North America and Europe. The two principal issues have to do with equitable treatment of applications (application neutrality) and side payments between independent content and service providers.<br\/><br\/>The four research thrusts of this grant are: the development of unbiased, parsimonious models of macro-economic and networking dynamics of all parties involved; analyzing these models with an aim to assess the relative benefit of different pricing regimes, provider alliances, and service-differentiation strategies; acquiring current, real-world data and practical lessons-learned to inform these models; and focusing in particular on comparing neutral to non-neutral frameworks.<br\/><br\/>In a preliminary example study, a passive model of end-user demand was used to define a game between multiple ISPs and multiple content providers. The users could engage in two types of applications: one delay sensitive, the other throughput sensitive. The fraction of users engaged with a particular provider depended on the provider?s current prices, subject to a customer inertia model when competitors? prices were close. A regulated side-payment between providers of different types was considered. A surprising finding at stable Nash equilibrium was that monopolistic providers (say a single ISP) receiving side payments actually had less income than the 'neutral' scenario without side-payments (side payments result in increased end-user prices by the payee which lowers end-user demand). Revenues from the application types which consumed the most bandwidth were naturally affected the most.<br\/><br\/>The primary intellectual merit of this research has to do with the challenge of formulating tractable though realistic mathematical models of the cross-disciplinary elements of the macroscopic interactions among different entities participating in the Internet economy. Identified near-optimal strategies are tracked in the presence of naturally time-varying system parameters. Though a model may be simple, it often yields unexpectedly complex behavior (e.g., multiple Nash equilibria with differing stability qualities). Important real-world data and practical lessons will be identified in this research through the study of sensitivity of derived results to the different model parameters in play.<br\/><br\/>One aspect of the broader impact of this research pertains to the enormous financial stakes involved in the network neutrality debate, and therefore the potential of this research to influence significantly Internet operations and architectural development even in the near term. Industry outreach is a significant part of this research, not only to keep abreast of current developments, but also to obtain first-hand relevant data that hopefully can be disseminated to the broader research community. Another aspect of the broader impact of this research is the development and dissemination of related \"economics\" teaching modules suitable for networking graduate courses, and the recruitment and training of students from under-represented minority groups in Computer Science and Electrical and Computer Engineering.","title":"NeTs: Small: Collaborative Research: Inter-provider dynamics in neutral and non-neutral networks","awardID":"1116626","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["562302"],"PO":["564993"]},"181439":{"abstract":"Routing is arguably the most fundamental aspect of networking, since it answers the basic question: how do you place the appropriate state in routers or switches so that packets can travel from source to destination? There is a huge literature on routing, covering many topics (intradomain and interdomain, wireline and wireless, convergence and policy oscillations, etc.), and the router vendors have been honing their routing implementations for many years. After all this academic and commercial work, one might expect that there would be little new of fundamental importance to say about routing, and that all current work would involve small, incremental improvements to algorithms and implementations.<br\/><br\/>However, there are two conflicting trends that are changing the context in which routing is being used, and which necessitate a new round of routing research:<br\/><br\/>Reliability requirements: Because networks are being increasingly used for critical services (hospitals, financial institutions, etc.), the reliability expectations for networks are becoming more stringent i.e., 'five nines' of reliability). Routing is responsible for directing traffic around failures (i.e., failure recovery) and avoiding hotspots (i.e., load distribution), so the required increases in reliability must come from improving the failure recovery and load distribution mechanisms embedded in routing protocols.<br\/><br\/>Network size: Networks are growing at a rapid pace, and a new class of networks - datacenters, which can have hundreds of thousands of hosts and millions of VMs - are pushing the scaling limits as never before. In all routing algorithms, because they are essentially distributed consistency algorithms, the convergence times (for responding to failures and hotspots) and\/or the routing overhead (in terms of the number and size of routing messages) increase with size.<br\/><br\/>The upshot of these two developments is that routing algorithms are being asked to do a better job (in terms of reliability) on a harder task (because of the increases in network size and complexity). As a result, both the commercial world and the academic community have embarked on a new round of routing research. These efforts first produced several ad hoc rerouting methods (such as MPLS Fast Reroute and ECMP) and then concentrated on developing multipath routing methods (such as Path Splicing and a variety of other approaches). However, all of these developments are retrofitted on top of the traditional approach to routing, which builds a single path from the source to the destination. These mechanisms significantly improve the reliability of networking, but they do not tell us how to incorporate more effective failure recovery and load distribution into the core foundation of routing algorithms.<br\/><br\/>More recently, we (along with others) have proposed a new routing paradigm, one that changes the basic output of routing from a path to a directed acyclic graph (DAG). This new approach, which here will be called Routing Along DAGs (RAD), automatically provides multiple paths for local failure recovery and load distribution. This allows RAD to, without any global route recomputations in response to failures or hotspots, guarantee connectivity (as long as the graph is connected) and provide optimal load distribution (in a simple single-destination traffic model). This project is investigating the RAD approach from many angles: design, simulation, implementation, and theory. The goal is to have a put this new routing paradigm on a firm scientific footing.<br\/><br\/>Broader Impacts: There is a pressing commercial and governmental need for increased reliability and easy-to-manage routing algorithms. This proposed project will produce prototypes of new routing and traffic engineering approaches built on commercial routing hardware (using the OpenFlow interface) that could be used to test these ideas in commercial settings. This could have a significant impact on how datacenter networking is done, and more generally improve network reliability. Promising preliminary discussions have already been held with router vendors in this regard.","title":"NeTS: Small: New Directions in Routing and Traffic Engineering","awardID":"1117161","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560562"],"PO":["565090"]},"185707":{"abstract":"Social networks link behavioral and social activities with a myriad of infrastructural networks that support relationships between individuals. These infrastructural networks include the Internet, telephone systems and transportation networks, all of which are in turn tied to power and fuel-supply networks, such as electricity grids. Social networks play a powerful shaping role on underlying infrastructural networks, placing great demands on their capacity and helping determine how they evolve through use. <br\/><br\/>An initial set of analyses suggests that there are significant opportunities for improving energy use by analyzing and optimizing the energy required to build and sustain social networks. This project seeks to quantify the energy requirements of social networks and identify strategies for optimizing their energy use by: assessing the ecology of technologies used in social networks through surveys and crowdsourced data; modeling and empirically measuring the power consumed in communication technologies; and developing a social sustainability composite indicator that will be integrated into a tool to help users make more sustainable choices. <br\/><br\/>Intellectual Merit This project will lead to an improved understanding of the behavior and dynamics of complex, socio-technical networks so that future networks can be better designed. The project seeks to build an understanding of how different communication technologies are used together in social networks and to use this model to address how energy use accumulates in technical networks that support relationships. Finally, the project seeks to link large-scale problems with the actions and behaviors of individuals, which is critical for promoting behavioral change. <br\/><br\/>Broader Impacts The questions answered in this project are critical to informed optimization and innovation of energy use in the context of social networks and social life. A better understanding of the energy cost of social networks and social computing technologies promises to have impact in climate change, information technology for development and operational efficiency. Additionally, the project?s findings will be distributed through a number of national programs for training and curriculum development.","title":"EAGER: GreenSC: Characterizing and Modeling Energy Use in Social Computing","awardID":"1141517","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[498457,498458],"PO":["564456"]},"180505":{"abstract":"How does a vision system recover the 3-dimensional structure of the world -- such as the layout of the environment, surface shape, or object motion -- from the dynamic 2-dimensional images received by the sensors in a camera, or the retinas in our eyes? This problem is fundamental to both computer and biological vision. Computer vision has developed a variety of algorithms for estimating specific aspects of a scene such as the 3-dimensional positions of points whose correspondence over time can be established, but obtaining complete and robust scene representations for complex natural scenes and viewing conditions remains a challenge. Biological vision systems have evolved impressive capabilities that suggest they have detailed and robust representations of the 3-dimensional world, but the neural representations that subserve this are poorly understood and neurophysiological studies thus far have provided little insight into the computational process. This project will pursue an interdisciplinary approach by attempting the understand the universal principles that lie at the heart of 3-dimensional scene analysis.<br\/><br\/>Specifically, the project will 1) develop a novel class of computational models that recover and represent 3-dimensional scene information, 2) collect high quality video and range data of dynamic natural scenes under a variety of controlled motion conditions, and 3) test the perceptual implications of these models in psychophysical experiments. The computational models will utilize non-linear decomposition - i.e., the ability to explain complex, time-varying images in terms of the non-linear interaction of multiple factors, such as the interaction between observer motion, the 3-dimensional scene layout, and surface patterns. Importantly, the components of these models will be adapted to the statistics of natural motion patterns that arise from observer motion through natural scenes and movement around points of fixation.<br\/><br\/>The project is a collaboration between three laboratories that have played a leading role in developing theoretical models of natural image statistics, visual neural representations, and perceptual processes. The investigators seek to combine their efforts to develop new models, data sets, and characterizations of 3-dimensional natural scene structure that go beyond previous studies of natural image statistics, and that can be tested in neurophysiological and psychophysical experiments. This project has the potential to bring about fundamental advances in neuroscience, visual perception, and computer vision by developing new classes of models that robustly infer representations of the 3-dimensional natural environment. It will create a set of high quality databases that will be made available to help other investigators study these issues. It will also open up new possibilities for generating realistic stimuli that can guide novel investigations of neural representation and processing.","title":"RI: Large: Collaborative Research: 3D Structure and Motion in Dynamic Natural Scenes","awardID":"1111654","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[483749],"PO":["564318"]},"181605":{"abstract":"How do ant colonies, bee hives, and markets function even when there is no leader? A starting point for answering this question is the fundamental problem of agreement in distributed computing: Byzantine agreement. The Byzantine agreement problem is to devise a protocol so that a group of agents, each with a private input can agree on a single common output that is equal to some agent's input. The problem is complicated by the fact that an unknown subset of the agents suffer Byzantine faults: they can engage in arbitrary deviations from the protocol, including false messages and collusion. Byzantine agreement has found applications in many areas, including peer-to-peer systems, database systems, control systems, grid computing, cloud computing and game theory. Unfortunately, continued application is hampered by a stark barrier: there is no practical, scalable algorithm for Byzantine agreement. In particular, all current Byzantine agreement algorithms require all-to-all communication: each agent must talk with every other agent.<br\/><br\/>This research will directly address this barrier by designing scalable algorithms for Byzantine agreement and other related problems. Our goal is to design algorithms that are scalable in the sense that each agent sends a number of bits that is O(sqrt(n) log n), and total latency is O(log n), where n is the number of processors; and robust in the sense that they can tolerate up to a constant fraction of Byzantine faults. In addition to Byzantine agreement, we will design scalable and robust algorithms for the following three related problems. First, Subcommittee Election: All processors agree on one or more subcommittees of size O(log n), where the fraction of bad processors in each subcommittee is within epsilon of the fraction of bad processors in the network, for any positive epsilon. Second, MapReduce: Enable the MapReduce software framework, even when there is no master. Finally, Robust Multiparty Computation: Each processor starts with a private input and there is a publicly known function F on n variables; the goal is for all users to learn the output of F at the point given by the private inputs. The long-term vision is to develop a technique, based on Byzantine agreement, that is on par with techniques like cryptography and error-correcting codes by 1) being frequently used in practice and applicable across a wide range of applications; and 2) having a clean interface between theory and practice.","title":"Computing without a Leader: Building Blocks for Internet-Scale, Robust Computing","awardID":"1117985","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["551090"],"PO":["565251"]},"181616":{"abstract":"This project addresses optimizing energy efficiency in the execution of parallel algorithms.<br\/><br\/>High energy cost is a salient constraint when running large scale parallel applications on the next generation of supercomputers that contain heterogeneous multicore processors and interconnections, motivating a rethinking of conventional approaches to modeling, designing and scheduling parallel tasks by taking energy-efficiency into consideration. <br\/><br\/>In this collaborative research, this team explores energy-efficient parallel task design, scheduling, and implementation and develops an power profiling tool (PowerPack) that can measure decomposed runtime power consumption of different computing components (e.g. processors, memory, networks and disks) when running large scale parallel applications.<br\/><br\/>The results of the research will be widely disseminated by maintaining an active project website, publishing peer-reviewed journal and conference papers, making the code available to other researchers, and presenting the research results in professional meetings. The availability of the research outcomes will provide ample opportunities for other researchers to further study the energy-efficiency of parallel applications. Through the collaboration of Texas State University ? San Marcos, Colorado School of Mines, and the Marquette University, PIs promote teaching, learning, and training by exposing graduate and undergraduate students to technological underpinnings in the fields of high performance computing in general and energy-efficient computing in particular. The close partnerships with a number of universities, data centers and national laboratories will also facilitate the broad dissemination of the proposed energy-efficient parallel tasks designing and scheduling techniques as well as the developed power profiling toolkits.","title":"CSR: Small: Collaborative Research: EEDAG: Exploring Energy-Efficient Parallel Tasks Generation and Scheduling for Heterogeneous Multicore Systems","awardID":"1118043","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["543571"],"PO":["551712"]},"180527":{"abstract":"In the face of the vast scale of software-intensive systems needed today, modern development environments fail dramatically, typically leading to information overload, an inability to deal with the highly dynamic nature of both the systems and the organizations that develop them, and failure to support collaboration across organizational boundaries. The overarching aim of this project is to provide a scientific foundation for human-centered environments that make large-scale and distributed project awareness, communication, and coordination as effortless as in a small team. It accomplishes this by (a) performing empirical studies of real-world large-scale high-complexity software projects to understand how task coordination occurs in and contributes to organizational context, (b) developing an underlying theory of coordination in context, which will motivate and guide (c) the design of new coordination technology that explicitly addresses information overload, dynamism, and organizational boundaries. <br\/><br\/>Intellectual merit: The research will result in four contributions: (a) a sound theoretical basis that captures how task coordination and organizational context interplay at scale; (b) theory-driven empirical studies of in-context coordination; (c) knowledge about how to achieve improvements in productivity, quality, and development speed; and (d) a suite of design principles, tool prototypes, and interaction techniques for collaboration at a very large scale. These outcomes will transform the landscape of coordination technology by squarely addressing the issue of scale, moving from coordination within a team to coordination across many developers, across many teams, and across multiple geographical and organizational boundaries.<br\/><br\/>Broader Impacts: As society enters the era of \"ultra large scale\" software-intensive systems, coordination at such scales is a major unsolved problem, persistently hampering development and advances in vital domains such as healthcare, security, defense, eGovernment, and energy. The outcomes of this project will not only provide major economic benefits, but also major societal benefits in the form of the new systems that now can be developed. Through close collaboration with industry partners, the results will quickly find their way into practice. The project will also increase involvement of women in computer science through workshops and mentoring activities.","title":"HCC: Large: Collaborative Research: Large-Scale Human-Centered Coordination Systems to Support Interdependent Tasks in Context","awardID":"1111750","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["561942",483809,"551802"],"PO":["565342"]},"181506":{"abstract":"Intellectual Merit:<br\/>This project addresses scalability of applications on Exascale parallel computer architectures. <br\/><br\/>Among the strategic challenges to scalability is identifying and exploiting new forms of parallelism as well as reducing overhead for effective fine grained parallelism execution. The project, \"Accelerated ParalleX (APX) for Enhanced Scaling\" project investigates combining a new model of computation with FPGA hardware support, in otherwise conventional multicore platforms, to realize significant gains in scalability. This approach is particularly applicable to the important class of adaptive mesh refinement based applications for colliding neutron stars and gamma ray bursts. <br\/><br\/>Prior NSF funding supported the development of an experimental ParalleX prototype. That model is employed in this new research project. This framework extracts inherent parallelism implicit in structure meta-data, eliminates most global barriers, and releases adaptive control to overlap multiple phases of computation and intermediate communication for latency hiding and circumvention of contention hot spots. <br\/><br\/>The research investigates the use of FPGA based hardware technology for accelerating system software to significantly reduce critical time path overhead in execution and directly enhance scalability. The experimental designs include synchronization atomics, thread scheduling and queues, and active message driven operations. In addition, for this class of science problems, higher precision floating-point arithmetic is becoming more important for such science questions as resolving the smallest possible black holes. FPGA technology will therefore accelerate multi-precision floating point arithmetic. <br\/><br\/>This research, if successful, will advance the specific science domain of numerical relativity and, more broadly, those science and engineering disciplines relying on both AMR and strong scaling. It will advance near-term computer system science through an innovative application of available FPGA technology to general computational science and long-term future scalable system design. The performance model derived for this purpose may prove valuable for extended preliminary exploratory investigation for establishing bounds and sensitivities in a complex multi-faceted trade-off space. <br\/><br\/>Broader Impact: <br\/>The APX research results and resources will be applied to the distance-learning course distributed live to other national and international campuses to expand its content and extend its advanced topics section, in the short term, while motivating a new graduate level seminar course next year around its topic areas. Summer internships for under-represented undergraduate and high school students will be created at LSU and the Beowulf Bootcamp will be expanded for more high school students.","title":"CSR: Small: Accelerated ParalleX (APX) for Enhanced Scaling AMR based Science","awardID":"1117470","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["563330","527880"],"PO":["551712"]},"180538":{"abstract":"Today, most urban traffic control is rudimentary: in smaller cities, many traffic signals remain isolated, and while most larger cities have integrated systems of signals, they are still not dynamically timed in response to real-time vehicle information. Congestion fees, which are increasingly popular as a traffic management tool, are usually based on historical traffic data rather than varying dynamically to reflect instantaneous conditions. Recent advances in communication, navigation, and sensor technologies present far more opportunities to increase the intelligence and efficiency of metropolitan streets than are in place today.<br\/><br\/>This project focuses on designing a real-time networked sensing and actuation platform for future 'intelligent' metropolitan traffic management with the aim of simultaneously reducing congestion, pollution, and traveler delays. The pivotal element of the proposed Green City intelligent transport architecture is the ability to 'close the loop' between traffic\/pollution sensing and traffic control; a system achieved through an incentivized collaboration between the central traffic management and the drivers. In this collaboration, the 'intelligent' traffic signals and the on-board navigators play key roles. Traffic signals sense traffic characteristics and vehicular emissions, collect data from vehicle sensors, and broadcast traffic advisories, routings, and restrictions to on-board navigators. The on-board navigators choose optimal routings taking into account drivers' preferences, local perceived traffic, and signal timing. All this is enabled by efficient vehicle to roadway infrastructure communications from 3G channels to DSRC radios.<br\/><br\/>Broader Impact: This project is highly interdisciplinary; it benefits from the collaboration and expertise of computer science, atmospheric science, and urban planning faculty and students. New education opportunities will result from the multidisciplinary nature of the project.","title":"NeTS: Large: Collaborative Research: Closing the loop between traffic\/pollution sensing and vehicle route control using traffic lights and navigators","awardID":"1111811","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":[483835,"486425"],"PO":["565090"]},"181308":{"abstract":"The primary goal of this project is to enable identification and segmentation of specific structures of interest from imaging data (such as DTI MR brain images). These regions may be small and inconspicuous with poor contrast, therefore, direct application of classical unsupervised segmentation (designed to extract \"salient\" regions) is problematic. The alternative pursued here is a system to leverage expert-like high level advice within the image segmentation process: to do this, the underlying engine is endowed with global constraints encoding (a) effort already expended by the user in segmenting similar images in the past, as well as (b) aggregate knowledge from a cohort of similar images. The key algorithmic component is the design of mechanisms to translate such constraints (as best as possible) to a combinatorial framework so that the resultant models can be optimized efficiently for high resolution 3-D imaging data. This research produces the methodology and accompanying software for this important image analysis task. <br\/><br\/>The project has broad scientific impact. Wide distribution of code produced from this research can enable improvements in various computer vision and medical imaging problems where image segmentation is a key step. Additionally, the algorithms developed here have applications in other problems such as object recognition and image categorization. The project is also well suited to involve undergraduate and graduate students from a diverse spectrum of backgrounds in cutting edge inter-disciplinary computer vision and image processing research.","title":"RI: Small: Endowing Graph-Based Image Segmentation with Global 'Advice': Applications to Diffusion Tensor Images","awardID":"1116584","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["563992"],"PO":["564316"]},"181429":{"abstract":"Millions of Americans are unable to independently perform activities of daily living (ADLs) such as dressing and grooming, and this number is rising rapidly as America?s aging and disabled population increases. This research focuses on designing and developing new algorithms and software systems that would help enable personal robots to autonomously compute safe motions to assist disabled and elderly individuals with ADLs. The proposed framework uses kinesthetic demonstrations to teach the robot desirable motion trajectories to accomplish several specific ADL assistance tasks. Based on these demonstrations, the research focuses on developing new computational methods to extract task constraints for desirable motion trajectories using learning methods based on Gaussian mixture models in conjunction with machine learning and 3D registration methods. A key element of this project involves investigation of methods to deformably register and generalize the motion trajectories and task constraints across individuals of different shapes and sizes. In order to generate safe plans in dynamic real-world settings, the proposed research investigates new highly parallel algorithms that effectively utilize the power of modern general purpose graphics processing units (GPUs) for real-time planning in uncertain environments. The framework is evaluated using articulated mannequin testbeds.<br\/><br\/>This project brings together an interdisciplinary team with computer science, robotics, and occupational therapy expertise. The project integrates research with education through community outreach activities. In the long term, the methods developed in the proposed research could have broad societal benefits by helping enable personal robots to assist disabled and elderly individuals with ADLs, allowing them to safely stay in their homes rather than moving to costly institutions.","title":"SHB: Small: Computing Robot Motions for Home Healthcare Assistance","awardID":"1117127","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["543535","562687"],"PO":["564768"]},"181209":{"abstract":"Providing young children with opportunities to develop early literacy skills is important to their success in school, their success in learning to read, and their success in life. This project focuses on the creation of a new interactive reading primer technology on tablet computers that will foster early literacy skills and shared parent-child reading through the use of a targeted discussion-topic suggestion system aimed at the adult participant. The Cloud Primer will crowdsource the interactions and discussions of parent-child dyads across a community of readers. It will then leverage this information in combination with a common sense knowledge base to develop computational models of the interactions. These models will then be used to provide context-sensitive discussion topic suggestions to parents during the shared reading activity with young children. The work will be evaluated in week-long at-home studies.<br\/><br\/>Intellectual merit: The project will make fundamental theoretical contributions to models of human-human and human-computer interaction, and their use in fostering engagement and learning. The effort will also produce new insights into how common sense reasoning can be integrated with large-scale data collection to develop interactive technologies that deal gracefully with inconsistencies and noise to provide diverse and semantically meaningful responses in unconstrained, real-world environments.<br\/><br\/>Broader impacts: Research shows that one in three children in the United States enter kindergarten unprepared, and the majority of children who start behind typically stay behind. The Cloud Primer will counteract this trend by leveraging a community of readers to define a set of common discussion topics, actively exposing parents to these topics, and, through a simple touch interface, providing children of pre-reading age a mechanism for engaging adults in discussion. The new context and common sense aware interactive reading primer will be a fundamental advance over current digital reading technologies, which neither effectively achieve educational goals when used alone, nor support joint reading and adult engagement. The project will further contribute to education through undergraduate research, graduate thesis research, graduate course development, and outreach programs to women and under-represented minorities. To promote research in this area, the project will make all parent-child interaction data captured and annotated in the process of this research freely available to the research community, together with the Cloud Primer software. Furthermore, the computational methods developed through the course of this research will have applications in interactive domains beyond early literacy, such as foreign language learning.","title":"HCC: Small: Collaborative Research: Cloud Primer: Leveraging Common Sense Computing to Learn Parent-Child Interaction Models for Early Childhood Literacy","awardID":"1116057","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["497073"],"PO":["565227"]},"180924":{"abstract":"The brain's ability to perform complex forms of pattern recognition, such as speech discrimination, far exceeds that of the best computer programs. One of the strengths of human pattern recognition is its seamless processing of the temporal structure and temporal features of stimuli. For example, the phrase \"he gave her cat food\" can convey two different meanings depending on whether the speaker emphasizes the pause between \"her\" and \"cat,\" or \"cat\" and \"food.\" Attempts to emulate the brain's ability to discriminate such patterns using artificial neural networks have had only limited success. These models, however, have traditionally not captured how the brain processes temporal information. Indeed most of these models have treated time as equivalent to a spatial dimension, in essence assuming that the same input is buffered and played at different delays. Similarly, more traditional approaches to pattern recognition, which generally rely on discrete time bins, also do not capture how the brain processes temporal information. The goal of the current research is to use a framework, referred to as state-dependent networks or reservoir computing, to simulate the brain's ability to process both the spatial and temporal features of stimuli. A critical component of this framework is that temporal information is automatically encoded in the state of the network as a result of the interaction between incoming stimuli and internal states of recurrent networks.<br\/><br\/>This project will develop a general model of spatiotemporal pattern recognition focusing on speech discrimination. The model will incorporate plasticity, a critical characteristic of the brain that has eluded previous state-dependent network models. Plasticity is a cardinal feature of the brain's computational power. For example, in the context of speech recognition, even at the age of 6 months, the brains of babies are tuned to recognize sounds of their native language. This ability is an example of experience-dependent cortical plasticity and it relies in part on synaptic plasticity and cortical reorganization. Incorporating synaptic plasticity into recurrent networks has proven to be a very challenging problem as a result of the inherent nonlinear and feedback dynamics of recurrent networks. The current project will use a novel unsupervised form of synaptic plasticity--based on empirically observed forms of plasticity referred to as homeostatic synaptic plasticity--to endow state-dependent networks with the ability to adapt and self-tune to the stimulus set the network is exposed to. This project interfaces recent advances in theoretical neuroscience and novel approaches in machine learning. The results will help develop artificial neural networks that capture the brain's ability to process temporal information and reorganize in response to experience.","title":"RI: Small: Temporal and Spatiotemporal Processing in Recurrent Neural Networks with Unsupervised Learning","awardID":"1114833","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[484825],"PO":["564318"]},"182805":{"abstract":"This project is awarded under the Nanoelectronics for 2020 and Beyond competition, with support by multiple Directorates and Divisions at the National Science Foundation as well as by the Nanoelectronics Research Initiative of the Semiconductor Research Corporation. <br\/><br\/>The proposed research will explore the interactions between candidate QCA molecules bound on a surface and employ the well-developed theory of electron transfer in mixed-valence compounds, focusing it on the particular problems presented by the molecular QCA paradigm. An interdisciplinary team of scientists and engineers from the University of Notre Dame will use a combination of synthesis, theory, measurement, and device architecture engineering to study classes of mixed-valence compounds designed for QCA operation. Candidate molecules will be synthesized and deposited on surfaces, shifts in the charge distribution of one molecule due the interaction with neighboring molecules will be imaged directly, and methods for querying and integrating these molecular systems into electronic devices will be developed. The interdisciplinary nature of this work will impact the education and training of students at all levels. Outreach efforts will include introducing scanning microscopy to the K12 classroom and continuing to develop a MATLAB project to energize high school science and math students by putting real programming power into their hands. At the graduate level, the fusion of chemistry and electrical engineering cultures will produce a broader perspective for students and overcomes disciplinary linguistic and conceptual barriers.<br\/><br\/>Computing using molecules has the potential to generate ultrasmall devices that use little power; however, many significant technical hurdles must be overcome to realize the benefits of molecular level computing. This work will further our understanding how molecules can communicate via their charges, which could lead to computer circuits that do not use the flow of electrical current to transmit information. Such work could impact industries that use microprocessors in their products, including computer, consumer electronics, automotive, etc.","title":"NEB: Nanoelectronics with Mixed-valence Molecular QCA","awardID":"1124762","effectiveDate":"2011-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1712","name":"DMR SHORT TERM SUPPORT"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1991","name":"CHEMISTRY PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[489795,489796,489797,489798],"PO":["564370"]},"181606":{"abstract":"Project Title: Semi-Regular Volumetric Parameterizations, Meshes, and Datafitting <br\/><br\/>Project PI: Elaine Cohen, University of Utah<br\/><br\/>Volumetric models are increasingly pervasive in computer graphics, computer-aided geometric design, visualization, and medical data analysis. Formulating high quality parameterizations and smooth representations is a difficult problem. Although it is possible to create unstructured tetrahedral based C0 bases, there are many problems for which semi-structured smooth hexahedral based representations give higher fidelity simulations, model representations, and analyses. However, automatic creation of such representations is still a challenge problem. At least partially because they require much manual interaction and effort, current techniques to create smooth representations have not been widely adopted. Our successful initial results in using mathematical theory to create representations for special classes of volumes has opened a door for extending the theory to create algorithms that deal with more complex volumetric shapes. A semi-regular parameterization facilitates many geometric processing and analysis algorithms, allowing their extension to volumetric processing, and it supports the use of smooth higher-order bases for simulation.<br\/><br\/>This research is creating automatic parameterization and data fitting techniques for heterogeneous volumes through i) developing a theoretical basis for techniques to represent volumetric models using semi-regular tensor product parameterizations, and ii) fitting higher order smooth representations of the volumes over the parameterizations and then using associated smooth bases for simulation. We are addressing domain matching, shape distortion, and issues in computational geometry for such algorithms. Shapes that are being investigated include multi-boundary polygonal models derived from scanned data and designed boundary models represented as smooth NURBS surfaces. Algorithms and software tools to help transform surface models to tensor product volume parameterizations and smooth representations of volumes were lacking, one issue that this research is overcoming. The results are being tested on a meaningful subset of graphics simulation problems, particularly in the case of elastic deformations of objects.","title":"HCC: CGV: Small: Semi-Regular Volumetric Parameterizations , Meshes, and Datafitting","awardID":"1117997","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[486565],"PO":["565227"]},"181617":{"abstract":"Portable storage devices such as USB flash drives have become virtually ubiquitous in daily life. They are as useful to students in college as to a soldier transferring data in a combat theater. However, the security risks posed by using these devices are all too real: after malicious code on a flash drive infected operational networks, allowing a mass exfiltration of classified data subsequently posted to Wikileaks, the Department of Defense banned these devices. The security vulnerabilities exposed by these events are of concern far beyond the military and extend to any user of portable storage. While numerous attempts have been made to secure hosts from malicious devices, very little research has considered the symmetrical problem of ensuring the protection of sensitive data from potentially compromised hosts, nor the security of the USB bus itself.<br\/><br\/>This project examines the factors contributing to the vulnerability of portable storage devices and consider a new framework for modeling and evaluating the security of these devices. We will consider the security of the storage devices themselves, the hosts they attach to, and the USB interface that transports the data. We consider methods of monitoring the integrity of attached hosts, and examine how to establish and manage host identity. We propose applications based on these devices, such as maintaining provenance and forensic information on stored data, and new frameworks supporting information flow for further enforcing finer-grained access protections. Such advances will ensure that flash drives and hosts they attach to remain safe and secure.","title":"TC: Small: Protection Mechanisms for Portable Storage","awardID":"1118046","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["553388"],"PO":["564223"]},"181628":{"abstract":"The PI will study and attempt to improve the state of the art in fundamental areas of algorithms: linear time solution of systems of linear equations, matchings, and approximation. The basis of the linear system work is the recent breakthrough work of Spielman and Teng and the follow up work of Koutis, Miller, and Peng, who gave very efficient, near linear time algorithms for solving a large class of linear systems. The ideas in this scheme are intertwined with graph partitioning and metric approximation which the PI has long researched. The PI will also use ideas from Spielman and Teng to attack the matching or assignment problem; in particular, understanding graph sparsification techniques in terms of the matching problem. Finally, the investigator proposes to work on extending a recent breakthrough on the TSP problem that reduced the asymmetric version of the problem to one of finding a tree that crosses cuts expediently.<br\/><br\/>The solution of linear systems is central to a tremendous variety of engineering and scientific problems ranging from climate change, to building modeling, to jet engine design (essentially any problem dealing with simulating classical physics). The assignment problem which the PI proposes to investigate is central in numerous production and business applications: indeed, almost any application that assigns jobs to tasks efficiently. Finally, the TSP problem is a famously intriguing problem which is worth studying for its own sake and for the methodogical breakthroughs that its study typically leads to.","title":"AF: Small: Algorithms: Linear, Spectral, and Approximation.","awardID":"1118083","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[486616],"PO":["565251"]},"181408":{"abstract":"Explosive growth in volume and complexity of data exacerbates the key challenge facing the management of massive data in a way that fundamentally improves the ease and efficacy of their usage. Exascale storage systems in general rely on hierarchically structured namespace that leads to severe performance bottlenecks and makes it hard to support real-time queries on multi-dimensional attributes. Thus, existing storage systems, characterized by the hierarchical directory tree structure, are not scalable in light of the explosive growth in both the volume and the complexity of data. As a result, directory-tree based hierarchical namespace has become restrictive, difficult to use, and limited in scalability for today's large-scale file systems.<br\/><br\/>This project investigates a novel semantic-aware namespace scheme to provide dynamic and adaptive namespace management and support typical file-based operations in Exascale file systems. The project leverages semantic correlations among files and exploits the evolution of metadata attributes to support customized namespace management, with the end goal of efficiently facilitating file identification and end users data lookup. This project provides significant performance improvements for existing file systems in Exascale file systems. Since Exascale file systems constitute one of the backbones of the high-performance computing infrastructure, the semantic-aware techniques also benefits a great number of scientific and engineering data-intensive applications. This project strengthens the ongoing development of high performance computing infrastructures at both UNL and UMaine. The project enhances undergraduate and graduate education at both participating institutions and outreach to K-12 in UMaine via an ongoing NSF-funded ITEST program.","title":"CSR: Small: Collaborative Research: SANE: Semantic-Aware Namespace in Exascale File Systems","awardID":"1117032","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[486060],"PO":["565255"]},"181419":{"abstract":"This proposal explores a robust quantum cryptography protocol for securing optical burst switching (OBS) networks, providing a means to make the OBS-based future Internet trustworthy from the ground up. Since the OBS network has a one-to-one correspondence between the header and its associated burst, the same relationship can be exploited for encryption. The quantum-based methodology makes it possible to distribute keys securely so that each burst is encrypted and decrypted with a unique key. As the well-known BB84 quantum cryptography protocol is susceptible to siphoning attacks on the multiple photons emitted by practical sources, we use a new 3-stage quantum cryptography protocol which is immune to such siphoning attacks, for it is based on random rotations of the polarization vector. The new 3-stage quantum cryptography protocol allows practical photon sources to be used in the quantum key exchange, making it feasible to extend quantum cryptography services beyond trusted routers. The 3-stage all quantum protocol is being investigated for its performance in different noise situations for different key generation rates. The implementation of the protocol uses quantum phase modulation rather than polarization modulation which is not stable in the long transmission over fiber. The research conducted in this proposal includes the design of an integrated secure router and investigation of quantum cryptography protocols for specific services. This research will be verified on a reconfigurable optical burst switching test bed.","title":"TC: Small: Collaborative Research: Exploring a Robust Quantum Cryptography Protocol for Securing Optical Burst Switching Networks","awardID":"1117068","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":[486088],"PO":["565327"]},"181309":{"abstract":"A fundamental challenge in many engineering and science problems today is to find tractable methods to handle large scale, complex nonlinear systems. This research considers large systems with linear mixing, where the system components interact through aggregates of small, linearizable perturbations. For such systems, the research investigates a promising new class of algorithms called generalized approximate message passing (GAMP) that exploits the nature of the linear mixing interactions to iteratively decompose large-scale problems into smaller, more tractable, problems. The GAMP methodology provides a systematic procedure applicable to a large class of systems that is computationally scalable to very high dimensions and admits a tractable mathematical analysis in the case of certain high-dimensional random systems. The potential for the GAMP algorithm is thus far reaching, and the research explores applications in diverse fields including scheduling in cellular wireless systems, image recovery, pattern recognition and detection of connectivity in neural networks.<br\/><br\/>The GAMP methodology is based on a Gaussian and quadratic approximations of loopy belief propagation on large, dense graphs. The resulting algorithm is a general, but computationally simple, iterative procedure that alternates between scalar optimization and estimation operations based on the local behavior of the system, along with linear transforms that capture the interactions between system components. The theoretical components of the research are to characterize the algorithm's asymptotic behavior, convergence and optimality along with developing extensions to the systems with mixes of linear and nonlinear interactions. The research will leverage tools from and contribute to the broader fields of optimization, graphical models, numerical methods and random systems.","title":"CIF: Small: Approximate Message Passing for Systems with Linear Mixing and Randomization","awardID":"1116589","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["541951"],"PO":["564924"]},"180925":{"abstract":"Increasing use of smartphones and location-based services (LBSs) for their on- and off-job functions will likely entice users to reveal their location and movement information, which may be exploited by adversaries to infer the Points of Interest (POIs) they visit, and hence their privacy information. To protect mobile users' location privacy, this project will first improve the understanding of emerging threats and attacks against their location privacy. With this understanding, it will then develop, implement, and evaluate an efficient and effective framework, called the Location Information ScrAmbler (LISA), that adjusts uncertainty in a user's location, thereby removing -- or significantly weakening -- the distinguishability of the POIs s\/he may visit. This project has intellectual merit as follows. By protecting location privacy locally on each mobile user's device, LISA will not rely on trusted third-party servers commonly required by existing approaches; this removes single-point-of-failure vulnerabilities and facilitates its implementation and deployment. Moreover, since energy-efficiency is the most critical requirement for energy-deficient mobile devices, this project will develop ways of making a trade-off between location privacy and energy consumption to adaptively achieve a balance between privacy protection and energy consumption. At present, location privacy is a very subjective concept with widely-varying definitions. To advance the understanding of, and develop effective measures for location privacy and protection, this project consists of (1) formal definition of location privacy based on the notion of m-unobservability; (2) collection of real-world traces of human and vehicle mobility pattern, and development of different mobility and tracking models by analyzing the traces; (3) optimization of the trade-off between the level of a mobile user's location privacy and energy consumption by the mobile user's device; (4) adaptive configuration of the location-privacy requirements according to the user's preference and situation so as to optimize energy consumption; (5) augmentation of users' mobile devices with LISA to protect their location privacy without requiring any trusted third-party server that most existing approaches rely on; (6) comprehensive field experiments to evaluate the efficacy and efficiency of LISA by implementing and deploying it to 20 some volunteers' smartphones. This research will also make broader impacts by improving both the security and productivity of a rapidly-growing number of people who use smartphones and LBSs for their daily functions. The proposed integration of research, outreach, and education activities will have social and educational impacts on the security research and industry communities, protecting mobile users' privacy, increasing the awareness of mobile service and network security, and developing skilled human resources.","title":"TC: Small: Location-Privacy Protection for Mobile Handset Users","awardID":"1114837","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553551"],"PO":["562974"]},"180419":{"abstract":"Computer networks, in particular the Internet, represent critical infrastructure for business, government, military, and personal communication. Several recent trends in technology and network use have pushed the capabilities required of the Internet beyond what can be provided by the currently deployed infrastructure. This project develops a new architectural design for the Internet of the near future that represents a transformative shift to enable sustained innovation in the core of the network, using economic principles. The core idea of this new network architecture is to support choice as the central aspect of the architecture. A network built on these principles will be able to adapt to emerging solutions for current and future challenges. The network architecture designed and prototyped in this work aims to (1) encourage alternatives to allow users to choose from a range of services, (2) let users vote with their wallet to reward superior and innovative services, (3) provide the mechanisms to stay informed on available alternatives and their performances. Solutions are approached from different directions, reflecting the team's multidisciplinary expertise in computer networking, network systems, management science, and network economics.<br\/><br\/>The broader impact of this project contributes to enhancing the functionality and usability of the next-generation Internet, which is expected to become an important piece of infrastructure. The project also integrates research and education of graduate and undergraduate students at the participating organizations, where current efforts to integrate underrepresented minorities are continued. Results from this work are disseminated in the form of an open-source prototype and publications.","title":"NeTS:Large:Collaborative Research: Network Innovation through Choice","awardID":"1111256","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["530742"],"PO":["565090"]},"186909":{"abstract":"This is a proposal to hold an NSF CISE-sponsored workshop in to survey the state-of-the art in cross-layer power optimization and management, to identify areas that require further research and development, and to chart a transformative research agenda for this field. The workshop is expected to bring together about 50 of the leading researchers studying system-wide power optimization techniques and dynamic power management from both academe and industry including representatives from major chip design companies. All of the material from the workshop will be made available to the research community and a detailed report will be prepared and submitted to NSF.<br\/><br\/>Power efficiency is an important driver for the semiconductor industry and all of its components. By investigating the shortcomings and weaknesses of the current approaches to power and\/or energy efficiency it is expected that a new slate of low power technology and circuit solutions with tangible impact on the design of the next generation portable electronics as well as high performance (yet energy aware) computing will be achieved.","title":"NSF Workshop on Cross-Layer Power Optimization and Management","awardID":"1147973","effectiveDate":"2011-09-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["325495","518663","518229"],"PO":["562984"]},"182807":{"abstract":"Overview: The astrophysics community has produced a Petabyte of of imaging data in a wide range of wavelength channels in the last decade, and is planning to produce a thousand times more in the next.<br\/>At the same time, the computer science machine learning community has developed powerful methods for extracting knowledge scalably from large, heterogenous data sets. This project is to construct a model--a detailed quantitative explanation--for every pixel of every digital astronomical image ever taken by any telescope in the world, including those from amateurs and hobbyists.<br\/><br\/>Technical description: The proposed model is a justified approximate probabilistic model, making extensive use of non-parametric Bayesian methods. The model will be hierarchical in nature, with the higher layers capturing regularities among stars and galaxies, and the lower layers will accurately model the image formation process, incorporating all the various noise processes. The internal parameters of the model will contain the best possible astronomical catalog given the input data; no current astronomical catalog is built using either hierarchical probabilistic inference, or built from the union of all available data. Science will be enabled by this catalog as it has been enabled by all previous astronomical catalogs: it will contain the position, brightness, temperature, parallax, and proper motion of every star and position, intensity, and morphology of every galaxy, even for sources for which there is evidence in the collection of data but not (sufficiently) in any individual image. Other internal parameters of the model will contain a quantitative description of calibration properties for all the image-generating hardware. All these products will help to refine and extend an existing astrophysics software and services for calibration and automated data processing.<br\/><br\/>Broader impacts: This project provides unique opportunities in citizen science since it leverages images taken by amateur and hobbyist astronomers in creating astronomical knowledge by offering them opportunities to contribute in exactly the same fashion as professional astronomers. The project draws together two disparate fields: machine learning and astronomy, and thus has the potential to create a new sub-area of \"inferential astronomy\". The project offers enhanced opportunities for research-based advanced interdisciplinary training for postdoctoral, graduate and undergraduate researchers. All code created for this project will be released under the open-source license and all model components, parameters, and other internals will be freely disseminated to the wider research community through the project websites at: <br\/>http:\/\/Astrometry.net\/ and http:\/\/thetractor.org\/ .","title":"CDI-Type I: A Unified Probabilistic Model of Astronomical Imaging","awardID":"1124794","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7750","name":"CDI TYPE I"}}],"PIcoPI":[489804,"502163"],"PO":["560586"]},"182818":{"abstract":"This project is awarded under the Nanoelectronics for 2020 and Beyond competition, with support by multiple Directorates and Divisions at the National Science Foundation as well as by the Nanoelectronics Research Initiative of the Semiconductor Research Corporation. This work is motivated by the vision of future computer chips with millions of cores, where each core has a complexity similar to early microprocessors. Furthermore, it is envisioned that computation in such systems might be done in an entirely new way, more akin to wave propagation in a brain-like network of processing elements. This work will identify wave-like non-Boolean computational primitives based on the spatial-temporal characteristics of such processor networks, and inspiration will be gained from known wave behavior in physics and applications derived from these. In addition, nanoelectronic systems will be explored where such wave-type excitations might find a natural implementation. This research will identify, on the physical level, computational building blocks based on nanoelectronic structures with spatial-temporal wave-like dynamics, and on the computer science level, ways to perform computation with such non-Boolean primitives. This interdisciplinary research, which spans the whole range from nanostructures to new paradigms for computing, will require a team with expertise that spans the whole range from physics to computer science. <br\/><br\/>This proposal will lay the groundwork for a radically different approach to information processing, which is based on physics-inspired and brain-like wave behavior in large-scale arrays of nanoelectronic processing elements. Specifically, our research will identify computational building blocks of future computing systems, along with the inherent state variables, where each computational task directly maps onto the underlying physical structure. This project will also identify which information-processing tasks will find their natural implementation in such architectures. This proposed research is planned in synergy with the Semiconductor Research Corporation (SRI) Nanoelectronics Research Initiative (NRI) and activities at the SRC-NRI Midwest Institute for Nanoelectronics Discovery (MIND). In particular, this research will partner with Dr. George Bourianoff at Intel, who leads a study group on Ultra Low Power Application Specific Non-Boolean Systems, which is closely related to the research proposed here.<br\/><br\/>If successful, this work would impact the way information processing is done in future information-processing systems. This work will not merely lead to incremental improvements in information processing systems, but open the door to an entirely new approach to computer architecture. Computation no longer will be based on elementary Boolean logic functions, but on physics-inspired and brain-like wave activity. This will necessitate a complete re-thinking of how computation is being done. As part of this research, graduate students will be educated and trained in this new way of thinking about how computation is done in a more brain-like fashion. Building upon active REU and RET programs, undergraduates and teachers will participate in this work. It is a stated goal to perform this research in an environment of maximum inclusivity of underrepresented groups.","title":"NEB: Physics-Inspired Non-Boolean Computation based on Spatial- Temporal Wave Excitations","awardID":"1124850","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1712","name":"DMR SHORT TERM SUPPORT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["560914","557409","550624","560915",489843],"PO":["562984"]},"182708":{"abstract":"Automated (and human) tutors are limited in their ability to infer what is going on in students' heads based on their observable behavior. The proposed work addresses this limitation by investigating how EEG input from a commercially-available device can be used as evidence about students' mental states. In particular, the project focuses on adding EEG-enhanced feedback to Project LISTEN's Reading Tutor, an intelligent tutoring system that helps children learn to read. The project seeks to answer two questions: (1) How can we use EEG to detect mental states that predict, indicate, or reflect student learning? (2) How can we use such detection to improve student learning? Analysis to answer these questions and to enhance the capabilities of the Reading Tutor draws on existing tools to explore annotate, and mine EEG data logged by the Reading Tutor. The research aims to tell us more about how to use EEG to identify mental states that predict learning and to use machine learning to make an intelligent tutoring system better, and it may also add to what is known about sources of reading difficulties. Expected technological contributions of this work include advances in relating EEG data to children's behavior, cognition, engagement, and learning and advances in elucidating how intelligent tutors can robustly exploit noisy EEG input to better assist learning. <br\/><br\/>The technological innovation in this project is particularly important for those children who need extra help with sounding out, word recognition, and\/or making simple inferences needed for understanding.","title":"DIP: Exploiting Longitudinal Electroencephalogram (EEG) Input in a Reading Tutor","awardID":"1124240","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["551746",489515],"PO":["562669"]},"181509":{"abstract":"This project develops a new framework to solve a large class of dynamic vision problems by exploiting correlated sparsity pattern change in the appropriate domain. The focus is on high-dimensional visual tracking problems such as deformable contour tracking or target tracking in the presence of significant illumination changes. These are difficult because of the high dimensionality and because the observation models are highly nonlinear and\/or non-Gaussian due to clutter, occlusions or low contrast. However, in most such problems, even though the state (e.g., contour deformation or illumination) is high-dimensional, at any given time, most change occurs in only a few principal directions. In a long sequence, this set of directions can gradually change over time. Most existing methods need a set of past state estimates to estimate this change on-the-fly while tracking noisy or nonlinear systems. The research team provides a completely new solution to this difficult problem by re-interpreting it as a problem of \"recursively reconstructing sparse state sequences with slow time-varying sparsity patterns\" and tapping into ideas from their ongoing recursive sparse recovery work.<br\/><br\/>The research of this project enriches the knowledge base of computer vision and can be applied to many different applications such as medical image analysis and video surveillance. The project provides research opportunities for graduate students and involves undergraduate students, including under-represented minorities, through summer, senior design projects and REU projects.","title":"RI: Small: Exploiting Correlated Sparsity Pattern Change in Dynamic Vision Problems","awardID":"1117509","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[486306],"PO":["564316"]},"186090":{"abstract":"Pioneering work of Seeman, Winfree, and Rothemund has raised the prospect of engineering useful structures and devices that autonomously assemble themselves from molecular components. Developing this capability will have transformative benefits for medicine, information technology, manufacturing, energy production, and other enterprises of twenty-first century society. In this project a team of scientists with expertise in self-assembly, software engineering, formal verification, programming languages, theory of computing, biochemistry, and molecular biology will explore the power and limitations of this \"programming of matter\" at the nanoscale.<br\/><br\/>The central thesis of this project is that methods that software engineers and theoretical computer scientists have developed for creating, controlling, and reasoning about software, hardware, networks, and environments of immense complexity will be an essential starting point for dealing with the greater challenges that nanotechnology will confront. The project will investigate applications of computational modeling, algorithmic randomness, requirements engineering, product lines, software verification, and software safety to DNA tile assembly, DNA origami, and DNA strand-displacement reactions. The project will conclude with a clear assessment--hopefully a compelling proof of concept--of the applicability and adaptability of software engineering methods in molecular programming and nanoscale self-assembly.<br\/><br\/>The project will contribute to a rigorously reasoned, verification- and safety-oriented approach to the social benefits of nanoscale self-assembly. It will strengthen software engineering methods as it adapts them to challenging new domains. It will enhance interdisciplinary science education at Iowa State University and nearby Simpson College, and it will provide web-accessible educational materials for such activities elsewhere.","title":"EAGER: Collaborative Research: Modeling and Analysis of Molecular Programming and Nanoscale Self-Assembly","awardID":"1143839","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[499378,499379,499380,499381],"PO":["564388"]},"175091":{"abstract":"In numerous industries, decisions are based on large amounts of data, where a ranked list of possible actions determines how limited resources will be spent. Over the last decade, machine learning algorithms for ranking have been designed to address prioritization problems. These algorithms rank a set of objects according to the probability to possess a certain attribute; for example, we might rank a set of manholes in order of their probability to catch fire next year. However, current algorithms solve ranking problems approximately rather than exactly, and these approximate algorithms can be slow; furthermore they do not take into account many application-specific problems.<br\/><br\/>The goals of this project include: <br\/><br\/>I) Finding exact solutions to ranking problems by developing a toolbox of algorithmic techniques based on mixed-integer optimization technology. <br\/><br\/>II) Finding solutions faster by showing a fundamental equivalence of ranking problems to easier classification problems that can be solved an order of magnitude faster. <br\/><br\/>III) Developing frameworks for new structured problems. The first framework pertains to ranking problems that have a graph structure that are relevant to the energy domain. The second framework handles a sequential prediction problem arising from recommender systems, with applications also in the medical domain.<br\/><br\/>Through collaboration with industry, the proposed methods are being applied in several different areas, including the prevention of serious events (fires and explosions) on NYC's electrical grid.","title":"CAREER: New Approaches for Ranking in Machine Learning","awardID":"1053407","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[469607],"PO":["562760"]},"185190":{"abstract":"In the minutes and hours following the recent earthquakes in New Zealand and in Japan, and storm in Haiti, thousands of locals posted pictures to social media sites like Facebook and Twitter. These pictures when coupled with extremely granular spatio-temporal information (e.g., timestamps and GPS-style geocodes) provide a minute-by-minute and region-by-region pictorial account of the emergency as it unfolded. The goal of this project is to assess, characterize, and model the quality of these images posted to social media in the minutes and hours post-emergency for guiding policy-based stakeholders and assets. Carefully framed images can convey a wealth of structural information to recovery experts: revealing damage levels, guiding resource allocation, and directing other policy-based assets. First, a sample of several thousand social media images from New Zealand will be assessed by domain experts and specifically structural earthquake engineers. Second, with RAPID funding, this project will link images posted during the emergency to actual damage assessments made in Christchurch for validating the quality of images. First, a sample of several thousand social media images from New Zealand will be assessed by domain experts and specifically structural earthquake engineers. The results of this project will have broad impacts, particularly in the development and deployment of a new rapid assessment tool for earthquake damage assessment based on social media. An additional broader impact is the ancillary development of training modules for increasing the effectiveness and image quality of future socially-generated image capture, which would greatly improve social computing for disasters. The methods and data generated by this project will be archived and made available for future studies.","title":"RAPID: Earthquake Damage Assessment from Social Media","awardID":"1138646","effectiveDate":"2011-09-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[496898,"502038"],"PO":["565136"]},"176181":{"abstract":"Power consumption imposes significant design constraints across the entire spectrum of computing, from the smallest handheld device to the largest data center. New technology nodes provide significant size reduction advantages, but introduce significant challenges in the power and process variability domain. These new technology nodes introduce concerns in the available first-order models commonly used by the research community. Transistor-level and gate-level simulators can offer higher accuracy, but are too slow to model multicore processors running real programs.<br\/><br\/>Fundamentally, validating novel power-centric ideas is limited by our ability to anticipate the future and to model large-scale effects or relatively poorly understood phenomenon. Fabricating prototypes can bridge the gap, but prototype-based architecture research requires a considerable amount of complex infrastructure making it relatively rare for academic researchers. This projects proposes a complete prototyping platform, that will greatly reduce the cost and effort required for prototype-based research into power-centric multicore architectures.","title":"Collaborative Research: II-NEW: Prototyping Platform to Enable Power-Centric Multicore Research","awardID":"1059333","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["557941"],"PO":["563661"]},"178370":{"abstract":"A recommender system takes on-line user histories and demographic information, and automatically creates personalized recommendations for goods and services. Already common for small items such as books and movies, such systems are destined to play an increasing role in the economy as new applications emerge for them, such as firms searching for suppliers and workers searching for jobs. Previous research, however, has shed little light on the economic benefits and costs that recommender systems bring, nor on which of the many sorts of systems work best in each current or prospective niche.<br\/><br\/>This project will improve metrics for measuring performance of recommender systems, use these metrics to evaluate existing recommender algorithms in major niches, and develop and test new algorithms and systems adapted to under-served niches. The research builds on previous research by computer scientists, and connects it to established economic theory as well as to controlled experiments with human subjects. The improved metrics explicitly incorporate the economic goals of users, suppliers, and platform providers. The algorithms include collaborative filtering, content based filtering, and hybrids as well as more advanced algorithms that use heterogeneous information and actively trade off exploration and exploitation while interacting with the users. The data will include proprietary industry data already compiled for this project, together with new data obtained in controlled laboratory experiments conducted at UCSC and in on-line field experiments.<br\/><br\/>The direct impact will be to increase understanding of the strengths and weaknesses of various sorts of recommender systems. More broadly, the research will shed light on how humans process freely available information, an important question in many social science disciplines, and practical benefits may ultimately accrue to millions of users of recommender systems. Additionally, conducting this research will promote on-campus teaching, training and learning for graduate students who serve as research assistants and programmers; for undergraduates (mostly game design engineering majors) who contribute to the programming; and for hundreds of undergraduates who will serve as laboratory subjects.","title":"ICES: Small: Economic Analysis of Recommender Systems","awardID":"1101741","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[478197,"537808","547825"],"PO":["565251"]},"177281":{"abstract":"This research investigates techniques to efficiently detect the first exploit against an unknown vulnerability on a user system, and then safely heal the system against further attacks. The research uses dynamic analysis -- the ability to monitor code as it executes -- because it can be used to check safety and security properties of actual executions and make sure that each step of the execution is safe. However, existing dynamic analysis techniques are far too slow for end users, and currently do not help user systems self-heal. This research investigates techniques to overcome these limitations by developing efficient dynamic analysis techniques, as well as techniques for diagnosing the root cause of an exploited vulnerability, repairing any damage done, and defending the system against further attacks.","title":"TC: Medium: Exploiting Multicore and Hardware Acceleration to Perform Efficient Behavior-Based Attack Detection and Repair","awardID":"1065112","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550874","485986","521611"],"PO":["565264"]},"176093":{"abstract":"Logic solvers are software programs that can solve complex logical<br\/>formulas fully automatically. Problems in many areas of Computer<br\/>Science, such as artificial intelligence, program analysis, security,<br\/>hardware verification, and cyber-physical systems can be faithfully<br\/>translated into logical formulas. Those formulas can then be solved<br\/>fully automatically by logic solvers. Over the past two decades, at<br\/>least ten different logic-solving communities have emerged, based on<br\/>different logical languages and solving techniques. These communities<br\/>have independently been building computing infrastructure to aid<br\/>development and evaluation of their solvers: libraries of benchmark<br\/>formulas, cluster-backed web services, annual competitions, and more.<br\/>Such infrastructure also provides an important access point for<br\/>users, who can find all the solvers at one site, or even run solvers<br\/>on the infrastructure cluster to test their relative capabilities.<br\/>The goal of this research is to build a single piece of shared<br\/>computing infrastructure called StarExec, which will be used by many<br\/>different logic solving communities. StarExec will provide improved<br\/>services for established logic-solving communities, and lower the<br\/>entry barrier for new and emerging communities.<br\/><br\/>The StarExec infrastructure will consist of a custom web service<br\/>interfacing to a medium-sized compute cluster. This open-source<br\/>service will allow multiple logic-solving communities to host<br\/>benchmark libraries, run jobs comparing different solvers, and host<br\/>competitions. StarExec will leverage economies of scale to provide<br\/>more sophisticated services than is feasible for most individual<br\/>logic-solving communities. A very important goal of StarExec is not<br\/>just to collocate different logic-solving communities, but to unite<br\/>them. To this end, the StarExec team will develop formal<br\/>specifications of both the syntax and proof-theoretic semantics of<br\/>different communities' logical languages. This will be done using a<br\/>meta-language called LFSC (\"Logical Framework with Side Conditions\"),<br\/>developed in previous NSF-funded research. Translation of formulas<br\/>between compatible fragments of different logics will be implemented,<br\/>which will will enable a greater degree of integration between solver<br\/>communities than was previously possible. For example, it will be<br\/>possible for solvers in one community to be run on benchmarks from<br\/>another. This integration will also aid users of logic solvers, who<br\/>will have a greater variety of options, all in a common framework, for<br\/>solving their problems. The broader impact of the StarExec project<br\/>will be to accelerate the development, adoption, and convergence of<br\/>different logic-solving technologies. This will enable faster<br\/>progress in nationally important application areas such as artificial<br\/>intelligence, verification, security, and cyber-physical systems,<br\/>which increasingly depend on high-performance logic solvers.","title":"Collaborative Research: CI-ADDO-NEW: StarExec: Cross-Community Infrastructure for Logic Solving","awardID":"1058925","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[471910],"PO":["565264"]},"159362":{"abstract":"Terra Populus: A Global Population\/Environment Data Network (TerraPop) will develop organizational and technical infrastructure that will integrate, preserve, and disseminate data describing changes in the human population and environment over time. A plethora of high-quality environmental and population datasets are available, but they are widely dispersed, have incompatible or inadequate metadata, and have incompatible geographic identifiers. The project will enable researchers to identify and merge data from heterogeneous sources to study the relationships between human behavior and the natural world. <br\/><br\/>TerraPop will focus on four specific kinds of data: (1) census and survey microdata describing the characteristics of individuals and their families and households; (2) aggregate census and survey data, describing the characteristics of places, including aggregate population characteristics, land use, and land cover; (3) remote-sensing data describing land cover and other environmental characteristics; and (4) climate data describing temperature, precipitation, and other climate-related variables. All four data types have an important temporal dimension; most of the data span the past five decades, and some sources reach back to the nineteenth century. TerraPop will make these data interoperable across time and space, disseminate them to the public and to multiple research communities, and preserve them for future generations. <br\/><br\/>Understanding of interactions between population and the environment has been hampered by the dearth of internationally comparable data. This infrastructure will expand the quality and quantity of such data while making them highly interoperable and easily accessible. Population data closely integrated with data on the environment will allow us to describe the unfolding transformation of human and ecological systems. Data on the human population are crucial for understanding changes in the Earth?s biological and climate processes; equally important, data on climate and land provide essential tools for understanding the impact of environmental change on human behavior. By creating a framework for locating, analyzing, and visualizing the world's population and environment in time and space, TerraPop will provide unprecedented opportunities for investigating the agents of change, assessing their implications for human society and the environment, and developing policies to meet future challenges. The data collection and its analysis tools will contribute to education and public understanding. It will allow teachers to integrate research and teaching, bringing the excitement of discovery into the classroom from primary school to graduate school. More broadly, TerraPop will be a model for the sustainable expansion, maintenance, and improvement of a global data resource.","title":"DataNet Full Proposal: Terra Populus: A Global Population\/Environment Data Network","awardID":"0940818","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7684","name":"STRATEGIC TECHNOLOGIES FOR CI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":["532009","550903","513638","565146","552857"],"PO":["565292"]},"159373":{"abstract":"Major science and engineering initiatives are dependent upon massive data collections that comprise observational data, experimental data, simulation data, and engineering data. To support science and engineering collaborations, a policy driven national data management infrastructure will be implemented. The implementation prototype will address both the life cycle of science and engineering data and the sustainability of data collections and repositories over time, across changes in technology and changes in usage. The motivation for building the national infrastructure comes from the data management requirements of the NSF Ocean Observatories Initiative (real-time data streams, simulation output, video), the NSF Consortium of Universities for Advancement of Hydrologic Science (point data), engineering projects in education and CAD\/CAM\/CAE archives, the iPlant collaborative (genome databases), the Odum social science institute (statistics), and the NSF Science of Learning Centers (EEG \/ MRI sensor data, video).<br\/><br\/>The approach is based on a bottom-up federation of existing data management systems through use of the integrated Rule-Oriented Data System (iRODS). Each of the referenced national initiatives has implemented a core data management system based upon the iRODS data grid technology. Through federation, the independent systems can be assembled into a national data infrastructure that integrates collections across project-specific technology (such as real-time sensor data acquisition systems), institutional repositories, regional data grids, federal repositories, and international data grids. The resulting infrastructure will enable collaborative research among researchers in academic institutions and federal agencies, and across national boundaries.<br\/><br\/>Evolution of the policies (computer actionable rules) and procedures (computer executable workflows) that govern each stage of the data life cycle will be supported. Specific policies and procedures will be implemented for each domain to support their community standards for managing data in their local data grid. The project will develop the interoperability mechanisms required to share data between the domains, develop sets of policies and procedures to govern the data life cycle stages, and develop policies and procedures that enable re-use of collections. The national data management infrastructure will demonstrate enforcement of data management policies that comply with NSF Data management and preservation requirements.","title":"DataNet Full Proposal: DataNet Federation Consortium","awardID":"0940841","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7684","name":"STRATEGIC TECHNOLOGIES FOR CI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":["490590","527151","554652","560676","501660"],"PO":["565292"]},"186291":{"abstract":"The next generation of wireless sensor networks will monitor critical infrastructure, collect vital signs from patients, and disseminate medical and planning information during emergency responses. In contrast to earlier wireless sensor networks for which best-effort services were sufficient, such systems require predictable performance and high reliability. Failure to meet these requirements may have significant adverse effects. This project aims at the development of an engineering methodology for predictable wireless sensor networks. A predictable wireless sensor network is a system for which it is possible to check that its requirements are met under reasonable assumptions regarding its workload and network properties. This project enables the development of predictable wireless sensor networks by providing developers with analytical tools to characterize and optimize the performance of sensor network systems. The intllectual merit of the project includes: (i) Statistical methods for assessing the properties of wireless sensor networks and for provisioning resources to achieve robustness in spite of node failures or temporal variations; (ii) Novel transmission scheduling techniques that ensure a system meets its reliability and real-time requirements; (iii) A new schedulability analysis that bounds network capacity and message latencies under realistic interference models; and (iv) A wireless architecture that instantiates proposed transmission scheduling techniques and the schedulability analysis. In terms of broader impacts, this project will help advance our national capability to develop performance-critical wireless systems. The PIs will teach the developed design and analytical techniques as part of wireless sensor network curriculum and share them with the research community through tutorials.","title":"NeTS: Small: Collaborative Research: Protocols and Analysis for Predictable Wireless Sensor Networks","awardID":"1144552","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560533"],"PO":["565303"]},"177271":{"abstract":"The project assesses patient cardiovascular risk and matches patients to the treatments most likely to be effective. The project addresses this problem through sophisticated computational methods that identify new markers of disease, improve the ability to measure both new and existing markers, and construct personalized models that can provide highly accurate assessments of individual risk. The core focus of the research addresses the poor performance of existing tools for cardiovascular decision support through advanced methods at the intersection of machine learning, data mining, signal processing, and applied algorithms; with the research guided by knowledge of cardiac pathophysiology. <br\/><br\/>This project impacts patient care for a disease that causes roughly one death every 38 seconds in the United States and imposes a burden of over half a trillion dollars in the U. S. each year. More generally, many of the ideas explored here (e.g., personalization of risk models) extends to a wide variety of other disorders in a straightforward manner and leads to wide improvements in outcomes while controlling costs. The research also strengthens interdisciplinary research in EECs and medicine throughout the computer science research community.","title":"SHB: Medium: Collaborative Research: Novel Computational Techniques for Cardiovascular Risk Stratification","awardID":"1065079","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[475241],"PO":["564768"]},"186281":{"abstract":"DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science, has a long history of bringing together groups of researchers with different interests and backgrounds, to study and advance the state of the art in discrete mathematics, theoretical computer science, statistics, operations research, and related areas, as well as their applications in a wide variety of domains including telecommunications, homeland security, the physical sciences, engineering, and public health. DIMACS's signature activity is a \"special focus\" (SF), a multi-year program of coordinated activities involving hundreds of diverse participants and addressing a broad, important topic that is poised for rapid advancement and has high potential for scientific, industrial, and societal impact. The project consists of the following three interacting SFs:<br\/><br\/>1). Information Sharing and Dynamic Data Analysis: The ability to instrument, monitor and collect data provides huge potential to improve life: designing better systems, better managing interactions between large complex systems, identifying subtle problems and bad outcomes. More work is needed to realize systems that span multiple, diverse, noisy data sources and use them to correctly draw conclusions and make decisions. The SF addresses data preparation and quality, privacy and security, continual and distributed processing, and fusion and inference, exploring applications in areas including web search engines and online social networks, healthcare, urban planning and traffic management, and homeland security.<br\/><br\/>2). Algorithms and Energy: It has become a major national and global priority to maintain a robust supply of energy that meets the demands of a growing economy and balances costs and environmental constraints. Themes of the SF are multiscale temporal models, multiscale spatial models, risk and reliability measures, data representation and model sharing, and stochastic optimization that can contribute to our ability to analyze new dynamic energy pricing algorithms, optimize investments in energy generation, storage and transmission, manage a dynamic new power grid, and analyze plans and protocols for electric vehicles and green information technology.<br\/><br\/>3). Cybersecurity: New emerging networks and applications raise more than ever the challenge to provide security and privacy in a world where everything is connected via wired or wireless networks. SF themes address critical infrastructure systems such as the power grid, applications with a high societal, industrial and governmental impact such as the changing landscape of cyber attacks, mechanisms for identity management, security for new paradigms like cloud computing, and fundamental studies such as cryptography, information <br\/>theory, and coding theory.<br\/><br\/>These three SFs will lead to a great deal of research activity, including significant new scientific accomplishments and significant new directions of scientific research. The project has significant potential benefit to society: improved capabilities to handle diverse, dynamic data in turn enables advances in medicine, homeland security, commerce, and other areas; improving and diversifying the energy infrastructure helps maintain affordable access to energy while mitigating the environmental costs of doing so; and improvements in cybersecurity are needed to ensure that we can justifiably rely on systems we use throughout our daily lives. The project also enhances educational programs for students and faculty from K-12 to graduate students.","title":"Three New DIMACS Special Focus Programs","awardID":"1144502","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1260","name":"INFRASTRUCTURE PROGRAM"}}],"PIcoPI":["540234","264120"],"PO":["565251"]},"185192":{"abstract":"This project focuses on understanding the spread of false information during responses to natural disasters and on the development of new techniques to prevent the spread of false information in social media. For example, after the March 11, 2011 major earthquake in Japan, social media such as Twitter played an important role in sharing information and coordinating disaster response. However, social media were also used by some people to spread false information about radiation and supplies, potentially creating widespread panic. The goals of this project are to better understand how false information is spread via Twitter after an emergency and to develop and evaluate new techniques to prevent the spread of false information. To achieve these goals, the investigators will build a visualization tool to measure the effectiveness of counteracting tweets that question the accuracy of false tweets and conduct experiments with university students in Japan and USA in which subjects' familiarity with and likelihood of spreading different types of false and counteracting tweets are measured. <br\/><br\/>Intellectual Merit: The project will provide new insights into the factors that determine the spread of false information, as well a set of recommendations for reducing this spread. The project will also contribute new methods for analyzing the spread of information in social media. <br\/><br\/>Broader Impacts: The insights and tools provided by the project will benefit future disaster response efforts by allowing emergency personnel to detect when false information is being spread and intervene to counteract the effects of false information before negative societal effects such as panic occur.","title":"RAPID: Minimizing the spread of false rumors in social media during a disaster","awardID":"1138658","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["529981"],"PO":["564456"]},"175160":{"abstract":"High-bandwidth, semi-private optical lambda networks carry growing volumes of data on behalf of large datacenters, both in cloud computing environments and for scientific, financial, defense, and other enterprises. These networks are treated as if they are perfect. However, it is not uncommon for them to suffer from unexpected performance degradations and loss rates, even when traffic is well-below capacity. This project studies end-to-end characteristics of lambda networks running at high speeds over long distances, with an eye toward better understanding loss, latency variations, and degraded throughput. This understanding is necessary for the design and efficient use of next-generation lambda networks and to enable the transition to cloud computing.<br\/><br\/>The research described in this project will focus on measuring, characterizing, modeling, and informing new network and protocol design for optical lambda networks. The educational activities will make aspects of network research more accessible to students; promote research initiative among undergraduate and graduate students, and leverage (interdisciplinary) collaborations between Cornell and Howard University, a historically black college and university (HBCU).<br\/><br\/>Intellectual Merit: Fundamental science requires well controlled experiments and observation. The research described in this project will produce novel network measurement instruments, along with a body of experimental knowledge needed for building networks and protocols that exhibit high performance. The research agenda has three major components.<br\/><br\/>- Further Development of the Software Defined Network Adapter (SDNA) that the PI has designed. SDNA provides precise and reproducible measurements of an optical lambda network. By achieving extremely high levels of precision, SDNA can shed light on the complexities of flows that traverse high-speed networks.<br\/>- Use of SDNA to measure and characterize optical lambda networks. These measurements will help explain observed packet loss at low data rates and reveal new aspects of network behavior.<br\/>- Research and deploy new network protocols that enhance end-to-end performance perceived by applications.<br\/>New network protocols will allow application developers and datacenter operators to better take advantage of the capacity of the underlying optical networks.<br\/><br\/>Broader Impacts: The education\/outreach agenda is designed to foster an environment for developing a new generation of network researchers who will take a keen interest in hands-on experimentation. There are two major components:<br\/>- Research opportunities for undergraduate and graduate students as well as faculty during the summer and in a semester-long class. This will include exploring the design of hardware and software layers for an SDNA apparatus and using SDNA to conduct network research and analyze network measurements.<br\/>- A partnership with Howard University (an HBCU) to collaborate on network research and inspire the next generation of underrepresented minority researchers.","title":"CAREER: Towards Inter-Datacenter Communication for Next-Generation Networks","awardID":"1053757","effectiveDate":"2011-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["502829"],"PO":["565090"]},"186050":{"abstract":"This award provides funding for a collaborative project between University of California, Los Angeles and Indian Institute of Information Technology, New Delhi, India. Buildings are among the largest consumers of energy, both directly in the form of electricity, gas etc. as well as indirectly through consumption of water as part of the critical energy-water nexus that one must consider for true sustainability. The objective of this project is to develop the foundations of low-cost and easy-to-deploy sensing methods that provide observability into patterns and causes of energy and water consumption in a building, and run-time methods that use the sensory information for intelligent control of various buildings systems to minimize the direct and indirect energy use. The project team is collaborating with international academic and industrial collaborators who offer access to complementary experimental opportunities and unique opportunities to develop low-cost technologies that scale across different climatic and socioeconomic contexts. Key elements of the research include (i) Low-cost self-calibrating sensors that infer energy and water usage indirectly from side-band signals, (ii) Methods to reduce overall energy and water footprint by better management of building subsystems, by timely identification and repair of energy and water wasting physical degradations, and by providing information feedback and incentives to influence occupant behaviors, and (iii) Study of the impact of human, cultural and societal factors on privacy, safety, and user interaction mechanisms. The project has the potential of significant socioeconomic benefits by facilitating assessment of efficacy of conservation measures, targeting of incentives, auditing compliance with regulations, and facilities maintenance. The project also contributes to workforce development and training of students on energy challenges in a global socioeconomic context. This project is a part of pervasive communications and computing collaboration (PC3) initiative.","title":"PC3: Pervasive Sensing and Computing Technologies for Energy and Water Sustainability in Buildings","awardID":"1143667","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["539241","515835"],"PO":["563661"]},"186083":{"abstract":"This proposal seeks to further a network of sociotechnical researchers in academia and industry capable of developing innovative applications that leverage next-generation gigabit networking infrastructure. This will foster new multidisciplinary partnerships between the social and computing sciences that will challenge established researchers and develop a new generation of students capable and confident in working in this area. The complex domains addressed by these applications, for example city-wide, media-rich socialinformation spaces for homeless citizens, will necessitate fundamental advances in network science. The emergent co-evolutionary properties will also likely drive research in human-centered computing. The urban government partnerships enable a scale of deployment typically impractical for academic research labs. This will enable at-scale experimentation with a critical mass of users in authentic usage environments, which is essential for advancing our understanding of social computing.<br\/><br\/>The project proposes a culminating two-day proto-proposal development workshop. The projects that emerge from this workshop will help envision a new future in which high-bandwidth connectivity coupled with a reengineered Internet enables new forms of social interaction and digital citizenship.","title":"WORKSHOP: Building Capacity for Sociotechnical Innovation in Next-Generation Network Applications","awardID":"1143828","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["264837"],"PO":["564993"]},"178240":{"abstract":"The intersection of Computer Science and Economics has become increasingly important to the development of both fields. Today's software often must handle multiple individuals with their own interests in mind, bringing incentive issues to the forefront in algorithm design. Economic problems, especially in electronic commerce, increasingly involve large numbers of goods and buyers as well as unknown and complex market conditions, making algorithms and machine learning of key importance. This project aims to address fundamental questions at the heart of the intersection of these two fields. These include problems of modeling and influencing behavior in systems with large numbers of agents and components, problems of optimization under complex and changing preferences and constraints in electronic commerce, and problems of efficiently computing and estimating basic economic quantities.<br\/><br\/>This project specifically has three main thrusts. The first is development of algorithms and analysis techniques for positively influencing dynamics in systems with large numbers of interacting agents. For example, if behavior is currently at a poor-quality equilibrium, when can additional information or a few targeted incentives be used to \"nudge\" behavior towards a good equilibrium? This applies not only to self-interested agents but also to components in a distributed system acting on local information (such as sensors in a sensor network). The second thrust is development of algorithms for efficiently computing or estimating important economic quantities. This includes approximately computing Nash equilibria in large interactions, and learning submodular functions and other common valuation classes from observations of behavior or experimentation. The third thrust is developing mathematical frameworks for understanding and solving problems of pricing and resource allocation in settings with unknown and changing market conditions. These frameworks are crucial for next-generation markets for resources such as computing power and network bandwidth.","title":"ICES: Small: Collaborative Research: Algorithms and Mechanisms for Pricing, Influencing Dynamics, and Economic Optimization","awardID":"1101283","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":["565091"],"PO":["565251"]},"178361":{"abstract":"Mechanism design lays the economic foundations for the design and analysis of economic institutions, social and computer protocols, service provisioning, and other applications where participants may act selfishly in their own best interest. A common paradigm for real-world mechanism design is trial and error: a mechanism is proposed, it is executed, then changes are made to it based on its performance. In order to make these changes an econometric analysis must be undertaken, i.e., the participants' actions in the mechanism (assumed to be in equilibrium) must be reverse engineered to obtain the participants' preferences. Using these inferred preferences, potential changes to the mechanism can be evaluated and ranked. While mechanism design theory for the most part relies on knowledge of the market, real world mechanisms tend to do some market analysis on the fly. The PIs research will combine econometric inference with mechanism design theory to investigate the econometric properties of mechanisms and design mechanisms that are simultaneously good at market analysis and exploiting that information to attain an objective specified by the mechanism designer.<br\/><br\/>This research program will introduce econometric techniques to computer science and will bring together topics from computer science and economics that have yet to be studied together. For example, these issues are very important in practice especially in the rapidly growing areas of sponsored search and targeted display advertising where auction mechanisms have been deployed for pricing and placement of advertisements and a major challenge is in adjusting the mechanisms in response to past data.","title":"ICES: Large: Collaborative Research: Towards Realistic Mechanisms: statistics, inference, and approximation in simple Bayes-Nash implementation","awardID":"1101706","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[478173],"PO":["565251"]},"178273":{"abstract":"In the last decade private data has become a commodity - it is gathered, bought and sold, and contributes to the primary business of many Internet and information technology companies. At the same time, various formalizations of the notion of \"privacy\" have been developed and studied by computer scientists. Nevertheless, to date we lack a theory for the economics of digital privacy, and this project aims to close this important gap.<br\/><br\/>Concretely, the project will develop a theory to address the following questions:<br\/><br\/>- How should a market for private data be structured? How can one design an auction that accommodates issues specific to private data analysis: that the buyer of private data often wishes to buy from a representative sample from the population; and that individuals' value for their privacy can itself be a very sensitive piece of information?<br\/><br\/>- How should other markets be structured to properly account for participants' concerns about privacy? How should privacy be modeled in auction settings, and how should markets be designed to address issues relating to utility for privacy?<br\/><br\/>- Studying economic interactions necessitates studying learning - but what is the cost of privacy on agent learning? How does the incomplete information that is the necessary result of privacy-preserving mechanisms affect how individuals engaged in a dynamic interaction can learn and coordinate, and how do perturbed measurements affect learning dynamics in games? How can market research be conducted both usefully and privately?<br\/><br\/>Our investigation of these questions will blend models and methods from several relevant fields, including computer science, economics, algorithmic game theory and machine learning.<br\/><br\/>This project directly addresses one of the most important tensions that the Internet era has thrust upon society: the tension between the tremendous societal and commercial value of private and potentially sensitive data about individual citizens, and the interests and rights of those individuals to control their data. Despite the attention and controversy this tension has evoked, there is no comprehensive and coherent science for understanding it. Furthermore, science (rather than technology alone) is required, since the technological and social factors underlying data privacy are undergoing perpetual change. Within the field of computer science, the recently introduced subfield of privacy preserving computation has pointed the way to potential advances. This project aims to both broaden and deepen these directions.","title":"ICES: Large: Economic Foundations of Digital Privacy","awardID":"1101389","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[477964,477965,"534274","486003","486003"],"PO":["565251"]},"178284":{"abstract":"Mechanism design lays the economic foundations for the design and analysis of economic institutions, social and computer protocols, service provisioning, and other applications where participants may act selfishly in their own best interest. A common paradigm for real-world mechanism design is trial and error: a mechanism is proposed, it is executed, then changes are made to it based on its performance. In order to make these changes an econometric analysis must be undertaken, i.e., the participants' actions in the mechanism (assumed to be in equilibrium) must be reverse engineered to obtain the participants' preferences. Using these inferred preferences, potential changes to the mechanism can be evaluated and ranked. While mechanism design theory for the most part relies on knowledge of the market, real world mechanisms tend to do some market analysis on the fly. The PIs research will combine econometric inference with mechanism design theory to investigate the econometric properties of mechanisms and design mechanisms that are simultaneously good at market analysis and exploiting that information to attain an objective specified by the mechanism designer.<br\/><br\/>This research program will introduce econometric techniques to computer science and will bring together topics from computer science and economics that have yet to be studied together. For example, these issues are very important in practice especially in the rapidly growing areas of sponsored search and targeted display advertising where auction mechanisms have been deployed for pricing and placement of advertisements and a major challenge is in adjusting the mechanisms in response to past data.","title":"ICES: Large: Collaborative Research: Towards Realistic Mechanisms: statistics, inference, and approximation in simple Bayes-Nash implementation","awardID":"1101429","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":["551023"],"PO":["565251"]},"183070":{"abstract":"Proposal #: 11-26344<br\/>PI(s): Hallstrom, Jason<br\/> Edison, Gene; Geist, Robert; Goasguen, Sebastian: Post, Christopher<br\/>Institution: Clemson University <br\/>Title: MRI\/Dev: Dev of the Intelligent River (R), a Basin-Scale Monitoring Instrument <br\/>Project Proposed:<br\/>This project, developing a river and water-resource consisting of a sensor network that forms an intelligent sensor fabric on a river basin, aims to provide real-time access to essential environmental and hydrological parameters at appropriate temporal and spatial scale for managing resources. Based on the INTELLIGENT RIVER\u00ae, this observation instrument comprises in situ sensors that form an expansive intelligent fabric. The instrument enables a new <br\/>1. Sensing Fabric: serves as the instrument lens and comprises multiple sensor networks.<br\/>2. Transit and Uplink System: responsible for relaying the data from the lens to a high-performance computing backbone.<br\/>3. Observation Management Middleware: responsible for normalizing data, ensuring validity, and routing the resulting data streams to end users applications<br\/>4. Repository and Presentation Services: serves as an instrument eyepiece and comprises an extensible set of applications.<br\/>The design of the goals in 1 include broad support for interconnect standards, support for high-fidelity sensing, scalable temporal and spatial coverage, rapid and reliable deployment, and system longevity. In 2, these goals include adaptability to diverse environments, coverage scalability, fault-tolerant data transport, and low cost operating expense. Scalability, real-time performance, and fault-tolerant, secure messaging are included in 3. The default instrument package in 4 includes an application for archiving observation data to common scientific data formats and presenting that data to a broad audience of end-users, including scientists, educators, ecosystem managers, and legislative policy makers.<br\/>It is evident that the growing mismatch between water supply and demand impacts us all: USA watersheds are in peril! This project does something about it with support from EPA and USAGE. Within the reach of environmental science, this work explores the connections among land use, energy production, climate effects, and water resources applying information and computing systems. The design, construction, and deployment of the instrument along the full reach of the Savanna River and two adjacent watersheds, covering a broad range of physical and chemical parameters should yield significant research contributions applicable to other watersheds and across subdisciplines, from sensor networking, to operating system design to cloud computing, to high performance ecosystem visualization. When complete, the instrument should enable a new class of data-intensive environmental ecological programs, ranging from fine-scale studies of river transport phenomenon to assessments of hydroelectric impacts on greenhouse gas concentrations, as well as the validation of kinetic-based quality models. Moreover, the instrument should yield significant research contributions in the areas of sensor networking, operating system, cloud computing, and high-performance ecosystem visualization.<br\/>Broader Impacts: <br\/>The impact should be felt both regionally and nationally. At the national level, the instrument should initiate a transformative shift towards real-time management. At the local level the instrument will contribute to initiate two new degree programs, creating collaborative ties with other institutions, and serve as an outreach hub that links regional high schools and museums.","title":"MRI: Development of the Intelligent River (R), A Basin-Scale Monitoring Instrument","awardID":"1126344","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[490673,490674,490675,490676,490677],"PO":["557609"]},"185160":{"abstract":"The University of California, San Diego and San Diego State University propose the Computing Principles for All Students' Success (ComPASS) Project that will build local capacity for teaching the proposed new Advanced Placement CS Principles (CSP) course. ComPASS will create novel curricula and methodology content for teacher profession development. The project will develop and evaluate pedagogical content knowledge curriculum to support the adoption of best methods and practices in teaching CSP content. It will continue the engagement of the San Diego-area computing education community, and tailor its offered training and support to engage university faculty, as well as in-service and pre-service teachers both with and without computing backgrounds. It will build comprehensive, multi-pronged, flexible, and scalable infrastructure to train and support teachers and faculty and it will pilot that infrastructure at 2 universities, 5 community colleges, and 15 high schools. The project's research component will evaluate the use of blended-learning approaches in transferring effective pedagogical techniques to diverse instructor groups. In addition, the pilot sites have been chosen to reflect a commitment to serving underrepresented populations and the research plan includes a qualitative study of the attitudes of those students with respect to course content and their beliefs about computing. ComPASS will foster the implementation of broadbased, inclusive, and motivational education in computing foundations and computational thinking for all students, regardless of their eventual career path. The ComPASS project will directly impact 105 pre-service teachers, 19 in-service teachers, and about 5000 students. If successful, its model could be adopted at other universities, colleges, and school districts.","title":"Collaborative Research: Type 1: CE 21: Computing Principles for All Students' Success (ComPASS)","awardID":"1138492","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":["497999","498000"],"PO":["561855"]},"186381":{"abstract":"This award is made to the Semiconductor Research Corporation (SRC) to hold a workshop in the area of sensor technologies together with the Irish counterpart of the National Science Foundation. The focus is not as much on sensor networks, but more on how lower level circuits and device technology including emerging bio-nano sensor technologies can have a possible impact. Various application areas e.g., from civil infrastructure to bio-sensing will be examined, with primary focus on circuits and device technologies. Various relevant industry constituents, both from the US and Europe, are going to be invited to this workshop, but for obvious reasons only the US participants will be able to receive benefits of NSF support. <br\/><br\/>The potential broader impact of the outcome of the workshop, albeit of somewhat technical nature, is expectedly very large. One of the several goals is to explore new technologies that may lead to small businesses and startups. In this vein, the several US academic participants with experience with startup technologies are being invited as well. In the long run sensors may benefit the educational arena as well via adoption of sensor technology in new courses and university curriculum, but the present proposal does not plan to be engaged in such activities.","title":"Forum on Integrated Sensors for Cybersystems (FISC-2030)","awardID":"1144999","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[500150,"525950"],"PO":["562984"]},"186172":{"abstract":"In the last 50 years, computational linguistics research has touched barely 1% of the world's languages. In 100 years, 90% of them will be extinct or nearly so. What can computational linguistics offer to support the urgent task of documenting and analyzing the world's endangered languages? Based on the observation that bilingual parallel text is both the primary artifact collected in documentary linguistics as well as the primary object of statistical translation models, this project explores the use of machine translation to accelerate the global language documentation effort. Specifically, it develops novel ways to model any number of related languages simultaneously, pooling information from all the languages to make stronger inferences about each. In order to exploit language relationships, it explores methods that simultaneously model phonological, morphological, lexical, and syntactic phenomena. In addition, it develops algorithms to standardize highly variable transcription practices.<br\/><br\/>These technologies, which will be field-tested in the Eastern Highlands of Papua New Guinea, are designed to enable speakers of endangered languages who have no specialized linguistic training to create large collections of translated oral literature, providing an authentic and interpretable record of their language, serving current and future generations of scholars, teachers, and learners. They will do so, moreover, at much less cost than is needed to support the efforts to trained linguists and ethnographers to create such collections.","title":"EAGER: Machine Translation for Language Preservation","awardID":"1144167","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}}],"PIcoPI":[499581],"PO":["565215"]},"177251":{"abstract":"Operators of networks and distributed systems often find themselves needing to answer a diagnostic or forensic question -- some part of the system is found to be in an unexpected state, and the operators must decide whether the state is legitimate or a symptom of a clandestine attack. In such cases, it would be useful to ask the system for an 'explanation' of the observed state. In the absence of attacks, emerging network provenance techniques can construct such explanations by constructing a chain of events that links the observed state to its root causes. However, an attacker can cause the nodes under his control to forge or suppress information and thus produce a plausible (but incorrect) explanation. As a result, the operators may fail to notice the attack.<br\/><br\/>This research develops secure network provenance techniques that can provide useful explanations even when the system is under attack by a powerful adversary. The project (i) substantially extends and generalizes the concept of network provenance by adding capabilities needed in a forensic setting; (ii) develops techniques for securely storing provenance without any trusted components; (iii) designs methods for efficiently querying secure provenance; (iv) introduces methods for protecting the confidentiality of provenance; and (v) evaluates these techniques in the context of concrete applications.<br\/><br\/>The project's theme of provenance and forensics is integrated with Penn's new undergraduate program in Market and Social Systems Engineering. It will provide forensics support for a wide variety of distributed applications, including emerging cloud applications upon which critical infrastructure may soon be based.","title":"TC: Medium: Collaborative Research: Tracking Adversarial Behavior in Distributed Systems with Secure Networked Provenance","awardID":"1064986","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["519691"],"PO":["565327"]},"186084":{"abstract":"Pioneering work of Seeman, Winfree, and Rothemund has raised the prospect of engineering useful structures and devices that autonomously assemble themselves from molecular components. Developing this capability will have transformative benefits for medicine, information technology, manufacturing, energy production, and other enterprises of twenty-first century society. In this project a team of scientists with expertise in self-assembly, software engineering, formal verification, programming languages, theory of computing, biochemistry, and molecular biology will explore the power and limitations of this \"programming of matter\" at the nanoscale.<br\/><br\/>The central thesis of this project is that methods that software engineers and theoretical computer scientists have developed for creating, controlling, and reasoning about software, hardware, networks, and environments of immense complexity will be an essential starting point for dealing with the greater challenges that nanotechnology will confront. The project will investigate applications of computational modeling, algorithmic randomness, requirements engineering, product lines, software verification, and software safety to DNA tile assembly, DNA origami, and DNA strand-displacement reactions. The project will conclude with a clear assessment--hopefully a compelling proof of concept--of the applicability and adaptability of software engineering methods in molecular programming and nanoscale self-assembly.<br\/><br\/>The project will contribute to a rigorously reasoned, verification- and safety-oriented approach to the social benefits of nanoscale self-assembly. It will strengthen software engineering methods as it adapts them to challenging new domains. It will enhance interdisciplinary science education at Iowa State University and nearby Simpson College, and it will provide web-accessible educational materials for such activities elsewhere.","title":"EAGER: Collaborative Research: Modeling and Analysis of Molecular Programming and Nanoscale Self-Assembly","awardID":"1143830","effectiveDate":"2011-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["531355","531357","531356","531354","510759"],"PO":["564388"]},"184171":{"abstract":"The XIX International Conference on Computational Methods in Water Resources will be held June 17-21, 2012, on the campus of the University of Illinois at Urbana-Champaign. This biennial series of meetings has served as the premier venue for engineers, geoscientists, hydrologists, computer scientists and applied mathematicians to present and discuss their latest research. The increase in raw computational power, software developments, availability of on-line hydrologic data, and recent advances in cyber-infrastructure make this a particularly exciting time for computational applications to water resources and geoscience challenges. The conference will serve as a unique forum to bring together those from the computer science\/applied math community who work in methods and tools with those from engineering, geoscience, government and industry who are responsible for addressing pressing water-related problems. Topics of pressing societal relevance being emphasized in special sessions include: climate change impacts on hydrology, river mechanics, circulation in coastal oceans, ecohydrology, contaminant transport in surface water and groundwater, and geological sequestration of carbon dioxide.<br\/><br\/>NSF support will allow undergraduate and graduate students to register at a reduced rate, thereby facilitating participation by students. Students and post-docs will benefit from the opportunity to present their work at a major international conference. The conference will foster interactions among those from academia, government, and industry, and will also enhance international exchange. At the last meeting in the United States, approximately 40% of the participants were international, representing more than 20 countries. Students and other conference attendees will have the opportunity to interact with the distinguished plenary speakers, who represent a diverse international group that includes both senior and mid-career scholars. Students will submit full papers, thus providing another opportunity for student training. The conference proceedings will be openly available on the conference web site, thereby benefitting the entire scientific community.","title":"Conference Support for the XIX International Conference on Computational Methods in Water Resources (CMWR 2012)","awardID":"1132243","effectiveDate":"2011-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0603","name":"Division of EARTH SCIENCES","abbr":"EAR"},"pgm":{"id":"1579","name":"HYDROLOGIC SCIENCES"}}],"PIcoPI":[493895],"PO":["564446"]},"186382":{"abstract":"Social Network, mobility and the cloud represent special and unique opportunities for synergy among several existing and emerging communities that are now often evolving in isolated silos. All three areas hold much promise for the future of computing and represent significant challenges for large scale data management. As these three areas evolve, their direct influence on significant decisions on each other becomes evident and critical. The potential for cross fertilization among these three areas of important research will drive much of the research in academia, and the products in industry. This two-day NSF workshop brings together leading researchers, practitioners, and planners to discuss and articulate interesting directions that the community should pursue in deploying large-scale mobile and social network applications in the cloud environment. The workshop includes invited talks, panels and breakout sessions.<br\/><br\/>This workshop has broader impacts across multiple segments of society as: (1) social network and mobile applications have the potential to significantly enhance productivity and quality of life;(2) the workshop produces a set of research challenges and directions that seed research projects and grant proposals that prepare and educate the next generation of researchers and students who will be critical for building the foundations of future computing, both short term in industry as well as long term in both academia and industry; and (3) the workshop widens the scope of research in each of its three main communities: social networks, mobile applications, and cloud environment, to include new aspects that evolve from integrations with the other two communities. More information on the workshop can be found at http:\/\/NSFSocialMobilityCloud.cs.umn.edu\/.","title":"NSF III Workshop on Social Networks and Mobile Applications in the Cloud","awardID":"1145004","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[500153,"518156","548220"],"PO":["563727"]},"187163":{"abstract":"Many infrastructure industries have made the transition from private ownership to utility, often through intermediate stages. It is believed that computing is in the midst of this transition today. The PIs believe that wireless-based systems will follow the same route in time. This path promises to alleviate the spectrum bottlenecks that plague emergent wireless applications. For this to occur, technological advances must take place that elicit cooperative behavior from firms that also compete with each other. These advances must leverage advances in radio system design, including cognitive radios. Relying heavily on system design methodologies and agent-based simulation modeling, this research explores the relationships between cooperation, competition and the implementation mechanisms, including system architectures and protocol design, especially where agents optimize locally. Particular attention is paid to the scalability of different approaches to large numbers of devices and heterogeneous uses. In the application to wireless systems, the research pays particular attention to ways in which transmission opportunities (called spectrum holes) may be created. These outcomes will enable easier access to wireless connectivity to emergent applications, thus enabling application designers to build services with explicit quality expectations for their users. Realistic models are constructed so that the mechanisms for spectrum hole generation and their use through protocols can be evaluated. The results will be published in major communications conferences and journals, and the development of pilot applications will be encouraged.","title":"Cooperation under Competition: System implications for DSA and computing systems","awardID":"1149442","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["194325","563662"],"PO":["557315"]},"176163":{"abstract":"Power consumption imposes significant design constraints across the entire spectrum of computing, from the smallest handheld device to the largest data center. New technology nodes provide significant size reduction advantages, but introduce significant challenges in the power and process variability domain. These new technology nodes introduce concerns in the available first-order models commonly used by the research community. Transistor-level and gate-level simulators can offer higher accuracy, but are too slow to model multicore processors running real programs.<br\/><br\/>Fundamentally, validating novel power-centric ideas is limited by our ability to anticipate the future and to model large-scale effects or relatively poorly understood phenomenon. Fabricating prototypes can bridge the gap, but prototype-based architecture research requires a considerable amount of complex infrastructure making it relatively rare for academic researchers. This projects proposes a complete prototyping platform, that will greatly reduce the cost and effort required for prototype-based research into power-centric multicore architectures.","title":"Collaborative Research: II-NEW: Prototyping Platform to Enable Power-Centric Multicore Research","awardID":"1059264","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["518228","518229"],"PO":["563661"]},"187174":{"abstract":"This project seeks to improve the quality and reliability of Analog\/Radio-Frequency (RF) integrated electronic circuits (ICs) by developing an intelligent system for systematically exploring the wealth of information generated throughout their production lifetime and applying it towards improving the effectiveness of their design, manufacturing, and testing. While a large amount of data is made available through extensive design simulations and measurements on actual fabricated circuits, there currently exists a striking lack of formal methods to efficiently extract meaningful information from this data. The research activities that will be carried out through this project aim to fill this void by developing correlation mining methods based on the most recent developments in the fields of machine learning and data mining. Ultimately, using data from actual IC productions provided by industrial partners (i.e. IBM and Texas Instruments), the objective of this project is to demonstrate the impact that such correlations can have on reducing the cost of testing, enhancing the yield of the production and enabling post-manufacturing calibration of analog\/RF circuits. <br\/><br\/>This project will facilitate the cost-effective realization of robust electronic circuits and systems, thus enabling more reliable computing and promoting technology trustworthiness. The proposed research is complemented by educational and outreach activities, including the development of a new graduate-level course on applications of Machine-Learning in Computer Aided Design and Test and the involvement of graduate, undergraduate and high-school students in research with the groups of the Principal Investigators, the industrial partners, and the research laboratory of the international collaborator.","title":"SHF: Small: Collaborative Research: Correlation Mining and its Applications in Test Cost Reduction, Yield Enhancement, and Performance Calibration in Analog\/RF Circuits","awardID":"1149463","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["550120"],"PO":["562984"]},"177142":{"abstract":"The Forum on Neuroscience and Nervous System Disorders focuses on building partnerships and enabling interdisciplinary large-scale research between the basic and applied sciences, which are necessary to understand the normal brain and nervous system, as well as, disorders in their structure and function. With funding from the National Science Foundation, Dr. Bruce M. Altevogt of the National Academy of Sciences directs the Forum, which brings together leaders from private sector sponsors of basic research, biomedical and clinical research, federal agencies sponsoring and regulating biomedical and clinical research, foundations, the academic community, and consumers. Quarterly the membership plans and organizes meetings to discuss issues of mutual interest and concern. In addition, the Forum sponsors workshops for members and the public to discuss approaches to resolve key challenges identified by Forum members. For example, upcoming workshops are addressing topics such as training and education for the next generation of neuroscientists, neuroscience animal models, environmental and genetic factors that affect the brain, and improving quality of care for individuals with neurological disorders in Sub-Saharan Africa. The IOM is focusing on data sharing collaboration and data mining. It is examining what is requried to merge industry and academic studies.<br\/><br\/>Through its meetings and workshops the Forum strives to enhance understanding of research and clinical issues associated with the nervous system among the scientific community and the general public, and provide a mechanism to foster partnerships among stakeholders. This project is being co-funded by the Behavioral & Cognitive Sciences Division of the Social, Behavioral, and Economics Directorate, the Chemical, Bioengineering, Environmental, and Transport Systems (CBET)Division of the Engineering Directorate, and the Information and Intelligent Systems Division of the Computer & Information Science & Engineering Directorate.","title":"Forum on Neuroscience and the Nervous System","awardID":"1064270","effectiveDate":"2011-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1699","name":"COGNEURO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"5345","name":"BIOMEDICAL ENGINEERING"}}],"PIcoPI":[474919],"PO":["565045"]},"177285":{"abstract":"Operators of networks and distributed systems often find themselves needing to answer a diagnostic or forensic question -- some part of the system is found to be in an unexpected state, and the operators must decide whether the state is legitimate or a symptom of a clandestine attack. In such cases, it would be useful to ask the system for an 'explanation' of the observed state. In the absence of attacks, emerging network provenance techniques can construct such explanations by constructing a chain of events that links the observed state to its root causes. However, an attacker can cause the nodes under his control to forge or suppress information and thus produce a plausible (but incorrect) explanation. As a result, the operators may fail to notice the attack.<br\/><br\/>This research develops secure network provenance techniques that can provide useful explanations even when the system is under attack by a powerful adversary. The project (i) substantially extends and generalizes the concept of network provenance by adding capabilities needed in a forensic setting; (ii) develops techniques for securely storing provenance without any trusted components; (iii) designs methods for efficiently querying secure provenance; (iv) introduces methods for protecting the confidentiality of provenance; and (v) evaluates these techniques in the context of concrete applications.<br\/><br\/>The project's theme of provenance and forensics is integrated with Penn's new undergraduate program in Market and Social Systems Engineering. It will provide forensics support for a wide variety of distributed applications, including emerging cloud applications upon which critical infrastructure may soon be based.","title":"TC: Medium: Collaborative Research: Tracking Adversarial Behavior in Distributed Systems with Secure Networked Provenance","awardID":"1065130","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["517980","518109",475279],"PO":["565327"]},"177296":{"abstract":"The goal of this research is to develop techniques that will permit a computer or robot to learn from examples to carry out multipart tasks specified in natural language on behalf of a user. It will study each of these components in isolation, but a significant focus will be on integrating them into a coherent system. The project will also leverage this technology to provide an entry point to educate non- or pre-computer science students about the capabilities and utility of computers as tools.<br\/><br\/>Our approach uses three main subcomponents, each of which requires innovative research to solve its portion of the overall problem. In addition, the integrated architecture is a novel contribution of this work. The three components are (1) recognizing intention from observed behavior using extensions of inverse reinforcement learning, (2) translating instructions to task specifications using novel techniques in the area of natural language processing, and (3) creating generalized task specifications to match user intentions using probabilistic methods for creating and managing abstractions.<br\/><br\/>The goal of the work is develop technology for an improved ability for human users to interact with intelligent agents, the incorporation of novel AI research insights and activities into education and outreach activities, and the development of resources for the AI educator community. In addition to permitting intelligent agents to be developed and trained in the future for a broad range of complex application domains, the interactive agents that we will develop will be used for outreach and student learning.","title":"RI: Medium: Collaborative Research: Teaching Computers to Follow Verbal Instructions","awardID":"1065195","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550488",475313],"PO":["562760"]},"188065":{"abstract":"This proposal requests travel funds from NSF to assist 50 US students to participate in IROS 2011, which will be held in San Francisco, CA, Sep. 25-30, 2011. The purpose of this Group Travel Grant Proposal is to make it possible for US students and postdocs to attend the conference, present their work, and forge connections with colleagues from around the world. <br\/><br\/>This year mark the 50th anniversary of robotics. In addition to the regular conference, IROS 2011 will feature interactive presentations, robot demonstrations, thematic plenary sessions on design, bio-robotics, and intelligent transportation, and special-topic symposia celebrating 50 years of robotics. As part of this award, students will also have the opportunity to participate in these historical events and learn more about the field of robotics. Travel funding will be in the form of partial airfare reimbursement and full reimbursement for student registration to approximately 50 U.S. students who plan to present at least one paper at the Conference.<br\/><br\/>The \"big two\" major international robotics conferences were outside of North America this past year, so demand should be very high from American students and professors to attend this major robotics event. The benefit to student learning and mentorship by encouraging attendance of students by direct monetary means brings large dividends in student confidence, knowledge and expertise.","title":"IEEE\/RSJ International Conference on Intelligent Robots and Systems (IROS 2011) Student Travel Awards","awardID":"1153994","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["543408"],"PO":["543539"]},"187780":{"abstract":"This is funding to support a one day interdisciplinary Workshop on Interactive Systems in Healthcare 2011 (WISH 2011), to be held on October 22, 2011 in conjunction with the 2011 Annual Meeting of the American Medical Informatics Association (AMIA). The workshop will bring together a diverse set of researchers from a range of disciplines, all of whom do research relevant to the development of Interactive Systems for Healthcare but who rarely have opportunities to interact. Attendees will include specialists in medical informatics, nursing informatics, medical sociology, human-computer interaction, and related fields. The goal is to promote interdisciplinary exchange of ideas about this important area of research and to advance the development of new healthcare technologies. <br\/><br\/>Participants will be selected through a peer review process based on materials submitted in response to the call for papers. The submission materials include a five-page paper in the AMIA submission format, including an abstract and a description of the participant\u00a8Vs research. The papers for accepted participants will be available as part of the WISH proceedings. Selected papers will be presented as either short talks or interactive posters.<br\/><br\/>Broader impacts: Addressing the complex interplay between human, organizational, and technological systems in healthcare is an important research area with the potential to impact quality, safety, efficiency, and effectiveness of health care in America. The workshop will improve attendees' current research projects through interdisciplinary feedback from other workshop participants, promote this area of research more generally through its visibility at the AMIA conference, lead to new interdisciplinary collaborations that can advance medical informatics, and help educate graduate students and post-doctoral fellows who want to work in this area. A workshop website and proceedings will make the content widely available to other researchers and the general public.","title":"Workshop on Interactive Systems in Healthcare 2011","awardID":"1152556","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[503387],"PO":["565342"]},"183193":{"abstract":"Proposal #: 11-26896 <br\/>PI(s): Hoanca, Bogdan; Mock, Kenrick <br\/>Institution: University of Alaska at Anchorage<br\/>Title: MRI: RUI: Acquisition of Eye Tracking Equipment to Support Research at UAA<br\/>Project Proposed:<br\/>This project, acquiring two eye tracking systems, (along with wireless sensors for creating a biometric profile for a computer user), enables new and innovative research directions in user authentication, assistive software for teaching mathematics, context aware document retrieval, and student attentiveness. These new, state-of-the-art eye trackers will replace two lower quality eye trackers, freeing one up for student use. The eye trackers will be located in a controlled-access, public use laboratory available to several researchers at the University of Alaska at Anchorage. <br\/>The enhanced capabilities of the new eye trackers will permit greater range of motion for more natural user interaction and higher accuracy for better biometrics. Consequently, the work will permit transformational research into more natural and transparent user authentication and computer security based on a comprehensive set of biomarkers, assistive research into mathematical learning techniques for persons with disabilities, enhanced, biomarker-based intelligent search and document categorization through online user profiling, and enhanced assessment of learning efficacy. Aside from brain activity, eye patterns are one of the most direct windows into a person?s understanding and mental activity. <br\/>Broader Impacts:<br\/>The broader impacts include the involvement of 4-6 undergraduate students per year in eye tracking research by the co-PIs, with possibly another 4-6 undergraduates per year from other faculty. Four broader impacts are apparent. First, if widely deployed, the proposed authentication scheme has the potential to thwart phishing attacks, and even man in the middle attacks, for e-commerce users. Second, advanced assistive technology for mathematics will allow physically disabled people to perform math manipulations on par with able-bodied people. Third, by tracking what a user actually reads, user profiling will result in better, faster searches for relevant information automatically. Finally, high quality eye tracking should provide the UAA faculty with insight into the direct connections between learning and eye patterns","title":"MRI: RUI: Acquisition of Eye Tracking Equipment to Support Research at UAA","awardID":"1126896","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[491237,491238],"PO":["543539"]},"184040":{"abstract":"Functional magnetic resonance imaging (fMRI) has become the most common tool for cognitive neuroscience, because it provides a safe, non-invasive, and powerful means to image human brain function. Based on recent rates of publication, there are currently more than 2000 fMRI studies being performed every year worldwide. The aggregation of data across multiple studies can provide the ability to answer questions that cannot be answered based on a single study. For example, using datasets from multiple domains one can start to investigate to what degree a region is selectively engaged in relation to a particular mental process, as opposed to being generally engaged across a broad range of tasks and processes. In addition, it provides the ability to integrate across specific tasks to obtain stronger empirical generalizations about mind-brain relationships, and to better understand the nature of individual variability across different measures. Recent work in neuroimaging analysis has focused on the application of methods such as machine learning techniques to understand the coding of information at the macroscopic level, and network analysis techniques to understand the interactions inherent in large-scale neural systems. The availability of a large testbed of high-quality fMRI data from published studies would also provide an important resource for the development of these and other new analytic techniques for fMRI data. However, sharing of raw fMRI data is challenging due to the large size of the datasets and the complexity of the associated metadata, and there is currently no infrastructure for the open sharing of new fMRI datasets.<br\/><br\/>This project, OpenfMRI, will provide a new infrastructure for the broad dissemination of raw data within cognitive neuroscience, addressing a critical need by providing an open data sharing resource for neuroimaging. The initial project is already online at http:\/\/www.openfmri.org with a limited number of datasets. The full project will greatly expand this repository by providing access to a large number of fMRI datasets from several prominent neuroimaging labs, spanning across a broad range of cognitive domains. Utilizing the substantial computational resources of the Texas Advanced Computing Center, the project will also perform standard fMRI analyses on all data in the repository using a common analysis pipeline, thus providing directly comparable analysis results for all of the studies in the database. The OpenfMRI project will support the development of infrastructural elements to make sharing of data by additional investigators more straightforward.<br\/><br\/>The repository of data that will be created by the OpenfMRI project will also serve as an important resource for teaching by providing students with the ability to replicate the analyses from published studies using the same data. By providing any researcher in the world with the ability to acquire large fMRI datasets, it will also provide all researchers with the ability to work with the same state-of-the-art datasets, regardless of institution. By creating the infrastructure for open sharing of research data, the project will also enhance the impact of other NSF-funded neuroimaging research projects by providing an infrastructure that can be used to make their data available. The planned work has the potential to benefit society by improving education, health, and human productivity through an increased understanding of mental function and its relationship to brain function.","title":"CRCNS Data Sharing: An open data repository for cognitive neuroscience: The OpenfMRI Project","awardID":"1131441","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1699","name":"COGNEURO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[493546],"PO":["565292"]},"186130":{"abstract":"Text search is undeniably vital to today's information-based societies, helping users locate relevant information in web pages, journal articles, news stories, blogs, emails, tweets, and a myriad of other sources. Naturally, users desire results that are not only good but also fast. Learning to rank, the dominant approach to information retrieval (IR) today, focuses almost exclusively on effectiveness, often neglecting the runtime speed (i.e., efficiency) of the ranking functions. This project contributes to the emerging research area of learning to efficiently rank, which aims to let algorithm designers capture, model, and reason about tradeoffs between effectiveness and efficiency in a unified framework. <br\/><br\/>Specifically, this project explores a novel cascade model for retrieval, where ranking is broken into a finite number of distinct stages. Each stage considers successively richer and more complex features, but over successively smaller candidate document sets. The intuition is that although complex features are more time-consuming to compute, examining fewer documents offsets the additional overhead. In other words, the cascade model views retrieval as a multi-stage progressive refinement problem. Based on the survey of the current state-of-the-art, knowledge, this is the first project to explore this approach to the ranking problem, marking a substantial departure from previous \"monolithic\" ranking functions. Although exploration in this uncharted area carries some risk, this research promises to open up a new frontier in IR research. <br\/><br\/>This project aims to narrow the chasm between academic and industrial IR research by bringing together theoretical IR research and practical considerations in \"real-world\" search. It is expected that the cascade model will be of interest to web search engine companies, thus providing a path from the exploratory research results to significant impact in production systems. Furthermore, this work dovetails with the emerging area of green computing: more efficient algorithms use less energy, hence help reduce the environmental footprint of web-scale services. The project web site (http:\/\/www.umiacs.umd.edu\/~jimmylin\/projects\/) includes more information about this project and will be used for the release of a prototype as part of the Ivory open-source retrieval toolkit.","title":"EAGER: Learning to Efficiently Rank with Cascades","awardID":"1144034","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["518100"],"PO":["563751"]},"185162":{"abstract":"The University of Texas Austin proposes Project Engage! to address the shortage of high school computer science (CS) students and teachers. The main components of this initiative are<br\/>(1) a novel dual enrollment (DE) CS Principles course for which high school students receive college credit, (2) a revamped college course that aligns with this DE course, and (3) a summer institute that trains in-service teachers to teach this DE course. The DE CS Principles course is innovative in three ways: First, it uses blended instruction in which classes are led by a high school teacher who is supported by online resources; second, it uses a problem-based curriculum that makes students active participants in the learning process; and third, it builds online learning communities for both students and teachers.<br\/>The online learning environment is central to this project because it provides teachers with instant access to pedagogical and curricular support, it provides teachers with an online community, allowing them to communicate with other teachers and discuss common concerns and successes, and it enables students to collaborate across traditional geographic and institutional boundaries.<br\/><br\/>This project promises significant impact in three dimensions. First, it will expand the CS community's supply of both students and teachers. The DE course can reach the 65% of Texas high schools that currently offer no AP CS courses. The summer institutes will train current math, CS, and science teachers to teach the DE course, and these teachers will receive on-going support from the online learning environment in the areas of course content and pedagogy. Second, it will significantly broaden participation among girls and under-represented minorities. DE courses disproportionately benefit students of lower socio-economic levels; anecdotal evidence suggests that the CS Principles course will attract a broader segment of the population, including girls; and the student-centered approach will engage students across all demographics, making computing relevant to their lives, their personal interests, and their future. Third, it will set a new standard for online CS education, answering many scientific questions about the impact and effectiveness of using blended instruction, problem-based learning, and online communities in a DE course.<br\/><br\/>This project will implement pilot DE courses at 6 Texas high schools, with the goals of eventually scaling this effort to several hundreds of Texas high schools and replicating the effort in other states through<br\/>the UTeach Institute.","title":"Type I: Project Engage!","awardID":"1138506","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[496821,496822],"PO":["561855"]},"189771":{"abstract":"The goal of this research is to investigate and develop discrete optimization algorithms for problems of clustering, pattern recognition, data mining and image processing. The research will address the theory and practice of such discrete optimization techniques, and will compare them to traditional approaches including variational models, spectral analysis, support vector machines and Principal Component Analysis. Algorithms will be implemented and their practical performance will be evaluated in applications of medical imaging; security detection; and image segmentation. The theoretical analysis will address the performance of algorithms for several clustering problems, which cannot be solved efficiently and optimally. For such known hard problems the performance will be evaluated in terms of how close the solutions attained are to the optimum, or the worst case error ratio. Efficient implementations will be developed to solve quickly pattern recognition and clustering problems on a sequence of data-sets that differ slightly from each other (e.g. for dynamically changing images, as in video). <br\/><br\/>The results of this research are expected to improve automated or semi-automated methodologies for pattern recognition, image segmentation, clustering and co-segmentation. The anticipated benefits include the reduction in cost and the frequency of human error in image analysis. In particular, automatic identification of unusual or pathological features is expected to improve diagnosis and reduce the cost of evaluating medical images by introducing accurate and fast automated procedures. The high speed of the proposed methodologies will permit real time deployment and mayl contribute to speeding up the rate of research and development in health-care, biological sciences and homeland security applications.","title":"Novel Efficient Clustering Techniques for Data Mining, Ranking, Pattern Recognition and Segmentation of Large Scale Data Sets","awardID":"1200592","effectiveDate":"2011-09-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":[508788],"PO":["565139"]},"186141":{"abstract":"While current cellular networks are based essentially on one-to-many and many-to-one single-hop subnets and cope with inter-cell interference by careful centralized resource planning, future wireless networks must consider heterogeneous environments characterized by user-deployed and user-operated infrastructure in which multiple flows and multiple hops will play an increasingly relevant role. Indeed, such networks are expected to open doors to trillions of dollars of e-commerce, while also providing vast amounts of easily accessible knowledge to the public. Developing a fundamental understanding of multihop multiflow wireless networks is therefore critically important at this time.<br\/><br\/>This exploratory project will seek to discover the fundamentals of such networks by obtaining their information theoretic capacity in an approximated sense. It is expected that scalable and extensible solutions are possible for such networks ranging from the seemingly simple ones involving two hops and two flows to apparently more complex ones involving multiple hops and more than two flows with arbitrary connectivity. In so demonstrating, multiple metrics will be employed. These metrics in the increasing order of accuracy in the high signal-to-noise ratio regime are (a) the fundamental limit on the available signaling (temporal\/spectral\/spatial) dimensions of the network, (b) the fundamental limit on the available signaling and signal-level dimensions, and (c) the capacity to within a (universal) constant number of bits independently of channel parameters.","title":"EAGER: Collaborative Research: CIF: Exploring the Fundamentals of Multihop Multiflow Wireless Networks","awardID":"1144059","effectiveDate":"2011-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["508212"],"PO":["564924"]},"189540":{"abstract":"The focus of this project is on two related research programs, one concerned with unconditional lower bounds in the theory of approximation algorithms and one concerned with unconditional lower bounds in the foundations of cryptography.<br\/><br\/>In the study of approximation algorithms, this project focuses on the complexity of finding approximate solutions to satisfiable constraint satisfaction problems; an example of such a problem is, given a 3-colorable graph, to efficiently find a 3-coloring that properly colors as many edges as possible. The well developed theory of \"Unique Games,\" and its relationship with the power of Semidefinite Programming relaxations, does not apply to satisfiable instances. This project explores Khot's \"2-to-1 games conjecture\" and its role in such questions, considering issues such as the existence of integrality gap instances for Semidefinite Programming relaxation of 2-to-1 games, the existence of approximation algorithms for 2-to-1 games, and the possibility of a `\"universality\" results similar to the one proved by Raghavendra for unique games.<br\/><br\/>In the foundations of cryptography, this project attacks problems in cryptoanalysis with theoretical computer science methods that have rarely been applied to such problems. The project will study generalizations and improvements of the Hellman-Fiat-Naor generic one-way function inverter, the security of Goldreich's one-way function candidate under various restricted forms of attack, and the security of efficient constructions of pseudorandom generators and hash functions under restricted forms of attack.<br\/><br\/>Progress in the approximation algorithms component of the project will further develop one of the most active and successful current research programs in theoretical computer science, by clarifying an important but still poorly understood part of the theory. Past advances in this area have been of broad interest to theoretical computer scientists and pure mathematicians.<br\/><br\/>Progress in the cryptography component of the project will bring a new connection between theoretical cryptography and cryptoanalysis, by applying techniques from the former research community to problems of interest to the latter. The project contributes to the long-term goal to develop new general tools that can be used to validate the security of cryptographic primitives.","title":"AF: Small: Unconditional Lower Bounds in Approximability and Cryptography","awardID":"1161812","effectiveDate":"2011-09-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["517279"],"PO":["565157"]},"186042":{"abstract":"Natural Language Generation (NLG) systems aim to improve the accessibility and impact of information by turning data into coherent and fluent text or speech, automatically. Developing high-quality NLG systems, however, remains a difficult and costly undertaking, in large part because bridging the gap between content planning and surface realization---a task known as \\textit{sentence planning}---continues to require extensive knowledge engineering.<br\/><br\/>This Early Grant for Exploratory Research investigates ways of bridging this gap by employing machine learning together with Discourse Combinatory Categorial Grammar (DCCG). Using a restaurant recommendation application as a proof-of-concept, the project explores methods of (1) adapting previous work on acquiring lexicalized grammar entries for semantic parsing to learn mappings from domain-general semantic dependency representations to application-specific representations of messages; (2) extending the approach to learn rules for combining messages; (3) employing the acquired resources to map content plans to disjunctive logical forms (DLFs), which compactly specify the range of possible realizations of the selected content; and (4) improving the efficiency of realizing DLFs with OpenCCG through grammar specialization.<br\/><br\/>The project will evaluate the success of these novel methods and assess the portability of the approach. By demonstrating methods for radically simplifying the construction of NLG systems, the project promises to transform the way NLG systems are built, from today's knowledge-intensive approach to one that relies primarily on assembling a parallel corpus of input-output pairs. Ultimately, it will facilitate the development of generation components in data-to-text systems as well as dialogue systems, including ones for the visually impaired.","title":"RI: EAGER: Exploratory Research on Acquiring and Adapting Sentence Planning Resources for Generating with Discourse Combinatory Categorial Grammar","awardID":"1143635","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["553805"],"PO":["565215"]},"178364":{"abstract":"Mechanism design lays the economic foundations for the design and analysis of economic institutions, social and computer protocols, service provisioning, and other applications where participants may act selfishly in their own best interest. A common paradigm for real-world mechanism design is trial and error: a mechanism is proposed, it is executed, then changes are made to it based on its performance. In order to make these changes an econometric analysis must be undertaken, i.e., the participants' actions in the mechanism (assumed to be in equilibrium) must be reverse engineered to obtain the participants' preferences. Using these inferred preferences, potential changes to the mechanism can be evaluated and ranked. While mechanism design theory for the most part relies on knowledge of the market, real world mechanisms tend to do some market analysis on the fly. The PIs research will combine econometric inference with mechanism design theory to investigate the econometric properties of mechanisms and design mechanisms that are simultaneously good at market analysis and exploiting that information to attain an objective specified by the mechanism designer.<br\/><br\/>This research program will introduce econometric techniques to computer science and will bring together topics from computer science and economics that have yet to be studied together. For example, these issues are very important in practice, especially in the rapidly growing areas of sponsored search and targeted display advertising. Auction mechanisms have been deployed for pricing and placement of advertisements and a major challenge is in adjusting the mechanisms in response to past data.","title":"ICES: Large: Collaborative Research: Towards Realistic Mechanisms: statistics, inference, and approximation in simple Bayes-Nash implementation","awardID":"1101717","effectiveDate":"2011-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":["516986"],"PO":["565251"]},"181290":{"abstract":"The ability to transfer information securely, to guarantee privacy, and to authenticate users in wireless networks forms the basis for confidentiality and economic advantage in today's information society. Contemporary wireless security systems evolved from schemes developed for traditional wireline applications, ignoring the special features of radio propagation channels. Meanwhile, the secrecy of wireless networks can be strengthened by exploiting the physical properties of these radio channels. Current research activities in this direction have largely ignored radio interference that can affect the secrecy of communication in a fundamental way. Therefore, it is crucial to characterize the various effects of interference (conventionally considered deleterious for communications) on network secrecy, as well as to develop techniques that exploit intrinsic properties of interference and radio channels for improving network secrecy.<br\/><br\/>This research establishes foundations for the intrinsically secure exchange of information within wireless communities formed by spatially distributed legitimate users, interferers, and eavesdroppers. Principles and concepts from multiple disciplines such as communication theory, information theory, statistical inference, probability theory, stochastic geometry, and graph theory are employed to characterize the role of interference on network secrecy. In particular, this research (1) establishes a framework to determine the secrecy rate in large-scale wireless networks; (2) determines the properties of the iSI-graph, a random geometric graph that characterizes intrinsic secrecy in the presence of interference; (3) analyzes network secrecy in the presence of colluding eavesdroppers; and (4) evaluates the performance of secrecy enhancing techniques, including deliberate interference generation and sectorized transmission. This research provides a deeper understanding of the advantages and disadvantages of interference on network secrecy, paving the way to a more secure and safer information society.","title":"CIF: Small: Foundations for Intrinsically Secure Networks: the Role of Network Interference","awardID":"1116501","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[485771],"PO":["564924"]},"183490":{"abstract":"Netcentric Software and Systems Center<br\/>Proposal #1128344<br\/>Proposal #1128270<br\/><br\/>This proposal seeks funding for the Netcentric Software and Systems Center sites at the University of North Texas and the University of Texas ? Dallas. Funding Requests for Fundamental Research are authorized by an NSF approved solicitation, NSF 10-601. The solicitation invites I\/UCRCs to submit proposals for support of industry-defined fundamental research. <br\/><br\/>Software development is increasingly achieved via Service Oriented Architectures (SOAs) served through web-based services, Quality of Service (QoS) is an important issue yet major gaps exist in the QoS paradigm. The proposed work looks at the composition approach where QoS properties are known at the individual web component level and used to determine an overall global QoS understanding. The proposed work seeks to establish a comprehensive framework for QoS-assured service composition and execution using a A QoS-reconfigurable service paradigm, compositional security and reliability analysis recently developed by the group, and a three phase composition algorithm to rapidly arrive at candidate compositions that meet QoA requirements. <br\/><br\/>The outcomes of the proposed work have the potential for significant impact in the area of software development and application and the SOA community. The work is supported by the Industry Advisory Board as well as individual industry members of the center. The effort has the potential to extend the center?s portfolio through further development and application of the QoS framework developed. The PI plans to develop Network Centric Operations Industry Consortium (NCOIC) patterns from the work and post these for public access. The center will involve graduate students in the work.","title":"FRP:Collaborative Project: QoS-Assured Service Composition and Execution","awardID":"1128344","effectiveDate":"2011-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["13545"],"PO":["564474"]}}