{"205634":{"abstract":"With the ever growing demand for ubiquitous connectivity and data access, there is a driving need to deploy ever more extensive and higher capacity network infrastructure---wired and wireless. With such increases in network density, the propagation environments become increasingly challenging, and new communication techniques, architectures, and protocols are needed to meet these critical challenges. Examples include intersymbol (or self-), inter-channel, intra-network, and extra-network interference. Over the years, the error-control coding community has developed a wide range of codes for efficiently mitigating the effects of noise in communication systems. Ultimately, the goal of this research can be viewed as developing a signaling architecture that efficiently and effectively transforms interference into standard, more benign noise from the perspective of the underlying code.<br\/><br\/>To approach these challenges, this research develops the role of super-Nyquist signaling formats in modern coded digital communication systems. In traditional systems, the symbol rate is chosen to match the channel bandwidth. With this classical approach, the transmit pulses can be designed to be orthogonal, corresponding to signaling on independent degrees of freedom. However, in systems with super-Nyquist signaling, the symbol rate is chosen to be significantly higher than the channel bandwidth, resulting in a transmission with self-interference, whose effects can be compensated through the use of appropriate equalization. The investigation develops the role of super-Nyquist coding in a range of network scenarios, starting from simple point-to-point intersymbol-interference channel models, and progressing to richer multi-input\/multi-output, multiple-access, and interference channel models. The research emphasizes the special role that such signaling plays in joint design of the physical and link layers in the protocol stack. Dual problems in source coding are also explored.","title":"CIF: Small: Theory, Algorithms, and Applications of Super-Nyquist Coding","awardID":"1319828","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[550597],"PO":["564924"]},"205799":{"abstract":"Many emerging applications in machine learning and data mining can be cast as graph computations. Efficient low-power implementations of graph computations promise disruptive capabilities for the increasingly ubiquitous embedded and mobile platforms. The project is building the GraphGen compiler to overcome the complexity and difficulty of creating graph computation hardware accelerators that are needed to meet the demanding power and performance constraints of embedded and mobile systems. The GraphGen compiler is a general-purpose compiler (within the graph computation domain) to handle arbitrary graph applications based on varying graph structures (e.g., grid-shaped, planar, natural graphs) that may be static or dynamically changing (e.g., updated by streaming data) following different execution strategies (e.g., synchronous vs. asynchronous). GraphGen implementation mapping makes use of reusable hardware implementation templates to allow the same graph computation specification to be efficiently mapped onto different target platforms. Overall, the GraphGen compiler captures knowledge from both application developers (in graph specifications) and hardware designers (in the reusable implementation templates), and bridges the gap between the two camps through automatic mapping of a specification to a template to yield a highly efficient embedded implementation tuned to the application developer's design objectives.<br\/><br\/>The continued exponential increase in transistors-per-die, coupled with advances in sensors and breakthrough algorithms in machine learning and data mining, have resulted in a revolution in the embedded and mobile application space. Graph computation is an important enabling computation paradigm for many of these emerging applications. The GraphGen compiler can facilitate rapid adoption of these applications into embedded and mobile devices by allowing domain experts to automatically translate their graph computation algorithms onto efficient FPGA-accelerated embedded platforms. This new capability has the potential to spark new research in graph computation and embedded hardware architectures by providing a common design automation environment that bridges the gap between application domain experts and hardware designers, thus benefiting industry.","title":"SHF: Small: Compiling Custom Hardware Accelerators from Graph Algorithms","awardID":"1320725","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[550978],"PO":["562984"]},"208505":{"abstract":"The International Conference on Artificial Intelligence and Education (AIED 2013; http:\/\/aied2013.memphis.edu) and the International Conference on Educational Data Mining (EDM 2013; http:\/\/edm2013.memphis.edu) provide professional opportunity for researchers from around the world to share results of cutting-edge research from the fields of artificial intelligence (AI), data mining, computer science, cognitive and learning sciences, psychology, and educational technology that focuses on the design and effective use of advanced learning technologies. AIED researchers aim to design new technologies and advance understanding of how to use those technologies and integrate them into learning environments so that their potential is fulfilled. EDM researchers focus on working towards better use of technology for collecting, analyzing, sharing, and managing data to shed light on learning, promoting learning, and designing learning environments. Researchers from both communities aspire to better understand how people learn with technology and how technology can be used productively to help people learn, through individual use and\/or through collaborations mediated by technology. <br\/><br\/>This project supports travel for advanced graduate students from US universities to attend these two conferences, held in Memphis, Tennessee, AIED 2013 from July 6 to 8, 2013, and EDM 2013 from July 10 to 12, 2013. Participating graduate students join the Doctoral Consortium (DC) tracks of the two conferences and are paired with a senior member of the AIED or EDM community for one-on-one mentoring throughout the conferences. The DC tracks of the conferences and mentor pairing are designed to provide young researchers with mentoring beyond what they get at their home institutions to help them transition from graduate school to a fruitful research career. DC track activities include structured poster sessions where students present their work, meetings with peers who have related interests, and interactions with senior members of the field. Each young researcher's one-on-one mentor will be senior members of the AIED\/EDM community who shares research interests with the young researcher and who comes from a different university and has a different approach than the young researcher experiences in his\/her home institution. It is expected that conversations between peers and between mentors and mentees will continue throughout each young researcher's career.<br\/><br\/>This activity supports the mission of NSF to train more advanced professionals in science, technology, engineering, and mathematics. Attending conferences is expensive for graduate students; funding their travel allows them to present their work to the larger community, speak individually with leaders in the field, and receive both support and advice from both senior researchers and peers. The AIED conference is special in its synthesis and cross-fertilization across three STEM capacities: building cutting-edge learning technologies, investigating pedagogical methods that are theoretically grounded in the cognitive, social, and learning sciences, and rigorously testing the learning environments for their effectiveness at promoting learning (in STEM and other disciplines) among K-12, college, and workplace populations. The EDM conference is special in its focus on learning how to use data collected as learners interact with learning technologies to assess learner understanding and capabilities so as to personalize feedback and advice.","title":"Support for Doctoral Students from U.S. Universities to Attend the AIED 2013 and EDM 2013 Conferences","awardID":"1340163","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[558856],"PO":["562669"]},"210573":{"abstract":"This project will explore the application of heterogeneous memory architectures to reduce power consumption while maintaining adequate response times in embedded computer systems. The slower response times of memory devices as compared to the speeds of processing elements is recognized as a major performance bottleneck. Power used by memory devices, especially static power, is recognized as a major source of energy consumption in computers. There are a variety of different types of memory technologies, each occupying a discrete point in a multidimensional trade-off space represented by parameters such as memory access latency, memory bandwidth, power consumption, memory lifetime, and cost of memory devices. Heterogeneous memory systems represent a potentially transformative development because combining several different types of memory opens up a much broader range of this trade-off space. The focus of this preliminary study is on efficient use of heterogeneous memory types in a scratch-pad memory. Expected outcomes include: 1) A new heterogeneous memory hierarchy that integrates on-chip Static Random Access Memory (SRAM), Magnetic Random Access Memory (MRAM), Zero-capacitor RAM (Z-RAM) technologies, as well as off-chip DRAM. 2) a set of algorithms that achieve allocation for optimal memory access speed or efficient space utilization. 3) a simulation toolkit that integrates commonly used simulation benchmarks, such as MiBench, PARSEC, and MediaBench.<br\/><br\/>The broader impacts of this research include potential for contributing technology that reduces energy consumption for current embedded computing applications, and may enable more advanced future embedded computing systems within energy, power, and thermal dissipation constraints. The project will integrate research with graduate education, both in the classroom and through direct participation of students in the research. It will include collaborations with researchers at IBM, Pacific Northwest Laboratories, and Intel.","title":"EAGER: Towards Low-Latency Low-Power Heterogeneous Memory Access","awardID":"1359557","effectiveDate":"2013-07-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[564228],"PO":["564778"]},"204721":{"abstract":"Side-channel attack (SCA) has shown to be a serious implementation attack to many cryptosystems. Practical countermeasures only mitigate the vulnerability to some extent. Considerable research efforts on leakage-resilient cryptography have so far not led to practical leakage-resilient implementations. One hindering reason is the lack of commonly accepted and sound metrics, standards, and evaluation procedures to measure and evaluate the vulnerability\/resilience of cryptosystems to various side-channel attacks. Accurate modeling of side channels, however, is one of the open problems in applied crypto research. This project aims to close the gap between SCA theories and practices by formalizing a general framework for side-channel attack analysis and security evaluation of cryptosystems. <br\/><br\/>The proposed framework quantifies the effect of algorithmic and implementation characteristics on the success rate of the theoretically strongest maximum likelihood attack, revealing system-inherent SCA-related parameters for security improvement. The framework will extract maximum leakage from the observed measurement data in the black-box scenario, often the realistic situation for adversaries. State-of-the-art statistical methods are employed in the framework to precisely analyze and evaluate the overall side-channel leakage. This holistic framework will significantly alleviate the burden of security system architects, software developers, and hardware designers in their quest to build SCA security into systems they design, so as to ultimately yield provably secure hardware.","title":"TWC: Medium: Collaborative: A Unified Statistics-Based Framework for Side-Channel Attack Analysis and Security Evaluation of Cryptosystems","awardID":"1314655","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548239,"557273"],"PO":["565264"]},"202796":{"abstract":"The project is aimed at enhancing an existing infrastructure that supports software engineering research on very large bodies of source code. The srcML infrastructure currently includes a generic XML representation for a variety of programming languages, a robust and efficient parser for C\/C++, and a limited set of tools to support analysis and manipulation of large bodies of source code. The infrastructure is currently being used by a wide number of researchers in the fields of software engineering and programming languages. It is also being directly applied to practical problems in a variety of industrial settings. The srcML infrastructure is open source and freely available to the public via a GPL license. Documentation for the infrastructure is available online and a number of other resources, including online tutorials, are under development. Additionally, tutorials on how to use the infrastructure to support various research efforts are planned for a number of software engineering conferences.<br\/><br\/>The PIs plan to extend the current efficient and robust parsing and markup to a broader variety of widely used programming languages (namely Java and C#) and allows for the addition of new languages via a plugin grammar architecture. The current toolkit is being greatly expanded to support the exploration, analysis, and manipulation of very large code bases. The tools include such things as a static slicer, metrics computation, various static analysis tools, a fact extractor, a call graph generator, syntactic querying tools, and a syntactic differencing tool. Additionally, a set of tools to support the construction and application of transformation rules is being developed. Extending the infrastructure to a broader set of widely used languages enables researchers to investigate more production and commercial software. <br\/>The enhancements to the srcML infrastructure can drastically reduce the entry cost for individuals to conduct research by enabling them to explore, analyze, and manipulate software in an extremely easy and flexible manner, thus allowing them more time to pursue novel and transformative research on software, software engineering, and software languages. The addition of analysis, transformation, and syntactic differencing tools enable unproblematic and flexible exploration of large code bases written in widely used programming languages.","title":"CI-ADDO-EN: Collaborative Research: Enhancing the srcML Infrastructure: A Mixed-Language Exploration, Analysis, and Manipulation Framework to Support Software Evolution","awardID":"1305217","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543491],"PO":["565272"]},"205711":{"abstract":"In future technology generations, smaller and more transistors <br\/>operating at low supply voltages and high clock speeds will be <br\/>increasingly susceptible to many different resiliency problems, such <br\/>as soft errors, wear-out issues, hard errors, and off- and on-chip bus <br\/>bit errors. These errors may cause silent data corruption, application <br\/>aborts, or system crashes in high-performance microprocessors and <br\/>computer systems. Previous techniques for addressing these errors <br\/>incur significant performance and power overheads despite <br\/>optimizations, and often require invasive changes that incur high <br\/>implementation complexity.<br\/><br\/>In this research project, the investigators propose a novel, <br\/>light-weight, yet highly-effective architectural approach to processor <br\/>reliability that incurs much lower overheads than existing approaches <br\/>by leveraging key architectural observations about the problems.<br\/><br\/>This project's innovative approach for the detection of soft errors, <br\/>wear-out, and hard errors is based on detecting execution anomalies <br\/>that are triggered by errors, without using redundant execution. By <br\/>exploiting the notion of value locality, this project generalizes <br\/>anomalies to include unexpected values as well as conditions (e.g., <br\/>memory access exceptions) and provides significant coverage which <br\/>includes the most problematic cases of silent data corruption. For <br\/>recovery from soft errors, the project's investigators propose a <br\/>retry-based scheme that avoids adding any hardware overhead to achieve <br\/>recovery by using existing spare speculative resources in the <br\/>processor. For off-chip bus bit errors, the investigators propose a <br\/>novel bit interleaving scheme that reduces the chances of multiple <br\/>bits in a single error correcting code (ECC)-protected data unit being <br\/>corrupted undetectably or uncorrectably. Like the other schemes, this<br\/>interleaving imposes minimal power, performance, and complexity overhead.<br\/><br\/>This project targets achieving reliability while keeping power, <br\/>performance, and hardware overheads low, an important goal for the <br\/>U.S. microprocessor and computer hardware industry. The project's <br\/>investigators are committed to releasing the research artifacts as <br\/>open-source software to be used by the research community. The <br\/>graduate students working on this project will be trained in <br\/>architecture and reliability issues and will be well-positioned to <br\/>join the U.S. computer hardware industry. This project will also <br\/>support educational activities such as homework and term projects in <br\/>undergraduate and graduate courses as well as outreach activities of <br\/>various centers at Purdue with which the investigators are involved. <br\/>With a woman as one of the investigators, the project will act as a <br\/>basis for encouraging women to join graduate programs in electrical <br\/>and computer engineering.","title":"SHF: Small: Light-weight Architectural Schemes for Resilient High-performance Microprocessors","awardID":"1320263","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[550778,550779],"PO":["366560"]},"202213":{"abstract":"The goal of this research is to create a flexible, micro-scale additive manufacturing platform utilizing a team of untethered micro-scale robots and modular, multifunctional building blocks to create smart micro-devices and structures. Externally applied magnetic fields are commonly used for the power and actuation of individual magnetic mobile microrobots. However, in order to achieve different behaviors from individual robots within a team of microrobots, there must be either significant variation in their design or in the magnetic control signals applied to each microrobot.<br\/><br\/>The intellectual merit of this research, therefore, lies in the novel approach to create a specialized magnetic potential field generating substrate from MEMS-fabricated planar microcoils and the related control methodology to enable truly independent control of multiple mobile microrobots. Thus, the research objectives of the proposal are: the design and fabrication of the micro-coils and related control electronics; motion control for mobile magnetic microrobot swarms; and magnetic microrobot and modular component design and fabrication, based on specialized micro-components with various material properties and functions.<br\/><br\/>Successful completion of the objectives will result in a transformative mobile microrobot swarm platform capable of executing various advanced additive manufacturing tasks. Potential applications include very high-density energy storage, high strain actuation, energy harvesting, very low power communications devices, and composite structures with integrated sensors. Further broader impacts of this project reside in disseminating the research output in industry and academia along with an educational agenda spanning related outreach activities from the K-12 through graduate levels.","title":"RI: Medium: Collaborative Research: Mobile Microrobot Platform for Advanced Manufacturing Applications","awardID":"1302283","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["541930"],"PO":["564069"]},"205865":{"abstract":"Continued advancement of computing is of critical importance given the ubiquitous use of computing systems in various forms across a growing landscape-from implantable and wearable biomedical devices to facilitate personalized healthcare; to embedded and smart-sensor devices to facilitate efficient transportation and civil infrastructure; to cloud servers to facilitate data collection, mining, modeling and discovery; to many other scientific, economic, and social computing applications touching numerous disciplines and sectors. Unrelenting progress in semiconductor technologies and continual emergence of new application areas spur unprecedented development of many-core chip multiprocessors (CMPs) to satisfy increasing performance expectations and tightening power and resource constraints of future systems. Along with this parallel processing paradigm comes many challenges for efficiently interconnecting tens to hundreds of cores on a chip and possibly many thousands of chips in stand-alone or distributed systems. To meet the challenges, on-chip network (or NoC) communication architectures must be developed that provide scalable performance while both requiring minimal resources and consuming ultra-low power.<br\/><br\/>This research investigates cross-cutting approaches and techniques to enhance on-chip network power, performance, and resource efficiency in CMP systems. Architecture-level support is explored for effectively exploiting circuit-level power-gating techniques. The objective is to maximize static power savings and minimize performance penalty of the NoC while conserving overall system dynamic power and energy expenditure when applying the techniques. Innovative approaches for minimizing NoC resources and enabling flexibility in resource utilization are also explored. The objective is to improve NoC resource efficiency while balancing system-level tradeoffs. The research plan establishes a systematic, comprehensive, and empirically-based method of investigating efficient communication architectures for many-core CMP systems, soundly grounded by theoretical support, that will lead to the design of promising new approaches and techniques. Beyond its contribution to fundamental advancements in computing, this research has broader potential impact to society through its outreach activities to broaden participation in computing and workforce development of persons from diverse backgrounds.","title":"SHF: Small: Enhancing Power, Performance, and Resource Efficiency of Many-core NoCs","awardID":"1321131","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["325495"],"PO":["366560"]},"205986":{"abstract":"This project lays the academic foundations for collaborations between researchers and indigenous American Indian community-based language practitioners for the purpose of developing a socio-technical means of, in parallel, preserving ancient indigenous languages and traditional ecological knowledge (TEK), and helping indigenous youth learn traditional languages and knowledge. The projected plan is to engage indigenous youth in the design of augmented reality immersive experiences for others (ARGs) that incorporate social media and immerse others in the culture and languages of the community as a means towards addressing these goals. Such an approach places youth in the position of being producers of immersive experiences for others and active collaborators with elders who they can share with and learn from. During the course of this Cyberlearning Capacity-Building Project (CAP), the PIs are convening a set of workshops involving researchers, indigenous language practitioners, and indigenous elders and youth to lay the foundations for later collaborative research and planning. Indigenous participants are being introduced to what is known about how people learn and about designing experiences for promoting learning; researchers are being introduced to the resources, needs, and knowledge of the indigenous people. American Indian participants are from four separate but linguistically-related tribal communities in the Midwest. <br\/><br\/>The next generation of indigenous peoples is faced with an awesome burden: how to sustain local ecosystems, languages, and lands in the face of rampant language, culture, and policy shifts. Existing theories of language and learning do not address these issues, and project participants are laying the groundwork for both developing theory around indigenous language and cultural learning and exploring the roles technology might play in drawing youth into these activities and helping them learn and preserve traditional languages and culture. Finding new channels for the transmission of indigenous languages and traditional ecological knowledge is both a practical and intellectual enterprise.","title":"CAP: Partnerships for Indigenous Knowledge and Digital Literacies","awardID":"1321663","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7719","name":"DEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}}],"PIcoPI":["427557",551483],"PO":["562669"]},"202235":{"abstract":"Rapid development of large-scale data collection technology has<br\/>ignited research into high-dimensional machine learning. For<br\/>instance, the problem of designing recommender systems, such as those<br\/>used by Amazon, Netflix and other on-line companies, involves<br\/>analyzing large matrices that describe users' behavior in past<br\/>situations. In sociology, researchers are interested in fitting<br\/>networks to large-scale data sets, involving hundreds or thousands of<br\/>individuals. In medical imaging, the goal is to reconstruct<br\/>complicated phenomena (e.g., brain images; videos of a beating heart)<br\/>based on a minimal number of incomplete and possibly corrupted<br\/>measurements. Motivated by such applications, the goal of this<br\/>research is to develop and analyze models and algorithms for<br\/>extracting relevant structure from such high-dimensional data sets in<br\/>a robust and scalable fashion.<br\/><br\/><br\/>The research leverages tools from convex optimization, signal<br\/>processing, and robust statistics. It consists of three main thrusts:<br\/>(1) Model restrictiveness: Successful methods for high-dimensional<br\/>data exploit low-dimensional structure; however, many real-world<br\/>problems fall outside the scope of existing models. This proposal<br\/>significantly extends the basic set-up by allowing for multiple<br\/>structures, leading to computationally efficient algorithms while<br\/>eliminating negative effects of model mismatch. (2) Non-ideal data:<br\/>Missing data are prevalent in real-world problems, and can cause major<br\/>breakdowns in standard algorithms for high-dimensional data. The<br\/>second thrust devises relaxations and greedy approaches for these<br\/>non-convex problems. (3) Arbitrary Outliers: Gross errors can arise<br\/>for various reasons, including fault-prone sensors and manipulative<br\/>agents. The third thrust proposes efficient and randomized algorithms<br\/>to address arbitrary outliers.","title":"CIF: Medium: Collaborative Research: New Approaches to Robustness in High-Dimensions","awardID":"1302435","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[541981,"550745"],"PO":["564898"]},"204667":{"abstract":"This project studies Internet censorship using novel measurement techniques, ranging from low-level packet filtering on Internet Protocol (IP) networks to high-level censorship of social media content. Collectively these techniques can provide greater situational awareness of censorship dynamics. <br\/><br\/>The project focuses on a suite of advanced inference techniques for when ?direct observation? is unavailable or impractical such as, for example, methods for detecting IP tunnels based on per-hop Maximum Transmission Unit (MTU) inference techniques in order to reason about the physical characteristics of a given IP network and, for example, measurement on social media postings of redactions and the speed of redactions. <br\/><br\/>This research has broad implications on studies of methods to provide awareness of restrictive control of information and content on networks, which would be of interest to software developers, system administrators, and policy makers alike.","title":"TWC: Medium: Collaborative: Measurement and Analysis Techniques for Internet Freedom on IP and Social Networks","awardID":"1314297","effectiveDate":"2013-07-15","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548106],"PO":["565239"]},"205525":{"abstract":"Project abstract <br\/><br\/>Information theory has had a profound impact on the fields of data transmission and compression. In contrast, it has yielded comparably few insights into problems such as knowledge extraction from and efficient search of massive datasets. While current information-theoretic tools and techniques can be applied to these problems to some extent, the paradigms for which these tools were developed will be being carefully reexamined in this project. Models that accurately capture the fundamental challenges faced by efficient search in modern massive database systems will be developed and analyzed. The asymptotic fundamental limits, which characterize the tradeoffs between accuracy, compression rate and search efficiency, will be investigated, along with development of practical algorithms that approach the ultimate benchmarks. One concrete problem being pursued is that of compression for efficient query and search. In this setting, the goal is, given a compressed representation, to answer search queries about the data that was compressed. This is in stark contrast to traditional compression, where the data need be merely reconstructible from the compressed form. The approach taken is tailored to distributed database design, but is also relevant to compression schemes that allow search within the compressed domain. <br\/><br\/>The fundamental quantities studied play a similar role to that of the channel capacity and entropy\/rate-distortion in channel and source coding, respectively. On one hand, they yield an understanding of the fundamental limits on the performance that any system for similarity queries based on compressed representations can hope to attain. On the other, the insights obtained from the theory are guiding the construction of schemes that approach these limits in practice. We will investigate how existing practical approaches (such as various hashing and clustering techniques) perform with respect to the information theoretic limits, and the extent to which approaches that have proved to be practical in source and channel coding can be used as building blocks to develop new efficient search algorithms that significantly improve on the current state of the art","title":"CIF: Small: Collaborative Research:Compressed databases for similarity queries: fundamental limits and algorithms","awardID":"1319304","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[550344],"PO":["564898"]},"202269":{"abstract":"Rapid development of large-scale data collection technology has<br\/>ignited research into high-dimensional machine learning. For<br\/>instance, the problem of designing recommender systems, such as those<br\/>used by Amazon, Netflix and other on-line companies, involves<br\/>analyzing large matrices that describe users' behavior in past<br\/>situations. In sociology, researchers are interested in fitting<br\/>networks to large-scale data sets, involving hundreds or thousands of<br\/>individuals. In medical imaging, the goal is to reconstruct<br\/>complicated phenomena (e.g., brain images; videos of a beating heart)<br\/>based on on a minimal number of incomplete and possibly corrupted<br\/>measurements. Motivated by such applications, the goal of this<br\/>research is to develop and analyze models and algorithms for<br\/>extracting relevant structure from such high-dimensional data sets in<br\/>a robust and scalable fashion.<br\/><br\/><br\/>The research leverages tools from convex optimization, signal<br\/>processing, and robust statistics. It consists of three main thrusts:<br\/>(1) Model restrictiveness: Successful methods for high-dimensional<br\/>data exploit low-dimensional structure; however, many real-world<br\/>problems fall outside the scope of existing models. This proposal<br\/>significantly extends the basic set-up by allowing for multiple<br\/>structures, leading to computationally efficient algorithms while<br\/>eliminating negative effects of model mismatch. (2) Non-ideal data:<br\/>Missing data are prevalent in real-world problems, and can cause major<br\/>breakdowns in standard algorithms for high-dimensional data. The<br\/>second thrust devises relaxations and greedy approaches for these<br\/>non-convex problems. (3) Arbitrary Outliers: Gross errors can arise<br\/>for various reasons, including fault-prone sensors and manipulative<br\/>agents. The third thrust proposes efficient and randomized algorithms<br\/>to address arbitrary outliers.","title":"CIF: Medium: Collaborative Research: New Approaches to Robustness in High-Dimensions","awardID":"1302687","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[542073],"PO":["564898"]},"205437":{"abstract":"In recent years there have been great advances in nucleic acid technology, such as the development of biomolecular circuits that compute logic functions, mimicking the behavior of semiconductor circuits. Biomolecular logic circuits consist of DNA or RNA molecules that react with each other and with particular target molecules. The goal of the circuit is to detect whether the target molecules are present and decide on an appropriate response. For example, a biomolecular logic circuit might instruct a particular cell to self-destruct, if that cell contains particular molecules known to indicate cancer.<br\/><br\/>Because molecules are continually colliding with each other, special care must be taken when designing biomolecular logic circuits to ensure that only the desired reactions actually take place. As circuits grow in size and complexity, it will become increasingly difficult to prevent unwanted reactions between different molecules within the circuit. In real-world applications we must also guard against interference caused by unwanted reactions with other molecules that are present in the solution but are not part of the circuit. Unwanted reactions introduce noise into the system, preventing the circuit from computing reliably.<br\/><br\/>This project will tackle these challenges by designing biomolecular logic circuits using distributed computational modules that are physically separated, to reduce non-specific molecular interactions. Each module will contain specific computing components inside a lipid membrane, and collections of communicating modules will be designed to carry out distributed computations. Putting modules inside membranes will reduce unwanted reactions between different parts of the circuit, which will increase the reliability of the system. It will also enable identical DNA sequences to be reused within multiple modules, which is an important step towards standardization of biomolecular computing components. Standardization will make it easier to build larger and more sophisticated circuits that are capable of more complex decision-making.<br\/><br\/>Intellectual Merit: The project will develop new designs for biomolecular logic circuits based on distributed, communicating modules, and investigate the advantages of this approaches to molecular computing, for example in terms of reliability. These advances will be directly applicable to many biomedical problems of interest, including detection of viruses and the development of autonomous smart drugs.<br\/><br\/>Broader Impact: The project will have a broad impact on medical technology by developing a new biocompatible platform for the implementation of biomolecular logic circuits for medical applications. This will improve access to rapid diagnoses, particularly in underserved communities. Community outreach in New Mexico will be achieved via internship programs, enabling high school and undergraduate students to experience interdisciplinary scientific research.","title":"AF: SHF: Small: Compartmentalized circuit architectures for real-world biocomputing applications","awardID":"1318833","effectiveDate":"2013-07-15","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":[550110,550111],"PO":["565223"]},"199299":{"abstract":"Developing new analytic tools and proof techniques will advance computer science in a fundamental way. The aim of this project is to explore techniques used in several different areas of theoretical computer science and mathematics in a unified way. One such development involves the study of low-degree polynomials. This research will address problems arising from two main considerations:<br\/><br\/>- Understanding the analytical structure of functions which have a small but significant correlation with a low-degree polynomial over a finite field.<br\/><br\/>- Understanding the expressive power of low-degree polynomials over reals for capturing proofs of several combinatorial facts.<br\/><br\/>The former leads to many questions spanning the areas of arithmetic combinatorics, coding theory, learning theory, hardness of approximation and Fourier analysis. Some of these questions extend the notions of list-decoding in coding theory and are also key to developing an algorithmic version of the theory of higher-order Fourier analysis, developed recently to study questions in arithmetic combinatorics. The latter consideration will strengthen our understanding of techniques from combinatorial optimizations and proof complexity. Progress on these questions will shed light on the design of new approximation algorithms using linear and semidefinite programs.<br\/><br\/>Part of this project also includes designing two new courses, to be offered at Toyota Technical Institute and the University of Chicago. The PI also plans to collect short \"research summaries\" to outline some of the exciting questions in different areas of theory, and make them accessible to advanced high-school and undergraduate students.","title":"CAREER: Understanding Polynomial Structure Analytically and Algorithmically","awardID":"1254044","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[534514],"PO":["565251"]},"202753":{"abstract":"Constraint solving is an integral part of program verification, in <br\/>general and abstract interpretation in particular. This proposal explores<br\/>some fundamental issues in integer feasibility checking and certification for <br\/>a specialized class of constraints called Unit Two Variable Per Inequality <br\/>(UTVPI) constraints. This approach is based on fundamentally new insights into <br\/>the problem of integer feasibility checking, and will provide actual certificates <br\/>of infeasibility. The ability to provide positive and negative certificates <br\/>will impact program verification, and enhance the reliability of software.<br\/><br\/>This project uses a proof system called FMR (Fourier-Motzkin with Rounding), which <br\/>is a sound and complete system for establishing the lattice point infeasibility of <br\/>a UTVPI system. This work will isolate the smallest-sized proof of infeasibility <br\/>in the FMR proof system with an appropriately defined notion of size, and will explore <br\/>the problem of certification by trying to identify the form of certificates and <br\/>optimize the size of such certificates.","title":"Eager: Optimal Length Integer Resolution Refutation in UTVPI Constraints","awardID":"1305054","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[543376],"PO":["565264"]},"204700":{"abstract":"The widespread deployment of parallel machines --- from multicores to supercomputers --- has made it critical to develop simple approaches to programming them. Significant progress has been made in simplifying parallel programming by developing programming models to support parallelism without concurrency, that is, without the nondeterminacies in the logic of programs caused by the relative and nondeterministic timing of communicating processes. Yet most parallel programs in practice are concurrent, and hence, nondeterministic, leading to code that can only be programmed and understood by experts. This research project aims to understand how parallel computers can be made easier to use by the vast majority of programmers by developing software technology that enables deterministic parallel computing.<br\/><br\/>The project takes a holistic view of the problem from the key perspectives of programming linguistics, software systems, algorithmic analysis, and absolute performance. It acknowledges the reality that parallel programming cannot be fully deterministic at every level of abstraction. It is pursuing three key strategies for dealing with concurrency: encapsulating concurrency so that it is hidden by layered abstractions at appropriate abstraction levels, avoiding concurrency by restructuring programs to employ deterministic approaches, and managing concurrency when it is impractical to either encapsulate or avoid concurrency completely. Among the specific techniques being studied are commutative building blocks, deterministic nonassociative reducers, deterministic pipelined parallelism, deterministic interfaces, and generalized race detection for detecting invariant races. The project is developing open-source libraries, tools, and runtime extensions integrated into a multicore-software platform, as well as a problem-based benchmark suite to compare approaches.","title":"SHF: AF: Large: Collaborative Research: Parallelism without Concurrency","awardID":"1314547","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[548187],"PO":["564588"]},"206801":{"abstract":"The goal of this project is to develop new methods for unsupervised learning from multivariate data based on counting and comparing frequencies of data patterns. A recursive testing approach will be used to infer the multivariate distribution. The investigator will use hardware-algorithm co-design to achieve qualitative improvement over existing methods in computational time as well as in the maximum data dimension and sample size that can be handled. The economic feasibility of making this methodology widely available will also be investigated. <br\/><br\/>This research is motivated by the challenge of \"Big Data\" analysis where the high dimensionality and extremely large sample size had made it infeasible to apply traditional statistical methods. The new methods developed in this project will be applied to several \"big data\" applications such as the analysis of videos, next generation sequencing data and microblogs. By developing the statistical methods for such analyses as well as customized computing resources to make these methods scalable to extremely large data sets, this research will enable more effective use of the rich information embedded in these data. Finally, the multidisciplinary approach integrating statistical, computational and hardware expertise is well suited for the training of next generation data scientists.","title":"EAGER: Algorithm-Hardware Co-Design for Multivariate Data Analysis","awardID":"1330132","effectiveDate":"2013-07-15","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":["431765"],"PO":["565063"]},"205866":{"abstract":"The capabilities of mobile devices have increased dramatically and end-users are able to perform a wide range of useful tasks on their smartphones. However, the usability of these devices is strongly influenced by their energy consumption. Despite advances in hardware and battery design, a poorly coded application can drain a smartphone's battery with numerous energy-expensive operations. Developers lack the tools and techniques to identify when and where the energy consumption profiles of their applications can be improved. This research aims to help developers understand how energy is consumed within their applications, and to help them change their applications in ways that will lead to reduced energy consumption. Given the widespread use of mobile applications and the prevalence of energy consumption-related problems, this work will impact both end users and developers by improving applications? energy efficiency and enabling further research in this area. The results of this research will also have marked educational impact through the training of future software engineers in predicting, estimating, measuring, and managing the effects of their system designs and implementations on energy consumption.<br\/><br\/>This project includes three inter-related thrusts. The first thrust develops program analysis techniques for online measurement and visualization that provides energy consumption information to developers at the level of individual lines of an application?s source code. Using this capability, the second thrust identifies a set of energy-aware development best practices via an empirical study of the relationship between energy consumption and implementation structure at the application's architecture, design, and code levels. The third thrust uses the best practices to propose a set of energy-reducing refactorings to the developers and help them to identify the changes that will lead to the most energy efficient applications.","title":"SHF: Small: Helping Developers Improve the Energy Consumption of Smartphone Applications","awardID":"1321141","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["553707",551145,551146],"PO":["564388"]},"202236":{"abstract":"This project deals with theory and efficient algorithms for statistical decision problems that are radically different from those that have been studied to date in two key aspects: First, the decision-maker may choose among a large class of observation channels (features) of varying complexity and quality; and second, the total cost of computational resources that can be used prior to arriving at a decision is limited. Computer vision is a paradigmatic source of such feature-rich decision problems, requiring the use of multiple heterogeneous feature types, integration of diverse sources of contextual information, and possibly even human interaction.<br\/><br\/>This project entails the development of a rigorous mathematical framework for feature-rich decision problems in accordance with three specific aims: (1) structural characterization of features as stochastic belief-refining filters; (2) universal cost-sensitive criteria for numerical comparison of features in terms of expected information gains; and (3) optimal value-of-information criteria for sequential feature selection that take into account both feature extraction costs and terminal decision losses. As corollaries, this research investigates connections to asymptotic information-theoretic characterizations of optimal feature selection rules and decisions. The fourth specific aim of the project is the development of practical algorithms for two challenging computer vision problems: active visual search and fine-grained categorization. This component of the project leverages theoretical aims (1) and (2) to develop practical cost- and loss-sensitive feature compression techniques. Theoretical aim (3) targets algorithms that function as autonomous decision-making agents. Faced with an inference task on an image, they apply cost-sensitive non-myopic value- of-information criteria to decide at each time step whether to extract a new feature from the image or to stop and declare an answer.","title":"CIF: Medium:Collaborative Research: Nonasymptotic Analysis of Feature-Rich Decision Problems with Applications to Computer Vision","awardID":"1302438","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[541984,541985],"PO":["564898"]},"205878":{"abstract":"Information theory has had a profound impact on the fields of data transmission and compression. In contrast, it has yielded comparably few insights into problems such as knowledge extraction from and efficient search of massive datasets. While current information-theoretic tools and techniques can be applied to these problems to some extent, the paradigms for which these tools were developed will be being carefully reexamined in this project. Models that accurately capture the fundamental challenges faced by efficient search in modern massive database systems will be developed and analyzed. The asymptotic fundamental limits, which characterize the tradeoffs between accuracy, compression rate and search efficiency, will be investigated, along with development of practical algorithms that approach the ultimate benchmarks. One concrete problem being pursued is that of compression for efficient query and search. In this setting, the goal is, given a compressed representation, to answer search queries about the data that was compressed. This is in stark contrast to traditional compression, where the data need be merely reconstructible from the compressed form. The approach taken is tailored to distributed database design, but is also relevant to compression schemes that allow search within the compressed domain. <br\/><br\/>The fundamental quantities studied play a similar role to that of the channel capacity and entropy\/rate-distortion in channel and source coding, respectively. On one hand, they yield an understanding of the fundamental limits on the performance that any system for similarity queries based on compressed representations can hope to attain. On the other, the insights obtained from the theory are guiding the construction of schemes that approach these limits in practice. We will investigate how existing practical approaches (such as various hashing and clustering techniques) perform with respect to the information theoretic limits, and the extent to which approaches that have proved to be practical in source and channel coding can be used as building blocks to develop new efficient search algorithms that significantly improve on the current state of the art.","title":"CIF:Small:Collaborative Research: Compressed databases for similarity queries: fundamental limits and algorithms","awardID":"1321174","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[551175],"PO":["564898"]},"202248":{"abstract":"Almost all application segments today experience data explosion, meaning that they need to store, access, manipulate and transform extremely large amounts of data stored in different mediums in a fashion that is simultaneously performance-aware and energy-aware. These data-hungry market segments include (i) consumer applications in the mobile and home electronics segment, (ii) desktop applications that are providing rich content and user experience, (iii) scientific applications that generate petabytes of data for analyzing experiments and real-world phenomena on temporal and spatial scales unheard of before, (iv) enterprise applications which tirelessly store all kinds of data\/knowledge for auditability, analytics, and optimization, (v) datacenters and cloud platforms which use storage to hold large virtual machine images of the workloads for consolidation across different servers, (vi) Internet services and social networking platforms which need to store, track and manage user patterns, and (vii) cyber-physical applications which continuously sense and store physical world data for real-time analytics and control. Current computer infrastructures are poorly equipped to cope with this data demand. The primary reason for this is the inherent physical divide between computation and storage. While both computation and storage technologies have undergone tremendous improvements in the last decades, the interactions and interfaces between them have not, thereby limiting the performance of critical data-intensive applications. If not addressed in a timely fashion, this problem has the potential to slow down scientific discoveries and engineering breakthroughs. <br\/><br\/>This project addresses the data management problem by breaking the physical divide between computation and NAND-flash storage. Doing so can potentially allow the communication bandwidth between computation and storage to scale together with the parallelism-driven scaling of both computation resources and storage resources. It can also allow each to become more aware of the intentions and operations of the other, opening a wide spectrum of possibilities in more ef&#64257;ciently managing storage. This will in turn allow better co-design, co-management, and co-evolution of the two for better scalability in the future, as applications start imposing even more stringent computing and storage demands. Specifically, this project investigates three main strategies for bridging the physical divide between compute and NAND-flash storage. The first strategy enables better cooperation between flash storage and host; the second strategy elevates NAND-flash storage to directly interface with the processors, similar to main memory DIMMs (dual inline memory modules) interfacing to the on-chip cores through memory controllers; and the last strategy explores different placement options for tighter integration of NAND-flash storage with computational resources. The broader impacts of this research include student training, participation of under-represented groups, recruiting workshops, incorporation of educational modules into existing and future courses, and public domain simulation tools. Further, through the Visit In Engineering Weekend (VIEW) program, the project fosters interest in computer science and engineering. The project provides hands-on-design activities to motivate the VIEW participants in new areas of computer science and engineering related to storage system and data management.","title":"SHF: Medium: Breaking the Physical Divide between Computation and NAND-Flash Storage","awardID":"1302557","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["550859",542015,542016],"PO":["366560"]},"205779":{"abstract":"The research addresses social networks of agents, where the agents learn about the state of nature not only from private signals (i.e., signals only available to the agents receiving them), but from neighboring agents too. The agents are rational and cooperative, and in forming their beliefs about the state of nature, they process all the information that is available to them. The research aims at finding how information and misinformation can diffuse over networks of agents. The objectives are to use the new theory to design better engineering systems and to influence biological systems in ways so that beneficial outcomes are attained.<br\/><br\/>The goals of the research are to understand the processes of belief evolution about the state of nature in time and\/or space in networks of agents and in a wide variety of settings. The knowledge of the agents is expressed by their beliefs about the state of nature and is quantified by posterior probability distributions. Unlike in the majority of known studies where the agents want to get point estimates about the unknown state of nature, the agents in the addressed problems strive for obtaining complete beliefs about the unknown states as measured by posterior distributions. The state of nature can be static or dynamic and the information acquired from neighbors about it can be of continuous or discrete nature. For information processing, the agents use the Bayes' rule. Endowed with Bayesian reasoning, the agents carry out optimal information processing, and thereby it is expected that they beat the performance of agents that use competing methodologies.","title":"CIF: Small: Belief Evolutions in Networks of Bayesian Agents","awardID":"1320626","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["563567"],"PO":["564898"]},"205548":{"abstract":"Making high performance applications resilient to failure of individual nodes is a major challenge today. Particularly, there is a need for reducing the overheads associated with checkpointing and for dealing with silent data corruption in an effective fashion. This project at Ohio State University is addressing these problems based on new insights and approaches. The work on improving the efficiency of checkpointing and restart is based on the following observation - current checkpointing protocols were developed in context of distributed computing, and do not exploit key properties seen in most scientific parallel programs. This project is developing static and dynamic analysis methods to determine what we refer to as the \"message intent\", which can then be used to allow automated application-level uncoordinated checkpointing, but without the need for message logging, keeping the checkpoint sizes small, and recovery low-cost. In addition, a distinct software approach for handling silent data corruption is being developed. The idea is to make the data structures that control what computation and\/or communication occurs in the program resilient, by only replicating them and their storage. This introduces modest overheads, but guards against the most drastic impact of silent data corruption on program stability and correctness. <br\/>This research will result in reducing overheads of making high performance systems resilient, which in turn will improve the efficiency and resource utilization.","title":"SHF: Small: Advanced Compiler Techniques for Meeting Fault Tolerance Needs of HPC Systems","awardID":"1319420","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["558505"],"PO":["565272"]},"198783":{"abstract":"This research seeks to develop novel machine learning algorithms that enable real-time video and sensor data analysis on large data streams given limited computational resources. The work focuses on healthcare as an application domain where real-time video analysis can prevent user-errors in operating medical devices or provide immediate alerts to caregivers about dangerous situations. The research will develop algorithms to automatically adapt data analysis approaches to maximize accuracy of analysis within a short time period despite limited available computing resources. Today's healthcare environment is significantly more technologically sophisticated than ever before. Many medical devices are now frequently used in patient's homes, ranging from simple equipment such as canes and wheelchairs to sophisticated items such as glucose meters, ambulatory infusion pumps and laptop-sized ventilators. The rapidly growing home health industry raises new safety concerns about devices being used inappropriately in the home setting. The proposed research is designed to reduce medical device related use-errors by developing computational algorithms that perform real-time video analysis and alert the patient or caregiver when medical devices are not used appropriately. The real-time video and sensor data analysis is also critical to the healthcare systems that monitor the activities of the elderly or those with disabilities in order to allow a caregiver to react immediately to an incident. <br\/><br\/>New machine learning theories and algorithms will automatically adapt to hardware limitations, with the aim to learn from a large number of training examples, a prediction function that (i) is sufficiently accurate in making effective predictions and (ii) can be run efficiently on a specified computer system to deliver time critical results. Three types of prediction models are studied to address the problem of automatic hardware adaptation, including a vector-based model, a matrix-based model, and a prediction model based on a function from a Reproducing Kernel Hilbert Space (RKHS). A general framework and multiple optimization techniques are being developed to learn accurate prediction models that match limited memory and computational capacity. The new learning algorithms will be evaluated in several medical scenarios through real-time prediction of a patient's activities from observations in the large video archives collected by several healthcare related projects. The intellectual merit of the proposed work is in bridging the gap between the high complexity of a prediction model and limited computational resources, a scenario that is encountered in many application domains besides healthcare. The proposed research in machine learning algorithms and theories will make it possible to run complicated prediction algorithms on big data within the limitation of a given computing infrastructure. The developed techniques for automatic hardware adaptation will be applied to a large dataset of continuous video and sensor recordings for medically-critical activity recognition. The project's broader impacts include providing medical experts with algorithms and tools supporting novel approaches to analyzing observational data in their quest to recognize and characterize human behavior. Surveillance systems with continuous observations will be able to categorize salient events with co-located, limited hardware. Researchers with complex data from continuous streams will be able to explore their domains with greater accuracy within constrained time using their available computing resources. Similarly, large archives can be exploited as rapidly as possible with limited hardware.","title":"BIGDATA: Small: DA: Collaborative Research: Real Time Observation Analysis for Healthcare Applications via Automatic Adaptation to Hardware Limitations","awardID":"1251031","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":["45437"],"PO":["565136"]},"205559":{"abstract":"Bioinformatics research and genomic sequence alignment in particular have revolutionized the understanding of how cells work. Genomic sequence alignment identifies regions of similarity between sequences of individual genes that are a likely consequence of functional or evolutionary relationships between the sequences. However, genes and other biomolecules in the cells do not function in isolation. Instead, they interact with each other to keep one alive. And this is exactly what biological networks (BNs) model: in BNs, biomolecules are represented as nodes and physical or functional interactions between the biomolecules are represented as edges. Thus, BN alignment, which aims to identify topologically and functionally similar regions between BNs of different species, is promising to give further insights into organizational principles of life, evolution, disease, and therapeutics. For example, it could guide the transfer of biological knowledge across species between the conserved (aligned) network regions. This is important, since many nodes in BNs are currently functionally uncharacterized even for well-studied model species. <br\/><br\/>Intellectual Merit: This project aims to address several issues with the current view of the problem of network alignment. First, it will develop a novel framework for fair evaluation of existing BN alignment methods, which is currently lacking. Second, it will redefine the problem of network alignment to allow for directly optimizing the amount of conserved network topology, which current methods fail to do. Third, since different types of BNs exist that capture different functional slices of the cell, and since the existing methods can align only homogeneous networks, ignoring any node or edge types, this project will extend the proposed methods to allow for alignment of heterogeneous networks encompassing the different BN types. The proposed methods will be used in two novel interdisciplinary collaborative applications: 1) studying the role of yeast S. cerevisiae and human proteasomes responsible for protein degradation, and 2) studying pathogenicity and drug resistance of malaria parasites from the Plasmodium family. <br\/><br\/>Broader Impact: BN alignment has broad applications. For example, it can be used to transfer biological knowledge from well annotated to poorly annotated species between similar network regions or to infer species' phylogenetic and evolutionary relationships based on similarities of their BNs. Besides computational biology, this project may impact other domains as well. For example, network alignment can de-anonymize online social networks and thus impact user privacy. Since network research spans many domains, a free open-source software tool implementing the proposed methods will be offered to researchers from diverse disciplines. The software will also serve as an educational tool.","title":"AF: Small: Novel Directions for Biological Network Alignment","awardID":"1319469","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":[550423],"PO":["565223"]},"205823":{"abstract":"This research concerns complex dynamical systems based on networks of logical gates updated and observed at discrete time intervals. Examples of such systems in contemporary technology abound, including digital logic systems, digital communication systems, and more. This is also the case, notably, of many biochemical systems, such as DNA regulatory circuits. In fact, Norbert Wiener, one of the pioneers of the modern information age, famously wrote about ?the essential unity of the set of problems centering about communication, control, and statistical mechanics, whether in the machine or in living tissue.?<br\/><br\/>This research studies a novel signal model, and corresponding optimal estimation methods, for Boolean dynamical system models under noisy observational conditions. The optimal recursive MMSE estimator for the proposed model is called the Boolean Kalman Filter (BKF). The terminology comes from the fact that this estimator is reminiscent of the (extended, unscented) Kalman filter for continuous state-spaces. The BKF also has similarities with the forward (and backward) algorithm used for state estimation in Hidden Markov Models (HMM). The methodology is applied to the inference of biochemical regulatory networks, in collaboration with the Translational Genomics Research Institute (TGen), the University of Pittsburgh, and the Oswaldo Cruz Foundation (FIOCRUZ), in Brazil.","title":"CIF: Small: Optimal Estimation and Network Inference for Boolean Dynamical Systems","awardID":"1320884","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[551032],"PO":["564898"]},"205504":{"abstract":"Recent advances in materials, devices and fabrication technologies have led to an emerging class of solid-state sensors that can detect individual photons in space and time. Thanks to their single-photon sensitivity, ultra-fast speed, and rapidly increasing spatial resolutions, these new single photon sensors (SPS) have great potentials in a wide range of applications, including fluorescence-based bio-imaging, time-of-flight 3D computer vision, high-speed videography, and astronomy. The goal of this project is to build rigorous signal processing foundations for optical imaging based on the emerging SPS scheme.<br\/><br\/>Analogous to silver-halide grains in photographic film, each pixel of the SPS has a binary response, revealing only one-bit and stochastic information of the local light intensity. With an array of pixels and high temporal sampling rates, the SPS generates a massive spatiotemporal volume of bits that sample and encode the original visual information. The investigator studies models, theory, and algorithms in signal sampling and inference to address the challenges associated with the SPS. Specific objectives of this project involve: (1) establishing sampling theorems for the SPS in acquiring light intensity fields of given spatiotemporal bandwidths; (2) identifying performance bounds and the precise tradeoffs between imaging performance and key device metrics; (3) designing adaptive sensing schemes to improve imaging performances; and (4) developing both offline and online image formation algorithms that can efficiently \"decode\" the massive bitstreams generated by the SPS.","title":"CIF: Small: Sampling and Inference Methods for Spatiotemporal Single-Photon Imaging","awardID":"1319140","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["535105"],"PO":["564898"]},"199301":{"abstract":"Probabilistic graphical models are central to automated reasoning. The past decade has seen significant progress on two basic reasoning tasks: combinatorial optimization (maximization or minimization) and marginalization (summation) tasks. Maximization queries are often used to generate predictions from a given model, such as image denoising or finding stereo correspondence. Summation queries are common in model learning, for computing and optimizing the data likelihood during fitting. <br\/><br\/>A key point is that for these tasks the model is treated homogeneously; all variables are either maximized (or minimized) or summed over. However, many important reasoning and inference tasks require a mixture of these where some variables are maximized (or minimized), while others are summed over. Such mixed problems occur in optimal estimation, decision making in single- and multi-agent systems, and worst-case or antagonistic problems that arise in robust estimation and games. Far less progress has been made on these more difficult query types.<br\/><br\/>The goals of this Faculty Early Career Development (CAREER) award are to develop a new framework for exact and approximate methods for such advanced computational reasoning problems. The project includes both theoretical and practical algorithm pieces, and studies their use in estimation and learning from data. The project extends the abilities of intelligent systems to reasoning and decision-making under uncertainty. It applies and tests these methods on a variety of application domains, including sensor networks and computer vision. The project supports graduate, undergraduate, and high-school student research, and it contributes to open and online course development. The project increases impact and algorithm adoption by deploying open-source tools, developing open standards and benchmark problems in these domains, and it encourages additional progress through open comparisons and competitions.","title":"CAREER: Estimation and Decisions in Graphical Models","awardID":"1254071","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["554545"],"PO":["562760"]},"202810":{"abstract":"The goal of this proposed infrastructure is to enable research towards the creation of the first buildingwide, pervasive, life-long learning, multi-robot intelligence that is situated within an existing building. This buildingwide intelligence (BWI) infrastructure will be comprised of multiple robot appendages, as well as a suite of static sensors and interactive displays. The ultimate goal of the facilitated research is to enable BWI to interact naturally with all of the buildings users, both learning about the patterns and preferences of its long-term inhabitants, and aiding first-time visitors. In addition, it will be robust to continual changes to the capabilities and availability of its component robots and other sensing and actuation resources; and it will consist of readily available components and open source software for ease of replication. <br\/><br\/>The most important broader impact of this proposal will be the development and dissemination of a new, open infrastructure suitable for cutting-edge research across the department and university, including reusable components suitable for installation in buildings everywhere. The concept of BWI will also provide impacts on education, including a new curriculum for a project-based course, serving as a platform for graduate and undergraduate research (including as a part of UTs novel Freshman Research Initiative), as well as a very public facade, which will enable public demonstrations at outreach events targeting underrepresented groups such as women in CS and Hispanics.","title":"II-NEW: Infrastructure for a Building-Wide Intelligence","awardID":"1305287","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["553684",543538],"PO":[543539]},"204526":{"abstract":"Indiana University, the PRAGMA project, the Network Startup Research Center (NSRC) and the National Center for Atmospheric Research (NCAR)) will organize a science and cyberinfrastructure workshop to be held in Vietnam in late 2013, involving countries of the Lower Mekong region (LMR), including Cambodia, Laos, Thailand, Vietnam and Myanmar. <br\/><br\/>The workshop will focus on three areas: 1) forming and enhancing science and education collaborations among US scientists and scientists of the countries of the LMR; 2) developing human capacity to operate and maintain cyberinfrastructure in support of science and engineering collaborations; 3) policy and regulatory best practices in cyberinfrastructure development and science collaboration. In countries where Research and Education Networks (RENs) are just emerging, developing a knowledgeable community of network operators, users and policy makers is a necessary step in supporting and fostering collaborations between researchers and educators within the region, with the US and globally. The intellectual merit of the workshop is the bringing together of these three groups: network operators and managers of RENs at the campus and national levels; researchers from institutions within the region and from the US who collaborate in three main areas of science and engineering: disaster management, climate change and forestry; and policy-makers and leaders from government and academia involved in supporting the development of cyberinfrastructure and collaborative science in their countries and in the region. <br\/><br\/>The results of the workshop will benefit science and engineering in areas of national and regional importance in the Lower Mekong countries, and where US science and engineering collaborations will be enhanced. The US Department of State is engaged in the multinational Lower Mekong Initiative (LMI), designed to enhance collaboration in the region on critical issues of education, health, environment and infrastructure. Funds from the Department of State will support participation by scientists from within the region, which will broaden the impact of the workshop. The NSF funds will support travel for US scientists and graduate students working with collaborators in the countries of the LMR and\/or collaborating with counterparts in the region, including those from across many NSF divisions. One of the workshop?s broader impacts will include increasing participation by researchers from countries of the LMR in international science and engineering projects. The training provided to both network operators and researchers using cyberinfrastructure tools will be done in a sustainable, train-the-trainer method to encourage ongoing learning.","title":"Building Network Enabled International Science and Engineering Collaborations in the Lower Mekong Region","awardID":"1313585","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7369","name":"INTERNATIONAL RES NET CONNECT"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[547710,547711,547712,547713,547714],"PO":["564246"]},"202238":{"abstract":"Statistical conclusions from research studies may often be misleading due to a variety of reasons including small sample sizes for the studies or confounding factors which are unknown to the investigators of the study. One way to reduce the possibility of misleading conclusions is to combine the results of multiple research studies using a technique referred to as \"meta-analysis.\" Meta-analysis is one of the most widely used techniques to infer knowledge from data in science. The idea behind meta-analysis studies is that the combined statistical conclusions from multiple research studies reflect the information in all of the studies and are more likely to be accurate. The conclusions from meta-analyses are considered \"better\" or \"more likely to generalize\" than conclusions from single studies. However, this notion is not well formalized and formalizing this question is a goal of this project. In addition, existing meta-analysis methods do not take into account any knowledge of the similarities and differences between the studies. Taking advantage of these similarities and differences can improve the effectiveness of meta-analysis.<br\/><br\/>This project takes advantage of recent developments in the area of \"causal inference\" which is the study inferring cause and effect relationships from data. These types of inferences utilizes a type of graph called a causal graph which graphically represents cause and effect relationships. This project develops an alternate framework for meta-analysis based on a novel type of causal graph, a selection graph. A selection graph formally represents the similarities and differences between the studies. This project provides a unifying framework and powerful powerful methodology for meta-analysis. The methods developed in this project are applied to genetic studies where meta-analyses have discovered thousands of variants involved in common human disease in the past few years.<br\/><br\/>Causal graphs have had a major impact on the way causality is taught and understood in cognitive science, statistics, and the health and social sciences. The proposed research promises to have similar impacts by transforming the approach to meta-analysis, one of the work horses of statistical inference in the physical, life and social sciences. The resulting techniques will be used to perform meta-analyses of genetic studies which can lead to the discovery of variation involved in disease. The results of the project, including publications, software, data sets, and course materials will be made freely available through the project web site: http:\/\/zarlab.cs.ucla.edu\/causal-meta-analysis\/.","title":"III: Medium: Meta-analysis reinterpreted using causal graphs","awardID":"1302448","effectiveDate":"2013-07-15","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[541989,"554197"],"PO":["565136"]},"198785":{"abstract":"Scientific Bigdata sets are becoming too large and complex to fit in RAM, forcing scientific applications to perform a lot of slow disk and network I\/O. This growth also makes scientific data more vulnerable to corruptions due to crashes and human errors. This project will use recent results from algorithms, database, and storage research to improve the performance and reliability of standard scientific data formats. This will make scientific research cheaper, faster, more reliable, and more reproducible.<br\/><br\/>The Hierarchical Data Format (HDF5) standard is a container format for scientific data. It allows scientists to define and store complex data structures inside HDF5 files. Unfortunately, the current standard forces users to store all data objects and their meta-data properties inside one large physical file; this mix hinders meta-data-specific optimizations. The current storage also uses data-structures that scale poorly for large data. Lastly, the current model lacks snapshot support, important for recovery from errors.<br\/><br\/>A new HDF5 release allows users to create more versatile storage plugins to control storage policies on each object and attribute. This project is developing support for snapshots in HDF5, designing new data structures and algorithms to scale HDF5 data access on modern storage devices to Bigdata. The project is designing several new HDF5 drivers: mapping objects to a Linux file system; storing objects in a database; and accessing data objects on remote Web servers. These improvements are evaluated using large-scale visualization applications with Bigdata, stemming from real-world scientific computations.","title":"BIGDATA: Small: DCM: Collaborative Research: An efficient, versatile, scalable, and portable storage system for scientific data containers","awardID":"1251037","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":["550086"],"PO":["565136"]},"208839":{"abstract":"This grant supports participation of approximately 22 US dissertation-stage doctoral students in the Organizational Communication and Information Systems (OCIS) doctoral consortium to be held at the Academy of Management meeting in Lake Buena Vista, Florida, in August 2013. The OCIS doctoral consortium is a research-focused meeting that has taken place annually at the Academy of Management conference since 2000, and has helped to launch the careers of many outstanding researchers in organizational communication and information systems. Goals of the workshop include building a cohort group of new researchers who will then have a network of colleagues spread out across the world, guiding the work of new researchers by having experts in the research field give them advice, and making it possible for promising new entrants to the field to attend their research conference. Student participants will make formal presentations of their research during the workshop, and will receive feedback from a faculty panel. The feedback is geared to helping students understand and articulate how their work is positioned relative to other OCIS research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. <br\/><br\/>The annual OCIS doctoral consortia traditionally bring together the best of the next generation of researchers in organizational communication and information systems, allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Applications are encouraged from all doctoral students whose research is OCIS-related, regardless of the fields in which they are earning their degrees. Participants will be a diverse group with regard to their research topics, methods, backgrounds, and the kinds of institutions they attend.","title":"Travel Support for the Organizational Communication and Information Systems Doctoral Consortium","awardID":"1342548","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["560755"],"PO":["564456"]},"210610":{"abstract":"This project develops an integrated framework to perform simultaneous object discovery and detector training in an unsupervised setting. It takes advantages of large amount (millions or even billions) of well-organized internet images to automatically learn rich image representations for a wide range of objects. The main activities in this project include the following. (1) The central component of this project is a formulation to turn unsupervised data into weakly-supervised \"noisy input\" through which commonalities are explored for rich object representation using a new learning method. (2) A large dictionary of mid-level image representations will be learned on a large scale number of images retrieved using thousands of object words through the internet search engine. (3) A new flexible object representation is developed to deal with articulated\/non-rigid objects.<br\/><br\/>The project advances computer vision and machine learning fields by developing an unsupervised paradigm to explore a large scale of internet images. The learned mid-level and high-level representations from images retrieved using thousands of words can significantly enhance the object representation power and benefit researchers in the object recognition field. The formulations, algorithms, and methods resulted from this project are also helpful to researchers in other fields such as medical imaging and data mining. The project dissemination plan includes the source code and learned mid-level and high-level representations.","title":"RI: Small: Unsupervised Object Class Discovery via Bottom-up Multiple Class Learning","awardID":"1360566","effectiveDate":"2013-07-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["564317"],"PO":[564316]},"202811":{"abstract":"The project is aimed at enhancing an existing infrastructure that supports software engineering research on very large bodies of source code. The srcML infrastructure currently includes a generic XML representation for a variety of programming languages, a robust and efficient parser for C\/C++, and a limited set of tools to support analysis and manipulation of large bodies of source code. The infrastructure is currently being used by a wide number of researchers in the fields of software engineering and programming languages. It is also being directly applied to practical problems in a variety of industrial settings. The srcML infrastructure is open source and freely available to the public via a GPL license. Documentation for the infrastructure is available online and a number of other resources, including online tutorials, are under development. Additionally, tutorials on how to use the infrastructure to support various research efforts are planned for a number of software engineering conferences.<br\/><br\/>The PIs plan to extend the current efficient and robust parsing and markup to a broader variety of widely used programming languages (namely Java and C#) and allows for the addition of new languages via a plugin grammar architecture. The current toolkit is being greatly expanded to support the exploration, analysis, and manipulation of very large code bases. The tools include such things as a static slicer, metrics computation, various static analysis tools, a fact extractor, a call graph generator, syntactic querying tools, and a syntactic differencing tool. Additionally, a set of tools to support the construction and application of transformation rules is being developed. Extending the infrastructure to a broader set of widely used languages enables researchers to investigate more production and commercial software. <br\/>The enhancements to the srcML infrastructure can drastically reduce the entry cost for individuals to conduct research by enabling them to explore, analyze, and manipulate software in an extremely easy and flexible manner, thus allowing them more time to pursue novel and transformative research on software, software engineering, and software languages. The addition of analysis, transformation, and syntactic differencing tools enable unproblematic and flexible exploration of large code bases written in widely used programming languages.","title":"CI-ADDO-EN: Collaborative Research: Enhancing the srcML Infrastructure: A Mixed-Language Exploration, Analysis, and Manipulation Framework to Support Software Evolution","awardID":"1305292","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543540],"PO":["565272"]},"198797":{"abstract":"Scientific Bigdata sets are becoming too large and complex to fit in RAM, forcing scientific applications to perform a lot of slow disk and network I\/O. This growth also makes scientific data more vulnerable to corruptions due to crashes and human errors. This project will use recent results from algorithms, database, and storage research to improve the performance and reliability of standard scientific data formats. This will make scientific research cheaper, faster, more reliable, and more reproducible.<br\/><br\/>The Hierarchical Data Format (HDF5) standard is a container format for scientific data. It allows scientists to define and store complex data structures inside HDF5 files. Unfortunately, the current standard forces users to store all data objects and their meta-data properties inside one large physical file; this mix hinders meta-data-specific optimizations. The current storage also uses data-structures that scale poorly for large data. Lastly, the current model lacks snapshot support, important for recovery from errors.<br\/><br\/>A new HDF5 release allows users to create more versatile storage plugins to control storage policies on each object and attribute. This project is developing support for snapshots in HDF5, designing new data structures and algorithms to scale HDF5 data access on modern storage devices to Bigdata. The project is designing several new HDF5 drivers: mapping objects to a Linux file system; storing objects in a database; and accessing data objects on remote Web servers. These improvements are evaluated using large-scale visualization applications with Bigdata, stemming from real-world scientific computations.","title":"BIGDATA: Small: DCM: Collaborative Research: An efficient, versatile, scalable, and portable storage system for scientific data containers","awardID":"1251137","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":["510424","543574",533341],"PO":["565136"]},"210611":{"abstract":"Designing automated algorithms to extract and analyze anatomical brain structures from neuro-images is of significant scientific and clinical importance in detecting abnormal brain patterns, analyzing various brain diseases, and studying the brain growth.<br\/><br\/>This project will develop a general statistical modeling\/computing framework to perform 3D holistic brain image understanding. The framework emphasizes rigorous, efficient, and effective learning-based statistical models to integrate the complex appearances, varying 3D shapes, and the large spatial configuration of anatomical brain structures.<br\/><br\/>Implicit models through discriminative approaches have the advantages of fusing a large amount of information and obtaining decisions quickly. Explicit models through generative approaches can directly represent the information and thus, better explain the structure and model the transformation and scale change. The PI explores harmonic relationships between discriminative and generative models for 3D image parsing by combining implicit and explicit models along several directions: (1) learning-based models with rich appearance, and implicit shape and context; (2) integrating skeleton with surfaces for 3D shapes; (3) effective 3D shape representation and similarity measure; (4) component-based simultaneous registration and segmentation.<br\/><br\/>This research will contribute to automating the process of extracting a large number of anatomical structures, and enhancing the shape analysis needed for detecting brain diseases, monitoring health conditions, studying drug effects, and discovering brain functions. The scope of the proposed model goes beyond medical image analysis and can be applied in other problems of statistical modeling\/computing, computer vision, multi-variate labeling in machine learning.","title":"CAREER: Holistic 3D Brain Image Parsing by Integrating Implicit and Explicit Models","awardID":"1360568","effectiveDate":"2013-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[564317],"PO":[564318]},"210677":{"abstract":"1140384 (Ramaswami). This award is funded under NSF's Science, Engineering, and Education for Sustainability (SEES) activities, which aims to address the challenges of creating a sustainable world. This project will develop a research collaboration network (RCN) across 20+ US universities and 2 national labs to coordinate work on the overarching theme of sustainable cities, with focus on reducing energy use, carbon emissions and mitigating climate-risks to water supply and public health in cities. The US network will collaborate with international sustainability research networks (in Australia, EU, Asia) and with a network of practitioners and policymakers in US and global cities. RCN activities will lead to the development of (a) inter-disciplinary systems framework(s) to represent linkages between people, infrastructures and the natural system, from the city-scale to the global scale, that shape sustainability outcomes in cities, (b) harmonized methods and international data standards to operationalize the framework, to report, for example, the carbon footprints of cities, water vulnerability of cities, or to analyze social actors who shape urban infrastructures and consumption patterns toward sustainability, (c) a network of 12 global cities for testing the framework and its component theories and models\/methods in cities with different natural, infrastructural, socioeconomic and cultural characteristics, (d) a virtual collaborative forum to share research methods, experiences and teaching tools across more than 20+ US universities on the common thematic area of sustainable cities. The RCN will provide science based systems analysis tools, much needed by more than 1000 cities worldwide that are developing sustainability plans addressing energy, water and climate change. A unique aspect of this RCN is broad-based integration across urban ecology, industrial ecology, atmospheric sciences, infrastructure engineering, architecture, urban planning, behavioral sciences, public affairs and public health toward the goal of sustainable cities. Cross-discipline integration, coordination of data across scales, and cross-city comparisons are expected to advance the science of sustainable cities. The RCN has potential to impact more than 1200 students in participating US universities and 65 million people in the network of cities where field work will be coordinated. Dissemination potential is high through network links with policy groups such as ICLEI-USA and The World Bank who work with cities worldwide.","title":"RCN - SEES: Sustainable Cities - People and the Energy-Climate-Water Nexus","awardID":"1361670","effectiveDate":"2013-07-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"7977","name":"CR-Water Sustainability & Clim"}}],"PIcoPI":[564480],"PO":["565364"]},"201976":{"abstract":"This award establishes a new Research Experiences for Teachers site at Drexel University. The Drexel team plans to create a summer research institute in computer science for STEM high school teachers and 2-year college faculty in the City of Philadelphia and Greater Philadelphia Metropolitan Area. Teachers will spend the time performing research with faculty and students in the associated labs and initiating work on educational modules for use at their home institutions. They will prepare poster presentations and videos summarizing their projects, initial accomplishments, further expectations and descriptions of their modules. Participants will remain engaged year-round by participating in Teacher2Teacher discussion groups, facilitated by the Math Forum@Drexel. They will also visit campus for quarterly meetings, culminating in a 1-day showcase event in the spring to present results, materials and posters, and to which their colleagues and students are invited. The objectives of the program are to build partnerships between high schools, community colleges and the university, introduce teachers to cutting edge research in the computer science community, inform and excite them about computer science principles and computational thinking, produce learning materials for use in high school and community college STEM curricula, and expand the pipeline of students studying STEM and computing curricula in college.<br\/><br\/>Intellectual Merit: The intellectual merit is in the strong research expertise of the participating faculty in research as well as their significant experience with pre-college education. The focus is on important themes of big data and machine learning which are areas that are current and of importance all citizens. The translation of the research experiences into modules compatible with Computer Science Principles should also add to the significant body of work linking fundamental computer science to classroom practice and applications. <br\/><br\/>Broader Impacts: The project makes significant outreach to the greater Philadelphia metropolitan area, with a population exceeding 5 million, and the eighth largest school district in the USA. The Math Forum involves a substantial community of mathematics teachers and professionals, providing a variety of services and resources. Through the partnership with these organizations and dissemination through other widely used services, the team expects to provide significant impact for these activities.","title":"RET in Engineering and Computer Science Site for Machine Learning, Big Data and Computer Science Principles","awardID":"1301171","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}}],"PIcoPI":[541316,541317],"PO":["564181"]},"204715":{"abstract":"The widespread deployment of parallel machines --- from multicores to supercomputers --- has made it critical to develop simple approaches to programming them. Significant progress has been made in simplifying parallel programming by developing programming models to support parallelism without concurrency, that is, without the nondeterminacies in the logic of programs caused by the relative and nondeterministic timing of communicating processes. Yet most parallel programs in practice are concurrent, and hence, nondeterministic, leading to code that can only be programmed and understood by experts. This research project aims to understand how parallel computers can be made easier to use by the vast majority of programmers by developing software technology that enables deterministic parallel computing.<br\/><br\/>The project takes a holistic view of the problem from the key perspectives of programming linguistics, software systems, algorithmic analysis, and absolute performance. It acknowledges the reality that parallel programming cannot be fully deterministic at every level of abstraction. It is pursuing three key strategies for dealing with concurrency: encapsulating concurrency so that it is hidden by layered abstractions at appropriate abstraction levels, avoiding concurrency by restructuring programs to employ deterministic approaches, and managing concurrency when it is impractical to either encapsulate or avoid concurrency completely. Among the specific techniques being studied are commutative building blocks, deterministic nonassociative reducers, deterministic pipelined parallelism, deterministic interfaces, and generalized race detection for detecting invariant races. The project is developing open-source libraries, tools, and runtime extensions integrated into a multicore-software platform, as well as a problem-based benchmark suite to compare approaches.","title":"SHF: AF: Large: Collaborative Research: Parallelism without Concurrency","awardID":"1314633","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[548222],"PO":["564588"]},"206926":{"abstract":"When we listen, we rapidly and reliably decode speakers' intentions and we mostly do so independently of whom were are talking to. Yet, anyone who has interacted with an automated speech recognition system (e.g., while booking a flight) is painfully aware that speech recognition is a computationally hard problem: although we hardly ever become aware of it, the physical signal corresponding to, for example, one speaker's \"b\" can be identical to another speaker's \"p\", making it hard for computers to distinguish between them. How then does the human brain accomplish this task with such apparent ease? <br\/><br\/>This NSF funded workshop brings together researchers from computer sciences, linguistics, and the cognitive sciences to discuss and investigate how the brain achieves robust language understanding despite variability. The invited speakers are internationally-known experts. Representatives from both industry and academia will present on the state of the art in automated speech recognition, implicit learning during language understanding, and the neural systems underlying speech perception. The workshop will take place in conjunction with the 2013 Linguistic Society of America's Summer Institute--the largest international linguistics summer school--and will thereby provide training to a large number of young language researchers.","title":"Workshop: How the Brain Accommodates Variability in Linguistic Representations; July, 2013 - University of Michigan","awardID":"1330937","effectiveDate":"2013-07-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[554035,554036],"PO":["564343"]},"205716":{"abstract":"Recent advances in biotechnology have facilitated the simultaneous measurement of response of thousands of genes, and in effect enabled comparative studies that can identify which drugs are most effective and have fewest side effects at the genetic level. To obtain true response patterns of genes from these studies, researchers have often utilized a conservatively large number of samples for each treatment, increasing the cost significantly for studies with many drugs. Efforts aimed to reduce sample size (i.e. the number of samples in experiments) are challenged by the difficulty to articulate relationships between sample size and true patterns of gene response to treatments. <br\/><br\/>Intellectual merit: This project will develop new methods that elucidate the relationships between true patterns of gene response to treatments and sample size. First, the use of directed graphs to represent gene response patterns make it easier for researchers to distinguish and visualize subtle gene-expression differences resulting from similar drugs. Further, properties of these graphs are exploited to isolate false patterns from true ones, enabling accurate predictions of true patterns of gene response even in cases where there are few samples. Accurate prediction of true response patterns of genes further leads to accurate prediction of gene function. Consequently, this work will pave the way for cost-effective experimental designs of comparative studies with many drugs.<br\/><br\/>These results also help develop new methods that improve clustering analysis of gene response patterns. Unlike prominent conventional methods that treat all observed patterns as true, the advantage of this approach lies in the ability to quantify the degree to which each observed pattern could be true. This advantage will ultimately result in more accurate determination of groups of genes that cooperate in same pathways or share similar functions.<br\/><br\/>Broader Impacts: This project will generate the materials that promote interdisciplinary teaching, training and research beyond the standard curriculum. Additionally, these materials will be refined and incorporated seamlessly into two separate events: the Computer Science Open House and the Programming Challenge, which have been organized annually by the PI for the past several years. Targeting high school students in the Memphis\/Mid-South areas, these events aim to raise awareness, attract talent and foster interest in computing and computational sciences.","title":"Analysis of gene expression data using transitive directed graphs","awardID":"1320297","effectiveDate":"2013-07-15","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[550789],"PO":["565223"]},"198798":{"abstract":"Massive longitudinal healthcare data, such as administrative claims and electronic health records, provide an opportunity to greatly enhance the accuracy and clinical impact of patient-level predictions across a wide range of outcomes. This research targets the national priority domain of healthcare IT and showcases the advances that Big Data afford in helping patients make informed healthcare decisions leading to improved outcomes. Other involved stakeholders include healthcare providers, insurers and governmental agencies, and the databases this proposed grant employs encompass diverse and vulnerable patient populations, including the young, the poor and the elderly. Within this context, this grant is seeking to predict patient-level health events based upon personal characteristics and conditions. Accurate and well-calibrated predictions could significantly improve the wellbeing of patients and populations. This grant proposes to derive predictive models from massive observational data and then, for example, predict that a particular patient has an 18% chance of experiencing a stroke in the next 12 months. With this prediction in hand, caregivers and patients can optimize medical interventions and implement behavioral changes to hopefully prevent the predicted event. Further, this grant integrates two graduate student researchers, whose mentored experiences begin to rectify the shortage of data scientists trained at the intersection of statistics and medicine, and provides general statistical software tools for building large-scale predictive models from massive data across scientific domains.<br\/><br\/><br\/>From a technical perspective, the proposed grant aims to first evaluate performance and applicability of an existing predictive model across five administrative claims and electronic health record databases covering over 80 million lives, using CHADS2 stroke risk as a motivating example. Then the grant will develop an innovative data-driven process for building patient-level predictive models from longitudinal observational data, and initially apply the process to predicting stroke in patients with atrial fibrillation for comparison of performance against CHADS2, Finally, the grant aims to explore characteristics of the process<br\/>and resulting models, such as: evaluation of out-of-sample predictive performance in different databases; consideration of how models change over time; and assessment of which clinical variables most substantially contribute to patient-level predictions. Together, this research will focus on identifying heuristics to extract clinically relevant predictors from longitudinal electronic healthcare data, developing algorithms to use this information in multivariate modeling through massive parallelization using graphics processing units, optimized for data sparsity, and evaluating performance based on accuracy in predicting outcomes at the patient level. As a proof-of-concept, the grant will develop an approach to predict stroke risk and apply this approach across five disparate data sources (80+ million patients, including drugs, lab values, procedures, emergency room visits, primary care visits, inpatient encounters, etc) that reflect diverse patient populations across the US, including the privately insured, Medicare-eligible, and Medicaid beneficiaries. The underlying goal of the grant is to apply innovative statistical and machine learning techniques using advancing computer technology to large-scale observational data to develop accurate and well-calibrated patient-level predictive models enabling the prediction of future medical events for individual patients.","title":"BIGDATA: Small: DA: Patient-level predictive modeling from massive longitudinal databases","awardID":"1251151","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":["539592",533344],"PO":["565136"]},"199227":{"abstract":"Digital models of human anatomy, already common elements of motion pictures and computer games, are now increasingly being incorporated into diverse \"serious\" applications such as medical diagnostics, surgical planning and vehicle design. Both current and emerging applications demand improved photorealism, enhanced biomechanical accuracy, better subject specificity and faster simulation algorithms. As these demands often outpace the evolution of computer hardware, new algorithms for biomechanical modeling and simulation are necessary to ensure that upcoming computational platforms are utilized to the best of their capacity.<br\/><br\/>With respect to computational performance, physics-based simulations of virtual materials in interactive applications have demonstrated inferior performance in terms of cost per degree of freedom when compared to large-scale simulations of similar phenomena in HPC settings. This is partly attributable to the regularity and economy of scale associated with large models, compared to the pronounced irregularity and heterogeneity at lower resolutions. But it is also due to the fact that the commonly-used algorithms and data structures for interactive virtual materials reflect design compromises with respect to features, accuracy and parallelization potential. In this project the PI will endeavor to show that it is possible to reinvent both algorithms and data structures so as to achieve optimal computational efficiency for nonlinear virtual materials even under the constraints of interactive simulation, and also to achieve improvements of orders of magnitude in runtime, resolution and accuracy. The work will leverage expertise from computer systems, scientific computing, continuum mechanics and numerical analysis.<br\/><br\/>Biomechanical simulation has provided a great opportunity for transformative advances in medical practice using virtual models of the human body for disease prevention and treatment. These emerging applications mandate an increased level of attention to the unique demands of interactivity, resolution and anatomical accuracy for clinical uses of biomechanical modeling and simulation. Algorithmic improvements that yield two or three orders of magnitude have the potential to transform clinical training or operation planning tasks from off-line processes to practical interactive experiences. In addition to being a valuable opportunity to improve patient care, the use of anatomical modeling as a testing ground for effective and scalable simulation algorithms will have a lasting legacy that extends well beyond the clinical field. The high degree of irregularity in shape and function that is inherent in human tissues yields an excellent and challenging benchmark for the validity of material models, the accuracy of discretization techniques and the efficiency of numerical solvers. Considerations such as the accommodation of topology change and facilitation of parallel processing make simulating virtual nonlinear tissue models an excellent opportunity to refine core computational physics and numerical analysis techniques.<br\/><br\/>Broader Impacts: Computer simulations have been established as an educational tool in many fields (e.g., driving and flight training), helping to improve the safety record of operators without risk of physical harm. They present a great opportunity to affect the quality of patient care, considering the fact that most surgical residents currently sharpen their skills while operating on actual patients. Anatomical simulators could also reduce the need for animal testing, and help with knowledge transfer across the international clinical community, especially in developing countries. As part of this project, the PI will develop new academic course offerings that will serve to connect computer engineers, applied mathematicians, and clinical practitioners.","title":"CAREER: Accelerated simulation of nonlinear solids with applications to human anatomy modeling in interactive virtual environments","awardID":"1253598","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[534370],"PO":["565227"]},"204749":{"abstract":"This project will develop foundational principles for hierarchical wireless network design by leveraging full-duplex transmissions in both access and wireless backhaul. Full-duplex is most promising at shorter ranges, and hence is fortuitously aligned with the predicted dominant access range in future networks. Furthermore, larger full-duplex ranges are feasible in infrastructure-to-infrastructure links, and hence are well suited for backhaul links. While full-duplex is well-aligned with the key elements of hierarchical networks, our current design principles are largely developed for half-duplex transmissions which is the basis for all current networks. With that in mind, this project will address both theory and protocols for hierarchical full-duplex networks by looking at: (1) data-driven signal models for self-interference caused by the node's own transmission to its own receiver, (2) theoretical foundations for scheduling and routing that leverage both self-interference and multi-hop interference cancellation; and (3) protocols and prototypes for network scale full-duplex resource management. <br\/><br\/>Full-duplex breaks one of the basic design constraints in current wireless networks, all of which are either half-duplex in time or frequency; it will therefore rewrite wireless networking fundamentals. Further, with emphasis on realizable networks using extensive Rice University's programmable testbeds, the project will impact the next-generation of wireless networks via its corporate partners. Finally, the project team will establish a unique inter-university education and research program, which will include joint advising and collaborative advising and leverage the team's complementary expertise.","title":"NeTS: Large: Collaborative Research: Foundations of Hierarchical Full-Duplex Wireless Networks","awardID":"1314822","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[548310,548311,548312],"PO":["565303"]},"199613":{"abstract":"CIF21 DIBBs: Building international data sharing capacity in lake sciences, with implications for the broader environmental science community <br\/>Environmental research, and science in general, are being transformed by the unprecedented amount and diversity of spatial and temporal data available for analysis. Hosts of new sensors and experimental techniques are driving this data flood. And while the transformational potential on science is understood, the reality of managing the data flows from collection through to analysis, especially integration with other data, insights, plus education, and outreach has not kept pace. A continuum of approaches exist for data archiving, publishing and sharing: from the single investigator with limited technical skills, or limited personal interest in archiving or sharing data, to the highly structured ecological observatory with an IT (Information Technology) department and the explicit goal of archiving data and making them accessible to researchers who were not involved in the sampling (e.g. NEON). Grassroots organizations like GLEON (the Global Lake Ecological Observatory Network) share many similarities with the single investigator approach without major IT support, but recognize data sharing as a mandatory first step to answer pressing research questions addressing climate and land-use change, diminishing ecosystem services, and large scale disruptions of ecosystem functioning on a global scale. It is proposed to collaborate with other groups invested in the area of environmental observations data management and develop a design and implementation plan for a data publishing and sharing system that will address not only GLEON?s needs but also those of environmental research communities that find themselves in a similar place along the outlined data management continuum, of which there is a growing number. We will leverage GLEON?s experience, organizational structure, community trust, and recognized need for data sharing, Our approach will be primarily based on deploying and testing technology components created by CUAHSI, DataONE, LTER, and DataTurbine in a prototype setting and to assess their applicability in the GLEON community through targeted focus groups. The intellectual merits are twofold. First, prototyping and testing of existing technologies by our community members will provide valuable feedback to the original creators of the technology. Second, and most importantly, through our efforts, our community will develop a design and implementation plan for a data publishing and sharing system that is not only well conceived and sustainable, but owned and manageable by our community members, with potential implementation by dozens, if not hundreds, of ecological observatories. Broader impact: This community is an international and multi-cultural grassroots organization based on the recognized need for collaboration, as very typical in the current and future landscape of environmental research approaches. Therefore, a community level data publishing and sharing design and implementation plan that considers aspects typical for these research approaches will benefit many other international grassroots research and education collaborations, and the approach will be transformational in developing such global infrastructures. Aspects of primary importance are governance, sustainability, buy-in, trust, appropriate credit, and last but not least, usability. Finally, during the evaluation phase many researchers and students will be exposed to and trained in the use of technology that is currently available to them, even if in the end it is not considered appropriate for the entire community.","title":"CIF21 DIBBs: Building International Data Sharing Capacity in Lake Sciences, with Implications for the Broader Environmental Science Community","awardID":"1255849","effectiveDate":"2013-07-15","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":["561825","538611","561826"],"PO":["565292"]},"210668":{"abstract":"This research will test a conceptual model of the relationship between social media goal pursuit and well-being that is grounded in motivational theory and results from two pilot studies. In the theoretical framework, the broad range of goals people have for using social media is uniquely determined by two broad dimensions that specify the primary focus of the 1) content interaction and the 2) person interaction. The social media goals corresponding to these dimensions are hypothesized to be pursued according to the basic needs that social media satisfy for its users and the motivational orientations supported by those needs. The model states how goals lead to different well-being outcomes with the relationship between social media goal pursuit and well-being moderated by perceptions of overall well-being in specific life domains, along with constructs related to social identity. Three studies will test and validate the conceptual model: validation of the dimensions underlying social media goal pursuit (Study 1), development of new scales to measure the social media goals (Study 2), and testing and refinement of the model in a structural equation modeling framework (Study 3). The model will permit examination of a host of research questions including whether certain social media goals render individuals more vulnerable to negative well-being outcomes. For example, do individuals low in well-being pursue particular social media goals in the hope of improving their lives? Are these goals different from those that individuals more satisfied with their lives pursue? The model will allow researchers to build upon a common set of constructs and can increase understanding of why people use social media, along with its benefits and consequences. <br\/><br\/>A validated theoretical framework relating higher-order social media goals to subjective well-being in the context of basic needs and motivations has the potential to advance foundational research in multiple domains of inquiry. Consumer psychologists and marketing academics can use the framework to examine the relationship between social media goals and consumer response to marketing efforts in interactive media environments. Social psychologists and personality researchers can further refine and extend the framework to include other important constructs likely to impact social media goal pursuit and well-being. Computer information systems researchers can use the model to further understand how social media systems are impacted by individual differences. Although there has been a great deal of descriptive research examining the different usage behaviors people engage in when they use social media, most studies tend to focus narrowly on reasons or motivations for using a particular type of social media, rather than on organizing the results in the context of a broader conceptual framework that can explain what drives use and how usage goals are related to key well-being outcomes. Understanding the drivers of social media use and its consequences for well-being will have important national policy and consumer welfare implications.","title":"HCC: Small: Motivations, Expectations and Goal Pursuit in Social Media","awardID":"1361502","effectiveDate":"2013-07-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[564455],"PO":[564456]},"204706":{"abstract":"The widespread deployment of parallel machines --- from multicores to supercomputers --- has made it critical to develop simple approaches to programming them. Significant progress has been made in simplifying parallel programming by developing programming models to support parallelism without concurrency, that is, without the nondeterminacies in the logic of programs caused by the relative and nondeterministic timing of communicating processes. Yet most parallel programs in practice are concurrent, and hence, nondeterministic, leading to code that can only be programmed and understood by experts. This research project aims to understand how parallel computers can be made easier to use by the vast majority of programmers by developing software technology that enables deterministic parallel computing.<br\/><br\/>The project takes a holistic view of the problem from the key perspectives of programming linguistics, software systems, algorithmic analysis, and absolute performance. It acknowledges the reality that parallel programming cannot be fully deterministic at every level of abstraction. It is pursuing three key strategies for dealing with concurrency: encapsulating concurrency so that it is hidden by layered abstractions at appropriate abstraction levels, avoiding concurrency by restructuring programs to employ deterministic approaches, and managing concurrency when it is impractical to either encapsulate or avoid concurrency completely. Among the specific techniques being studied are commutative building blocks, deterministic nonassociative reducers, deterministic pipelined parallelism, deterministic interfaces, and generalized race detection for detecting invariant races. The project is developing open-source libraries, tools, and runtime extensions integrated into a multicore-software platform, as well as a problem-based benchmark suite to compare approaches.","title":"SHF: AF: Large: Collaborative Research: Parallelism without Concurrency","awardID":"1314590","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[548200],"PO":["564588"]},"198778":{"abstract":"Big Data has become ubiquitous in modern industrial and scientific applications where the size and dimensionality of data are becoming so large as to require new statistical tools for efficient data analysis. This collaborative project involving researchers at Rutgers University and Microsoft Research focuses on the theoretical and algorithmic development of advanced computational methods for big data analytics. While the problems to be investigated are motivated by various Internet applications, the resulting solutions are expected to be broadly applicable to other domains. <br\/><br\/>The project considers three interrelated main themes in big data analytics: (a) effective sampling of big datasets to filter out unreliable data source and improve statistical analysis; (b) dimensionality reduction techniques that can best preserve information via hashing and sparse random projection techniques; and (c) large scale optimization techniques for machine learning that can directly handle large datasize. Anticipated results of this work include new theoretical results, new data analytics algorithms, and their open source software implementations.<br\/><br\/>Broader impacts of the research include broadly disseminated open source implementations of scalable data analytics algorithms, research-based training and education of graduate and undergraduate students, and academic-industrial collaborations resulting in an interplay between fundamental research in machine learning and industrial applications.","title":"BIGDATA: Small: DA: Statistical Machine Learning Methods for Scalable Data Analysis","awardID":"1250985","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":["360575"],"PO":["565136"]},"198800":{"abstract":"This research seeks to develop novel machine learning algorithms that enable real-time video and sensor data analysis on large data streams given limited computational resources. The work focuses on healthcare as an application domain where real-time video analysis can prevent user-errors in operating medical devices or provide immediate alerts to caregivers about dangerous situations. The research will develop algorithms to automatically adapt data analysis approaches to maximize accuracy of analysis within a short time period despite limited available computing resources. Today's healthcare environment is significantly more technologically sophisticated than ever before. Many medical devices are now frequently used in patient's homes, ranging from simple equipment such as canes and wheelchairs to sophisticated items such as glucose meters, ambulatory infusion pumps and laptop-sized ventilators. The rapidly growing home health industry raises new safety concerns about devices being used inappropriately in the home setting. The proposed research is designed to reduce medical device related use-errors by developing computational algorithms that perform real-time video analysis and alert the patient or caregiver when medical devices are not used appropriately. The real-time video and sensor data analysis is also critical to the healthcare systems that monitor the activities of the elderly or those with disabilities in order to allow a caregiver to react immediately to an incident. <br\/><br\/>New machine learning theories and algorithms will automatically adapt to hardware limitations, with the aim to learn from a large number of training examples, a prediction function that (i) is sufficiently accurate in making effective predictions and (ii) can be run efficiently on a specified computer system to deliver time critical results. Three types of prediction models are studied to address the problem of automatic hardware adaptation, including a vector-based model, a matrix-based model, and a prediction model based on a function from a Reproducing Kernel Hilbert Space (RKHS). A general framework and multiple optimization techniques are being developed to learn accurate prediction models that match limited memory and computational capacity. The new learning algorithms will be evaluated in several medical scenarios through real-time prediction of a patient's activities from observations in the large video archives collected by several healthcare related projects. The intellectual merit of the proposed work is in bridging the gap between the high complexity of a prediction model and limited computational resources, a scenario that is encountered in many application domains besides healthcare. The proposed research in machine learning algorithms and theories will make it possible to run complicated prediction algorithms on big data within the limitation of a given computing infrastructure. The developed techniques for automatic hardware adaptation will be applied to a large dataset of continuous video and sensor recordings for medically-critical activity recognition. The project's broader impacts include providing medical experts with algorithms and tools supporting novel approaches to analyzing observational data in their quest to recognize and characterize human behavior. Surveillance systems with continuous observations will be able to categorize salient events with co-located, limited hardware. Researchers with complex data from continuous streams will be able to explore their domains with greater accuracy within constrained time using their available computing resources. Similarly, large archives can be exploited as rapidly as possible with limited hardware.","title":"BIGDATA: Small: DA: Collaborative Research: Real Time Observation Analysis for Healthcare Applications via Automatic Adaptation to Hardware Limitations","awardID":"1251187","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[533348],"PO":["565136"]},"210517":{"abstract":"Considerable research in the field has been focused on developing new technologies to enhance privacy; encryption of personal data is often presented as a potential solution. Many of the technologies resulting from this research are not being effectively utilized because of issues rooted in human judgment under risk and uncertainty. The majority of existing models and products related to human judgement are based on a limited number of documented incidents and on questionable assumptions about user intent and behavior. To better develop and apply privacy technologies requires better methods of understanding and measuring human perceptions of privacy.<br\/><br\/>In this project we are investigating the underlying neurobiological manifestations of privacy, and seeing to understand -- and measure -- variations of uncertainty in online privacy decisions. The outcomes of this proposed project will contribute to answering fundamental questions about human behavior in online environments?e.g., under what circumstances do systems in the mind cooperate or compete in privacy decisions? When there is competition, how and where is it adjudicated? Do higher-level deliberative processes rely similarly on multiple mechanisms, or a single, unitary set of mechanisms? We anticipate these results being used to further refine and develop useful privacy policies and technologies.","title":"EAGER: Neurobiological Basis of Decision Making in Online Environments","awardID":"1358651","effectiveDate":"2013-07-16","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[564095],"PO":["565327"]},"209070":{"abstract":"This grant supports student travel for select students participating in the Doctoral Consortium at the International Joint Conference on Artificial Intelligence (IJCAI 2013), that will be held in Beijing, China, August 3-9, 2013. The biannual IJCAI conference is the premier international conference spanning all topics in AI across a fully international research community. <br\/><br\/>This consortium is oriented on research and career development for students who have identified their PhD topics and are just embarking on that independent research. This consortium is covering topics that are important and relevant to the success of these students, including, \"funding and strings attached to them, use of subjects in research (including IRB), data collection, maintaining privacy and integrity of data, authorship (single and multi-author submissions, ghost writing), plagiarism and self-plagiarism, proper use of citations, reviewing of papers and proposals, and how to get the best out of attending a conference.\"<br\/><br\/>Student participation in this conference has direct impact through encouraging promising U.S. students to engage in internationally-competitive research. This program will also enhance the broader scientific community through exposure to emerging research topics. IJCAI is the major international conference that will figure prominently in the research careers of these young investigators. Students gain valuable research insights from the exchange of technical ideas in this broader venue. In the process, they make valuable connections with potential collaborators from around the world. In addition, students participate in the main IJCAI conference activities. This allows them to attend presentations of the leading research in AI, as well as avail themselves of the available tutorials, workshops, and demonstrations.","title":"Doctoral Mentoring Consortium at at the 23rd International Joint Conference on Artificial Intelligence (IJCAI 2013)","awardID":"1343599","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["561562"],"PO":["565035"]},"209151":{"abstract":"This project will support two interdisciplinary training workshops designed to bring together graduate students and scholars in the field of Science and Technology Studies (STS), with the goal of framing an agenda for the emerging study of cyber-mediated science. The first workshop will take place in Summer 2013 at Harvard University, with a focus on the role of design methods (such as codesign and data visualization) in digital science. The second workshop will take place in Fall 2013 at the California Institute for Telecommunications and Information Technology, on the campus of the University of California-San Diego, where it will be co-located with the annual meeting of the Society for Social Studies of Science (4S).<br\/><br\/>As science becomes increasingly computational and increasingly dependent on cyberinfrastructure, much can be gained by extending STS inquiry beyond the traditional STS focus on bench science and civil engineering, to encompass virtual science and CI-engineering. The proposed workshops will address this intellectual gap, both by sparking a conversation among digital STS researchers about topics, methods and directions for the field, and also by making that conversation accessible to graduate students and other emerging scholars. In particular, the digitalSTS workshops will introduce STS scholars to design methods that can enhance studies of digital materiality and hybrid sociotechnical systems. As a means of engaging with cyber-mediated scientific research materials and communities of practice, the use of visualizations, models, maps, and data documentaries is well suited to the current technological moment. The long-term goal of this workshop is the development of a Digital Science and Technology Studies Handbook, which will offer a methodological and substantive guide on the present and future of the field.","title":"digitalSTS Workshops","awardID":"1344142","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[560633,560634],"PO":["565342"]},"209074":{"abstract":"This grant supports participation of approximately 12-15 graduate students from US institutions in the first instance of the Conference on Online Social Networks (COSN) of the Association for Computing Machinery, to be held in Boston, Massachusetts, on October 7-8, 2013. Participation in conferences such as COSN is an extremely important part of the graduate school experience, provides students with an opportunity to interact with more senior researchers and exposes them to leading edge research in the field. Attendance at the inaugural COSN event is especially important as it will be the first unified meeting of core members of the research community, the result of merger of six different workshops held over the last few years that were co-located with a diverse set of conferences.<br\/><br\/>This project integrates research and education of students through exposure to a premier technical meeting in online social networks. Students will have the opportunity to observe high-quality presentations and interact with senior researchers in the field. The proposed student participation is expected to have a positive impact on the students' research interests. The project will promote diversity by encouraging and enabling women and other under-represented minorities to participate. Furthermore, the truly international flavor of COSN as an annual conference is reflected in the composition of the Technical Program Committee as well as the expected set of authors of papers. As such, it cultivates international research interactions and presents a tremendous opportunity to students.","title":"Student Travel Support for the COSN 2013 Conference","awardID":"1343637","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[560388],"PO":["564456"]},"208592":{"abstract":"This grant supports travel for students to attend the Empirical Software Engineering International Week, which will take place in Baltimore in October 2013. The week includes a number of co-located conferences that are the main meetings for the international community doing empirical research in the field of Software Engineering. More information can be found at http:\/\/umbc.edu\/eseiw2013\/. Empirical Software Engineering has the potential to be an increasingly productive and transformative part of the Software Engineering research landscape, because the quantity of usable\/analyzable data has increased dramatically just over the last few years. Repositories and community development sites are become more common and larger. Tools for mining and analyzing Software Engineering data are appearing and accelerating the pace of research. NSF's support of student travel will increase intellectual advances in the field and create broader impacts including improvements in software engineering and global experiences for the future workforce.","title":"Travel Grant Proposal to Support Student Participation in IDoESE, IASESE, and ESEM 2013 in Baltimore","awardID":"1340881","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[559100],"PO":["564388"]},"208285":{"abstract":"This funding supports student involvement and attendance at the 2013 ACM SIGGRAPH Conference. SIGGRAPH is the premier computer graphics conference in the world, attracting over 15,000 attendees and filling over 100,000 feet of exhibition space. Although many attendees come for the exhibition and advanced technology demonstrations, the SIGGRAPH Conference has long been the premier place to publish technical papers in computer graphics. The papers are published as a special issue of the ACM Transactions on Graphics. The SIGGRAPH Pioneers (20+ years of work in the field) started a mentoring program in 2003 to add more students to the technology pipeline. While small in number, the impact has been high as the students do not merely attend the conference, but rather are mentored by longstanding members of the community. Because each Pioneer is assigned no more than two students, the Pioneer guides the students to talks, courses, etc. that were not immediately on the students radar. The Pioneer mentors perform this service without compensation.<br\/><br\/>The intellectual merit and broader impact of the proposed activity lies in the educational opportunities provided the student by the mentoring process. The program also focuses on underrepresented groups (e.g., women, Hispanics, and African-American) who would have no opportunity to hear about SIGGRAPH, let alone attend, without the mentoring program. The students are exposed to the latest research and hardware covering the use of computer graphics for numerous topics that benefit society ranging from engineering design to simulation and entertainment. Written student feedback has, in the past, been extremely favorable.","title":"SIGGRAPH Pioneers Mentoring","awardID":"1338982","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[558165,558166],"PO":["565227"]},"209275":{"abstract":"The proposed grant will promote the design, development and analysis of mobile computing and wireless networking technologies, systems, and applications by encouraging student participation in the ACM Mobicom 2012 conference. Besides technical paper presentations, MobiCom, through this grant, will be able to stimulate several intellectual activities by students including potentially killer apps (through the mobile app competition) and breakthrough research (through the student research competition, and the S3 workshop). Furthermore, the conference offers several opportunities for intellectually stimulating discussions between<br\/>the students and researchers from around the world.<br\/><br\/>The participation of students in MobiCom can have an important impact on their development as a junior researcher. The grant will also promote diversity by encouraging and enabling women and other underrepresented minorities to participate.","title":"MobiCom 2013 Students Travel Grant","awardID":"1344977","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[561046],"PO":["565303"]},"209221":{"abstract":"This project develops a partnership among four successful and mature Centers of Academic Excellence in Information Assurance Research (CAE-R) and the National Security Agency (NSA), the Department of Homeland Security and other federal agencies in order to design, develop and test the research network. The project is a self-organizing, cooperative, multi-disciplinary, multi-institutional, and multi-level collaborative research that can include both unclassified and classified research problems in cybersecurity.<br\/><br\/>The project provides an opportunity for students to work on problems proposed and mentored by practitioners in the real world rather than just faculty led research. More pressing and urgent problems are addressed and the students also benefit from the guidance of multiple and interdisciplinary research faculty from multiple institutions. The student lead research may provide solutions for pressing national problems.<br\/><br\/>This pilot is designed to break down the competitive barriers and lack of community that currently exists within CAE-R institutions. By jointly addressing a shared problem space, the participating institutions establish a stronger and more trusting relationship. Mississippi State brings a high concentration of minority students but also provides the lessons learned from the NSF-funded project aiming to increase the number of female participants in cybersecurity.","title":"INSuRE EAGER","awardID":"1344369","effectiveDate":"2013-07-15","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":[560875,560876,560877,560878,560879],"PO":["564264"]},"209276":{"abstract":"Green building applications need efficient and fine-grained determination of power consumption pattern of a wide variety of consumer-grade appliances through non-intrusive load monitoring (NILM) techniques for an effective adaptation and percolation of demand response model down to the consumer level appliances. A key inhibitor to the widespread adoption of such demand response policy at the consumer grade appliances for intelligent building energy management, is the inability of smart plug to efficiently determine, control or infer the power consumption pattern of multiple devices in tandem. In practice, deploying smart plug based NILM and acquiring the low-level power measures of a large number of devices is often difficult or impossible due to the deployment complexity and varying characteristics of devices and thus must instead be employed at the circuit-level and inferred through the incorporation of novel usage-based measurement and probabilistic level-based disaggregation algorithm. But the challenges in deploying non-intrusive load monitoring algorithm involve disaggregating individual device?s consumption from the aggregate power measurement, as well as modeling and incorporating the usage based prediction. Thus in this project we will focus on advanced machine learning and data analytics algorithms that capture the measurement based approach and circuit level NILM with the autonomous profiling and prediction logic to enable the deployment of flexible and fungible smart plug and the evolvability of future DR model in green building applications.","title":"CSR: EAGER: Design and Implementation of a Fine-Grained Appliance Energy Profiling System for Green Building","awardID":"1344990","effectiveDate":"2013-07-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[561048],"PO":["565255"]},"205592":{"abstract":"Software developers are increasingly using dynamic scripting languages not only for quickly prototyping or as \"glue\"code, but also to write large applications. Programmers like scripting languages because they have the flexibility of simply using a variable when needed, without having to declare it. This results in fewer lines of code and allows for faster code development. Unfortunately the same features that make dynamic scripting languages more productive, make them hard to generate efficient code for.<br\/><br\/>This project is working on a hardware-software solution to enable programs written using dynamic scripting languages to run as fast as statically typed languages, such as C, C++ or Java. To that end, this project is working on the design of new program transformations that can generate highly efficient code by taking advantage of innovative hardware support that detects if the assumptions done when generating the code are correct. Additionally, novel hardware provides to the compiler information that enables even more aggressive optimizations. Hardware and software designs are driven by the results obtained from a study that analyzes the main sources of overhead of scripting languages. The research in this project will result in higher programmer productivity and will enable the use of scripting languages in domains where they are not used today.","title":"CSR: Small: Scripting at the Speed of C","awardID":"1319657","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550505,550506],"PO":["565319"]},"205340":{"abstract":"Many key problems in signal processing and wireless communications can be formulated as extremal optimization problems, whose solutions require a careful integration of results located at the interface of different fields such as information theory, signal processing, statistics, and optimization. This project addresses extremal optimization problems located at the interface between information theory and signal processing. This project focuses on two major research problems: extension of De Bruijn's identity and development of extremal information theoretic inequalities. Successful completion of this project helps to advance the state-of-the-art results in the optimization of communications networks performance and security of communication channels (evaluating the secrecy capacity of wiretap channels, designing of energy efficient secure transmissions), design of robust communications systems (designing min-max optimal training sequences for channel estimation and synchronization), and robust signal estimation and detection algorithms (for smart grid, radar, sonar, and wireless communications applications). <br\/><br\/>This project consists of two closely intertwined research thrusts: developing new extensions and applications of De Bruijn's identity, and development of novel extremal information theoretic inequalities with applications in the design of wireless communications systems with improved performance. At a broader scale, this project will impact positively the economy and society through the development of more efficient technologies for communication networks, power grids, wireless sensing and monitoring devices, biomedical devices, and radar and sonar systems. This project will be also integrated with the educational mission of investigator's university and will be largely disseminated to the community through journal papers, conference and workshop presentations, and editing of journal special issues.","title":"CIF:Small: Aspects of the Interplay Between Information Theory and Signal Processing: Extremal Problems and Applications","awardID":"1318338","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[549853],"PO":["564898"]},"208871":{"abstract":"Recent advances in mobile technologies (e.g., smart phones, sensors) have created opportunities for applications that were not previously possible in data gathering (activity monitoring, physiological, and psychological states assessment) and intervention (just in time and context aware alerts and reminders). As such mobile technologies are poised to transform various facets of our lives especially social and health-related aspects. Taking a full advantage of the mobile and mobile health (mHealth) technologies will require considerable multidisciplinary research at the intersection of behavioral, social sciences and clinical research fields with computer science, networking and engineering. The mHealth Summer Institute addresses the multidisciplinary challenges by bringing together scientists from diverse fields to enhance the quality of mHealth research.<br\/>Intellectual Merit: <br\/>The mHealth Summer Training Institute is the premier venue for cross-fertilization of research in the mHealth area. By providing a structured environment for researchers from multiple disciplines to collaboratively work on a mobile health issues of common interest, the training institute provides a platform for idea generation and development that can directly lead to transformative innovations, it provides invaluable experience of working in multidisciplinary teams towards a common goal. It facilitates research, development and specially innovation in mobile health and career development of young scientists in a transdisciplinary environment with rapidly changing landscape.<br\/>Broader Impacts:<br\/>The institute has several long-term impacts on the society. First, the ideas generated during the institute, are frequently developed fully into promising grant proposals, several of which (from prior year institutes) have been funded. These ideas generated at the institute can lead to scientific advancement and impact the society by improving health. Second, the participants who are selected for the institute directly benefit by developing skills and experience of working in multidisciplinary teams and acquire the basic knowledge and skills of the mobile health domain via lectures from thought leaders in mobile health across all the relevant disciplines. Third, the teams formed at the institute frequently lead to long-term collaborative relationships, which continue and flourish in the long-term. It helps seed new connections among young scientists who would not otherwise work together. Fourth, the participants often become champions of mobile health at their respective home institutions and in their respective scientific communities, and educate\/train others, including the students.","title":"2013 mHealth Training institute @UCLA","awardID":"1342693","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[559871],"PO":["564768"]},"209553":{"abstract":"This is funding to support participation by about 6 graduate students from U.S. institutions, along with 5-6 senior members of the ICMI community (faculty and industry researchers, who will receive partial support only), in a Doctoral Consortium (workshop) to be held in conjunction with and immediately preceding the 15th International Conference on Multimodal Interaction (ICMI 2013), which will take place December 9-13, 2013, in Sydney, Australia, and which is organized by the Association for Computing Machinery (ACM). The ICMI conference series is the premier international forum for multidisciplinary research on multimodal human-human and human-computer interaction, interfaces, and system development. The conference focuses on theoretical and empirical foundations, component technologies, and combined multimodal processing techniques that define the field of multimodal interaction analysis, interface design, and system development. Topics of special interest to the conference this year include multimodal interaction processing, interactive systems and applications, modeling human communication patterns, and data, evaluation and standards for multimodal interactive systems. ICMI 2013 will feature a single-track main conference which includes: keynote speakers, technical full and short papers (including oral and poster presentations), special sessions, demonstrations, exhibits and doctoral spotlight papers. The ICMI 2013 proceedings will be published by ACM The ICMI proceedings will be published by ACM Press and included in the ACM Digital Library. As a further incentive for high-quality student participation ICMI will be awarding outstanding paper awards, with a special category for student papers. More information about the conference may be found online at http:\/\/www.acm.org\/icmi\/2013. <br\/><br\/>The goal of the ICMI Doctoral Consortium is to provide PhD students with an opportunity to present their work to a group of mentors and peers from a diverse set of academic and industrial institutions, to receive feedback on their doctoral research plan and progress, and to build a cohort of young researchers interested in designing multimodal interfaces. Student participants will present their ongoing thesis research as a short talk at the Consortium and also as a poster at the conference Doctoral Spotlight Session. This year, the organizers seek to expand the scope of the Doctoral Consortium to provide more opportunities for interaction between the students and senior members of the field; to this end, the program will also include a lunch on the day of the workshop for students and mentors, a career panel that will provide the students and mentors the opportunity to ask and answer questions and discuss challenges and opportunities in the field, and a dinner that will provide the students with the opportunity to hold informal conversations among themselves as well as with the organizers and mentors. <br\/><br\/>Broader Impacts: The Doctoral Consortium will give student participants exposure to their new research community, both by presenting their own work and by observing and interacting with established professionals in the field. It will encourage students at this critical time in their careers to begin building a social support network of peers and mentors. The organizers will take steps proactively to achieve a diversity of research topics, disciplinary backgrounds, methodological approaches, and home institutions among the students. Priority will be given first to minority students, female students, students from geographically underrepresented states, and finally to students whose advisors or departments have insufficient funds to support their participation in the conference. To further increase diversity no more than two students will be invited from any given U.S. institution of higher learning.","title":"WORKSHOP: Doctoral Consortium for the International Conference on Multimodal Interaction (ICMI 2013)","awardID":"1346655","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["563326"],"PO":["565227"]},"199081":{"abstract":"Computational intractability is the absence of provably efficient algorithms to solve a problem. Consider the traveling salesperson problem (TSP): visit a set of cities in an order that will minimize the distance traveled. If one considers only efficient algorithms to solve this problem, then, pessimistically, one can only guarantee a solution that is at most 40% longer than the shortest tour. One should ask whether their instance is really that bad, as often it is not. In fact, many industrial instances of TSP are geographical and are well represented by Euclidean or planar-graph distances. For these instances there are efficient algorithms that will find a tour that is very close to optimal. In practice, heuristics do very well in solving even large instances.<br\/><br\/>The research under this award will address two limitations of the start-of-the-art: neither the input domain is as perfect as a planar graph, nor the problem definition is as clean as TSP. The PI will design efficient and accurate algorithms for a broader class of low-dimensional domains and problem constraints. This will greatly advance the theoretical understanding of these low-dimensional metrics. The PI will work with practitioners in energy and transportation systems in order to ensure the practicality of her algorithms and promote the design of practical heuristics inspired by these algorithms. <br\/><br\/>The PI will involve the education and training of high school, undergraduate and graduate students. With high-school students, the PI will develop video lectures on basic algorithmic-design and graph-theoretic concepts suitable to the general public. Undergraduate students will be exposed to graph-theoretic aspects of this research through summer research experiences. The effort will also design course materials for active-learning problem-solving sessions in advanced algorithms classes and develop lecture notes for a graduate course on domain-specific algorithm design.","title":"CAREER: Understanding and advancing network design in planar domains","awardID":"1252833","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[534066],"PO":["565157"]},"205286":{"abstract":"Many beneficial applications of computers cannot now be realized because they demand excessively high performance and\/or low power. An example of interest is real-time image processing to restore sight to the visually impaired. This project explores an unconventional and little-understood technology called stochastic computing (SC) which is very well-suited to such applications. Stochastic Computing processes numbers in the form of bit-streams that resemble neural signals and are interpreted as probabilities. It can implement complex arithmetic operations by small logic circuits. However, high accuracy may require long bit-streams that can be difficult to interface with conventional binary logic. The project aims to develop a comprehensive theory of SC leading to practical methods for designing and applying stochastic circuits. It will study the foundations of SC, especially speed, accuracy and hardware-cost trade-offs, using various novel methods. Stochastic Computing will be applied to a broad set of image-processing tasks, ranging from retinal implants for the blind, to on-the-fly feature extraction. Prototype designs will be constructed and evaluated using software simulation and hardware emulation via field-programmable gate arrays. <br\/><br\/>The project's goal is a full theoretical and practical understanding of stochastic computing in the context of emerging integrated circuit technologies and applications. Its results should interest research engineers and scientists in academe, as well as in the microelectronics, computer, and bioengineering industries. They should also be of direct practical value to designers and manufacturers in such application areas as image-processing chips, implantable medical devices, and video surveillance systems. The project's outputs will be distributed primarily via peer-reviewed journal and conference papers. A key goal is to support the training of graduate students in computer science and engineering, who will participate directly in the research as part of their M.S. and Ph.D. programs at the University of Michigan. A few undergraduates will also be invited to join the project as interns to encourage them to pursue research-related careers. A special effort will be made to involve women and minority students.","title":"SHF: Small: Stochastic Computing Techniques for Real-Time Image-Processing Applications","awardID":"1318091","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[549712],"PO":["562984"]},"209543":{"abstract":"Dynamic spectrum access (DSA) based on cognitive radio (CR) allows unused licensed bands to be used by unlicensed (secondary) networks in an opportunistic\/dynamic manner under the provision that they would vacate upon the return of the licensed users. DSA allows unlicensed users to share frequencies, but the paradigm does not provide good protection from interference. This raises serious challenge of self-coexistence among the secondary networks as well as risks of disruption from malicious CR devices\/networks through various non-traditional spectrum attacks. This project studies the self-coexistence challenges of CR networks under adversarial conditions and investigates inter-disciplinary methodologies based on game theory, behavioral adaptation, stochastic learning and network forensics that aid survivability of these networks. To assess effectiveness, the mechanisms are implemented on CR prototype testbed. The intellectual merit of this project lies in: 1) constructing behavioral frameworks studying the evolutionary dynamics of spectrum conflict, 2) systematically understanding the unique shadow-disruptive nature of the malicious CRs exploiting the finest granularity of spectrum agility, and 3) developing a suite of survival mechanisms against cognitive disruptions and exploring their effectiveness. The project has broader impact on wireless technologies\/policies and is expected to help in the efficient and secure design of future cognitive radios. This project is committed to tightly integrate research and educational plans which revolve around student mentoring, graduate\/undergraduate curriculum enhancement and hands-on project based learning taking feedback from research findings and K-12 outreach. Research results will be disseminated through publications, seminars, and tutorials.","title":"CAREER: Survivability and Selfcoexistence in the Battle of Cognitive Radio Network Societies","awardID":"1346600","effectiveDate":"2013-07-01","expirationDate":"2017-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[561710],"PO":["557315"]},"208696":{"abstract":"The purpose of this proposal is to fund travel for undergraduate students to participate in the Experiencing HPC for Undergraduates program at the SC13, SC14 and SC15 conferences. The primary goal of this program is to lead the students into research as an undergraduate and then encourage them to attend graduate school in HPC topics in Computer and Computational Science. The program makes use of several existing parts of the SC technical program, with additional activities specific to the program. The unique content for the participants in this program will include an HPC boot camp session, talks by well known researchers in the field, a panel featuring current graduate students, and a panel on academic and industry career opportunities in the HPC field.<br\/><br\/>The key idea of this program is that the best way to get people excited about HPC is to visit and participate in a major technical conference in the field. SC is an ideal venue for such a program since it combines elements of a high quality technical meeting (papers, posters, tutorials) with a major industry trade show (commercial and research exhibits, vendor briefings, birds of a feather sessions). By providing sophomore and junior undergraduates an opportunity to see what the field is about, it is believed that we can excite them about the field in time for them to apply to graduate school or decide on which industry to enter when they complete their bachelor?s degrees.<br\/><br\/>The goal of this program is to expand the High Performance Computing workforce by encouraging talented undergraduates to consider graduate studies and careers in the field of HPC. The program will make a special effort to recruit participants from under represented groups and minority serving institutions. HPC is critical to many national goals from scientific innovation to product development. Currently there is a shortage of new students entering the field. This program is designed to try to help meet those national needs.","title":"SC Conference Experiencing HPC for Undergraduates Program","awardID":"1341349","effectiveDate":"2013-07-15","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7781","name":"PETASCALE - TRACK 1"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}}],"PIcoPI":["245234",559445],"PO":["565247"]},"209279":{"abstract":"The Principal Investigator (PI) will explore and test a number of hardware platforms and software algorithms whose goal is to facilitate sub-second human-robot synchronization. To this end the PI will utilize the medium of music, one of the most time-demanding media where accuracy in milliseconds is critical because asynchronous operations of more than 10 ms are noticeable by listeners. Specifically, the PI will develop up to three different kinds of robotic devices intended to allow a drummer, whose arm was recently amputated from the elbow down, to play and synchronize between his organic functioning arm and the newly developed robotic devices. In addition, he will develop and investigate the efficiency of novel anticipation algorithms designed to foresee human actions before they take place and trigger robotic actions with low-latency and in a timely manner. This research will advance our understanding in a variety of areas, including the biomechanics of limb operations, machine-learning techniques for the anticipation and prediction of human gestures, and highly accurate myoelectric robotic devices.<br\/><br\/>Broader Impacts: This project will ultimately benefit a large population of amputees whose quality of life could improve through the use of low-latency robotic limbs with sub-second synchronization. Facilitating such accurate sub-second human-robot synchronization could also improve efficiency and flow in other human-robot interaction scenarios where humans and robots must collaborate to achieve time-demanding common goals. The novel solenoid-based robotic device(s) created in this research should also benefit musicians in general (that is to say, who are not disabled), who will be able to explore novel drumming techniques and create novel musical results.","title":"EAGER: Sub-second human-robot synchronization","awardID":"1345006","effectiveDate":"2013-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[561054],"PO":["565227"]},"209048":{"abstract":"This grant supports student participation in a doctoral mentoring consortium at the International Conference on Automated Planning and Scheduling (ICAPS). The ICAPS Doctoral Consortium (DC) is a primary method for broadening participation and improving retention of doctoral researchers in the field of automated planning and scheduling. This DC at ICAPS 2013, June 2013 in Rome, Italy, is the eleventh occurrence of the event.<br\/>This symposium is carrying on a multiyear tradition of holding DCs and summer schools, providing an important venue to encourage students and junior researchers in automated planning and scheduling. Activities include research panel discussions, lunch with mentors, and poster session held as part of the main conference. The DC brings together a broader community of researchers in planning and scheduling, promoting integration with other areas of AI and computer science, and encouraging junior researchers with a more focused attention to this area than is otherwise possible in other venues. Of particular note is the potential to involve participants who might not have attended an AI conference before. This is especially true for those outside of the usual AI research community: those at smaller institutions who use AI in teaching but not in research; those from smaller\/liberal arts institutions; and those from institutions that are poorly represented in STEM disciplines.","title":"Doctoral Consortium Support for ICAPS 2013","awardID":"1343507","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[560319],"PO":["565035"]},"202174":{"abstract":"Over the past two decades, advances in multi-antenna wireless systems have opened up the possibility of tremendous increases in wireless communication throughputs. The practical realization of these increases in real-world wireless networks is constrained by size and cost considerations that limit the number of antennas, especially for mobile devices. This research aims to achieve the gains from multi-antenna techniques in a distributed fashion by having groups of wireless transceivers pool together and cooperatively act like a virtual antenna array. The concept of virtual arrays has broad transformative potential for wireless networks by extending the numerous benefits of multi-antenna systems to networks of single-antenna devices. We will prototype and demonstrate virtual array techniques experimentally on a software-defined radio platform, and we plan to share our implementations as reusable building blocks to stimulate technology transition and to promote interactions between the academic, open-source software community and radio hobbyist communities. The elements of a virtual array have an unknown, typically time-varying, geometry and are driven by independent oscillators, each with stochastic drift; the main technical challenge is in maintaining distributed coherence in the array in the presence of these effects. While this is a very challenging problem, recent results have demonstrated the feasibility of virtual arrays.<br\/><br\/>This research will establish a solid theoretical foundation for distributed coherence and chart a clear path to technology transfer by applying the theory and techniques to the cross-layer design of concept systems based on virtual antenna arrays. Specifically we will develop a state space framework for tracking and prediction of oscillator dynamics and mobility, and scalable architectures for distributed transmission and reception appropriate for large distributed arrays of low-cost single-antenna devices. We will also identify fundamental tradeoffs and scaling laws for virtual arrays. We will apply and integrate the theory and techniques to two concept systems of great societal significance: Distributed base station provides multi-antenna capabilities even for low carrier frequencies where standard antenna arrays would be too bulky (e.g., white space frequencies). Distributed 911, enables a cluster of nodes to communicate with a possibly moving distant rescue vehicle which would be out of range for any one of the nodes. Our goal is to perform design and performance evaluation in sufficient detail to clear conceptual hurdles for implementation.","title":"Distributed coherence: fundamental building blocks, system concepts, and experimental demonstration","awardID":"1302104","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["550414"],"PO":["564924"]},"202196":{"abstract":"The goal of the research is to enable software engineers to find software development best practices from past empirical data. The increasing availability of software development project data, plus new machine learning techniques, make it possible for researchers to study the generalizability of results across projects using the concept of transfer learning. Using data from real software projects, the project will determine and validate best practices in three areas: predicting software development effort; isolating software detects; effective code inspection practices. <br\/><br\/>This research will deliver new data mining technologies in the form of transfer learning techniques and tools that overcome current limitations in the state-of-the-art to provide accurate learning within and across projects. It will design new empirical studies, which apply transfer learning to empirical data collected from industrial software projects. It will build an on-line model analysis service, making the techniques and tools available to other researchers who are investigating validity of principles for best practice. <br\/><br\/>The broader impacts of the research will be to make empirical software engineering research results more transferable to practice, and to improve the research processes for the empirical software engineering community. By providing a means to test principles about software development, this work stands to transform empirical software engineering research and enable software managers to rely on scientifically obtained facts and conclusions rather than anecdotal evidence and one-off studies. Given the immense importance and cost of software in commercial and critical systems, the research has long-term economic impacts.","title":"SHF: Medium: Collaborative: Transfer Learning in Software Engineering","awardID":"1302216","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[541880],"PO":["564388"]},"205485":{"abstract":"Blockciphers are the basic building block of shared-key cryptography. However, for certain important cryptographic goals, like building encryption schemes, the interface presented by blockciphers is limiting. A more modern primitive, the tweakable blockcipher (TBC), is often a better fit. Like a blockcipher, a TBC takes as input a secret key, a block of data and the tweak which is an additional input which provides variability to the TBC's input-output behavior without having to change the secret key. TBC-based cryptography has the potential to deliver efficient constructions with better security than analogous blockcipher-based designs, as well natural support for associated data inputs, key reuse, and other practical considerations.<br\/><br\/>Despite its clear promise, TBC-based cryptography has not received a sustained and coherent examination. This project provides such an examination, in an effort to better understand the potential of TBCs to impact future cryptographic practice. It explores the construction of TBCs, both from scratch and leveraging off-the-shelf primitives. It reconsiders existing blockcipher-based constructions starting from the question, \"what happens if we replace the blockcipher with a TBC?\", and leading to new designs with increased security, and greater resilience to certain implementation and usage mistakes. It also considers foundational matters concerning definitions of security for TBCs, and connections to idealized models of ciphers.","title":"TWC: Small: Theory and Practice of Tweakable-Blockcipher-Based Cryptography","awardID":"1319061","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550236],"PO":["565264"]},"205023":{"abstract":"Adaptive self-healing is an emerging methodology to combat the deleterious effects of nanoscale process variations, to maintain the aggressive scaling of analog and mixed-signal (AMS) circuits. Nowadays, each tunable AMS circuit becomes a large-scale, complex system that can adaptively vary over time. The prohibitively high cost associated with pre-silicon validation and post-silicon tuning of such a complex system is a growing problem as devices continue to shrink and the relative magnitude of critical process fluctuations continues to grow. Hence, there is an immediate need to develop new statistical methodologies that minimize the validation and tuning cost of nanoscale AMS circuits for future technology generations. This project develops a novel statistical framework, referred to as Bayesian Model Fusion (BMF), that aims to minimize the simulation and\/or measurement cost for both pre-silicon validation and post-silicon tuning of self-healing AMS circuits. The proposed BMF technique is motivated by the fact that today's AMS design cycle typically spans multiple stages (e.g., schematic design, layout design, first tape-out, second tape-out, etc). The key idea is to reuse the simulation and\/or measurement data collected at an early stage to facilitate efficient validation and tuning of AMS circuits with a minimal amount of data required at the late stage. It provides a fundamental infrastructure that enables next-generation AMS design for future IC technology.<br\/><br\/><br\/>The proposed project offers a radically new AMS design methodology based on Bayesian inference. It is expected to yield significant performance improvement for advanced electrical circuits in a broad range of applications, from consumer electronics to medical instruments. Hence, successful development of the proposed BMF framework will have both short-term and long-term impacts on the semiconductor industry. In addition, the education activities integrated with this project offer a number of unique training opportunities to both university students and industrial engineers. It will substantially improve the education infrastructure and generate high-quality researchers and practitioners in the field.","title":"SHF: Small: Bayesian Model Fusion: A Statistical Framework for Efficient Validation and Tuning of Complex Analog and Mixed Signal Circuits","awardID":"1316363","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["531467"],"PO":["562984"]},"205287":{"abstract":"Algorithms for lossy\/lossless compression and error-correcting codes have been at the core of the digital revolution. This project focuses on the particular set of applications in which both lossy compression and noise resilience are required. Examples include storage of high resolution imagery on non-perfect semiconductor (flash) memory and real-time video surveillance over jammed or noisy channels.<br\/><br\/>The state-of-the art solution is \"separation\": serial concatenation of an off-the-shelf compression algorithm with an off-the-shelf error-correcting code. However, as shown recently by the investigators, for worst-case guarantees the separated solution is far from being (even asymptotically) optimal. This provides the principal motivation for a multifaceted investigation of the combinatorial, geometric, algebraic and information theoretic aspects of the joint source-channel coding problem.<br\/><br\/>The breadth of mathematics will be appealing to young researchers with a wide variety of backgrounds, and will help attract new talent to the field. Creation of sophisticated source-channel codes with dependable guarantees is expected to have technological impact in military, space exploration, natural science, and consumer applications.","title":"CIF: Small: Collaborative Research: Combinatorial Joint Source-Channel Coding","awardID":"1318093","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[549714],"PO":["564924"]},"209555":{"abstract":"This project is for a workshop on \"Scaling Terabit Networks: Breaking Through Capacity Barriers and Lowering Cost with New Architectures and Technologies,\" to be held at the Optical Society of America (OSA) headquarters in Washington, DC, on September 19-20, 2013. The goal of the workshop is to develop a set of \"grand challenges\" for the optical networking community. This will be accomplished by: exploring how new network architectures driven by changing traffic patterns, virtualization and programmability drive new requirements for the optics, and how emerging photonic components can help scale these architectures to terabit capacities; rethinking the operating system interface and application interface to the network; exploring what physical layer phenomena and characteristics need to be communicated to the higher layers and what higher-layer functions can benefit from physical layer intelligence; and understanding how optics and electronics will be used together in the future and what their respective metrics will be when used together in an optical networking context.<br\/><br\/>In addressing these technical areas, the workshop will be organized to achieve the following objectives: identify the technological challenges facing terabit networks and continued network scaling; establish key metrics, targets, and capabilities for efficient and scalable terabit networking; set research priorities and requirements within optical networking to enable efficient and scalable terabit networking; and identify application drivers and early adopters of this new technology.<br\/><br\/>Ultra-high capacity optical networks are the key enabler of the ongoing revolution in data-driven science. They are also part of critical infrastructure technologies that the United States needs to maintain national competitiveness and national security. By informing both the U.S. research community as well as NSF and other Federal agencies about key research problems and opportunities, this workshop will support U.S. national interests. The final workshop report will be made publicly available.","title":"Scaling Terabit Networks: Breaking Through Capacity Barriers and Lowering Cost with New Architectures and Technologies","awardID":"1346666","effectiveDate":"2013-07-01","expirationDate":"2014-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[561739],"PO":["564993"]},"202240":{"abstract":"Over the past two decades, advances in multi-antenna wireless systems have opened up the possibility of tremendous increases in wireless communication throughputs. The practical realization of these increases in real-world wireless networks is constrained by size and cost considerations that limit the number of antennas, especially for mobile devices. This research aims to achieve the gains from multi-antenna techniques in a distributed fashion by having groups of wireless transceivers pool together and cooperatively act like a virtual antenna array. The concept of virtual arrays has broad transformative potential for wireless networks by extending the numerous benefits of multi-antenna systems to networks of single-antenna devices. We will prototype and demonstrate virtual array techniques experimentally on a software-defined radio platform, and we plan to share our implementations as reusable building blocks to stimulate technology transition and to promote interactions between the academic, open-source software community and radio hobbyist communities. The elements of a virtual array have an unknown, typically time-varying, geometry and are driven by independent oscillators, each with stochastic drift; the main technical challenge is in maintaining distributed coherence in the array in the presence of these effects. While this is a very challenging problem, recent results have demonstrated the feasibility of virtual arrays.<br\/><br\/>This research will establish a solid theoretical foundation for distributed coherence and chart a clear path to technology transfer by applying the theory and techniques to the cross-layer design of concept systems based on virtual antenna arrays. Specifically we will develop a state space framework for tracking and prediction of oscillator dynamics and mobility, and scalable architectures for distributed transmission and reception appropriate for large distributed arrays of low-cost single-antenna devices. We will also identify fundamental tradeoffs and scaling laws for virtual arrays. We will apply and integrate the theory and techniques to two concept systems of great societal significance: Distributed base station provides multi-antenna capabilities even for low carrier frequencies where standard antenna arrays would be too bulky (e.g., white space frequencies). Distributed 911, enables a cluster of nodes to communicate with a possibly moving distant rescue vehicle which would be out of range for any one of the nodes. Our goal is to perform design and performance evaluation in sufficient detail to clear conceptual hurdles for implementation.","title":"CIF: Medium: Collaborative Research: Distributed coherence: fundamental building blocks, system concepts, and experimental demonstration","awardID":"1302456","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[541994,541995],"PO":["564924"]},"202263":{"abstract":"In modern server architectures, the processor socket and the memory system<br\/>are implemented as separate modules. Data exchange between these modules<br\/>is expensive -- it is slow, it consumes a large amount of energy, and there<br\/>are long wait times for narrow data links. Emerging big-data workloads will<br\/>require especially large amounts of data movement between the processor<br\/>and memory. To reduce the cost of data movement for big-data workloads,<br\/>the project attempts to design new server architectures that can leverage<br\/>3D stacking technology. The proposed approach, referred to as Near Data<br\/>Computing (NDC), reduces the distance between a subset of computational<br\/>units and a subset of memory, and can yield high efficiency for workloads<br\/>that exhibit locality. The project will also develop new big-data <br\/>algorithms and runtime systems that can exploit the properties of the<br\/>new architectures.<br\/><br\/>The project will lead to technologies that can boost performance and<br\/>reduce the energy demands of big-data workloads. Several reports have<br\/>cited the importance of these workloads to national, industrial, and<br\/>scientific computing infrastructures. The project outcomes will be<br\/>integrated into University of Utah curricula and will play a significant<br\/>role in a new degree program on datacenter design and operation. The<br\/>PIs will broaden their impact by publicly distributing parts of their<br\/>software infrastructure and by engaging in outreach programs that<br\/>involve minorities and K-12 students.","title":"CSR: Medium: Energy-Efficient Architectures for Emerging Big-Data Workloads","awardID":"1302663","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[542053,542054,"556789","548382"],"PO":["565319"]},"208951":{"abstract":"The Association for Computational Linguistics (ACL) is the primary international organization in the field of natural language processing and computational linguistics. The NAACL HLT conference is the ACL's major conference held annually in North America. This project subsidizes travel, conference registration, and housing expenses of students selected to participate in the NAACL HLT Student Research Workshop, which takes place during the main conference held on June 10-12 in Atlanta and in a one-day workshop on June 13th. The workshop accepts papers in two categories: thesis proposals and general research papers. The thesis\/research proposal can have only one author who must be a student. The research papers can have multiple authors, with the first author being a student. The workshop is organized and run by students.<br\/><br\/>The Student Research Workshop provides a valuable opportunity for the next generation of natural language processing researchers to enter the research community. It allows the students in the field to take an important step toward becoming professional computational linguists by receiving critical feedback on their work from experts outside of their dissertation committee, and by making contacts with other students and senior researchers in their field. The students who are involved in running and reviewing for the workshop also gain valuable opportunities for professional growth and interaction with the researchers on the organizing committee of the main conference. The NAACL HLT Student Research Workshop contributes to the maintenance and development of a skilled and diverse computational linguistics and natural language processing community.","title":"NAACL-HLT 2013 Student Research Workshop","awardID":"1343068","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[560064],"PO":["565215"]},"202186":{"abstract":"The goal of the research is to enable software engineers to find software development best practices from past empirical data. The increasing availability of software development project data, plus new machine learning techniques, make it possible for researchers to study the generalizability of results across projects using the concept of transfer learning. Using data from real software projects, the project will determine and validate best practices in three areas: predicting software development effort; isolating software detects; effective code inspection practices. <br\/><br\/>This research will deliver new data mining technologies in the form of transfer learning techniques and tools that overcome current limitations in the state-of-the-art to provide accurate learning within and across projects. It will design new empirical studies, which apply transfer learning to empirical data collected from industrial software projects. It will build an on-line model analysis service, making the techniques and tools available to other researchers who are investigating validity of principles for best practice. <br\/><br\/>The broader impacts of the research will be to make empirical software engineering research results more transferable to practice, and to improve the research processes for the empirical software engineering community. By providing a means to test principles about software development, this work stands to transform empirical software engineering research and enable software managers to rely on scientifically obtained facts and conclusions rather than anecdotal evidence and one-off studies. Given the immense importance and cost of software in commercial and critical systems, the research has long-term economic impacts.","title":"SHF: MEDIUM: Collaborative Research: Transfer Learning in Software Engineering","awardID":"1302169","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[541853,541854],"PO":["564388"]},"206003":{"abstract":"In the foreseen future a mix of changes in technologies, user and application requirements and the business model of delivering computing capacity will continue to pose new challenges to the effectiveness of high throughput computing (HTC) technologies. To address these challenges, this ongoing research and development effort will devise new policy-driven capabilities to increase throughput within a defined budget by effectively managing extremely large workloads of homogenous jobs running on homogenous machines provisioned by cloud services. These capabilities will be augmented with effective schedulers for servers that have multiple cores of execution, many disks, perhaps several GPUs each with different capabilities, and multiple networking interfaces. New communities will be introduced to the power of HTC through customized, easy to deploy and secure software. Novel tools for profiling the requirements and dependencies of scientific applications will expand the reach of distributed computing infrastructures that leverage advanced networks to cross institutional and national boundaries. <br\/><br\/>The advances in HTC technologies will be delivered through the widely adopted HTCondor software tools. More than 150 domestic universities, a growing number of national and international science communities and a wide spectrum of commercial organizations employ HTCondor to improve the throughput of their compute and data intensive applications. This project will sustain a software engineering process that enables translational work to occur in a transitional manner, building upon the previous generation of software while simultaneously continuing to offer and support dependable software that is suitable to handle the ever growing amounts of experimental and simulated scientific data.","title":"Accomplisment Based Renewal (ABR) to the award Flight-Worthy Condor: Enabling Scientific Discovery","awardID":"1321762","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8027","name":"Cyber Secur - Cyberinfrastruc"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7553","name":"PHYSICS AT THE INFO FRONTIER"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7369","name":"INTERNATIONAL RES NET CONNECT"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":["560467",551528],"PO":["564246"]},"202176":{"abstract":"Over the past two decades, advances in multi-antenna wireless systems have opened up the possibility of tremendous increases in wireless communication throughputs. The practical realization of these increases in real-world wireless networks is constrained by size and cost considerations that limit the number of antennas, especially for mobile devices. This research aims to achieve the gains from multi-antenna techniques in a distributed fashion by having groups of wireless transceivers pool together and cooperatively act like a virtual antenna array. The concept of virtual arrays has broad transformative potential for wireless networks by extending the numerous benefits of multi-antenna systems to networks of single-antenna devices. We will prototype and demonstrate virtual array techniques experimentally on a software-defined radio platform, and we plan to share our implementations as reusable building blocks to stimulate technology transition and to promote interactions between the academic, open-source software community and radio hobbyist communities. The elements of a virtual array have an unknown, typically time-varying, geometry and are driven by independent oscillators, each with stochastic drift; the main technical challenge is in maintaining distributed coherence in the array in the presence of these effects. While this is a very challenging problem, recent results have demonstrated the feasibility of virtual arrays.<br\/><br\/>This research will establish a solid theoretical foundation for distributed coherence and chart a clear path to technology transfer by applying the theory and techniques to the cross-layer design of concept systems based on virtual antenna arrays. Specifically we will develop a state space framework for tracking and prediction of oscillator dynamics and mobility, and scalable architectures for distributed transmission and reception appropriate for large distributed arrays of low-cost single-antenna devices. We will also identify fundamental tradeoffs and scaling laws for virtual arrays. We will apply and integrate the theory and techniques to two concept systems of great societal significance: Distributed base station provides multi-antenna capabilities even for low carrier frequencies where standard antenna arrays would be too bulky (e.g., white space frequencies). Distributed 911, enables a cluster of nodes to communicate with a possibly moving distant rescue vehicle which would be out of range for any one of the nodes. Our goal is to perform design and performance evaluation in sufficient detail to clear conceptual hurdles for implementation.","title":"CIF: Medium: Collaborative Research: Distributed coherence: fundamental building blocks, system concepts, and experimental demonstration","awardID":"1302114","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["549356"],"PO":["564924"]},"202187":{"abstract":"Organizing and using 3D data related to physical sites is important in many applications such as historical reconstruction, architectural design, and urban planning. However, no method has been developed that exploits the full range of data types available for such sites. Useful data often comes from historical sources, and requires substantial processing to be useful. Some of this processing can be automated, but some of it must be done by humans. An as-yet unsolved problem is how to coordinate human effort to efficiently carry out this process. In the current project the PIs will address quantitative and qualitative accuracy issues in reconstructing 3D sites so as to allow for input and participation by different populations in building data sets, and will demonstrate a variety of applications using a heterogeneous 3D site representation. Specifically, the work will make the following contributions: new techniques for annotating heterogeneous input will be developed, balancing automated and human input; new techniques for coordinating digital computation, human computation, and machine learning will be devised; new tools for architectural analysis and design, and for material weathering analysis, will be developed based on the new 3D representation; and new ideas for storytelling from 3D data will be demonstrated. Project outcomes will include a new organization of heterogeneous data for 3D sites, new insights into the relative contributions of automated techniques and human computation in the domain of 3D site data (which will be applicable to other challenging problems involving large complex data sets), new algorithms for reconstructing 3D models, and new techniques for conducting studies in architecture and in cultural heritage.<br\/><br\/>Broader Impacts: This research will have a strong impact on architectural-design and cultural heritage documentation, interpretation and communication. The various phases of the project will involve students at both the graduate and undergraduate levels, and in diverse disciplines including computer science, architecture, and art history. The PIs will produce teaching modules based on this work targeted at computer science, architecture, and cultural heritage.","title":"CGV: Medium: Collaborative Research: A Heterogeneous Inference Framework for 3D Modeling and Rendering of Sites","awardID":"1302172","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[541856,541857],"PO":["565227"]},"205344":{"abstract":"Magnetic resonance imaging (MRI) is an important medical imaging modality widely used clinically to visualize soft-tissue structure and function in the human body. However, acquiring diagnostic quality MR images is a relatively slow process, and shortening MRI scan times is an important goal for reducing motion artifacts, improving clinical efficiency and patient comfort, and reducing cost. The long duration of MRI also forces a tradeoff between image spatial, temporal, and contrast resolution, and there are many potential applications where clinical requirements cannot be met by current protocols. Sparsity-driven reconstruction techniques are being increasingly employed to try and address these needs. However, MRI data commonly has auxiliary non-spatial dimensions (e.g., time, receiver channel), and sparse methods only efficiently exploit intra-dimensional redundancies. Calibration or training procedures are consequently used to identify and incorporate inter-dimensional redundancies into the reconstruction model. This comes at the expense of prolonged scan duration, error propagation, and limited experimental freedom. <br\/><br\/>This project focuses on the development of a robust, efficient, flexible, and totally calibration- and training-free framework for higher-dimensional MR image reconstruction. It is hypothesized that totally training-free MRI can be achieved by structuring image reconstruction as a low-rank matrix or tensor estimation problem that: 1) actively exploits inter-dimensional redundancies; 2) works complementarily with existing sparsity-based strategies; and 3) naturally generalizes for advanced imaging scenarios like non-Cartesian imaging. The first stage of the research focuses on building the mathematical foundation for this framework. The second stage focuses on practical realization, through development of efficient optimization strategies, high-performance code implementations, and automated parameter selection methodologies. These developments may lead to improved diagnoses, faster scanning, cost reduction, and the enablement of novel clinical MRI applications.","title":"CIF:Small:Low-rank matrix and tensor methods for higher-dimensional MR image reconstruction","awardID":"1318347","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[549864,549865],"PO":["564898"]},"205597":{"abstract":"The goal of the VeriQ project is to develop techniques for the formal<br\/>verification of quantitative properties of software. Every program<br\/>requires a certain amount of resources such as memory, power, and<br\/>processor cycles to perform its task. A proof that the resources<br\/>provided by the hardware of the system are sufficient to safely<br\/>execute a program should be the first step in the verification of that<br\/>program. In addition to the verification of such resource-usage<br\/>bounds, there are a vast number of domain-specific quantitative<br\/>properties that are crucial for the correctness of software. Finally,<br\/>reasoning about quantities can simplify the verification of<br\/>non-quantitative properties such as termination. By advancing the<br\/>state-of-the art in quantitative verification, VeriQ facilitates the<br\/>development of reliable, efficient and predictable software systems.<br\/><br\/>The investigators focus on three technical goals that are among the<br\/>most important problems in the field of quantitative verification.<br\/>First, they develop an automatic and compositional resource analysis<br\/>for programs that are written in high-level languages with garbage<br\/>collection, side effects, and higher-order functions. Second, they<br\/>apply the techniques from resource analysis for high-level languages<br\/>to simplify the reasoning about quantitative properties of realistic<br\/>system code with concurrent execution and advanced control flow.<br\/>Third, they investigate the relationship between quantitative<br\/>properties and liveness properties with the goal of utilizing<br\/>quantitative reasoning techniques in correctness proofs of software<br\/>verification.","title":"SHF: Small: VeriQ: Formal Quantitative Software Verification in Realistic Application Scenarios","awardID":"1319671","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[550516,550517],"PO":["565264"]},"205399":{"abstract":"Algorithms for lossy\/lossless compression and error-correcting codes have been at the core of the digital revolution. This project focuses on the particular set of applications in which both lossy compression and noise resilience are required. Examples include storage of high resolution imagery on non-perfect semiconductor (flash) memory and real-time video surveillance over jammed or noisy channels.<br\/><br\/>The state-of-the art solution is \"separation\": serial concatenation of an off-the-shelf compression algorithm with an off-the-shelf error-correcting code. However, as shown recently by the investigators, for worst-case guarantees the separated solution is far from being (even asymptotically) optimal. This provides the principal motivation for a multifaceted investigation of the combinatorial, geometric, algebraic and information theoretic aspects of the joint source-channel coding problem.<br\/><br\/>The breadth of mathematics will be appealing to young researchers with a wide variety of backgrounds, and will help attract new talent to the field. Creation of sophisticated source-channel codes with dependable guarantees is expected to have technological impact in military, space exploration, natural science, and consumer applications.","title":"CIF: Small: Collaborative Research: Combinatorial Joint Source-Channel Coding","awardID":"1318620","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[550006],"PO":["564924"]},"208578":{"abstract":"A living system is distinguished from most of its non-living counterparts by the way it stores and transmits information. It is just this biological information that is the key to the biological functions. It is also at the heart of the conceptual basis of what we call systems biology. Much of the conceptual structure of systems biology can be built around the fundamental ideas concerning the storage transmission and use of biological information. Biological information resides, of course, in digital sequences in molecules like DNA and RNA, but also in 3-dimensional structures, chemical modifications, chemical activities, both of small molecules and enzymes, and in other components and properties of biological systems at many levels. The information depends critically on how each unit interacts with, and is related to, other components of the system. Biological information is therefore inherently context-dependent, which raises significant issues concerning its quantitative measure and representation. An important and immediate issue for the effective theoretical treatment of biological systems then is: how can context-dependent information be usefully represented and measured? This is important both to the understanding of the storage and flow of information that occurs in the functioning of biological systems and in evolution. This work involves both new ideas and the integration of new ideas. It represents new mathematical methods as well as a novel integration of approaches that are focused on the very real and practical problems of biological data analysis. The PI as developed a new conceptual approach that is novel and mathematically well-defined, exploring the relationships between graph properties and set complexity and considering new approaches to network analysis. New interaction distance measures are considered with a new way of dealing with especially large data sets, especially the maximal information coefficient, for which a general approach may be possible, certainly for a small number of variables, and possibly in the general case. The ideas will be tested on a number of diverse biological data sets, especially around gene expressions, and other variants. Current methods often fail in the face of truly complex dependencies in large data sets, and powerful new methods would be of high value. This work involves both new ideas and the integration of new ideas. It represents new mathematical methods as well as a novel integration of approaches that are focused on the very real and practical problems of biological data analysis.","title":"EAGER: Information and complexity in the analysis of biological data sets and networks","awardID":"1340619","effectiveDate":"2013-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[559061],"PO":["565136"]},"204772":{"abstract":"This project will develop foundational principles for hierarchical wireless network design by leveraging full-duplex transmissions in both access and wireless backhaul. Full-duplex is most promising at shorter ranges, and hence is fortuitously aligned with the predicted dominant access range in future networks. Furthermore, larger full-duplex ranges are feasible in infrastructure-to-infrastructure links, and hence are well suited for backhaul links. While full-duplex is well-aligned with the key elements of hierarchical networks, our current design principles are largely developed for half-duplex transmissions which is the basis for all current networks. With that in mind, this project will address both theory and protocols for hierarchical full-duplex networks by looking at: (1) data-driven signal models for self-interference caused by the node's own transmission to its own receiver, (2) theoretical foundations for scheduling and routing that leverage both self-interference and multi-hop interference cancellation; and (3) protocols and prototypes for network scale full-duplex resource management. <br\/><br\/>Full-duplex breaks one of the basic design constraints in current wireless networks, all of which are either half-duplex in time or frequency; it will therefore rewrite wireless networking fundamentals. Further, with emphasis on realizable networks using extensive Rice University's programmable testbeds, the project will impact the next-generation of wireless networks via its corporate partners. Finally, the project team will establish a unique inter-university education and research program, which will include joint advising and collaborative advising and leverage the team's complementary expertise.","title":"NeTS: Large: Collaborative Research: Foundations of Hierarchical Full-Duplex Wireless Networks","awardID":"1314937","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551137"],"PO":["565303"]},"202254":{"abstract":"This project deals with theory and efficient algorithms for statistical decision problems that are radically different from those that have been studied to date in two key aspects: First, the decision-maker may choose among a large class of observation channels (features) of varying complexity and quality; and second, the total cost of computational resources that can be used prior to arriving at a decision is limited. Computer vision is a paradigmatic source of such feature-rich decision problems, requiring the use of multiple heterogeneous feature types, integration of diverse sources of contextual information, and possibly even human interaction. <br\/><br\/>This project entails the development of a rigorous mathematical framework for feature-rich decision problems in accordance with three specific aims: (1) structural characterization of features as stochastic belief-refining filters; (2) universal cost-sensitive criteria for numerical comparison of features in terms of expected information gains; and (3) optimal value-of-information criteria for sequential feature selection that take into account both feature extraction costs and terminal decision losses. As corollaries, this research investigates connections to asymptotic information-theoretic characterizations of optimal feature selection rules and decisions. The fourth specific aim of the project is the development of practical algorithms for two challenging computer vision problems: active visual search and fine-grained categorization. This component of the project leverages theoretical aims (1) and (2) to develop practical cost- and loss-sensitive feature compression techniques. Theoretical aim (3) targets algorithms that function as autonomous decision-making agents. Faced with an inference task on an image, they apply cost-sensitive non-myopic value- of-information criteria to decide at each time step whether to extract a new feature from the image or to stop and declare an answer.","title":"CIF: Medium: Collaborative Research: Nonasymptotic Analysis of Feature-Rich Decision Problems with Applications to Computer Vision","awardID":"1302588","effectiveDate":"2013-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["553607"],"PO":["564898"]},"205653":{"abstract":"A wide variety of important applications rely upon our ability to quickly and accurately understand the physical world using a meager supply of event-based data. Such data arise when indirect observations of a physical phenomenon are collected by measuring discrete events (such as photons hitting a detector, sequence motifs appearing in a genome, packets traveling through an Internet router, neurons firing, or people interacting in a social network). The challenge here is to use extremely small numbers of random events to perform inference on the underlying high-dimensional phenomenon (e.g., the distribution of tissue in the body or the distribution of traffic in a network). In this case, conventional models of sensing and noise do not apply, and robust inference requires the development of both novel theoretical analyses and new computational methods.<br\/><br\/>Point processes model random processes in which a realization consists of a collection of isolated events distributed across space or time. This research program is aimed at the development of new theory and methods for exploiting low-dimensional or sparse models of high-dimensional signal structure using scarce point process realizations. The theoretical results facilitate characterization of fundamental performance limits, such as bounds on the error of physically realizable models of inverse problems in photon-limited imaging and the performance gap between online and batch processing of streaming data. Furthermore, the methods themselves are practical and resource-efficient in a broad range of contexts, and being used by astronomers, microscopists, social scientists, and geneticists.<br\/>Underlying these methods are techniques at the intersection of statistical signal processing, learning theory, sparse coding, nonlinear approximation theory, optical engineering, and optimization theory.","title":"CIF: Small: Sparsity and Scarcity in High-Dimensional Point Processes","awardID":"1319927","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[550641],"PO":["564898"]},"204696":{"abstract":"This project studies Internet censorship using novel measurement techniques, ranging from low-level packet filtering on Internet Protocol (IP) networks to high-level censorship of social media content. Collectively these techniques can provide greater situational awareness of censorship dynamics. <br\/><br\/>The project focuses on a suite of advanced inference techniques for when ?direct observation? is unavailable or impractical such as, for example, methods for detecting IP tunnels based on per-hop Maximum Transmission Unit (MTU) inference techniques in order to reason about the physical characteristics of a given IP network and, for example, measurement on social media postings of redactions and the speed of redactions. <br\/><br\/>This research has broad implications on studies of methods to provide awareness of restrictive control of information and content on networks, which would be of interest to software developers, system administrators, and policy makers alike.","title":"TWC: Medium: Collaborative: Measurement and Analysis Techniques for Internet Freedom on IP and Social Networks","awardID":"1314492","effectiveDate":"2013-07-15","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548177],"PO":["565239"]},"205334":{"abstract":"The microprocessor industry has transitioned to chip-multiprocessor designs, where additional on-chip resources provided by continued process scaling are dedicated to providing more and more processor cores per die. Since power for a single die is capped, each core is allotted a shrinking fraction of the overall power budget, making it difficult or impossible to design a core that provides the performance improvements that end users expect. At the same time, ever smaller devices are more vulnerable to transient errors caused by cosmic rays. For these reasons, there is an urgent industry demand for novel microarchitectural approaches that deliver high levels of single-thread performance (execution latency) and increased resilience to soft errors (reliability), while dramatically reducing power consumption. Without dramatic innovations in the design of power-efficient, high-performance multicore building blocks, the continued device scaling of future nanometer technologies may no longer provide substantial returns in utility or performance. As a result, the microprocessor industry, and by extension, the computer industry as a whole, face a serious challenge in maintaining the growth-based business model that has sustained them for four decades. This research has broad industry- and economy-wide impact since it helps to address or avert these challenges. <br\/><br\/>The Reliable In-Place Execution (RIPE) project investigates microarchitectural approaches based on the concept of in-place execution of instructions. In contrast to conventional designs where instructions traverse deep processing pipelines at high frequency, RIPE assigns an instruction to a fixed execution station where it is evaluated in place. This approach dramatically improves power efficiency by minimizing device activity and avoiding pipelining, complex control logic, multiported storage structures, and other power-hungry components of traditional out-of-order processor cores. RIPE also inherently reduces vulnerability to single-event upsets (SEUs), while forming an attractive substrate for low-cost detection of and recovery from single-event transients (SETs). RIPE is also uniquely suited for streamlining instruction fetch, since the in-place instructions can be reactivated for multiple loop iterations or to resolve conditional control flow, avoiding the power and performance costs of fetching instructions from the memory hierarchy, and eliminating performance penalties due to mispredicted branches. RIPE cores can also be clustered and interconnected to provide very high levels of performance in a scalable and power-efficient manner. The proposed research, if successful, will lead to processor core designs that meet the seemingly contradictory objectives of modest area, low power consumption, high instruction-level parallelism (ILP), competitive frequency, and reliable operation even in inherently unreliable future technologies.","title":"SHF: Small: Reliable In-place Execution for Multicore Processors","awardID":"1318298","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[549841],"PO":["366560"]},"208744":{"abstract":"This is funding to support a Doctoral Colloquium (workshop) of about 18 dissertation stage doctoral students, in a variety of visualization subfields, for a day of discussions and interactions with 6 distinguished research faculty, to be held in conjunction with this year's IEEE VIS meeting (formerly known as IEEE VisWeek), which will take place during the week of October 13-18, 2013, in Atlanta, Georgia. Visualization, or the use of interactive graphics to support data analysis and understanding, has become an integral part and critical component of many application areas. IEEE VIS is the premier forum for visualization advances in science and engineering for academia, government, and industry, now bringing together about 900 researchers and practitioners from around the world with a shared interest in techniques, tools, and technology. VIS consists this year of the 24th annual IEEE Scientific Visualization Conference (SciVis), the 19th annual IEEE Information Visualization Conference (InfoVis), and the 8th annual IEEE Visual Analytics Science and Technology Symposium (VAST). Co-located symposia this year include the IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), the IEEE Symposium on Biological Data Visualization (BioVis), and the International Symposium on Visualization for Cyber Security (VisSec). The papers published in the special conference issue of IEEE Transactions of Visualization and Computer Graphics are rigorously refereed and widely cited. More information is available online at http:\/\/www.ieeevis.org. <br\/><br\/>The Doctoral Colloquium at IEEE VIS is a research-focused meeting which has taken place annually at the visualization conferences since 2006, and has helped launch the careers of a number of outstanding young researchers. In 2013 the workshop will convene on Saturday, October 12, with follow-up events during the VIS technical program. A primary goal of the Doctoral Colloquium is to allow students to discuss their research directions in a supportive atmosphere with a panel of distinguished leaders and with their peers, who will provide helpful feedback and fresh perspectives. To this end each student will be assigned a specific mentor among the expert panelists and will be allotted approximately 30-40 minutes of time during the group sessions, to include a formal presentation about the student's doctoral research followed by in-depth discussions and feedback. The workshop will support community building by connecting beginning and advanced researchers (during events such as a common lunch for all DC participants, students and panelists alike, and a roundtable discussion at the end of the day where the focus will be on high-level topics beyond technical research), one of the objectives being to build a cohort group of new researchers who will then have a network of colleagues across the world. Student research will be disseminated via posters during the VIS technical program, and via publication in the VIS Extended Abstracts. Feedback about the Doctoral Colloquium will be provided to future conference committees. <br\/><br\/>Broader Impacts: The VIS Doctoral Colloquium brings together the best of the next generation of visualization researchers and allows them to create a social network both among themselves and with senior researchers, which plays a major role in their enculturation into the profession. Since the students and faculty are a diverse group on several dimensions (nationality, scientific discipline, research specialization), the students' horizons are broadened at a critical stage in their professional development. The PI has affirmed that in managing this event the organizers, while striving to identify and include the broadest possible group of highly qualified participants, will also make an effort to encourage participation by women, racial\/ethnic minorities, and persons with disabilities. They will furthermore ensure that NSF funds are used chiefly to support participation by students enrolled in graduate programs in the United States.","title":"WORKSHOP: Doctoral Colloquium at IEEE VIS 2013","awardID":"1341912","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["292127",559567,559568],"PO":["565227"]},"209624":{"abstract":"The speech and spoken dialog communities watched with interest as the world discovered Apple's SIRI. One of the first applications of an advanced spoken dialog system to a real world problem, it captured the imagination of potential users; the idea of speaking to an object to obtain information or direct an action has entered into the public mind, and the possibilities seem endless. Yet despite the potential advantages, academia has so far created few spoken dialog systems that serve real users and real applications. In the first three years of being open to the research community, the Let's Go system developed by the PI and her team was used for over 150 publications, including 18 theses outside of its host institution. The speech and spoken dialog communities clearly need more real world systems that furnish data, free architectures and research platforms. The PI's goal in this project is to foster such new real world systems, which will give the speech and spoken dialog communities steady streams of data as well as research platforms that they can use to run studies. The project will engage seasoned researchers (who know what will work and what will not), along with high school and undergraduate students (whose younger minds are free to imagine what speech applications can become, uninfluenced by research results or funding concerns), in an effort to find the next great speech applications. <br\/><br\/>Broader Impacts: The REAL Challenge will be the spark that ignites the creation of novel real speech applications. The project will address a broad range of students and invigorate research in a way that can be used in other areas of natural language research. It will inspire a new generation of researchers and provide a unique opportunity for young students to work with seasoned researchers. The novel applications that will be found will ultimately be of help to the general public, whether it be for better access to information, for interaction with a robotic helpmate, or perhaps for a new way of communicating with others using social networks.","title":"EAGER: The REAL Challenge","awardID":"1347063","effectiveDate":"2013-07-15","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[561898],"PO":["565227"]},"199240":{"abstract":"As computing devices solve increasingly complex and diverse problems, engineers seek to design processors that provide higher performance, while remaining energy-efficient for environmental reasons. To achieve this, processor vendors have embraced manycore devices, where thousands of cores cooperate on a single chip to solve large-scale problems in a parallel manner. They have further incorporated heterogeneity, combining cores with different architectures on a single chip in a bid to provide ever-increasing performance per watt. This project boosts the search for higher energy-efficient performance by inventing novel cross-core learning techniques. Cores in current chips individually learn about the behavior of parallel programs in order to run programs more efficiently in the future, devoting complex and power-hungry hardware structures to do this. However, this research observes that parallel programs tend to exercise the hardware structures of different cores in correlated ways, meaning that the behavior of the program run on one core can be communicated to other cores for various performance and power benefits. As such, this form of intelligent cross-core information exchange is effective in achieving high performance per watt across computing domains from datacenters to embedded systems<br\/><br\/>In this light, this research provides techniques to deduce how similarly a parallel program's various threads exercise their cores' hardware structures (looking at a range of different programmer, compiler, and architectural mechanisms to do so). When this is detected, cross-core learning hardware gleans the information that is most useful to exchange to improve performance or power, and then transmits this information among heterogeneous cores using low-overhead hardware\/software techniques. This project develops a lightweight runtime software layer to orchestrate this information exchange, relying on dedicated hardware support when necessary. Through developing this framework, cross-core learning is applied to a number of specific cases, ranging from higher-performance manycore cache prefetching and branch prediction, to performance and power-management techniques for interrupts and exceptions in scale-out systems, as well as thread and instruction scheduling. Furthermore, this project heavily disseminates knowledge on how to design and program large-scale manycore systems (or scale-out systems) by involving students at the graduate, undergraduate, and high-school levels through active research and coursework. Overall, this work impacts the engineering community and broader society by: (1) helping to achieve high-performance, but also energy-efficient and environmentally-friendly computing systems; (2) providing academics and chip designers a design methodology and infrastructure to study manycore design; (3) broadening the participation of underrepresented groups in computer science; (4) educating graduate, undergraduate, and high-school students on parallel programming for manycore systems.","title":"CAREER:Cross-Core Learning in Future Manycore Systems","awardID":"1253700","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["556617"],"PO":["366560"]},"202210":{"abstract":"Organizing and using 3D data related to physical sites is important in many applications such as historical reconstruction, architectural design, and urban planning. However, no method has been developed that exploits the full range of data types available for such sites. Useful data often comes from historical sources, and requires substantial processing to be useful. Some of this processing can be automated, but some of it must be done by humans. An as-yet unsolved problem is how to coordinate human effort to efficiently carry out this process. In the current project the PIs will address quantitative and qualitative accuracy issues in reconstructing 3D sites so as to allow for input and participation by different populations in building data sets, and will demonstrate a variety of applications using a heterogeneous 3D site representation. Specifically, the work will make the following contributions: new techniques for annotating heterogeneous input will be developed, balancing automated and human input; new techniques for coordinating digital computation, human computation, and machine learning will be devised; new tools for architectural analysis and design, and for material weathering analysis, will be developed based on the new 3D representation; and new ideas for storytelling from 3D data will be demonstrated. Project outcomes will include a new organization of heterogeneous data for 3D sites, new insights into the relative contributions of automated techniques and human computation in the domain of 3D site data (which will be applicable to other challenging problems involving large complex data sets), new algorithms for reconstructing 3D models, and new techniques for conducting studies in architecture and in cultural heritage.<br\/><br\/>Broader Impacts: This research will have a strong impact on architectural-design and cultural heritage documentation, interpretation and communication. The various phases of the project will involve students at both the graduate and undergraduate levels, and in diverse disciplines including computer science, architecture, and art history. The PIs will produce teaching modules based on this work targeted at computer science, architecture, and cultural heritage.","title":"CGV: Medium: Collaborative Research: A Heterogeneous Inference Framework for 3D Modeling and Rendering of Sites","awardID":"1302267","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[541919,"548698"],"PO":["565227"]},"205566":{"abstract":"Key-value and NoSQL storage systems are growing and predicted to become a multi-billion dollar industry sector within a few years. This project targets global reconfiguration operations in this new generation of storage systems. Today such operations largely involve exporting and then re-importing entire databases, thus making data unavailable for long periods of time. The project will first design efficient online algorithms for a variety of global reconfiguration operations, with the twin goals of making such operations efficient, while continuing to support fast read and write actions on the data at all times. We will then implement and build our solutions into real production code, with a focus on existing and widely-used open-source systems software. This work requires a carefully orchestrated mix of algorithmics with systems design and implementation. Our systems will be evaluated using industry benchmarks and traces, and in production clusters.<br\/><br\/>The project will augment existing widely-used key-value and NoSQL storage systems software with the much-needed ability to support online reconfiguration operations. Our work will produce open software and meaningful datasets. Thus our innovations and systems will be directly available to, and impact positively, both providers of key-value and NoSQL stores as well as a variety of customers ranging from small to large companies. On the educational front, the project will address the dearth today of learning materials for key-value and NoSQL stores by developing and disseminating course materials for this area. Additionally, we will incentivize entrepreneurial activities centered around key-value and NoSQL technologies.","title":"CSR: Small: Online Global Reconfigurations in Key-Value and NoSQL Cloud Storage Systems","awardID":"1319527","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550441],"PO":["565319"]},"208789":{"abstract":"This workshop on \"Airborne Networks and Communications\" in conjunction with the annual American Institute of Aeronautics and Astronautics (AIAA) Infotech@Aerospace Conference will be held in Boston, Massachusetts, on Aug. 21, 2013. The workshop will provide a discussion forum for researchers in disciplines important for airborne networking, including wireless communications, autonomous air vehicles, routing planning, cyber-physical security, and test beds, and important to real-world situations such as in disaster relief during which communications, coordination, and sensing are critical. This project provides travel support for invited speakers and for U.S. graduate students.","title":"Workshop on Airborne Networks and Communications","awardID":"1342130","effectiveDate":"2013-07-01","expirationDate":"2014-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[559670,559671,559672],"PO":["565239"]},"199285":{"abstract":"Machine learning on large-scale patient medical records can lead to the discovery of novel population-wide patterns enabling advances in genetics, disease mechanisms, drug discovery, healthcare policy, and public health. However, concerns over patient privacy prevent biomedical researchers from running their algorithms on large volumes of patient data, creating a barrier to important new discoveries through machine-learning. <br\/><br\/>The goal of this project is to address this barrier by developing privacy-preserving tools to query, cluster, classify and analyze medical databases. In particular, the project aims to ensure differential privacy --- a formal mathematical notion of privacy designed by cryptographers which has gained considerable attention in the systems, algorithms, machine-learning and data-mining communities in recent years. The primary challenge in applying differentially-private machine learning tools to biomedical informatics is the lack of statistical efficiency, or the large number of samples required.<br\/><br\/>The project will overcome this challenge by drawing on insights obtained from the PI's expertise to develop differentially-private and highly statistically-efficient machine learning tools for classification and clustering. The proposed research will advance the state-of-the-art in privacy-preserving data analysis by combining insights from differential privacy, statistics, machine learning, and database algorithms. <br\/><br\/>The proposed research is closely tied to the development of the undergraduate and graduate curricula at UCSD, feeding into the PI's new undergraduate machine learning class, a new graduate learning theory class, and updates to an algorithm design and analysis class. The corresponding materials will be publicly disseminated through the PI's website. The PI is strongly committed to increasing the participation of women and minorities, and will engage in outreach activities to attract and retain women in computer science.","title":"CAREER: Differentially-Private Machine Learning with Applications to Biomedical Informatics","awardID":"1253942","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[534486],"PO":["562760"]},"199186":{"abstract":"Nanomagnetic logic and memory have emerged as powerful alternatives to conventional transistor based circuits because a multiferroic nanomagnet, switched with electrically generated strain (\"straintronics\"), is a far more energy-efficient switch than a transistor. However, nanomagnetic logic is extremely error-prone at room temperature since thermal fluctuations can seriously disrupt magnetization dynamics during switching. In order to make nanomagnetic logic viable, the issue of high error rate must be addressed and a solution found to mitigate its deleterious effects. This project pursues an approach for reducing error rates without calling for impractical on-chip error-correction resources.<br\/><br\/>This research could enable processors to be built with superbly energy-efficient technology that can lead to implantable smart medical devices, button-sized face recognition systems, structural health monitoring systems, and consumer applications such as wearable electronics. A graduate course on nanoscale magnetism with an emphasis on nanomagnetic computing will be created. With the support of the Richmond Area Program for Minorities in Engineering, minority high school students will be hosted in the Principle Investigator's lab every summer. The Principle Investigator will develop innovative hands-on workshops to explain nanomagnetic memory and logic to K-12 students from selected schools that have low representations in Virginia science fairs and will also transfer this knowledge and expertise to teachers from these schools. Science fair participation from such schools will be analyzed to study the impact of this 5-year innovative outreach effort in K-12 teaching.","title":"CAREER: Reliable and Fault Tolerant Super Energy Efficient Nanomagnetic Computing in the Presence of Thermal Noise","awardID":"1253370","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["541221"],"PO":["562984"]},"210241":{"abstract":"The unprecedented amounts of data available to individuals, companies, governments, and scientists promises to revolutionize the way entertainment, business, governance, and science operate. And while data are cheap and plentiful, much of this data is lower quality than the precise data that has been managed for the last 30 years. Building an application that processes this imprecise data is difficult: it requires that developers handle both standard data management challenges (e.g., concurrency and scalability), while at the same time coping with imprecise and incomplete data, which is typically done using statistical or machine learning techniques (e.g., interpolation and classification). The Hazy project addresses this challenge by building a system that integrates the paradigms of relational database management systems with statistical machine learning techniques. This project conducts the following major tasks: (I) designing a language to integrate these techniques with standard SQL, (II) proposing an algebra to implement this language along with support for automatic optimization (similar to a standard RDBMS), and (III) discovering techniques to efficiently maintain the statistical models as the underlying data are changed or updated. The end goal is a system that makes it as easy to develop scalable applications that use imprecise data as it is to develop their precise counterparts. Hazy allows users to process larger amounts of data with more sophisticated statistical processing than ever before. In turn, this enables new applications in a divese set of areas, such as life and physical science sensing applications, health-care and environmental monitoring, and enterprise-based and Web-based information extraction.<br\/><br\/>The research of this project is used to develop the data and infrastructure for new practicum-style courses that are under development at the University of Wisconsin-Madison. In addition, this infrastructure will be used as part of an outreach effort to enable high school students to gain access to data analysis tools. The source code of Hazy is released into open source and the results are disseminated on the project Web site (http:\/\/www.cs.wisc.edu\/hazy\/).","title":"CAREER: A Scalable, Declarative, Imprecise Database Management System","awardID":"1353606","effectiveDate":"2013-07-01","expirationDate":"2016-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563875"],"PO":["563727"]},"205523":{"abstract":"For analog signals of high dimension, compression methods relying on the acquisition and quantization of the entire signal may not always be possible. It is hence of interest to develop methods for compressing information directly from the analog to the analog (A2A) domain. Two philosophies have proven successful in addressing the general problem of conveying analog information through an analog medium: the Shannon theoretic approach and the compressed sensing approach. This research investigates a third approach, which blends the generality of the Shannon theoretic approach with the practicality of the compressed sensing approach. The fundamental limits of A2A compression are investigated in single and multi-signal settings, and constructive schemes are proposed to achieve these limits. <br\/><br\/>The challenge of A2A compression is to achieve the maximal dimensionality reduction, i.e., a bandwidth reduction factor of the signal dimension per measurement, by exploiting prior knowledge about the signal, which may include, but it is not limited to sparsity. Wu-Verd\u00fa have shown that the Renyi Information dimension (RID) is the fundamental limit for i.i.d. signals with known distributions. The RID is a very coarse measure of information, as many different signals lead to the same RID. This research investigates other signal features that influence the A2A compression performance beyond RID, particularly in the non-asymptotic regime. It investigates the A2A compression of signals which do not have an i.i.d. known distribution, and of multi-signal settings, where correlations among signals can be exploited. Finally, it proposes constructive schemes to achieve the fundamental limits using polar codes.","title":"CIF: Small:Analog-to-Analog Compression: Fundamental Limits and Constructive Schemes","awardID":"1319299","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[550339,"550344"],"PO":["564898"]},"208933":{"abstract":"This project includes organization of the 2013 Cyber-Physical Systems (CPS) Principal Investigators (PI) meeting. This will be the latest in a series of annual meetings held for CPS program grantees, at which they are able to present research results and collectively identify future research directions.<br\/><br\/>Cyber-physical systems use computations and communication deeply embedded in, and interacting with, physical processes to add new capabilities to physical systems. These cyber-physical systems range from the very small to the very large, and can increasingly be found in a wide variety of technologies we use in our daily lives.<br\/><br\/>The purpose of this annual CPS PI meeting is to discuss the latest developments in the field and to help develop ideas for future research. The attendees of this workshop will hear general plenary talks by leaders in the field, then participate in breakout sessions to discuss more specialized aspects. The meeting will feature broad, diverse participation comprising the CPS PI community.","title":"Cyber-Physical Systems Principal Investigator Meeting 2013","awardID":"1342957","effectiveDate":"2013-07-15","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[560018],"PO":["565274"]},"204698":{"abstract":"This project will develop foundational principles for hierarchical wireless network design by leveraging full-duplex transmissions in both access and wireless backhaul. Full-duplex is most promising at shorter ranges, and hence is fortuitously aligned with the predicted dominant access range in future networks. Furthermore, larger full-duplex ranges are feasible in infrastructure-to-infrastructure links, and hence are well suited for backhaul links. While full-duplex is well-aligned with the key elements of hierarchical networks, our current design principles are largely developed for half-duplex transmissions which is the basis for all current networks. With that in mind, this project will address both theory and protocols for hierarchical full-duplex networks by looking at: (1) data-driven signal models for self-interference caused by the node's own transmission to its own receiver, (2) theoretical foundations for scheduling and routing that leverage both self-interference and multi-hop interference cancellation; and (3) protocols and prototypes for network scale full-duplex resource management. <br\/><br\/>Full-duplex breaks one of the basic design constraints in current wireless networks, all of which are either half-duplex in time or frequency; it will therefore rewrite wireless networking fundamentals. Further, with emphasis on realizable networks using extensive Rice University's programmable testbeds, the project will impact the next-generation of wireless networks via its corporate partners. Finally, the project team will establish a unique inter-university education and research program, which will include joint advising and collaborative advising and leverage the team's complementary expertise.","title":"NeTS: Large: Collaborative Research: Foundations of Hierarchical Full-Duplex Wireless Networks","awardID":"1314538","effectiveDate":"2013-07-01","expirationDate":"2018-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[548182],"PO":["565303"]},"198791":{"abstract":"Scientific Bigdata sets are becoming too large and complex to fit in RAM, forcing scientific applications to perform a lot of slow disk and network I\/O. This growth also makes scientific data more vulnerable to corruptions due to crashes and human errors. This project will use recent results from algorithms, database, and storage research to improve the performance and reliability of standard scientific data formats. This will make scientific research cheaper, faster, more reliable, and more reproducible.<br\/><br\/>The Hierarchical Data Format (HDF5) standard is a container format for scientific data. It allows scientists to define and store complex data structures inside HDF5 files. Unfortunately, the current standard forces users to store all data objects and their meta-data properties inside one large physical file; this mix hinders meta-data-specific optimizations. The current storage also uses data-structures that scale poorly for large data. Lastly, the current model lacks snapshot support, important for recovery from errors.<br\/><br\/>A new HDF5 release allows users to create more versatile storage plugins to control storage policies on each object and attribute. This project is developing support for snapshots in HDF5, designing new data structures and algorithms to scale HDF5 data access on modern storage devices to Bigdata. The project is designing several new HDF5 drivers: mapping objects to a Linux file system; storing objects in a database; and accessing data objects on remote Web servers. These improvements are evaluated using large-scale visualization applications with Bigdata, stemming from real-world scientific computations.","title":"BIGDATA: Small: DCM: Collaborative Research: An efficient, versatile, scalable, and portable storage system for scientific data containers","awardID":"1251095","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[533326],"PO":["565136"]},"208757":{"abstract":"This grant will fund student participation at the \"Future of Software Engineering\" (FuSE) symposium in Seattle in July 2013. All other costs associated with student attendance will be covered by other sponsors. The goal of the symposium is to bring together top software engineering researchers and students to discuss a broad range of software engineering research topics, to consider future visions for the future of software engineering, and to inspire graduate and undergraduate students to work on the identified challenges. Participants will include senior researchers from both academia and industry, as well as up to one hundred students. The broader impacts are educational and will help build the next generation of researchers in Software Engineering.","title":"Travel Grant for Future of Software Engineering 2013 Symposium","awardID":"1341994","effectiveDate":"2013-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[559597],"PO":["564388"]},"204742":{"abstract":"Side-channel attack (SCA) has shown to be a serious implementation attack to many cryptosystems. Practical countermeasures only mitigate the vulnerability to some extent. Considerable research efforts on leakage-resilient cryptography have so far not led to practical leakage-resilient implementations. One hindering reason is the lack of commonly accepted and sound metrics, standards, and evaluation procedures to measure and evaluate the vulnerability\/resilience of cryptosystems to various side-channel attacks. Accurate modeling of side channels, however, is one of the open problems in applied crypto research. This project aims to close the gap between SCA theories and practices by formalizing a general framework for side-channel attack analysis and security evaluation of cryptosystems. <br\/><br\/>The proposed framework quantifies the effect of algorithmic and implementation characteristics on the success rate of the theoretically strongest maximum likelihood attack, revealing system-inherent SCA-related parameters for security improvement. The framework will extract maximum leakage from the observed measurement data in the black-box scenario, often the realistic situation for adversaries. State-of-the-art statistical methods are employed in the framework to precisely analyze and evaluate the overall side-channel leakage. This holistic framework will significantly alleviate the burden of security system architects, software developers, and hardware designers in their quest to build SCA security into systems they design, so as to ultimately yield provably secure hardware.","title":"TWC: Medium: Collaborative: A Unified Statistics-Based Framework for Side-Channel Attack Analysis and Security Evaluation of Cryptosystems","awardID":"1314770","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550154"],"PO":["565264"]},"205842":{"abstract":"Computer processing power is so integrated into our daily lives that we hardly notice how it enables everything from a routine text message to solving \"large data\" problems that mandate immense supercomputing resources. And yet, the processing power of today's computers pales in comparison to that most advanced processor - the human brain. It is now believed that technological progress would enable us to take up the challenge of developing a new kind of computing architecture that functions more like the brain. In recent years, scientists have examined the electrical interaction between brain synapses and how biological neurons interact. They have also derived mathematical models to explain how these processes work. By employing these models in combination with a new device technology that exhibits similar electrical response to the neural synapses, this project will design entirely new computer processing chips that mimic how the brain processes information.<br\/><br\/><br\/>We envision these chips performing pattern recognition with machine complexity an order of magnitude higher than traditional computing and digital signal processor (DSP) architectures. And even though the chip physical size and weight will match current processors, their power consumption will be orders of magnitude lower than with the von Neumann computing architecture that forms the basis for most of today's computer processors. Therefore, by mimicking the brain's billions of interconnections and pattern recognition capabilities, we may ultimately introduce a new paradigm in speed and power, and potentially enable systems that include the ability to learn, adapt, and respond to their environment.","title":"CIF: Small: Realizing Chip-scale Bio-inspired Spiking Neural Networks with Monolithically Integrated Nano-scale Memristors","awardID":"1320987","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[551082,551083,551084],"PO":["562984"]},"205743":{"abstract":"Computational Science involves computer modeling and simulation of natural phenomena, and the validity of scientific inquiry depends on the way computers are used to do numerical computation. Numeric errors pose a serious threat to output validity for modern scientific data processing. Raw inputs are acquired by physical instruments that have limited precision, leading to input errors. Parameters used in data processing may be provided by human scientists based on their experience, leading to uncertainty. Data may not be represented exactly due to the limited precision of the machine used. Once these errors creep into a computation, they may get propagated and magnified by the sequence of operations conducted, producing unreliable output. Such instability problems may ultimately have substantial impact on scientific research and even the economy. <br\/><br\/>This project aims to develop dynamic program analysis tools to address instability problems caused by errors. These tools will automatically analyze the data processing programs provided by the users and transform them to allow online representation of and reasoning about errors. The user runs the transformed programs on the original input data as usual, with the option of providing additional input\/coefficient error ranges. The execution will produce regular output as before, together with an indication of whether the output is stable in the presence of errors, including input errors, uncertain coefficients, and internal representation errors. If the execution is determined to be unstable, the technique will automatically report the possible consequences induced by the errors. Another option is to automatically switch to executing a high-precision version of the program, which is also generated by the project's tool set.","title":"SHF: Small: Reliable Data Processing by Dynamic Program Analysis","awardID":"1320444","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[550848],"PO":["564388"]},"205864":{"abstract":"This project addresses the study of cooperation in distributed networks, first through the study of simple structures that isolate dedicated resources for global or local cooperation and then directly in general networks. The work is organized into three thrusts. The first thrust employs a global facilitator that has access to all messages in the network and can transmit a rate-R description of these messages to all nodes. Bounding the capacity of such a network as a function of R gives a first-order estimate of the minimal cost and maximal benefit of cooperation in a given network. In the second thrust, we move from global to local models of cooperation to understand how much of the cooperative advantage can be achieved using smaller groups of cooperators. The final thrust studies the implementation and approximation of the most successful cooperation strategies from the earlier thrusts for use in wireless, sensor, and wired networks; here the rate employed to enable cooperation shares the same network resources as the capacity it aims to increase.<br\/><br\/>Example networks demonstrate large potential benefits in communication system performance through the use of strategies that employ cooperation among the communicating devices. Performance improvement is here measured as an increase in the amount of information that can be reliably delivered through a communication network. Increasing rate through cooperation may allow more users to simultaneous communicate or each user to communicate at an increased rate in a given network. This project aims to develop the theoretical foundations of cooperation-based communication strategies and to help guide the design of communication protocols that realize the benefits of cooperation in practice.","title":"CIF: Small: Cooperation in networks: a quantitative study","awardID":"1321129","effectiveDate":"2013-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[551140],"PO":["564924"]}}