{"74816":{"abstract":"EIA 02-20520<br\/>Rao, Nagaraj<br\/>MacIntyre, Richard<br\/>Mercy College <br\/><br\/>Mercy College Minority Institution Infrastructure: Planning <br\/><br\/>This one-year planning award, expanding activities geared to attract and retain minority students, supports the development of a project that will position Mercy College, a minority serving institution, to expand its capabilities in the Division of Mathematics and Computer Science. Faculty members will be hired with experience in human communication technology to incorporate cutting edge technological advancements into teaching and research activities and to develop multidisciplinary, discipline-specific and foundational modules in key areas of the curriculum. The modules will provide a foundation for the integration of new technologies. The award will also facilitate further development by a planning group consisting of faculty members at Mercy, and researchers from the University Arizona, University of Colorado-Boulder, and University of Houston-Downtown. The project supports on-site faculty training at the University of Colorado's Center for Spoken Language Research and the development of a five-year infrastructure development proposal to improve faculty and student research capability at Mercy. The award will enable Mercy College to initiate and continue critical steps towards invigorating and strengthening offerings in the computer science and information technology fields","title":"Mercy College Minority Institution Infrastructure Program One-Year Planning Grant","awardID":"0220520","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":[194367,194368],"PO":["297837"]},"75916":{"abstract":"This small grant for exploratory research will support development of novel computer systems that will enhance the quality of life of people suffering from Alzheimer's Disease and similar cognitive disorders. Assisted Cognition systems use ubiquitous computing and artificial intelligence technology to replace some of the memory and problem-solving abilities that have been lost by an Alzheimer's patient. Assisted Cognition systems: sense aspects of an individual's location and environment, both outdoors and at home, relying on a wide range of sensors such as Global Positioning Systems (GPS), active badges, motion detectors, and other ubiquitous computing infrastructure; learn to interpret patterns of everyday behavior, and recognize signs of distress, disorientation, or confusion, using techniques from state estimation, plan recognition, and machine learning; offer help to patients through various kinds of interventions including speech and natural language processing; and alert human care-givers in case of danger.<br\/><br\/>Two concrete examples of the Assisted Cognition systems that will be developed are an activity compass that helps reduce spatial disorientation both inside and outside the home, and an adaptive prompter that helps patients carry out multi-step everyday tasks. This project will explore an emerging area that could be of great humanitarian, commercial, social, and scientific importance in the coming decades.","title":"SGER: Assisted Cognition: First Steps Towards Computer Aids for People with Alzheimer's Disease","awardID":"0225774","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["550377","550054","365925"],"PO":["246649"]},"74607":{"abstract":"EIA-0219547<br\/>Patrick O. Bobbie (Southern Polytechnic State University), Brian Davis (Kennesaw Mountain High School), and Jennifer L. Uboh (South Cobb High School)<br\/>Institution: Southern Polytechnic State U.,<br\/><br\/>TITLE: ITR: A Community Based Partnership for Community-Based Education (COPIRE)<br\/><br\/>This ITR- and ITWF-funded project is a partnership between Southern Polytechnic State University (SPSU) (a suburban technology-focused institution), Kennesaw Mountain High (KMH) School (a new school with a magnet program) and South Cobb High (SCH) School (an established school, also with a magnet program). The project is driven by an overarching goal of establishing a community-based partnership, which focuses on an integration of education, research, and training in the design and development of embedded system simulations. The motivation for the project stems from 1) the plausibility of extending embedded system research\/knowledge to high school students and 2) enhancing their opportunities and chances in the field.<br\/><br\/>SPSU is involved in a Georgia statewide research initiative, Yamacraw, which is focussed on embedded software development and the design of broadband (high-speed) communications systems, devices, and chips. SPSU's partnership project is designed to dovetail with Yamacraw to take advantage of the research resources of Yamacraw and to train students early in the academic pipeline. SPSU is:<br\/><br\/>1. Partnering with KMH and SCH to select a cohort of both non-minority and minority students - females and males - at the 11th and 12th grade levels and SPSU undergraduates to be involved in various hands-on research projects. The students are participating in the program for 7 weeks during the summer and once a week when school is in session for 3 years;<br\/>2. Cstablishing a training, mentoring, role modeling, and a management group, which involves Yamacraw graduate students and the PIs, to support the program; and<br\/>3. Continually assessing and measuring achievements along the 'pipeline' to ensure successful transfer of students across its stages.","title":"ITR: A Community-based Partnership for Integrated Research and Education (COPIRE)","awardID":"0219547","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["343329","361223",193787,193788],"PO":["564181"]},"74409":{"abstract":"EIA-0218506 <br\/>Burge, Christopher B<br\/>MIT<br\/><br\/>CRCNS: Bioinformatics of Alternative Splicing in the Nervous System<br\/><br\/>Almost every human cell contains a huge instruction manual called the genome with many thousands of pages (the genes), each of which tells the cell how to make a particular building block (protein) that it needs to live or grow or to perform its assigned function in the body. The cell uses this manual in a complicated way, first copying (transcribing) each page that it needs to a piece of scratch paper (the pre-mRNA), and then cutting and pasting (splicing) pieces of the scratch paper (the exons) together to form the final recipe (mRNA) for the protein product. Interestingly, this cutting and pasting is often carried out in different ways in different types of cells or under different conditions in a process called alternative splicing (AS), generating many different varieties of a protein under different conditions. Alternative splicing is particularly common in neurons, helping to generate protein variants whose properties are optimized to the local environment of the neuron. For example, AS is used to tune the electrical properties of ion channels which help different sensory neurons in the inner ear respond to different frequencies of sound. In addition, mutations that affect AS are associated with a number of neurodegenerative diseases. The goal of the proposal is to gain a better understanding of the signals in a gene that determine how that gene will be spliced when it is expressed in a particular part of the brain, and of how alternative splicing is used to modulate brain function.","title":"CRCNS: Bioinformatics of Alternative Splicing in the Nervous System","awardID":"0218506","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}}],"PIcoPI":["523294",193241,"375883"],"PO":["564318"]},"71978":{"abstract":"Integrating humans with their naturally developed control algorithm and robots with their extended capability of applying forces and torques into one system offers multiple opportunities for creating a new generation of assistance technology for both healthy and disabled people suffering from neuromuscular diseases and neuro-degenerative disorders. The exoskeleton is a wearable robotic arm. It is worn by the human as an orthotic device and acts as a human-amplifier allowing the operator natural control of the device as an extension of his\/her body while sharing an external load. One of the primary innovative ideas of this research is to set the human machine interface at the muscular level of the human physiological hierarchy using an expression of body's own control command (surface electromyography - sEMG) signals as one of the primary command signals of the exoskeleton for improving the synergy between the operator and the exoskeleton. The goals of this research are to design, build, and experimentally study the integration of a powered exoskeleton controlled by myosignals (sEMG) for the human arm with healthy people. It is anticipated that the scientific activity involved in this research will integrate and fuse multidisciplinary knowledge by promoting dialogues and collaborative work between students and faculty members from different disciplines with a long-term goal of improving the quality of life of the physically disabled community.","title":"Neural Control of an Upper Limb Powered Exoskeleton System","awardID":"0208468","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["520782","434705"],"PO":["335186"]},"74828":{"abstract":"EIA 02-20562<br\/>Rishe, Naphtali<br\/>Wongsaroj, Ben<br\/>Florida International University (FIU) and Florida Memorial College (FMC) <br\/><br\/>Title: MII Consortium: Infrastructure for Research and Training in Database Management for Web-based Geospatial Data Visualization with Applications to Aviation <br\/><br\/><br\/>This proposal, facilitating research on high-performance database management and Internet dissemination of geospatial data, aims at attracting, recruiting, and retaining minority students while engaging these in research. The project enables the creation of a consortium between Florida International University (FIU) and Florida Memorial College (FMC). A pipeline of students from FMC, a four year HBCU, to FIU, a Carnegie-I HSI will be formed, encouraging FMC's students and others to enter FIU's masters or doctoral program in computer science. The consortium will focus on research necessary to enhance TerraFly, a web-based geospatial data viewer stemming from research performed at FIU's High Performance Database Research Center (HPDRC) under grants from NSF and other agencies. Researchers will work in Affinity Groups that consist of undergraduate and graduate students, post-docs, and faculty members. These groups provide the framework that enables deepening knowledge of a field by procuring a physical setting in a cooperative research-engaging environment. The project enhances TerraFly's underlying data storage mechanism, client-server interaction, user interface, its ability to overlay additional information layers, and its ergonomics of use and maintenance. The following specific research issues are addressed.<br\/>Efficient and ergonomic dissemination of imagery with spatio-temporal data overlays, <br\/><br\/>Data storage and querying methods for spatio-temporal data, <br\/>Integration of heterogeneous data sources including relational and semantic databases and web <br\/>sources with the spatial data, <br\/>Testbed applications using geospatial data dissemination for aviation needs.<br\/>Thus, the requested infrastructure will be used to perform this research, as well as the training of students at both institutions. Showing TerraFly's potential applications, FMC's knowledge of the aviation industry will be leveraged as the test beds are developed and tailored. The deployment of infrastructure at FMC will enable FIU's distributed database research to be incorporated into TerraFly research, as FMC students gain valuable hands-on experience with the requested infrastructure on a daily basis.","title":"MII: Infrastructure for Research and Training in Database Management for Web-based Geospatial Data Visualization with Applications to Aviation","awardID":"0220562","effectiveDate":"2002-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":["558108",194404],"PO":["563751"]},"72529":{"abstract":"EIA-0210736<br\/>Watson, Susan K<br\/>Middlebury College<br\/><br\/>NIRT: Nanotube and Nanowire Based Quantum Computation<br\/><br\/>A team research effort has been organized to implement a simple one-dimensional quantum computer using carbon nanotubes and Si nanowires as the substrate, and to in-vestigate issues of synthesis, nanofabrication, theoretical physics, and computer science surrounding this focused goal. The device on which the proposed effort will concentrate consists of a one-dimensional string of islands of charge-quantum dots-with coupling between the dots controlled by the application of gate voltages. The intrinsic magnetic moments ('spins') of the dots are used to form the quantum bits ('qubits') of a quantum computer. The strength of the scheme lies in its simplicity; in contrast to other proposed schemes, only changes to the coupling between neighboring quantum dots along the nanotube or nanowire are necessary. <br\/>The research project is complemented by an educational program that brings to-gether students from several disciplines, encouraging them to develop intellectually and interact as part of a single collective effort. The educational goals of the Nanoscale Sci-ence and Engineering program will be explicitly advanced through the creation of courses and lab modules focused on nanoscience.<br\/>A number of basic physics questions are raised by this project, relating to active spin manipulation in this simple 1D system and to the ways in which coupling beyond nearest neighbors can correct for problems of quantum decoherence and timing errors. If the device ultimately operates as intended, it will function as a general-purpose quantum computer, a goal towards which much current research is focused.","title":"NIRT: Nanotube and Nanowire Based Quantum Computation","awardID":"0210736","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}}],"PIcoPI":["347393","512386","479891","479996",187946],"PO":["561889"]},"74718":{"abstract":"The objective of the proposed work is to develop a unified framework<br\/>for synthesis and control of infinite-state reactive systems based on<br\/>temporal specifications. With synthesis, the full program is<br\/>generated directly from its specification. With control, part of the<br\/>system is given and the task is to generate the modules interacting<br\/>with the given components such that the overall system satisfies its<br\/>specification. The framework will include a computational model to<br\/>represent the notions of infinite games, control, realizability, and<br\/>synthesis of reactive systems, a specification language that can<br\/>assign goals (winning conditions) to sets of system components, and<br\/>deductive-algorithmic methods to solve the synthesis and control<br\/>problems in their various forms for the infinite-state case.<br\/><br\/>The starting point for this framework will be a theoretical foundation<br\/>built on the models and methods developed for algorithmic synthesis<br\/>and control of finite-state reactive systems. These methods will be<br\/>combined with methods developed for deductive verification and<br\/>abstract interpretation of reactive systems, and with deductive<br\/>synthesis techniques for functional programs to allow the synthesis<br\/>and control of infinite-state systems. Preliminary investigations into<br\/>this approach, described in this proposal and also accepted for<br\/>publication, are promising.","title":"ITR: Synthesis and Control of Infinite-state Reactive Systems","awardID":"0220134","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["309451"],"PO":["561889"]},"74608":{"abstract":"Existing methods to validate mobile code integrity and author authentication include using certificates, encrypting the code, and using digital signatures to sign applications. This proposal addresses the challenge of providing users with a system that can overcome the weaknesses of certificates (which require additional bandwidth) and conventional signatures (which can be removed) without becoming as obtrusive as encrypted code. This research proposes a novel approach in which the code serves as its own authentication device. The overall goal of this proposed research is to develop both the foundations and a unifying framework for ensuring integrity and authentication of mobile code, and then to build a prototype environment consisting of a set of automatic tools that embody the developed techniques.<br\/>The results will be:<br\/>(1) techniques for statically analyzing mobile code representations to efficiently compute a tamper detection mark and to embed, extract, and validate the mark, <br\/>(2) static analysis techniques for generating a unique program fingerprint to be used as a less stringent form of tamper detection and for intellectual property protection, <br\/>(3) a suite of platform-independent tools that automate the process of ensuring integrity and authentication for mobile code, <br\/>(4) thorough experimental evaluation of the developed techniques, and <br\/>(5) increased participation of undergraduates in experimental computer<br\/>science research, with particular attention to encouraging <br\/>the pursuit of graduate education and women in computer<br\/>science.<br\/>This proposed research represents a significant step towards ensuring high confidence in the integrity of mobile code, which is becoming a major component of software systems exploiting the Internet.","title":"ITR: Bandwidth Efficient Techniques for Ensuring Mobile Code Integrity and Authentication","awardID":"0219559","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["527984"],"PO":["521752"]},"75609":{"abstract":"FMRI Analysis of Emotion Regulation and Its Developmental Trajectory<br\/><br\/>Abstract<br\/><br\/>With National Science Foundation support, Dr. Gabrieli and colleagues will conduct a three-year investigation of the maturation of the brain systems that support emotion regulation using functional magnetic resonance imaging (fMRI), a noninvasive technique that can identify brain regions recruited for specific emotion and cognition processes. Children and young adults, ages 8 to 30, will participate in two experiments that examine how they regulate an initial emotional response to either highly negative or highly positive photos. These studies will identify what brain regions initially respond to negative or positive emotional experiences, and what brain regions then support cognitive regulation of those emotional responses. Of greatest interest is how these brain responses mature, or change, from late childhood through early adulthood.<br\/><br\/>Emotion regulation, the subject of this research, is a fundamental aspect of human experience and behavior, and the interaction between thoughts (cognition) and feelings (emotions) that guides how people evaluate and act on what is going on around them. Successful emotion regulation makes people resilient to difficult circumstances, and thus can help people avoid distress or psychiatric diseases such as major depression. Successful regulation also promotes prosocial behaviors, such as not behaving violently in response to feelings of anger. It is generally thought that children and adolescents have emotions as strongly felt as do adults, but that the cognitive regulation of emotion matures slowly as children and adolescents learn how to regulate their feelings in ways that promote positive social interaction and long-term mental health. Risky behaviors that pose severe health threats for adolescents may reflect the faster maturation of emotion than cognitive aspects of emotion regulation. Although emotion regulation is thus important for health and for social functioning, little is known about its underlying cognitive and neural mechanisms. For example, it is unknown whether people use the same brain systems to regulate negative and positive emotions. Further, nothing is known about how these mechanisms support the normal maturation of emotion regulation in childhood and adolescents. The findings from this research may also illuminate the roots of mental diseases that reflect a disadvantageous development of emotion regulation pathways of the human brain.","title":"fMRI Analysis of Emotion Regulation and its Developmental Trajectory","awardID":"0224342","effectiveDate":"2002-09-01","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1699","name":"COGNEURO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V577","name":"CIA-ANTENNE ARRAY PROCESSING"}}],"PIcoPI":["413651"],"PO":["352965"]},"70802":{"abstract":"Symbolic Representation Based Partial Order Methods<br\/>S. Purushothaman Iyer<br\/><br\/> Symbolic representations are used in analysis of finite and infinite<br\/>state concurrent system. However, they could be subjected to<br\/>constraint explosion much like state explosion in analysis of finite<br\/>state designs of concurrent systems. The reason for both of these explosions<br\/>is the consideration of all interleavings, of a concurrent system, during their<br\/>analysis.<br\/><br\/>Partial-order techniques depend upon the notion of independence among<br\/>actions to avoid considering all possible interleavings. The proposed<br\/>research will investigate the notion of unfolding, which aids both in<br\/>discovery of independent actions and in succinctly representing the state<br\/>space of systems. In particular, the proposed research will address the <br\/>following topics:<br\/><br\/> o How to build unfoldings for real-time automata as available, for <br\/> instance, in the tool-set UPPAAL.<br\/><br\/> o Implementation of an unfolding-based partial order method for UPPAAL.<br\/><br\/> o A comparative (theoretical) investigation of unfoldings and current partial<br\/> order methods, with a view to generalizing unfoldings to other infinite<br\/> state systems. <br\/> <br\/> o Empirical evaluation of the proposed implementation against current<br\/> practices.<br\/><br\/>The proposed research will aid in faster, and more complete, analysis of<br\/>infinite state concurrent systems than is currently possible.","title":"Symbolic Representation Based Partial Order Methods","awardID":"0204159","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["78952"],"PO":["564388"]},"71847":{"abstract":"This project is a study of computational complexity theory, in particular<br\/>a study of structural complexity theory and some compelxity problems<br\/>relating to lattice problems. Computational complexity theory is<br\/>the study of the inherent hardness of computational problems, both<br\/>in the worst-case measure as well as in the average-case measure.<br\/>This theory is the underpinning of all computer security based on the<br\/>hardness or insolvability of computational problems.<br\/><br\/>The investigator will study the interrelationship between a number of<br\/>complexity classes, especially those between determinisitic P and the<br\/>second level of the polynomial time hierarchy, building on the recent<br\/>breakthrough concerning the class S2, the symmetric second level class of<br\/>the hierarchy. The investigator also explores a notion of persistent<br\/>NP-hardness. This is to be an intermediate level of complexity<br\/>measure between worst-case hardness and average-case complexity<br\/>in the framework of Levin and others. In lattice problems, <br\/>the investigator will search for moderately efficient algorithms<br\/>for the shortest vector problem and the closest vector problem,<br\/>both in the worst case measure as well as in the average case measure.<br\/>The investigator will study their connections to random lattices,<br\/>and potential applications to the design of secure public-key<br\/>cryptosystems based on assumptions of hadness in the worst case <br\/>complexity only.","title":"Some Problems in Structural and Lattice Complexity","awardID":"0208013","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["517847"],"PO":["499399"]},"70758":{"abstract":"Integrating Software Architecture and Software Development Craig Chambers <br\/>The goal of the research is to extend the benefits of software architecture from design into later stages of the software lifecycle by ensuring a rigorous connection between architecture and implementation code. Existing architecture description languages are not tightly coupled to implementation languages in a way that ensures that the implementation code conforms to the architectural specification. To overcome this limitation, this project is developing ArchJava, a simple extension to Java that allows programmers to express software architecture within their implementation. The language is flexible, supporting dynamically changing software architectures as well as common object-oriented implementation idioms, but it also rigorously guarantees that the program semantics conform to the constraints in the architectural specification. A system's design can be expressed in ArchJava before any implementation exists; this design can then be fleshed out incrementally into a complete implementation. At all times, conformance between the architecture and the (partial) implementation can be mechanically verified. By extending the benefits of software architecture throughout the software lifecycle and by allowing developers to trust the accuracy of the architecture, this work has the potential to make software architecture a much more effective and commonly used tool.","title":"Integrating Software Architecture and Software Development","awardID":"0204047","effectiveDate":"2002-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["332082"],"PO":["564388"]},"70879":{"abstract":"The objective of the project is to produce useful and practical<br\/>methods for the development of large complex software systems. The<br\/>research will address the problem of composing software components<br\/>into large systems that have guaranteed correctness properties.<br\/>State-explosion (the exponential growth of the number of possible<br\/>system behaviors with the number of the system's components) is<br\/>avoided by analyzing interactions among every pair of components<br\/>separately, rather than inspecting the interaction of all components<br\/>at once. This local approach nevertheless enables us to prove that<br\/>the overall system behaves as desired. Since the number of behaviors<br\/>that have to be analyzed is much smaller, the amount of effort needed<br\/>to rigorously analyze and verify large systems is greatly reduced.<br\/><br\/>The main activities are:<br\/><br\/>1. Develop techniques for the precise description of the<br\/>required behavior of a software component.<br\/><br\/>2. Develop practical methods for reasoning about the behavior that<br\/>results when a set of components are connected to form a large<br\/>system.<br\/><br\/>The benefit of this research is to reduce the cost of creating<br\/>realistic size software systems that have demonstrable correctness<br\/>properties.","title":"Constructing Large Complex Systems via Tractable Pairwise Composition of Software Components","awardID":"0204432","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["306142","540016"],"PO":["564388"]},"74719":{"abstract":"The goal of the proposed research is to develop a multithreaded prototyping environment that allows hardware and software experimentation with fine-grain and speculative multithread chip multiprocessor (CMP) architectures. This environment will allow the analysis of single-chip fine-grain threaded systems at full hardware speeds in a much more flexible manner than is possible today with software simulation, and will be the first hardware implementation to execute speculatively multithreaded applications. This environment would be used to investigate threaded applications much more efficiently and thoroughly than any other system existing today. <br\/><br\/>The prototyping environment will be built without doing any VLSI design. The key idea is that by combining ten-year-old microprocessor chips with state-of-the-art FPGA chips it is possible to build a single-board multiprocessor prototyping environment that provides support for thread level speculation (TLS) and operates at hardware speeds, yet has the latency and bandwidth characteristics equivalent to a modern CMP architecture. Such an environment will be ideal for architecture and software research on multithreaded microprocessors","title":"ITR: Prototyping Multithreaded Systems","awardID":"0220138","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["556786"],"PO":["325495"]},"74609":{"abstract":"This research will study the SPMP (Selective Private Model-based<br\/>Prediction) problem demonstrated with the following scenario: A client<br\/>with a private input wants to use a server's private model to make<br\/>predictions; however, neither side wants to disclose its private data to<br\/>anybody. More specifically, the research will study the problem for<br\/>selected models including the Hidden Markov Model, the Neural Network<br\/>Model, the Bayesian Network Model, and the Decision Trees Model. The goal<br\/>is to develop efficient and practical solutions that enable such type of<br\/>privacy preserving prediction.<br\/><br\/>The project will investigate two approaches: commodity-server approach and<br\/>multiple-server approach. The commodity-server approach uses the<br\/>commodities (data) from a third party to preserve the confidentiality of<br\/>the private data. The multiple-server approach uses duplicate servers so<br\/>no single server can learn all information about the client's data. Based<br\/>on these two approaches, various data disguising techniques will also be<br\/>studied.<br\/><br\/>Efficient solutions to the SPMP problems enable model owners to provide<br\/>new forms of e-commerce services while protecting customers' private<br\/>information. Furthermore, the results, methodologies, and the building<br\/>blocks gained from the proposed activity can provide invaluable<br\/>understanding and insights into the Secure Multiparty Computation (SMC)<br\/>research, and help to advance and expand the areas of SMC research.<br\/>---------------------------------------","title":"ITR: Private Prediction Using Selective Models","awardID":"0219560","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["553652","550133"],"PO":["469867"]},"70825":{"abstract":"Research is proposed on the specification and verification of computer programs written in languages that provide a low-level view of storage and other resources. This research will focus on novel formal methods for two particularly crucial programming techniques:Shared mutable data structure - the use of representations that may contain more than one pointer to a location that can be updated by the program. These data representations will be specified in an extension of predicate logic, called separation logic, in which the structure of assertions mirrors the separation of storage into<br\/>Disjoint components. Embedded code pointers - the use of data representations<br\/>Containing updatable components that point to program instructions. <br\/>Programs using code pointers will be specified by using a reflection<br\/>Operator that allows code to occur within assertions.<br\/><br\/>Specific aspects of low-level programming to be investigated include<br\/>storage allocation, share-variable concurrency, and the relation<br\/>between specifications and tye systems.<br\/>As a consequence of this research, it will become easier to avoid<br\/>errors in an important class of useful but difficult computer programs. <br\/>Eventually, it should be possible to automate the logic so that programs in this<br\/>Class can be accompanied by machine-checkable proofs of their correctness","title":"Reasoning About Low-Level Programming","awardID":"0204242","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["511108"],"PO":["564388"]},"70726":{"abstract":"EIA-0203971 Gianfranco Ciardo College of William & Mary Structured Methods to Evaluate the Performance of Distributed Software<br\/><br\/>Our goal is a collaborative research effort aimed at removing the computational barriers to the widespread adoption of Markov chain modeling technology in the software performance engineering process. <br\/><br\/>We will approach the problem from different and complementary points of view, and have the necessary means to solve many of the remaining computational issues. The results of the proposed research will open up the Markov modeling field to a surge of new, and probably unanticipated, research activity in very diverse areas of national and international importance, and provide a path towards the compositional performance assessment of systems built from off-the-shelf software modules.","title":"NGS: Methods to Evaluate the Performance of Distributed Software","awardID":"0203971","effectiveDate":"2002-09-15","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5980","name":"WESTERN EUROPE PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["200721","451554"],"PO":["301532"]},"70847":{"abstract":"Execution of distributed applications over the Internet involves method invocations on remote objects and coordination tasks. This proposal addresses the task coordination problem by (1) limiting the model of computation to tree structured concurrency, and (2) assuming that there is an environment that provides sacilities for remote method invocation on distributted objects, persistent storage,and computation using standard function library. Tree structured concurrency permits only restricted communications among the tasks: a task may spawn children task and all communications are between parents and their children. It can be shown that such structure communication, though less powerful than interactions in process networks, are sufficient to solve most problems of interest, and they avoid many of the problems associated with concurrency. The broader impact of this research will be to (1) design a theory for restricted class of concurrent computing, which still exhibits the power to solve a variety of task coordination problems, and (2) develop prototype implementations that allow non-programmers to develop with ease distributed applications on the Internet.","title":"Orchestrating Computations on the World-Wide-Web","awardID":"0204323","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["370809","261975"],"PO":["564388"]},"70748":{"abstract":"EIA-0204022 Phillip M. Dickens Illinois Institute of Technology End-to-End Performance Modeling of Applications Executing in the Internet2 Domain<br\/><br\/> The objective of this research project is to advance the state-of-the-art in modeling and simulation to the point that the Internet2 network infrastructure and protocols, the high-performance applications that are and will be developed within this environment, and the interactions between these individual components can be studied, Analyzed, and predicted. This project will provide significant support to both systems engineers, and application developers and users. From a systems point of view, it will provide and environment in which new and existing networking hardware and software can be tested and studied as a function of expected (and observed) application types and loads on the system. From the point of view of an application, this research will support its performance and scalability analysis as a function of its execution environment.","title":"End-to-End Performance Modeling of Applications Executing in the Internet2 Domain","awardID":"0204022","effectiveDate":"2002-09-15","expirationDate":"2004-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["344399"],"PO":["301532"]},"74709":{"abstract":"As the demands on portable embedded systems increase with the incorporation of high-bandwidth wireless data along with multimedia and speech processing, it is becoming increasingly difficult to achieve the required performance and power requirements with programmable solutions. Current platforms for high-end embedded systems typically comprise one or more RISC or DSP processors, along with an increasing number of application-specific (ASIC) components that are necessary to deliver high performance at low power. As more and more functionality is implemented using ASIC components, the platform's range of application decreases and its vulnerability to obsolescence increases.<br\/><br\/>Coarse-grained adaptable architectures bridge the gap between traditional processors and ASIC solutions and can be used to replace many of the ASIC components in high-performance embedded platforms. The goal of this research is to make these adaptable architectures accessible to programmers via a high-level programming language interface. This project will develop a compiler comprising a standard front-end combined with a parallelizing backend that performs scheduling and optimization using a simultaneous place and route algorithm based on those used in physical design automation. Posing the scheduling problem as a place and route problem allows the many constraints imposed by adaptable architectures to be solved by a single phase of the compiler.","title":"Compiling for Explicitly Parallel Adaptable Architectures","awardID":"0220095","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["485670","332082"],"PO":["325495"]},"70804":{"abstract":"Systems where components share information and resources<br\/>indiscriminately are often fragile. Conversely, the control of sharing<br\/>contributes to modularity, reliability, and security. Java, C#, and<br\/>other modern programming languages rely on sophisticated concepts and<br\/>methods for controlling sharing. These are embodied in constructs such<br\/>as locks, abstract data types, and unforgeable object references, and<br\/>in type systems and static analyses. <br\/><br\/>This project aims to study and develop techniques for controlled<br\/>sharing in programming languages. For this purpose, it relies on the<br\/>development of foundational calculi (e.g., calculi of objects or<br\/>processes). It focuses on capabilities (such as unforgeable<br\/>references), on related \"packaging\" constructs (such as objects and<br\/>abstract data types), and on disciplines for the safe use of run-time<br\/>mechanisms for controlled sharing.","title":"Controlled Sharing: Programming-Language Principles and Techniques","awardID":"0204162","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["284691"],"PO":["564388"]},"71948":{"abstract":"This proposal concerns the development of methods to allow a variety of uni-cast, multicast, geocast and location-based mobile ad-hoc routing protocols to adapt. It addresses specifically the ad-hoc routing protocol design related to quantification of the mobility by specific metrics, in particular mobility, which are used to solve various routing tasks. In this three-year project, the following research activities will be particularly pursued. The research team will address the development of local mobility metrics that are specific to individual nodes. For that purpose, a generic feedback agent that resides on a mobile node will be developed, which gathers the information required to compute the value of the mobility metrics, and present the information to an arbitrary type of protocol. The simulation studies under a wide variety of network conditions will be con-ducted to determine appropriate trade-offs between active and passive monitor-ing and optimal sampling times for estimating metrics such as node speed, link change rate, link duration, etc. The project activities will also include the devel-opment of example adaptive routing protocols utilizing the feedback agent. For example, the research team will explore a protocol that will combine location-based routing with localized flooding in an effort to enable successful packet delivery in times of extreme network mobility (low link duration times). Finally, the development of new mobility models that are more realistic will be consid-ered. For example, the networks in which node speeds vary among different parts of the network will be studied, e.g. for the case of regions where the mobil-ity dynamics vary widely throughout the network. In addition to the above ac-tivities the research team also plans to address a variety of other metrics such as link change rate and passive and active traffic monitoring metrics.","title":"Adaptive Protocols for Mobile Ad Hoc Networks","awardID":"0208352","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["392036","546219"],"PO":["565090"]},"71927":{"abstract":"Through the years, much work has been done on synchronization algorithms for<br\/>shared-memory multiprocessors. In contrast, very little work has been done on<br\/>time-complexity lower bounds that express fundamental limits to which such<br\/>algorithms are subject. Given the vastness of the literature on<br\/>synchronization, this may seem somewhat surprising. However, there is a<br\/>simple explanation: while devising a useful time complexity measure for<br\/>sequential algorithms is straightforward, it is not altogether obvious how to<br\/>do this in a meaningful way for synchronization algorithms. Indeed, in most<br\/>synchronization algorithms, processes may wait unboundedly; thus, if one merely<br\/>applies the standard sequential measure of counting all operations to such an<br\/>algorithm, then its time complexity is unbounded. This is not a very useful<br\/>statistic.<br\/><br\/>Recently, some progress has been made towards defining useful time complexity<br\/>measures. One such measure is the the remote memory references (RMR) measure.<br\/>Under the RMR measure, a distinction is made between local and remote accesses<br\/>of shared memory. An access is local if it does not require a traversal of<br\/>the global interconnect between processors and shared memory, and is<br\/>remote otherwise. The RMR measure was motived by research on \"local-spin\"<br\/>synchronization algorithms. In such algorithms, processes are structured so<br\/>that all busy waiting is on variables cached locally or stored in a local<br\/>memory module.<br\/><br\/>When studying synchronization problems, the following key question arises:<br\/>Using some class C of synchronization primitives, what is the most<br\/>efficient possible algorithm for solving a given synchronization problem?<br\/>It is this basic question to which this research project is directed, where<br\/>\"efficiency\" is defined as time complexity under the RMR measure. The<br\/>research agenda includes work on both algorithms and lower bounds. Based<br\/>on such work, rankings of synchronization primitives are being developed<br\/>that order synchronization primitives according to the time complexity<br\/>(worst-case, average-case, amortized) with which various synchronization<br\/>problems can be solved. Such rankings should be of value to computer<br\/>architects. Indeed, preliminary research has shown that a variety of<br\/>fetch-and-phi primitives are more powerful than comparison primitives for<br\/>implementing blocking synchronization mechanisms. This stands in contrast<br\/>to the fact that compare-and-swap and related comparison primitives are<br\/>commonly regarded to be among the most powerful and useful of primitives,<br\/>and are widely supported in modern machines.","title":"Time Complexity Limits for Shared-Memory Synchronization","awardID":"0208289","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["31436"],"PO":["279077"]},"70838":{"abstract":"ABSTRACT<br\/>0204293<br\/>Suneeta Ramaswami<br\/>Rugers U New Brunswick<br\/><br\/>The broad goal of this project is the complete development of robust algorithms for the modeling<br\/>and visualization of data in a specific application domain, namely medical imaging. The focus of<br\/>the proposal is on the generation of quadrilateral and hexahedral meshes for medical data obtained<br\/>from structural studies (MR and CT) of human organs.<br\/>The generation of good quadrilateral and hexahedral (quad\/hex) meshes is not well-understood<br\/>and several important questions remain open. By exploiting the geometry that is central to these<br\/>problems, we aim to develop algorithms for generating guaranteed-quality surface and volume<br\/>meshes composed of quadrilateral and hexahedral elements. Algorithmic techniques and data struc-<br\/>tures from computational geometry will be utilized towards this end. We also investigate adaptive<br\/>quad\/hex meshes, i.e., meshes designed to have varying levels of refinement depending on factors<br\/>such as the desired level of detail in a localized part of the input domain. The algorithms will be<br\/>designed for and tested on medical imaging data. Improved surface and volume meshing algorithms<br\/>will directly impact automated clinical analysis of medical data, which is typically carried out by<br\/>procedures that require finite element simulations on discrete anatomical models. Some examples<br\/>of such procedures are elastic matching and viscous uid ow. Our work will be done in collabo-<br\/>ration with researchers in the area of brain image analysis in the Department of Radiology at the<br\/>University ofPennsylvania.","title":"RUI: Geometric Techniques for Quadrilateral and Hexahedral Mesh Generation with Applications in Medical Imaging","awardID":"0204293","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["381439"],"PO":["321058"]},"71839":{"abstract":"Optical communication, in particular, wavelength-division multiplexing (WDM) technique, has become a promising networking choice to meet ever-increasing demands on bandwidth from many emerging bandwidth-intensive computing\/communication applications. As optics become a major networking media, optical interconnects will inevitably play an important role in interconnecting processors in parallel\/distributed computing systems. This research focuses on fundamental challenges and issues <br\/>on using optics in two converging areas: parallel\/distributed computing and communications. The objective of this research is to design high-speed, cost-effective optical interconnects for current and future generation parallel\/distributed computing and communication systems. Due to the unique characteristics of optics, many important issues of optical interconnects, different from those of <br\/>electronic interconnects, need to be addressed. Specially, this research focuses on (1) explore unique properties and classifications of WDM interconnects; (2) optimal and cost-effective designs; (3) study the effect of wavelength conversion; (4) performance modeling; (5) fault-tolerance issues. The proposed research combines architecture\/circuit design, algorithmic, probabilistic, combinatorial and simulation <br\/>techniques to conduct comprehensive studies on the above issues. The research results will provide viable solutions for designing high-bandwidth, high-connectivity, low-latency and low-cost optical interconnects. The proposed research will have a significant impact on next generation arallel\/distributed computing and communication systems and future networking infrastructure.","title":"Wavelength-division Multiplexing (WDM) Optical Interconnect Architectures for Parallel and Distributed Computing and Communications","awardID":"0207999","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["550688"],"PO":["550859"]},"70829":{"abstract":"SF Proposal 0204248 Type Refinements<br\/>Frank Pfenning and Robert Harper<br\/><br\/>An important aspect of software development and maintenance is to<br\/>understand properties of a complete system, its individual<br\/>components, and how they interact. There is a wide range of<br\/>properties of interest, some concerned only with the input\/output<br\/>behavior of functions, others concerned with concurrency or<br\/>real-time requirements of processes. Upon examining the techniques<br\/>for formally specifying, understanding, and verifying program<br\/>behavior available today, one notices that they are almost bi-polar.<br\/>On the one extreme we find work on proving the correctness of<br\/>programs, on the other we find type systems for programming<br\/>languages. Both of these have clear shortcomings: program proving<br\/>is very expensive, time-consuming, and often infeasible, while<br\/>present type systems support only minimal consistency properties of<br\/>programs.<br\/><br\/>The proposed research is intended to help bridge this gap by<br\/>designing and implementing more refined type systems that allow rich<br\/>classes of program properties to be expressed, yet still be<br\/>automatically verified. Through careful, logically motivated design<br\/>the research combines the best ideas from abstract interpretation,<br\/>automated program analysis, type theory, and verification.","title":"Type Refinements","awardID":"0204248","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["339844","485877"],"PO":["564388"]},"74090":{"abstract":"Modern, componentized Internet services allow server consolidation <br\/>by sharing common service components. <br\/>Such sharing can potentially reduce the installation cost, <br\/>space, and energy consumption. However, to date, services <br\/>are seldom shared across server applications to avoid<br\/>possible interference between them. Service providers often run<br\/>multiple instances of shared services, one for each frontend<br\/>service. The only benefit gained thus far, from the deployment of<br\/>multi-tier services is that new services can be composed quickly using<br\/>existing service components. Since these service<br\/>components may execute on different machines, each optimally configured<br\/>for its services, multi-tiered services tend to be more<br\/>scalable than monolithic counterparts.<br\/><br\/>The proposed research aims to address the shortcoming of current<br\/>OSs in executing multi-tiered services. We will focus on OS extensions <br\/>that correlate and trace service activities across the tiers of a <br\/>multi-tiered server farm. We will develop mechanisms for online<br\/>classification of activities (e.g., premium vs.~basic service classes), <br\/>as well as mechanisms that allow system administrators to insulate <br\/>(performance-wise) different service classes even when the <br\/>activities of different service classes may overlap and <br\/>share backend services. <br\/><br\/>The same OS mechanisms that are used to manage multi-tiered <br\/>services can be used to analyze the interactions between different <br\/>tiers and the interferences between different service classes. <br\/>We will show that a combination of service interaction analysis <br\/>and service policing minimizes performance invasiveness <br\/>between services\/applications. <br\/>We will also investigate how to improve insulation between <br\/>services in this environment. <br\/>We will explore how service implementations may take <br\/>advantage of an improved OS infrastructure for multi-tiered","title":"ITR\/SY: QoS-Aware Execution Environments for Multi-tier Network Services","awardID":"0216977","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["553551"],"PO":["543507"]},"76192":{"abstract":"EIA-0227651<br\/>Jean L. Camp<br\/>Harvard University<br\/><br\/>Digital Government: The Virtual Citizen: Identity, Autonomy, and Accountability<br\/><br\/>This proposal will apply Camp's unusual multidisciplinary expertise (Engineering and Public Policy Ph.D.) in the area of trust, an area with both technical and social implications. She will use this small grant to develop government relationships relevant to preparation of a workshop in this area and to place the issue of \"trust\" within a government context.","title":"Digital Government: The Virtual Citizen: Identity, Autonomy, and Accountability","awardID":"0227651","effectiveDate":"2002-09-01","expirationDate":"2004-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["537066"],"PO":["371077"]},"72090":{"abstract":"The research addresses problems in two topics: scheduling of random<br\/>processes and quantum information theory. Scheduling problems arise in<br\/>many areas of computer science. The investigator studies the possibility<br\/>of scheduling two random sequences of activities in a way that prevents<br\/>certain conflicts between them. The methods applied also advance the state<br\/>of the art in percolation theory (a fundamental area of probability theory<br\/>and statistical physics). Quantum information theory extends the questions<br\/>concerning conditions and methods for reliable transmission of information<br\/>to the setting of quantum mechanics. It has applications in cryptography,<br\/>and also relates to the promising area of quantum computing. The theory of<br\/>description complexity has been useful in clarifying concepts of classical<br\/>information theory. The research extends description complexity theory in<br\/>order to help study the much more complex questions of quantum information<br\/>theory.<br\/><br\/>In the scheduling problem, given are the sample paths of two or more random<br\/>processes (like queues) and some condition telling when these processes<br\/>``collide''. The task is to introduce delays into each of the processes in<br\/>a way that avoids collisions. Reformulation introduces a dependent<br\/>percolation model with novel convergence properties that aroused much<br\/>interest. The principal tool of the solution is renormalization, greatly<br\/>refined. The achieved results are qualitative, leaving much quantitative<br\/>work to be done. In the application of description complexity to quantum<br\/>information theory, a universal semicomputable density matrix (``universal<br\/>probability'') is taken as a starting point, and complexity (an operator)<br\/>is defined as its negative logarithm. A number of properties of Kolmogorov<br\/>complexity and von Neumann entropy extend naturally to the new domain, and<br\/>the quantity reflects appropriately some of the peculiarities of quantum<br\/>information (no cloning). The approach taken unifies other approaches made<br\/>by several researchers in this direction.","title":"Scheduling of Random Processes and Quantum Information","awardID":"0208879","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[186675],"PO":["499399"]},"75071":{"abstract":"Recent technological advances have led to the emergence of sensor networks that integrate small, low-power sensors and actuators with limited on-board processing and wireless communication capabilities.An example of this type of sensor networks is homeland security at airports, bridges, and public buildings: a large number of low cost lightweight wireless devices is scattered in a geographic region and form a surveillance and communication network.Its major function is to locate and track unusual sounds in the region.These wireless devices are equipped with acoustic sensors and can locate a sound wave.They have to organize themselves dynamically, and<br\/>convey the location information within a time frame that allows the controller to take necessary action, even in the case of poor spatial distribution of sensor devices, wireless\/acoustic interference, and malicious destruction. Out-of-date information is of no use, as the object that was tracked may no longer be in the vicinity when the information is received.This presents a key technical challenge in cooperative engagement how to effectively coordinate and control sensors over an unreliable wireless ad hoc network and is the focus of this proposal.<br\/>Specifically, the researchers propose an integrated framework in which a comprehensive solution can be designed with a set of component solutions to achieve the targeted goals.Then the resesarchers propose to carry out tasks along the following five research avenues:<br\/>A unified framework for designing, and reasoning the effectiveness of, sensor networks: the researchers survey several application scenarios of data-centric, application-oriented sensor networks, define an abstract problem for information dissemination in sensor networks, and identify a set of requirements and objectives. Then, the researchers configure the required functionalities into modules in\/across layers, and figure in their functional dependency.Under this unified framework, one can design protocols specific to a layer without negligence of their interaction, and compatibility, with protocols in other layers.Also, cross layer issues can be identified and appropriately addressed.<br\/>Hierarchical cluster formation and routing: Due to the unique characteristics of data-centric sensor networks, the researchers believe topology in the form of hierarchical cluster structure offer the greatest performance benefits.Also, as the information collected by various sensors may be correlated, redundant, and\/or of different qualities, this structure facilitates digests of sensor data. The researchers propose to develop, and rigorously prove its optimality of, a decentralized cluster formation scheme that captures and utilizes these unique characteristics. The researchers will also exercise motion control of mobile routers\/base stations to effectively recover network partition and\/or to relieve communication bottlenecks.<br\/>Topology control and power management: The researchers consider, in conjunction with the hierarchical cluster formation scheme, how to exercise power management so as to maintain network connectivity, optimize spatial network reuse, and mitigate MAC-level interference.This is achieved by (i) powering off sensors that are not relay nodes when there are no events; and (ii) devising strategies for setting (a set of) minimal transmission powers when sensors are not evenly distributed.Again tasks in this avenue will be carried out with a rigorous theoretical base.<br\/>MAC design for timely dissemination of delay-sensitive data: The researchers address several medium access issues: (i) how to mitigate medium contention to improve short-term and long-term throughput fairness, (ii) how to incorporate well-grounded scheduling policies in MAC to achieve temporal QoS within\/between clusters, and (iii) how to tradeoff throughput for delay when real-time messages are involved.<br\/>Empirical study with the use of Motes: To validate the design and to empirically study the overall performance, the researchers will leverage the tiny wireless sensors, Motes, and construct a sensor network testbed. As Motes are rather limited in their processing and communication capability, the researchers will integrate Motes with MOPS\/520 PC104 boards.This is realized by attaching a Mote to the PC board and use the Mote's serial peripheral interface (originally for synchronous data transfer between the Atmega 163 processor in Motes and peripheral devices) for data transfer between the two boards.The researchers will also simulate acoustic sensor behaviors by using the sound cards and microphone on the PC104 board.With such a sensor network testbed in place, the researchers will be able to implement and experiment with the proposed protocols and algorithms. The researchers plan to simulate homeland surveillance where acoustic sensors can give clues to guards who watch close circuit TVs.","title":"Data Centric Sensor Networks","awardID":"0221357","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["541861","553686","342042"],"PO":["543507"]},"71090":{"abstract":"ABSTRACT<br\/><br\/>The establishment of unlicensed communication bands has successfully encouraged innovation, most recently in wireless devices and infrastructure that use unlicensed spectrum to provide connections to the Internet. A key aspect of Internet usage is an almost unlimited capacity for growth. For unlicensed wireless, the transition from 11 Mb\/s 802.11b to 54 Mb\/s 802.11a marks the start of an industry race toward ever-higher data rates. The combination of increasing data rates and a proliferation of devices could easily lead to inefficiency in the use of unlicensed spectrum due to a combination of overuse and failure to develop mechanisms for efficient sharing of this resource. While the overload of any finite band may be inevitable, this project is addressing the increase in capacity of the available unlicensed bands as much as possible, and is developing approaches that can predict overloads and prevent sudden, unexpected failure modes.<br\/><br\/>This multi-disciplinary project seeks efficient use of unlicensed spectrum by combining an engineering and technology perspective with insights from the literatures on regulation, property rights, and economic coordination. The team includes researchers with expertise in property rights, networking fairness, and wireless communications and network engineering. This team is developing a general framework for understanding cooperation in unlicensed band wireless networks by studying the following issues:<br\/><br\/> Property rights as applied to spectrum management<br\/> Protocols for collaboration between technology neutral wireless devices<br\/> Pricing mechanisms for efficient and fair sharing of congested unlicensed spectrum<br\/> Radio-level interference avoidance techniques<br\/><br\/>The above problems are being studied with a combination of formal and conceptual analysis, simulation and experimental methods, including a dynamic spectrum management testbed which implements potential collaboration protocols and cooperation models. The thrust is to preserve the \"creative chaos\" of the unlicensed bands while creating a degree of long term stability and predictability that is appropriate to the size of the investments being made and the strategic importance of these uses to the nation. Results from the project are of value to both policy makers and emerging unlicensed band wireless Internet providers as well as wireless technologists.","title":"ITR: Collaborative Research: Achieving Innovative and Reliable Services in Unlicensed Spectrum","awardID":"0205281","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["426324","374337"],"PO":["348215"]},"72080":{"abstract":"This project investigates spoken language systems for the elderly and non-native speakers of English. Existing systems have been constructed for the average user and thus perform poorly for these nontraditional populations. The elderly have little access at present to computerized information, yet they have telephones that would enable them to access computers easily if the information were presented in a way that they could readily understand. Non-native speakers have difficulty being understood by the same dialogue systems, which need to be adapted to their speech and aid them in finding the correct way to express themselves. In order to improve the understandability of spoken output, Let's Go will investigate differences in lexical, prosodic and spectral content to enable elderly and non-native listeners to better understand the message. In order to improve spoken input, the project will explore adaptation of the statistical models of the lexical and acoustic information of the incoming speech signal for the target populations. Let's Go will assess the pertinence of its findings by creating a spoken language demonstrator that allows elderly and non-native users to access Port Authority Transit Bus information over the telephone.","title":"LET'S GO: Improved Speech Interfaces For The General Public","awardID":"0208835","effectiveDate":"2002-09-15","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["561898","396893","409821"],"PO":["565227"]},"67361":{"abstract":"A fundamental fact in computer and network security is that there never can be a one hundred percent assurance that a computer system is trusted. The term trusted is used heavily in Computer Security. Unfortunately, the term has several definitions depending on who uses it and how the term is used. Throughout this proposal, a definition which is a slight modifications of Peter Neumann's, is used. Based on this definition, an object is defined as trusted when the object always operates as expected according to design and policy. A stronger trust statement is when an object is trustworthy. A trustworthy object is one that has been shown in some convincing manner, e.g. a formal code-review or formal mathematical analysis, to operate as expected.<br\/> Ken Thompson described very clearly one of the many issues involved in determining if a system is trusted in his Turing Award speech in 1984. For over twenty-five years, the security community has focused on technology, and yet information systems remain as vulnerable as ever (perhaps more so). However, a significant improvements in security lie in another area-the secure management of technologies and the systems that implement them. In this proposal, the PI demonstrates the need for intensive research on the secure management of distributed heterogeneous networks and systems, and describes a novel research plan using active system management to address this area.<br\/> The tremendous growth of the use of information technology has exacerbated the problem of effectively managing and securing the resultant information infrastructure. This coupled with the fact that the current state of the art in security is essentially \"penetrate and patch\" has created a situation where information technology is more vulnerable than ever. The vulnerability of information technology is demonstrated by the large number of news stories relating to wide-spread computer intrusions and network scanning that are published each week. The big question is \"how do we improve the situation?\"<br\/> While studies, anecdotal evidence, and press reports have demonstrated the increasing vulnerability of information technology, information security research is currently primarily focused on the underlying security technology rather than the secure management of the information technology. Yet, the tremendous growth in the use of information technology and its rate of change creates a configuration and system management nightmare that amplifies existing security problems. Unfortunately, current approaches for solving this complex problem are ad hoc, do not scale, and have not focused on security.<br\/> In this research, the PI proposes a broad examination of distributed heterogeneous configuration and security management of network elements and hosts from both a theoretical and a systems approach. The proposed research provides the formalism, mechanisms, and protocols so that enterprises can implement and utilize a very small, or quick, management loop, i.e. the tools to allow the defenders to react faster than the attackers. Doing so eliminates one of the principle advantages of attackers, and dramatically increases the work factor of successful attacks- providing one of the first real improvements in computer and network security.","title":"CAREER: Active System Management","awardID":"0133092","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["467998"],"PO":["565090"]},"68374":{"abstract":"0137761 <br\/>Mishra, Mina<br\/>Stanford University<br\/>ADVANCE Fellows: Data Mining Algorithms for Business Intensive Applications<br\/><br\/>This proposal, framing business intelligence applications as concrete theoretical problems, develops data mining techniques for applications in customer management, wireless mining, and product affinities. The work, studying clustering measures, alternate embedding techniques, and computational complexity, involves designing computationally efficient algorithms that find approximately good answers. The scalability and I\/O efficiency of proposed algorithms will also be studied. Two problems are mentioned for: (1)Identifying wireless communities and product affinities: the Maximum Edge Bi-clique problem and<br\/>(2) Customer segmentation, text clustering, new clustering measures that combine inter and intra distances: <br\/>the Conjunctive Clustering problem. The algorithms can be applied to various areas, including e-commerce. Results from this work are expected to impact (3) Customer relationship management by segmenting the customer population to target marketing programs more effectively and (4)Cell phone usage data to enable wireless companies to discover patterns in wireless access.","title":"ADVANCE Fellows Award","awardID":"0137761","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1681","name":"ADVANCE - FELLOWS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[176980],"PO":["564181"]},"71080":{"abstract":"Our ability to capture human motion data has increased dramatically<br\/>making possible human motion databases that can support creative and<br\/>educational endeavors such as training of athletes, diagnosing and<br\/>treating motion disorders, and preserving our cultural heritage. To<br\/>have an impact, however, motion databases must be accessible to a wide<br\/>audience, including children and adult users with little programming<br\/>experience. During the time frame of this project, we will undertake<br\/>an exploration of a performance-based interface for a human motion<br\/>database. The interface will allow the user to act out the desired<br\/>motion and will require comparing time sequence data from the performance,<br\/>perhaps with missing or noisy entries, to time sequence data in the<br\/>database.<br\/><br\/>Retrieval techniques must compute the distance between a sample and<br\/>arbitrary motion subsequences in the database, making brute force<br\/>techniques prohibitively expensive, particularly for interactive<br\/>performance. Algorithms for dimensionality reduction, feature<br\/>transformations, and automatic segmentation will be implemented,<br\/>distance functions will be compared both quantitatively and via user<br\/>studies, and the performance of these algorithms with missing data will<br\/>be assessed. The research will be evaluated with traditional database<br\/>retrieval evaluation techniques and through observation and analysis of<br\/>users of the interfaces.","title":"ITR: Providing Intuitive Access to Human Motion Databases","awardID":"0205224","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["517101","438709","548220","233332","560865"],"PO":["469867"]},"71091":{"abstract":"EIA-0205286 David A. Wood University of Tennessee ITR: SafetyNet: Synergist Support for Availability, Designability, Programmability, & Performance<br\/><br\/>Information services, supported by remote server computers, are becoming part of society's essential infrastructure for commerce, science, education, and government. Many servers are shared-memory multiprocessors that multiply the 60-fold single-processor performance improvements of the last decade by an additional factor of two to 64. These incredible performance improvements are putting increasing pressure on sever designs to improve complementary computer properties, such as:<br\/><br\/>Availability. Society needs information services that are as dependable as our electricity and fresh water supplies. Unless new architectural techniques are developed and applied, however, server availability will go down with time, since deep submicron transistors are less reliable (and more susceptible to radiation) and future servers will employ more transistors, offering more failure opportunities.<br\/><br\/>Designability. Designability is the challenge of deploying a completely correct computer. Getting the bugs out of today's computer systems is expensive, in both manpower and time, and getting worse as the transistor bonanza enables more complex designs. Furthermore, unpredictable delays leave expensive manufacturing facilities underutilized and cost 5% performance per month (due to Moore's Law).<br\/><br\/>Programability. Servers typically run multi-threaded software to turn their raw computing power into high-throughput information services. Unfortunately, hard-to-test races make writing such software a challenge that stresses current programming practices and leads to bugs in deployed software. Hardware that facilitates rapid development of robust software should be prized.<br\/><br\/>Performance. Solutions that improve availability, designability, and programmability will more likely flourish if they have, at most, a modest impact on cost-performance. Better yet would be hardware that actually improves performance, in addition to the other properties.","title":"ITR: SafetyNet: Synergistic Support for Availability, Designability, Programmability, & Performance","awardID":"0205286","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["541915","541916"],"PO":["551712"]},"74490":{"abstract":"0218938<br\/>Janet L. Kolodner<br\/>Georgia Institute of Technology<br\/><br\/>Title: \"Tools for Promoting Productive Reflection in Science Learning \"<br\/><br\/>This project builds on this institution's prior successes with an educational software system called SMILE. This system provides structuring and prompting for students working in small groups or as individuals as they are getting ready to carry out project-based activities and as they are interpreting results and making sense of whole-class discussions. It builds on discussions about the \"how-to's\" of carrying out activities in class and reminds students what to pay attention to. The software suite, SMILE, includes tools for planning and reporting on several kinds of investigative activities, for reporting on and justifying design ideas, for reporting on and explaining design experiences, and for carrying on conversations across classrooms about each. SMILE's intentions are (a) to help students be productive while working in small groups and (b) to provide the kind of help that will make students presentations to the class more articulate and understandable by their peers. The goals of the current project are: 1) to investigate the hypothesis that relatively simple general-purpose software can be used to promote sophisticated reasoning among students about both content and process and that that same software is useful to teachers in providing them the kinds of reminders that help them better facilitate the kinds of reflective reasoning that result in transfer (a) in the contexts of both Learning By Design and more general-purpose project-based inquiry science classrooms, (b) across a variety of science disciplines, (c) across a variety of grade levels, and (d) possibly, in project-based contexts outside of science (e.g., math, social studies), 2) to iteratively extend the reach of the software tools already designed and constructed to make them more capable and to make them applicable to a larger variety of project-based contexts, 3) to develop guidelines for productive design and use of tools in support of planning and reflection in project-based inquiry classrooms, and 4) to develop teacher materials and disseminate software on the web. This institution's experiences with Learning by Design have contributed to understanding the ins and outs of creating opportunities in the project-based inquiry classroom for the kinds of reflective experiences that lead to lasting learning. This current project will provide additional insights and tools that may be of value in the broader educational community.","title":"ITR\/EHR: Augmenting Individuals: Tools for Promoting Productive Reflection in Science Learning","awardID":"0218938","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["562669"],"PO":["551712"]},"79561":{"abstract":"EIA 02-42822<br\/>Wolff, Lawrence B.<br\/>Johns Hopkins University <br\/><br\/>CISE RI: A Networked Computing Environment for the Manipulation and Visualization of Geometric Data <br\/><br\/><br\/>This project, enabling the RI\/MII PI Workshop, strengthens the national computing infrastructure by supporting exchanges on infrastructure development needs of research. The meeting serves to judge the effectiveness of the awarded infrastructure and awarded research carried upon such infrastructure, as well as their impact on research and education. Facilitating face-to-face contacts and exchanges of ideas, the conference serves as a tool for the principal investigators to judge their own work and that of others awarded. In addition to research exchange, often the PIs gain insights as to where to recommend students to pursue graduate studies and even what universities to apply that best might service their new PhD degree, and alternately, where their research might have the most influence.","title":"CISE Research Infrastructure: A Networked Computing Environment for the Manipulation and Visualizatiion of Geometric Data","awardID":"0242822","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":[207142,"218093"],"PO":["557609"]},"67483":{"abstract":"Computational complexity is the study of the inherent difficulty of<br\/>computational problems. The theory considers various models of <br\/>computation, such as classical computers, probabilistic computers, <br\/>and quantum computers. For each of these, it aims to describe how many <br\/>resources are needed to compute the solution to a problem as a function<br\/>of the problem size.<br\/><br\/>The most prominent open question in complexity theory is whether the<br\/>ability to efficiently verify the validity of a candidate solution <br\/>implies the ability to efficiently compute a valid solution (assuming<br\/>one exists). The question is usually stated in terms of the <br\/>corresponding classes of computational problems: Is NP contained in P? <br\/>Lots of computational problems from virtually any discipline fall in<br\/>the class NP but are not known to be in P. Therefore, a positive answer <br\/>to the P versus NP question would have tremendous algorithmic implications. <br\/>It would also imply a way to break any public-key cryptographic system, <br\/>as the security of such systems rests on the assumption that a particular <br\/>problem in NP does not belong to P.<br\/><br\/>This research project aims to develop techniques for determining the <br\/>relationships between complexity classes like P and NP: separations <br\/>and inclusions. On the separation side, the investigators focus on <br\/>techniques that do not suffer from the known pitfalls of relativization <br\/>and natural proofs. In particular, they concentrate on indirect <br\/>diagonalization and exhibiting distinguishing properties of complete <br\/>problems. On the inclusion side, the emphasis lies on efficient <br\/>classical simulations of time and space bounded probabilistic and <br\/>quantum computations.<br\/><br\/>The educational goal consists of the development of graduate courses <br\/>on pseudo-randomness and derandomization and on quantum computing. At <br\/>the undergraduate level, the investigators plan to further the <br\/>integration of discrete structures in the core curriculum.","title":"CAREER: Techniques for Separations and Inclusions of Complexity Classes","awardID":"0133693","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["565082"],"PO":["499399"]},"71180":{"abstract":"This project will develop a new, integrative theory of software problem management by studying software<br\/>problems in their ongoing sociotechnical contexts. The researchers willcomparatively analyze large bodies (gigabytes) of longitudinalproblem-report data from open-source software development projects such as networked computer games, Internet\/Web infrastructure, X-ray astronomy\/deep space imaging, and academic software research, using grounded-theory and automated concept, data, and text-mining<br\/>methods. The project will analyze instances of (mis-)alignment between software artifacts, problem episodes, problem-management activities, problem-management infrastructure, and underlying social<br\/>organization. Explanatory models will be built by linking patterns of (mis-)alignment among these elements to outcomes such as ease-of-repair, persistence of problems, amount of information exchanged, kinds of skills needed, and structure of social organization. The resulting models can guide the development of new<br\/>tools, infrastructures, and organizational practices for software. They will also provide new perspectives on community-wide practices of capturing and managing knowledge. This research will provide a conceptual shift in understanding how system development and use are bound together with the richness, variety, and temporal evolution of the socio-technical contexts provided by the global software industry.","title":"ITR: Collaborative Research: Organizational Dynamics of Software Problems, Bugs, Failures, and Repairs","awardID":"0205679","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V050","name":"NSA-WORLD RENOWNED EXPERTS FRO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V463","name":"NSA-MEIDS PROJECT"}}],"PIcoPI":["535599"],"PO":["564456"]},"71070":{"abstract":"EIA-0205181 J. Tinsley Oden University of Texas, Austin ITR\/AP: A COMPILATION INFRASTRUCTURE FOR RELIABLE COMPUTER SIMULATIONS<br\/><br\/>The research of this project will develop mathematical and computational processes for validation analogous to those used for verification and evaluate these processes by actual and computational experiments. At the core of the proposed integrated framework for verification and validation lies the concept of hierarchical modeling. Hierarchical modeling is a systematic coarsening of mathematical models from a base model which is known a priori to contain all of the information, which can be extracted from a given experiment to within quantifiable bounds. The goal is to determine, by introducing approximations into the base model, the computationally simplest model which contains the information content of the experiment. This process requires an ability to evaluate the error introduced by each approximation to the base model, a capability for capturing the semantic content of both models and experiments, a capability for comparing the information content of the experiments and simulations and a capability for implementing a family of computational systems implementing the sequence of models so that the conceptual process can be realized and evaluated.","title":"Itr\/ap: A Computational Infrastructure For Reliable Computer Simulations","awardID":"0205181","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["510448","485474"],"PO":["301532"]},"71191":{"abstract":"Mark P. Jones and Richard B. Kieburtz<br\/>CCR-0205737<br\/>\"Advanced Programming Languages for Embedded Systems\"<br\/><br\/>Over the last few decades we have witnessed remarkable changes in the way that computers are both used and programmed. For example, many of the computers in use today are hidden in embedded systems. From everyday appliances---such as washing machines and televisions---to safety and security critical systems---such as vehicle navigation and control, defense applications, or medical devices---the use of embedded computers allows manufacturers to build systems with much greater flexibility,<br\/>functionality, and sophistication than has ever been possible before.<br\/><br\/>During the same time, new programming languages have been developed with features that increase developer productivity and allow the construction of produce more reliable and flexible systems. For example, module systems help to manage the complexity of large projects, type systems can be used to detect bugs at compile-time, and automatic storage management techniques eliminate a common source of errors.<br\/><br\/>In industry, however, much of the embedded software that is being developed today is still written using older languages, or lower-level assembly languages, without the benefits that modern languages can provide. The problem is that the results and focus of recent programming language research have not been a good match for the challenges and context of embedded systems development. As a result, where some might have expected embedded systems developers to embrace modern programming languages, it might seem instead that many have chosen to ignore them!<br\/><br\/>One source of problems arises from difficulties in capturing so-called non-functional aspects of behavior---such as execution time, power consumption, and adaptivity---that are critical requirements for many embedded systems. Unfortunately, these are exactly the kinds of things that language designers have abstracted away from in the hope of increasing productivity and portability. Other difficulties occur as the result of complicated treatments of features such as concurrency and event handling, which again play a central role in many embedded applications. Significant bugs can occur if programmers do not adhere to a carefully worked out discipline of coding when they use such features, but there is very little that the underlying type system or semantics can do to help in detecting these problems.<br\/><br\/>This project is working to bridge the gap between these two important fields, and to demonstrate how embedded systems development can benefit from and inform programming language research. In particular, the project is focusing on the ongoing development and use of a high-level language called Timber that supports an implicit notion of concurrency, asynchronous communication, and non-blocking, reactive programming. All of these features are directly relevant in the context of embedded systems design. In addition, the project is developing new analysis and compilation techniques that enable non-functional aspects of behavior to be specified using high-level constraints and policies for graceful degradation. Because they are specified at a high level, these constraints can continue to serve as meaningful descriptions of required<br\/>behavior, even as programs evolve to accommodate new functionality or to support new platforms. The key to success is a declarative approach in which programmers focus on what is required, while compilers determine how it should be accomplished, using the results of analysis to guide the selection of an appropriate, low-level implementation strategy.<br\/><br\/>With the transition from research to industry in mind, the project is focusing on tools for PC\/104 systems, which is an industry standard and an important sector in today's embedded systems market. In the longer term, the project is contributing to shifts in attitude and beneficial changes in the role that programming language technology can plays in the delivery of more widespread, more flexible, more reliable, and more secure embedded systems.","title":"ITR: Advanced Programming Languages for Embedded Systems","awardID":"0205737","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["40586","485861"],"PO":["561889"]},"72291":{"abstract":"This research project is funded in response to the Nanoscale Science and Engineering Initiative, NSF 01-157, category NIRT. Nanorobotics is concerned with (1) manipulation of nanoscale objects by using micro or macro devices, and (2) construction, control and programming of robots with overall dimensions at the nanoscale (or with microscopic dimensions but nanoscopic components). This project covers both of these aspects, because both are important: nanomanipulation is the most effective process developed until now for prototyping of nanosystems, and nanorobots with dimensions comparable to those of biological cells are expected to have revolutionary applications in environmental monitoring and health care-for example, in the early detection and destruction of pathogens. The initial research will be biased towards manipulation, with a focus on the automation of techniques developed in previous NSF grants for reliable and accurate nanomanipulation by using the tip of a Scanning Probe Microscope (SPM) as a sensory robot. Work on nanorobot construction will begin at a low level but increase as the project evolves. It will integrate research on sensors, actuators, control, power, communications, and interfacing across spatial scales and between organic\/inorganic as well as biotic\/abiotic systems. <br\/><br\/>The theoretical and experimental results of this work will contribute to the understanding of robotics in domains with large spatial uncertainties, and to the development of NEMS (Nanoelectromechanical Systems). The software will be widely distributed and will be very useful to scientists and engineers working in nanomanipulation and nanolithography. The project will involve students at all levels, from postdocs to minority high-school students, who will be exposed to this new and interdisciplinary field. The research will be further coupled to education through conference tutorials and new, regular university courses. For example, a graduate course in nanorobotics offered in the Spring semester of 2002 will evolve by incorporating the research findings of the project, and a tutorial based on the course will be offered at the 2002 IEEE conference on nanotechnology.","title":"NIRT: Nanorobotics","awardID":"0209678","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5980","name":"WESTERN EUROPE PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}}],"PIcoPI":[187175,"422070","539842"],"PO":["564651"]},"72093":{"abstract":"Conditional branches are expensive. Branches require a significant<br\/>percentage of the execution cycles since they occur frequently and can<br\/>cause pipeline stalls. In addition, branches result in forks in the<br\/>control flow, which can prevent other code-improving transformations<br\/>from being applied. We plan to develop path profile-based techniques<br\/>for replacing the execution of a set of two or more branches with a<br\/>single branch on a conventional scalar processor. We propose to<br\/>improve performance by merging the conditions of two or more branches<br\/>into a single condition. Previous approaches have accomplished<br\/>such merging of conditions that have either only involved a single<br\/>variable or have required special hardware to merge multiple<br\/>conditions together. Techniques will be developed to produce a merged<br\/>condition involving multiple variables that can be used to bypass the<br\/>code testing the original set of conditions on a conventional processor.<br\/>Merging conditions may be very good fit for run-time optimization<br\/>systems, which optimize frequently executed paths during the execution<br\/>of a program.","title":"Collaborative Research: Branch Elimination by Condition Merging","awardID":"0208892","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["537231","554071","537233"],"PO":["565272"]},"75393":{"abstract":"This research explores perception of task-level information from kinesthetic sense data in mobile manipulation tasks. A mobile manipulator interacts with the terrain through its feet or wheels, and it interacts with fixed or mobile objects through its hands, wheels, bumpers, or other effectors. All of these interactions contribute to the robot's motion and to internal shape deformations of the robot, which can be detected by encoders, strain gauges, and other sensors. This kinesthetic sense data can be used to estimate features of the terrain, locations of objects, location of the robot, contact state between the robot and objects, and other task variables. This project is developing a theory of task-level kinesthetic perception, by developing suitable models of task and robot dynamics, and using the framework of nonlinear observability to analyze specific tasks and develop algorithms for estimating task parameters and state variables. Experimental work includes evaluation of several mobile manipulator designs, implementation and testing of observers, and demonstration in mobile manipulation tasks.","title":"Task-Level Perception From Kinesthetic Sensors","awardID":"0222875","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":[196088,"560864"],"PO":["335186"]},"77461":{"abstract":"This project will address the interplay among various robotic control and networking problems focusing on the issue of teleautonomy. The research addresses both the problems of remote assembly with minimal human intervention and direct teleoperation. Both (semi-)autonomous and teleoperated systems as described herein will be important to realize the goal of assembling and operating Space Solar Power (SSP) systems. For systems in earth orbit and for human coordination of multiple networked robotic systems, direct teleoperation is a viable and attractive option, while greater autonomy is crucial for more remote assembly systems, such as lunar based systems where longer time delays make direct teleoperation difficult. A significant level of autonomy, i.e. local intelligence, will also be required due to the possibly unreliable communication networks over which these systems will be controlled.<br\/><br\/>The present research seeks to integrate robotic control algorithms with communication networking research, along with issues associated with projecting and magnifying human capabilities to facilitate assembly in space structures. The technical issues include bilateral teleoperation, the reliability of the communications links, and the coordination of complex assembly tasks. Bilateral teleoperation will be studied using passivity-based nonlinear control along with logic-based switching control. The reliability of the communication links will be studied to mitigate the effects of unknown and time-varying delays and to incorporate recent ideas from networked control systems (NCS). Finally the issue of coordination will be studied using concepts from statistical learning theory that borrow and generalize ideas from Internet protocols.<br\/><br\/>More broadly, this research will have important applications beyond teleautonomous robotic systems. We expect to contribute to the growing area of networked control systems, to incorporate our research in areas such as control in hazardous and remote environments, surveillance, search and rescue robots, autonomous vehicles and autonomous locomotion systems, haptic devices, remote construction, and remote surgery.","title":"Collaborative Research: Teleautonomy in Networked Robotic Systems","awardID":"0233314","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"W415","name":"NASA-SSP"}}],"PIcoPI":["474699"],"PO":["335186"]},"67451":{"abstract":"The goal of this project is to develop a methodology for analyzing the wealth of information captured by imaging sensors that densely sample visible light. Methods will be developed for automated selection of an \"ideal\" set of filters for multi-spectral imaging. Algorithms will be explored for accurate interpretation and recreation of scenes with complex light interaction, in particular in the high-dimensional spectral domain. Techniques for extraction of geometric and photometric invariants from video images will be studied, and novel algorithms will be generated for visualization of \"invisible\" spectral information. The project's education component includes development of new cross-disciplinary undergraduate and graduate courses, appropriate modification of existing courses, and hands-on approach to coursework and research projects.","title":"CAREER: Exploring the Multispectral Frontier in Computer Vision","awardID":"0133549","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7339","name":"COMPUTER VISION"}}],"PIcoPI":[174830],"PO":["317663"]},"68221":{"abstract":"Accurate network traffic measurement is required for accounting, bandwidth provisioning, and detecting DOS attacks. However, keeping a counter to measure the traffic sent by each of a million concurrent flows is too expensive (using SRAM) or slow (using DRAM). The current state-of-the-art (e.g., Cisco NetFlow) methods which log periodically sampled packets are slow, inaccurate, and memory-intensive. This proposal introduces a paradigm shift by concentrating on the problem of measuring only \"heavy\" flows | i.e., flows whose traffic is above some threshold such as 1% of the link. After showing that a number of simple solutions based on cached<br\/>counters and classical sampling do not work, the resarchers describe two novel and scalable schemes for this purpose which take a constant number of memory references per packet and use a small amount of memory. Further, unlike NetFlow estimates, we have provable bounds on the accuracy of measured rates and the probability of false negatives. The researchers propose to implement, evaluate, and fine-tune these new ideas. Using these ideas as a basis, the researchers also propose to investigate the following questions. First, they will investigate a new form of accounting called threshold accounting in which only flows above threshold are charged by usage while the rest are charged a fixed fee. Threshold accounting generalizes the familiar notions of usage-based and duration based pricing. Second, they propose to investigate a more general question: the computation of flow statistics at very high speeds using very small amounts of high speed memory. Examples of other potentially useful flow statistics include the number of flows, the standard deviation of flow sizes, the average duration of a flow etc. Naive algorithms to measure such quantities all scale linearly with the number of flows. Finally, with colleagues at CAIDA, the researchers plan to deploy our algorithms in real-time on 5 traffic monitors placed at strategic Internet sites (AIX, the UCSD backbone, and possibly on Abilene). The potential impact of this proposal is the development of novel and practical tools for accounting, measurement, and security. These are three central problems as the Internet transitions from a research network to a commercial enterprise.","title":"New Directions in Accounting and Traffic Measurement","awardID":"0137102","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["438592","538350"],"PO":["7594"]},"71170":{"abstract":"When humans interact with each other and their environment, there are breakdowns that naturally result due to the mismatch in their understanding of the current situation. This is often exacerbated by computers because they only have a minimal understanding of human dialogue and interaction. The breakdowns can be smoothed out by making computers more aware of the physical and social contexts they are a part of. This project seeks to investigate user-centered methods and technologies to assist designers and developers in the design, prototyping, and evaluation of real-world context-aware applications, focusing on issues that have yet to be addressed, including usability, privacy, and scalability. This work focuses on (1) exploring new user-centered methods and tools for designing, prototyping, and evaluating context-aware applications, (2) understanding the nature of privacy concerns with respect to context-aware systems and developing mechanisms for addressing these concerns, and (3) providing an infrastructure to help programmers to build these applications for a large number of users and sensors. This work will be evaluated by developing two socially relevant applications: (1) emergency response support for coordinating, communicating, and allocating resources, and (2) an augmented wheelchair providing word prediction for individuals with motor impairments","title":"ITR: Human-centered Design of Context-aware Computing: Scalability, Usability and Privacy","awardID":"0205644","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["409023","483342","518044","532662"],"PO":["565227"]},"71181":{"abstract":"Because of the relentless march of the silicon-based electronics technology as predicted by Moore's Law, computation, storage, and communication are now woven into the fabrics of our lives. The emerging technology of flexible electronics, where electronics components such as transistors and wires are built on a thin flexible material, offers a similar opportunity to weave computation, storage, and communication into the fabric of the very clothing that we wear. The implications of seamlessly integrating a large number of communicating computation and storage resources, mated with sensors and actuators, in close proximity to the human body will transform many aspects of biomedical research and practice. For example, one can imagine biomedical applications where biometric and ambient sensors are woven into the garment of a patient or a person in a medically-critical or hazardous environment to trigger or modulate the delivery of a drug.<br\/>To realize this vision outside the laboratory, radical innovation is required in the area of system-level information technology. These systems will not scale to widespread use if they are viewed simply as traditional chips or motherboards based on a different, flexible form factor. Rather, a rethinking of the architecture and the design methodology for all layers of these systems is needed. The reasons are two-fold. First, the underlying technology of electronics in flexible materials has characteristics and computation-communication cost trade-offs that are very different from that of silicon and PCB-based electronics. Second, the natural applications of these systems have environmental dynamics, physical coupling, resource constraints, infrastructure support, and robustness requirements that are very different from those faced by traditional systems. <br\/>One of the challenges in developing the needed information technology architecture and design methodology for these systems is that one needs to both conduct experimental work and develop a conceptual understanding of the problem domain. This research studies: <br\/> Application: Use as a driver application capability, reconfigurable fabric (R-Fabric) based on a combination of (i) the technology of flexible electronics using organic materials, and (ii) computing, communication, and sensing elements implemented as E-Buttons.<br\/> Architecture: Develop the general architecture concepts and cost\/performance optimization techniques. The issues that we will focus on will include (i) appropriate primitives for composing the architecture, (ii) system interconnect network optimized for the electrical characteristics of the organic electronics, (iii) techniques to cope with the high ration of communication to computation cost, and (iv) architecture level self-configuration and re-configuration for robust operation.<br\/> Programming: Develop techniques and primitives for programming a system composed of hundreds of computation, storage, sensing, and actuation elements that are individually resource constrained and are connected by a structured but fault-prone high-cost interconnect network.<br\/> Processors: Develop domain-specific processor architecture optimized for these power-constrained, physically coupled applications.<br\/><br\/>Design Methodology: Develop techniques and hybrid emulation platform for systematic architecture exploration, simulation, optimization, and reconfiguration of these systems.","title":"ITR: Reconfigurable Fabric","awardID":"0205682","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["560926","547185","555996","515835","417551"],"PO":["561889"]},"74591":{"abstract":"The problem of developing efficient automated systems of logical<br\/>inference is a key step toward the dream of creating verifiable,<br\/>reliable, and secure hardware and software systems. This research is<br\/>aimed at developing a well-founded, unified theory of practical<br\/>logical inference, that combines complementary ideas and powerful<br\/>approaches for propositional inference developed in AI, formal<br\/>verification, and theoretical computer science.<br\/><br\/>This unified theory will focus on (ii) combining the different<br\/>representations used in the various approaches to propositional<br\/>inference, such as Boolean decision diagrams and conjunctive normal<br\/>form, in order to take advantage of the diverse algorithmic techniques<br\/>associated with each; (ii) developing new and improved inference<br\/>algorithms using the combined representation; (iii) precisely<br\/>characterizing the power of various heuristic inference techniques,<br\/>such as clause learning and randomized search; and (iv) developing a<br\/>rigorous understanding of how problem structure indicates the<br\/>potential effectiveness of particular inference strategies.<br\/><br\/>The research will involve theoretical work using methods of proof<br\/>complexity as well as experimental work on logical encodings of both<br\/>real-world verification problems and AI planning problems. The<br\/>ultimate goal research is to significantly expand the size and<br\/>complexity of software and hardware systems that are amenable to<br\/>formal analysis.","title":"ITR: Inference in AI, Verification, and Theory: A Unified Approach","awardID":"0219468","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["550377","517581"],"PO":["564388"]},"65780":{"abstract":"Information is currently accessed and manipulated using a variety of fragmented tools. The researchers use a desktop computer as our primary information tool, a server, network of servers, or an ISP to provide file system support, computationally intensive computing, and other system support functions. They use a notebook computer, which may or may not have network access, when they desire a portable information tool. When information needs are modest, and mobility needs most apparent, the researchers use a variety of other devices such as handheld computers, personal digital assistants, cellular telephones, and pagers. Software version management in this situation is inefficient, and licensing is complex. Ensuring that the same (and latest) version of each desired application program is installed on a large number of computers can consume a significant amount of system support staff resources, even if these computers are accessible from the same network. The protection of information from unauthorized access is similarly difficult.<br\/><br\/>The result of this fragmentation of data, applications, and devices is an increasingly complex and unmanageable collection of information tools that communicate with each other ineffectively. The convergence in time of substantial need, substantial communication infrastructure, and high performance, low power computing resources challenges the researchers to explore a better alternative. The Bifrost location independent computing project seeks to provide a flexible and comprehensive information access environment. The function of Bifrost is to provide location and device independent access to data. Data in Bifrost encompasses both information and the applications used to manipulate that information. Bifrost uses affinity between data, and between users and data, to make appropriate decisions about when and where to move data. We refer to this approach as affinity directed mobility.<br\/><br\/>The core research issues of the project are mobility management (how we move data and threads to support user and device mobility), data management (how we represent, access, update, and protect information), and application management (how we provide a common applications base across a variety of devices). In contrast to previous approaches to mobile data management, Bifrost anticipates that in 3-5 years network connectivity will be the norm, even for highly mobile computing devices. In this situation, the problem of how users can access remote personal data, regardless of location or computing device, becomes at least as important as planning for a possible disconnection.<br\/><br\/>The researchers propose to design, implement, deploy and evaluate a two-campus prototype of the Bifrost location independent computing system. The Bifrost design represents a new paradigm for information access and manipulation. We propose to integrate the way in which information is managed with the way in which the applications that access this information are managed. One of the design principles of Bifrost is that the ability to access data should be consistent across all platforms, including portable computing devices. This approach is in stark contrast to the stripped down operating system plus stripped down applications plus limited data set computing model currently associated with most hand-held computing devices.<br\/><br\/>In addition to the educational benefits to the students directly involved in the project, the researchers intend that this project contribute in broader ways to the academic community. They will incorporate this research into the operating systems and distributed systems classes taught at the University of Colorado and Cornell University. All software and other research products of this project will be made readily available via the world wide web.","title":"Collaborative Research: Affinity Directed Mobility for Location-Independent Data Access","awardID":"0125987","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":[170283,"517663"],"PO":["565090"]},"65681":{"abstract":"This project proposes to perform fundamental research on the development of classes of<br\/>distributed control laws and algorithms for optimal traffic engineering in a multiple-<br\/>service enabled Internet. Having its basis on recent results on the use of Sliding Mode<br\/>theory in the context of control of computer networks, the proposed research aims at<br\/>developing decentralized algorithms and tools for optimal traffic engineering in the<br\/>presence of both multiple paths and multiple classes of service. The theoretical<br\/>underpinnings of various traffic engineering algorithms will be developed. It will also<br\/>provide solutions, implementation guidelines to practitioners in the field and also<br\/>valuable input to standardization bodies on the effectiveness of various traffic<br\/>engineering approaches.","title":"Decentralized Traffic Engineering in the Internet: A Sliding Mode Approach","awardID":"0125653","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["553440","282069"],"PO":["565090"]},"75372":{"abstract":"Information-sharing and privacy are fundamentally in tension, and it is important to study the trade-off from both technical and social-contextual perspectives. The emergence of ubiquitous computing opens up radical new possibilities for acquiring and sharing information, but today's methods cannot exploit the possibilites without grave privacy risks. This proposal explores a new methodology that provides much finer control over information exchange: only the information needed for the collaboration is shared, everything else is protected, and protection is provably strong. It is then possible to explore collaborative applications in ubiquitous computing settings that are exciting, but which would be otherwise impossible. Specifically, a class of collaborative applications called ``Ant Club Trails'' (ACT) will be developed. The idea behind Ant Club Trails is to combine information from the ``trails'' left by individual users, and to share it with other users by collaborative filtering in a way which protects individual privacy. The project draws on cryptography, probabilistic reasoning and computational geometry for the development of working ACT systems. It is also guided by sociology and critical theory toward design of socially realistic and desirable systems. The outcome should be better scientific understanding of the information-sharing privacy tradeoff, and a larger landscape of collaborative applications that protect privacy. The broader impacts of the work include: (i) empowerment of communities to share and possibly make a market in community knowledge; (ii) training of research graduate students; and (iii) involvement of undergraduates in developing ACT applications on smart phones.","title":"Ant Club Trails: Privacy and Collaboration in an Ubiquitous Computing World","awardID":"0222745","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["409023"],"PO":["564456"]},"75020":{"abstract":"This award will support approximately 15 students in attending the ACM HotNets-I Workshop being held in Princeton, NJ on October 28-29, 2002. The purpose of the workshop is to bring together researchers in the networking and distributed systems community to debate emerging research directions.","title":"Student Travel Support for ACM HotNets-I Workshop; Princeton, NJ; Oct. 28-29, 2002","awardID":"0221163","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["560046"],"PO":["250082"]},"68871":{"abstract":"EIA - 0139634<br\/>Williams, Frank<br\/>University of Alaska - Fairbanks<br\/><br\/>TITLE: Alaska Research Summer Challenge at the Artic Region Supercomputing Center of the University of Alaska - Fairbanks.<br\/><br\/>The Alaska Research Summer Challenge is an intern program offered by the Arctic Region Supercomputing Center (ARSC) at the University of Alaska Fairbanks (UAF). This program allows up to ten undergraduate students to perform research in the areas of Computer Science, Supercomputing, and Visualization. This minority outreach program is open to students primarily from minority institutions, with preference given to minority applicants. Recruitment is done by onsite recruiting at target institutions. ARSC focus our efforts on these groups, as they have traditionally been underrepresented in the science and research fields. With intern input, each participant is assigned a project related to their field of study, to be performed under the direct supervision of a faculty member or senior staff. Students spend an average of 10 weeks in Fairbanks where they live in campus housing with undergraduate interns from other groups and work an average of 40 hours per week to complete their projects. Under the oversight of the Program Manager, they work independently and within research groups, live in housing with other interns, gain new work and study skills and establish a stronger sense of self-assurance. The program manager ensures that each participant fully understands their project and what is expected of them. Through this program ARSC strives to promote and further interests in many areas of arctic research. The program also serves to develop positive research and life skills while increasing involvement of various minorities in science and research.","title":"REU SITE: Alaska Research Summer Challenge at the Arctic Region Supercomputing Center of the University of Alaska Fairbanks","awardID":"0139634","effectiveDate":"2002-09-15","expirationDate":"2006-03-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["411868","236705",178393,178394],"PO":["281760"]},"79662":{"abstract":"CCR-0215394<br\/>GC: A merger of the workshops on Generative and Component-based Software Engineering (GCSE) and on the Semantics, Applications and Implementation of Program Generation (SAIG) <br\/>Walid M. Taha, Yale University, P.I.<br\/><br\/>This document requests funding in the amount of $9K for a pilot joint event of two previously independent workshops called GCSE and SAIG. Both GCSE and SAIG are forums for publishing research generative techniques. GCSE focuses on generative techniques from the software engineering point of view, and SAIG from the formal and programming languages point of view. The pilot joint event, called the First ACM SIGPLAN Conference on Generators and Components (GC'02) will be held in October 2002, in Pittsburgh, PA. The event will replace GCSE and SAIG this year. If this experiment is successful, the result will be a regular, three-day joint conference bringing the two communities in one consolidated forum.","title":"A Merger of the Workshops on Generative and Component-Based Software Engineering (GCSE) and on the Semantics, Applications and Implementation of Program Generation (SAIG)","awardID":"0243259","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["495365"],"PO":["564388"]},"68222":{"abstract":"The goal of this project is the design of joint power control, rate control, and base station assignment for multimedia wireless networks. Two key aspects of the multimedia network will be considered that have been given short shrift in the past: the requirements of data and system dynamics. The project will consider 4th generation Direct-Sequence Code-Division Multiple-Access (DS-CDMA) networks. The goal is to implement dynamic assignment of downlink transmit power, data rate, and codes to each mobile in accordance with the ability of each application to use the resulting QoS. The focus is on network-wide behavior, and therefore network-wide performance measures will be considered, jointly optimized between physical and networking layers. Three main thrusts will be considered: <br\/>(a) Use of multiple state automata hybrid systems models as a novel tool to control wireless network dynamics. <br\/>(b) Design and analysis of resource allocation algorithms using novel pricing theory. <br\/>(c) Design and analysis of parameter estimation algorithms to achieve robust network behavior. <br\/>The first thrust is intended to provide a powerful tool for generating control algorithms for systems with both discrete and continuous parameters and switching costs. It will be used in this project for controlling power, data rate, and handoffs. The research in this area will extend the dimensionality of a previously studied hybrid systems approach to handoff control. The second research thrust is the construction of joint power control, data rate control, and base station assignment algorithms. This research will be based on economic theory for resource allocation, and implemented using hybrid systems. The final thrust will address the reliance of many resource allocation schemes upon unknown communication parameters such as received SINR. Three investigators will work together: an expert in hybrid systems, an expert in resource allocation, and an expert in multiuser spread spectrum wireless systems.","title":"Collaborative Research: A Hybrid Systems Approach to Resource Allocation for Multimedia Wireless Networks","awardID":"0137103","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["206019","516930"],"PO":["557315"]},"68113":{"abstract":"Encoded video is expected to account for a large portion of the traffic in the Internet of the future<br\/>and next generation wireless networks. The video carried over future networks is expected to be (1)<br\/>coded using heterogeneous encoding schemes, (2) coded at a range of quality levels, and (3) to a large extent scalable encoded (e.g., into several layers) to enable scalable multimedia services over highly heterogeneous networks. To date the traffic characteristics of these heterogeneous and scalable encoded videos are largely unexplored (only a few initial observations based on a small number of short video sequences have been made). Even less is known about the implications of these traffic characteristics for the network transport of heterogeneous and scalable encoded video. Therefore, the researcher proposes a comprehensive large scale study of the traffic characteristics and the network transport of heterogeneous and scalable encoded video. The researcher will investigate<br\/>1. the traffic characteristics (i.e., statistical properties) in conjunction with the video quality and<br\/>the content features, and<br\/>2. the network capacity, i.e., the number of video streams that a given network can support<br\/>(multiplexing performance) subject to given quality of service (QoS) constraints<br\/>both for<br\/>(a) non scalable video encoded at a range of quality levels using diffierent encoding schemes, and<br\/>(b) scalable encoded video.<br\/>These traffic and networking studies are traditionally based on traces of real video traffic. The<br\/>existing video trace libraries, however, provide only frame size traces of a limited number of single<br\/>layer MPEG 1 encoded videos. Hence, the existing trace libraries are inadequate for this study<br\/>(and also for other researchers studying scalable multimedia services over networks). Therefore, the researcher proposes to create an extensive publicly available trace library of heterogeneous and<br\/>scalable encoded video as the basis for the proposed study. The researchers will <br\/>(1) encode over 100 di.erent videos, spanning a wide range of video genres and lengths and<br\/>including diverse texture and motion characteristics.<br\/>(2) encode each video into a single layer (non scalable) at a range of quality levels using di.erent<br\/>encoding schemes.<br\/>(3) encode each video into several quality layers, using the temporal, spatial, SNR, and data<br\/>partitioning scalability modes, as well as the object based scalability mode of MPEG 4.<br\/>(4) broaden the notion of video traces by capturing the video traffic, the video content features,<br\/>and the video quality in traces.<br\/>(5) disseminate the created video trace library through publicly available web sites.<br\/>The trace library will stimulate research on protocols and mechanisms for scalable multimedia<br\/>services in heterogeneous wireline and wireless networks. To date, the research in this area has been hampered by the lack of representative traces of scalable encoded video. In fact, the lack of realistic traffic data for scalable video may have prevented the development of e.cient and reliable protocols for heterogeneous multimedia services.<br\/>As part of the seed work for the proposed project, the researchers have created a preliminary publicly available library of traces of non scalable MPEG 4 and H.263en coded video (http:\/\/www.eas.asu.edu\/trace) and studied the statistical properties of the traces in the library. This library is a first attempt at providing MPEG 4 and H.263 video traces. These traces are already widely used by networking researchers.<br\/>The PIs complement each other in their competencies. Martin Reisslein brings to the project<br\/>his expertise in developing and evaluating traffic management schemes for video traffic in high<br\/>speed wireline networks and wireless networks. Sethuraman Panchanathan brings to the project his<br\/>expertise in video compression, scalable video coding, video content analysis, and MPEG 4.","title":"Video Traces: Create, Disseminate, Analyze","awardID":"0136764","effectiveDate":"2002-09-15","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["528940","455149"],"PO":["7594"]},"71160":{"abstract":"This project is a multidisciplinary, international collaborative research project aimed at developing a theoretical understanding of the records generated by the scientific, government and artistic sections. On this basis, the project will formulate and test various technology, metadata, and policy models, etc. to ensure that records created using these systems can be trusted as to content reliability and accuracy and for subsequent multipurpose use. The project will address issues related to how information technology is transforming functions of modern society, particularly in the areas of digital government, e-commerce and large-scale research efforts.","title":"ITR: International Research on Permanent Authentic Records in Electronic Systems (InterPARES): Experimental, Interactive, and Dynamic Records","awardID":"0205620","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[184274,184275,184276,"369288",184278],"PO":["433760"]},"74680":{"abstract":"For many practical reasons (e.g., hardware development cost, power<br\/>consumption, etc.), it would be attractive if we could increase the<br\/>effective performance of a computer system by simply adding more processors<br\/>to it. While it is reasonably straightforward to build such systems that<br\/>support \"parallel processing\", relatively few of today's programs would<br\/>enjoy any performance gain on such machines because they were not written<br\/>with parallel processing in mind. The ideal solution for harnessing the<br\/>potential benefits of parallel processing without placing a large burden on<br\/>the programmer would be for the compiler to automatically transform a<br\/>sequential program into an efficient parallel program. While there has<br\/>been progress on using compilers to automatically \"parallelize\" regular<br\/>numeric programs (typically written in FORTRAN), there has been little<br\/>progress in automatically parallelizing broader classes of programs. The<br\/>key stumbling block has been that compilers have traditionally created<br\/>parallelism by proving that potential threads are always independent. To<br\/>circumvent this limitation, recent hardware prooposals enable the compiler<br\/>to optimistically create parallel threads without proving independence. In<br\/>this project, we plan to develop the compiler technology necessary to fully<br\/>exploit this new potential for harnessing parallel processors.","title":"ITR: Compiler Technology for Automatic Parallelization via Thread-Level Speculation","awardID":"0219931","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["485986"],"PO":["565272"]},"71193":{"abstract":"This project focuses on facilitating and augmenting social interaction in virtual environments, particularly immersive virtual environments. Virtual environment technology allows individuals to freely move about digital \"worlds\" in real time observing and interacting with the environment and <br\/>virtual others within it. Increased sophistication of virtual environment technology and digital imaging of people promises a new age for technologically mediated social interaction of geographically separated individuals. However, in order to implement such interaction virtually in <br\/>meaningful and productive ways, an understanding of the parameters of people's perceptions of each other's non-verbal signals (e.g., facial expressions, gestures, gaze) within virtual environments is necessary. Such an understanding will provide a hierarchical taxonomy of the necessary and <br\/>sufficient non-verbal signals that are critical to social interaction within virtual environments and, therefore, must be tracked and rendered among interactions in virtual environments. Realizing the objectives of the proposed project will advance scientific understanding in the areas of social interaction and non-verbal behavior, human participation in collaborative virtual environments, and technological (e.g., computer vision) aspects of automated tracking and rendering of human on-verbal signals.","title":"ITR: Using Virtual Environment Technology to Understand and Augment Social Interaction","awardID":"0205740","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["356814","408895","558448","286412","553205"],"PO":["564456"]},"75593":{"abstract":"EIA 02-24187<br\/>Foster, Ian<br\/>University of Chicago <br\/><br\/>Title: CISE RR: (Collaborative) DOT--Distributed Optical Testbed to Facilitate the Development of Techniques for Efficient Execution of Distributed Applications <br\/><br\/>This collaborative proposal with Illinois Institute of Technology (Sun, 02-24377) and Northwestern University (Taylor, 02-24427), acquiring data nodes and compute nodes at five sites, contributes to build a Distributed Optical Testbed (DOT). The DOT system, a product of the paradigm shift from large-scale applications running on large parallel systems at single sites to those running on distributed systems, has come about by the availability of high-speed optical networks (E.g., Starlight, TeraGrid 40 Gb\/s network, the PacificRail 10 Gb\/s network). This shift necessitates techniques that allow applications to efficiently utilize distributed systems. In contrast to parallel systems, these systems must exploit two characteristics:<br\/>Heterogeneity of resources (processors and networks) and <br\/>Dynamic changes in performance of shared resources, especially wide area networks. <br\/>The system, consisting of Linux clusters at six geographically different sites interconnected via two existing research DWDM networks, I-WIRE and OMNInet, involves the following sites: Argonne National Laboratory (ANL), Illinois Institute of Technology (IIT), National Center for Supercomputer Applications (NCSA), Northwester University Chicago Campus (NU-C), Northwestern University Evanston Campus (NU-E), and the University of Chicago (UC). DOT will facilitate the following research activities in the area of distributed applications:<br\/>Dynamic Load Balancing (Taylor)<br\/>Performance Monitoring and Prediction (Dinda, Sun, Taylor)<br\/>Data Management (Choudhary, Foster)<br\/>The first activity develops techniques utilizing network performance predictions that take into consideration the heterogeneity of the processors and networks of distributed systems to dynamically balance the load during execution. The second extends performance monitoring, modeling and prediction techniques that have been focused on parallel systems and broadband network to distributed systems with optical networks and different topologies. The last develops techniques that manage the distributed data such that the actual data location is transparent and the data is accessed efficiently. These research activities are driven by three applications that have been parallelized using MPI, such that the applications can be easily ported to DOT:<br\/>ENZO, an adaptive cosmological application,<br\/>Cactus, an open framework used to solve Einstein's equations, and<br\/>AudioVoice, a virtualized distributed audio application with physical simulations that have real-time deadlines and varying computational demands.<br\/>Each application presents challenges, which include adaptivity, flexible framework, and simulations with real-time deadlines.","title":"Collaborative Research: DOT -- Distributed Optical Testbed to Facilitate the Development of Techniques for Efficient Execution of Distributed Applications","awardID":"0224187","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["554547"],"PO":["557609"]},"74394":{"abstract":"EIA-0218441<br\/>Navin Khaneja<br\/>Harvard University<br\/><br\/>Time Optimal Control of Quantum Information Processing Systems<br\/><br\/>Time optimal control of quantum mechanical systems can significantly minimize decoherence effects in coherent manipulation of quantum pheonomenon. The central theme of the project is to develop a mathematical theory for optimal unitary control of quantum networks. Network of coupled two level quantum systems form the benchmark for a quantum computer. Finding the minimum time it takes to produce a desired unitary evolution in a network of coupled quantum systems is of fundamental practical importance not just in the field of quantum information processing but the whole field of coherent spectroscopy. In particular, focus is on optimal control of network of coupled spin half particles (acting as qubits in liquid and solid state NMR quantum conputing with fixed interaction Hamiltonian and ability to selectively excite some of the qubits. One of the goals of this project is to develop geometric methods for computing fundamental bounds on the minimum time it takes to produce unitary evolution in a network of coupled quantum systems and find time optimal control laws which achieve these bounds. <br\/><br\/>These methods are based on variational ideas as captured by the theory of optimal control. Finding optimal strategies to control the dynamics of quantum networks can be reduced to problems in Riemannian geometry of computing subriemannian geodesics in certain homogeneous spaces. Using these geometric techniques time optimal control strategies for quantum networks are being computed.","title":"Time Optimal Control of Quantum Information Processing Systems","awardID":"0218411","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}}],"PIcoPI":["323756","344990"],"PO":["521045"]},"79971":{"abstract":"In order to design and manufacture future generations of complex VLSI chips, this project explores new techniques for the physical design of integrated circuits and systems. This project focuses on (1) the development of interconnect planning algorithms that are essential to the change in design paradigm from gate-centric approach to interconnect-centric approach, (2) the development of circuit optimization methods using the transmission line delay model which give more accurate results than algorithms based upon the commonly used lumped circuit models, (3) the development of physical design algorithms which can anticipate errors to be introduced by the photo-lithography process in chip manufacturing, and (4) the development of ultra-fast routing techniques for field-programmable chips suitable to be used in reconfigurable computing where \"on-the-fly\" routing is needed in real-time.","title":"Research in Physical Design of VLSI","awardID":"0244236","effectiveDate":"2002-09-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["550908"],"PO":["562984"]},"75395":{"abstract":"In the last decade, computer systems have increasingly become participants in complex, distributed communities comprising people and computer systems, rather than devices used by individuals. This major shift engenders a significant challenge for computer science: to determine ways to construct computer systems able to act effectively as team members. Although many current computer systems have sophisticated capabilities as individual actors, most lack capabilities required for working successfully as members of a collaborative group. This proposal addresses problems central to this challenge. It focuses on providing the foundation for the design of decision-making components of software agents that can handle multi-agent, dynamic team contexts. The proposed research comprises three activities: (1) empirical investigations, including examination of the influence on individual and group behavior and outcomes of policies and mechanisms for producing appropriately helpful behavior in collaborative settings and for<br\/>governing commitment to group activities; (2) development of formal theories that may be used to address abstractly questions of these mechanisms; and (3) construction of more sophisticated<br\/>collaboration-capable software agents. The research will contribute to the development of collaboration-capable software agents and collaborative human-computer interface systems, and,<br\/>thus, will significantly increase the effectiveness of heterogeneous teams of people and software-systems agents.","title":"Collaborative Research: Decision-making in Collaborative Activities","awardID":"0222892","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["333902"],"PO":["564456"]},"81061":{"abstract":"Techniques such as program generation, partial evaluation, just-in-time compilation, and run-time code generation respond to the need for general purpose programs which do not pay unnecessary<br\/>run-time overheads. The thesis of this project is that a uniform, principled, high-level, and practical view of these diverse techniques is possible through multi-stage programming, a novel paradigm for the development of maintainable, high-performance software. The key idea in multi-stage programming is the use of simple, high-level annotations to allow the programmer to break down the cost of a computation into distinct stages.<br\/><br\/>The goal of this proposal is to demonstrate that the theoretical machinery that has been developed for multi-stage programming can be put to work. This project will involve the development of compilers<br\/>of multi-stage programming languages, addressing both practical and theoretical problems that arise in the development of such systems, and using these compilers in interesting applications ranging from dynamic programming algorithms and rewriting systems to implementations of domain specific programming languages.","title":"ITR\/SY(CISE): Putting Multi Stage Annotations to Work","awardID":"0302421","effectiveDate":"2002-09-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7316","name":"EAPSI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["495365"],"PO":["564388"]},"71150":{"abstract":"ABSTRACT<br\/>0205575<br\/>U of Mass, Amherst<br\/>Leon J. Osterweil<br\/><br\/>The internet has changed forever the way science is done. Collaborations such as NSF-sponsored<br\/>Globus, and GriPhyN are beginning to employ internet access to facilitate data sharing and<br\/>expedite collaboration among worldwide communities of geographically distributed researchers.<br\/>This creates opportunities to do better science through the use of shared data and expertise, but it<br\/>also creates risks arising from uncertainty about how internet-accessed data sets were produced<br\/>and how they can be used. If scientists cannot determine how particular results were obtained,<br\/>those results may be subsequently combined in ways that will lead to incorrect or misleading<br\/>conclusions, possibly with devastating effects.<br\/>Our project will develop, demonstrate, and evaluate technologies to facilitate the building of<br\/>community consensus by supporting definition, validation, repeatability, and adaptability of<br\/>scientific processes that integrate and combine web-based data sets and tools. Although there will<br\/>always be debate about the most appropriate models, methodologies and conclusions used in<br\/>scientific inquiry, our work should help scientists focus on areas of disagreement and resolve these<br\/>disagreements more quickly, perhaps through further experimentation and inquiry. Thus, our work<br\/>will also help policy makers in areas where scientific results are critical ingredients, such as<br\/>economic policy, environmental management, and social initiatives..","title":"ITR\/AP: The Analytic Web","awardID":"0205575","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"V477","name":"NSA-ANALYTIC WEB"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V675","name":"NSA-LEMUR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V236","name":"NSA-MAINTENANCE & DEV OF LEMUR"}}],"PIcoPI":["536735","558020","290021","536737","507668"],"PO":["564388"]},"71161":{"abstract":"0205625<br\/>Christopher DiGiano<br\/>SRI International, Menlo Park, CA<br\/>\"Training and Resources for Assembling Interactive Learning Systems\"<br\/><br\/>This project leverages research and development outcomes from prior NSF funding that focused on interactive mathematics education. The current project addresses three areas: 1) Research involving undergraduate education focused on investigating the training needed to produce practitioners capable of collaborative design of educational software, 2) Research into the processes used by collaborative software design teams, and 3) Research into K-12 educational impact because of the use of software produced by collaborative design teams. The project involves pre-college teachers and undergraduate and professional software developers in teams producing interactive software for K-12. In addition to primary goals of studying multidisciplinary collaborative teams and the impacts of the systems they develop on pre-college students, the project also looks at software re-use and collaborative tools needed for innovative applications of IT in education. Outcomes of this project will be insights into and understanding of: the kinds of course activities that are needed to enable effective teamwork between students with different backgrounds; course activities that will enable teams to discuss, share, and enact educational values in their software production process; the packaging of curricula into modules that are adaptable by a variety of institutions; the promotion of curricula that encourages enrollment by a broad spectrum of students in educational software development; and, the preparation of new teachers and developers for future work involving collaborative design. In addition, this project involves research into optimal design tools (the kinds of tools and resources such as design scenarios, national standards, bug lists, feature lists, and mailing lists that help teams achieve shared understanding), collaboration mechanisms and the design of tools and spaces to encourage a culture of reuse where team members borrow pedagogical ideas and technical modules from exemplary artifacts and in turn contribute useful products of their own, and a social network of human experts and coaches needed to produce educational software (i.e., best practices that can be identified for the ways experienced classroom teachers and software developers coach and support teams in developing good designs and encourage balanced participation by technical and non-technical team members). The overarching need that is addressed by the project is the shortage of standards-based, high-quality educational software for K-12 classrooms. The project aims to validate the premise that appropriate training and resources can enable a team to transform today's designs into improved designs that elicit and support higher-order mathematical thinking among the target K-12 students. Testing this hypothesis requires research in classroom impact including: exploring whether university student co-design teams can adapt and refine existing mathlet resources to produce new mathlets that engage higher-order mathematical thinking, identifying, refining, and disseminating to classrooms around the country the best mathlets from all participating institutions, expanding the adoption and utility of deployed mathlets be increased by enabling in-service teachers to configure the tools for their particular classroom needs. This project involves collaboration between several academic institutions, research organizations, and businesses.","title":"ITR\/PE: Training and Resources for Assembling Interactive Learning Systems","awardID":"0205625","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["453838","457714","524324","561255","338158"],"PO":["551712"]},"74681":{"abstract":"The recent and growing popularity of thin-client systems makes it<br\/>important to develop techniques for analyzing and comparing their<br\/>performance, to assess the general feasibility of the thin-client<br\/>computing model in modern networking environments, and to determine<br\/>the factors that govern the performance of these architectures. <br\/>This project involves carrying out a series of experiments to gain<br\/>information and understanding on the effectiveness of thin-client<br\/>architectural mechanisms for graphical and multimedia applications in<br\/>various network environments. These experiments include performance<br\/>analysis using several real applications as well as controlled<br\/>experiments with specialized micro-benchmarks designed to isolate<br\/>particular aspects of thin-client architectures that have significant<br\/>impact on overall application performance. Application and user<br\/>workloads will be varied to understand and analyze the scalability of<br\/>different remote display mechanisms in terms of network and server<br\/>resources. These experiments will be conducted in a testbed<br\/>environment in which network characteristics such as bandwidth,<br\/>latency, and packet loss are varied in a controlled manner to<br\/>understand their impact on thin-client architectural design<br\/>choices. The results of these experiments will have a fundamental<br\/>scientific impact by laying a quantitative foundation for future<br\/>innovations in thin-client computing research.","title":"ITR: An Experimental Study of Thin-Client Computing Architectures","awardID":"0219943","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["508477"],"PO":["325495"]},"72052":{"abstract":"Generational garbage collection is a leading technology for<br\/>automatic and efficient recycling of the computer storage<br\/>occupied by a program's unreachable objects. This research<br\/>seeks to develop a more quantitative theory of generational<br\/>garbage collection, to be based on more realistic analytic<br\/>models for the distribution of object lifetimes. These<br\/>models will be derived by abstraction from the detailed heap<br\/>storage profiles of real programs, and will be evaluated by<br\/>comparing their predictions against the performance of actual<br\/>garbage collectors.<br\/><br\/>Insights from this research should lead to faster, more<br\/>space-efficient, and less intrusive algorithms for generational<br\/>garbage collection.","title":"Modelling Generational Garbage Collection","awardID":"0208722","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":[186582],"PO":["565272"]},"72063":{"abstract":"Abdelzaher <br\/>CCR-0208769<br\/>\" A Paradigm for Scalable Open Real-Time Computing Under Uncertainty\"<br\/><br\/>A key challenge for embedded real-time computing is that of providing temporal performance guarantees. Unfortunately, the wealth of knowledge developed to date in the area of performance assurances in embedded<br\/>systems has been confined to a somewhat restrictive application domain where detailed knowledge is assumed of both the available resource capacity in the system and the resource requirements of individual tasks. These restrictions prevent many previous research results from being applied to a wider scope of mainstream applications and services where QoS guarantees are required, yet load and resource models are unavailable. This research seeks a solution to the problem of providing performance guarantees in the absence of detailed load and resource knowledge. The goal is to establish that fine-grained guarantees are achievable with real-time system performance even in the absence of fine-grained models of system load and resource capacity. <br\/><br\/>This is approached through new foundations for performance guarantees in embedded real-time systems operating under uncertainty. The research centers on a new calculus aimed to counter fundamental limitations on robustness and scalability in current approaches for performance guarantees. There are two main elements: <br\/><br\/>1) A theory for robust schedulability analysis based on feasible regions: A feasible region is a set of aggregate system states in which all timing constraints are guaranteed to be met. This research is developing methods for deriving multi-dimensional feasible regions in a continuous state space, where the dimensions represent aggregate measurable quantities such as the overall utilization of different system resources. Maintaining a system within feasible region boundaries guarantees temporal correctness based on aggregates only. These mechanisms will be more scalable and suitable for systems where detailed information about the load and resources is unavailable. <br\/><br\/>2) Middleware components that enforce conformance of a run-time system to its feasible region. The theoretical framework being developed is incorporated into a middleware framework based on control theory, which executes run-time performance monitoring and feedback control mechanisms to ensure that system state converges to a feasible region. This condition is enforced using admission control and QoS adaptation.<br\/><br\/>These two elements maintain guarantees on real-time behavior by linking applications with the middleware, specifying desired QoS guarantees, and leveraging run-time feasible region enforcement mechanisms to provide correct temporal behavior in in open real-time systems. This increases the scope of embedded computing from predominantly closed custom-designed systems to large distributed open systems composed of commercial off-the-shelf components such as web servers, mainstream operating systems, and standard protocols such as TCP\/IP, where accurate load and resource knowledge is unavailable. High impact is expected through the ability to achieve predictable behavior in many important systems ranging from large Web server farms and Internet routers to ubiquitous computing systems, and smart spaces.","title":"A Paradigm for Scalable Open Real-Time Computing Under Uncertainty","awardID":"0208769","effectiveDate":"2002-09-01","expirationDate":"2006-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["550342","553633"],"PO":["561889"]},"71095":{"abstract":"EIA-0205301<br\/>Albert Corbett<br\/>Carnegie-Mellon University<br\/><br\/>ITR: Collaborative Research: Putting a Face on Cognitive Tutors:<br\/>Bringing Active Inquiry into Active Problem Solving<br\/><br\/>Collaborative project with:<br\/>0205506<br\/>Michelene Chi<br\/>University of Pittsburgh<br\/><br\/>This project builds on a growing body of research concerning effective learning and tutoring strategies. The project involves constructing and evaluating educational technology that emulates human tutors by integrating a state-of-the art educational technology called Cognitive Tutors with a innovative interactive questioning environment called Synthetic Interviews to produce an inactive learning environment that rivals the effectiveness of human tutors. Cognitive tutors are built around a cognitive model of problem solving knowledge and provide precisely the support students need to complete problems successfully. Used alone, cognitive tutors do not support the help-seeking and meta-cognitive skills that characterize active learners. By incorporating a novel interactive communication technology called Synthetic Interviews, an Active Learning Environment is offered that rivals the effectiveness of human tutors in supporting deep student learning. Synthetic Interviews allow learners to engage in active inquiry by providing the means for conversing in-depth with an individual. Synthetic Interviews permit knowledge capture in a new form providing utility similar to an expert system but a development effort approaching the simple video taping of a conversation. The Active Learning Environment serves as a research tool to examine both computational and pedagogical challenges and also as an educational environment in classrooms and homes. In particular, the domains of knowledge that are constructed around this learning environment are mathematics and biology courses. The project promises to make important contributions to cognitive science, computer science and educational practice including the following: 1) The analysis of student questions during synthetic interviews will contribute to basic cognitive models of the functional relationship between declarative conceptual knowledge and procedural problem solving knowledge, 2) This project will integrate cognitive models of student knowledge and tutorial dialogue structure. More generally, the project will help define a design and engineering process for intelligent learning environments, 3) The research will inform the design of more effective computer-based learning environments. 4) The research and the active learning environment can support improved professional development both for pre-service and in-service teachers. The Active Learning Environments for mathematics and biology that are developed in this project promise to directly improve educational practice nationally. Current generation cognitive mathematics tutors are already in use in about 2% of middle schools and high schools around the country. The demand for effective mathematics and science education continues to grow. States are increasing mathematics graduation requirements and instituting assessments that govern student graduation and school evaluations. If Active Learning Environments are more effective than current generation Cognitive Tutors, they promise to rapidly enter widespread classroom use.","title":"ITR: Collaborative Research: Putting a Face on Cognitive Tutors: Bringing Active Inquiry into Active Problem Solving","awardID":"0205301","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1688","name":"ITR LARGE GRANTS"}}],"PIcoPI":["333951","548127","405986","533937"],"PO":["551712"]},"77772":{"abstract":"This research investigates scalable formal methods and their combinations as a way to reduce the gap between formal methods and software practice. These methods include domain-specific certification and runtime verification and monitoring. Important subthemes are: exploitation of domain-specific knowledge to derive efficient and scalable algorithms and decision procedures; strength through the combined use of several \"lightweight\" formal methods; multidimensional components to represent not only code, but also<br\/>different views of the system from different perspectives; dependability metrics based on the notion of multidimensional component, so that increases in dependability along each dimension are aggregated into measurable overall dependability increases. Various prototypes are developed: safety policy certifier for units of measurement; coordinate frame safety certifier; optimality state estimation certifier; runtime verification and monitoring prototypes. These are experimentally evaluated using the NASA-HDCP testbed.<br\/><br\/>This research is expected to lead to advances in software technology and to benefit advanced education. Novel combinations of software synthesis, certification and monitoring lead to new, powerful<br\/>dependable software development methodologies ensuring safe execution with little or no overhead. Two graduate courses are planned. Supported graduate students are given a solid scientific foundation<br\/>and acquire invaluable experience by working closely with NASA scientists.","title":"Scalable Formal Methods for Multidimensional Components","awardID":"0234524","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"W379","name":"NASA-HIGHLY DEPENDABLE COMPUTI"}}],"PIcoPI":["550264","549774"],"PO":["564388"]},"74384":{"abstract":"EIA-0218359<br\/>Hao Yan <br\/>Duke University<br\/><br\/>Molecular Robotics for DNA Nanostructures<br\/><br\/>The objective of this project is to develop molecular motors that are incorporated into self-assembled DNA lattices. The main goal of this project will be to develop experimental proof-of concept demonstrations of the construction of novel DNA motors such as a DNA motor that is designed to have both translational and rotational motion. Incorporation of molecular motors into DNA arrays has many applications: It can selectively manipulate molecules using molecular motor devices arranged on DNA tiling arrays; A DNA array of motors may offer a mechanism to do DNA computation of arrays whose elements (the tiles) hold state; Parallel cellular automata computation may be executed from arrays of finite state automata each of which hold state. This project is also developing DNA nanostructures containing motors that operate autonomously without environmental changes. Methods are being tested to use \"fuel DNA\" to provide energy to drive the motion of DNA nanostructures. As an alternative approach, experiments are conducted to incorporate protein motors such as Kinesin into DNA lattices. In particular, the use of selective aptamer binding to link protein motors to periodic sites of a DNA lattice will be tested. The resulting arrays of protein motors have many applications to nanorobotics, e.g., they are potentially very useful for sorting and transport of nanoparticles.","title":"QuBIC: Molecular Robotics for DNA Nanostructures","awardID":"0218359","effectiveDate":"2002-09-01","expirationDate":"2004-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["550822","555498",193172],"PO":["565223"]},"74153":{"abstract":"Over the past decade, wireless sensor networks have evolved from primarily unidirectional star networks into a wide variety of forms, with large-scale research programs and significant commercialization activity. These systems will increasingly connect the physical world to wide-area networks for monitoring and control purposes including homeland defense and industrial applications. Yet relatively little is known on the fundamental limits to how efficiently a network can glean useful information from the environment to process it and relay it to the larger public network. Research is being conducted on fundamental limits in four areas: the rate distortion region for correlated sources, capacity for distributed nodes, packet delay across networks, and the dependability of heterogeneous wireless networks. These four topics collectively address many of the important parameters in sensor network design and will allow practical algorithms to be tested against fundamental limits.","title":"ITR-Fundamental Limits in Sensor Networks","awardID":"0217260","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["539242"],"PO":["348215"]},"77431":{"abstract":"This project will address the interplay among various robotic control and networking problems focusing on the issue of teleautonomy. The research addresses both the problems of remote assembly with minimal human intervention and direct teleoperation. Both (semi-)autonomous and teleoperated systems as described herein will be important to realize the goal of assembling and operating Space Solar Power (SSP) systems. For systems in earth orbit and for human coordination of multiple networked robotic systems, direct teleoperation is a viable and attractive option, while greater autonomy is crucial for more remote assembly systems, such as lunar based systems where longer time delays make direct teleoperation difficult. A significant level of autonomy, i.e. local intelligence, will also be required due to the possibly unreliable communication networks over which these systems will be controlled.<br\/><br\/>The present research seeks to integrate robotic control algorithms with communication networking research, along with issues associated with projecting and magnifying human capabilities to facilitate assembly in space structures. The technical issues include bilateral teleoperation, the reliability of the communications links, and the coordination of complex assembly tasks. Bilateral teleoperation will be studied using passivity-based nonlinear control along with logic-based switching control. The reliability of the communication links will be studied to mitigate the effects of unknown and time-varying delays and to incorporate recent ideas from networked control systems (NCS). Finally the issue of coordination will be studied using concepts from statistical learning theory that borrow and generalize ideas from Internet protocols.<br\/><br\/>More broadly, this research will have important applications beyond teleautonomous robotic systems. We expect to contribute to the growing area of networked control systems, to incorporate our research in areas such as control in hazardous and remote environments, surveillance, search and rescue robots, autonomous vehicles and autonomous locomotion systems, haptic devices, remote construction, and remote surgery.","title":"Collaborative Research: Teleautonomy in Networked Robotic Systems","awardID":"0233205","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"W415","name":"NASA-SSP"}}],"PIcoPI":["465604"],"PO":["335186"]},"78410":{"abstract":"This award is for a workshop to bring together a broad range of networking researchers to discuss the focus, needs, and physical\/managerial structures for a new generation of networking research testbeds that w ill enable\/enhance cutting edge networking and network-application research over the next decade. The output of the workshop will be a report documenting the discussion and overall recommendations that emerge from the workshop.","title":"Workshop on Next Generation Research Testbeds","awardID":"0237569","effectiveDate":"2002-09-15","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["499259"],"PO":["234222"]},"79862":{"abstract":"This project will develop a scalable parallel computing framework for high-end computational research, which will achieve scalability beyond tightly coupled Teraflop architectures, i.e., for distributed supercomputing on multiple Teraflop computers as well as on future Petaflop computers with deep memory hierarchy. To accomplish this goal, the PI will conduct the following research tasks: <br\/><br\/>Topology-preserving computational-space decomposition to minimize the number of messages using a structured message-passing scheme; <br\/>Wavelet-based adaptive load balancing in dynamic, heterogeneous metacomputing environment using simulated annealing to minimize load imbalance and message sizes; <br\/>Recursive and reconfigurable grouping of processors with message renormalization and computation\/communication overlapping to hide latency at each grouping level; <br\/>Spacefilling-curve-based adaptive data compression --- in situ processing of interoperable compressed data to reduce message sizes with user-controlled error bound. <br\/><br\/>A suite of scalable scientific programs developed within the new framework will be disseminated as a computational-scientist's toolkit through a Web portal to have significant impacts on high-end computational research, including the design of quantum-dot architectures for future quantum computing.","title":"ALGORITHMS: Hierarchical Computational-space Decomposition: A Framework for Scalable Scientific Computing Beyond Teraflop","awardID":"0243898","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["490009"],"PO":["565272"]},"75385":{"abstract":"Isosurface extraction and rendering is a useful and popular method for exploring volume datasets.<br\/>While many studies of extraction techniques have been presented, few researchers have considered how to perform isosurface extraction from very large datasets in a way that utilizes parallel computation while also effectively managing memory access. For out-of-core datasets (i.e., those too large to be processed entirely in main memory), delays from access of secondary storage must be minimized if high performance is to be achieved.<br\/>In this project, an investigation of new techniques for parallel, out-of-core isosurface extraction are conducted. The work seeks to exploit multiple types of parallelism, effectively organize memory access to minimize access penalties, and to effectively manage inter-process communication. A hallmark of the workis that it focuses on total system performance rather than attempting to only maximize intermediary measures of a single aspect of performance. One primary target platform for testing of the techniques is cluster computation environments comprised of commodity CPUs.<br\/>Intellectual Merit. The proposed activity can benefit multiple disciplines. Many scientific and engineering enterprises generate and\/or wish to use large datasets. Some finance and consumer applications also desire to effectively utilize large collections of business data. Discovery of trends, phenomena, and structures in those datasets can be aided by more efficient visualization. In particular, for large datasets too large to be processed in-core, the time to compute a visualization is likely to be very high due to the relatively slow access times of the secondary storage. Reduction of these times by resource (memory, CPU, and communication)-effective processing will increase productivity among scientific visualization users and consumers. In addition, reduction of processing times may make tractable the consideration of certain very large problems. The proposed activity builds upon prior work of the PI and of the other experiences with parallel out-of-core isosurface extraction. The PI has access to the necessary computer resources to complete the work, including access to cluster computers at three sites and to supercomputers at three other sites.<br\/>Due to the impact of the proposed activity on visualization methods that are used across the scientific community, society at large is likely to benefit via new knowledge discovery by the<br\/>discipline science that this project aids. In addition, the proposed work will be beneficial in managing and understanding the increasing body of data being collected about scientific, engineering, and business phenomena. The project's results will be disseminated via publication in<br\/>the open literature, in conferences, and on the web. Through the PI's partnerships with NASA, NIH, and other researchers, the results of the work have a high probability of producing an impact in multiple disciplines. The project will also aid undergraduate and graduate student training and development via (1) PI-mentoring of the graduate student supported on the project, (2) presentation, discussion, and analysis of results at a regular research forum, and (3) integration of research findings in graduate computer graphics\/visualization courses taught by the PI.","title":"VISUALIZATION: Efficient Out-of-Core Isosurface Extraction from Large Datasets","awardID":"0222819","effectiveDate":"2002-09-15","expirationDate":"2007-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["349823"],"PO":["565272"]},"74175":{"abstract":"Two forces have exacerbated problems associated with packet processing. First, demands for higher bandwidth and line rates challenge our abilities to perform real-time packet processing. Second, more complex functional requirements and services are being defined that significantly increase packet computational demand. <br\/><br\/>In response, modern routers are being equipped with Network Processors (NPs) that include both general-purpose multiprocessing and special hardware capabilities. NPs push the envelope of our design capabilities. This research aims at quantifying NP design and at developing a performance driven methodology that is cognizant of both physical constraints (e.g., area, power) and the computational requirements of packet applications.<br\/><br\/>Principal architectural approaches (parallelism, pipelining, instruction specialization) are investigated and design procedures for exploiting these architectural paradigms are developed. The NP architecture models along with associated benchmarking lead to a coherent NP design methodology and extend our understanding of real-time computer design.<br\/><br\/>The research directly benefits the rapidly expanding area of NP and router design, and network performance. The techniques utilized are those of classical computer architecture, including the formalization of the design constraints, development of design models, and the use of benchmarks for quantitative model parameterization.","title":"Network Processors: Architecture and Design","awardID":"0217334","effectiveDate":"2002-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["511555","522381"],"PO":["200829"]},"67432":{"abstract":"The research project will develop a distributed data management system for managing sensor data. Specifically it will develop an infrastructure for a sensor data management system as well as techniques for processing queries over data streams. It will also develop data models for handling new data types inherent in sensor data. The techniques will be demonstrated in a working prototype. This prototype will be used for research and education purposes in sensor data management. The career development plan will include the use of \"active learning\" for teaching. In this method, teachers involve students in presenting material through in-class exercises, open questions, as well as working in three-minute in-class two or three member group projects.","title":"CAREER: Towards Sensor Database Systems","awardID":"0133481","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["448955"],"PO":["469867"]},"77112":{"abstract":"This SGER grew out of an EU-US workshop held in Venice in October, 2002. The intent of that workshop was to bring together researchers from the US with those from the EU who were working on similar projects related to e-work and e-business and who would like to begin to collaborate together. This SGER will allow for US cooperation with the EU's STAR project, which involves the conduct of dozens of case studies mapping change in a variety of industries across member states of the EU. This project will focus on the home mortgage service sector, in particular retail financial institutions, and will bring the US and one its industries into the collection. Case study protocols will be developed that will allow for cross-comparison with the EU case studies that have already been completed. In addition, travel to the EU will allow for a team meeting and coordination of project goals, methods, and analysis.","title":"Collaborative Research: SGER: Exploring the Integration of Electronic Commerce in Industry Value Chains: A Focus on the Home Mortgage Service Sector","awardID":"0231584","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["409223"],"PO":["495796"]},"78124":{"abstract":"As more real-world data are included in the Web, requirements to capture more meaning of the data have rapidly increased. Semantic Web has been proposed by W3C to be the next generation of web by representing the metadata using RDF (Resource Description Framework). Even though the metadata encoded in RDF have rich semantics and high potential for providing lots of intelligent features, there have not been enough efforts to utilize them in practical Web application areas.<br\/>A real-time Semantic Web is modeled as an active environment that consists of a set of real-time objects each consisting of a set of attributes, functions, and active rules. A real-time object can be changed spontaneously or triggered by demands (via messages) in real-time. The semantics of such a distributed, real-time object system can be described by a formal logical foundation called Active Real-Time Semantic Web (ARTSW) that is the ordinary first order language (that is time-invariant) plus a set of time-varying constructs. <br\/>The ARTSW can be used to describe the constraints on top of a real-time Semantic Web, or it can be used as a specification language that defines the semantics of a dynamic environment. The declarative ness and inference capability of formal logic are coupled with real-time distributed objects in order to enable the users to encode easily the domain knowledge into rules. Our research is aimed at providing a software engineering framework that covers specification, execution, and management of an active real-time semantic web. Because several technical subjects (i.e., real-time objects, distributed systems, logic, and Web) are involved, this research will focus on the explorative investigation of the technical soundness of the proposed framework.","title":"Incorporating Active Real-Time Objects and Control Into Semantic Webs","awardID":"0236409","effectiveDate":"2002-09-15","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["217949"],"PO":["563751"]},"70172":{"abstract":"EIA 02-02063<br\/>Schulzrinne, Henning<br\/>Feiner, Steven K., Kaiser, Gail E., Kender, John R., McKeown, Kathleen R. <br\/>Boston University <br\/><br\/>Title: RI: Pervasive Pixels<br\/><br\/>Projected Proposed:<br\/><br\/>This project, developing a flexible department-wide collaborative work infrastructure, \"Pervasive Pixels,\" that will serve as a testbed for research in collaborative systems, aims to use this collaborative framework to conduct research and teaching. Pervasive Pixels will capture and deliver multimedia information across heterogeneous networks and devices. The system will schedule meetings, manage and prefetch multimedia objects, laying out material on individual and shared displays. Meetings are facilitated by locating, tracking and identifying users as they desire and are recorded, annotated and summarized, with extensive research capabilities. While improvements in core computation and communication technologies encourage working and interacting remotely, engaging in interdisciplinary collaborations that span buildings, cities, and countries, routinely encounters severe limitations imposed by current collaboration support systems. Pervasive Pixels is created to address these problems and should make possible <br\/> Capturing and delivering multimedia information (including video), through heterogeneous networks, clients, and devices;<br\/> Scheduling meetings, managing and prefetching work documents and multimedia objects, and laying out materials of individual and shared displays, based on models of workflow needs and models of temporal, spatial, and semantic interrelationships;<br\/> Facilitating meetings by locating, tracking, and identifying users, and understanding their gestures, in live and captured video and audio;<br\/> Recording, annotating, summarizing, and searching meeting content, from multiple physical perspectives and via multiple types of database queries, thus maximizing the effects of temporal differences.<br\/>The infrastructure emphasizes<br\/> Large, instrumented, multi-display workspaces in a variety of locations, to accommodate group interactions.<br\/> Networked mobile devices of various capacities, used individually and in the context of larger workspaces.<br\/> Transparent and automatic adaptability to changes of place, platform, or group composition, allowing mobile users to interact as they move about, without having to account for these changes manually.<br\/> Support a wide range of hardware and software, beginning with commercial off-the-shelf commodity components, whose capabilities are retained while the system evolves, ultimately leading to new standards for meeting environments.","title":"CISE Research Infrastructure: Pervasive Pixels","awardID":"0202063","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["337904","423553","541922","530199","518545"],"PO":["550859"]},"71041":{"abstract":"The research program will develop a large-scale digital archive of children's literature and explore problems in technology for access and use by children, and in rights management. There are five primary<br\/>goals: (1) to give children around the world access to international children's literature, (2) to understand data acquisition and rights management in the creation of a large-scale digital library, (3) to develop interface technologies that support children using large amounts of digital information, (4) to evaluate the impact of such a collection on children's librariesa and children's librarians, (5) to evaluate the impact and benefits of such a collection for children. The project plans to develop a digital library of 10,000 children's books representing 100 cultures.","title":"ITR: Developing a Children's International Digital Library","awardID":"0205082","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["406745","426438","518152",183852],"PO":["564456"]},"74682":{"abstract":"The project aims to improve the robustness of XML-based software systems using static typing. The primary goal is the design, formal analysis, and implementation of a new programming language called Xtatic-- a lightweight and completely inter-operatable extension of a mainstream object-oriented language, with native support for statically checked XLM processing.<br\/><br\/>The key technology underlying the project is REGULAR EXPRESSION TYPES. The basic constructors of regular expression types ( union, concatenation, repetition, etc.) are similiar to those of existing XML schema formalisms. In a language with regular expression types, however, XML trees become built-in values of the language and the static analysis of the shapes of built-in value of the language and the static analysis of the shapes of trees that may appear at run time ( as values of variables, parameters to methods, result of complex expressions, or structued messages sent across the network)becomes part of the ordinary work of typechecking.","title":"ITR: Types for XML","awardID":"0219945","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["563479"],"PO":["564388"]},"72031":{"abstract":"The integration of wearable and embedded devices into a pervasive computing environment requires significant attention to security and privacy issues. A system architecture with associated protocols for secure pervasive computing is investigated.<br\/><br\/>The system architecture is based on the existence of a software proxy for each device. All objects in the system, e.g., appliances, wearable gadgets, software agents, and users have associated trusted software proxies that either run on an embedded processor on the appliance, or on a trusted computer. In the case where the device has minimal computational power, and communicates to its proxy through a wired or wireless network, the communication in the proposed system adheres to a proposed device-to-proxy protocol. It is also proposed that proxies communicate with each other using a secure proxy-to-proxy protocol based on SPKI\/SDSI (Simple Public Key Infrastructure \/ Simple Distributed Security Infrastructure). Some devices, e.g., terminals or displays, may not be trusted or their security might be compromised, but users may still wish to use them, because they provide a large screen or large bandwidth resources. An untrusted computer protocol based on visual authentication is proposed such that users can use the untrusted computer and authenticate displayed information as well as communicate securely to a remote application.<br\/><br\/>Using the architectural ideas described above, the design and implementation of a pervasive-computing environment which allows for secure, yet efficient, access to networked, mobile devices is proposed.","title":"Security Protocols for Pervasive Computing Applications","awardID":"0208631","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["561979"],"PO":["521752"]},"71184":{"abstract":"Over the last two years, we've built a new type of experimental environment for research in distributed systems and networks: a highly configurable Internet emulator, known as Emulab. This time-and spaceshared facility has been used by numerous top institutions for research published in top venues. So successful is the project, that others are building their own Emulabs, centered around our software and design. While the individual power of such Emulabs in experimentation and teaching is great, connecting these into one large Research and Education Grid will offer unprecedented power and flexibility.<br\/>We now propose, with dramatically expanded software and innovative algorithms, to establish the framework for a federated set of local Emulabs, each heterogeneous under local control and offering a unique set of hardware. Adding sites to the Grid will be easy and cheap, offering even small institutions a chance to contribute while gaining access to an immensely diverse and powerful resource. Individual sites' users will have priority for local hardware, as well as control over local administrative, security, and resource allocation policies. Such autonomy will encourage organic growth, while intelligent allocation, scheduling, and swapping systems will provide abstraction. Researchers and students can be unconcerned with local complexities, instead seeing one large collection of a wide variety of hardware, including standard PCs, network processors, wireless nodes, and more. Even the links between Emulabs will be a useful resource for experiments wishing to operate on the real Internet, while controlled-bandwidth links will shield experiments that do not. Support for wireless, mobile nodes will open entirely new avenues for experimentation.<br\/>Achieving this vision, however, involves daunting challenges. Creating the software to manage this will involve a dramatic extension of existing Emulab systems and the application of novel algorithms and techniques. Existing database systems will be augmented with failure-resistant peer-to-peer sharing of network information between Emulabs. Through these mechanisms, topology data will be shared for observation and experiment scheduling. Such scheduling on a non-static, wide-area system is a particularly challenging NP-complete problem which will require new algorithms to be designed and implemented. Automated systems to control experiment scheduling and allocation will be developed all the while facing the challenge of maintaining simple user interfaces. Emulab algorithms and software must also be extended to handle a wider variety of hardware, including wireless nodes. Aspect-oriented programming and component technology, developed at Utah, will manage software interfaces for complex and numerous inter-operating hardware systems. In addition, methods for sharing, saving, and restoring state between machines, as well as maintaining performance isolation while multiplexing multiple virtual nodes on a single computer, will be explored.<br\/>The incorporation of multiple Emulabs into a single federated entity offers a rich opportunity to overcome a wide variety of network research and software engineering challenges, and allows for experimentation on an unprecedented scale. Users, ranging from individual students to large research groups, will benefit from a greatly expanded ability to controllably and faithfully emulate large real networks, coupled with the availability of diverse and cutting-edge network components. Unifying resources in a standard and consistent way will simplify experimentation, and make accurate emulation an integral part of systems and network instruction and research.<br\/>The resulting loosely-coupled distributed system will enable experiments in a host of areas. As just one example, if Emulab is successful in one of its core goals, isolation, experiments too dangerous to conduct in the wild could be run. Realistic Internet War Games could be staged, in which attackers and defenders engage in a simulation of possible Internet attack scenarios, replete with destructive and contagious worms and dangerous automated counterattacks. Only in an Emulab Petri dish could they be safely evaluated at reasonable scale.","title":"ITR: A Grid for Research and Education in Distributed Systems and Networks","awardID":"0205702","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["300996","344532"],"PO":["565090"]},"74572":{"abstract":"This project addresses using technology to teach science in an effective and agile manner at the Community College level. As jobs requiring science and math increase in numbers, the burgeoning bio-technologies being only one example, future workers will be asked to learn new skills rapidly. The NSF-funded Molecular Workbench Project (REC 9980620), now in its final year of research and testing, has developed several powerful atomic-level models. These models, together called the Molecular Workbench, when combined with a scripting language that 'talks with\" our model, and with Berkeley's WISE program that delivers on-line projects in inquiry science, can illuminate some of the hardest-to-teach concepts in chemistry, biology and physics.<br\/><br\/>Community Colleges are a critical gateway not only to career training but also, for many, to college itself. Infusing science courses with the powerful interactivity of models will allow students not only to master science, but facilitate their transfer to specialty courses. The overall goal of this project is to develop and evaluate the use of complex, interactive computational models in the real-world situations encountered in two-year college technical programs. The project will develop and evaluate flexible atomic-scale modeling software as well as the software architecture that supports the rapid development and deployment of educational materials that utilize this model. The Molecular Workbench software is capable of underpinning key physics and some chemistry concepts. It is situated between the rigor of professional science and the simplifications required by good teaching. This project proposes to develop the modeling software's capacity to model chemical bonds, and photon interactions as well as new computational and visualization algorithms needed to model different features of larger biomolecules (e.g. steric ligand-receptor interactions at active sites). Working together with science advisors and a set of community college educators, this project will not only enhance the Molecular Workbench software, but will also develop classroom activities using the models, and carefully evaluate their use and efficacy. This technology will be pilot tested in two-year college courses by providing a range of hypermodels, or scaffolded models, that use atomic-scale models to illustrate key science topics in the context of typical technical specialties. The principle investigators will identify a set of key science topics typically taught in biology, chemistry, and physics courses at this level and generate hypermodels for each that are based on technologies and processes used in specialty programs. They will capitalize on an existing platform for inquiry science projects that has been developed at the University of California, Berkeley. The Web-based Inquiry Science Environment (WISE) supports students as they work collaboratively on inquiry projects. Using WISE, the hypermodels will be integrated into complete online instructional units that faculty can adapt to their needs without significant changes in the organization or learning objectives of current instruction. They will all, however, have a consistent, atomic-scale approach that could be the basis of a new, interdisciplinary approach to the core sciences. The materials will be developed in collaboration with faculty at two-year colleges and curriculum experts, including Springfield (MA) Technical Community College (STCC) and others throughout the US recruited through the Center for Occupational Research and Development (CORD) and their Community College Presidents Council. The PIs will make all grant-supported code available as open source as part of their Open Source Library of Educational Technology (OSLET) initiative.","title":"ITR: Atomic-Scale Models in Two Year Colleges: Bridging Science and Technology with Atomic-Scale Models","awardID":"0219345","effectiveDate":"2002-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"1666","name":"RESEARCH ON LEARNING & EDUCATI"}}],"PIcoPI":["487434","501315","365292"],"PO":["564318"]},"74473":{"abstract":"Bayesian Learning at the Syntax-Semantics Interface<br\/>Abstract<br\/><br\/>Children easily learn features of novel verbs from small numbers of scene-utterance pairs. For example, after encountering a few examples of \"breaking\" an object, they infer that break might require an object, e.g., John broke the glass. They also learn semantic properties. Children and adults can then generalize to other scene instances representing break. This project hypothesizes that children combine syntactic and semantic evidence to learn verb features, using a probabilistic method called Bayesian inference. <br\/><br\/>The project's first goal is to implement a computational model that can induce probability distributions on features from a very small number of scene-utterance pairs. This model will make explicit all the information sources used. Second, the project will confirm which cues are actually used by human learners in certain settings. The experimental method matches the computer model's predictions empirically, by presenting adult and child learners with training sequences of novel verbs used across varying syntactic and semantic feature situations. This project's results will advance adaptable computer systems and information-filtering, both in terms of robustness to noise and an ability to learn from a small number of examples. These results will improve the construction of a key component of natural language processing engines: the dictionary.","title":"ITR: Bayesian Learning at the Syntax-Semantics Interface","awardID":"0218852","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["431663","412777"],"PO":["565215"]},"75221":{"abstract":"The objective of this research is to develop general methods that automatically discover original and useful knowledge from historical or experimental data. Learning discriminants and descriptors associated with patterns extracted from the data is a central issue in data mining. The project will develop techniques to do this. The results will be experimentally evaluated. In addition, an integrated data mining performance system will be developed.","title":"Learning Critical Discriminants and Descriptors in Data Mining","awardID":"0221954","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["552321"],"PO":["563751"]},"72086":{"abstract":"Optimization problems that arise in practice are often inherently<br\/>online; that is, the input data is not available prior to<br\/>computation but, instead, is given as a sequence of requests<br\/>each of which must be served before the next one is received.<br\/>A classical example is the caching problem in two-level memory<br\/>systems. Modern computer architectures enhance memory performance<br\/>by storing frequently accessed data items in a cache, which is<br\/>a small buffer memory. Memory locations stored in the cache<br\/>can be accessed quickly. Requests to memory locations that are<br\/>not in the cache are called faults or misses, and take much<br\/>more time. After each memory access, an online caching algorithm<br\/>needs to decide whether to put the requested item in the cache,<br\/>and if so, which item to evict from the cache. The objective<br\/>is to minimize the number of cache faults.<br\/><br\/>Due to incomplete information, online algorithms cannot, in general,<br\/>compute optimal solutions. This brings up the issue of performance<br\/>evaluation: how do we tell good algorithms from bad ones? One measure<br\/>of the quality of online algorithms is their competitive ratio,<br\/>defined as the maximum, over all request sequences, of the ratios<br\/>between the solution computed by the online algorithm and the optimal<br\/>(offline) solution. Thus, an algorithm with competitive ratio, say,<br\/>1.5, always computes a solution that is within 50% of the minimum.<br\/><br\/>This research deals with the competitive analysis of online algorithms.<br\/>Several research directions are being explored. The first direction<br\/>is to study general techniques for the design and analysis of online<br\/>algorithms. Here, the most promising ideas include the<br\/>work-function algorithm (and its extensions) and the primal-dual method.<br\/>Both of these techniques, as well as some other, have been successfully<br\/>applied to specific online problems, but the mechanism behind their<br\/>success is still poorly understood, and they still require an in-depth<br\/>study to determine their applicability to other problems. Another<br\/>direction is to study several extensions of the competitive analysis,<br\/>including access graphs (for caching), diffuse adversaries, loose<br\/>competitiveness and resource augmentation. This work focuses on some open<br\/>problems related to these models, on adapting these models to other<br\/>online problems, and on designing new problem-specific models. The<br\/>investigator is also continuing his work on several classical<br\/>problems in competitive analysis, including the k-server<br\/>problem, several versions of caching and scheduling problems,<br\/>the k-median problem, and other. The main goals of these efforts<br\/>are to develop efficient competitive algorithms for these problems<br\/>and to establish matching lower bounds on the competitive ratios.","title":"Online Competitive Algorithms","awardID":"0208856","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["517719"],"PO":["499399"]},"76684":{"abstract":"Award number: 0229809<br\/>PI: Robin R. Murphy<br\/>Institution: University of South Florida<br\/>Title: Adaptive Shoring for Robot-Assisted Search and Rescue<br\/>The long-term goal for this project is to contribute to the science and engineering that will enable development of a network of distributed shoring mobile robots. Each robot would be able to position itself in the rubble pile in places where humans and other tools could not go (mobile), adapt the pressure in the air bags to shifts in the structure as well as identify better positions to provide support (adaptive), and would work in concert with other shoring robots to maintain stability (distributive). This type of system would be an important addition to urban search and rescue teams and has been specifically requested by FEMA and regional response teams in the aftermath of the WTC.<br\/><br\/>While immediate progress in shoring can be made by simply coupling air bags with man-packable robots (such at those used by the PIs at the WTC), a true breakthrough depends on advances in sensing, distributed control and communications technology. The adaptive shoring application is both novel in its demands on distributed, real-time cooperative control of robots and its need for sensors for damage assessment. As a result, there is a high risk that a traditional multi-year research project is premature because the demands of the domain and the relevant state of the art are unknown.<br\/><br\/>This one-year exploratory project will investigate the feasibility of contact and remote sensors for local adaptive shoring (e.g., load on the air bag) and for dynamic placement of the robots (e.g., location of the load based on damage). Laboratory and field experiments with a distributed team of two air bags and robots will also be conducted. The results are expected to be a trade study of sensing, an assessment of the requirements of adaptive shoring for sensing, distributed control and communications, and prototype equipment that will be available for use in real emergencies. The lessons learned will be captured through journal publications for both the robotics and structural engineering communities and, should the data support it, as a full proposal.","title":"SGER: Adaptive Shoring for Robot-Assisted Search and Rescue","awardID":"0229809","effectiveDate":"2002-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1468","name":"Manufacturing Machines & Equip"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1631","name":"CIVIL INFRASTRUCTURE SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1638","name":"INFRAST MGMT & EXTREME EVENTS"}}],"PIcoPI":["565226"],"PO":["496112"]},"75353":{"abstract":"EIA 02-22628<br\/>Kavi, Krishna M.<br\/>Mikler, Armin R.; Swigger, Kathleen M.; Wilson, Angela K.<br\/>University of North Texas <br\/><br\/>CISE RR: Computational Science and Engineering: Intelligent Information Acquisition and Management Infrastructure<br\/><br\/>This proposal, addressing multithreaded computer architectural and sensor-network simulations, concurrent analysis of multiple flight data recorders, and computational chemistry, requests a Beowulf cluster, a Sun multiprocessor, and a 1.3TB storage device to enable research in the following four projects:<br\/><br\/>1. Scalable Clustered Multithreaded Architecture for Embedded and DSP Applications,<br\/>2. SensorNet,<br\/>3. Analysis of Flight Data Recorder (FDR) Information, and<br\/>4. Computation Chemistry: Quantum Chemical Functional Group (QCFG) approach.<br\/><br\/>The first project evaluates the suitability of multithreaded architectures for embedded and DSP systems developing customizable and scalable implementations to meet the performance and energy requirements of future embedded and DSP applications. The second designs and implements an agent-based monitoring infrastructure to facilitate data-acquisition and event-correlation for large number of widely distributed environmental sensors of different types. This project aims at integrating the Leibniz system for computation based on prepositional logic. The third project concentrates on problems related to the organization and management of large, real-time distributed knowledge investigating various architectures and systems for real-time transmission of flight data to insure more accurate and reliable information. Looking into real-time collaborative interfaces that can support distributed communications and collective decision-making, this projects examines data mining techniques that can be used to aid in post-mortem analyses of accidents. The last project enables an approach to obtain quantitative descriptions of structures, energetics, and other properties for intermediate- to large-sized molecules.<br\/>The equipment is expected to lead to new research in Intelligent Information and Intelligent Resource Management.","title":"Research Resources: Computational Science and Engineering: Intelligent Information Acquisition and Management Infrastructure","awardID":"0222628","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["13545","334005","448584","557985"],"PO":["557609"]},"72097":{"abstract":"Energy is becoming the limiting resource for many applications, as processor performance and network bandwidth continue to rapidly advance. Devices such as wireless sensor networks, cell phones with integrated personal organizers (PDAs), laptops, and even Internet hosting centers are all concerned about power consumption either due to limited battery capacity or the high cost of operating and cooling large server farms. In many of these systems main memory can become a significant portion of the overall power budget, particularly with the advent of low-power, high-performance processors.<br\/><br\/>This project investigates main memory power management research issues that span several levels of computer system design: from the operating system managing memory power states, to the design characteristics of platform architectures, and finally down to the details of internal DRAM organization.<br\/>This project will investigate power management design decisions within each system level and explore interactions across levels.","title":"Main Memory Power Management","awardID":"0208920","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["353750","555929"],"PO":["325495"]},"76233":{"abstract":"EIA - 0227845<br\/>Yanco, H <br\/>Univ of Massachusetts at Lowell <br\/><br\/>TITLE: Student Travel to the AAAI Robot Competition and Exhibition<br\/><br\/>This award provides support for fifteen students, with special efforts made to incorporate women and underrepresented minorities, to attend and participate in the AAAI Robot Competition and Exhibition at the National Conference on Artificial Intelligence (AAAI-2002) in Edmonton, Alberta. This event brings together robotics researchers from colleges, universities and research laboratories to compete and to demonstrate cutting edge, state of the art research in this area. Students attending benefit from observing demonstrations of the research, networking with students from other institutions with similar interests, presenting and discussing their own research, and through a significant mentoring program. Every supported student will be expected to write a one or two page report on her or his experiences at the competition and exhibition. These reports will be used in evaluating the success of the funded student participation in the event.","title":"Student Travel to the AAAI Robot Competition and Exhibition","awardID":"0227845","effectiveDate":"2002-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["526078"],"PO":["329035"]},"75386":{"abstract":"This is a Collaborative Proposal between Northwestern University and University of Florida which addresses the key research challenges associated with management of dynamic Virtual Machines (VM) and interfacing these mechanisms with existing grid middleware techniques. The project will develop novel solutions that will address<br\/>- resource management for distributed virtualized end-resources that can be created dynamically,<br\/>- image management for the on-demand transfer of data representing the entire state to create a dynamic VM instance, and<br\/>- data management for the on-demand transfer of user and application data between decoupled compute and data servers on the grid.<br\/><br\/>The proposed approach will lead to middleware solutions that will form an information processing foundation for grid computing. The software generated in this project will be sued to implement the next generation of network computing hubs currently being used to support simulation needs in nanotechnology, electronics CAD, computer architecture and parallel programming.<br\/><br\/>The project addresses key research challenges to allow the management of dynamic instances of virtual machine middleware and will lead to solutions that will form an information processing foundation for grid computing on virtualized end-resources. In particular, the software generated in this project will be used to implement the next generation of network computing hubs currently being used to support simulation needs in nanotechnology, electronics CAD, computer architecture and parallel programming.","title":"Collaborative Research: Resource and Data Management for Virtualized End-Resources in Computational Grids","awardID":"0222828","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["540130"],"PO":["7594"]},"76145":{"abstract":"ABSTRACT<br\/>0227337<br\/>Douglas M. DeCarlo<br\/>Rutgers U, New Brunswick<br\/><br\/>We propose to show that non-photorealistic renderings which exhibit meaningful abstraction<br\/>are easily understood. Abstract images are designed to make meaningful structure clear. We have<br\/>worked on the interactive transformation of photographs into versions which manifest meaningful<br\/>abstraction by drawing on eye movement data [DeCarlo & Santella SIGGRAPH 2002, Santella &<br\/>DeCarlo NPAR 2002]. Over the next year, we intend to carry out psychophysical experiments that<br\/>could both validate our interactive technique, and provide new ways of learning more about human<br\/>vision eye movements, in particular.<br\/>This is high-risk research. Non-photorealistic rendering (NPR) is an established field, but has<br\/>never been evaluated. Psychophysical methods are typically applied to simple patterns (i.e. dots<br\/>and blobs). However, our method already involves a close link between NPR and perception and<br\/>psychophysics, and our lab maintains close connections with psychophysicists including Eileen<br\/>Kowler and Thomas Papathomas (both are, like us, affiliated with the Rutgers Center for Cognitive<br\/>Science). Many simple conjectures and experiments can be stated naturally in our framework; we<br\/>believe we can obtain compelling results.","title":"Evaluating Non-Photorealistic Rendering","awardID":"0227337","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["355043"],"PO":["532791"]},"77476":{"abstract":"This project is to research and develop a self-assembling system (with an option for human remote control) for deploying, storing, docking, and assembling the Space Solar Power System (SSPS) in space. The research challenges include the design for self-assembling components, the control for a self-assembly process, the autonomous docking among components, and the coordination of components' actions for precision maneuvers in space. The project will build upon the latest technologies from self-reconfigurable modular robotics and develop (1) a novel design for building the Intelligent and Reconfigurable Components (IRC) for SSPS; (2) the free-flying \"intelligent fiber\/rope\" \"match-maker\" (FIMER) robots with self-reconfigurable and self-adjustable tethering for matching, fetching, and docking among IRCs; and (3) a biologically inspired, totally distributed control method called the Digital Hormone Model for planning, executing, and monitoring the self-assembly process. All IRCs and FIMER robots use the same type of docking connectors, and each FIMER robot is a self-adjustable string with free-flying heads that can attach to any connectors in the system. Using these concepts, the sequence of self-assembly can be either pre-programmed in IRCs or remotely controlled by humans. The project will also investigate effective and practical solutions for dynamic control in micro-gravity environments, and new construction techniques for reducing payload for space transportation. All these new technologies will be validated on earth by free-flying prototypes generalized from an existing self-reconfigurable robotics system called CONRO to perform self-assembly in the laboratory, and the results of these experiments will eventually lead to a flight-qualified system for testing in space.","title":"The Assembly, Maintenance, Service for Space Solar Power Systems via Self-Reconfigurable Modules (SSP-SRM)","awardID":"0233364","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V483","name":"DARPA-MIDSTEP PROGRAM"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"W415","name":"NASA-SSP"}}],"PIcoPI":["560305","212108",202092],"PO":["403839"]},"74760":{"abstract":"This project concerns authentication, audit trails, and privacy in secure electronic transactions, with the intended scope encompassing a wide array of daily activities such as banking, on-line shopping, elections, and surveys. Some of these activities are already be based in part on electronic transactions today, but would benefit from better mechanisms for security. Other activities have the potential to be performed electronically given greater confidence in the security infrastructure surrounding electronic transactions.<br\/><br\/>This project develops the design of a concurrent domain-specific language for distributed electronic transactions that will provide more security guarantees and automation of checks than has been previously done in such languages. It proposes an alternative to security based on software packages with dynamic checks, by a type-theory based approach where security guarantees are verified automatically and statically via typechecking, factoring out checks that other approaches perform dynamically for every execution, and performing them only once at compile time.<br\/><br\/>Efforts in these directions are potentially rich in social and economic benefits. Research on secure electronic transactions will directly reduce the incidence of electronic fraud, theft, and forgery, improving the quality and extending the scope of the software available to the general public.","title":"ITR:Secure Electronic Transactions","awardID":"0220286","effectiveDate":"2002-09-01","expirationDate":"2006-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["384403","549775","546946"],"PO":["521752"]},"71130":{"abstract":"Pnueli, Emerson, and Sistla<br\/>CCR-0205571, CCR-0205483 and CCR-0205365<br\/>\"Towards a Seamless Process for the Development of Embedded Systems\"<br\/><br\/><br\/>Embedded systems are of vital economic importance and are literally<br\/>becoming ubiquitous. They have already become an integral component of<br\/>safety critical systems involving aviation, military,<br\/>telecommunications, and process control applications. Interest in<br\/>embedded systems is growing further due to the expectation that they<br\/>will become a key component of many commonplace consumer appliances.<br\/>Consumers will expect levels of reliability and predictability<br\/>associated with the very best brands of cars, televisions, and<br\/>refrigerators. Glitches, crashes, and general erratic behavior of the<br\/>sort seen with prior generations of consumer PC software products will<br\/>be unacceptable for these embedded applications. It thus becomes<br\/>crucial that these embedded software systems satisfy high levels of<br\/>correctness criteria, well above those of today's large software<br\/>systems, which are often highly error-prone.<br\/><br\/>Besides the requirement of a new standard of functional correctness,<br\/>embedded systems pose additional challenges which were not fully<br\/>addressed by previous validation and verification approaches. These<br\/>include adequate guarantees of timeliness, low or controlled power<br\/>consumption, and low or controlled memory utilization. With the<br\/>spread of embedded systems, and the need to guarantee an acceptable<br\/>level of functionality and reliability of the applications they are<br\/>embedded in, the industry needs an effective and reliable development<br\/>process. Due to market constraints, such a process should also support<br\/>a fast turn-around time as well as enable the easy design of many<br\/>customized variations of the same product.<br\/><br\/>This project is developing the foundation for a seamless design<br\/>process for embedded systems as described below. In particular, it is<br\/>developing:<br\/><br\/> A formal visual language for requirements, including behavioral,<br\/> temporal, and TPM constraints;<br\/><br\/> A methodology for the automatic synthesis of an executable<br\/> specification from the requirement specification language;<br\/><br\/> A methodology for the verification of the intermediate and<br\/> distributed representation of the systems against requirements;<br\/><br\/> A methododology for automatic code-distribution of<br\/> specifications, possibly with some architectural constraints<br\/> provided by the user;<br\/><br\/> A model for representing hardware\/software co-design<br\/> platforms that enables modeling of both loosely- and tightly-coupled<br\/> components as well as compositional reasoning about them;<br\/><br\/> Algorithms for automatically generating <br\/> architecture-optimized code from executable specifications;<br\/><br\/> Methods for translation validation of the<br\/> generated code and run-time validation on the system using<br\/> monitors;<br\/><br\/> The Design of a profiler process which analyzes machine code,<br\/> computes the resulting figures for time, power, and memory, and<br\/> back-associate these figures with their executable specification<br\/> sources, enabling early-stage analysis of these requirements.<br\/><br\/>The impact of the project is to streamline and significantly<br\/>accelerate the time to market of embedded applications of both new<br\/>products and revisions and customizations of existing product lines.<br\/>Another impact is to upgrade the level of dependability and<br\/>predictability of embedded software to new standards, compatible and<br\/>comparable to those expected from the best brands of consumer<br\/>products.","title":"ITR: COLLABORATIVE RESEARCH: Towards a Seamless Process for the Development of Embedded Systems","awardID":"0205483","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[184167,184168],"PO":["561889"]},"70173":{"abstract":"EIA 02-02067<br\/>Bestavros, Azer<br\/>Betke, Margrit; Crovella, Mark E.; Matta, Ibrahim; Sclaroff, Stan<br\/>Boston University <br\/><br\/>RI: SENSORIUM: Research Infrastructure for Managing Spatio-Temporal Objects in Video Sensor Networks<br\/><br\/>This project, developing an open sensor network research infrastructure (SENSORIUM), aims to catalyze fundamental advances in image and video computing, network protocols, and resource management to deal with unique spatio-temporal constraints of sensor networks. SENSORIUM is composed of a sensor network of video cameras spanning several rooms, networked processing units, and a terabyte database, managed together to satisfy queries using those generated by mobile users within this environment. The infrastructure enables the following research projects:<br\/>a. Modeling, interpretation, and prediction of human motion in video streams at multiple <br\/>scales in space\/time and at multiple layers of detail; <br\/>b. Development of efficient location management, routing, transport, and content <br\/>distribution protocols for multi-resolution\/scale streaming sensory data networks; <br\/>c. Characterization of traffic and access patterns in mobile sensory networks; <br\/>d. Instrumentation of embedded real-time operating systems to enable coordinated resource management and the development of middleware services for the management of active sensor networks; <br\/>e. Indexing and mining of large spatio-temporal non-textual sensory datasets, with a particular emphasis on mining of human motions and activities; <br\/>f. Enhancing code safety for embedded systems through the use of type systems and run-time support, with emphasis on flow-oriented programming; <br\/>g. Development of algorithms and protocols for supporting security and trust, and for protecting the confidentiality and integrity of data in video sensor networks and repositories.<br\/><br\/>These collaborative projects target two vertical applications. The first aims to merge the physical and cyber worlds in an integrated, well defined, privacy-protecting manner. It involves the development of a system capable of gathering, interpreting, routing, and storing data from distributed video sensors, and answering queries about the physical world on the Web. The second aims to develop assistive environments for people with severe disabilities, to help them gain access to computers, and thereby obtain a tool to communicate with their environments. These applications will unify the various research projects leveraged by the SENSORIUM by acting as catalysts for the development of generic technologies that could be used (and reused) in other vertical applications.","title":"CISE Research Infrastructure: SENSORIUM: Research Infrastructure for Managing Spatio-Temporal Objects in Video Sensor Networks","awardID":"0202067","effectiveDate":"2002-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["562061","486062","472054","438360","557296"],"PO":["564316"]},"74661":{"abstract":"The goal of the proposed research is to efficiently exploit on-chip parallelism via the design and evaluation of a dynamically tunable clustered multithreaded (DT-CMT) architecture. <br\/>The proposed architecture will combine the utilization advantages of simultaneous multithreaded architectures (SMTs) with the speed advantages of chip multiprocessors (CMPs). <br\/>The PIs will design an architecture that can be rapidly configured into a restricted number of organizations (so as to minimize speed and density impact) in order to balance instruction-level parallelism and thread-level parallelism to maximize utilization and minimize energy. <br\/>Key to this approach will be the development of software systems (compilers, runtime systems, multiprogramming and multithreaded support) that analyze application requirements and combine this<br\/>knowledge with feedback mechanisms from the hardware. The performance and power saving potential of this approach will be characterized via simulation.<br\/><br\/>This project has the potential to significantly impact the microarchitecture and software of future server and network processors, and will help train the graduate students in the design of future increasingly process technology-aware architectures. The proposed work will allow dynamic tailoring of the processor<br\/>architecture in order to meet the needs of increasingly diverse applications, thereby allowing future processors to scale as process technology improves.","title":"ITR: Dynamically Tunable Clustered Multithreaded Architectures","awardID":"0219848","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["556692","550887","550486"],"PO":["325495"]},"74672":{"abstract":"Proposal Number CCR-0219893<br\/><br\/>Title: ITR: Printer Characterization and Signature-Embedding for Security and Forensic Applications<br\/><br\/>Co-Principal Investigators: Jan P. Allebach, Edward J. Delp, and George T. Chiu<br\/><br\/>We propose to develop two strategies for printer identification. The first strategy is passive. It involves characterizing the printer and finding intrinsic features in the printed output that are characteristic of that particular printer, model, or manufacturer's products. We call this the intrinsic signature. Developing the intrinsic signature requires an understanding and modeling of the printer mechanism, and the development of image analysis tools that are used for printer characterization during the signature development phase, and then later, for the actual detection of the signature in printed pages with arbitrary content.<br\/><br\/>The intrinsic signature is detected by scanning the printed pages with a high resolution drum scanner, and applying low-level image analysis routines to extract features. These features are processed with a soft classifier to yield likelihoods at each level of a decision tree that the document was printed with a device belonging to each particular class. At the highest level of the decision tree, likelihoods are provided for which of the two possible dominant printing technologies: electrophotography (commonly referred to as a laser printer) and inkjet was used. At the next level,likelihoods are generated for the candidate printer manufacturers, and so on. As we proceed down through the tree, we generate liklihoods regarding information that is more and more specific to the particular printer in question.<br\/><br\/>The second strategy is active. Here we embed an extrinsic signature in every printed page. This signature is generated by modulating the process parameters in the printer mechanism to encode identifying information, such as the printer serial number and date of printing, in every printed page. To detect the extrinsic signature, we again scan the printed pages, and process them using image analysis techniques; but in this case, our goal is to decode the signature to extract the information embedded in it. Development of the methodology for extrinsic signature embedding will build directly on our work with intrinsic signatures. We will use our knowledge of the printer mechanism models and the results of the printer characterization to determine the printer process parameters that can be modulated to encode the desired identifying information. The modulation of these parameters will require modification to the actual printer mechanism.<br\/><br\/>A distinguishing feature of the proposed effort will be the development of an undergraduate project course that will be associated with the research. In this course, students will learn about printing technologies and the application of electrical and mechanical engineering theory from their core courses to analysis and modeling of printing systems. They will also learn about image processing and decision theory; and they will see how all these tools can be applied to the solution of practical real-world problems.","title":"ITR: Printer Characterization and Signature-Embedding for Security and Forensic Applications","awardID":"0219893","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["563744","284859","385369"],"PO":["521752"]},"72131":{"abstract":"The general area within which this research is performed is known as<br\/>computational learning theory. The starting point for research in this<br\/>area is typically the definition of mathematical models of what the term<br\/>``learning'' may mean in a variety of settings. The concept of learning<br\/>captured by these models is then formally analyzed, frequently leading<br\/>to algorithms for solving learning problems within the models as well as<br\/>to proofs that certain problems cannot be solved. These<br\/>learning-theoretic models and results lend support to more applied work<br\/>in machine learning, which in turn has demonstrated utility in<br\/>applications ranging from e-commerce to advanced research on vehicles<br\/>that drive themselves.<br\/><br\/>This project adds to the existing body of learning-theoretic knowledge<br\/>in a number of ways, including analysis of a relatively new model called<br\/>Probably Exactly Correct learning, development of an algorithm that<br\/>learns arguably the broadest class of functions yet shown to be<br\/>learnable (majority of AC0 functions), and work toward extending<br\/>hardness results for learnability of a fundamental class, the class of<br\/>parity functions. The key tool used in these and other project tasks is<br\/>Fourier analysis of classes of functions. While the primary purpose of<br\/>the Fourier analysis is to support research into learning questions, a<br\/>side benefit is the enhancement of our understanding of several<br\/>interesting classes of functions, such as majority of AC0. Furthermore,<br\/>this project provides a stimulating research experience to undergraduate<br\/>and master's students at a university that, from an NSF perspective, is<br\/>largely an undergraduate institution.","title":"RUI: Fourier Analysis of Learning Problems and Function Classes","awardID":"0209064","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["348029"],"PO":["499399"]},"71163":{"abstract":"EIA-0205628 Theodore B. Trafalis University of Oklahoma ITR: A Real Time Mining of Integrated Weather Data<br\/><br\/>The mission is to build systems and develop theory for extracting information and identifying patterns that are useful for making decision in real-time. Funding is being requested to build pattern recognition techniques that will exploit multisensor data in an integrated manner to provide information such as the presence or absence of tornados, supercells and mesocyclones; estimate precipitation; predict the occurrence of flash floods; assimilate and display large volumes of multisensor data and trigger the archive of selected data sets. These tasks will be accomplished by customizing and developing techniques for real-time data mining. The approaches used will include traditional data reduction methods such as PCA and clustering; Procrustes analysis; Kalman filters and non-linear time series analysis with regime switching; and, decomposition and robust optimization methods for training support vector machines.","title":"ITR: A Real Time Mining of Integrated Weather Data","awardID":"0205628","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["559125",184289,"381873","393628","257547"],"PO":["551712"]},"72142":{"abstract":"ABSTRACT<br\/>What is the ``typical\" traffic of a link? What constitutes ``abnormal\" traffic, and therefore warrants an alert for suspicious behavior (intrusion)?<br\/>How will the Internet look like next year? These are the questions that the project focuses on.<br\/><br\/>It has two major thrusts:<br\/>The first is to find patterns in the network traffic, and the second is to find trends in the Internet evolution. The technical merit is in the synergy of the networking and data mining fields, pushing the envelope in both:<br\/>The networking field will enjoy novel insights and fast tools to predict the network performance. The data mining field will benefit from new problems<br\/>and new tools (using fractals, power laws, large-graph algorithms), that will be stress-tested on multiple Gigabytes of real, network data. <br\/><br\/>The broader impact of this work will be a novel insight of the network behavior at the micro and macro level. In addition, the work will explore our ability to predict the network behavior and its evolution. As a result, the work will provide new tools to identify abnormal behavior, that could be due to a security breach like a DDoS attack.","title":"Collaborative Research: NetMine: Finding Patterns in Network Data","awardID":"0209107","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["548220"],"PO":["563751"]},"74562":{"abstract":"EIA-0219310<br\/>Peter McCartney<br\/>Arizona State University<br\/><br\/>Title: Networking Urban Ecological Models Through Distributed Services<br\/><br\/> Urbanization is a central force in altering core ecological processes such as biogeochemical cycling, decreased biodivesity and changing land use and land cover. Understanding and managing these processes is crucial to sustaining natural resources and maintaining quality of life. The goal for this project is to develop and deploy a distributed information infrastructure so that diverse members of the urban ecological research community in central Arizona can benefit from integrated ecological models and data. Government agencies involved will include the Maricopa Association of Governments and the Arizona Dept. of Water Resources.","title":"ITR: Networking Urban Ecological Models Through Distributed Services","awardID":"0219310","effectiveDate":"2002-09-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["522273","547710","538611","260091",193662],"PO":["371077"]},"74694":{"abstract":"EIA-0220021 Wei-Hsu University of Minnesota-Twin Cities ITR: DREAM-Dynamic RE-optimization for Application Migration<br\/><br\/>This project proposes the design and implementation of a common dynamic binary re-optimization system called DREAM (Dynamic RE-optimization for Application Migration). DREAM can be used for migrating compatible legacy application binaries such as moving applications in Intel 486 code to Pentium IV processors, or moving IA-64\/Itanium code to IA-64\/McKinley processors. DREAM can also be used to improve the performance of migrating incompatible application binaries, such as moving applications in Unisys x2200 code to the new IA-64 processors. In this case, a dynamic translator first translates the incompatible binaries into native code and stored in a translation cache. DREAM will focus on speeding up the native code stored in the translation cache. Furthermore, DREAM can be used to speed up applications released in intermediate form that may require generating native code dynamically for higher execution efficiency.","title":"ITR: DREAM -- Dynamic Re-optimization for Application Migration","awardID":"0220021","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["383979","383980"],"PO":["301532"]},"71185":{"abstract":"While handheld, battery-powered devices such as personal digital<br\/>assistants (PDA's) and web-enabled mobile phones are emerging as new<br\/>access points to the world's digital infrastructure, their cost and<br\/>short battery life are factors that are holding back their enormous<br\/>potential. Worse yet, the cost of such devices might even widen the<br\/>\"digital divide\". This research addresses these cost and battery-life issues<br\/>simultaneously, thereby getting one step closer to a vision of ubiquitous<br\/>computing embracing all of society. The specific focus is the digital university<br\/>campus with wireless Internet coverage.<br\/><br\/>In this setting, the aim is to increase the utility and battery-life<br\/>and decrease the cost of handheld wireless computers by enabling the<br\/>use of relatively simple hardware for the mobile devices. This research aims<br\/>both at designing embedded hardware that better conserves resources, as well as<br\/>creating a software layer that masks the limited computational prowess<br\/>of a handheld device by seamlessly coupling it to a relatively high-powered<br\/>stationary computational infrastructure via an \"always on\" wireless connection.<br\/>By off-loading power-intensive operations to the stationary infrastructure,<br\/>the battery-powered mobile device is provided with \"virtual power\".<br\/><br\/>Adaptive just-in-time compiler technology will be developed for minimizing<br\/>power use on mobile devices running mobile<br\/>code, and adaptive scheduling methods using results from the<br\/>Computational Grid research community. Depending on the algorithm to<br\/>be run on the mobile device and its current distance from the nearest<br\/>base station, the computation to be performed is to be automatically<br\/>partitioned between a part to be executed in the stationary<br\/>infrastructure and another to be run on the mobile device.<br\/><br\/>At the hardware level, orchestrated resource-management strategies will be<br\/>developed to enable designers to correctly design and implement highly<br\/>resource-constrained embedded systems while helping them to meet system-level<br\/>constraints. This requires augmenting today's functional design flows with a<br\/>resource-centric view. Here, the goal is not to replace existing design methodologies<br\/>with yet another all-encompassing methodology, but rather making a cross-cutting<br\/>impact by demonstrating the applicability of results to several driving examples<br\/>at different levels of abstraction, including System-on-Chip (SoC) platforms,<br\/>memory architecture level, and operating system level.","title":"ITR: Virtual Power for a Wireless Campus - A Vision of Ubiquitous Computing On Low-Cost Mobile Devices","awardID":"0205712","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["541836","402357","486136","561463"],"PO":["561889"]},"72054":{"abstract":"How does a computer determine that user requests are authentic? Currently, users must prove their identity from time to time, and this authentication is assumed to hold for all user requests until it is either explicitly or implicitly revoked. This model is poorly matched to mobile devices, which are prone to loss or theft. An adversary, holding the device of a trusted user, has the full authority of that user for the remainder of the authentication period. Systems that require more frequent authentication are burdensome; users disable or work around such safeguards, forfeiting their protection. This problem is addressed by a technique called transient authentication. Rather than invest long-term authority with a mobile device---something easily set down or stolen---it is retained within a small authentication token worn by the user. <br\/><br\/>This research explores the implications of making authentication, traditionally a persistent property, into a transient one. Transient authentication will be applied to process state and file system state. An application programming interface (API) will be designed, and a number of applications and services ported to it. The system will be evaluated through controlled benchmarking, establishing the claims of performance and usability. The resulting system will provide strong protection against loss or theft without inconveniencing authorized users.","title":"Transient Authentication for Mobile Devices","awardID":"0208740","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"V116","name":"NSA-TRAN AUTH FOR SECUR PDA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["530391"],"PO":["529429"]},"77741":{"abstract":"The purpose of the proposed project is developing novel fault-tolerance techniques which exploit the synergy between the host and network processors in high-speed networked systems, and providing<br\/>tools for their validation and the assessment of their effectiveness.<br\/><br\/>Our project will include the following tasks:<br\/><br\/>* Construct a layered architecture with a symbiotic relationship <br\/>between the network and host processors so that fault tolerance<br\/>is provided.<br\/><br\/>* Develop expanded fault injection capabilities in order<br\/>to study and fully understand the fault propagation and detection<br\/>process in a network architecture.<br\/><br\/>* Develop a tool for validating our fault detection and recovery <br\/>policies and evaluate their effectiveness in a networked system using<br\/>both traditional and specially constructed dependability measures. <br\/><br\/>* Integrate our fault tolerance layer and the evaluation and<br\/>validation tool into the NASA testbed. <br\/><br\/>This project will deliver techniques to better utilize the resources of modern network architectures for fault detection and recovery. Such techniques are crucial in space missions, which are characterized<br\/>by the need for a proper management of computational and networking resources for missions lasting years in severely resource-constrained applications.","title":"Achieving and Validating Higher Dependability Through Host and Network Processor Collaboration","awardID":"0234363","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}}],"PIcoPI":["553614","553615"],"PO":["564388"]},"74595":{"abstract":"This project will build information retrieval interfaces for the rapidly<br\/>expanding but virtually unstudied domain of biodiversity databases. An<br\/>understanding of the nature and magnitude of biological diversity is fundamental to most pressing environmental and conservation debates. Biodiversity databases contain organism-related information such as distribution, taxonomy, natural history, and conservation data. This project will combine information visualization techniques and rapid feedback dynamic query interfaces coupled with an aggressive approach of working with representative users at all levels, from design through evaluation. It will also utilize zoomable interfaces to allow users to navigate multiple hierarchies, in order to visually accommodate highly interconnected data. The goals of the project are: <br\/> * To develop a searching interface for biodiversity databases <br\/> targeting domain-novice adults. <br\/> * To build interfaces combining \"folk\" and \"scientific\" understanding. <br\/> * To evaluate the developed interfaces and compare them to existing <br\/> interface models in the biodiversity domain.","title":"Search Interfaces for Biodiversity Informatics","awardID":"0219492","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["426438"],"PO":["563727"]},"65894":{"abstract":"Information is currently accessed and manipulated using a variety of fragmented tools. The researchers use a desktop computer as our primary information tool, a server, network of servers, or an ISP to provide file system support, computationally intensive computing, and other system support functions. They use a notebook computer, which may or may not have network access, when they desire a portable information tool. When information needs are modest, and mobility needs most apparent, the researchers use a variety of other devices such as handheld computers, personal digital assistants, cellular telephones, and pagers. Software version management in this situation is inefficient, and licensing is complex. Ensuring that the same (and latest) version of each desired application program is installed on a large number of computers can consume a significant amount of system support staff resources, even if these computers are accessible from the same network. The protection of information from unauthorized access is similarly difficult.<br\/><br\/>The result of this fragmentation of data, applications, and devices is an increasingly complex and unmanageable collection of information tools that communicate with each other ineffectively. The convergence in time of substantial need, substantial communication infrastructure, and high performance, low power computing resources challenges the researchers to explore a better alternative. The Bifrost location independent computing project seeks to provide a flexible and comprehensive information access environment. The function of Bifrost is to provide location and device independent access to data. Data in Bifrost encompasses both information and the applications used to manipulate that information. Bifrost uses affinity between data, and between users and data, to make appropriate decisions about when and where to move data. We refer to this approach as affinity directed mobility.<br\/><br\/>The core research issues of the project are mobility management (how we move data and threads to support user and device mobility), data management (how we represent, access, update, and protect information), and application management (how we provide a common applications base across a variety of devices). In contrast to previous approaches to mobile data management, Bifrost anticipates that in 3-5 years network connectivity will be the norm, even for highly mobile computing devices. In this situation, the problem of how users can access remote personal data, regardless of location or computing device, becomes at least as important as planning for a possible disconnection.<br\/><br\/>The researchers propose to design, implement, deploy and evaluate a two-campus prototype of the Bifrost location independent computing system. The Bifrost design represents a new paradigm for information access and manipulation. We propose to integrate the way in which information is managed with the way in which the applications that access this information are managed. One of the design principles of Bifrost is that the ability to access data should be consistent across all platforms, including portable computing devices. This approach is in stark contrast to the stripped down operating system plus stripped down applications plus limited data set computing model currently associated with most hand-held computing devices.<br\/><br\/>In addition to the educational benefits to the students directly involved in the project, the researchers intend that this project contribute in broader ways to the academic community. They will incorporate this research into the operating systems and distributed systems classes taught at the University of Colorado and Cornell University. All software and other research products of this project will be made readily available via the world wide web.","title":"Collaborative Research: Affinity Directed Mobility for Location Independent Data Access","awardID":"0126341","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["384485"],"PO":["565090"]},"74364":{"abstract":"EIA-0218256<br\/>Wendell Lim<br\/>University of California- San Francisco<br\/><br\/>Engineering Protein-Based Logic Gates<br\/><br\/>Living cells use protein-based signal transduction circuits to decide how to respond to environmental stimuli. In eukaryotic cells these signaling networks are organized in a hierarchical, component-based manner -- they are assembled from multiple interacting proteins, while individual proteins are assembled from combinations of a finite toolkit that includes catalytic domains (e.g. kinases, phosphates) and protein interaction domains. Current hypotheses suggests that complex cellular circuitry may have evolved through recombination of these protein domain components. The overall goal of this project is to exploit this framework to engineer novel protein-based sensors, circuits, and computational devices. The initial focus is on individual signaling proteins that function as input\/output switches, analogous to the fundamental logic gates used to build complex electronic circuits. The proteins often have an output activity that is only triggered by a specific set of upstream inputs. Recent studies suggest that these regulatory properties result from a relatively simple mechanism in which the interplay of intra- and intermolecular domain interactions controls protein conformation and therefore activity. In this project domain recombination is being used to reprogram natural catalytic activities (e.g. acting nucleators, kinesis, phosphates) such that they are precisely controlled by a combination of selected molecular inputs (e.g. specific peptide ligands, phosphorylation\/dephosphorylation). Targeted switch designs include AND, NAND, NOR, and XOR-type input\/output relationships. If successful, this project will allow for engineering of complex cell-based sensors.","title":"Engineering Protein-Based Logic Gates","awardID":"0218256","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":[193121],"PO":["521045"]},"74485":{"abstract":"The ITR: Flathead Reservation Wireless Community Network at Salish Kootenai College would examine, explore, and adjust how people utilize wireless communications technology on this rural reservation to interface more effectively from remote locations. This project will facilitate changes in educational and business organizational processes in fixed wireless telecommuting through various wireless networking technologies. In addition, this project will also greatly enhance numerous programs and research projects both on campus and with other organizations throughout the reservation. Other activities that will be implemented are technologies and services that assist in teaching, training and the expansion of innovative educational environments.<br\/><br\/>The goal of this project is threefold. First, to see how far you can push wireless technology in a rural and remote environment to provide high-speed network connections. Second, to radically change the way certain educational and business organizational processes are carried out. Third, enhance peoples' experiences with information technology through a variety of wireless activities. <br\/><br\/>During the first 6 months of the project, a single high-speed wireless link will be deployed to provide service to a selected part of the reservation. The second 6 months will focus on conducting the initial research activities, review of any results. The third <br\/>6 months will be devoted to making adjustments and modifications to ongoing research activities, and the addition of another high-speed link. The final 6 months will be focused on making the transition to a fully self-sufficient, community-owned network.<br\/><br\/>The Flathead Reservation Wireless Community Network will be collaborating with other tribal entities on conducting research test connections to examine the usefulness and how people respond to high-speed wireless network connections. Over the course of the project, various wireless networking technologies will be employed as they become available to test the reliability, functionality and practicality of each. Also, this project will collaborate with other NSF-sponsored projects with a wireless component and\/or focus.","title":"ITR: Flathead Reservation Wireless Community Network","awardID":"0218915","effectiveDate":"2002-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["538777"],"PO":["250082"]},"72076":{"abstract":"The thrust of this collaborative project is to design, analyze and implement efficient algorithms for several tiling, packing and covering problems with rectangles in two or higher dimensions with applications in diverse areas such as: VLSI, computer graphics, image processing, database design, data mining and computational biology. Since computing exact solutions for almost all of these problems is provably hard, the goal is to use diverse unifying techniques of algorithm design such as local-ratio, multi-phase methods, and slice-and-dice methods, and linear programming with nontrivial rounding and primal-dual schema. They will develop novel data structures on grids for efficient approximation algorithms for these problems.","title":"Collaborative Research: Efficient Combinatorial Algorithms for Several Tiling, Packing and Covering Problems with Rectangles and Hyper-Rectangles","awardID":"0208821","effectiveDate":"2002-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[186641],"PO":["499399"]},"74496":{"abstract":"Software is multidimensional; it has many representations besides the<br\/>program source. These include formal specifications, test suites,<br\/>documentation and even the development history. As software evolves,<br\/>these dimensions must stay consistent and reflect each other as<br\/>thoroughly as possible. In practice, however, while these are usually<br\/>consistent when first created, they tend to receive unequal attention<br\/>and therefore gradually become inconsistent. Programmers thus<br\/>typically rely on the source code to the exclusion of most other<br\/>dimensions.<br\/><br\/>This project's goal is to help programmers cope with software<br\/>evolution by viewing the dimensions of software as constraints on one<br\/>another. The project proposes a constraint representation common to<br\/>the different software dimensions. Software evolution then becomes a<br\/>process of maintaining consistency between constraints. These<br\/>constraints also help programmers identify high-level features in<br\/>their system, and generate rationales to document design decisions.<br\/><br\/>The escalating costs of software maintenance give the project<br\/>immediacy and its results high significance. It will have immediate<br\/>impact by developing tools for programmers to use. It will have<br\/>effect over the long term by employing these tools in educational<br\/>settings so future developers have a better appreciation for the<br\/>importance of maintaining the multiple dimensions of software.","title":"ITR: Consistent Software Evolution","awardID":"0218973","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["448702","519555"],"PO":["564388"]},"72087":{"abstract":"Henzinger, Thomas<br\/>CCR-0208875<br\/>\"Towards Predictability and Portability in Embedded Software\"<br\/><br\/>This project develops, implements, and validates platform-independent programming models for embedded software with hard real-time constraints. For high-performance control applications, the time-triggered programming language Giotto is implemented by targeting the Embedded Machine. The Embedded Machine is a virtual machine that mediates in real time the interaction between software processes and physical environment processes. The Embedded Machine is ported to single-CPU and distributed platforms.<br\/>Embedded Machine code is validated by schedulability analysis.","title":"Towards Predictability and Portability in Embedded Software","awardID":"0208875","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["226709"],"PO":["561889"]},"72098":{"abstract":"Lee, Insup<br\/>CCR-0208924<br\/>Rate-Based Resource Allocation Methods for Real-Time Embedded Systems <br\/><br\/>Run-time executives and operating system kernels for embedded systems have long relied exclusively on static priority scheduling of tasks to ensure timing constraints and other correctness conditions are met. Static priority scheduling is easy to understand and support but it suffers from a number of significant problems such as: the complexity of simultaneously mapping timing and importance constraints onto priority values, dealing with tasks whose execution time is either unknown or may vary over time, dealing with tasks whose execution time (or rate) deviates from the behavior expected at design-time, degrading system performance gracefully in times of overload, and ensuring full utilization of the processor or other resources in tightly resource constrained systems.<br\/><br\/> Rate-based resource allocation schemes offer an attractive alternative to traditional static priority scheduling as they offer flexibility in specifying and managing timing and criticality constraints. In a rate-based system a task is guaranteed to make progress according to a well-defined rate specification such as \"process x samples per second,\" or \"process x messages per second where each message consists of 3-5 consecutive network packets.\" This research investigates the use of rate-based resource allocation methods for constructing embedded systems with real-time execution constraints. <br\/><br\/> The focus of the project is two-fold: an algorithm design and analysis component, and a prototype implementation and use component. In the design\/analysis component, a framework is being developed using taxonomy of rate-based resource allocation consisting of proportional share scheduling, polling server-based scheduling, and rate-based extensions to classical Liu and Layland scheduling. The goal is to relate the different scheduling models and abstractions to one another and to understand the fundamental principles of rate-based resource allocation such as the form and nature of timing guarantees and the algorithmic overhead. In addition, the existing theory of rate-based resource allocation is extended to deal with considerations such as preemption constraints. <br\/><br\/>The implementation and use component of this research explores rate-based resource allocation in operating system kernels and applications. The objective is to assess the fit between the formal task model used to develop a particular allocation algorithm and implementation constraints that arise in practice. <br\/><br\/> Three scheduling problems are considered: application-level scheduling (i.e., scheduling of user programs or application threads), scheduling the execution of system calls made by applications (\"top-half\" operating system-level scheduling), and scheduling asynchronous events generated by devices (\"bottom-half\" operating system-level scheduling). This reflects the logical structure of traditional, monolithic real-time (and general purpose) operating systems and kernels with hardware enforced protection boundaries. The research results will be distributed as an experimental version of FreeBSD that employs different forms of rate-based scheduling and resource allocation at different levels in the system.<br\/>Rate-Based Resource Allocation Methods for Real-Time Embedded Systems","title":"Collaborative Research: Rate-Based Resource Allocation Methods for Real-Time Embedded Systems","awardID":"0208924","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["554765","491562"],"PO":["561889"]},"73187":{"abstract":"This project will address theoretical and computational methodology for massively large, approximate optimization problems in network design and routing, encompassing both static and online problems. A central component of the work will be the implementation of the PI's algorithms on architectures such as IBM's forthcoming BG\/L.<br\/><br\/>The work will be directed at problem instances arising in networking and telecommunications, that are far larger than those currently studied by the mathematical programming community. While metropolitan area networks, at an appropriate level of aggregation, involve a few hundred nodes, computer networks can be far larger. Looking toward next-generation networking, especially wireless and adhoc networking, the need for optimization tools that can handle much larger networks becomes pressing.<br\/><br\/>The PI's previous work built upon methodologies on potential function methods for linear programming, developed during the last decade primarily by the theoretical computer science community. His work further developed the methodology and produced an effective implementation. This implementation is fast (more efficient than competing special-purpose algorithms and much faster than commercial software), it is quite accurate for engineering purposes, and it is general: it handles network design problems, static throughput routing problems, multicommodity flow problems, and in fact, a much more general class of linear programming problems, all with a common interface and no user-selected parameters. It successfully handles problems involving networks with hundreds and up to a few thousand nodes. The resulting linear programs, with tens of millions of variables and constraints, are at the limit of what can be considered approachable with state-of-the-art linear programming software.<br\/><br\/>When considering larger networks, however, the dimensions of the optimization problems increase by several orders of magnitude, placing them well beyond the capabilities of current methods and implementations - these problems are large enough that the idea of optimization becomes rather daunting. At the same time, the complexity, economics, and fast-changing nature of networking applications provides a stringent need for cost-effective, survivable designs and high throughput routing schemes. This work will seek to build on new, concrete methodological ideas so as to develop algorithms with provably stronger convergence properties; further, it will also develop high-performance implementations that can tackle massively large problems.<br\/><br\/>A parallel effort will concern online routing problems. Many online routing methods (for example, dynamic routing schemes that seek to minimize congestion, or to achieve fair routings) can be viewed as single iterations of potential function methods for corresponding static problems. This project will use this idea, together with the PI's work on static problems, with the aim of developing effective routing algorithms; again, a significant part of this work will be computational.<br\/><br\/>In both cases, this project will use previously established industrial research partnerships to validate methodologies and to obtain realistic data.","title":"ITR: High Performance Implementation of Approximate Algorithms for Large-Scale Routing and Network Design","awardID":"0213848","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["283751"],"PO":["279077"]},"77796":{"abstract":"CCR-0234603<br\/>Whitehead, Emmet James<br\/>Univ. of Calif. - Santa Cruz<br\/><br\/>Software today is tightly woven into the daily fabric of business, government, and homes. This software is maintained for many years to accommodate changing operational environments and to add new capabilities. An increasing body of evidence shows that the structure of software decays over time, leading to a cluster of related problems: changes take longer to implement since they touch more files, modular boundaries soften, and large recent changes are a good predictor of software faults.<br\/><br\/>This project aims to improve the effectiveness of perfective software maintenance techniques by developing a novel tool called IVA (Instability Visualization and Analysis) that allows the rapid identification and ranking of unstable code regions, so they can be redesigned first. The concept of an instability region is introduced as a set of dependent software fragments that have been frequently modified together, and the project uses analysis and visualization techniques to show the locations and relative severity of these instabilities utilizing Instability Identification, Analysis, and Visualization. It is expected that this approach will dramatically reduce the time required to identify and prioritize instability regions. The project takes full advantage of the NASA testbed to perform activities related to validating the correctness, usability, scalability, and performance of the IVA system. Furthermore, the project will validate that IVA would have provided much earlier identification of code regions that were ultimately refactored. In addition, IVA will be incorporated in undergraduate and graduate teaching and research.","title":"Software Instability Analysis","awardID":"0234603","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"W379","name":"NASA-HIGHLY DEPENDABLE COMPUTI"}}],"PIcoPI":["443290"],"PO":["564388"]},"75387":{"abstract":"This project examines the dynamics of the Open Source Software (OSS) movement, a genuine behavioral and technical puzzle with a far-reaching impact on the world's economy. The OSS community has developed a substantial portion of the infrastructure of the internet and has many outstanding technical achievements, without the benefit of traditional project management techniques, organizational structure, face to face interaction, and in most cases, without direct monetary compensation. We seek to understand the factors that predict developer retention and project success, and to model the growth of the OSS network over time in order to inform policy decisions regarding the OSS movement. We develop an organizational behavior\/social psychological model of developer motivation and project effectiveness using a modification of Hackman & Oldham's job characteristics model and March's role identity construct, and use simulation, data mining, and agent-based modeling techniques to model how the OSS network develops over time.","title":"Understanding Open Source Software Development","awardID":"0222829","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["434617","426517",196074],"PO":["564456"]},"65597":{"abstract":"The objective of this research is to lay the foundation for a QoS metric that can be easily <br\/>understood and can be used for the design of future packet networks. The premise of the <br\/>proposed research is that Quality of Service (QoS) mechanisms have not been widely <br\/>employed because of both their complexity and their lack of relationship to user <br\/>perceived performance. Therefore, it is currently difficult to justify the investment in <br\/>complex QoS technologies while their value to the end customer is unknown. There have <br\/>been cases where commercial networks have been over provisioned, resulting in all users, <br\/>independent of QoS requirement or priority, receiving the same service. Based on these <br\/>experiences network customers are reluctant to pay extra for QoS. <br\/>Historically, the telephony QoS metric, call blocking probability, was not only <br\/>easily understood but provided the foundation for network design. Clearly this metric is <br\/>not suitable for packet networks like the Internet, since packet networks experience delay <br\/>and packet loss in the presence of congestion. Recently, it has become increasingly <br\/>apparent that temporal characteristics of the congestion episodes have the dominant effect <br\/>on user perceived QoS. Reinforcing the increasing importance of the temporal <br\/>characteristics of congestion is the recent work in the Internet Engineering Task Force <br\/>(IETF) on measurement-based temporal QoS metrics. Once congestion occurs at a <br\/>bottleneck point in the network it tends to persist and cause a user observable <br\/>impairment. Thus, there is a need to increase our understanding of the temporal <br\/>characteristics of congestion. To address this issue a new QoS metric is defined, the rate <br\/>of congestion events per unit time, and a research effort identified to develop analytic <br\/>methodologies to study this QoS metric. Specifically, this research will focus on: 1) <br\/>predicting the frequency of congestion events for long range dependent (LDR) like <br\/>traffic, i.e., fractional Brownian motion, in a network context, 2) developing simple <br\/>approximations for predicting the frequency of congestion events, 3) validating the <br\/>resulting prediction methodologies for networks using real high resolution traffic <br\/>measurements, 4) developing efficient techniques to measure the rate of congestion <br\/>events, and 5) relating the congestion event metric proposed here to new measurement-<br\/>based temporal QoS metrics. A rigorous definition is proposed for the time between <br\/>congestion episodes, which leads to the application of first hitting time analysis for its <br\/>prediction. The proposed research will exploit some recent theoretical results as well <br\/>develop new methods for predicting first hitting times for a realistic traffic. <br\/>Network users have been struggling to quantify their perceived performance. The <br\/>new QoS metric proposed here summarizes the network component of performance in <br\/>one easily understandable number. Equally important, the proposed metric is structured <br\/>in such a way that it can be used for network engineering. We expect the proposed <br\/>metric, combined with accurate prediction techniques, will play an important role in <br\/>designing future packet networks.","title":"Quantifying the Temporal Characteristics of Congestion Events in the Internet","awardID":"0125410","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["482223","402055"],"PO":["565090"]},"67423":{"abstract":"The research focuses on new approaches for exposing concurrency and improving performance in modern<br\/>superscalar microprocessors. These approaches include semantic decomposition of instruction <br\/>sets and bitslice decomposition of data paths to expose elements of the processor's control and data path <br\/>to allow flexible, programmable control over at least a subset of the microarchitectural features <br\/>that are available. Preliminary analysis shows that there are significant opportunities for reducing ALU <br\/>cycle time, power consumption, and the deleterious effects of wire delay with little or no harmful <br\/>effects on throughput measured in instructions per cycle. Further, the research proposes pre-execution <br\/>using partial operand knowledge to resolve conditional branches, identify references that miss the cache, and mitigate the effects of other problematic instructions.<br\/><br\/>The primary objectives of the proposed educational plan are to integrate advanced topics into the <br\/>University of Wisconsin's computer architecture curriculum at the graduate and undergraduate level; <br\/>to continue to involve undergraduate students in research to enhance their educational experience <br\/>via exposure to leading-edge research topics; to incorporate advanced pedagogic techniques into the <br\/>classroom environment in order to accommodate all learning styles; and to exploit emerging web-based <br\/>technologies to streamline interactive and off-line communication between instructor and students.","title":"CAREER: Semantic Decomposition of Instruction Sets","awardID":"0133437","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["549841"],"PO":["550859"]},"77466":{"abstract":"This project will build a QoIA-aware attack resistant database<br\/>system framework, call Linba. The trustworthiness of a computing<br\/>system in delivering valid services in face of attacks has<br\/>become a more critical concern than ever as people are experiencing<br\/>increased cyber security threats. A Quality of Information<br\/>Assurance (QoIA) service is a service associated with a specific level<br\/>of trustworthiness. From the viewpoint of end users, the goal of trusted<br\/>computing is to enable people to get the QoIA services that they<br\/>have subscribed for even in face of attacks. However, (most) existing<br\/>trusted systems cannot deliver QoIA services since they have very limited<br\/>ability in providing (sustained) quantitative trustworthiness guarantees.<br\/><br\/>The objective of this research is to build a new trusted computing<br\/>infrastructure that is able to continue delivering QoIA services<br\/>in face of attacks and cost constraints. Based on a novel formal<br\/>(service) trustworthiness model, Linba<br\/>delivers multilevel, differential, quantitative QoIA services<br\/>through near optimal neuro-fuzzy composite QoIA adaptations where<br\/>Linba intelligently adapts itself to environment changes and<br\/>QoIA-cost tradeoffs are done in an optimized way. Successful<br\/>development of Linba will arm existing trusted database systems<br\/>with the ability to deliver QoIA services (in a cost-effective<br\/>way) and provide very valuable hints on developing a variety of other<br\/>types of trusted computing systems that can deliver QoIA services.<br\/>The cost-effectiveness of Linba will be evaluated through<br\/>simulation or prototyping.","title":"QoIA-Aware Attack Resilient Database Systems","awardID":"0233324","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["277956"],"PO":["521752"]},"76179":{"abstract":"We propose to organize a joint COST-IST (EU) \/ NSF (USA) workshop on Networking in September\/October 2002, in Crete, Greece. There are two main objectives for the proposed workshop. The first is to discuss and try to shed some more light into key, new and upcoming networking technologies by focusing on the driving fundamental aspects and principles. A better understanding could help better steer the upcoming advancements with the expected benefits in reduced complexity, improved performance and enhanced services. <br\/><br\/>The second main objective is to give the opportunity to the networking communities in Europe and USA to get together and have a first-hand exposure to the advancements and strengths in the other side of the Atlantic. The targeted balance in the participation of researchers from the two sides of the Atlantic will help achieve this cross-fertilization objective, bring the benefits to both communities and help advance the technology. <br\/><br\/>As funding is a major driving force, another objective of this workshop is to provide a forum that could help the workshop-sponsoring funding agencies from the EU and USA identify the key and required networking technologies and direct their funding accordingly. <br\/><br\/>Key networking areas represented by the best researchers from EU and USA will be targeted. The focus of the proposed workshop may be divided into three broad themes: <br\/><br\/> Internet Modeling and Control <br\/> Overlay Networks, Content Distribution Networks, Peer-to-Peer <br\/> Broadband Wireless, Ad Hoc and Sensor Networks, Hybrid Networks <br\/>The precise focus will be determined by the makeup of the participants. Program officers from COST-IST and ANIR-NSF are expected to attend the workshop. The General Workshop Chair is Ioannis Stavrakakis, University of Athens. The Program Co-chairs are Ioannis Stavrakakis, Ibrahim Matta (the PI) and Michael Smirnov (Fraunhofer FOKUS, Germany). Ibrahim Matta will handle the NSF funding and Michael Smirnov will handle the COST funding for the workshop. After the conclusion of the workshop, the organizing committee will furnish a report to the <br\/>COST-IST (EU) and ANIR-NSF (USA), and will make it publicly available to participants an others via the workshop site.","title":"COST-IST (EU)\/NSF (USA) Workshop on Networking; September\/October 2002, Crete, Greece","awardID":"0227595","effectiveDate":"2002-09-01","expirationDate":"2004-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["438360"],"PO":["292741"]},"74761":{"abstract":"In a wireless network, multiple communications devices in close proximity form a natural distributed antenna array. If a group of such devices transmit and receive in some cooperative manner, then the system performance can be significantly improved. This researchexplores techniques for cooperative transmission and reception using multiple devices. This cooperative communication approach is differentfrom traditional array processing because the distributed nature of<br\/>the communication nodes calls for network-oriented design approaches and processing algorithms. In particular, techniques that allow distributed and asynchronous processing that utilizes information provided by other nodes in a cluster will be considered.<br\/><br\/>For cooperative transmission, distributed space-time coding will be employed to take advantage of transmit diversity provided by the distributed array. One crucial issue for distributed space-time coding is that only rough synchronization between the nodes can be achieved. Hence space-time coding in an asynchronous setting needs to be considered. This leads to research on asynchronous diversity and coding gain analysis, symbol waveform design, and tradeoff between the complexity of transmitter synchronization and complexity of the decoding process.<br\/><br\/>For cooperative reception, distributed iterative decoding will be employed to obtain diversity advantage in reception. In this approach, multiple nodes form a distributed antenna array by collaboratively processing a received signal. By exchanging information in a distributed decoding process, the nodes are able to extract diversity from the channel and decode the message. The main obstacle to this approach is that there is a vast amount of information that can be<br\/>shared between the nodes. This problem can be solved by using iterative decoding to extract important information from the received signal at each node, and only this information is passed to other nodes. Each node will then utilize the information from other nodes to perform further decoding to obtain the diversity advantage provided by the additional information. The objective is to develop distributed processing techniques that allow us to obtain the maximum degree of<br\/>diversity advantage from the signals received at multiple receiving nodes, while requiring a minimum amount of information exchange between the nodes.<br\/><br\/>In order to make the above cooperative communication schemes work, a control signaling strategy has to be designed to allow sharing of information between nodes. More importantly, the physical-layer communication performance of the proposed system will be dependent on<br\/>the control signaling strategy. Therefore this signaling design problem will be attacked by a cross-layer design approach.<br\/><br\/>Analytical guidelines for designing systems employing the proposed cooperative communication schemes will be developed. The expected results of this research can be utilized in many different commercial and military communication networks, such as cellular and sensor networks.","title":"ITR: Cooperative Communication Schemes for Wireless Networks","awardID":"0220287","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["560200","550716","518031"],"PO":["7594"]},"71142":{"abstract":"The Internet is large, decentralized, and heterogeneous in its technology, administration and capacity. The core of the Internet's success arises from its adherence to a number of architectural principles, central to which is the notion that the network should try to achieve a robust, very often works pretty well level of performance. One of the main techniques for achieving this across a wide range of conditions is making Internet protocols and mechanisms adaptive, so that they self-tune to work reasonably well in whatever circumstances they find themselves.<br\/><br\/>This approach has been extremely successful. However, some of the mechanisms, designed to be good enough across a large range of conditions, must now or will soon operate in regimes beyond their effective dynamic range. For example, TCP congestion control mechanisms require revisiting for tomorrow's Internet, both the coming high speed paths, and the coming low speed paths (e.g., lossy wireless links). Similarly, the architecture's ability to gracefully tolerate failures does not extend to new forms of failures, such as misconfigured routing information or malfunctioning middle-boxes, nor to distributed stresses, such as flash crowds, rapidly-spreading worms, or denial-of-service (DoS) floods.<br\/><br\/>If we view robustness as the ability of the network to function well over a wide spectrum of conditions particularly given a very large, ever-growing and ever-changing network then we argue that the robustness of the future Internet is clearly at risk. In this proposal, we emphasize a multifaceted approach to robustness:<br\/>1) Robust performance in the presence of extreme environments such as very high speed and highly variable delay, which requires rethinking today's congestion control mechanisms.<br\/>2) Robust performance in the presence of new forms of failure, both at the network layer, in terms of robust routing, and at the application layer, in terms of coping with the now widespread deployment of middleboxes that have elbowed their way into the architecture. This will require investigating broader notions of fault inference.<br\/>3) Robust performance in the presence of distributed stresses, both malicious (denial-of-service floods; congestion control cheaters) and merely teeming (flash crowds). This will require an understanding of the network's topology and the makeup of traffic aggregates, coupled with new control mechanisms deployed inside the network.<br\/><br\/>Part of the approach to these is to refine existing protocols and mechanisms, and investigate new ones. But the researchers also emphasize achieving robust performance by detecting incipient failures, on both short time scales (via distributed operational monitoring) and long time scales (via diagnostic probing of deployed protocol implementations).<br\/><br\/>While certainly these topics do not address the full range of challenges facing the Internet architecture, they do address some of the core issues in preserving and enhancing the Internet's robustness. In one sense, the proposed research is conservative, in that we frame it in terms of working within the current Internet architecture, rather than advocating a clean sheet approach. The researchers argue, however, that in some ways this conservative approach makes for research that is more fundamental rather than less. The clean sheet approach, while more tidy and much more conducive to easy exploration of basic principles, misses the crucial reality of how different mechanisms wind up interacting once integrated into a truly large-scale network.","title":"ITR\/ANI: Addressing Fundamental Issues for Robust Internet Performance","awardID":"0205519","effectiveDate":"2002-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["560562",184210,"562327","416473"],"PO":["402055"]},"74662":{"abstract":"Tracking social agents that have a variety of mental states is quite different from and more challenging than tracking more predictable systems, say aircraft or ships. While multi-target tracking systems typically use physics-based models to track maneuvering vehicles, this work centers on developing probabilistic models of behavior and mental state to address the effects of interactions between agents. This work has practical applications in many areas including, for example: monitoring crowds of people, analyzing urban traffic patterns, and understanding robot and human team behavior. Additionally, this work should accelerate progress in experimental behavioral ecology, especially in the study of social insect systems. For this reason the investigation will initially be conducted in collaboration with biologists in the context of tracking and analyzing the behavior of captive live ant colonies. This research will yield novel, probabilistic algorithms for sensor-based identification, tracking, and modeling of the behavior of social multiagent systems. A tight coupling between tracking and modeling is critical, especially when the observed system is composed of many agents. The focus is on using models of behavior to improve the accuracy of sensor-based tracking, and on using improved tracking to learn better models.","title":"ITR: Observing, Tracking and Modeling Social Multiagent Systems","awardID":"0219850","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["436270","485377"],"PO":["564456"]},"71153":{"abstract":"This proposal is concerned with developing of 3-D scanning methods to be applied to the imaging of cuneiform tablets. This process can make the tablets more readable by \"deepening\" the marks in tablets badly worn over centuries, thus sharpening the images. The panel gave this proposal a Highly Competitive rating, noting that it was an excellent proposal with innovative work in information technology and the humanities and social sciences. For IT, the impact is the development of a portable, very high resolution surface scanner and the multi-resolution algorithms. For the humanities, the project represents significant work with a potentially very wide application to other other objects with the result of opening up new fields of study to a larger group of scholars. The technology and techniques developed can be imported to other areas of study of ancient cultures and languages.","title":"ITR: Digital Hammurabi - High Resolution 3D Imaging of Cuneiform Tablets","awardID":"0205586","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["218093","522452"],"PO":["433760"]},"72011":{"abstract":"High-Performance Adaptive Receivers for Broadband Multi-User Communications<br\/><br\/>High speed communications over wireless channels has emerged as a key feature of future communications systems due in part to the explosive interest in information technology applications, including wireless sensor networks, mobile wearable systems, mobile computing, wireless location (E911), high-speed mobile<br\/>internet, and video transmission over wireless channels. The demand for higher information capacity in these applications has motivated the use of broadband wireless channels in order to provide wider bandwidth and higher data rates. This demand has also motivated the development of multi-user communication<br\/>schemes in order to allow users to share the same physical channel; thereby contributing to even higher data rates. A key challenge that limits the performance of such multi-user communications systems is the distortion introduced by the coupled communication channels, by the interference among users and by the<br\/>channel fading conditions. This research aims at studying and developing adaptive receivers that can combat such distortions by adapting their performance in accordance to the communications environment.<br\/>The research studies and develops efficient adaptive receivers for broadband multi-user communications by exploiting spatial, data, and model structures in order to reduce computational complexity and increase performance level. In so doing, it is expected that the resulting schemes will help increase data rates, lower<br\/>overhead due to training, lower bit-error-rate, improve signal-to-noise ratio, and help mitigate the ombined effects of inter-symbol interference, inter-user interference, and noise.<br\/>Such schemes would increase the capacity of broadband wireless networks by allowing multiple users to share the same time slot and frequency band in an efficient manner. This study focuses on<br\/>both time-domain and frequency-domain equalization techniques, with the latter receiving increasing attention since it has been accepted as IEEE 802.16 Standard for Wireless Metropolitan Area<br\/>Networks. The research is also relevant to other wireless applications such as wireless location (E911), which has emerged as an essential public safety component of future cellular systems. This is because this work enables the development of enhanced adaptive techniques that are robust to fast channel<br\/>fading, low signal-to-noise ratio conditions, and severe multipath propagation situations, all of which are characteristic of the E911 environment","title":"High-Performance Adaptive Receivers for Broadband Multi-User Communications","awardID":"0208573","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["448637"],"PO":["564898"]},"74673":{"abstract":"This project will develop concepts and techniques to improve the security and reliability of system software by detecting and managing invisible links in the code. Invisible links are dependencies among program components that are difficult to find by looking at the code alone. A common source of invisible links is the optimization process that removes \"unnecessary\" code due to some system invariants. Software reuse and evolution may invalidate these invariants, break invisible links, and cause crashes such as the Ariane 501 rocket. Further, malicious attacks such as TOCTTOU (time-of-check to time-of-use) often exploit invisible links. <br\/><br\/>Our approach combines three techniques that have not been brought together previously. First is a software abstraction with support for flexible correctness criteria definitions, called Transactional Activity Model, which will demark code boundaries that contain invisible links. Second is the use of wrappers to implement the enforcement of correctness criteria on top of production software, for example, concurrency control around the Unix file system for TOCTTOU. Third, program specialization techniques, in particular, the guarding of quasi-invariants, can make invisible links visible and generate the code to maintain the integrity of these links (e.g., making sure the file has not been replaced by the attacker). This combination offers the promise to reveal invisible links and therefore manage those dependencies explicitly.","title":"ITR: Guarding Quasi-Invariants: Generalizing Specialization for System Software Security & Reliability","awardID":"0219902","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["532971"],"PO":["521752"]},"75410":{"abstract":"This research is intended to develop and evaluate a haptic simulator suitable for training people to detect very small features in a physical surface such as a human tooth. A driving force behind the apparent demise of professional haptic skill in recent years may simply be a failure to develop and maintain sufficiently rigorous standards of skill specification, training and assessment. Haptic information is not readily amenable to either verbal or visual clarification, and yet professionals such as dentists, jewelers and engravers must learn haptic skills. Limitations of our language make it difficult to accurately describe haptic techniques; our haptic vocabulary consists of vague words such as \"tough,\" \"spongy,\" and \"sticky.\" It is also difficult to visually demonstrate or assess haptic skills. Instructors are unable to see exactly how hard a student presses. Unlike visual information, instructors are generally unable to share a haptic experience with a student. The salvation of haptic skills may lie with computers, strain gauges and motors. These devices can accurately record, visually display, and endlessly reproduce haptic signals. Together, these technologies present an opportunity to reestablish a robust, rewarding culture of haptic skill in the professional workplace. Such a workplace would more productively and thoroughly engage the whole scope of human capability. <br\/><br\/>Training dentists to elicit and recognize force signals is the primary design challenge for the simulator. It will be refined and developed around this simple criterion, placing force signal fidelity above all other competing design criteria including: 1) the geometry of the tooth surface, 2) the visual appearance of the tooth, 3) the precise shape and feel of the dental tool handle, 4) the spatial resolution of the simulator device and 5) the simulated hardness of the tooth itself. Ultimately the project will compare the clinical performance of dentists trained with the simulator against those trained with traditional methods. This work will provide an important contribution to the field of haptic simulation by suggesting a method to empirically identify force signals, benchmark a simulator's performance for reproducing these signals, and demonstrating a tangible, practical benefit to haptic simulator training.","title":"Using Force Feedback Devices to Train and Assess Recognition of Force Signals as a Component of Professional Skill","awardID":"0223006","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["256072","543448",196140],"PO":["565227"]},"74442":{"abstract":"EIA-0219627 Craig Douglas University of Kentucky Collaborative Research: ITR\/AP-Predictive Contaminant Tracking Using Dynamic Data Driven Application Simulation \\(DDDAS\\) Techniques<br\/><br\/>This project will lead to a leap-ahead technology in simulation capabilities. Research in the development of new methods and algorithms for the specific application areas is needed. The dynamic application requirements will dictate computing systems' support that includes systems' software technologies, such as active middleware services for real time, dynamic reconfiguration capabilities, resource discovery, load balancing, security, fault tolerance, quality of service, and dynamic interfaces with field measurement systems. <br\/><br\/>An encoded web stream set of contaminations from actual situations (both above ground and underground) will allow researchers besides us to tap into our virtual reality DDDAS environment. Visualization systems will allow us to work with a variety of real networks, sensors, and environments.","title":"Collaborative Research: ITR\/AP: Predictive Contaminant Tracking Using Dynamic Data Driven Application Simulations (DDDAS) Techniques","awardID":"0218721","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"T027","name":"NIH-VISUALIZATION RES CHALLENG"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"5345","name":"BIOMEDICAL ENGINEERING"}}],"PIcoPI":["496204"],"PO":["551712"]},"74695":{"abstract":"Wireless sensor networking is an emerging technology that has a wide range of potential applications including environment monitoring, smart spaces, medical systems and robotic exploration. While the technology is very promising, it raises serious challenges in network<br\/>and system design. Sensor networks differ in many ways from than the traditional IP or voice networks, and have their unique features and requirements. Although MAC protocols such as 802.11 and TDMA are ideal for wireless IP or voice, no MAC protocol today meets the needs<br\/>of sensor networks.<br\/><br\/>This project will execute a systems-driven research program to address these problems through the development of sensor-network specific MAC protocols. Specifically, we are investigating:<br\/><br\/>ADAPTIVITY AND ENERGY EFFICIENCY: Sensor network MACs must be adaptive in several dimensions, including energy consumption, traffic loads, and deployment density. Energy is *the key limitation* for battery-powered sensor nodes. The researchers are investigating and will provide designs for ENERGY CONSERVATION approaches that modify node duty cycle<br\/>to conserve energy while considering user varying application traffic requirements. One approach to energy conservation is to trigger primary node radios with a paging channel, but this requires a second radio (with corresponding cost, space, and money requirements). Sensor nodes already must operate sensors full time, so the researchers are evaluating the use of sensors (acoustic, seismic, etc.) as a PHYSICAL SENSOR PAGING CHANNEL.<br\/><br\/>MAC INTERACTION WITH THE PHYSICAL LAYER: With low-power, relatively unsophisticated radios, sensor networks applications and MAC protocols are very close to physical layer effects of radio propagation. A serious problem with current sensor applications is dealing with link<br\/>error conditions such as packet loss and asymmetric communication. Energy-conserving MAC layers already keep track of neighbors, so the researchers will provide a BLACKLISTING SERVICE that allows the MAC to identify and exclude unusable links. The researchers also will study and report on radio POWER CONTROL AND APPLICATION INTERACTIONS to understand how MACs can control neighborhood size.<br\/><br\/>UNIQUE APPLICATION NEEDS OF SENSOR NETWORKS: Sensor networks are fundamentally different from Internet-style networks of peer nodes in several different ways. A first differences is that sensor networks are primarily quiescent, but they occasionally become very active when<br\/>something is sensed. The researchers will develop a MAC PROTOCOL WITH MULTIPLE<br\/>OPERATING MODES to allow the MACs to adjust to this ``feast or famine'' traffic load. In addition, energy conservation introduces a *directional bias* in node communication; sleep\/wake-up schedules can either add latency to all directions equally, or can allow rapid communication in one direction and slower communication in the other. The researchers will evaluate how controllable MAC-LEVEL DIRECTIONAL BIAS INTERACTS WITH APPLICATION, exploiting it where possible.<br\/><br\/>Finally, the research community has a compelling need for a publicly available, freely modifiable Sensor-MAC protocol for experimentation and simulation. Evaluation of our ideas requires implementation and evolution of a MAC protocol. We will provide this implementation to other researchers for use over existing sensor network radios (with a reference implementation on the UC Berkeley Mote hardware) and in simulation (with a reference implementation in the ns-2 simulator).<br\/>Thus, in addition to opening up sensor-network-specific MAC protocols as a new subfield of research, this work will serve as a catalyst for wider sensor network research that is sorely in need of an appropriate and modifiable MAC.","title":"ITR: MAC Protocols Specific for Sensor Networks (MACSS)","awardID":"0220026","effectiveDate":"2002-09-15","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["377594"],"PO":["292741"]},"75300":{"abstract":"EIA-222359<br\/>Salim Hariri<br\/>University of Arizona<br\/><br\/>NGS: The Fourth Annual Workshop on Active Middleware Services (AMS 2002) and The Third Annual International Workshop on Grid Computing (Grid 2002)<br\/><br\/>The increasing complexity of the emerging ubiquitous grid network infrastructure in conjunction with active technologies requires additional support for application developers and users. Middleware will play a crucial role in the degree to which active technologies achieve their full potential. Such middleware will in all probability be deployed in grid environments. For these reasons, two workshops are proposed: one in active middleware and another in grid computing. While these two workshops will be held separately, each will bring together leading researchers in their respective fields. Research in related areas will be invited to add their expertise to the discussions. While the main focus of each workshop in different, there is nonetheless a synergy between them. Both could explore the advanced area of active grid middleware.","title":"NGS: The Fourth Annual International Workshop on Active Middleware Services (AMS 2002) and the Third Annual International Workshop on Grid Computing (GRID 2002)","awardID":"0222359","effectiveDate":"2002-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["561892"],"PO":["301532"]},"75421":{"abstract":"The long range goal of this project is to develop an integrated biological and computational approach to decipher gene regulatory networks. This project combines discovery-based approaches to identify and characterize new regulatory networks with hypothesis-driven approaches in which transcriptional control by two regulatory factors important in galactose metabolism will be examined. The specific aims of this project are: (1) to temporally profile the global genetic and proteomic response to galactose; (2) to globally identify the elements of transcriptional networks important for galactose utilization; (3) to develop an advanced computational framework for integration, modeling, and prediction of transcriptional networks; and (4) to experimentally test the networks models predicted from these studies.","title":"QSB: Development of an Integrated Biological and Computational Approach to Decipher Transcriptional Regulatory Networks in Saccharromyces Cerevisiae","awardID":"0223056","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1491","name":"BIOTECH, BIOCHEM & BIOMASS ENG"}}],"PIcoPI":["415743",196175,196176],"PO":["360556"]},"75542":{"abstract":"EIA 02-23785<br\/>Reddy, A.L. Narasimha<br\/>Cantrell, Pierce E.; <br\/>Shi, Weiping<br\/>Texas A & M University (TX Engineering Experimental Station) <br\/><br\/>Title: CISE RR: Secure Networked Storage Systems<br\/>This proposal, building an experimental testbed for research on high performance networked storage systems and the resulting issues in network resources management, builds system level software support for secure networked storage systems possible through iSCSI type of storage devices that directly attach to IP networks. Test applications comprise multimedia (i.e., videoserver application) and VLSI CAD (distributed fault simulation). An experimental networked implementing partial state architectures will be developed. The network element will utilize partial state to provide a better handle on networked and end-host traffic by regulating high bandwidth flows through individual state while aggregating the rest of the flows (similar to how caches are employed in current memory systems). Using realistic VLSI CAD and multimedia applications, the work will evaluate an integrated system consisting of storage and network elements. The project will employ video delivery as an application to evaluate the impact of attaching devices to the network, the storage services (i.e., third party transfers and data filtering), network centric issues (e.g., QoS, congestion management, and transport protocols), and new architectures and mechanisms in protecting storage systems against Denial of Service (DOS) attacks. Moreover, the equipment will be used for developing the target applications and for staffing DOS attacks against the new experimental systems. Specifically the proposed research encompasses: <br\/> Providing third party transfers and<br\/> Network security: QoS regulation for mitigating DOS attacks and security enhancement through partial state network architectures<br\/><br\/>The infrastructure is expected to offer students valuable training in systems-building, I\/O and networked software, parallel and distributed programming, performance evaluation of real systems and interdisciplinary research.","title":"Secure Networked Storage Systems","awardID":"0223785","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["530862",196484,"550709"],"PO":["557609"]},"74574":{"abstract":"This project will advance understanding of how information technology is perceived, used, and reconfigured in diverse cultures in Central Asia. By conducting an empirical investigation into the cultural factors that affect information technology adoption, and articulating which of these elements are most significant in determining the success rate of IT initiatives, the research will provide a blueprint that can be used by programs delivering IT-related programs in disparate settings. The research will focus on Central Asia because of that region's unique combination of infrastructure and literacy combined with relatively low exposure to Western culture and early stages of Internet adoption. The project will draw on qualitative and quantitative methods, using survey instruments, statistical analysis, coded interview data, and ethnographic observation. Surveys will be developed based on previous research, and they will be distributed at Internet access sites in Central Asia. Interviews will also be conducted in Central Asia. The survey and interview data will be analyzed in an effort to correlate usage habits with local cultural factors. As information technology becomes increasingly important, effective implementation becomes even more critical. This project will make a significant contribution to understanding how culture affects technology adoption, thus advancing broad-based approaches to bridging the digital divide.","title":"ITR: Cross-Cultural Patterns of Information Technology Adoption and Adaptation: Lessons from Central Asia","awardID":"0219350","effectiveDate":"2002-09-01","expirationDate":"2003-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1353","name":"Hist & Philosophy of SET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["483630","545986"],"PO":["495796"]},"72044":{"abstract":"The next generation of computers will be multi-threaded,<br\/>allowing the simultaneous execution of several programs.<br\/>Most computer workloads are difficult to recast into<br\/>multi-threaded form, under-utilizing multi-threading capabilities.<br\/><br\/>This research studies a new approach to program translation:<br\/>Assist Threads.<br\/><br\/>An assist thread is a specialized version of an application program that,<br\/>when run as an independent thread, assists (and optimizes) the application.<br\/>Roles for assist threads include program profiling, monitoring, pre-execution,<br\/>and memory management.<br\/><br\/>Experiments show that assist threads<br\/>can effectively implement garbage collection.<br\/>An assist thread mimics an application's execution,<br\/>tracking memory accesses and recycling unused memory as it is recognized.<br\/>The main application thread ignores memory management concerns,<br\/>becoming simpler, faster and more reliable.<br\/><br\/>Other varieties of assist threads execute slightly in advance of an<br\/>application program, precomputing and preloading needed data values.<br\/><br\/>This research makes both theoretical and practical contributions to<br\/>compiler technology. It explores how to generate the computations<br\/>necessary to implement assist threads. It also experiments with a variety<br\/>of assist threads, evaluating their effectiveness and efficiency.<br\/><br\/>In summary, this research opens new avenues of application for multi-threaded<br\/>processors, making them more effective in supporting the needs of a wide<br\/>variety of computer users.","title":"Assist Thread Compilation for Multi-threaded Processors","awardID":"0208677","effectiveDate":"2002-09-01","expirationDate":"2005-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":[186565],"PO":["565272"]},"71087":{"abstract":"0205625,0205118, 0205429, 0205627 <br\/><br\/>TITLE: Collaborative Research: ITR: Acquiring Accurate Dynamic Field<br\/>Data Using Lightweight Instrumentation<br\/><br\/>Dynamic analyses, such as testing and profiling, play a key role in state-of-art approaches to software quality assurance (QA). With rare exception, these analyses are performed in-house, on developer<br\/>platforms, using developer-provided input workloads. Shortcomings of this approach include that the results simply cannot be trusted to tell us how the software actually performs in the field.<br\/><br\/>The project goal is to give developers unprecedented insight into the actual runtime behavior of their software, allowing developers (and ultimately the software itself) to change, optimize, and adapt the software based on highly accurate field data. Lightweight, collaborative dynamic analyses conducted around-the-world and around-the-clock form the new platform: (1) lightly instrument fielded software (i.e., each program copy performs a small part of the analysis) (2) collect the partial data from many instances of the software, fusing it to conduct the complete analysis, (3) change the running program instances based on the findings and (4) repeat the process.<br\/><br\/>Seven critical research challenges form the core of the project: <br\/>1. Lightweight instrumentation--Develop instrumentation that is virtually transparent to individual users. 2. Compositional analysis techniques--Develop distributed analysis techniques that decompose<br\/>traditional analyses into smaller steps, distribute the steps among multiple users, and then fuse each user's results into an accurate solution to the original problem. 3. Scalability--Develop storage<br\/>and analysis techniques to deal with the high data volumes we expect to encounter. 4. Anomaly Detection--Define data-driven techniques to automatically identify anomalous behaviors of deployed<br\/>software. 5. Privacy and Security--Incorporate privacy and security safeguards into our data collection and analysis approaches. 6. Dynamic updating mechanisms--Develop techniques to make runtime changes to the location and function of instrumentation, and to parts of the software itself. 7. Validate approach on industrial<br\/>software.","title":"Collaborative Research: ITR: Acquiring Accurate Dynamic Field Data Using Lightweight Instrumentation","awardID":"0205265","effectiveDate":"2002-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["485900"],"PO":["564388"]},"66852":{"abstract":"EIA-0130773 Randall D. Beer-Case Western Reserve-Reconfigurable and Multifunctional Behavior Pattern Generators <br\/><br\/>We propose to develop new theories and models that extend current computational frameworks by understanding and implementing the dynamically reconfigurable and multifunctional information processing architectures of biological systems. We will address this challenge through a collaborative interdisciplinary research program focusing on multifunctional neuromechanical components and their reconfiguration into multiple behavioral patterns in animals. The ultimate goal of our proposed research is to abstract general design principles that can eventually be applied in a variety of other contexts. Specifically, we propose the following four closely intertwined experimental and modeling\/theoretical projects:<br\/><br\/>1)We will undertake a detailed experimental analysis of the feeding system of the mollusk Aplysia California, which dynamically reconfigures its feeding behavior in response to changing environmental circumstances, and does so through the multifuntionality of its neuromechanics. First, we will characterize the conditions under which the animal switches between distant behavioral patterns. Second, we will examine the neural and mechanical basis of these switches.<br\/><br\/>2)We will create and analyze models of behavioral pattern switching as the basis for new design principles. First, we will construct interconnected semi-Markov models to capture behavioral pattern reconfiguration observed in biological systems. Second, we will pursue the development of a systematic design methodology for engineered systems, with potential applications to robotic assembly.<br\/><br\/>3)We will create and analyze models of multifunctional pattern generations in order to identify general design principles. First, we will use genetic algorithms to evolve multifunctional neural pattern generators that can switch between distinct behavioral patterns. Second, we will undertake a detailed study of the \"design space\" of these model pattern generators.<br\/><br\/>4)We will explore the implementation of multifunctional neural pattern generators in analog VLSI. First, we will develop compact, low-power pattern generators based on the experimental and theoretical work proposed above. Second, we will study the effects of noise and component mismatch on the performance of these networks.","title":"BITS: Reconfigurable and Multifunctional Behavioral Pattern Generators","awardID":"0130773","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}}],"PIcoPI":["475447","517345","548925","228525"],"PO":["565223"]},"74475":{"abstract":"The Genesis Group of the MIT Artificial Intelligence Laboratory is working<br\/>on a computational theory of human intelligence. Their work is grounded in<br\/>two key assumptions: first, that humans think with their language, vision,<br\/>and motor systems, and their interaction; and second that humans can think<br\/>abstractly because they can build on a foundation of thinking about concrete<br\/>events in the physical world.<br\/><br\/>Their plan includes the development of a testbed that features paths,<br\/>agents, causes, both language and visual inputs and outputs, complex state<br\/>transitions, and support for abstract reasoning in abstract worlds.<br\/><br\/>They propose to exploit both symbolic and nonsymbolic representations. The<br\/>symbolic representations will include a representation for describing the<br\/>movement of animals and artifacts along trajectories and a representation<br\/>for describing state transitions in terms of a vocabulary of qualitative<br\/>changes. The nonsymbolic representations will include memory traces lying<br\/>close to experienced sensory inputs.<br\/><br\/>The Genesis Group expects success to lead not only to a better<br\/>understanding of natural intelligence buy also, in the long term, to<br\/>important practical results, such as computer applications with genuine<br\/>commonsense and educational applications that exploit an understanding of<br\/>how best to engage human linguistic and visual problem solving faculties.","title":"ITR---Reinventing Artificial Intelligence","awardID":"0218861","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["536919"],"PO":["355797"]},"75333":{"abstract":"This award for research at an undergraduate institution will support the development and testing of methods to create recurrent reinforcement learning neural networks that can solve challenging problems related to time series generation and analysis. There are two main attributes of improvisation that make it an excellent research area for machine learning. First, it is a procedure in which one makes up a solution to a problem in real-time, using available materials and knowledge, and in response to environmental effects. Second, it requires variety, modifying the solution from one time to another, even under the same conditions. Yet the overall result must be cohesive from beginning to end. Thus, improvisation is a significant challenge for computer science.<br\/><br\/>This project will extend the range of problems that can be solved, through a fusion of two separate methods. The first is recurrent neural networks, that are nonlinear neural networks in which the outputs of parts of the network are fed back to provide input to some or all parts of the network. They are emerging as feedback systems that can learn to model non-Markov processes, can learn to predict values in a time series, and can learn to generate actions or control signals that depend on past behavior. The second method is reinforcement learning, an area of machine learning that has taken on an important role in computationally solving problems that are characterized by sparse feedback as to whether a proposed solution is correct, given a situation or state. Human beings have a much greater ability than machines currently do to improvise in uncertain environments, and the ability to extemporize would be a very important asset for intelligent software systems.<br\/><br\/>In addition to supporting promising research, this award will encourage broader participation of women in science, by involving women in research and by helping to enable progress in computer science at a college for women.","title":"RUI: Machine Learning of Improvisational Time Series","awardID":"0222541","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["408593"],"PO":["491702"]},"74365":{"abstract":"EIA-0218262<br\/>Milan N. Stojanovic<br\/>Columbia University<br\/><br\/>Decision-Making Deoxyribozyme Networks<br\/><br\/>In this project, silicomimetic networks of enzymes are being developed. These networks will reproduce the functionality of individual silicon devices to perform Boolean algebra functions with analytical inputs and decision outputs and they represent first artificial autonomous decision-making sets of molecules with potential for incorporation into drug delivery or analytical systems. <br\/><br\/>The computation components of these networks (i.e. \"circuits\") are being made modularly from deoxyribozyme-based logic gates (YESA, NOTA, AANDB, YESANOTB), which have oligonucleotides as inputs and outputs. Communication between individual molecular gates is being developed through connections in which an output oligonucleotide, formed or degraded by a catalytic action of an upstream gate, is an input allosteric effector of a downstream gate. This type of communication allows serial connection or tiling of individual elements. Computer program is being developed, which would aid in the construction of any decision-making tree from custom-made materials and then coupled to deoxyribozyme-based sensor arrays. For example, one analytical network under construction senses the presence of an oligonucleotide, a small molecule and a protein, and makes a decision to release or not a fluorescent signal.","title":"Decision-Making Deoxyribozyme Networks","awardID":"0218262","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["459219","550110"],"PO":["565223"]},"74387":{"abstract":"EIA-0218376<br\/>Thomas LaBean<br\/>Duke University<br\/><br\/>Novel DNA Nanostructures for Targeted Molecular Scale too Micron Scale<br\/><br\/>The main thrust of this project is to develop fabrication techniques which bridge the gap between two size scales: (i) the micron scale, where conventional lithographic methods provide efficient top-down object construction, and (ii) the molecular scale, where viable bottom-up techniques for object assembly are beginning to emerge. The key problem addressed is how molecular scale structures can be selectively attached and interconnected with micron scale structures such that the molecular scale structures are functional. Bridging this gap is particularly important for advancing molecular-electronics into practical applications and for continuing the miniaturization trend of micro-electronics. This project approaches the scale gap challenge by the use of novel DNA nanostructures that have a scale between the two and can be made to selectively assemble with either. These structures present unique opportunities: (i) they provide for selective attachments via DNA annealing, (ii) they have length scales and flexibility permitting attachment to micron scale structures (iii) they can be metallized to provide conductive interconnects, (iv) potentially they can be used to orient other nanostructures such as carbon nanotubes. The major research steps to be taken include: (1) development of a diverse family of DNA nanostructures, (2) further characterization of existing DNA nanostructures, (3) further development of metallization techniques for these DNA nanostructures, (4) attachment experiments to various materials.<br\/><br\/> The project impacts important educational objectives by providing training opportunities for science students at several educational levels. Funds are included for a high school student from the SEED project for under-represented minority students, as well as for a graduate student and half the salary of a post-doctoral fellow. Training of students at graduate and undergraduate levels is helping to create future scientists with strong interests in nanotechnology, DNA engineering, and related fields critical to continued growth in electronics and computer sciences.","title":"QuBIC: Novel DNA Nanostructures for Targeted Molecular Scale to Micron Scale Interconnects","awardID":"0218376","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["550822","531216"],"PO":["521045"]},"72099":{"abstract":"Given a metric space, that is a finite set of points with<br\/>distances between them, there are several classical<br\/>minimization problems that are hard to solve exactly. A<br\/>prime example is the traveling salesman problem (TSP),<br\/>where we want to find a cyclic tour visiting all the<br\/>points with minimum total distance. These problems arise<br\/>in a wide range of applications such as manufacturing and<br\/>communications network design. In the worst case it is<br\/>NP-hard to solve these problems even approximately, that<br\/>is with relative error better than some constant threshold.<br\/><br\/>Recent results show that these problems are easier in<br\/>metric spaces that often arise in practice. In particular<br\/>if the distances are geometric, or if they are given by<br\/>shortest paths in a simple graph (such as a planar graph),<br\/>then the TSP and similar problems have approximation<br\/>schemes. These schemes run in polynomial or<br\/>quasi-polynomial time, with the exponent depending on the<br\/>desired relative error. The main techniques include<br\/>separators, spanners, and dynamic programming. In<br\/>particular a spanner is a subgraph of a given graph, whose<br\/>shortest path metric is a close approximation of the<br\/>original. In various graph families we can find spanners<br\/>with a useful tradeoff between the total weight and the<br\/>relative error.<br\/><br\/>This research continues the development of these<br\/>techniques, in particular seeking better spanner<br\/>constructions and possibly some useful lower bounds. One<br\/>goal of the project is some progress on two unsolved<br\/>variants: the geometric case in the presence of<br\/>obstacles, and the graphical case in the presence of many<br\/>extra ``Steiner'' points.","title":"Light Spanners for Hard Metrical Optimization Problems","awardID":"0208929","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[186703],"PO":["565157"]},"76334":{"abstract":"This award is to establish a Network for Computational Nanotechnology (NCN) at Purdue University with three-fold mission: (1) to catalyze the formation of teams of theorists, computational scientists, and experimentalists in research that addresses key challenges in realizing integrated nanosystems; (2) to support the research and the broader National Nanotechnology Initiative with an infrastructure that provides ready access to high-perfomence computing and visualization, facilities collaboration, delivers simulation services, and enables solutions to large, multi-scale problems by assembling standard, open-source components tht are available to the entire community; and (3) to develop educational packages that can be incorporated into the curricula to train students, scientists, and engineers. The NCN will initially address three research themes: (1) nanoelectronics, (2) naoelctromechanics, and (3) nsnobioelectronics. The University of Illinois, Urbana\/Champaign, Stanford University, Northwestern University, and University of Florida will be initial participants. The core research topics and participants will evolve while preserving relevance and leadership in the rapidly developing field of nanoscience. A number of special projects will be undertaken designed to address the need for a second-generation network computing platform. This award is for an initial period of five years, subject to renewal for another five years.","title":"Network for Computational Nanotechnology","awardID":"0228390","effectiveDate":"2002-09-15","expirationDate":"2010-10-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1735","name":"MATERIALS RSCH SCI & ENG CENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1633","name":"MATERIALS AND SURFACE ENG"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1480","name":"ENGINEERING RESEARCH CENTERS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"7604","name":"NANOSIMULATON GROUPS\/NETWORK"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"7641","name":"INT'L RES & EDU IN ENGINEERING"}}],"PIcoPI":["283852","501195","520672",198884,"532703"],"PO":["431774"]},"77786":{"abstract":"Highly dependable software is, by nature, predictable. For example, one can predict with confidence the circumstances under which the software will work and under which it will fail. Empirically-based <br\/>approaches to creating predictable software are based on two assumptions: (1) historical data can be used to develop and calibrate models that generate empirical predictions, and (2) there exists relationships between internal attributes of the software (i.e. concrete attributes such as size, effort, and defects) and external attributes of the software (i.e. abstract attributes such as quality or time to failure.). Software measurement validation is the process of determining a predictive relationship between available internal <br\/>attributes and correspondingly useful external attributes.<br\/><br\/>The general objective of this research is to design, implement, and validate software measures that support: (1) identification of fault-prone modules, enabling more efficient and effective allocation of <br\/>quality assurance resources, and (2) an incremental software development method through incremental and developer-specific notifications and analyses. <br\/><br\/>Empirical assessment of these methods and measures during use on the Mission data System project at Jet Propulsion Laboratory will advance both the theory and practice of software measurement validation. The <br\/>research will also produce an open source software system for software measurement validation.","title":"Supporting Development of Highly Dependable Software Through Continuous, Automated, In-process, and Individualized Software Measurement Validation","awardID":"0234568","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"W379","name":"NASA-HIGHLY DEPENDABLE COMPUTI"}}],"PIcoPI":[202874,"451116"],"PO":["564388"]},"74398":{"abstract":"EIA-0218435<br\/>Meera Sitharam<br\/>University of Florida <br\/><br\/>Virus-Inspired Declarative Geometric Computation<br\/><br\/>The goal of the project is to develop geometric computational models and tools for virus assembly from their constituent proteins, and virus crystal packing. Furthermore, inspiration of the above processes is being used to rethink computationally tractable declarative geometry (DG), defined as the intuitive, constraint-based representation and efficient realization of composites of simple interacting geometric objects, starting from a declarative specification of the composite's properties. In particular, a new game-theoretic constraint model is being developed for the underlying class of algebraic-geometric computations and corresponding algebraic varieties. Existing software in the form of the PI's geometric constraint solver FRONTIER is forming the base for implementing the new computational framework. <br\/><br\/><br\/>The new virus computational models is used for the studying the following unanswered questions on carefully chosen, geometrically significant viruses: (a) the isolation of crucial geometric events during assembly (helpful for disrupting assembly); (b) the isolation of assembly events - such as molecular conformational changes - that require the involvement of viral genomic material, (helpful for understanding DNA-protein interactions); and (c) the isolation of key geometric events during virus crystallization (as an idealized version of molecular crystallization).<br\/><br\/>The new DG virus models is being refined and validated by checking consistency with known behavior of viruses and their constituent proteins during assembly and crystallization. A small number of other highly focused experiments; selective X-ray crystallography and\/or cryoelectron microscopy is being performed. As a significant player to help with both of the above goals, use the distinctive Maize-streak virus (MSV) will be used, whose structure and properties are particularly suited to goals of the project. A comparison of the new geometric virus models with other geometry-based computational virus models is being made.","title":"Virus-Inspired Declarative Geometric Computation","awardID":"0218435","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["488681","488683"],"PO":["521045"]},"78578":{"abstract":"The goal of the workshop is to bring together a multidisciplinary group of researchers to identify and explore promising research directions in the alternatives to CMOS, that is, nano-based technologies. The researchers come from diverse communities including computer science, design automation, computer architecture, device physicists, and physical designers. The workshop aims at pinpointing the areas in which computer scientists and engineers can make important contributions to the technology of nanoelectronic computers. Researchers are to present position papers followed by discussions and breakout groups in which everyone participates. Sample questions being addressed are:<br\/>How will design sciences change in order to design, build and program future computers based on nanoelectronic principles?<br\/>What are the enabling abstractions that permit productive research on the design of nano computers?<br\/>What technologies from computer science and engineering are needed by the nanotechnology community?<br\/>What investments are needed and when to foster proper development of computing technologies for nano computing?<br\/>In order to provide a broad input to the workshop, there will be a workshop website. Prior to the meeting, comments from interested parties about the workshop topics can be posted on the website. A draft workshop report will be prepared at the meeting, posted on the workshop website and commentary from researchers solicited.","title":"ITR: NSF Workshop on NanoComputing, Oct. 15-17, 2002","awardID":"0238376","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["475429","332333"],"PO":["562984"]},"70692":{"abstract":"TITLE: Software Innovations for Liquid Architectures<br\/><br\/> We propose to bring the advantages of custom logic to low-volume but high-performance applications by semiautomatically generating custom logic, deployed in reconfigurable logic. By coupling (hard-or soft-core) commodity processors with reconfigurable logic, an application is essentially offered a liquid architecture, where the definition and implementation of the computer's instruction set, its coprocessors' functionality, and its supporting structures can be easily changed. These architectural changes can improve performance by supplying instructions and efficient implementations for frequently occurring operations, by changing the size or policies of caches and other supporting structures, and by dynamically exchanging speed for power-savings where required.<br\/><br\/> With proper software support, liquid architectures can improve the performance of many kinds of applications, ranging from high-performance, scientific calculations to low-power, embedded systems. Our research aims to develop the software infrastructure and methodologies needed to facilitate execution of applications on liquid architectures, addressing the following issues:","title":"NGS: Software Innovations for Liquid Architectures","awardID":"0203869","effectiveDate":"2002-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["511556","525751","316262","218159"],"PO":["301532"]},"70593":{"abstract":"This project integrates recent search developments in ad hoc netorks into mainstream computer science and electrical engineering curricula. It explores students to challenges posed by this emerging class of systems, improving studets' exposure to future infrastructures by developming real world ad hoc networking test-beds and deployment platforms, and permits educators at other U.S. institutions to do the same by sharing the system infrastructure and educational materils developed for this project. Specifically, the project transforms several undergraduate and graduate level courses in computer systems to address the challenges posed by wirless, mobile and embedded networks of computers that form transient alliances in ad hoc networks. This project transforms classes in networking, databases, operations systems, adaptive systems to integrate pervaive, ubiquitous, ad hoc networking and sensor networks. A three-tiered approach benefits both current classsroom instructions as well as ongoing research on ad hoc network, and involves: 1) The development of software and courseware infrastructure necessary to build, use and evaluate system services for ad hoc networkss in a classroom setting. 2) Deployment of the critical mass of equipment to field a large, physical test-bed. This network consists of mobile computers, ranging form sensors and pocket-sized information appliance through hand-helds to laptops. Equipped with a wireless networking card, and multi-purpose sensors such as camera, these machine provide a real physical test-bed on which system services are evaluated for ad hoc networks. 3) Collection of information from the deployed test-bed on application communication pattersn, mobility models, and observed link characteristics. This information can be used to carry out better-informed simulations of ad hoc networks. This grant impacts computer challenges the nation is facing, it results in innovative research on operating systems, database and telecommunications, and it generates course materials and define infrastructure that will allow the project to be repeated elsewhere in the country","title":"CRCD: The Ad Hoc Classroom: Integrating Emerging Wireless Communications and Networking Technologies into Mainstream Computer Science and Electrical Engineering Curricula","awardID":"0203449","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["345714","450625","448955","483774"],"PO":["551712"]},"74751":{"abstract":"Application partitioning is the task of breaking up the<br\/> functionality of an application into distinct entities that can<br\/> operate independently, usually in a distributed setting. As<br\/> networking changes the computing landscape, application<br\/> partitioning is becoming an increasingly common form of distributed<br\/> programming. This project examines the possibility of automating the<br\/> partitioning of a software application. Instead of hand re-coding,<br\/> higher-level tools allow the user to express how the application is<br\/> to be partitioned. The tools can then rewrite the existing<br\/> application code to replace local data exchange (e.g. function<br\/> calls, data sharing through pointers) with remote communication<br\/> (e.g. remote function calls, remote pointers or mobile objects).<br\/> The tools are based on a novel static analysis and translation<br\/> algorithm. The potential impact of this work is in significantly<br\/> simplifying distributed program construction, a prime<br\/> intellectual and practical challenge of computer science.<br\/> Automatic partitioning can revolutionize the way a large class of<br\/> distributed programs is developed. Additionally, the proposed<br\/> tools have a high educational value: they can be used for<br\/> illustrating crucial concepts in both programming languages and<br\/> distributed systems, while minimizing distractions due to low-level<br\/> complexity.","title":"ITR: Application Partitioning Without Programming","awardID":"0220248","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["422657"],"PO":["564388"]},"80086":{"abstract":"The objective of this project is to enable low bitrate transmission of highly compressed video streams over wireless channels which are subject to fading. One of the most important challenges in wireless video transmission is that terrestrial wireless channels are typically bandlimited so that significant compression is required; however, this compression results in <br\/>low quality reconstructed video as well as bitstreams which are extremely sensitive to channel errors. Traditionally, in order to protect against channel errors, powerful forward error control codes were carefully selected and employed at the expense of a portion of the limited bandwidth. This research addresses the problem of bandwidth expenditure on channel error <br\/>protection by exploiting the redundancy in a source-coded video stream to perform iterative, soft source decoding. With these improvements in source decoding less of the overall bandwidth must be expended on channel coding. This recovered bandwidth can then be devoted to reducing the compression rate, thereby increasing the quality of the transmitted video.<br\/><br\/>The iterative video decoder consists of two stages. The first stage is a traditional video decoder with error detection capabilities which employs hard channel values, while the second stage is an adaptive Viterbi-like source decoder employing soft channel values or reliability information from a channel decoder. The project focuses on developing efficient and reliable error detection techniques and on determining appropriate decision metrics for the Viterbi-like decoder which incorporate the soft channel values with knowledge of errors from the error detection process. <br\/><br\/>The objectives of this project are closely related to the teaching objectives. One primary goal of the teaching plan is to integrate this research in wireless communication into undergraduate courses in order to encourage interest in research and graduate study. The second goal is to develop a hands-on technology camp for middle-school girls to actively promote the <br\/>study of engineering and, in particular, telecommunications. In order to demystify the field of engineering, projects will involve illustrating the relationship between engineering and everyday life, exposing the students to the applicability and prevalence of engineering.","title":"CAREER: Research and Education in Video Coding and Wireless Communications","awardID":"0244647","effectiveDate":"2002-09-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":[208545],"PO":["223414"]},"74652":{"abstract":"The ongoing proliferation of battery-powered computing devices has created a new type of \"denial of service\" attack: If an attacker can drain a device's battery, for example, by having it repeatedly execute a energy-hungry program, the device will be rendered inoperable. Unlike other denial-of-service attacks where the attacker must keep up the attack in order to continue to deny the service, the attacker can quit attacking a battery-powered device once she has fully discharged the<br\/>battery, and move on to attack another device. Just as the advent of computer networks enabled an increase in the number of computer viruses, Trojan horses, and other computer security breaches, the rising availability of and increasing dependence on mobile computing devices will lead to the creation and spread of \"power-related security attacks.\" The battery in a mobile computing device is thus a point of vulnerability and must be protected. The purpose of this research is to defend against attacks on the battery.<br\/><br\/>In a typical mobile computer, the battery is expected to give a certain battery life under a set of usage conditions where the user is actively using the device for a small fractionof the time, and the device is idle the rest of the time. When the device is idle, power management software puts the<br\/>device into low power standby and sleep modes, extending the device's battery life. If an attacker can prevent the device from entering low power modes by keeping it active, the battery life can be drastically shortened. There are three main methods for an attacker to drain the battery: (1)<br\/>Service request attacks, where repeated requests are made to the victim for services, typically over a network--even if the service is not provided, the victim must expend energy deciding whether or not to honor the request; (2) benign power viruses, where the victim is made to execute a valid but energy-hungry task repeatedly, and (3) malignant power viruses, where an attacker modifies a program to make it consume more energy than it would otherwise.<br\/><br\/>The ongoing research defends against these attacks by defining (1) a power-secure architecture for mobile computing devices that guarantees a minimum battery life, and (2) a design flow for identifying power-related security vulnerabilities. This work guarantees a minimum battery life by guarding against attacks on the device's battery, including service request attacks, benign power viruses, and malignant power viruses. The overall power-secure architecture employs two<br\/>fundamental security features in the system, multi-layer authentication and energy signature monitor: The multi-layer authentication ensures that all untrusted services rendered consume less than a certain amount of energy. Additional resources are committed only to those requesters who have obtained further levels of trust. The energy signature monitor catches those intrusions that have entered the system to execute an energy-hungry application or service. The research<br\/>consists of the following tasks:<br\/><br\/>* Classification of services to guarantee minimum mission time<br\/><br\/>* Generation, capture, and validation of energy signatures<br\/>for trusted service requests<br\/><br\/>* Validation of the architecture by implementing power-related<br\/>security attacks<br\/><br\/>This project has a number of direct benefits to the stateof the art in information technology. First, it protects battery-powered mobile computing systems, an increasingly important portion of the information technology infrastructure, from a potentially devastating form of security attack. Second, it explores a new problem and attracts attention to an areathat should be studied by a large community of researchers.<br\/><br\/>The broader impact of the this research is to ensure that mobile computing continues to be attractive to a growing community. By protecting against battery-based security attacks, this work ensures the ongoing adoption of mobile computing by a wider segment of society.","title":"ITR: Architecture for Surviving Denial-of-Service Attacks on Battery-powered Mobile Computers","awardID":"0219801","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["475415","494757","553340"],"PO":["7594"]},"72122":{"abstract":"Mislove & Pavlovic<br\/>CCR-0208743--0209004<br\/><br\/>This project focuses on mathematical foundations and design methodologies for embedded hybrid systems (EHS). The essential feature of such systems is that software components interact not only with each other, but also with the physical world, through sensors and actuators. The discrete dynamics of computation thus adds up with the continuous dynamics of physical systems. Hybrid systems are an attempt to capture this double dynamism in a unified framework. To limit the interference of the formidable complexities of dynamical systems of both types, the continuous trajectories are usually encapsulated into states, at the static points of the discrete computational paths. The methods of continuous mathematics are then simply combined with the methods of discrete mathematics to analyze such combined systems.<br\/><br\/>The starting point of the planned research is a belief that the burgeoning field of coalgebra provides methods and techniques that will allow uniform representation and implementation methods for continuous and discrete objects and aspects. While algebraic methods allow specifying and programming of finite objects and inductive structures, such as expressions or well-founded trees, coalgebraic methods allow specifying and programming infinite objects, as coinductive structures: they include automata and various state machines on the one hand, as well as iterative function systems, analytic functions and operators, and real numbers on the other hand.<br\/><br\/>In a real sense, coinduction permeates analysis just like induction<br\/>permeates arithmetic. The difference is that the latter has been recognized as a fundamental logical principle a long time ago, whereas the the former has been recognized only recently, although it has appeared implicitly for some time (e.g. in most existence-of-the-solutions theorems, although it has been recognized as backwards induction in game theory).<br\/><br\/>The task is now to make explicit and systematize the use of coinductive and coalgebraic methods, and to apply them in analysis and design of embedded hybrid systems.","title":"Collaborative Proposal: A Coalgebraic Framework for Development and Composition of Hybrid Systems","awardID":"0209004","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["561160","236026"],"PO":["561889"]},"71154":{"abstract":"0205447 and 0205588<br\/>TITLE: ITR: Collaborative Research: Natural Language in the Development of High-Confidence Software<br\/>PI: John Knight and Robyn Lutz<br\/><br\/>Inadequate communication of domain knowledge in natural language (such as English textual descriptions) is a major source of requirements defects in high-confidence software. Such defects can threaten lives, property, and the dependability of critical infrastructures. This research develops innovative, multi-disciplinary techniques designed expressly to identify and cope with the properties of natural language that lead to these problems. It analyses the domain-knowledge communication problem from the perspective <br\/>of current linguistic theory in order to generate models and techniques that reduce communication breakdowns between domain experts and software developers. On the basis of this analysis, techniques for the elicitation, recording, and propagation of domain knowledge in requirements activities will be designed. A set of tools will also be developed to support the practical use of these engineering techniques. Several case studies will be used to assess and refine the techniques and tools on actual, high-confidence software systems in the aviation and spacecraft application domains. The research effort is directed at the reduction of requirements defects through the application of techniques that take into account the linguistic difficulties particular to domain knowledge communication.","title":"ITR: Collaborative Research: Natural Language in the Development of High-Confidence Software","awardID":"0205588","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["531356"],"PO":["564388"]},"74311":{"abstract":"This proposal describes a set of new techniques for managing access to remote files in the wide area. The vehicle for evaluating these techniques will be a wide-area file system called MoteFS. MoteFS will provide fast, flexible, and secure access to remote files over untrusted wide-area networks. In more detail, the following mechanisms and policies will be investigated:<br\/>- fine-grained namespace mechanisms that allow namespaces to be efficiently and securely added, mutated, transferred and deleted at granularities from single files to millions of files.<br\/>- decomposable credentials, which allow credential holders to locally derive and transfer weaker credentials without contacting file owners.<br\/>- a cross-server versioning abstraction, which allows correlated versions of a group of files to be referenced even if they span multiple users and file systems.<br\/>- client-side differencing, which allows redundant data to be eliminated during network writebacks.<br\/>- wide-area prefetching and caching algorithms.<br\/>The combined effect of these techniques will allow allow users to interact with their files in a flexible, secure, location-independent manner.","title":"ITR: Fast, Flexible, and Secure Wide-Area File Systems","awardID":"0218019","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["409678"],"PO":["543507"]},"72023":{"abstract":"Conditional branches are expensive. Branches require a significant<br\/>percentage of the execution cycles since they occur frequently and can<br\/>cause pipeline stalls. In addition, branches result in forks in the<br\/>control flow, which can prevent other code-improving transformations<br\/>from being applied. We plan to develop path profile-based techniques<br\/>for replacing the execution of a set of two or more branches with a<br\/>single branch on a conventional scalar processor. We propose to<br\/>improve performance by merging the conditions of two or more branches<br\/>into a single condition. Previous approaches have accomplished<br\/>such merging of conditions that have either only involved a single<br\/>variable or have required special hardware to merge multiple<br\/>conditions together. Techniques will be developed to produce a merged<br\/>condition involving multiple variables that can be used to bypass the<br\/>code testing the original set of conditions on a conventional processor.<br\/>Merging conditions may be very good fit for run-time optimization<br\/>systems, which optimize frequently executed paths during the execution<br\/>of a program.","title":"Collaborative Research: Branch Elimination by Condition Merging","awardID":"0208606","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["385733"],"PO":["565272"]},"74685":{"abstract":"EIA- 0219976<br\/>Richard Fujimoto<br\/>Georgia Institute of Technology<br\/><br\/>Title: Simulation-Based Operations Planning for Regional Transportation Systems<br\/><br\/> This grant will support the development and application of high performance modeling and simulation techniques and tools to design and manage regional transportation systems. Tools will be developed to integrate forecasted travel demands with detail micro-level simulation of the transportation infrastucture; the intention is to enable more reliable projections of transportation system behavior. A reservation system will be developed to help manage traveler demands, rather than simply responding to individual traveler's priorities.","title":"ITR: Simulation-Based Operations Planning for Regional Transportation Systems","awardID":"0219976","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["536648","549887"],"PO":["371077"]},"72144":{"abstract":"ABSTRACT<br\/>0209109<br\/>Columbia U<br\/>Yannis Tsividis<br\/>This research explores the possibilities of performing linear analog signal processing using systems which are internally nonlinear. The context is fully integrated systems, fabricated on a single silicon chip, containing a digital signal processor or a computer plus an analog signal processor; the latter is often a necessary part of the interface to the physical world. Conventional linear techniques for implementing analog processors often result in very large energy consumption, which rules them out in many practical cases. We are investigating the use of internally nonlinear processors to bypass those limitations. The applications of this work extend from wireless communications and computer hardware to consumer products to biomedical intrumentation.<br\/><br\/>The use of input-output linear signal processors which are permitted to be internally nonlinear allows the internal signals to have, for a large input signal range, a magnitude well above that of noise and interference, while at the same time remaining safely below overload levels. The result is an adequate signal-to-noise ratio over the entire input range, without requiring large power dissipation and chip area. A number of other related ideas are being investigated as well. One is the use of dynamic biasing, in which the bias levels of dynamical analog circuits, such as filters, are dynamically varied depending on the signal level; the other is the use of multiple signal processors, each being placed dynamically in the path of the signal as required. Since output disturbances would normally occur when the internal parameters of a dynamical system are varied, a key consideration in this research is how to eliminate such disturbances or prevent them from occurring.","title":"Externally Linear Low-Power Analog Signal Processing Circuits","awardID":"0209109","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["526881"],"PO":["564898"]},"74564":{"abstract":"The overall objective of this project is to develop new intrusion detection techniques by integrating intrusion detection with visualization and intelligent interaction strategies. The resulting system allows a user to easily monitor an underlying intrusion detection system (IDS), intercede if it fails to detect potential attacks, identify and address attacks, and update the IDS with attack profiles so that future occurrences will be properly reported. The expected contributions of this project include (1) interactive intrusion detection algorithms that capitalize on human knowledge and judgment, (2) visualization and interaction techniques that support rapid, accurate, and effective monitoring of potential attacks, and (3) semi-automated tools for constructing and evaluating attack profiles to extend the capabilities of an intrusion detection system.<br\/><br\/>Research in this project offers the potential for significant advances in our understanding of how to detect and prevent network intrusions. We expect to make important breakthroughs on a number of fronts, including (1) new methods to automatically identify sophisticated intrusion attempts, (2) new techniques that harness a human observer's unique analysis talents to augment and extend an automated IDS's ability to respond to new or unexpected attacks, and (3) new approaches that allow automated detection algorithms to continually improve by learning from their users. Moreover, the multidisciplinary approach we are using offers the significant benefit of making the problem-solving processes of intrusion detection accessible and available to non-experts. Interactive systems that incorporate visualization and some degree of intelligent assistance can be very appealing to students and even casual computer users, providing a platform for exploration and further learning about the topic. Due to growing interest in the area of intrusion and appropriate countermeasures, the impact of this work will be broadly felt. The research will lead to improved techniques for intrusion detection, and thus to significantly enhanced computer and network security.","title":"ITR: Integrating Intrusion Detection with Intelligent Visualization and Interaction Strategies","awardID":"0219315","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["289699","530056","553866"],"PO":["292741"]},"71077":{"abstract":"This project focuses on compiler-enabled power-aware architectures. <br\/>Its purpose is to leverage static program information in smart ways, <br\/>to reduce power and energy consumption in both embeddded<br\/>and general-purpose architectures.<br\/>We follow three key general ideas to achieve this goal:<br\/>(1) we use static information to throttle processor resources,<br\/>(2) we incorporate architectural features to directly support static<br\/>compiler managed modes of operation, and<br\/>(3) we leverage speculative static information in addition to<br\/>the predictable static information to support (1) and (2). <br\/><br\/>We have demonstrated, in a number of processor architectural domains, <br\/>that our approach is feasible, and can be easily implemented, and that <br\/>considerable energy savings, beyond what would be possible with circuit<br\/>and architectural techniques alone, can be achieved.<br\/>We estimate that our techniques if combined, can give an additional <br\/>30% or more energy savings compared to state-of-the-art low-power <br\/>designs, while not significantly affecting performance.","title":"ITR: Statically Speculative Power-Aware\\(SPA)\\Architectures","awardID":"0205212","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["553614","553615","408968"],"PO":["325495"]},"72056":{"abstract":"Mislove & Pavlovic<br\/>CCR-0208743--0209004<br\/><br\/>This project focuses on mathematical foundations and design methodologies for embedded hybrid systems (EHS). The essential feature of such systems is that software components interact not only with each other, but also with the physical world, through sensors and actuators. The discrete dynamics of computation thus adds up with the continuous dynamics of physical systems. Hybrid systems are an attempt to capture this double dynamism in a unified framework. To limit the interference of the formidable complexities of dynamical systems of both types, the continuous trajectories are usually encapsulated into states, at the static points of the discrete computational paths. The methods of continuous mathematics are then simply combined with the methods of discrete mathematics to analyze such combined systems.<br\/><br\/>The starting point of the planned research is a belief that the burgeoning field of coalgebra provides methods and techniques that will allow uniform representation and implementation methods for continuous and discrete objects and aspects. While algebraic methods allow specifying and programming of finite objects and inductive structures, such as expressions or well-founded trees, coalgebraic methods allow specifying and programming infinite objects, as coinductive structures: they include automata and various state machines on the one hand, as well as iterative function systems, analytic functions and operators, and real numbers on the other hand.<br\/><br\/>In a real sense, coinduction permeates analysis just like induction<br\/>permeates arithmetic. The difference is that the latter has been recognized as a fundamental logical principle a long time ago, whereas the the former has been recognized only recently, although it has appeared implicitly for some time (e.g. in most existence-of-the-solutions theorems, although it has been recognized as backwards induction in game theory).<br\/><br\/>The task is now to make explicit and systematize the use of coinductive and coalgebraic methods, and to apply them in analysis and design of embedded hybrid systems.","title":"Collaborative Research: A Coalgebraic Framework for Development and Composition of Hybrid Systems","awardID":"0208743","effectiveDate":"2002-09-01","expirationDate":"2006-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["536741"],"PO":["561889"]},"71088":{"abstract":"A system called Aura will be designed, implemented, deployed and <br\/>evaluated. Aura will exploit the abundance of computing resources <br\/>made possible by Moore's Law to reduce demand on the scarcest <br\/>resource, human attention. Aura is targeted for environments <br\/>involving wireless communication, wearable or handheld computers, and <br\/>smart spaces.<br\/><br\/>The research spans every system level: hardware, operating system, <br\/>applications and end users. Aura applies two broad concepts. First, <br\/>is proactivity, or the ability of a layer to act in anticipation of <br\/>requests by a higher layer. Second, is self-tuning: layers adapt by <br\/>observing the demands and adjusting performance and resource usage to <br\/>match. Both techniques contribute to lowering demand on human <br\/>attention. These ideas will be evaluated through controlled <br\/>experiments and live use by a small community. The metrics used in <br\/>evalutation include both traditional computer systems metrics plus <br\/>user-centric metrics.<br\/><br\/>There are three major research thrusts. First, operating system and <br\/>networking capabilities required by Aura-like systems are <br\/>investigated. Second, how high-level user intent can be captured and <br\/>exploited for proactivity is explored. Third, how contextual <br\/>information can be used is examined. A unique aspect of the research <br\/>is its tight integration with education since the Aura prototype will <br\/>be used in graduate-level courses.","title":"ITR: Proactive Self-Tuning Systems for Ubiquitous Computing","awardID":"0205266","effectiveDate":"2002-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["485947","463128","492191","475390"],"PO":["564777"]},"77501":{"abstract":"This collaborative SGER research project brings together two research areas, heterarchical organizations and knowledge networks, to investigate coordination among the myriad government agencies, civic associations, architectural and design firms and academics involved in the redevelopment of Lower Manhatten. The project will 1) identify the field of actors and stakeholders differentiated by sector, 2) identify and analyze existing ties among actors and organizations, 3) analyze existing web sites maintained by the diverse actors, 4) map the network of existing web sites to discern coalitions within and among sectors, 5) conduct interviews with individual members identified as key stakeholders, 6) map existing and potential networks using visual mapping tools, 7) trace the shifting boundaries of knowledge networks over time, 8) deploy IKNOW, a community-ware web-based tool that makes knowledge networks visible to communities of practitioners, so that relevant information and insights are available when and where they are needed, and 9) track the use of IKNOW by different stakeholders. This investigation will have practical and theoretical outcomes. The community participants will benefit from new forms of technology to help them better understand \"Who knows what?\" and \"Who knows who knows what?\" The researchers will benefit from access to an acute and timely setting for studying emerging heterarchical structures that involve lateral coordination across organizational boundaries with multiple performance criteria and diverse evaluative principles to assess what is worthy and valuable.","title":"SGER: Collaborative Research: Knowledge Networks and Emerging Heterarchies in Rebuilding New York","awardID":"0233449","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["532398"],"PO":["565227"]},"78832":{"abstract":"Abstract<br\/>CCR0 0239511<br\/><br\/>This award supports a workshop on information for Critical Infrastructure Protection, organized by the University of California at Berkeley, in cooperation with Vanderbilt University and the University of Virginia. The NSF Workshop on Information Technology Research for Critical Infrastructure Protection, to be held in cooperation with OSTP, September 19-24, 2002 in Leesburg VA. The purpose is to evaluate status and identify research needs for information technology embedded in critical infrastructures. This workshop addresses research gaps in secure, networked, embedded systems for critical infrastructures; Supervisory Control and Data Acquisition (SCADA) systems; and infrastructure interdependencies. The first session is a two-day, in-depth exploration of research needs. This session brings together the academic research community, industry, and federal participants. The objective is the identification of challenge areas and development of a research agenda for software and information technology to support secure, networked, embedded systems. The goal is a new software and systems research strategy that can underpin next-generation embedded systems, provide research infrastructure, and ultimately improve the nation's critical infrastructure. Next is a one-day session, organized and co-funded by the Computing Research Association, to discuss academic perspectives on challenges in Critical Infrastructure Protection. Concluding the workshop is a two-day session jointly sponsored by NSF, the Department of State, and OSTP to promote global progress on these issues and to promote international collaboration between researchers in the US and the EU. The product of the workshop is a report, made available to the research community, to OSTP for strategic planning and to NSF and other Federal program managers for planning and coordination of research investments.","title":"Workshop on Critical Infrastructure Protection; September 23-24, 2002; Leesburg, VA","awardID":"0239511","effectiveDate":"2002-09-01","expirationDate":"2005-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["526900"],"PO":["561889"]},"75686":{"abstract":"EIA-0224671<br\/>Jeffrey T. Clark<br\/>Brian M. Slator<br\/>North Dakota State University - Fargo<br\/><br\/>CISE RR: Advancing Vidualization Projects Through the Use of High-Performance Virtual Reality Systems<br\/><br\/>This proposal from an EPSCoR state, fostering development in computer visualization research, aims at acquiring equipment to support North Dakota's State University Archeological Technologies Lab. The research involves the use of compelling digital visualization experiences and authentic simulated virtual worlds to support the following projects:<br\/><br\/>1. Virtual reconstruction of Like-a-Fishhook Village (to be displayed at the Heritage Center - state museum - in Bismarck and the Cultural Center of Three Affiliated Tribes in New Town),<br\/>2. Virtual reconstruction of On-a-Slant Village (for display at the Fort Abraham Lincoln Museum in Mandan), and<br\/>3. Immersive virtual environment of a Native American powwow-dancing competition for use in diabetes prevention in Native American youth.<br\/><br\/>An SGI Reality Center as a state-or-the-art technology augmentation to current NDSU facility and computer visualization capabilities will contribute to the virtual reconstructions of the villages and the computer simulation game for diabetes education. The work facilitates projects in archeology, anthropology, and museology. Expecting to develop and host a variety of virtual 3D environments at the highest levels and to send the virtual worlds to multiple remote location for concurrent display, the equipment and requisite software systems will constitute a qualitative leap in the capabilities to share high-detail 3D content for both research and education.","title":"CISE-RR: Advancing Visualization Projects Through the Use of High-Performance Virtual Reality Systems","awardID":"0224671","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["411409","537856"],"PO":["557609"]},"74597":{"abstract":"There are many different sources from which relevant information can be<br\/>obtained for an intelligence task at hand, such as an analysis of operations<br\/>planning by Al Qaeda. The accuracy of this information is frequently<br\/>imperfect. <br\/><br\/>Information obtained from each source is frequently also different in<br\/>structure and scope. XML has emerged today as the standard for information exchange. Its<br\/>flexibility permits the representation of information from heterogeneous<br\/>sources in a single unified framework.<br\/><br\/>The goal of this project is to manage uncertain (probabilistic) data,<br\/>represented in XML. While there have been previous efforts to develop<br\/>probabilistic relational systems, the need for representing and querying<br\/>uncertain information is much greater for loosely structured data not <br\/>readily amenable to a relational representation.<br\/><br\/>XML data poses several modeling challenges that are the focus of this<br\/>project: due to the data having (an inclusion hierarchy) structure,<br\/>probabilities cannot be assigned independently; due to XML elements occurring<br\/>at multiple granularities, probabilities may be assigned at multiple levels;<br\/>due to the possibility of missing and repeated sub-elements, one may not be<br\/>able to obtain complete distributions.","title":"ITR\/IIS: Querying Heterogeneous and Uncertain Information","awardID":"0219513","effectiveDate":"2002-09-01","expirationDate":"2007-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["533266"],"PO":["469867"]},"77512":{"abstract":"This collaborative SGER research project brings together two research areas, heterarchical organizations and knowledge networks, to investigate coordination among the myriad government agencies, civic associations, architectural and design firms and academics involved in the redevelopment of Lower Manhatten. The project will 1) identify the field of actors and stakeholders differentiated by sector, 2) identify and analyze existing ties among actors and organizations, 3) analyze existing web sites maintained by the diverse actors, 4) map the network of existing web sites to discern coalitions within and among sectors, 5) conduct interviews with individual members identified as key stakeholders, 6) map existing and potential networks using visual mapping tools, 7) trace the shifting boundaries of knowledge networks over time, 8) deploy IKNOW, a community-ware web-based tool that makes knowledge networks visible to communities of practitioners, so that relevant information and insights are available when and where they are needed, and 9) track the use of IKNOW by different stakeholders. This investigation will have practical and theoretical outcomes. The community participants will benefit from new forms of technology to help them better understand \"Who knows what?\" and \"Who knows who knows what?\" The researchers will benefit from access to an acute and timely setting for studying emerging heterarchical structures that involve lateral coordination across organizational boundaries with multiple performance criteria and diverse evaluative principles to assess what is worthy and valuable.","title":"SGER: Collaborative Research: Knowledge Networks and Emerging Heterarchies in Rebuilding New York","awardID":"0233489","effectiveDate":"2002-09-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["525526"],"PO":["495796"]},"75114":{"abstract":"The Next Generation Internet (NGI) poses scalability challenges to the efficient operation of <br\/>the transport protocol (TCP). In particular, as the product (bandwidth x delay) grows, the <br\/>congestion window required to .fill the pipe. becomes quite large, especially on cross-country <br\/>links. One well known problem in TCP in this scenario is the selection of the .initial <br\/>window.. More recently, new challenges have emerged because of the increasing popularity <br\/>of nomadic access to the Internet via wireless links (e.g., wireless LANs, satellite links, <br\/>UMTS, etc). The data rates on wireless links have been constantly on the rise, approaching <br\/>the 50Mbps on 802.11a wireless LANs and thus providing an effective extension of backbone <br\/>services to mobile users. However, wireless links tend to introduce random packet errors and <br\/>loss that are not correlated to congestion. This creates problems to conventional TCP <br\/>protocols (e.g., TCP New Reno and TCP SACK), which interpret any loss as a buffer overflow <br\/>(i.e., as a symptom of congestion) and thus reduce the congestion window unnecessarily with <br\/>consequent loss in performance. The drop in performance is proportional to the (bandwidth x <br\/>length) product of the connection and can be quite significant in the high bandwidth NGI <br\/>environment, especially on cross country paths including .last hop wireless LANs, UMTS <br\/>links, or high bandwidth satellites. <br\/>Several approaches to enhance TCP congestion control over high bandwidth wireless links <br\/>have been reported in the literature (e.g., TCP Peach, TCP Westwood (TCPW)). Some of <br\/>these enhancements have been quite successful. For example, TCPW, a TCP variant that <br\/>uses bottleneck bandwidth share estimation. to adjust the congestion window upon loss, has <br\/>shown scalable properties and good link utilization in large leaky pipes., (i.e. large <br\/>bandwidth delay product, and non negligible random packet loss). <br\/>This proposal is about carrying out a systematic, experimental investigation of performance <br\/>of TCP over wired\/wireless paths. This investigation will include the comparison of various <br\/>TCP enhancements proposed so far in the literature. It will consider a representative set of <br\/>experimental environments and application scenarios. The proposed project is in part <br\/>motivated by our recent positive experience with TCPW Internet experiments of large file <br\/>transfers over lossy paths. In this project the researchers will broaden the scope to include a vast gamut of TCP wireless enhancement techniques. The researchers will identify the pros and cons of each scheme, characterize the traffic\/network environment for which it is best suited, and, more generally, develop models that relate wireless media characteristics, TCP congestion control <br\/>parameters and performance results. <br\/>In summary, given: (1) the increasing importance of nomadic computing and wireless access <br\/>to the high speed wired Internet; (2) the performance degradations observed in conventional <br\/>TCP protocols over wireless path, and (3) the encouraging improvements offered by <br\/>modified, wireless versions of TCP (which yet retain the basic end to end paradigm), the researchers believe this a very appropriate time to engage in a systematic, experimentally based <br\/>evaluation of wireless TCP protocols by a team that includes protocol developers, <br\/>applications developers and network measurement experts.","title":"Transport Protocols for the Wired\/Wireless NGI: Implementation and Experimental Evaluation","awardID":"0221528","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["558959","260968"],"PO":["7594"]},"67458":{"abstract":"EIA-0133589<br\/>Erez Zadok <br\/>SUNY -Stony Brook<br\/><br\/>CAREER: An In-Kernel Runtime Execution Environment for User-Level Programs<br\/><br\/>We propose to develop a system that will simplify operating system code development while improving performance. Developing operating system kernel code is difficult for three reasons. First, the kernel is an unforgiving environment to work in, where any small bug can result in large-scale data corruption; debugging tools for kernels are not as flexible as their user-level counterparts and are not used often. Second, kernel developers must write codes that takes into account many unusual conditions such as resource contention, locks, reference counts, being interrupted or re-entrant, and more. Third, before programmers can become proficient kernel developers, they must read and understand large amounts of complex kernel code. However, one major advantage to developing kernel code is that it runs very fast; the kernel has direct access to all the system resources.<br\/><br\/>The benefits of this research will include the creation of a novel system that allows anyone who can write user-level code to develop and test their code in the user level where it is easier to do so, and then to execute that code inside the kernel to gain significant performance benefits. This research will enable us to learn about the security and scalability of running many kernel applications and develop methods to optimize the performance of in-kernel applications further.","title":"CAREER: An In-Kernel Runtime Execution Environment for User-Level Programs","awardID":"0133589","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["543574"],"PO":["551712"]},"68217":{"abstract":"The goal of this project is the design of joint power control, rate control, and base station assignment for multimedia wireless networks. Two key aspects of the multimedia network will be considered that have been given short shrift in the past: the requirements of data and system dynamics. The project will consider 4th generation Direct-Sequence Code-Division Multiple-Access (DS-CDMA) networks. The goal is to implement dynamic assignment of downlink transmit power, data rate, and codes to each mobile in accordance with the ability of each application to use the resulting QoS. The focus is on network-wide behavior, and therefore network-wide performance measures will be considered, jointly optimized between physical and networking layers. Three main thrusts will be considered: <br\/>(a) Use of multiple state automata hybrid systems models as a novel tool to control wireless network dynamics. <br\/>(b) Design and analysis of resource allocation algorithms using novel pricing theory. <br\/>(c) Design and analysis of parameter estimation algorithms to achieve robust network behavior. <br\/>The first thrust is intended to provide a powerful tool for generating control algorithms for systems with both discrete and continuous parameters and switching costs. It will be used in this project for controlling power, data rate, and handoffs. The research in this area will extend the dimensionality of a previously studied hybrid systems approach to handoff control. The second research thrust is the construction of joint power control, data rate control, and base station assignment algorithms. This research will be based on economic theory for resource allocation, and implemented using hybrid systems. The final thrust will address the reliance of many resource allocation schemes upon unknown communication parameters such as received SINR. Three investigators will work together: an expert in hybrid systems, an expert in resource allocation, and an expert in multiuser spread spectrum wireless systems.","title":"Collaborative Research: A Hybrid Systems Approach to Resource Allocation for Multimedia Wireless Networks","awardID":"0137091","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["515828"],"PO":["7594"]},"70792":{"abstract":"Safety analysis is essential for high-assurance software systems. <br\/>Safety analysis identifies the hazards, derives the software safety<br\/>requirements to eliminate or control these hazards, and ensures that the design<br\/>and implementation incorporate those safeguards. A product line is a<br\/>set of products that share a common set of features and a related market or<br\/>mission.Currently, high-assurance product lines are being built without the<br\/>tools or conceptual framework necessary to perform effective safety analyses. <br\/>This research addresses the question of how safety analysis can<br\/>become a reusable asset of a product line by developing a framework and asuite of techniques for the safety analysis of critical product lines. Anticipated benefits of the research include extending safety analyses toproduct lines, providing a framework for reuse of safety analyses within a product line, deriving formally specified limits on reuse of product-line safety analysis, and enabling safer product-line systems at lower cost and reduced schedules. The results will be empirically evaluated by application in<br\/>industrial case studies. This project will expand the opportunities available to<br\/>student researchers to participate in development of safety-analysis<br\/>techniques for product lines.","title":"Safety Analysis for Critical Product Lines","awardID":"0204139","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["531356"],"PO":["564388"]},"70693":{"abstract":"TITLE: Towards Community Services: Putting Parallel Network Services On-line<br\/><br\/>This project will investigate a community service system architecture and run-time infrastructure needed to support such high-end services. We will focus on two key run-time issues for performance: dynamic resource management and scaling. Dynamic resource management allows: (i) resources to be {de-} allocated to service requests on-the-fly, (ii) resources to be acquired via negotiation, and (iii) resources to be shared across inter-service domains. Resource management will be based on a performance estimation technique that learns service execution time as function of dependent inputs and resources allocated. We will produce a set of next generation tools and libraries that can be leveraged by community services running in single-site clusters and in multi-site Grids. The toolset will be evaluated by applying it to several high-end network services in the area of visualization, astronomy, and bioinformatics.","title":"Towards Community Services: Putting Parallel Network Services On-line","awardID":"0203870","effectiveDate":"2002-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["543508"],"PO":["301532"]},"74730":{"abstract":"Proposal Number: 0220166<br\/> Title: ITR\/SY Features, Components, and Legacy Systems<br\/> PI: George T. Heineman, Computer Science Department, WPI<br\/><br\/> A legacy system is any software system that is in use and must evolve<br\/> to meet changing conditions. These systems must be re-engineered<br\/> because over time, the ability to evolve the system decreases with<br\/> each successive maintenance. The proposed research combines the<br\/> concepts of features and software components in a novel way to<br\/> extract feature-based software components from a legacy<br\/> system. First, the features of the target legacy system are elicited<br\/> and using existing code profiling tools, the code associated with<br\/> these features is identified. This task is made possible by the<br\/> regression test suite that many legacy systems already have to ensure<br\/> proper functioning as the system is upgraded. Second, software<br\/> components are refactored from the legacy system. In short, the data<br\/> generated by execution traces is analyzed for evolution purposes.<br\/> The research will provides a viable long-term strategy for an<br\/> organization to incrementally modernize its software code base. A<br\/> reengineering methodology will be defined and applied. A<br\/> corresponding cost\/savings model will be developed based upon<br\/> preliminary success with the legacy system for a financial<br\/> company. The methodology will be packaged and disseminated to ensure<br\/> other organizations with legacy systems can easily benefit from the<br\/> results of this research.","title":"ITR\/SY: Features, Components, and Legacy Systems","awardID":"0220166","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["355586"],"PO":["565272"]},"74620":{"abstract":"EIA-0219627 Craig Douglas University of Kentucky Collaborative Research: ITR\/AP-Predictive Contaminant Tracking Using Dynamic Data Driven Application Simulation \\(DDDAS\\) Techniques<br\/><br\/>This project will lead to a leap-ahead technology in simulation capabilities. Research in the development of new methods and algorithms for the specific application areas is needed. The dynamic application requirements will dictate computing systems' support that includes systems' software technologies, such as active middleware services for real time, dynamic reconfiguration capabilities, resource discovery, load balancing, security, fault tolerance, quality of service, and dynamic interfaces with field measurement systems. <br\/><br\/>An encoded web stream set of contaminations from actual situations (both above ground and underground) will allow researchers besides us to tap into our virtual reality DDDAS environment. Visualization systems will allow us to work with a variety of real networks, sensors, and environments.","title":"Collaborative Research: ITR\/AP - Predictive Contaminant Tracking Using Dydnamic Data Driven Application Simulation (DDDAS) Techniques","awardID":"0219627","effectiveDate":"2002-09-15","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["495104"],"PO":["551712"]},"71122":{"abstract":"Proposal Numbers: 0205447 and 0205588<br\/>TITLE: ITR: Collaborative Research: Natural Language in the Development of High-Confidence Software<br\/>PI: John Knight and Robyn Lutz<br\/><br\/>Inadequate communication of domain knowledge in natural language (such as English textual descriptions) is a major source of requirements defects in high-confidence software. Such defects can threaten lives, property, and the dependability of critical infrastructures. This research develops innovative, multi-disciplinary techniques designed expressly to identify and cope with the properties of natural language that lead to these problems. It analyses the domain-knowledge communication problem from the perspective of current linguistic theory in order to generate models and techniques that reduce communication breakdowns between domain experts and software developers. On the basis of this analysis, techniques for the elicitation, recording, and propagation of domain knowledge in requirements activities will be designed. A set of tools will also be developed to support the practical use of these engineering techniques. Several case studies will be used to assess and refine the techniques and tools on actual, high-confidence software systems in the aviation and spacecraft application domains. The research effort is directed at the reduction of requirements defects through the application of techniques that take into account the linguistic difficulties particular to domain knowledge communication..","title":"ITR: Collaborative Research: Natural Language in the Development of High Confidence Software","awardID":"0205447","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["402466","246910"],"PO":["564388"]},"74642":{"abstract":"This proposed research project aims to explore several unanswered questions in the area of differentiated services for next generation Internet. In particular, the issue of routing SLAs in the presence of multiple alternative physical paths is a topic that has been seldom researched<br\/>upon. It is an important issue since the objective is to maximize the probability of success for an SLA without opting for over-provisioning. Also, in the presence of multiple physical paths, which is typical in large networks, there is a need to choose the optimal path based on appropriate criteria. The proposed research directly addresses this critical issue. Currently, there are no standard schemes for hierarchical QoS routing. One of the most crucial problems in hierarchical QoS routing is to make intelligent decisions in the presence of out-of-date or stale network stateinformation. The proposed research will address this issue by making use of local statistics collected at each router and obtaining a time history of the network state information. Furthermore, every domain will have a finite traffic handling capacity. This capacity is bound above by the domain topology and the maximum link bandwidth. For computing feasible paths, current QoS routing schemes take only the individual link bandwidth into account as a constraint but not the domain capacity as a whole. The research will address this shortcoming by incorporating the domain capacity as a constraint in the path computation algorithms. Additionally, this research project will also study the problem of splitting aggregated flows in a transit domain with the goal of maximizing the domain resource utilization. The motivation comes from the fact that splitting of aggregated flows will lead to better utilization of the network bandwidth.","title":"ITR: Routing of Dynamic Service Level Agreements between Inter-domain Bandwidth Brokers","awardID":"0219747","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["528208","562302","429449"],"PO":["292741"]},"73553":{"abstract":"EIA-0215356<br\/>Ikhlas Abdel-Qader<br\/>Bradley Bazuin<br\/>Karlis Kaugars<br\/>Abhay Sharma<br\/>Li Yang<br\/>Western Michigan University<br\/><br\/>MRI\/RUI Acquisition of Computing and Peripheral Hardware to Support Collaborative Research and Research Education in Imaging and Information Visualization<br\/><br\/>This proposal from a RUI institution, developing an Ethernet-Based imaging and visualization infrastructure, supports interdisciplinary research projects that span a variety of application areas such as Information Visualization, Imaging Science, Color Analysis, Time-Varying Images, and Real-Time Image Processing. The laboratory, consisting of one server, multiple workstations, associated cameras, frame grabbers, output devices, and selected network and image processing software, will be bridged to existing departmental, college, and campus networks, and will be used to accomplish the following goals:<br\/> Expand research investigations advancing image processing and information visualization,<br\/> Encourage interdisciplinary research, research training, and educational activities,<br\/> Increase industrial collaboration adding a real world problem environment,<br\/> Support graduate and undergraduate instruction in related courses such as Pattern Recognition, Computer Graphics, and Digital Imaging, and<br\/> Attract women and minority groups at both graduate and undergraduate levels to pursue research projects.<br\/>The infrastructure will service the following projects within three research groups:<br\/>1. Information Visualization and Data Mining Group<br\/>A. Visual Exploration and Mining of Large Relational Datasets<br\/>B. Algorithm Visualization<br\/>C. Interactive Document Management<br\/>D. Visualization of Association Rules<br\/>2. Image Visualization, Color Measurement, and Color Analysis Group<br\/>A. Color Reproduction in Digital Imaging<br\/>B. Fundamental Analysis of CCD Imaging Systems Using Fourier Theory<br\/>3. Real-Time Image Processing and Pattern Recognition Group<br\/>A. Utilizing Wavelets for Target Tracking<br\/>B. An Integrated Image Analysis Algorithm from Dynamic Scenes<br\/>C. Confocal Microscopy and Image Analysis in Gamma-Ray Astronomy<br\/>D. Wireless Vision for Intelligent Transportation System<br\/>E. Pavement Surface Image Analysis System","title":"MRI: Acquisition of Computing and Peripheral Hardware to Support Collaborative Research and Research Education in Imaging and Information Visualization","awardID":"0215356","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["441371","490803","514674","197380",190490],"PO":["557609"]},"74521":{"abstract":"This study will investigate online investing and virtual investing-related communities (VICs)looking at two broad research issues: (a) How is information generated, discussed, and diffused within and across VICs, and how do such activities impact market efficiency? and (b) How do economic, social and psychological influences together impact investor adoption, participation, and satisfaction? The study will involve processing over three million messages covering 40 stocks from 10 major VICs. The information will be parsed and categorized, and various hypotheses related to diffusion and market impacts will be tested. In-depth interviews and a large-scale survey of online investors will validate a comprehensive model of investor satisfaction. This research contributes to the information processing and diffusion, rumor propagation, impact of IT on markets, and individual\/group behavior literatures that lie at the intersection of information systems, psychology, marketing, and economics. The research results will lay the foundation for the design of software tools that can detect worrisome types of information flow in real-time. From a regulatory perspective, an understanding of social and psychological biases and distorting influences will support the design of regulatory measures that counter their negative impacts.","title":"ITR: Collaborative Research:Virtual Investing-Related Communities and Online Investing: A Study of Adoption, Usage, and Performance and Policy Implications","awardID":"0219107","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[193543],"PO":["564456"]},"74653":{"abstract":"Projects of national importance critically depend on supercomputers, such as the ASCI White supercomputer deployed at Lawrence Livermore Laboratories. Supercomputers such as these are comprised of thousands of microprocessors that share terabytes of main memory. In order to bring down the cost of these `shared memory' supercomputers and to ensure their error-free operation during long-running simulations, their design and verification complexity must be significantly reduced. A significant amount of this complexity exists in the concurrent protocols that allow the microprocessors to reliably share memory. The investigators study how to automatically synthesize these protocols from higher level descriptions that are easier (and hence quicker) to verify correct. This research involves a formal understanding of high performance protocols in use this area, the creation of a guided synthesis procedure that allows designers to quickly explore the space of protocols and select one that meets the performance goals, and then mathematically prove the correctness of the high level protocol as well as its translation to a detailed hardware-level protocol description. Design and verification tools that the industry can adopt are being developed.<br\/><br\/>The distributed shared memory (DSM) is a dominant organizational paradigm for multiprocessor machines. DSM machines are used as desktop computers, supercomputers such as the 512-node ASCI White of Lawrence Livermore, and in future sold as single-chip multiprocessor components. The high verification complexity of DSM machines is known to delay the shipping dates of microprocessors and parallel processing software. This complexity stems from a host of DSM protocol design issues, such as: (i) aggressive latency hiding through out-of-order processing, implying the use of complex weak memory consistency models; (ii) complex protocol actions that require buffer reservation and deadlock avoidance. This research involves a formal understanding of weak memory models (captured as a theorem-prover library), and high performance protocols in use this area. It develops guided synthesis procedures that allow designers to quickly explore a wide spectrum of protocols. Once a high-level protocol meeting estimated performance goals is selected, model checking is employed to verify conformance against the chosen weak memory model. A mathematically proven (using theorem proving) translation procedure is then applied to obtain a detailed protocol description. This description is analyzed for performance and iterated till convergence. Examples drawn from industrial multiprocessors are used to illustrate our new methods. Design and verification tools that the industry can adopt are being developed.","title":"ITR: Protocol Synthesis and Verification","awardID":"0219805","effectiveDate":"2002-09-01","expirationDate":"2006-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["561775",193919],"PO":["562984"]},"71144":{"abstract":"PROPOSAL ABSTRACT<br\/><br\/>Scalable Molecular Electronics<br\/><br\/> We are approaching the end of a remarkably successful era in computing: The era where Moore's Law reigns, where processing power per dollar doubles every year. This success is based in large part on advances in complementary metal-oxide semiconductor (CMOS)-based integrated circuits. Although we have come to expect, and plan for, the exponential increase in processing power in our everyday lives, today Moore's Law faces imminent challenges both from the physics of deep-submicron CMOS devices and from the enormous costs of chip masks and next-generation fabrication plants.<br\/> A promising alternative to CMOS-based computing being investigated is chemically assembled electronic nanotechnology (CAEN). Electronic nanotechnology (EN) constructs electronic circuits out of nanometer-scale devices that take advantage of quantum-mechanical effects. The fundamental strategy of CAEN is to substitute compilation time (which is inexpensive) for manufacturing precision (which is ex-pensive). The research will be directed at integrating defect measurements with computer architecture and compiler technology to create circuits from chemically assembled structures.<br\/> Using EN to build computer systems requires new ways of thinking about computing devices; spanning everything from circuits to compilers. Unlike conventional CMOS, CAEN cannot be used to construct complex structures. Instead, one fabricates dense regular (but potentially defective) structures, which we call nanoFabrics, that can be programmed after fabrication to implement complex circuits. The proposed research investigates how to scale CAEN to create useful computational devices with more than 10^10 gate-equivalents per cm^2 by developing new circuit technology, reconfigurable computing, defect tolerance, architectural abstractions and innovative compiler technology While the researchers will not be designing the EN devices themselves, their goal is to show how they can be used to create computing devices and guide EN scientists in their development of the underlying technology. The investigators approach this problem at four levels:<br\/> Logical Building Blocks: The researchers will develop models of EN devices and new circuit simulation technology that will allow predictions of performance across important metrics such as power, speed, density, area, and delay. These models will be used to design and determine the characteristics of logical circuit building blocks, nanoBlocks, for computing systems.<br\/> Manufacturing: Due to the nature of EN and specifically CAEN fabrication, the devices will have defects. The investigators will develop methods which will allow systems based on EN devices to transparently work in the presence of such defects.<br\/> Computer Architecture: The researchers will develop a hierarchy of abstract machines that support re-configurable computing and hide complexity. A split-phase abstract machine (SAM) will be used to partition programs into processes, which will be mapped to an abstract machine composed of tiles arranged on a 2-D grid. Each tile will contain four components: a finite state machine, a data path segment, a local memory, and a router. Tiles may be grouped together into a complete pipelined datapath. The tiles themselves will be implemented in nanoBlocks, the basic unit of the nanoFabric.<br\/> Compilation: Compilation technology will be developed to map programs written in general-purpose programming languages, e.g. C or Java, to nanoFabrics. The research will focus on ensuring that the compiler will scale to nanoFabrics, which can have hundreds of millions of components. The compiler decomposes an application into a series of independent SAMs based on control flow and memory access patterns. They are developing a new intermediate representation with a precise semantics that turns all control flow into data flow. The IR unifies predication, speculation and static-single assignment and makes explicit data flow, control flow, and synchronization. This leads to an enormous simplification of many optimizations and provides the framework for formal translation and optimization validation of the compiler. <br\/> This research has the potential to utilize, and guide the development of, electronic nanotechnology to inexpensively produce low-power circuits a million times more dense than conventional CMOS circuits.","title":"ITR: Scalable Molecular Electronics","awardID":"0205523","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["551078","332333","524886","549747"],"PO":["325495"]},"74532":{"abstract":"This award addresses an important fundamental problem in computational mathematics: how to optimize complex systems described by partial differential equations (PDEs). The focus is on PDE simulations that can scale into millions of variables, and hundreds or thousands of processors. The size of the problems and the complexity of the techniques for solving these PDEs pose major challenges to modern optimization methods. The project uses a general framework for solving optimization problems in interaction with PDE solvers.","title":"ITR: Collaborative Research: Optimization of Systems Governed by Partial Differential Equations","awardID":"0219190","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["517222","517075"],"PO":["565272"]},"72002":{"abstract":"Lemmon Michael<br\/>CCR-0208537<br\/>\"Performance Based Soft Real-time Scheduling in Networked Control Systems\"<br\/><br\/>This project is developing novel methods for the design of high performance networked control systems. The networked control system under consideration distributes controller functionality over a collection of micro-controllers that communicate over an ad-hoc communication network. The project uses a soft variation of the (m,k)-firm guarantee model to characterize task scheduling in networked control systems. The project consists of three tasks. The first task obtains upper bounds on dropout probabilities that assure robust performance of the closed loop system. These bounds define the soft (m,k)-model, which is one major emphasis of the research. The second emphasis is on the design of implementable schedulers that enforce the soft (m,k) model arising from the control design.<br\/><br\/>The project's broader impact is achieved through the inclusion of methods and concepts developed in this project in undergraduate courses that introduce embedded system principles.","title":"Performance Based Soft Real-time Scheduling in Networked Control Systems","awardID":"0208537","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["460500","526924","550624"],"PO":["561889"]},"74543":{"abstract":"EIA-0219229<br\/>Torng, Eric K<br\/>Michigan State University<br\/><br\/>ITR: Evaluating Phylogeny Reconstruction Algorithms with Digital Organisms<br\/><br\/>The investigators study methods of determining the historic relationship<br\/>between species using only knowledge of currently existing organisms, a technique called \"phylogenetic tree reconstruction\". Many tree reconstruction algorithms are known, but it is difficult to properly test them for the very<br\/>reason that the algorithms are useful -- the original trees are lost to<br\/>history.<br\/><br\/>The studies proposed make use of a new evaluation methodology based on an<br\/>artificial evolving system called Avida. In Avida, populations of digital<br\/>organisms (self-replicating computer programs) experience natural selection<br\/>as they compete for limited resources, and will evolve into new species<br\/>often with entirely new genes. The history of such a system can be<br\/>monitored, and hence a reconstruction from the final state can have its<br\/>accuracy measured.<br\/><br\/>The proposed activity has several broader impacts on society. It is a core<br\/>activity in the Center for Biological Modeling, a new interdisciplinary<br\/>research and education center at Michigan State University. Undergraduate<br\/>students including underrepresented minorities will be involved by studying<br\/>small, self-contained questions. Finally, enhanced understanding of<br\/>phylogeny reconstruction algorithms will improve our ability to interpret<br\/>the<br\/>sequences of genes, aiding in drug design and helping efforts to reconstruct<br\/>an evolutionary \"tree of life\".","title":"ITR: Evaluating Phylogeny Reconstruction Algorithms with Digital Organisms","awardID":"0219229","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["425363","562295","477302"],"PO":["565136"]},"72134":{"abstract":"Rinard, Martin<br\/>CCR-0209075<br\/><br\/>The project will investigate a new program analysis, interaction<br\/>analysis, and a new set of implementation techniques to support<br\/>future generations of embedded systems. Instead of executing low-level<br\/>code whose sole responsibility is to control a specific piece of<br\/>hardware, these future systems will be built in a layered fashion,<br\/>with the core control software surrounded by outer layers of software<br\/>that integrate the core software and the device that it controls into<br\/>a larger integrated, distributed system of devices and users.<br\/>The key challenge associated with realizing this vision is the need to<br\/>effectively apply implementation mechanisms that enable the outer<br\/>layers to share the hardware device without disrupting the actions of<br\/>the time and safety critical core code. The economics of developing<br\/>large software systems will ensure that most of the outer layers will<br\/>consist of standard, off-the-shelf software components from the world<br\/>of laptop, desktop, and server computing. The outer layer software<br\/>will therefore have been developed to use implementation mechanisms<br\/>that are unsuited for use in time-critical control<br\/>software. Nevertheless, the core software and the outer layer software<br\/>will need to interact. With standard implementation mechanisms,<br\/>interactions mediated by objects shared with outer layers could easily<br\/>lead to unacceptable delays and a loss of real-time control in the<br\/>core.<br\/>The focus of this research is the development and investigation of new<br\/>interaction analysis algorithms that extracts the interaction patterns<br\/>between the core and outer layers, then uses these patterns to<br\/>classify objects into several categories. Each category can then use<br\/>an implementation mechanism appropriate for how it is used in the<br\/>system. The end result is a system in which the outer layers and core<br\/>software effectively cooperate without a loss of safety or<br\/>predictability.<br\/>The envisioned analysis has several properties that will make it<br\/>suitable for this application. First, it is capable of extracting a<br\/>meaningful result with an analysis of only part of the program.<br\/>Second, it can effectively analyze the multithreaded programs that<br\/>come from the integration of the outer layers and the core. Third, the<br\/>partial analysis is goal-driven to extract the required information<br\/>with an analysis of only those parts of the program required to obtain<br\/>the result.","title":"Interaction Analysis for Integrated Embedded Systems","awardID":"0209075","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["497068"],"PO":["561889"]},"78910":{"abstract":"Data mining is the semi-automatic discovery of patterns, associations, changes, anomalies, rules, and statistically significant structures and events in data. Thus, data mining aims to extract knowledge from sensor data, and is an emerging area with numerous commercial applications. Work in data mining ranges from theoretical work on the principles of learning and mathematical representations of data to building advanced engineering systems that perform information filtering on the web, find genes in DNA sequences, help understand trends and anomalies in economics and medicine, and detect network intrusion. <br\/><br\/>The problem gets more complicated in a distributed system where the data itself is positioned across different sites and coordination across the sites needed to mine information from the distributed data. Distributed Data Mining (DDM) arises in diverse areas such as sensor stream data generated from satellite etc. <br\/><br\/>Presently, there are several proposed ad-hoc approaches to distributed data mining (DDM) that deal with specific schemes and most of them do not address any real time analysis for solving different classes of distributed data mining problems. This project will address this very explicitly the merits of the new framework.","title":"Real Time Distributed Data Mining for Sensor Networks","awardID":"0239914","effectiveDate":"2002-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["558109"],"PO":["563751"]},"75401":{"abstract":"In the last decade, computer systems have increasingly become participants in complex, distributed communities comprising people and computer systems, rather than devices used by individuals. This major shift engenders a significant challenge for computer science: to determine ways to construct computer systems able to act effectively as team members. Although many current computer systems have sophisticated capabilities as individual actors, most lack capabilities required for working successfully as members of a collaborative group. This proposal addresses problems central to this challenge. It focuses on providing the foundation for the design of decision-making components of software agents that can handle multi-agent, dynamic team contexts. The proposed research comprises three activities: (1) empirical investigations, including examination of the influence on individual and group behavior and outcomes of policies and mechanisms for producing appropriately helpful behavior in collaborative settings and for governing commitment to group activities; (2) development of formal theories that may be used to address abstractly questions of these mechanisms; and (3) construction of more sophisticated<br\/>collaboration-capable software agents. The research will contribute to the development of collaboration-capable software agents and collaborative human-computer interface systems, and<br\/>thus will significantly increase the effectiveness of heterogeneous teams of people and software-systems agents.","title":"Collaborative Research: Decision-making in Collaborative Activities","awardID":"0222914","effectiveDate":"2002-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["333993"],"PO":["564456"]},"74433":{"abstract":"EIA-0218652<br\/>John Ketterson<br\/>Northwestern University<br\/><br\/>A Qubit Based on SINIS Josephson Tunnel Junction<br\/><br\/>Forming controlled super positions of quantum states lies at the heart of quantum computing and devices that perform this function have been termed \"qubits\". The device chosen here to realize a qubit is based on a double-barrier SINIS Josephson junction (where S is a superconductor, I is an insulator, and N is a normal metal). The basic strategy involves the controlled manipulation of the occupations in a 2-level system comprised of the two lowest (the ground and the first excited) Andreev bound states (ABS) that can form within an SINIS junction. In fact the parameters of the SINIS-based qubit can chosen such that only the above two ABS levels are present; this conclusion, which independently follows from the theory, is in agreement with preliminary experimental data taken on Nb\/AlOxAl\/AlOx\/Nb double-barrier junctions. <br\/> <br\/> The required control of the two Andreev states is achieved by applying appropriate bias voltages and transport currents to a device fabricated in a three-terminal geometry. The control parameters turn out to be the voltage across one of the barriers, and the transport current across one of the super conducting layers; these quantities play the role of the dynamic magnetic fields, which enter the associated qubit Hamiltonian. <br\/> <br\/> The primary goal of this proposal is to achieve the controlled manipulation of the Andreev bound states and, in parallel, advance the understanding of the underlying physical mechanisms. This will include: i) extending the present technology for preparing two-terminal SINIS devices to 3-terminal devices; ii) performing measurements on the ABS characteristics, including the observation of Rabi oscillations between the two ABS levels, iii) further developing the theory of localized ABS inside double barrier junctions to allow for arbitrary barrier transparency and arbitrary impurity concentrations in all three electrodes, iv) performing detailed numerical simulations of the switching dynamics; v) studying the recombination and decoherence effects that relate to the performance of these devices, and lastly vi) examining strategies for connecting qubits to form simple logic circuits.","title":"QuBIC: A Qubit Based on SINIS Josephson Tunnel Junctions","awardID":"0218652","effectiveDate":"2002-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["435929"],"PO":["521045"]},"75885":{"abstract":"EIA-0225656<br\/>Reddy, Raj<br\/>Carnegie Mellon University<br\/><br\/>Title: Computational Learning and Discovery in Biological Sequence, Structure and Function Mapping<br\/><br\/>Computer scientists, together with biological chemists will collaborate using statistical and computational tools and methods that the computer scientists have been developing for dealing with human language to better understand the function of proteins. Proteins are major players in the functioning of human and all other living cells. <br\/>As in languages, where sequences of letters determine patterns of words and sentences, sequences of amino acids in proteins determine protein structure, dynamics and function. Such sequences and their constituents can be thought of as syllables or words that have particular properties. Given these sequences, scientists want to be able to predict their geometrical structure and dynamics, and hence their function. A deeper understanding of the relationship between these is required so that the information hidden in the DNA sequences of genes can be used to develop drugs to fight disease. In particular, there is great societal demand to understand and treat degenerative diseases, many of which are based on defective triggers for protein shape and interactions. Work toward these goals requires deep knowledge both in computer science and in biological chemistry, and must therefore be collaborative in nature. Carnegie Mellon computer scientists will therefore be partnering with colleagues with expertise in Biological Chemistry at the University of Pittsburgh, the Massachusetts Institute of Technology (MIT), Boston University and the National Research Council of Canada. Industry collaborators include Mathworks, Inc., and medical bioinformatics company, Medstory, Inc. <br\/>Using tools like statistical language modeling, machine learning methods and high-level language processing for understanding how proteins work inside cells is a relatively new field called computational biolinguistics. At this point, the researchers have been able to detect protein fragment signatures from pathogens by application of statistical language modeling technologies to genome sequences, promising novel strategies in identifying and targeting such pathogens. <br\/>.","title":"ITR: Collaborative Research: Computational Learning and Discovery in Biological Sequence, Structure and Function Mapping","awardID":"0225636","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1688","name":"ITR LARGE GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1994","name":"BIOINFORMATICS PROGRAM"}}],"PIcoPI":[197517,"499671","305885"],"PO":["565136"]},"72145":{"abstract":"The primary goal of this research is to produce practical codes that provide<br\/>unequaled robustness, approaching the performance predicted by compound<br\/>channel information theory for linear Gaussian channels. The resulting<br\/>channel codes will find application in many scenarios including wired and<br\/>wireless broadcast, wireless local area networks, asymmetric digital<br\/>subscriber lines, military anti-jam communications, and frequency hopped<br\/>communications.<br\/><br\/>Results from compound channel information theory state that a single code<br\/>exists that supports communication over every channel that has a mutual<br\/>information above the information rate of the code. Thus, once the<br\/>transmitter power spectrum is fixed, a code need not be specialized to a<br\/>particular frequency selective channel in a single antenna system or a<br\/>particular space-time path-gain matrix in a multiple antenna system. While<br\/>this theoretical result is more that thirty years old, practical code design<br\/>has focused to date on a weaker notion of robustness, that of average<br\/>performance according to a statistical channel model, such as Rayleigh<br\/>fading. The power of the code design approach taken in this<br\/>research is that the code design is independent of statistical assumptions<br\/>about the channel. The code simply works on every channel that it possibly<br\/>could.<br\/><br\/>A second goal of this research is to develop codes that support multiple<br\/>rates to different users. Here again, information theory (this time<br\/>information theory for degraded broadcast channels) lays out the limits of<br\/>performance. Our research will closely approach these performance limits by<br\/>applying turbo codes to the concept of superposition coding for the degraded<br\/>broadcast channel.","title":"Robust Codes for Space-Time Communication, Iterative Decoding, and Multi-Rate Broadcast","awardID":"0209110","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["562262"],"PO":["348215"]},"72167":{"abstract":"ABSTRACT<br\/>Bresler, Yoram<br\/>0209203<br\/>U of Ill<br\/><br\/>Tomography, or the reconstruction of an object from a collection of its line integrals from various directions (known as its x-ray transform) is a well known problem. Perhaps most importantly, it is the principle underlying most of the key diagnostic imaging modalities including x-ray Computed Tomography (CT), PET and SPECT, certain forms of MRI, and emerging techniques such as electric impedance tomography (EIT) and optical tomography. Tomographic reconstruction is also widely used for nondestructive evaluation (NDE) in manufacturing, and has been recently proposed for safety screening of passenger luggage in airports. Tomography is also the fundamental principle in numerous other problems and applications in science and engineering from electron microscopy of subcellular structures through geophysical exploration and environmental monitoring, to remote sensing by synthetic aperture radar (SAR). In cone-beam tomography, projections are acquired by an area detector, using a source of divergent rays traveling on a one of several possible trajectories. It is already used in current PET and SPECT scanners and in NDE, and because it appears to be the only practical method for rapid volume acquisition, it will be the basis for the next generation of diagnostic CT scanners. This will allow to use CT as a dynamic imaging modality for cardiac imaging or for real-time surgical guidance in medicine, or as a high-throughput NDE system in manufacturing.","title":"Fast Algorithms for 3D Cone-Beam Tomography","awardID":"0209203","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["551068"],"PO":["564898"]},"71078":{"abstract":"As computer systems become increasingly ubiquitous, computer systems research and design has moved<br\/>from being a highly performance-centric process to being one that juggles many design goals and metrics.<br\/>Mobile and embedded computing systems must, in addition to providing sufficient performance, be rugged,<br\/>reliable, power-efficient, and lightweight. Because of the extreme and multidimensional design constraints they face, they must also be attentive to the specific needs of application domains, so they can be designed to satisfy these needs while still meeting power budgets and weight limits.<br\/><br\/>The Princeton ZebraNet Project is an inter-disciplinary effort with thrusts in both Biology and Computer<br\/>Systems. On the computer systems side, ZebraNet is studying power-aware, position-aware<br\/>computing\/communication systems. Namely, the ZebraNet project works to develop, evaluate, implement,<br\/>and test systems that integrate computing, wireless communication, and non-volatile storage along with<br\/>global positioning systems (GPS) and other sensors. On the biology side, the technology enables novel<br\/>studies of animal migrations and inter-species interactions. From a computing standpoint, key research<br\/>breakthroughs are required in protocol and system design in order to make the system power-efficient and<br\/>reliable. From a biology standpoint, the system enables fundamentally new types of biological<br\/>observations that allow us to: (i) understand long-range migrations in large mammals, (ii) observe inter-species interactions between carnivores (predators) and ungulates (prey), and (iii) track the behavior of extremely endangered species.<br\/><br\/>As a computer systems research problem, ZebraNet is compelling because the needs of the biological<br\/>researchers are stringent enough to require real breakthroughs in wireless protocols and in low-power<br\/>computer systems design and computer systems power management. These breakthroughs can be<br\/>leveraged into other (non-wildlife-oriented) fields of research; essentially ZebraNet is a power-aware<br\/>wireless ad hoc sensor network, but with more serious bandwidth and computational needs than most prior<br\/>sensor networks research problems. As a biology research problem, ZebraNet allows researchers to pose<br\/>and to answer important long-standing questions about long-range migration, inter-species interactions, and nocturnal behavior.<br\/><br\/>Major research activities span a broad range, including:<br\/> Modeling long-range animal migrations<br\/> Observing inter-species predator-prey interactions<br\/> Analyzing the impact of human development on animal behavior<br\/> Developing power-aware systems for position-aware computing<br\/> Incorporating error resilience and domain-specific performance optimizations into lightweight<br\/> wireless protocols<br\/> Managing logged sensor data to minimize the number of required uploads from tracking nodes<br\/><br\/>ZebraNet is engaging in a mix of theoretical research, prototyping, and field experimentation. The project<br\/>is not solely about systems-building, but rather mixes theory with practical hands-on evaluations of the<br\/>ZebraNet designs. Research is conducted both at Princeton University and at the Mpala Research Centre.<br\/>Mpala is a biology field station in central Kenya that Princeton University administers along with the<br\/>Kenya Wildlife Service, the National Museums of Kenya, the Mpala Wildlife Foundation, and the<br\/>Smithsonian Institution.<br\/><br\/>Overall, ZebraNet represents a truly interdisciplinary effort bringing together research strengths from<br\/>disparate fields over a challenging problem. The potential contribution of the project includes significant<br\/>advances in computing technology as well as in our understanding of wildlife migrations. The three main<br\/>researchers bring strengths in wildlife biology, power-aware computer systems, and wireless technology.<br\/>The interplay between these disciplines fosters creative to the research problems in both arenas.","title":"ITR: ZebraNet: Position-aware Power-aware Wireless Computing for Wildlife Tracking","awardID":"0205214","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["560130","495323","522280"],"PO":["561889"]},"74587":{"abstract":"The Center for Bibliographical Studies at the University of California, Riverside, is in the process of digitizing the Burney Collection of eighteenth-century English newspapers at the British Library. Access is currently possible only through a single microfilm copy in the reading room, because of the fragility of the originals. Use of even a digitized version could remain cumbersome and time-consuming because of the large size of the collection, 650,000 pages, and access limited by date and title. Heretofore the vagaries of handset type, uneven lines, broken letters, smudged or changing ink intensities and yellowing paper, it has not been possible produce an accurate, searchable text through available optical character reading software. The emergence of new technologies now enables the Center to produce a searchable text with a high degree of accuracy. A fully searchable text linked to digital images will permit extraordinary access and unlock for researchers the incredibly rich range of data the Collection contains. The result will provide a new model for accessing both periodicals and monographs of the hand-press era. It will open up whole new research strategies and topics. And it will extend the wonders of computer-based text searching to the corpus of texts that form the foundation of the modern world.","title":"ITR\/IM: Digitizing the Burney Collection of Early English Newspapers","awardID":"0219461","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[193735],"PO":["433760"]},"72057":{"abstract":"The thrust of this collaborative project is to design, analyze and implement efficient algorithms for several tiling, packing and covering problems with rectangles in two or higher dimensions with applications in diverse areas such as: VLSI, computer graphics, image processing, database design, data mining and computational biology. Since computing exact solutions for almost all of these problems is provably hard, the goal is to use diverse unifying techniques of algorithm design such as local-ratio, multi-phase methods, and slice-and-dice methods, and linear programming with nontrivial rounding and primal-dual schema. They will develop novel data structures on grids for efficient approximation algorithms for these problems.","title":"Collaborative Research: Efficient Combinatorial Algorithms for Several Tiling, Packing and Covering Problems with Rectangles and Hyper-Rectangles","awardID":"0208749","effectiveDate":"2002-09-01","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["516991"],"PO":["499399"]},"71089":{"abstract":"Although large parts of our brains are devoted to the processing of sound cues and sound plays an important role in the way we interface with the world, this rich channel has not been extensively exploited for displaying information. The mechanisms by which received sound waves are processed neurally to form objects with auditory properties in many perceptual dimensions, including three corresponding to the source location (range, azimuth, elevation) and three to qualities ascribed to the source (timbre, pitch and intensity), are beginning to be understood. There has been significant progress over the last decade in understanding the mechanisms by which acoustical cues arise and how the biological system performs transduction and neural processing to extract relevant features from sound, and in the way we perceive and organize objects in acoustical scenes. Our goal is to exploit this understanding, and uncover the scientific principles that govern the computerized rendering of artificial sound scenes containing multiple sound objects that are information and feature rich. We will test, use and extend this knowledge by creating auditory user interfaces for the visually impaired and the sighted. The work aims both at developing interfaces and answering fundamental questions such as: Is it possible to usefully map \"X\" to the auditory axes of a virtual auditory space? Here \"X\" could be an image (e.g., a face), a map, tabular data, uncertain data, or temporally varying data. Are there neural correlates that can guide natural mappings to acoustic cues? What limitations does our perception place on rendering hardware? How important is","title":"ITR\/AITS: Customizable Audio User Interfaces for the Visually Impaired and the Sighted","awardID":"0205271","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["527292","564721",184001,"531848","532931"],"PO":["565227"]},"76534":{"abstract":"Written Language Recognition has great significance not only as a convenient and natural way of interacting with computers but also as an important challenge in AI. Its importance as an input interface to computers is comparable to that of speech in terms of naturalness and convenience of use.<br\/><br\/>Notwithstanding the strong evidence from cognitive reading theories that suggests that text recognition is an interactive process that makes efficient use of resources at every stage, traditional handwriting recognition systems have employed a monotonically cascaded architecture. The primary goal of this proposed research is to develop a computational model of handwriting recognition that is grounded in cognitive reading theories. The model will account for several aspects of handwriting recognition that have not been addressed in the literature to date. The architecture of the word recognition model will allow it to actively seek information from earlier processing stages. Depending on the quality of the image and the difficulty of the lexicon, the feature extractor will send information on only a subset of possible features, allowing an internal decision-maker to evaluate the information and request more if needed.","title":"Use of Cognitive Reading Models in Handwriting Recognition","awardID":"0229280","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["548306"],"PO":["565227"]},"65776":{"abstract":"In the past decade the world has seen an explosion in Internet activity and with it has come increased expectations for its performance. Internet users now demand faster and higher-quality service for applications ranging from audio\/video-on-demand to Internet telephony. At the heart of these information exchanges is the Transmission Control Protocol (TCP) and active queue management (AQM) schemes which work together with the goal of preventing network congestion and improving end-to-end performance. However, it is becoming increasingly evident that the present form of these schemes may not be able to cope with the growing demands on the Internet. It is well documented that congestion-avoidance schemes relying on Drop-Tail routers are prone to high-loss rates while AQM routers deploying random early detection (RED) are difficult to tune.<br\/><br\/>Motivated by this situation, this proposal is concerned with the design of advanced AQM schemes. This projects approach departs from the prevailing techniques by explicitly relying on dynamic network models and feedback control principles. Central to the approach is the recognition that AQM schemes are feedback control systems and that feedback control principles provide essential tools for the analysis and design of AQM strategies. The absence of feedback control principles from the design scene so far is apparently due to a lack of an analytical model of TCP. Fortunately, this roadblock has been recently removed by one of the PIs through the introduction of a fluid-flow model that expresses TCP in a language that allows network control engineers to analyze and design AQM schemes. Indeed, in several recent papers the PIs have accomplished just that by: 1) relating key network parameters to the performance of AQM networks, 2) analyzing RED and suggesting parameter settings for stable queue management, and 3) introducing a new AQM scheme, the PI controller, that compares favorably with RED.<br\/><br\/>The proposed research builds on these recent results and has two objectives. First, to study the interaction of heterogeneous fluid-flows with AQM routers and secondly, to investigate the scalability of PI controllers. The first objective is aimed at the recently developed TCP\/AQM movel which assumes only long-lived flows and ignores short-lived flows. This research will develop models of heterogeneous flows and explore their impact on the AQM analysis and design. In the second objective the PI controller is considered which was originally designed and analyzed for a TCP connection encountering only a single bottleneck router. The scalability for the PI controller will be explored where complex network topologies, consisting of many routers each under local PI control, will be considered. Unlike the development of the original PI controller, this research will necessarily use, multivariable feedback control techniques to establish network stability, performance and robustness to network parameter variations.","title":"Scalable AQM Routers Supporting Hetergenous Traffic","awardID":"0125979","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["379421","300687","497480"],"PO":["565090"]},"75577":{"abstract":"EIA 0224012<br\/>Dietterich, Thomas G.<br\/>Herlocker, Jonathan L.<br\/>Metoyer, Ronald<br\/> Oregon State University <br\/><br\/>Title: CISE RR: Instrumentation for Experimental Research in Machine Learning, Collaborative Filtering, and Virtual Environments <br\/><br\/> This project, upgrading the current cluster for use in large pre-computations that enable effective real-time performance, supports equipment servicing the following four projects:<br\/>Real Time Animation of Human Characters for Use in Immersive Training Environments,<br\/>Probabilistic Recommendation Methods for Collaborative Filtering (CF),<br\/>Machine Learning for Spatial and Sequential Data, and<br\/>Reinforcement Learning for Learning Search Control Heuristics with Applications to Protein Structure Determination from Nuclear Magnetic Resonance Spectroscopy and to Real-Time Animation.<br\/>The first project aims at automatically selecting and ordering short sequences of captured motion to drive a character along a trajectory while maintaining naturally looking transitions between the sequences. The project exploits off-line reinforcement learning (dynamic programming) algorithms to pre-compute a policy for moving between any pair of poses under a range of trajectory constraints. Real-time control of characters is then permitted without the need for large run-time searches. The second project utilizes collaborative filtering (CF) systems that can predict a probability distribution over the rating of an item. Currently CF, a method by which multiple computer users indirectly help each other make decisions and identify solutions to problems, provides ratings or votes returning the items with the higher number of votes, rather than attaching a probability. The equipment will speed the research process by enabling the testing of un-optimized prototype implementations of new algorithms, and hence allow the evaluation of proposed algorithms without the delay of manual optimization. The third project deals with emerging applications of machine learning (e.g., computer intrusion detection, information extraction from web pages, remote sensing) involving temporal, sequential, or spatial data where nearby data points are typically correlated. The PIs have developed a parallel implementation of a sequential analysis method for conditional random fields (CRFs) that gives near-linear speedups in the computation time, but which is limited in the size of data sets that can be processed. The cluster upgrade should yield a faster solution and allow consideration of larger data sets. The last project, experiments with two new algorithms for reinforcement learning that scale to large search spaces as long as the number of reachable states is small enough to fit in main memory. One method combines linear programming with support-vector machine techniques; the other combines gradient descent search with dynamic programming. These methods, requiring an expensive off-line computation, result in an efficient heuristic that can be applied to the run-time search. Moreover, the cluster will be used by students in a parallel computation course.","title":"CISE Research Resources: Instrumentation for Experimental Research in Machine Learning, Collaborative Filtering, and Virtual Environments","awardID":"0224012","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["554550","255543","554552"],"PO":["557609"]},"73157":{"abstract":"Intellectual merit. Numbers of nonindigenous species--species introduced from elsewhere - are<br\/>increasing rapidly worldwide. They are a major cause of biodiversity loss and environmental<br\/>change, and are estimated to cost the US $137 billion\/yr. The 2001 National Invasive Species<br\/>Management Plan (www.invasivespecies.gov) highlighted the urgent need for more rigorous and<br\/>comprehensive risk analysis frameworks for nonindigenous species so that prevention and<br\/>control strategies can be targeted appropriately. The central public policy consideration is how<br\/>much of society's resources should be expended in response to nonindigenous species, and how,<br\/>for example, should it be allocated between prevention and control? These considerations,<br\/>though, include a nexus of interacting ecological and economic factors that require<br\/>interdisciplinary effort. Species invasions are caused by economic activities, and in turn affect<br\/>economic activities. This ecological and economic linkage and feedback means that the<br\/>assessment of risk interacts with the management of risk, which contradicts the common notion<br\/>that risk assessment and risk management are independent. Social welfare and risk assessment<br\/>are both determined jointly by ecological and economic processes.<br\/>In response to the need for interdisciplinary risk analysis, this project brings together<br\/>experts from invasion biology, mathematical modeling, and economics. The main goal is to<br\/>develop and apply a bio-economic modeling framework for nonindigenous species that<br\/>integrates risk assessment and risk management, includes uncertainty distributions, and<br\/>optimizes prevention and control strategies in a landscape context. The overall bio-economic<br\/>model uses Stochastic Dynamic Programming, which allows the investigators to incorporate<br\/>ecological-economic feedbacks in such a way to optimize combinations of prevention and<br\/>control strategies to maximize social welfare. This framework will be extended to the landscape<br\/>scale with Neural Network models.<br\/>The applications will focus on freshwater nonindigenous species in the Great Lakes<br\/>region. A preliminary application to zebra mussels suggested, for example, that society should<br\/>be spending about $240,000\/yr to keep zebra mussels from invading each lake with a power<br\/>plant (to prevent fouling of pipes). This is in sharp contrast to the $825,000 that the Fish &<br\/>Wildlife Service spent in FY2001 for prevention and control efforts for all aquatic nuisance<br\/>species for all lakes. Our analyses will be directly relevant to policymakers and natural resource<br\/>managers.<br\/>Broader impacts. The investigators will partner with the Shedd Aquarium in Chicago to<br\/>educate schoolchildren and the public about the general problem of nonindigenous species, about<br\/>what individuals can do to reduce the problem, and about the role that science plays in public<br\/>policy decisions. By partnering with an educational software firm, they will convert research<br\/>models into user-friendly formats for use by schoolchildren, the public, policymakers, resource<br\/>managers, and stakeholders. In partnership with the Great Lakes Commission, research methods,<br\/>results, and user-friendly products will be disseminated in workshops to policymakers, managers,<br\/>and stakeholders. Finally, they will develop international collaborations and a reciprocal<br\/>exchange of information and techniques with top researchers in Australia, where NIS research is<br\/>advanced relative to North America.","title":"IRCEB: Ecological Forecasting and Risk Analysis of Nonindigenous Species","awardID":"0213698","effectiveDate":"2002-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7731","name":"OTHER GLOBAL LEARNING & TRNING"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1128","name":"POP & COMMUNITY ECOL CLUSTER"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1174","name":"POPULATION DYNAMICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1182","name":"POP & COMMUNITY ECOL PROG"}}],"PIcoPI":["466314","494572"],"PO":["563582"]},"74488":{"abstract":"This research aims to further integrate the study of behavior in both animals and robots. The research investigates how rules of animal behavior can be analyzed, quantified, coded, and instantiated in robots. It focuses on individual and group sensorimotor behavior from a developmental perspective using Norway rats (Rattus norvegicus). Robotic rat pups will be built that instantiate sensorimotor rules discovered by careful observation and computational modeling of pups in isolation and in groups at different stages of development. Specific attention will be paid to how these rules change at different stages of development. For the study of behavior, the aim is to use robotic systems to validate rule-based computational models of behavior and generate testable predictions. For robotics, the aim is to transfer information from organisms that start out life as simple sensorimotor systems, but subsequently develop social behaviors, while developing new sensorimotor, learning, and cognitive capabilities. By studying precisely how these capabilities develop, this research will provide additional insight into the emergence of group behaviors in robotics. In the longer run, this research should facilitate the design of group robotic systems that develop greater and greater sensorimotor, learning, and cognitive capabilities over time.","title":"ITR: Research and Design of Robot Group Behavior Development","awardID":"0218927","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["380835","513156"],"PO":["564456"]},"74499":{"abstract":"This study will investigate online investing and virtual investing-related communities (VICs)looking at two broad research issues: (a) How is information generated, discussed, and diffused within and across VICs, and how do such activities impact market efficiency? and (b) How do economic, social and psychological influences together impact investor adoption, participation, and satisfaction? The study will involve processing over three million messages covering 40 stocks from 10 major VICs. The information will be parsed and categorized, and various hypotheses related to diffusion and market impacts will be tested. In-depth interviews and a large-scale survey of online investors will validate a comprehensive model of investor satisfaction. This research contributes to the information processing and diffusion, rumor propagation, impact of IT on markets, and individual\/group behavior literatures that lie at the intersection of information systems, psychology, marketing, and economics. The research results will lay the foundation for the design of software tools that can detect worrisome types of information flow in real-time. From a regulatory perspective, an understanding of social and psychological biases and distorting influences will support the design of regulatory measures that counter their negative impacts.","title":"ITR: Collaborative Research:Virtual Investing-Related Communities and Online Investing: A Study of Adoption, Usage, and Performance and Policy Implications","awardID":"0218988","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[193487,193488],"PO":["564456"]},"76457":{"abstract":"This workshop focuses on new challenges of signal processing and communications in decentralized (non-cellular) wireless networks. Of particluar interests are fundamental limitations of wireless networks, emerging signal processing and communications theory and techniques, sensor networks and applications, and recent initiatives by commercial and defense industry. The objective is to identify pressing problems in communications and signal processing in the network environment and make recommendations about important research areas. The workshop will feature keynote speakers from leading researchers followed by the panel discussions.","title":"A Workshop on Future Challenges of Signal Processing and Communications in Wireless Networks","awardID":"0228948","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["531874"],"PO":["564898"]},"78525":{"abstract":"CSTB will convene an expert committee to conduct a comprehensive assessment of wireless technology and application trends and their implications for spectrum management and policy. The committee will seek broad input and produce a report with consensus findings and recommendations. This project will be grounded in technical expertise but examine the interplay among technical, economic, and policy issues. <br\/><br\/>The committee will deliver a final report 18 months from its first meeting that would provide analysis, conclusions, and recommendations based on input gathered during the study and committee expertise and deliberations. The final report will be subject to NRC review procedures and would be prepared in sufficient quantity to ensure its distribution to the sponsors and other relevant parties in accordance with NRC policy. The report will be made available to the public without restriction. It will be posted on the World Wide Web as well as distributed in printed form. Briefings to key people in government, industry, academia and the nonprofit sector are anticipated. <br\/><br\/>The intellectual merit of the project will flow from its examination of an arena for research--wireless communications--that is poised for growth. It will characterize trends and illuminate opportunities for new R&D activity. Because the project will relate technical possibilities to economic concerns and legal\/regulatory options, it will also speak to opportunities for social science research. The broader impacts of the project will also derive from its interdisciplinary character. The project will leverage the technical insight of the committee and its analysis to improve the quality of policy analysis in the wireless arena (spectrum management and related policy), which will affect the public.s ability to benefit from wireless innovations and economic competitiveness associated with production and uses of wireless technologies.","title":"Wireless Technology Prospects and Policy","awardID":"0238131","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["298189","234699","298190","560890"],"PO":["434241"]},"77557":{"abstract":"Assembly of Space Solar Power facilities will be significantly more complex and demanding than any prior on-orbit assembly. While it is evident that human workers will not be able to construct such facilities directly, alternatives involving many robot teams and few human supervisors are not yet mature. To succeed in this enterprise, revolutionary new capabilities are needed in areas such as autonomous robotic assembly and human-robot interaction. This project will seek fundamental new insights and demonstrations of how Space Solar Power (SSP) facilities can be built using autonomous robots supervised by humans. It will have two main objectives, important to the future of Space Solar Power assembly:<br\/><br\/>Enable heterogeneous multiple robots to coordinate in the performance of complex tasks, such as assembly~<br\/><br\/>Enable flexible human-robot interaction during assembly operations to deal contingencies that cannot be anticipated.<br\/><br\/>For some of the key tasks, such as moving substructures, autonomous control is already feasible. For other aspects, such as fine manipulation to connect components, human perception and control is needed.<br\/>The PI seek to develop a general framework, which they term sliding autonomy, where any subtask, on any of the robots, can be performed either autonomously or by a tele-operator, depending on the situation. The framework will enable mixed-initiative decision making: Human users can decide to take control, if they want, and the autonomous systems can decide to hand over control, when they need help.<br\/><br\/>This project will utilize an existing robotic testbed, developed for a previous NASA program, consisting of three heterogeneous robots (a crane, a mobile manipulator. and a roving eye) that are used for autonomous assembly. It will demonstrate several basic assembly tasks, such as docking beams and stringing cables. It will quantify the advantages of sliding autonomy for this task, in terms of time spent and success ratio. A clear improvement in efficiency will demonstrate the feasibility of such assembly for Space Solar Power facilities.","title":"JIETSSP: Coordination of Robotic Teams for Space Solar Power Assembly Operations","awardID":"0233698","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"W415","name":"NASA-SSP"}}],"PIcoPI":["561623","549607","460554","539160"],"PO":["563109"]},"75379":{"abstract":"This project will develop an integrated framework for modeling, control, and guidance of robotic helicopters, which will enable these vehicles to exploit their full operating capabilities to fly fast, precise, and reliable missions in a variety of operations in urban and remote environments. Potential applications include search and rescue, surveillance, law enforcement, inspection, aerial mapping, wildlife observation, and cinematography. The integrated framework consists of three interrelated activities: (1) the development of a modeling technique for high-fidelity low-order dynamics modes, (2) the use of linear robust multiviariable control theory (H_infinity loop shaping), gain scheduling, and high-fidelity models for the design and simulation of high-bandwidth full-flight-envelope controllers, and (3) the use of optimal feedforward methods (model predictive control) for the design of guidance systems that rely on the performance and robustness of the closed-loop helicopter dynamics.A key aspect of the project will be the flight test validation and refinement of the framework on Carnegie Mellon's Yamaha R-50 and RMAX helicopters. Flight validation will include a complex mission in a known environment. The mission will consist segments of standard maneuvers (e.g. hurdle-hop, dash\/quick stop, coordinated turn, slalom, rearward flight, S-turn, etc.). The robotic helicopters will fly the missions in several different ways (e.g for aggressiveness, precision, fuel economy, etc.) according to the mission specification.","title":"Integrated Modeling, Control, and Guidance for Full-Envelope Flight of Robotic Helicopters","awardID":"0222775","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["457516","477495"],"PO":["335186"]},"70880":{"abstract":"A critical issue for process-based software development tools and methodologies is to balance the need for innovation with knowledge of past experiences and best practices. Achieving this balance is particularly important for software development, which involves the development of a highly variable product requiring continuous process adjustments. Past work has focused on either creating process frameworks at a high level of abstraction that avoids issues of variance or composing fine-grained activities with process languages. These approaches miss important opportunities to capture and reuse process knowledge as a resource for future development efforts. <br\/><br\/>The research objectives are to:<br\/><br\/>Advance the state of research in knowledge-based support for process-centered software engineering through meta-modeling tools capable of constructing a variety of organization-level methodologies that can be tailored to specific development efforts. The tools are complemented by an experience-based approach that captures development practices to continuously refine and improve the methodology to meet emerging needs of software development organizations.<br\/><br\/>Employ a mixture of empirical studies to investigate process improvisation and the impact of delivering process and product knowledge sources during the development process. This strategy will be used to both evaluate innovative system building efforts and improve the overall understanding of software development practices.","title":"Knowledge-Based Support for Process Centered Software Engineering","awardID":"0204436","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["356244"],"PO":["564388"]},"68229":{"abstract":"NSF has invested heavily in high-performance Internet infrastructure and development of<br\/>distributed applications, resulting in burgeoning demand for additional capacity and services.<br\/>We propose a project that 1) takes advantage of existing traffic measurement instrumentation,<br\/>and 2) enhances availability and utility of existing and planned distributed heterogeneous network<br\/>measurement data repositories.<br\/> In today's 'cooperative Internet anarchy', competitive providers, struggling to meet skyrocketing<br\/>needs, do not significantly invest in gathering or analyzing workload data on their networks. Rather, Internet service providers (ISPs) match rising demand by increasing network capacity as fast as possible; today's core backbone links are OC48 and will be OC192c by 2002. This 'traditional' approach of per-link excess capacity is typically based on brute force over-engineering (e.g., upgrade after you reach a certain link utilization), rather than identification or understanding of parameters describing how network capacity is actually utilized. Individual ISPs also suffer from the fact that visibility of traffic trends is usually limited to their local domain. In addition, there is as yet no instrumentation available for gathering fine-grained workload information from any link above OC12 bandwidth; few such links are instrumented to do so, and most of these are located at lightly used research sites. Larger providers have little incentive to invest in measurement instrumentation, much less to risk political damage by making any resulting data public. Exacerbating the situation is the lack of rigorous analysis tools to support wide-area Internet data collection, and the absence of baseline data against which to compare any independent results. The lack of identified parameters for characterizing and managing network growth in a cost-effective manner is a situation that shows little sign of changing without substantial shift in attention to this task.<br\/> One detrimental side effect is that myths about Internet growth and performance abound,<br\/>and plans for provisioning are often made based on locally attained data generalized to mythical<br\/>proportions. One of the most important contributions of our proposed research is to provide<br\/>the ability to base predictions of Internet traffic, performance, and growth on real data rather<br\/>than obsolete assumptions[1]. The community could make better use of its collective intellectual<br\/>resources if they could validate ideas against a larger variety of empirical data sets before<br\/>investing research and development resources in further studies.<br\/> This proposal takes advantage of and integrates existing NSF-sponsored technologies and<br\/>tools to 1) more strategically instrument the Internet to capture real data of interest to both traf-<br\/>fic engineers and Internet modelers, 2) create distributed repositories of experimentally derived<br\/>traffic trend parameters while enabling access to heterogeneous network measurements, and<br\/>3) develop meaningful and timely analysis tools and reports. The research and tools proposed<br\/>under this effort can lead to empirically-based understanding of the evolving Internet infrastructure,<br\/>yielding results that benefit all who depend on this increasingly critical global resource.<br\/>The proposed project will also assist in the development of much-needed tools for navigation,<br\/>analysis, and correlated visualization of massive network data sets. This work is critical to advancing both research and operational efforts regarding the evolving commercial Internet, and<br\/>has obvious relevance to public policy and regulatory questions concerning the organization and<br\/>administration of Internet infrastructure.","title":"Correlating Heterogeneous Measurement Data to Achieve System-Level Analysis of Internet Traffic Trends","awardID":"0137121","effectiveDate":"2002-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"4091","name":"NETWORK INFRASTRUCTURE"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T326","name":"NSA-CORRELATING HETEROGENEOUS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T207","name":"NSA-CORRELATING HETEROGENEOUS"}}],"PIcoPI":["521741","538350"],"PO":["547712"]},"70210":{"abstract":"ABSTRACT<br\/>0202179<br\/>Rida Farouki<br\/>U of Calif Berkeley<br\/><br\/>Minkowski geometric algebra is concerned with the complex sets populated by the sums and products of all pairs of complex numbers drawn from given complex Cset operands.Whereas the Minkowski sum under vector addition in R n has been thoroughly studied,from both the theoretical and computational<br\/>perspective,the Minkowski product in R 2 induced by the multiplication rule for complex numbers is a relatively unexplored oncept.<br\/>Conceptually, Minkowski geometric algebra is the natural generalization of real interval arithmetic to complex Cnumber sets.With the transition from real to complex,however,the trivial geometry of real intervals and their consequent closure under addition and multiplication is relinquished. The<br\/>two Cdimensional haracter of Minkowski geometric algebra endows it with a rich geometrical ontent,in which simple operands (e.g.,circular disks) yield subtle results described by analytic curves such as the Cartesian oval ovals of Cassini and their higher Corder generalizations,while sophisticated algorithms are required to approximate Minkowski combinations for general sets.Apart from being a basic tool to monitor the propagation of uncertainty in complex Cvariable computations,the algebra o .ers a versatile language for<br\/>two Cdimensional shape operators and the description of (direct or inverse) wavefront re .ection\/refraction problems in optics.It is also fundamental to the stability analysis of systems with uncertain parameters,in the context of the Routh CHurwitz criterion and the Kharitonov robustness theorem.","title":"Minkowski Geometric Algebra of Complex Sets: Theory, Algorithms, and Applications","awardID":"0202179","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[181687],"PO":["321058"]},"70694":{"abstract":"EIA-0203872 Daniel Menasce George Mason University A Framework for the Dynamic Composition and Reconfiguration of QoS-Aware Next Generation Software Systems<br\/><br\/>In large, dynamic, highly distributed, loosely coupled, component-based systems, it is necessary to use a framework for software system composition and dynamic reconfiguration that can support the evolution of functional and performance requirements as well environmental changes (e.g., network, hardware and software failures). The proposed method by which software systems in these environments are composed of autonomous components. All components must have several capabilities (e.g., QoS negotiation, registration, QoS monitoring, etc) that are identical to all components. What makes a component unique is the set of services it provides. QoS-based approach , proposed to distribute software system composition and reconfiguration. Our method uses resource reservation mechanisms at the component level to guarantee QoS requirements at the software system level.","title":"A Framework for the Dynamic Composition and Reconfiguration of Qos-Aware Next Generation Software Systems","awardID":"0203872","effectiveDate":"2002-09-15","expirationDate":"2004-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["374686","374687"],"PO":["301532"]},"74720":{"abstract":"Web-based services delivered on scalable cluster platforms are playing<br\/>an increasingly important role in today's society. A key aspect that<br\/>has not been sufficiently addressed is delivering scalable performance<br\/>with quality of service guarantees. It is all too common that web<br\/>services suffer from outages due to unexpected demand. In the future,<br\/>as even more computing devices (e.g., Sensor Networks) depend on<br\/>services, ensuring scalability, reliability, fault-tolerance and<br\/>quality of service will become paramount, and will allow our society<br\/>to function normally. This proposal aims at solving the critical<br\/>research necessary to achieve this vision.<br\/><br\/>This project will study the problem of resource management for<br\/>Internet services on large-scale clusters, and develop novel solutions<br\/>that address the shortcomings of traditional approaches (i.e., poor<br\/>resource utilization, high cost, and low flexibility). This work will<br\/>develop models that express how clusters share the resources, and will<br\/>devise metrics that capture the needs of Internet services. Performing<br\/>extensive simulations using workloads of real web services, a variety<br\/>of scheduling algorithms and techniques for managing resources will be<br\/>analyzed. Results from these studies will be applied in building an<br\/>actual cluster research prototype capable of delivering the desired<br\/>service guarantees.","title":"ITR: Resource Management Techniques for Internet Services on Large-Scale Clusters","awardID":"0220139","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[194103],"PO":["309350"]},"71101":{"abstract":"EIA-0205327 David E. Evans University of Virginia ITR: A Framework for Environment-Aware, Massively Distributed Computing <br\/><br\/>We propose to develop a programming language for swarms of devices that allows a programmer to express an application in terms of desired aggregate behavior rather than explicitly programming individual devices. We will produce a program synthesizer that automatically generates the appropriate device programs that will implement the aggregate behavior for a particular deployment. The program synthesizer draws from a library of primitives that can be combined to produce complex applications with known scaling and non-functional properties. In addition to analytical results, we will test our approach using simulations and using a physical swarm composed of wireless devices with sensors and actuators.","title":"ITR: A Framework for Environment-Aware Massively Distributed Computing","awardID":"0205327","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["553633","483825","257184"],"PO":["301532"]},"74621":{"abstract":"Main memory has long been the weak link in high-performance Internet-connected computer systems, sandwiched between continuing rapid increases in both network bandwidths and CPU performance. As<br\/>networks reach 10 Gb\/s and CPU clock rates shoot past 2 GHz, the memory system is under more pressure than ever to keep up. Meanwhile, increased transistor counts are enabling integration of multi-megabyte<br\/>caches and DRAM controllers directly on the processor device, with switched interconnects built from high-speed point-to-point channels carrying I\/O and memory coherence traffic between chips.<br\/><br\/>This inflection point in the configuration, level of integration, and capacity of the memory hierarchy represents an opportunity to optimize the memory system for high-bandwidth Internet networking support.<br\/>This research will (1) establish a baseline analysis to characterize the key bottlenecks of future memory hierarchies on Internet server workloads, and (2) evaluate specific system enhancements to address<br\/>these bottlenecks, leading to more efficient, higher performance Internet server systems.","title":"ITR: Network-Oriented Memory Hierarchies for Internet Servers","awardID":"0219640","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["383899"],"PO":["325495"]},"81276":{"abstract":"This project is about the study of representations and algorithms for the computational modeling of human movements. The ultimate goal is to devise a general representation of human motion structure that potentially covers a wide range of domains: from subtle lip motions during speaking and facial expressions, to complex hand and full-body gestures. Possible applications include improved visual tracking algorithms, gesture classification tasks, face and body animation tasks, and new tools for bio-medical studies. Corner-stones will be the use of large example motion databases and appropriate statistical estimation algorithms. In this proposal, we specifically focus on techniques that can acquire kinematic models from video sequences. These models and measurements will be a building block for further studies on dynamics and higher-level human activity representations and will aid motion studies for research in bio-mechanical and medical projects.","title":"Models of Human Kinematics","awardID":"0303360","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["355388"],"PO":["335186"]},"71123":{"abstract":"EIA-0205448<br\/>Joshi, Aravind<br\/>University of Pennsylvania<br\/><br\/>ITR: Mining the Bibliome -- Information Extraction from the Biomedical<br\/>Literature <br\/><br\/>The major goal is the development of qualitatively better methods for automatically extracting information from the biomedical literature, relying on recent research in high-accuracy parsing and shallow semantic analysis. The special focus will be on information relevant to drug development, in collaboration with researchers in the Knowledge Integration and Discovery<br\/>Systems group at GlaxoSmithKline. <br\/><br\/>This project will also address several database research problems, including methods for modeling complex, incomplete and changing information using semistructured data, and also ways to connect the text analysis process to an information integration environment that can deal with the wide variety of extant bioinformatic data models, formats, languages and interfaces.<br\/><br\/>The engine of recent progress in language processing research has been linguistic data: text corpora, treebanks, lexicons, test corpora for information retrieval and information extraction, and so on. Much of this data has been created by Penn researchers and published by Penn's Linguistic Data Consortium. Hence, one of our major goals is to develop and publish new linguistic resources in three categories: a large corpus of biomedical text annotated with syntactic structures `Treebank' and shallow semantic structures (proposition bank or `Propbank'; several large sets of biomedical abstracts and full-text articles annotated with entities and relations of interest to drug developers, such as enzyme inhibition by various compounds or genotype\/phenotype connections `Factbanks'; and broad-coverage lexicons and tools for the analysis of biomedical texts.","title":"ITR: Mining the Bibliome -- Information Extraction from the Biomedical Literature","awardID":"0205448","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1994","name":"BIOINFORMATICS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V242","name":"CIA-MACHINE TRANSLATION(MT)"}}],"PIcoPI":["472144","541878","511542","507484","365960"],"PO":["565136"]},"72454":{"abstract":"Mark Oskin<br\/>University of Washington<br\/>0210373<br\/><br\/>Quantum computers seem the subject of science fiction, but their tremendous<br\/>computational potential is closer than we may think. Despite significant<br\/>practical difficulties, small quantum devices of 5 to 7 bits have been built<br\/>in the laboratory. Silicon technologies promise even greater scalability.<br\/>To use these technologies effectively, and help guide quantum device<br\/>research, computer architects need to start designing and reasoning about<br\/>quantum processors now. However, two major hurdles stand in the way.<br\/>First, compactly describable rules that characterize silicon-based quantum<br\/>computing technologies are not known. Second, there does not exist an<br\/>infrastructure to design, test, and evaluate architectural alternatives.<br\/><br\/>This grant addresses both of these<br\/>items. First, we will formalize the design rules of a widely discussed<br\/>and likely quantum device technology. Second, we have already begun to<br\/>develop architectural abstractions for this technology that can be composed<br\/>together to form general-purpose quantum information processors. Third,<br\/>using these abstractions we will develop an automated computer aided<br\/>design tool that takes a description of a quantum computing architecture and<br\/>compiles it to a device library of quantum cells. Finally, we will<br\/>develop a simulator that quickly estimates the cost-performance of quantum<br\/>systems.<br\/><br\/>These research goals, once accomplished, will serve as foundational<br\/>resources for the development of quantum computer architectures. In<br\/>addition, by reasoning about architectures we can begin to find the limits<br\/>of current quantum device proposals. These limits can be turned into<br\/>research goals, items that further quantum device research needs to<br\/>overcome.","title":"NER: Computer Aided Design of Silicon-based Quantum Computers","awardID":"0210373","effectiveDate":"2002-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["555935"],"PO":["562984"]},"74643":{"abstract":"This research project explores the extent to which the proliferation of technology-enabled, international distributed teams can serve a social as well as an economic good by promoting cross-national understanding and the competence of members. Two issues of theoretical and practical significance are examined in depth, subgroup dynamics and cross-national learning processes. Understanding these processes in such teams and the impact of the use of communication technologies on them are important objectives. Moreover, the research will consider the role that each process plays in team effectiveness. Psychological processes and behavior at the team and individual levels will be examined by means of an ethnographic field study in a large, internationally distributed company. Particular attention will be given to patterns of communication, use of communication technologies, and the sharing of contextual information. The research seeks to advance science through the development of theory and evidence concerning subgroup polarization and collaboration in distributed groups, cross-national learning processes in moderately heterogeneous international groups, and the impact of these processes on team effectiveness. Envisioned advances also include recommendations <br\/>for the design of supporting collaborative technologies.","title":"ITR Collaborative Proposal: Subgroup Fault Lines in Distributed International Teams: The Impact on Cross-National Learning and Team Effectiveness","awardID":"0219754","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["455469"],"PO":["565227"]},"74401":{"abstract":"EIA-0218447<br\/>Andrew D. Ellington<br\/>University of Texas at Austin<br\/><br\/>Ribozymes as Molecular Logic Gates<br\/><br\/>Biological macromolecules have the potential to perform computations. 'DNA computers' such as those pioneered by Adleman and his co-workers have already been shown to be able to perform simple calculations. However, these computers have for the most part been based on 'hybridization logic' involving base-pairing interactions between digitally encoded strands. The emphasis on 'hybridization logic' limits the utility and applicability of nucleic acid computation because there are very few ways to read in environmental conditions or read out answers.<br\/><br\/>Nucleic acid enzymes (ribozymes) may prove to be the equivalent of the transistors or logic gates that underlie silicon computation, and could potentially increase the ultimate applicability of nucleic acid computation by interfacing directly with the environment and generating easily read answers. Ribozyme logic gates will be developed and integrated with mesoscale shape elements (known as MUFFINS) for the logical evaluation of sets of analytes in the environment.","title":"Ribozymes as Molecular Logic Gates","awardID":"0218447","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["487898","507106"],"PO":["565223"]},"74654":{"abstract":"ABSTRACT <br\/>0219809<br\/>Thomas L. Martin<br\/>Va Poly Inst. <br\/><br\/>Wearable computing has the potential to allow access to information anytime and anyplace. <br\/>Three of the major goals of wearable computing are to allow the user to go about a normal daily <br\/>routine while constantly wearing a device, to be invisible to those around the user, and to be aware of the user.s actions and location. The purpose of this research is to investigate the wearable computing uses of electronic textiles (e-textiles), a novel hardware\/software platform that has the potential to solve many of the problems in achieving these goals, and to create a design environment for e-textile-based wearable computing. <br\/>E-textiles are fabrics that have electronics and interconnections woven into them. The <br\/>electronics consist of general-purpose microprocessors, digital signal processors, sensors, and <br\/>actuators at regular intervals throughout the fabric. E-textiles allow the creation of systems with a <br\/>physical flexibility and size that cannot be achieved with currently available electronic <br\/>manufacturing techniques. Components and interconnections are a part of the fabric and thus are <br\/>much less visible and, more importantly, not susceptible to becoming tangled together or snagged <br\/>by the surroundings. Consequently, e-textiles can be worn in everyday situations where currently <br\/>available wearable computers would hinder the user. E-textiles also have greater flexibility in <br\/>adapting to changes in the computational and sensing requirements of an application for the <br\/>purpose of managing power consumption and context awareness. The number and location of <br\/>sensor and processing elements can be dynamically tailored to the current needs of the user and <br\/>application, rather than being fixed at design time.","title":"ITR: Tailor-Made: Design of e-Textile Architectures for Wearable Computing","awardID":"0219809","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["485861","553340"],"PO":["561889"]},"74665":{"abstract":"This project investigates two problems associated with the monitoring of human activities: The first problem is tracking of articulated motion as a whole without identifying individual limb motion. The goal is to address certain shortcomings in previous solutions to this problem, the main shortcoming being their over-constrained nature. The proposed solution, which is presented as a real-time human tracking<br\/>system, will be capable of working under many difficult circumstances. The second problem is recognition of<br\/>articulated motion. The goal here is to show that the recovery of three-dimensional properties of the object or even two-dimensional tracking of the object parts are not necessary steps that must precede action recognition. The proposed approach uses motion features only. Unlike other similar approaches, the motion<br\/>features will be used in such a way to represent complex and long actions as well as to distinguish different actions with many similarities. Each action is represented as a manifold in the lower dimension space and matching is done by comparing these manifolds. As part of a homeland security scenario, its is planned to use these methods to monitor outdoor human activities based on the ability to recognize, for example, that a human runs in the opposite direction that a crowd moves.","title":"ITR: Monitoring Human Activities","awardID":"0219863","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["442887","557449"],"PO":["564456"]},"72124":{"abstract":"Lee, Insup<br\/>CCR-0209024<br\/><br\/>Many embedded systems are part of safety-critical applications, e.g.,<br\/>avionics systems, manufacturing, automotive controllers, and medical<br\/>devices. The safety-critical nature of embedded applications requires a higher<br\/>level of robustness and reliability than is called for in conventional<br\/>software systems development. In the attempt to insure a higher level of<br\/>confidence in the design and implementation, current practice merely<br\/>increases the duration, frequency, scope, etc. of traditional<br\/>verification practices. The net result is substantially higher<br\/>development costs and longer design cycles, leading to a design cycle<br\/>where a verification bottleneck is impacting overall operational<br\/>effectiveness, efficiency and safety. <br\/><br\/>This project seeks to mitigate the verification bottleneck by identifying<br\/>appropriate specification formalisms, and using those formalisms as a<br\/>basis to develop fully automated techniques for verifying<br\/>implementations using testing. An important distinguishing <br\/>characteristic of the embedded applications listed earlier is the <br\/>hybrid (discrete and continuous)nature of behaviors. The continuous <br\/>components of embedded systems, and the large state<br\/>spaces of all industrially relevant systems, make verification<br\/>techniques based on exhaustive exploration of the state space<br\/>intractable. Therefore, it is necessary to approach the verification<br\/>problem with techniques based on sampling, i.e., testing. This requires <br\/>abstracting the original system state space to<br\/>create a condensed state space that can be explored to determine<br\/>valuable points to sample. Methods of abstraction, methods for<br\/>selecting test points, and methods for evaluating the relative merit<br\/>of one set of test points vs. another are all issues addressed by this<br\/>work. The research also explores the use of traditional<br\/>notions of test coverage applied to formal specifications of hybrid<br\/>systems. Test suites are generated using the counterexample or<br\/>witness generation techniques of model checkers as well as random path<br\/>generations.<br\/><br\/>The practical issues of demonstrating the working techniques, and the<br\/>efficacy of these techniques when applied to realistic systems, are<br\/>addressed through the implementation of tools that automate all<br\/>steps of the process: abstraction, test selection, test derivation,<br\/>test application to concrete implementations, and the evaluation of<br\/>test results. Tools are developed on top of the existing<br\/>CHARON framework for creating hybrid system models.<br\/>Case-study work based on real system specifications and<br\/>benefit from interaction with practicing engineers working for Honeywell, a<br\/>leader in the development of advanced avionics systems. One issue is how<br\/>to integrate the techniques into development processes that conform <br\/>to the DO-178B avionics certification process.<br\/>Among the broader impacts that are anticipated from this work are (1)<br\/>an increase in awareness of and actual use of formal methods by<br\/>practicing developers, and (2) an acceleration of the safety-critical<br\/>embedded system development process that will enable the creation of<br\/>safer, more reliable systems with shorter development cycle times.","title":"Testing Based on Hybrid System Models","awardID":"0209024","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["553656","553657"],"PO":["561889"]},"74302":{"abstract":"Miniaturized sensors and actuators, also referred to as Microelectromechanical Systems (MEMS), play a critical role in information technology revolution. For example, the development of wireless internet, complex systems on a chip for aerospace, medical, health and various other industries is enabled by the MEMS technology. Over the past decade, advances in microfabrication technologies have enabled breakthrough developments in miniaturized sensors, actuators, devices and systems (collectively called MEMS). Some of the most recent innovative applications include accelerometers in navigational-grade guidance systems, rate gyroscopes in<br\/>antilock-braking systems, and chemical sensors in complex biomedical instrumentation. MEMS based sensors are more attractive as they are often less expensive and perform better than traditional devices and they can more easily be integrated with control electronics to enable the concept of systems-on-a-chip. The lack of efficient and accurate computational prototyping tools has thus far been a significant barrier to the development of MEMS, because most existing electronic and mechanical computational prototyping tools do not have the ability to analyze<br\/>microscopic phenomena adequately. As a result, MEMS manufacturers have been forced to develop and test prototypes, both of which have been time-consuming and very expensive.<br\/><br\/>In this proposal we focus on a particular class of MEMS - referred to as microelectrofluidicmechanical systems (MEFMS). MEFMS are miniaturized sensors, actuators, devices and systems, where mechanical, electrical and fluidic energy domains play a central role. Many electrofluidicmechanical devices have been designed and fabricated - e.g. pressure sensors, accelerometers, gyroscopes, digital micro mirrors, microphones and other devices. While fabrication approaches for these devices are mature enough, investigation of design alternatives<br\/>for many of these devices is currently limited because of the lack of computational design tools. While computational research primarily addresses engineering analysis, in this proposal we focus on computational research for design and analysis of microelectrofluidicmechanical systems.<br\/><br\/>We expect this work to break new grounds in the areas of software tools with advanced computational methods for MEMS. Graduate students will be trained on the MEMS technology, advanced computational methods and design methodologies for MEMS. We anticipate that the design of miniaturized systems based on MEMS will progress rapidly with the availability of efficient, accurate and robust computational prototyping tools. Aggressive designers, who are currently handicapped because of the limited computational analysis tools for MEMS, will be able to challenge their design skills when computational prototyping tools for MEMS are in place.","title":"ITR: Computational Prototyping of Micro-Electro-Fluidic-Mechanical Systems","awardID":"0217986","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["539633"],"PO":["565272"]},"75402":{"abstract":"Graph drawing and information visualization tools are essential in many fields, including telecommunications,databases, and software engineering, where the models contain millions of objects and relationships. Even though graph drawing is a rich discipline, the promising new concepts and algorithms in the field have had too little practical impact in application areas. <br\/>This project presents an integrated research and education plan focusing on graph drawing and information visualization techniques for large data sets and graph processes. <br\/>The research component of this work focuses on the design and implementation of efficient data structures and algorithms for visualization of large graphs with the goal of impacting real-world problems in application areas. This problem is especially relevant because recent technological advances have brought about increased data volumes and increased data complexity. The theoretical aspects of this work include designing scalable force-directed methods, hierarchical graph decompositions, alternative visual representations for graph processes, external memory algorithms, and data structures that support efficient navigation operations. <br\/>The theoretical results will be used to develop practical tools that will be packaged in a software library and an Adaptive GrAph Visualization Environment, AGAVE, that uses the new graph modeling standard GraphML. Through industrial collaborations, the new methods will be calibrated and tested using real-world data.<br\/>Alternatives graph representation methods and techniques for visuazalizing dynamic graph processes will also be investigated. The educational component of this proposal includes: (1) Creation and management of the already funded new Graphics and Visualization Lab; (2) Design and implementation of educational tools for visualization of large graphs and graph processes; (3) Supervision of graduate and undergraduate students; (4) Active involvement in outreach and integrative activities.","title":"VISUALIZATION: Visualization of Giga-Graphs and Graph Processes","awardID":"0222920","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[196112,"485534","451114"],"PO":["565272"]},"72047":{"abstract":"This project will develop techniques for trusted systems that can provide correct information and take correct actions when needed and where needed. The focus will be on peer-to-peer (P2P) systems, where computers or nodes operate autonomously, without any central control. In a P2P system, each node provides storage and compute resources. It connects to other neighbor nodes, and the community provides services like file sharing, document archiving, or data analysis.<br\/><br\/>P2P systems are especially well suited as the \"backbone\" of a trusted system because nodes operate independently, without reliance on particular network connections or on nodes with a fixed functionality. Thus, a P2P system can adapt to a changing environment, and with the proper mechanisms, can isolate or ignore malicious nodes.<br\/><br\/>As part of the project, several important problems will be addressed such as: <br\/><br\/>Denial of Service (DoS): How does one protect against malicious sites that generate excess load to prevent others from receiving resources or service?<br\/><br\/>Searching: How does one efficiently find information without using centralized index facilities, and in a dynamically changing environment?<br\/><br\/>Information Authenticity: How does one verify the authenticity of documents or information?<br\/><br\/>Preservation: How does one preserve information past the lifetime of the originating node?<br\/><br\/>The proposed research is high risk, but there is also the potential for a large payoff. The research is high risk because the problems faced are difficult: Building a trusted community out of building blocks that may be transient and malicious, is not an easy task. However, the only way to build a trusted system is, as proposed, by making as few assumptions as possible about the trustworthiness of its components. The techniques to be developed, if successful, will provide a solid foundation for building truly reliable, secure, and trusted systems for electronic commerce, military applications, healthcare, and many other applications.","title":"Trusted Peer-To-Peer Systems","awardID":"0208683","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["447448"],"PO":["521752"]},"72058":{"abstract":"This project investigates the role of information encoding techniques for reducing energy consumed by various processor components including the fetch mechanism, on-chip instruction and data caches, functional units, instruction issue logic, and CPU I\/O pins. To address energy consumption by all of the above processor components, three distinct types of encodings will be investigated in this project. Data encoding will be used to reduce the activity in data caches where the data resides and external data bus I\/O pins over which data is transmitted. Instruction encodings in form of 32 bit ARM ISA and 16 bit Thumb ISA available in the XScale processor will be used to generate compact code which gives high performance. Finally, compiler or profiler generated hints will be encoded into the generated code to throttle the energy consumption of a processor.","title":"Information Encoding for Energy Efficient Processor Design","awardID":"0208756","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["549718"],"PO":["325495"]},"74357":{"abstract":"Functional logic (FL) programming languages provide several<br\/>advantages over declarative languages based on either functions or<br\/>predicates only. A narrowing engine is an essential component of<br\/>FL languages. Narrowing engines available to date are all<br\/>prototypical and almost universally incomplete. The goal of this<br\/>research is the design and development of a general, efficient and<br\/>complete narrowing engine for FL languages.<br\/><br\/>This research will define both internal and external<br\/>representations of executable FL programs---the latter in XML.<br\/>This approach will decouple the frontends of different compilers<br\/>and interpreters of FL languages from the narrowing engine. This<br\/>separation will enable frontends for different languages to use<br\/>the same backend. By contrast to other contemporary research<br\/>efforts, the proposed narrowing engine will map narrowing<br\/>computations to computations in an imperative language. The<br\/>internal representation of the executable code will be a<br\/>thin-layer bytecode over the mapping of narrowing computations to<br\/>computations in an imperative language. This approach promises a<br\/>good efficiency without sacrificing tasks, such as tracing,<br\/>debugging and profiling, that are more easily implemented in an<br\/>interpreter. An integral part of the implementation will be a<br\/>run-time environment for using the narrowing engine in the backend<br\/>of a compiler\/interpreter of FL languages.","title":"ITR: Implementation of Functional Logic Languages","awardID":"0218224","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["549403"],"PO":["564388"]},"74599":{"abstract":"The growing popularity of mobile devices with wireless capabilities<br\/>imposes new and fundamental challenges in extending the capabilities<br\/>of wired Internet applications to the wireless domain. This project will<br\/>investigate proxy-based techniques for enabling the next generation of<br\/>mobile multimedia and web applications. The proposed research will focus on<br\/>three characteristics of mobile environments, namely client mobility,<br\/>intermittent connectivity, and resource-poor nature of mobile devices. <br\/>Research issues that will be addressed in this project include<br\/>(i) power-friendly streaming techniques and real-time handoffs for<br\/>mobile multimedia applications, and (ii) caching and dissemination of<br\/>time-varying and location-dependent data accessed by mobile web<br\/>applications. The proposed techniques will be evaluated using an<br\/>eclectic mix of simulation, analysis and prototype implementation. The<br\/>significance of the proposed research arises from the widespread and<br\/>growing use of mobile devices that provide ubiquitous, wireless access<br\/>to data on the Internet. The likely impact of this research will be<br\/>to advance the state of the art in proxy-based infrastructures for<br\/>next-generation mobile multimedia and web applications.","title":"ITR: System Support for Mobile Multimedia and Web Applications","awardID":"0219520","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["558563"],"PO":["309350"]},"72069":{"abstract":"This project will use subjectivity analysis to improve the accuracy of information extraction (IE) systems. IE systems are designed to extract facts, but they are prone to false hits from subjective statements such as accusations, allegations, suspicions, and opinions. The first phase of the research will create a subjectivity classifier that uses learning algorithms to identify linguistic features associated with subjective language. The classifier will use several natural language representations, including extraction patterns, N-grams, and noun phrases. The classifier will be embedded in a bootstrapping architecture so that it can learn from unannotated corpora, requiring only a small amount of annotated data to jumpstart the bootstrapping. In the second phase, the classifier will be integrated into an IE system to measure the impact of subjectivity classification on IE performance. Information extracted from objective sentences will be treated as facts, but information extracted from subjective sentences will be labeled as uncertain or discarded. This research will produce a better understanding of how subjective language is expressed and the role that context plays in recognizing subjectivity. The potential impact of the research is to produce more accurate subjectivity classifiers and to demonstrate that subjectivity analysis can improve the performance of IE systems.","title":"Collaborative: Improving Subjectivity Analysis to Achieve High-Precision Information Extraction","awardID":"0208798","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["409250"],"PO":["565227"]},"77789":{"abstract":"The research places dependability analysis in a formal, software engineering process. This process is integrated with the analysis phase, when analysts and domain experts are interacting to<br\/>formalize models of the artifact, environment and requirements of the system. The research focuses on building accurate, useful, robust models of the environment. The general approach is to look to existing modeling methodologies that center on exploring the environment. Those that show promise, e.g., the strand space methodology used in security models, will be retooled and integrated into the HDCP\/MDS testbed.<br\/><br\/>The research also focuses on the environmental assumptions that are made during modeling as a basis for dependability of the deployed system. The research explores the link between assumptions made at analysis time, i.e., the assumptions made about the environment for the system to function correctly, and the actual environment behavior seen at run time (or testing\/simulation time).<br\/><br\/>The evaluation of the research will be conducted on a series of projects taken from the HDCP\/MDS testbed. Each project will be selected to highlight a separate modeling issue of the environment.","title":"Building and Monitoring Models of the Environment","awardID":"0234571","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}}],"PIcoPI":["449118"],"PO":["564388"]},"67427":{"abstract":"Modern operating systems are large and complex code bases in which<br\/>hundreds of programmer-years have been invested. As a result,<br\/>modifying an operating system is a difficult, costly, and often<br\/>impractical endeavor. However, viewing the OS as an immutable object<br\/>is at odds with most OS research.<br\/><br\/>This research proposes techniques that enable the deployment of OS<br\/>ideas without changing OS source code. The thesis is that an OS-like<br\/>service can acquire information about the internal state of the OS and<br\/>control its behavior, even when no explicit interfaces to do so are<br\/>provided. With this approach, the OS is treated as a gray box, in<br\/>which the general characteristics of its algorithms are known; this<br\/>knowledge is then combined with run-time observations of how the OS reacts<br\/>to probes in order to infer its state and exert control.<br\/><br\/>Initial experience with gray-box systems points to additional areas of<br\/>research: automated discovery of algorithms, on-line benchmarking to<br\/>configure parameters, dynamic insertion of probes, and aggressive<br\/>inference of OS internal state. Thus, the goal of this proposal is<br\/>two-fold: to understand the theoretical foundations of gray-box<br\/>systems and to implement a toolbox of software for the rapid<br\/>development of gray-box systems.","title":"CAREER:Exploiting Gray-Box Techniques in Systems","awardID":"0133456","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["550390"],"PO":["561889"]},"68219":{"abstract":"EIA-0137098<br\/>Bennett, Beth Anne V<br\/>Yale University<br\/><br\/>Title: ADVANCE Fellow: Local Rectangular Refinement Solution-Adaptive Gridding Method<br\/><br\/> This proposal, extending previous work, pursues two lines of research. <br\/>1 Expansion of the Local Rectangular Refinement (LRR) adaptive gridding to 3D and <br\/>2 Numerical Modeling of Solidification of Aluminum Alloy. The former, an adaptive grid method for simultaneous, fully implicit solution of coupled systems of nonlinear partial differential equations arises from the modeling of complex 2-dimensional (2D) physical systems, such as those encountered in fluid flow, heat transfer, and combustion applications. The LRR method will be expanded to 3D, making it a viable tool for simulating real-world 3D systems, including solidification and combustion processes. The completed adaptive code on 3D thermofluids applications will be tested, quantifying its accuracy and efficiency by comparison with a structured-grid code. The latter, a new application for the LRR method, involves collaboration with WU, an expert in nucleation theory. His work will be embedded within the existing LRR-2D code and later with the 3D code. Because microscopic material properties such as strength and hardness depend strongly upon microscopic quantities (e.g., grain size distribution), the ultimate goal is a numerical model which will predict the grain size distribution in an aluminum alloy part of simple 3D geometry, under various processing conditions.","title":"ADVANCE Fellows Award","awardID":"0137098","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1681","name":"ADVANCE - FELLOWS"}}],"PIcoPI":["494305"],"PO":["564181"]},"73940":{"abstract":"0216467<br\/>Moshe Y. Vardi<br\/>Don H. Johnson; Ken W. Kennedy; John M. Mellor-Crummey; Willy Zwaenepoel<br\/>MRI: Acquisition of CITI Terascale Cluster \\(CTC\\)<br\/><br\/>This proposal, requiring access to the kinds of experimental computational resources needed for scalability experiments, aims to support scalability to thousands of processors. Achieving this goal requires experimentation of computational facilities of sufficient size to establish that solutions will scale to large systems. A high-performance computational cluster with a peak performance of approximately one teraflop, supporting both compute- and data-intensive science and engineering, will enable researchers to make fundamental advances in diverse areas such as biochemistry, biology, chemistry, computational mathematics, computer science and engineering, earth science, economics, physics, political science, and psychology. Experiments planned include:<br\/>a. Scalability of compiler techniques for systems with hundreds of processors and deep memory and communication hierarchies;<br\/>b. Development, simulation, and testing of scalable Web services on hundreds of processors;<br\/>c. Simulations of ad hoc multihop wireless networks scaling to thousands of nodes;<br\/>d. Scalable algorithms for Monte-Carlo studies of the physics of heavy ion collisions;<br\/>e. Design and evaluation of scalable optimization algorithms based on component frameworks;<br\/>f. Extraction and analysis of data on hundreds of millions of international events, to better predict and understand international conflicts (extend the Kansas Data System); and<br\/>g. Scalability tests and practical application of new algorithms for modeling and simulation of biomolecular interactions using several thousand flexibility parameters.<br\/><br\/>By integrating the equipment in the existing curriculum the educational impact is expected to be large, going beyond a course in parallel programming. Several programs are already in place addressing diversity.","title":"MRI: Acquisition of CITI Terascale Cluster (CTC)","awardID":"0216467","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["24590","142498",191820,"565263","517356"],"PO":["557609"]},"70695":{"abstract":"Proposal Number 0203876<br\/>Title: \"Smart Event Models and Architectures\"<br\/>Gail E. Kaiser, Columbia University<br\/><br\/><br\/>This project investigates wide-area publish\/subscribe event system models and architectures. The focus is on two new models called Smart Events and Active Events, and an event bus architecture called Virtual Private Event Networks (VPENs).<br\/><br\/>Smart events are associated with a structural type model (a grammar or schema), and a semantic model that defines the processing to be performed on the structural subcomponents. Smart events are routed via content-based messaging, where subscriptions may specify complex patterns indicating the events of interest. Active events include their semantic model directly as mobile code. Active events operate as<br\/>mobile agents transported (conceptually) under their own power point-to-point. Smart events may optionally include active event substructures, enabling content-based messaging to be applied to this subset of active events.<br\/><br\/>VPENs extend multi-protocol label switching (MPLS) protocols and mechanisms to the application layer, to improve the performance of content-based routing by preplanning label switched paths when publisher advertisements as well as consumer subscriptions are available. VPENs also add encryption-based security and privacy in the style of virtual private networks (VPNs).","title":"Smart Event Models and Architectures","awardID":"0203876","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["541922"],"PO":["564388"]},"74710":{"abstract":"This project, which is a collaborative effort between the University of<br\/>California at Riverside and Los Angeles, focuses on processor and<br\/>system architecture issues for Web Switches. Web switches are network<br\/>processing elements that modify network traffic based on content.<br\/>These devices are frequently used to provide load balancing between<br\/>functionally equivalent servers as well as cryptographic services; in<br\/>in the future will be used for a host of new applications including<br\/>active security and multimedia trans-coding. This project will begin<br\/>by developing a benchmarking framework that can be used to evaluate<br\/>the performance of Web switches. The research will then use advanced<br\/>processor simulation tools to study architectural tradeoffs in the<br\/>face of the benchmark workload. In particular, the researchers will<br\/>focus on the efficacy of hardware accelerator blocks that have been<br\/>proposed. Finally, work will be completed to implement the workload<br\/>and capitalize on acquired knowledge in the context of an existing<br\/>test bed for network processors.","title":"ITR: Collaborative Research: Processor Architectures for Web Switches","awardID":"0220096","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["516924"],"PO":["325495"]},"74721":{"abstract":"Automatic Analysis of Spontaneous Facial Expressions<br\/>Abstract<br\/>The goal of this project is to develop computer systems for automatic analysis of spontaneous facial expressions, with a focus on the scientific study of the role of facial expressions in deception. A state-of-the-art digital video database of spontaneous facial expressions will be developed. This database will be hand-coded by behavioral scientist experts on facial expressions. This database will be used to develop an array of software tools for automatic analysis of facial expressions from video sequences. These tools will be developed by machine perception scientists in close collaboration with behavioral scientists and will be evaluated and refined for application to the scientific study of facial expressions.<br\/><br\/>The machine perception community is in critical need for standard video databases to train and evaluate systems for automatic recognition of facial expressions. This project will provide one such database and thus could potentially accelerate research in this field. Automated recognition systems would have a tremendous impact on basic research by making facial expression measurement more accessible as a behavioral measure, providing data on the dynamics of facial behavior at resolutions that was previously unavailable. Such systems would also lay the foundations for computers that can understand this critical aspect of human communication.","title":"Collaborative Research: ITR: Automatic Analysis of Spontaneous Facial Expressions","awardID":"0220141","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["560905","463668","523911"],"PO":["565215"]},"74611":{"abstract":"A technique has been identified that will enable ultra high-density electronic packaging connectivity: chip to package; package to socket; and board to board (connector). Named \"AC coupled interconnect\", this approach has the potential to enable a massive increase in the functional density of connections across all layers of electronic packaging and permit pin counts to continue scaling. This technique will allow microprocessor chips to have thousands of pins, instead of the hundreds enabled today. It will allow connectors and sockets to also support thousands of pins. This will lead to faster computers, networking systems, etc.<br\/><br\/>The central thesis is this effort hinges on the recognition that the DC component of a digital signal carries no information, and that non-contacting AC connections can be built a lot denser and simpler than DC connections. An array of non-contacting structures is inherently denser, more compliant and more mechanically robust than an array of contacting structures. By imposing direct contacts only where DC current transfers are needed, this approach will allow very high density interconnects to be realized and alleviate the compliance and rework problems encountered in other high density interconnect technologies. The AC connections can be inductive, capacitive, or a combination of the two.","title":"ITR: Ultra High Density Computer Interconnect","awardID":"0219567","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["475429"],"PO":["564898"]},"71113":{"abstract":"ABSTRACT<br\/>0205422<br\/>Harrold, Mary J<br\/>GA Tech Res Corp - GIT<br\/><br\/>TITLE: Collaborative Research: ITR: Acquiring Accurate Dynamic Field Data Using Lightweight Instrumentation<br\/><br\/>Dynamic analyses, such as testing and profiling, play a key role in state-of-art approaches to software quality assurance (QA). With rare exception, these analyses are performed in-house, on developer<br\/>platforms, using developer-provided input workloads. Shortcomings of this approach include that the results simply cannot be trusted to tell us how the software actually performs in the field.<br\/><br\/>The project goal is to give developers unprecedented insight into the actual runtime behavior of their software, allowing developers (and ultimately the software itself) to change, optimize, and adapt the software based on highly accurate field data. Lightweight, collaborative dynamic analyses conducted around-the-world and around-the-clock form the new platform: (1) lightly instrument fielded software (i.e., each program copy performs a small part of the analysis) (2) collect the partial data from many instances of the software, fusing it to conduct the complete analysis, (3) change the running program instances based on the findings and (4) repeat the process.<br\/><br\/>Seven critical research challenges form the core of the project: <br\/>1. Lightweight instrumentation--Develop instrumentation that is virtually transparent to individual users. 2. Compositional analysis techniques--Develop distributed analysis techniques that decompose<br\/>traditional analyses into smaller steps, distribute the steps among multiple users, and then fuse each user's results into an accurate solution to the original problem. 3. Scalability--Develop storage and analysis techniques to deal with the high data volumes we expect to encounter. 4. Anomaly Detection--Define data-driven techniques to automatically identify anomalous behaviors of deployed software. 5. Privacy and Security--Incorporate privacy and security safeguards into our data collection and analysis approaches. <br\/>6. Dynamic updating mechanisms--Develop techniques to make runtime changes to the location and function of instrumentation, and to parts of the software itself. 7. Validate approach on industrial software.","title":"Collaborative Research: ITR: Acquiring Accurate Dynamic Field Data Using Lightweight Instrumentation","awardID":"0205422","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["400310","530729","550876","550999"],"PO":["564388"]},"80188":{"abstract":"Stochastic programs involve time, probability and concurrency. The classical research into reasoning about probabilistic models of concurrency provides methods to establish when two processes can be considered the same and be inter-substituted for each other. Such equivalences are too exact since they are usually not robust under even slight perturbation of probabilities. This is particularly unfortunate since practice dictates that probability numbers are to be viewed as numbers with some error estimate. The focus of this proposal is approximations and approximate reasoning for stochastic concurrent systems. The PI proposes to use metric based frameworks to formalize approximation schemes and develop compositional reasoning methods to study robust notions of ''approximately inter-substitutable'' programs. <br\/><br\/>The first intended application is the exploration of ''secure substitution'' in mobile code applications, where programs (such as tax software) are downloaded as needed, executed on a trusted host (the home computer), require access to sensitive local data (such as financial information) and yet should not be permitted to leak information. Probabilistic modeling is used in such applications to quantify the amount of information flow between systems. A permissible secure substitution of one component for another in a program context has to preserve such information flow properties in addition to the usual observations. The goal of this project is to define a robust notion of secure substitution, and develop compositional proof rules and algorithms to determine if a component can be securely substituted for another.<br\/><br\/>The second intended application is the design and implementation of StochCC, an executable specification language for stochastic hybrid systems. This research will build on the PI's prior work into HybridCC, a declarative language for specifying and simulating hybrid systems. Users of HybridCC(in biological systems modeling) have already found it useful to add limited forms of discrete probabilistic specification to HybridCC. StochCC will perform a full and general integration of probabilities into HybridCC. In order to come to computational grips with such systems, one needs a notion of discrete approximation. Such discrete approximants play a role in both simulation (executing the system within some error bound) and approximate reasoning (calculating the observations of the system within some error bound).","title":"Approximate Reasoning in Stochastic Concurrency: Applications to Secure Substitution and Stochastic Hybrid Systems","awardID":"0244901","effectiveDate":"2002-09-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["409674"],"PO":["564388"]},"74501":{"abstract":"This project explores new ways of searching, organizing, preserving, and interacting with large information resources in the humanities and the social sciences. It involves the creation and support of a digital library of materials of significant international importance drawn from the Franklin D. Roosevelt Library and Digital Archives (which includes image, sound, video and textual data), and the encoding, annotation, and multi-modal linkage of a portion of the collection to develop state-of-the-art methods for search and retrieval. The goal is to establish methods and procedures that can be later applied to the full FDR collection, and to consider the best means to enable flexible and creative access to this important resource. <br\/><br\/>The project involves, on the one hand, computer scientists with significant experience in the representation of and access to on-line data, together with historians who require sophisticated and intelligent access to on-line historical resources. Because we will apply techniques from several technical fields to data that is typical of the humanities, the project represents an important cross-disciplinary effort. Another benefit is the collaboration between two undergraduate liberal arts institutions, Marist College and Vassar College, and the potential to involve students from both institutions in cutting edge research.","title":"ITR\/RUI: Accessing FDR's America : Enhanced Search and Retrieval","awardID":"0218997","effectiveDate":"2002-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["501442",193494],"PO":["433760"]},"74754":{"abstract":"Recently there has been considerable interest in the design of power\/energy-aware electronics seeking to reduce the power consumption of military and consumer applications by over two orders of magnitude. This interest is driven by the power demands of today's high-speed, high-density, (portable) integrated electronics. Unless new power-efficient design methods are developed, there will be stringent limitations on the levels of electronics integration possible in the future as well as limitations on the speeds at which hardware can operate. Hardware portability will also be affected by battery size and weight. Simple calculations reveal that future microprocessors will dissipate several hundred watts of power unless drastic power reduction features are implemented. High power consumption and the associated high temperatures can also lead to reliability problems leading to early failure. If the trends in reduction of feature sizes and the increase in the levels of integration in silicon are to continue well into the future, the power consumption problem must be handled effectively and solved urgently.<br\/><br\/>This research involves the study of hardware-software co-optimization methods to achieve ultra low power\/energy consumption over a range of applications. Such co-optimization has been difficult in the past due to the complexity of the optimization problem and the fact that the optimization parameters stretch across software, hardware and technology parameters. While factors of energy savings up to 5X are possible using software, hardware and technology optimization individually, much larger savings are possible if a vertically integrated power optimization approach across software, hardware and technology boundaries is undertaken. To handle the complexity problem of such a vertically integrated power\/energy minimization approach, a very simple optimization metric is proposed. This metric seeks to allocate delay to software and hardware modules in such a way that the delay of the module is proportional to the energy consumed by the module. Using such a metric, the problem of technology optimization (Vdd, Vt, device sizing) can be decoupled from that of system-level optimization without compromising the quality of the solution obtained. As long as the above metric is satisfied, software\/hardware and technology optimizations can be done independently with high confidence that the resulting solution will be close to the optimum. Note that the proposed metric relies on the knowledge of the energy consumption of each module relative to other modules than on the absolute values of energy consumption of each module. The energy consumed by a hardware or software module relative to that of other modules is computed easily using simulation. It is conjectured that the use of the proposed power metric will simplify the complexity of the optimization problem to a degree that will allow much bigger, vertical optimizations to be performed across the software, hardware and technology boundaries.","title":"ITR: Software-Hardware-Technology Co-Optimization for Ultra Low Power Architectures Via Delay Considerations","awardID":"0220259","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["550643"],"PO":["562984"]},"71124":{"abstract":"Computer networks have become more pervasive in scope and mission-critical to businesses, scientific endeavors and other computing applications. But at the same time, network instability and unreliability has become an increasing problem.<br\/><br\/>This research tackles this issue by laying the groundwork for a new system infrastructure and an associated generation of algorithms capable of overcoming the unreliable nature of the network using probabilistic techniques for ensuring consistent cooperative behavior, coordination, and coherency. The central property of the infrastructure is that it uses probabilistic techniques (instead of absolute guarantees) but, by so doing, obtains outstanding stability under stress, scalability, and robustness to even extreme disruptions. <br\/><br\/>This research will proceed in steps, starting with a quantitative study of existing distributed system architectures, especially focusing on (1) gossip-style data dissemination, (2) anonymous communication, and (3) peer-to-peer networks. The next step will explore the design of new and enhanced architectures for large-scale distributed analysis systems. It is the ultimate goal to implement new designs in ways compatible with prevailing platforms (Windows, Java, Unix), and release public-domain versions of these experimental solutions, and to measure their behavior on a large scale.","title":"ITR: Massively Convergent Distributed Computing","awardID":"0205452","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["495285","345714","448955","483774","289708"],"PO":["309350"]},"70167":{"abstract":"0202048<br\/>Wise, David S.<br\/>Indiana University - Bloomington<br\/> <br\/>RI: A Research Infrastructure for Collaborative, High-Performance Grid Applications<br\/><br\/>This project, developing an experimental infrastructure for distributed high performance computing, supports ten research projects extending the location-transparency that the Grid provides for computation resources to the full spectrum of activities which end-users require. Services being explored include software development, parallel code middleware, distributed software components for scientific computing, security for parallel remote method invocation, <br\/>managing large-scale data streams, and collaboration methodologies. The research builds on and extends the institutions collaborations with several national Grid research teams. In contrast to existing national and university infrastructure available through production machines, this research requires an environment tolerant of experimental network protocols, temporary middleware, and other system-level changes. The infrastructure will contribute to the following research projects:<br\/>a. Opie: basic work on parallel matrix algorithms that achieve high efficiency across many architectural platforms<br\/>b. LAM: middleware MPI implementations supporting hierarchical and fault-tolerant parallel computing<br\/>c. dQUOB: application of SQL queries to live data streams<br\/>d. RMI Security: basic research into security mechanisms for remote method invocation, allowing security to be traded off with efficiency<br\/>e. HPJ: High Performance Java creating a language platform for portable high performance coding<br\/>f. Grid Broker: reliable, robust publish\/subscribe service for introducing fault tolerance into the distributed Grid environment<br\/>g. Community Grids Collaboratory: advanced collaboration capabilities with applications to both distance education and distributed communities<br\/>h. Xports: design of methodologies for remote instrument access and data management of the resulting extremely large data sets<br\/>i. Software Components: distributed software component model designed for applications that use parallel computing \"nodes\" in wide-area Grid environments<br\/>j. Science Portals: set of tools that allow programmers to build Grid distributed applications accessed and controlled from desktop environments and web browsers<br\/>Major improvements to infrastructure supporting all these projects include a 16-node cycle server and a large-scale file server as well as network upgrades to and within the building.","title":"CISE Research Infrastructure: A Research Infrastructure for Collaborative, High-Performance Grid Applications","awardID":"0202048","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["538992","562709","283428","565242","430172"],"PO":["550859"]},"75612":{"abstract":"EIA-0224368<br\/>Edward B. Allen<br\/>David A. Dampier; Thomas Philip<br\/>Mississippi State University<br\/><br\/>CISE RR: Resources for Software Engineering Research<br\/><br\/>This proposal from an EPSCoR state, enhancing capabilities for software-engineering research, aims at acquiring a data base server, a configuration management system, and workstations to support the following projects:<br\/><br\/>1. CAREER: Assessment of Open-Source Software for High-Performance Computing,<br\/>2. Using Pathfinder Networks to Model Perceptions of Software Requirements,<br\/>3. Automating Steps in Software Evolution, and<br\/>4. Integrated Information Sifting for Scientific Instruments.<br\/><br\/>The first project ascertains the quality of the software using retrospective case studies by building and evaluating models that could have developed during the historical projects or releases. The second provides methods for uncovering divergent perceptions of software requirements by stakeholders and developers, thus giving an early indication of potential requirements issues in light of conceptual differences among groups. The third, creating automated techniques for semantics-based slicing and change-merging that will facilitate the reliable delivery of small increments, devises automated methods for incorporating incremental changes into software systems as they evolve. The last project, producing of imagery, develops an integrated set of algorithms and tools for analysis of scientific-instrument data to support on-line monitoring and process control. The information sifting approach includes artificial neural networks for classification of spectral images, statistical methods for rapid comparison of spectra, rule-based models of thermal imaging, and fuzzy classification using autonomous agents.","title":"CISE Research Resources: Resources for Software Engineering Research","awardID":"0224368","effectiveDate":"2002-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["528454","557830","558000"],"PO":["557609"]},"74655":{"abstract":"The large number and diversity of quality of service (QoS) measures present a significant challenge to the design and operation of multimedia wireless communications systems. Each information source (data, audio, video) has its own metrics of signal quality and the network has an aggregate measure of capacity for each source (for example, Erlangs of telephone traffic and data throughput). In addition to signal quality and network capacity, the battery life of a portable terminal has a major effect on the value of mobile information services to consumers. Existing knowledge of quality optimization is generally confined to studies of individual sources. In the 1990s, a significant body of knowledge was created on radio resource management for cellular telephone communications. More recently, the research community has turned its attention to wireless data and video. Each study focuses on one or two quality measures for one type of information: for example, power and distortion for video; power and throughput for data. <br\/><br\/>This project takes a more comprehensive view by considering the collection of QoS measures to be a point in a multidimensional space. Given a system design and a set of operating conditions, the achievable points constitute a feasibility volume, with optimum points on the surface. Within this formulation, we study simultaneous transmission of data and video by analyzing projections of the volume onto various combinations of QoS dimensions including: <br\/>video distortion;<br\/>data throughput for each source;<br\/>data utility for each source;<br\/>total power dissipation (signal processing power and transmission power) in a terminal;<br\/>number of simultaneous video transmissions at a base station;<br\/>aggregate base station throughput;<br\/>aggregate base station utility.<br\/><br\/>The emphasis is on power efficient communications and the results provide guidance on joint adaptation of the following properties of terminals that transmit signals to the same base station: transmission power and rate in data terminals and transmission power, compression, and channel coding in video terminals.","title":"ITR: Power Efficient Multimedia Wireless Communications","awardID":"0219822","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["258464","491898","559524"],"PO":["348215"]},"72114":{"abstract":"Growing pressure to collect information on the Internet has created a need for more sophisticated ways to characterize privacy rights and balance them against legitimate commercial and law enforcement objectives. A wide range of businesses now rely on their ability to collect information about online customers as a foundation of their added value in the market place. The use or potential use of<br\/>the Internet for purposes such as child pornography and planning of hate crimes and terrorism have heighted interest in (and loosened regulations on) network monitoring. Theft of intellectual property has led to the development of numerous protection mechanisms; these often involve registrations and involuntary monitoring of various kinds. In order to make security easier (and explore a lucrative business model), a number of companies seek to act as third-party caretakers of private information such as keys, authentication secrets, and credit card numbers. Arrayed against these trends are many citizens incensed by aggressive means used to collect information from them and a variety of groups<br\/>that champion privacy rights.<br\/><br\/>There have been many advances in technologies both to aid information gathering and limit it. One important trend is toward more advanced systems for creating and managing digital credentials and authorization databases. In current practice credentials are sometimes `pushed' (like presenting a ticket to get into a movie theater) sometimes `pulled' (like getting access to an airplane seat with<br\/>a `paperless' ticket) and sometimes both (like making a purchase at a store with a credit card whose validity is confirmed online). These approaches have Internet-based analogs, and technical advances have increased the range of options considerably in recent years. For example, work on public key systems<br\/>has advanced techniques for delegation based on chains of `pushed' credentials and increased the automation of credential collection. Another important trend is toward more advanced systems for protecting privacy using anonymizing techniques. Tools such as onion routers and anonymous web publication servers provide some support but other techniques directly aid fine-grained mechanisms<br\/>for obtaining privileges without exposing information unnecessarily. <br\/><br\/>This work aims to develop formal support for characterizing privacy in the context of these advances. Efforts to improve access control systems and credential distribution have paid little attention to privacy mechanisms so far, resulting in systems that are good at propagating credentials reliably, but not<br\/>tuned to do so within well-understood privacy constraints. This collaboration will build on our work in credential distribution and anonymity to create an integrated architecture and protocols to provide advanced access control within the limitations of privacy constraints.","title":"Collaborative Research: Formal Privacy","awardID":"0208983","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["233258"],"PO":["521752"]},"71146":{"abstract":"Taha, Walid<br\/>CCR-0205542<br\/>\"ITR: A Framework for Rapid Development of Reliable Robotics Software\"<br\/><br\/>Robots are entering daily life. Commercially available systems are<br\/>delivering medication to patients in hospitals, mowing lawns, vacuuming<br\/>floors, and finding wide applications in the entertainment industry. In the future, they will play a more substantial role in areas such as space exploration, health care, and search and rescue. But as<br\/>these applications grow, so does the complexity of these robots, making<br\/>the reliability of their software and the productivity of their<br\/>programmers a priority. It is not clear that current techniques for<br\/>programming robots are sufficient for building systems that are orders of magnitude more complex than the ones available today. The vast majority of programming methods in current use focus on high-level planning and task and behavioral aspects. By contrast, there are no widely-accepted specialized software processes or programming languages for the integrated development of robotics applications.<br\/><br\/>This project explores the impact of state-of-the-art programming languages techniques in a small-scale robotics setting. The project applies domain-specific languages methods and automatic program generation techniques. The framework exploits core technologies such as multi-stage programming with simple, high-level annotations<br\/>to avoid unnecessary runtime overheads yet provide a natural and algorithmic approach to program generation, where generation occurs in a first stage, and the execution of the synthesized program occurs in a second stage. Because (even when the final goal is embedded software) the first stage does not need to be resource-bounded, conventional programming techniques can be used. <br\/><br\/>The challenge, then, becomes ensuring that the generated programs are suitable for execution on an embedded platform. Multi-stage languages already provide significant safety guarantees. For example, a program generator written in such a language not only is type-safe in the traditional sense, but we are guaranteed that any generated program will also be type safe. This provides a noteworthy degree of assurance about the quality of the generated code. But like most traditional high-level programming techniques, multi-stage programming was designed to satisfy functional requirements rather than operational ones, and existing multi-stage languages do not provide any guarantees about the behavior of programs in the presence of bounded resources. The focus of this project is ways to address this problem by strengthening<br\/>``traditional'' multi-stage type systems using a number of state-of-the-art techniques from type theory and functional reactive programming (FRP) to create resource-aware multi-stage programming. Linear and alias types (in conjunction with dependent typing) will be used to ensure space-boundedness, new typing techniques are used to ensure time-boundedness, and signals and behaviors from FRP allow for a natural style of reactive programming.","title":"ITR: A Framework for Rapid Development of Reliable Robotics Software","awardID":"0205542","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["541946","186518","497125","495365"],"PO":["561889"]},"75623":{"abstract":"EIA-0224424<br\/>Paul R. Woodward<br\/>David H. Du; Ernest F. Retzel; Jon B. Weissman; Ted J. Wetherbee<br\/>University of Minnesota-Twin Cities<br\/><br\/>CISE RR: Collaborative Data Analysis and Visualization<br\/><br\/>This project, creating a high-speed network that will enable coupling a large number of PCs and Macintoshes to tackle computationally-intensive problems during idle times, enhances the collaboration between the University of Minnesota Laboratory for Computational Science and Engineering (LCSE), Center for Computational Genomics and Bioinformatics (CCGB), Academic Distributed Computing Services (ADCS), the computer science research group, and Fon du Lac Tribal and Community College. The facility will be used as a platform to perform off-line batch jobs related to visualization and data mining. Augmenting network, storage, and graphics rendering capacity for a pre-existing student lab, the project will link together approximately 100 workstations at UMN via a Gigabit Ethernet network to service an interdisciplinary group or researchers. UMN collaborating teams, with on exception, will move the new Digital Technology Center (DTC) into a common location at the heart of the campus. This common location creates a special opportunity to exploit the workstations as a powerful data analysis and visualization engine for the genomics and scientific visualization applications of CCGB and the LCSE. The use of workstations during the time of low student utilization is expected to provide five-to ten-fold increases in data storage capacity and bandwidth, data mining processing power, and image rendering power. The collaboration with computer scientists, on distributed computing techniques and networked storage technology, plays a vital role in realizing the benefits. The project, involving two students from Fond du Lac Tribal College, provides platforms for research in cluster network design, cost-effective commodity-based storage area network design and operation, distributed computing, and distributed visualization. A fully connected Gigabit Ethernet network will be built by the collaborating team. This network-switching fabric will interconnect the machines of the ADCS lab and the machine and network attached storage of the CCGB and LCSE. A gigabit Ethernet link to UMN OC-12 Internet-2 connection will enable large amounts of data to be brought into the combined environment (e.g., NSF TeraGrid). The project leverages resources and expertise to create a combined capacity for data analysis and visualization far greater than existed in any one of the participating labs before the collaboration.","title":"CISE Research Resources: Collaborative Research Resources: Collaborative Data Analysis and Visualization","awardID":"0224424","effectiveDate":"2002-09-15","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["543507","382574","455559","335810","543508"],"PO":["557609"]},"74666":{"abstract":"Abstract:<br\/>0219870<br\/>PI: Morris Chang<br\/>Iowa State<br\/><br\/>The thesis of this project is very simple: the performance of garbage collection is critical to the successful deployment of distributed Java embedded systems. Applications for such systems have different operating requirements than applications written for desktop or server environments. They include frequent software update, low power consumption, low resource availability, distributed computing capability, and real-time operating constraints. Therefore, garbage collectors for such devices must be designed to support those requirements. <br\/><br\/>Garbage Collection (GC), or automatic dynamic memory management, is one of the many attractive features available in Java. It allows programmer to be more productive and software to be more robust. On the other hand, it is also notorious for being intrusive and consuming large amount of power due to frequent memory accesses. As a result, the garbage collection can severely degrade the performance and affect the viability of Java embedded devices.","title":"A Low-power High-efficient Garbage Collector for Embedded Java Systems","awardID":"0219870","effectiveDate":"2002-09-15","expirationDate":"2008-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["209728"],"PO":["561889"]},"72125":{"abstract":"Embedded systems require maximum performance from a processor within<br\/>significant constraints in power consumption and chip cost. Using<br\/>software pipelining, high-performance digital signal processors can<br\/>often exploit considerable instruction-level parallelism (ILP), and<br\/>thus significantly improve performance. However, software pipelining<br\/>sometimes fails to utilize the processor efficiently and may hinder<br\/>the goals of low power consumption and chip cost.<br\/><br\/>The problems with software pipelining can be ameliorated by using<br\/>advanced compiler loop transformation techniques. However, current<br\/>methods for applying loop transformations are lacking. Metrics for<br\/>applying loop transformations do not model high-performance digital<br\/>signal processing (DSP) architectures and the effects of software<br\/>pipelining effectively. <br\/><br\/>This research will address the above problems by developing<br\/>and experimentally validating the following:<br\/><br\/>1) A performance metric that accurately models software-pipelined<br\/>loop performance on high-performance DSP architectures. <br\/><br\/>2) A prediction of the register pressure of a software-pipelined<br\/>loop before high-level loop transformations are applied.<br\/><br\/>As a result of this research, more ILP will be exploited in DSP<br\/>applications, resulting in an increase in performance and a savings in<br\/>the overall energy required to execute an application. Improvements in<br\/>performance and energy usage will allow better and more<br\/>computationally expensive algorithms to be used in embedded systems.","title":"High-Level Optimization for DSP Architectures","awardID":"0209036","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["530278"],"PO":["565272"]},"71047":{"abstract":"EIA-0205116<br\/>Fred Roberts<br\/>Rutgers University<br\/><br\/>ITR: Special Focus on Computer Science and Epidemiology<br\/><br\/>Mathematical methods have become important tools in analyzing the spread and control of infectious and also noninfectious diseases. The size of modern epidemiological problems and the large data sets that arise call out for the use of powerful computational tools in conjunction with the mathematical analysis. This project believes that partnerships between computer scientists and epidemiologists can make important new contributions to the usefulness of these mathematical methods.<br\/><br\/>Research efforts in the project will be carried out by interdisciplinary, international working groups which will investigate issues in computer science and related mathematics that need to be resolved to make progress on important problems in epidemiology and will explore and apply methods of computer science and related mathematics not widely used in epidemiology. Topics to be studied by these groups include: Adverse Event\/Disease Reporting, Surveillance, and Analysis; Data Mining and Epidemiology; Analogies Between Computer Viruses and Immune Systems and Biological Viruses and Immune Systems; Distributed Computing, Social Networks, and Disease Spread Processes; Phylogenetic Trees and Rapidly Evolving Diseases, Spatio-Temporal and Network Modeling of Diseases; and Methodologies for Comparing Vaccination Strategies. <br\/><br\/>Other important goals will be to involve more computer scientists in epidemiological research; develop and strengthen collaborations and partnerships between mathematical scientists and biological scientists; introduce young investigators from both the computer science and biological science communities to the issues, problems and challenges of epidemiology; and involve biological and computer scientists together to define the agenda and develop the tools of computational epidemiology.","title":"ITR: Special Focus on Computer Science and Epidemiology","awardID":"0205116","effectiveDate":"2002-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H228","name":"CIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["264120"],"PO":["565136"]},"75403":{"abstract":"The proposed project addresses the development of a NEtwork ofAutonomous Robots (NEAR) with sensors and wireless network cardswith the goal of developing a distributed implementation of arobotic assistant. The key applications of NEARinclude: (a) transportation and retrieval of objects in asemi-structured environment; (b) organization and reconfiguration ofsensors for observations in dynamically changing environments; and (c) coordinated motion of multiple vehicles for cooperative manipulationor for efficient group locomotion. The NEAR robot network isalways \"near\" the human user, interacting with the user, andaugmenting her skills, providing a natural synergism.Our focus in this project is to leverage advances in automation andaugmentation and steer them in the direction of autonomy for servicerobotics. We will develop a network of simple mobile robots serving ahuman being. Each robot has some basic sensing capability (vision inour case) and the ability to communicate with other mobilerobots. Robots can be programmed to exhibit simple behaviors:controllers and estimators and policies that couplessensing\/perception at a very low level. The ability to use multiplerobots enables autonomy without increasing the complexity ofindividual robot behaviors but by instead exploiting the distributedexecution of these behaviors in a network. Since the human isexplicitly involved in programming and commanding the robots, it ispossible to exploit this natural synergy by allowing humans toinfluence the assembly of the behaviors and the organization of theteam in a top-down fashion.","title":"NEAR: NEtwork of Autonomous Robots","awardID":"0222927","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["553286","554983"],"PO":["335186"]},"75766":{"abstract":"The workshop titled ``Radical Innovations of software and systems<br\/>engineering of the future'' to be held October 7-11, 2002 at<br\/>Universita' Ca'Foscari di Venezia in Venice, Italy, will bring<br\/>together leading researchers in all aspects of Software and System<br\/>Engineering with a view towards discussing potential research topics of<br\/>tomorrow. To accomplish this goal, the workshop will have several<br\/>talks and several open discussions, with the hope that the latter<br\/>would lead to cross-fertilization of ideas from several disparate<br\/>sub-areas of Software and Systems Engineering.","title":"Workshop: Radical Innovations of Software and Systems Engineering in the Future","awardID":"0224970","effectiveDate":"2002-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["78952"],"PO":["561889"]},"72026":{"abstract":"Many results in computational learning are witnessed by self-referential classes. For example, one can show that restricting learning machines to output always conjectures consistent with their data lessens learning power | as witnessed by such a class. Various kinds of algorithmic transformations of witnessing classes (which can eliminate the self-reference) preserves some learn ability results and destroys others. It is proposed to investigate this phenomenon more thoroughly for greater insight into learning. Machine learning, which is concerned with practical\/empirical techniques, seeks robust learners, and, in some cases, provides consistent learners. The PI and collaborators recently showed that, if one considers a formal robustness requiring that all algorithmic transformations of learnable classes must be uniformly learnable as well, then all such resultantly difficult learning that's possible can be done by consistent machines. It is proposed to show this result does not extend to the not-necessarily-uniformly case (or that it does) with the hope of thereby gaining insight for machine learning. It is proposed to extend prior work of the PI and others to provide a theory of learning to coordinate goal-oriented tasks. U-shaped learning involves learning, unlearning, and re-learning. U-shaped learning occurs in many domains of human cognitive development (including language, understanding of temperature, understanding of weight conservation, the interaction between understanding of object tracking and object permanence,<br\/>and face recognition). In the context of algorithmically learning grammars for (formal) languages from any stream of complete positive data about those languages, it has been shown by the PI and collaborators that, for some classes of learnable languages L, any machine M which learns L must exhibit, on some L in L, U-shaped learning. It is proposed to strengthen and extend this result and to characterize insightfully such classes L and with an eye to informing the cognitive scientist. Lastly, it is proposed to combine the use of type-2 feasible functional and feasible counting down from notations for constructive ordinals to obtain general concepts of feasible iterative learning. In general, the separate items proposed above are highly interconnected and mutually reinforcing toward obtaining important and unifying insights for complexity theory, machine learning, and cognitive science.","title":"Self-Reference, Complexity, and Learning","awardID":"0208616","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"W385","name":"DARPA-GENOMIC SIGNAL PROC & ST"}}],"PIcoPI":[186515],"PO":["499399"]},"71179":{"abstract":"Deformable objects are ubiquitous in the physical world at all scales, from the molecular to the astrophysical. Many of life's basic functions, from protein folding and ligand binding at the micro level, to meiosis and mitosis at the cellular level, to the beating of a heart at the macro level, are best described as shape deformations in time. Flexible materials are finding increasing applications in engineering, across areas such as testing and manufacturing, and especially in biomedical applications, including prosthetic devices and minimally invasive imaging and surgical procedures. Special effects in the entertainment industry and haptics-based human-computer interfaces also require better models for flexible objects. Though deformation in nature can be based on a variety of underlying physical processes, we believe that there are a number of unifying principles common to understanding all deformations. Today, however, we lack a general computational theory of how to sense, represent, simulate, approximate, actuate, control, and render deformable objects.<br\/><br\/>Research Goals and Methods<br\/>The goal of this proposal is to undertake a foundational study of representations and algorithms for the computational modeling of deformable objects. Such modeling is challenging because deformations involve representations of shape and motion, and bring together continuous and discrete phenomena, as well as local and global constraints. Some of the specific challenges that have to be addressed are:<br\/>1. the behavior of deformable objects is defined by both geometry and physics and characterized by complex high-dimensional energy landscapes that need to be compactly encoded and efficiently interrogated for actuation, control, and planning;<br\/>2. physically accurate simulation of deformations is of-ten computationally expensive; we must find ways to approximate the full physics, while still guaranteeing the correctness, or at least appropriateness, of the solution that we compute in the parts of the system we care about;<br\/>3. discrete events, such as collisions and self-collisions, alter the continuous evolution law of the system; these events must be efficiently predicted or detected, and processed;<br\/>4. contact and self-contact must be modeled across rapid changes in the contact manifold, including its dimensionality (e.g., cloth draping over a rigid object);<br\/>5. deformations are often associated with changes in the shape topology (e.g., the surgeon's scalpel cutting the patient's skin tissue); such topology modifications must be smoothly accommodated in our models.<br\/>Towards this goal we have put together a team of PIs and consultants\/advisors that combines expertise in scientific computing and physical simulation, geometric modeling and computation, motion planning and control, local and distributed sensing and actuation, model parameter estimation, as well as extensive experience in the computational modeling of specific deformable objects, from molecules to textiles, and in applications from medicine to entertainment","title":"ITR: Representations and Algorithms for Deformable Objects","awardID":"0205671","effectiveDate":"2002-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["521232","264577","522465",184355,"557516"],"PO":["565272"]},"74446":{"abstract":"This proposal presents a visual approach to the representation and validation of document structures specified in XML and transformation of one structure to another, in a general framework of automatic language generation. The underlying theory of this visual approach is a context-sensitive graph grammar formalism. The proposal demonstrates the conciseness and expressiveness of the graph grammar formalism and its suitability to visual specification and automatic generation of visual XML languages. <br\/><br\/>The PI's previous research on the graph grammar formalism and visual language generation will be extended and adapted to suit automatic generation of visual XML design languages with tools that assist the design of XML-like of documents and their translations between each other. A set of tools will be developed to facilitate the visual specification of XML-like document structures and automatic generation of target documents. The tools would therefore enable a wide community to use the latest computing and Internet technology in storing and exchanging digital documents. The tools and the concepts associated with them will also make excellent teaching and self-training vehicles for the courses on programming languages, compilers, and visual interfaces.","title":"Visual Specification and Automatic Transformation of Web Interchanging Documents","awardID":"0218738","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["287416"],"PO":["563727"]},"74699":{"abstract":"ITR: Information Representation for Cooperation Across Networks<br\/><br\/>We define cooperation among the nodes of a network to include any activity <br\/>where the action of a single individual relies on information from other <br\/>individuals in a shared environment. Using this broad definition, <br\/>information aggregation in sensor networks, group activities performed by <br\/>autonomous robotic devices, internet exploration and modeling, and <br\/>establishment of ad hoc networks are all examples of tasks involving <br\/>cooperation among the nodes of a network. An essential feature common to <br\/>cooperative tasks is the need to share information across a distributed <br\/>system. Thus cooperation requires the flow of information. In environments <br\/>limited by constraints on power, bandwidth, time, or memory, efficient <br\/>information flow requires efficient data representation. We are currently <br\/>studying strategies for efficient information representation in network <br\/>systems. When we speak of information representation for a network, <br\/>we consider the network as a whole, asking questions about where information <br\/>resides in the network, where it is needed, and how to most efficiently <br\/>represent the information to make it accessible where it is needed. <br\/>Current topics of investigation include network data compression, functional <br\/>source coding for networks, and joint source-channel coding for networks.","title":"ITR: Information Representation for Cooperation Across Networks","awardID":"0220039","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["551140"],"PO":["348215"]},"72158":{"abstract":"Bonnie Heck<br\/>CCR-0209179<br\/>\"Integrated System-Theorectic and Software-Enabled Strategies for Embedded Smart Sensors in Hybrid Systems\"<br\/><br\/>This research addresses the efficient design and effective operation of \"smart\" sensor suites, which are to be embedded in complex hybrid systems with multiple modes of operation and multiple mission \/ fault scenarios. An integrated approach is being pursued in which system-theoretic analysis is combined with real-time embedded software design techniques that focus on composition and dynamic reconfiguration issues. This integrative approach supports the design of the sensor suite, including its management software, which is capable of fusing information from heterogeneous sensors to develop estimates for physical parameters and detect \/ diagnose faults, and of dynamically reconfiguring itself in the face of identified fault scenarios or mode changes. <br\/>The research addresses system-theoretic issues and software-design issues on a concurrent basis so that the requirements and capabilities of the two sides can be understood and taken into account. Hence, issues such as synchronizing data from multiple distributed sources and managing transitions while reconfiguring continuous components, are being formalized and explicitly accounted for throughout the design, beginning with the sensor selection \/ placement decision to the development of algorithms for sensor fusion and dynamic reconfiguration. This work is drawing upon existing results in the hybrid systems literature and developing some additional theories and tools as necessary. The topics studied in this research include:<br\/>o Sensor placement in a distributed hybrid system: What types of sensors should be placed where so that important changes, both continuous and discrete, can be observed with required accuracies.<br\/>o Sensor fusion: How the signals generated from a heterogeneous sensor array will be combined to generate useful information, such as physical states, parameter values, and fault status, under different modes of operation.<br\/>o Dynamic reconfiguration: How to reconfigure on the fly the processing and fusing of signals from different sensors, in the face of an identified fault or a mode change, and how the information will be transitioned from one mode to another.<br\/><br\/>The research is creating system-theoretic and software modeling tools for constructing smart sensor suites that can adapt to changes and faults that occur in a complex hybrid system. The research is also expected to improve the fundamental understanding into the observability property of hybrid systems and the design and analysis of a state estimator for such a system. The theoretical \/ methodological development is being validated on sensor suites for real applications (e.g., a three tank process demonstrator) so that no important real issues are overlooked.<br\/><br\/>On the educational front, cross-disciplinary course(s) and research programs are being developed that breed a unique set of students versed in both systems-control theories and real-time software design.","title":"Integrated System-Theoretic and Software-Enabled Strategies for Embedded Smart Sensors in Hybrid Systems","awardID":"0209179","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":[186858,"554411","393313","520215"],"PO":["561889"]},"72169":{"abstract":"In modern computer systems, computation is distributed over many host machines. Mutually untrusted machines and users coexist, and software is built using plug-and-play components downloaded from remote hosts. Multiple users share resources so it is critical to ensure, e.g., that private information is not compromised. Languages like Java and C# are designed to provide such security by enforcing encapsulation boundaries that restrict interdependencies and information flows between program components. Such boundaries are undercut, however, by ubiquitous pointer aliasing which can be maliciously exploited to leak sensitive information.<br\/><br\/>This project studies ways to confine pointers to their intended scopes. The focus is on the interplay between static analysis and dynamic access control to achieve confinement. The technical goal is to find confinement regimes that can be used to assure secure information flow in systems implemented using dynamic binding, multithreading, inheritance, class-based encapsulation, and access control. Analyses and transformations to minimize run-time performance costs for confinement and access control are also investigated. This work will lead to better programming methods and tools for development of web-based services and other distributed applications that require a high level of assurance. The work will contribute to technology for implementing programming languages and for checking for security flaws in application programs.","title":"Collaborative Research: Integrating Pointer Confinement and Access Control for Encapsulation","awardID":"0209205","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["564588"],"PO":["521752"]},"78626":{"abstract":"CSTB would convene an expert committee to conduct a comprehensive assessment of telecommunications research and development. The study would develop a picture of telecommunications research in the United States, including areas that are and are not being emphasized, the interplay between telecommunications and neighboring fields such as computer science and electrical engineering, and the relationships between pre-competitive research and standards-setting efforts. The study would examine changes in the level of support, research focus, and research time horizon at the major U.S. industrial labs as well as more broadly across the industry, including startups. The study would also examine telecommunications research within universities, considering how much is done, where, and under what conditions. It would assess the implications of these changes for the U.S. telecommunications industry--recognizing that that industry itself is changing and considering possible future trajectories for the industry--and compare the U.S. research model to research initiatives being undertaken in other countries (especially Europe and Japan) and bythe European Union. Looking across industry and academia, it would consider future research directions, the interplay between telecommunications and computer science, and assess whether new institutional arrangements or programs are needed. <br\/> <br\/>The project would culminate in a consensus report recommending ways to strengthen the U.S. research base, sustain education and training of future telecommunications researchers, and enhance the competitiveness of the U.S. telecommunications sector. The report would be distributed to key decision-makers in government, industry, academia; as well as congressional staff and the general public. The report would be made available on the Web as well as in hard copy. The completed report would be briefed to interested parties in government, industry, and academia. <br\/> <br\/>The intellectual merit of the project and its broader impacts both would flow from its focusing attention on an area of critical national (and international) importance. Historically, telecommunications R&D has been the province of private industry(with comparatively little effort in academia), notably the former Ma Bell and other companies that were leaders in different telecommunications segments--actors that have suffered with recent economic conditions. Intellectually, the project would explore and characterize telecommunications as a field and a focus for different kinds of research. It will address what it would take to grow a more significant academic research capability. In addition to stimulating research, boosting academic interest and activity, the project will have broader impacts by helping to sustain and enhance an arena that is important to national security, economic competitiveness, and the larger base of information technology capability and use of which telecommunications is a vital part. The technical opportunities it will discuss will be linked to benefits among the public and large and specific segments as users of different kinds of telecommunications capabilities.","title":"Telecommunications Research and Development","awardID":"0238609","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["298189","234699","298190","560890","560890"],"PO":["7594"]},"70871":{"abstract":"Software systems evolve over time in order to adapt to changes in<br\/>environment. Graceful software evolution requires that only expected<br\/>changes in functionality occur; while desirable, this is difficult to<br\/>achieve. Software tools are needed to automate the evolution of<br\/>complex software systems containing heterogeneous components, by<br\/>reporting change impact information to programmers, allowing<br\/>examination of the effects of code edits. Tool support for change<br\/>impact analysis has a clear potential to boost programmer productivity<br\/>and enable safe code enhancement.<br\/><br\/>This research in change impact analysis assumes that an<br\/>object-oriented system is developed with a suite of tests, run as the<br\/>system is updated to check the safety of changes. Analyses can<br\/>determine which tests are affected and which changes affect each of<br\/>these tests. Since these tests often exercise independent<br\/>functionalities, the tests affected correspond to those<br\/>functionalities that may have been altered. This research will develop<br\/>an interactive tool for change impact analysis of Java, as part of a<br\/>industrial-strength programming environment to ensure practicality.<br\/>The tool will allow experimentation with the granularity of changes<br\/>and program representations, incrementalization of the analyses,<br\/>collection of a Java benchmark suite, and application to collaborative<br\/>software development.","title":"Change Impact Analysis of Object-oriented Software","awardID":"0204410","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[183447,"438877"],"PO":["564388"]},"73820":{"abstract":"EIA-0216131<br\/>Christoph Hoffmann<br\/>James Bottum; Davis S. Ebert; Ananth Grama; Ahmed H. Sameh<br\/>Purdue University<br\/><br\/>MRI: Acquisition of Equipment for Purdue Envision Center for Data Perceptualization<br\/><br\/>This proposal, developing techniques to effectively utilize the information capacity available to human comprehension, aims at acquiring the visualization, sensing, and haptics infrastructure required for a new center. The center, connected to ultra high-speed network hubs, cable broadcast and high performance computing facilities, and on-campus technology incubators, will support applications' needs by a spectrum of research graphics, visualization, and systems infrastructure, as well as provide development, technology transfer, education, and outreach. The infrastructure includes 3D and next generation ultra-high resolution displays, and sensing and haptic devices. The project addresses the challenges posed by the devices with respect to perceptualization techniques, infrastructure for supporting data and processing rates for effective use, and integration of applications into the environment. Educational and outreach efforts include a comprehensive graphics curriculum built around the facility, minority recruitment, and retention efforts, national visualization fore, series of symposia and workshops, development of online educational material, public domain software, and use of Access grid as a vehicle for dissemination and collaboration. Moreover, the I-Light high-speed optical fibre infrastructure (10Gb\/sec) will be connected with the facility.","title":"MRI: Acquisition of Equipment for Purdue Envision Center for Data Perceptualization","awardID":"0216131","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["501195","425107","540776","499748","532703"],"PO":["557609"]},"70685":{"abstract":"EIA-0203846 Gagan Agrawal Ohio State University An Integrated Middleware and Language\/Compiler Framework for Data Intensive Applications in a Grid Environment<br\/><br\/>We propose to develop methods that will enable data intensive applications to be developed or specified using high-level interfaces, and yet effectively utilize grid resources. This will be accomplished by developing runtime techniques, a middleware based upon filter-stream programming, and Just in Time (JIT) compilation techniques for decomposing high-level programs into a set of filters. Our tools and techniques will exploit important commonalities of the data intensive applications we target.<br\/><br\/>Our target class of applications include both scientific and commercial data intensive applications. We are developing a middleware framework called DataCutter. DataCutter provides support for processing of datasets stored in archival storage systems in a wide-area network. DataCutter exports an interface for specifying processing as a set of coordination filters. While DataCutter offers a framework suitable for developing scientific and commercial data intensive applications in a grid environment, its programming interface is a relatively low-level one. The programmers need to decompose their application into a set of filters and specify the filters and their interaction.<br\/><br\/>In this project, we propose a series of high-level language interfaces that can be used for expressing data-intensive applications. We target data parallel Java, XML query language (XQL), and mining operators as interfaces that will allow processing to be specified assuming that all data and compute cycles are available at a single site. We propose research in compiler techniques that will decompose such applications into a set of filters, based upon the availability of data, computing, storage, and networking resources.","title":"NGS: An Integrated Middleware and Language\/Compiler Framework for Data Intensive Applications in a Grid Environment","awardID":"0203846","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["410444","558505","530803","256888"],"PO":["301532"]},"74700":{"abstract":"Curved geometry plays an important role in many applications, including manufacturing, robotics, and graphics. In many cases, highly accurate and robust operations and representations are desired, but the perceived implementation difficulties and inefficiencies (e.g. from exact computation) prevent application. Compared to the linear and combinatorial problems traditionally associated with computational geometry, problems involving curved solids are far more complicated. In practical terms, problems with accuracy, efficiency, and robustness are all significantly worse when dealing with curved geometry, and significant work remains in addressing these three areas. With further development, efficient implementations, and demonstrated applications, however, accurate and robust operations will find greater acceptance, giving a potential benefit to several application areas. This proposal outlines a plan of research that addresses accuracy, efficiency, and robustness of operations on curved geometry. Overall, it is a topic that is both challenging and promising in terms of potential impact and future research opportunities. <br\/><br\/>The proposed research addresses fundamental areas needed for further development of precise operations with curved solids. Theoretical issues are addressed, but a primary focus of the proposed research is on implementation. Most of the areas of proposed research are geared toward finding highly accurate or exact implementations that still achieve reasonable efficiency. Software will be released to support dissemination of the results. Specific areas of research include:<br\/><br\/>- Filtered Sequences of Computations<br\/>- Incorporating Root-Finding into Expression Trees<br\/>- Filtered Geometric Representations<br\/>- Resultant Computations<br\/>- Evaluating Combinations of Efficiency Improvements<br\/>- Handling Degeneracies<br\/>- Computing with Transcendental Functions<br\/>- Exact Geometric Representations<br\/><br\/>Application will be a major goal for all of the research areas. Application will serve both to drive new research ideas, and to allow testing and evaluation of research results. The primary application that will be used is solid modeling, from a traditional CAD perspective. The need for accurate and efficient representations in solid modeling is well recognized, making this research particularly relevant. In addition, solid modeling applications present a wide range of problems of varying complexity that allow thorough evaluation of the new methods. Besides solid modeling, we will also investigate application to geometric modeling of other objects, such as neurons, plants, and other naturally occurring objects. Application to neuron modeling will be in conjunction with an ongoing project on mapping brain microstructure, an exciting new interdisciplinary problem area with enormous potential that Texas A&M is in a unique position to address.<br\/><br\/>The proposed research will be integrated into educational activities. A new course in practical computer algebra will be developed that supports the research areas. Undergraduate student research will be encouraged through direct involvement in projects, coursework, and interaction through service activities.","title":"ITR: Accurate and Robust Operations on Curved Geometry","awardID":"0220047","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["535314"],"PO":["565272"]},"74711":{"abstract":"This research project explores the extent to which the proliferation of technology-enabled, international distributed teams can serve a social as well as an economic good by promoting cross-national understanding and the competence of members. Two issues of theoretical and practical significance are examined in depth, subgroup dynamics and cross-national learning processes. Understanding these processes in such teams and the impact of the use of communication technologies on them are important objectives. Moreover, the research will consider the role that each process plays in team effectiveness. Psychological processes and behavior at the team and individual levels will be examined by means of an ethnographic field study in a large, internationally distributed company. Particular attention will be given to patterns of communication, use of communication technologies, and the sharing of contextual information. The research seeks to advance science through the development of theory and evidence concerning subgroup polarization and collaboration in distributed groups, cross-national learning processes in moderately heterogeneous international groups, and the impact of these processes on team effectiveness. Envisioned advances also include recommendations <br\/>for the design of supporting collaborative technologies.","title":"ITR Collaborative Research - Subgroup Fault Lines in Distributed International Teams: The Impact on Cross-National Learning and Team Effectiveness","awardID":"0220098","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["518945"],"PO":["565227"]},"74601":{"abstract":"The explosive demand for communication services, fueled by the<br\/>rapid growth in the areas of mobile communications and the<br\/>Internet, has generated and will continue to generate immense<br\/>research efforts in the area of wideband wired\/wireless<br\/>communications. To accommodate the demanding future applications,<br\/>systems must be designed to perform joint equalization, detection,<br\/>decoding and estimation of the unknown and possibly time varying<br\/>channel parameters, while maintaining reasonable complexity (and<br\/>low cost). Motivated by these requirements, and using an OFDM<br\/>indoor wireless system as a design example, two main directions<br\/>are investigated in this project.<br\/><br\/>In the first direction, receiver algorithms are designed for<br\/>iterative, joint equalization, detection and decoding, that<br\/>address the critical issues mentioned above. The investigation<br\/>starts by identifying a powerful model that encompasses all the<br\/>salient features of the OFDM transmission system. Data detection<br\/>in OFDM is then stated as a problem of two-dimensional (2D) data<br\/>detection in the presence of localized, 2D intersymbol<br\/>interference, non-linear distortion, and unknown and time varying<br\/>parameters. We then identify fast, joint data detection and<br\/>channel estimation schemes which are utilized as building blocks<br\/>for powerful adaptive iterative detection receivers. Unlike the<br\/>entire iterative receiver, these sub-blocks are optimal in a<br\/>precisely defined sense, and can be implemented with<br\/>less-than-exponential complexity with respect to the data sequence<br\/>length.<br\/><br\/>The second direction is the development of a unified framework for<br\/>the analysis of the transient and steady-state behavior of<br\/>adaptive iterative algorithms. In the proposed study, the receiver<br\/>is assumed to have no explicit knowledge about the channel<br\/>parameters, other than their statistical description. The minimum<br\/>signal-to-noise ratio required for convergence to error-free<br\/>transmission, and the optimal allocation of power in pilot and<br\/>coded symbols, are some of the issues that are investigated for a<br\/>wide variety of adaptive iterative receiver architectures.<br\/>Regarding propagation modeling for the indoor environment, the<br\/>approach followed herein is a direct divergence from the classical<br\/>approaches that include either measurements, or the<br\/>well-established ray-tracing techniques. In particular, ultra-fast<br\/>algorithms for the numerical solution of the electromagnetic<br\/>problem are developed. These algorithms result in almost exact<br\/>solutions that can be evaluated with complexity comparable to the<br\/>less accurate ray-tracing techniques.","title":"ITR: Design of Novel Receiver Algorithms for OFDM Incorporating Realistic Indoor Channel Modeling","awardID":"0219531","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["562653","483402"],"PO":["348215"]},"74634":{"abstract":"Fourier analysis appears in many of the celebrated cornerstones of<br\/>theoretical computer science. It plays essential roles in expander<br\/>graph construction and derandomization, complexity lower bounds,<br\/>probabilistically checkable proof systems, quantum computing, lower<br\/>bounds for distributed computation, and traditional applications to<br\/>computer algebra. The majority of these applications involve the<br\/>familiar framework of commutative Fourier analysis. The proposed<br\/>project brings together a multidisciplinary research team to apply the<br\/>beautiful tools of non-Abelian (that is, noncommutative) Fourier<br\/>analysis to investigate open questions in two areas where non-Abelian<br\/>groups have recently become very important: lower bounds for parallel<br\/>computation and quantum algorithms. The program also further develops<br\/>efficient algorithms for the discrete Fourier transform over finite<br\/>non-Abelian groups.<br\/><br\/>This project focuses on developing tools for separating the complexity<br\/>classes ACC^0 and NC^1, in order to demonstrate that there are natural<br\/>(polynomial-time computable) problems which simply cannot be<br\/>parallelized in the sense of ACC^0. The project applies a new family<br\/>of tools for separating such circuit classes, using non-Abelian<br\/>Fourier analysis to bound their computational power. These tools apply<br\/>also to the problem of solving equations over finite groups, and the<br\/>development of new probabilistically checkable proof systems based on<br\/>non-Abelian groups. In addition, the project applies non-Abelian<br\/>Fourier analysis to develop improved lower bounds on the standard<br\/>Quantum Fourier Transform approach to Graph Isomorphism and study<br\/>quantum Monte Carlo algorithms. Finally, the project focuses on<br\/>adaptations of Bratelli diagrams and quivers to develop classical and<br\/>quantum algorithms for the non-Abelian Fourier transform itself.","title":"ITR Collaborative Research: Complexity-Theoretic Applications of Fourier Analysis","awardID":"0219717","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["559033"],"PO":["499399"]},"86976":{"abstract":"Problems involving massive amounts of data arise naturally in a variety of disciplines, such as spatial databases, geographic information systems, constraint logic programming, object-oriented databases, statistics, virtual reality systems, and computer graphics. NASA's Earth Observing System project, the core part of the Earth Science Enterprise (formerly Mission to Planet Earth), produces petabytes (1015 bytes) of raster data per year! A major challenge is to develop mechanisms for processing the data efficiently, or else much of it will be useless<br\/>The bottleneck in many applications that process massive amounts of data is the <br\/>Input\/Output (or I\/O) communication between internal memory and external memory. The bottleneck is accentuated as processors get faster and parallel processors are used. Parallel disk arrays are often used to increase the I\/O bandwidth. The goal of this research is to deepen the understanding of the limits of I\/O systems and to construct external memory algorithms that are provably efficient. The three measures of performance are number of I\/Os, disk storage space, and CPU time.<br\/>Theoretical work will consist of the development and analysis of provably efficient <br\/>external memory algorithms for a variety of important application areas. Several batched and on-line geometric problems will be addressed, including real-life problems from environmental applications. Techniques for innovative use of wavelets in an external memory setting will be explored. Models and technique will be developed to answer practical issues such as how to design algorithms to be robust to changing memory allocations. Focus is both on theoretical development and experimental validation. The TPIE programming environment will be enhanced and used to implement the external memory algorithms that are developed.","title":"External Memory Algorithms: Dealing with MASSIVE Data","awardID":"0328013","effectiveDate":"2002-09-01","expirationDate":"2003-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["313394"],"PO":["543507"]},"71125":{"abstract":"EIA-0205456<br\/>Joshi. Aravind K<br\/>University of Pennsylvania<br\/><br\/>ITR: Language, Learning, and Modeling Biological Sequences<br\/><br\/>Recent significant advances in natural language processing such as the integration of grammatical and probabilistic machine-learning techniques have not been exploited for modeling biological sequences. These new techniques are highly relevant to the biological domain because they support the integration of sequence features at several scales, from dependencies between successive items through dependencies involving complex structures to overall sequence statistics. Hence, the major goals to be pursued are: (1) Development of new techniques for integrating grammatical and probabilistic information, in particular, integration and evaluation of grammatical, probabilistic, and approximate counting methods for fold prediction in secondary and tertiary structures of biomolecules. (2) Development and evaluation of probabilistic exponential models for gene finding, in particular genes for apicoplast-targeted proteins in eukaryotic human pathogens of the phylum `Apicomplexa'. <br\/><br\/>This research is highly interdisciplinary, involving the disciplines of computer science, biology and linguistics. It will have a significant impact on the modeling of biological sequences. It will also provide a wonderful opportunity to train new researchers to carry out this interdisciplinary research, thus contributing to science and mathematical education and human resource development. <br\/><br\/>The proposed research arose out of many discussions that took place at a landmark workshop on `Language Modeling of Biological Data' held at the University of Pennsylvania in February 2001.","title":"ITR: Language, Learning, and Modeling Biological Sequences","awardID":"0205456","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1994","name":"BIOINFORMATICS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["472144","560705","485891","507484","365960"],"PO":["565136"]},"74403":{"abstract":"EIA-0218469<br\/>Jonathan R. Friedman<br\/>Amherst College<br\/><br\/>Toward Quantum Computing with Molecular Magnets; Studies of Spin Dynamics<br\/><br\/>The viability for using molecular magnets as qubits, the processing elements of quantum computers by using pulsed microwave and millimeter-wave radiation to perform quantum operations on the spin states of these systems are being investigated. In the process, some important issues regarding the tunneling mechanism by which the magnetic moments of these systems reverse direction at temperatures below a few Kelvin are also investigated.<br\/><br\/>A series of experiments are being performed to measure the effect of the applied radiation on the magnetic relaxation of the molecular magnets. These experiments include photon-assisted relaxation, which occurs when the radiation helps the molecule's spin reverse direction, Rabi oscillations of the probability of reversal with radiation-pulse duration, and free-precession of a quantum superposition of spin states produced by a series of radiation pulses. These experiments are aimed at providing a measure of the decoherence time of the excited spin state, a crucial parameter for determining whether the molecular magnets can be used as qubits. The project is also investigating methods of mitigating inhomogeneous broadening effects due to dipole interactions with neighboring molecules, nuclear spins and defects.<br\/><br\/>The project has potential impacts for the fields of quantum computation and information storage. It is also promoting the education of undergraduate students, especially underrepresented groups like women and minorities.","title":"Toward Quantum Computing with Molecular Magnets: Studies of Spin Dynamics in a Radiation Field","awardID":"0218469","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["545354","545908"],"PO":["521045"]},"74656":{"abstract":"The idea of providing differentiated network services to customers with different usage profiles is gaining strong commercial support. Many companies are providing solutions to policy-based management for desired Quality of Service (QoS). These network-based services range from application level control to bandwidth management. However, the onus of deciding or designing these policies rests on network managers. The view taken by most solution providers is that of a static organization where requirements can be assessed in advance. Consequently, at the user end overprovision of services has become a norm. This proposal investigates the economics of differentiated network service arrangements in business environments and the design and development of realistic network environments to conduct experiments and evaluate performance of a wide class of pricing approaches. The class of approaches we propose to investigate range from purely deterministically guaranteed QoS through contracts to real-time pricing that provides consumers with option to buy a QoS for each application at the time of consumption. To test the various pricing schemes, the token-bucket paradigm will be used. It will simulate a given price\/contract arrangement. The framework for economic experiments developed by this project will provide a benchmark tool to assess network efficiency under different contractual arrangements.","title":"ITR: A Unified Experimental Testbed to Compare Bandwidth Contract Choices for Differentiated Service Networks","awardID":"0219825","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["521736","281653"],"PO":["564456"]},"72115":{"abstract":"In modern computer systems, computation is distributed over many host machines. Mutually untrusted machines and users coexist, and software is built using plug-and-play components downloaded from remote hosts. Multiple users share resources so it is critical to ensure, e.g., that private information is not compromised. Languages like Java and C# are designed to provide such security by enforcing encapsulation boundaries that restrict interdependencies and information flows between program components. Such boundaries are undercut, however, by ubiquitous pointer aliasing which can be maliciously exploited to leak sensitive information.<br\/><br\/>This project studies ways to confine pointers to their intended scopes. The focus is on the interplay between static analysis and dynamic access control to achieve confinement. The technical goal is to find confinement regimes that can be used to assure secure information flow in systems implemented using dynamic binding, multithreading, inheritance, class-based encapsulation, and access control. Analyses and transformations to minimize run-time performance costs for confinement and access control are also investigated. This work will lead to better programming methods and tools for development of web-based services and other distributed applications that require a high level of assurance. The work will contribute to technology for implementing programming languages and for checking for security flaws in application programs.","title":"Collaborative Research: Integrating Pointer Confinement and Access Control for Encapsulation","awardID":"0208984","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["521696"],"PO":["521752"]},"71147":{"abstract":"Abstract<br\/><br\/>Databases are at the very heart of the information economy. Database<br\/>performance is a driving factor that dictates what is possible through the<br\/>use of information technology. While database management systems have<br\/>evolved since they were invented several decades ago, their current design<br\/>is unfortunately antiquated given the state-of-the-art computer memory<br\/>hierarchies of today (and even more so tomorrow). This project seeks to<br\/>alleviate this problem.<br\/><br\/>While processor speeds double every year, memory access speeds follow a<br\/>much shallower improvement curve. To bridge this speed gap, small, fast<br\/>memories called caches are used to hold frequently accessed data and<br\/>instructions close to the processor. When executing database workloads,<br\/>accesses often miss in the (fast) cache and access the (slow) memory,<br\/>thereby reducing performance significantly. Hardware approaches are<br\/>typically limited by access time constraints and by applicability to a wide<br\/>range of workloads. To keep the hardware design feasible, caches typically<br\/>use simplistic data placement and replacement schemes, and are oblivious to<br\/>the memory access behavior of the application.<br\/><br\/>Cache-conscious software methods are, on the contrary, extremely promising.<br\/>The proposed algorithms collect data statistics in order to correctly group<br\/>data with similar usage patterns and optimize cache utilization. By<br\/>carefully observing behavior, data is prefetched into the cache before it<br\/>is used. Preliminary results demonstrate that these techniques (i) minimize<br\/>the number of misses in the cache and (ii) significantly reduce the<br\/>incurred penalties.","title":"ITR: Cache-Resident Databases","awardID":"0205544","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["485986","342331"],"PO":["474792"]},"75624":{"abstract":"EIA- 0224427<br\/>Taylor, Valerie<br\/>Choudhary, Alok; <br\/>Dinda, Peter A.; <br\/>Mambretti, Joel J.<br\/>Northwestern University <br\/><br\/>Title: CISE RR: (Collaborative) DOT--Distributed Optical Testbed to Facilitate the Development of Techniques for Efficient Execution of Distributed Applications <br\/><br\/>This collaborative proposal with Illinois Institute of Technology (Sun, 02-24377) and the University of Chicago (Foster, 02-24187), acquiring data nodes and compute nodes at five sites, contributes to build a Distributed Optical Testbed (DOT). The DOT system, a product of the paradigm shift from large-scale applications running on large parallel systems at single sites to those running on distributed systems, has come about by the availability of high-speed optical networks (E.g., Starlight, TeraGrid 40 Gb\/s network, the PacificRail 10 Gb\/s network). This shift necessitates techniques that allow applications to efficiently utilize distributed systems. In contrast to parallel systems, these systems must exploit two characteristics:<br\/>Heterogeneity of resources (processors and networks) and <br\/>Dynamic changes in performance of shared resources, especially wide area networks. <br\/>The system, consisting of Linux clusters at six geographically different sites interconnected via two existing research DWDM networks, I-WIRE and OMNInet, involves the following sites: Argonne National Laboratory (ANL), Illinois Institute of Technology (IIT), National Center for Supercomputer Applications (NCSA), Northwester University Chicago Campus (NU-C), Northwestern University Evanston Campus (NU-E), and the University of Chicago (UC). DOT will facilitate the following research activities in the area of distributed applications:<br\/>Dynamic Load Balancing (Taylor)<br\/>Performance Monitoring and Prediction (Dinda, Sun, Taylor)<br\/>Data Management (Choudhary, Foster)<br\/>The first activity develops techniques utilizing network performance predictions that take into consideration the heterogeneity of the processors and networks of distributed systems to dynamically balance the load during execution. The second extends performance monitoring, modeling and prediction techniques that have been focused on parallel systems and broadband network to distributed systems with optical networks and different topologies. The last develops techniques that manage the distributed data such that the actual data location is transparent and the data is accessed efficiently. These research activities are driven by three applications that have been parallelized using MPI, such that the applications can be easily ported to DOT:<br\/>ENZO, an adaptive cosmological application,<br\/>Cactus, an open framework used to solve Einstein's equations, and<br\/>AudioVoice, a virtualized distributed audio application with physical simulations that have real-time deadlines and varying computational demands.<br\/>Each application presents challenges, which include adaptivity, flexible framework, and simulations with real-time deadlines.","title":"Collaborative Research: DOT -- Distributed Optical Testbed to Facilitate the Development of Techniques for Efficient Execution of Distributed Applications","awardID":"0224427","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["540138","320720","560392","541641"],"PO":["557609"]},"72005":{"abstract":"The objectives of the Cryptyc project are to develop a Cryptographic Protocol Type Checker, which allows secrecy and authenticity properties of cryptographic protocols to be specified as types. A formal type soundness proof shows that any protocol which passes the type checker is guaranteed to satisfy its secrecy and authenticity requirements.<br\/><br\/>Prior work on the Cryptyc project has developed a theory and tool which deals with many, but not all, cryptographic techniques and attacker models. This project extends the Cryptyc system to include<br\/>support for more advanced cryptographic primitives, more sophisticated attacker models, object-based component architectures, and applies the Cryptyc system to the development of secure component libraries for cryptographic protocols.","title":"Cryptyc: Cryptographic Protocol Type Checking","awardID":"0208549","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"W381","name":"NSA-TRUSTED COMPUTING PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["409674","258485"],"PO":["521752"]},"71037":{"abstract":"EIA- 0205061<br\/>Ray, Animesh <br\/>Keck Graduate Institute <br\/><br\/>TITLE: A Twin-Framework To Analyze, Model and Design Robust, Complex Networks Using Biological and Computational Principles<br\/><br\/><br\/><br\/>Vulnerability of natural networks (such as the Internet, power supply grid, or gene regulatory circuits of cells) to accidental or deliberate attack is an important area of study. To date most work has focused on observations of existing static networks or on computer simulations, because most natural networks are difficult to manipulate experimentally. The complex molecular machinery regulating the synthesis of RNA molecules in the nucleus of budding yeast, a single-celled organism, is a real-world instance of a natural network that can be experimentally perturbed by defined genetic manipulations, and the results of these perturbations can be studied at the molecular level with unprecedented accuracy by current genomic techniques. The goal of this project is to develop a biology-driven computational framework for network robustness. To achieve this goal, a biological test-bed of sufficiently complexity, the gene regulatory network of sporulation in yeast, has been adopted as an experimental network model. Systematic gene knockout mutations (equivalent to node removal), and regulatory site deletion mutations (equivalent to edge removal), are being used as tools to actively alter the network. Effects of these perturbations in the gene regulatory network architecture are being analyzed at the level of whole-genome transcriptional profiles. A generic data model for large-scale networks is being developed. The relevant experimental behavior of the biological network is being emulated with the data model. Design principles underlying the architecture of complex networks selected through evolution are being probed through mathematical modeling and testing. Insights obtained from these studies will be valuable for defensive strategies in complex network design, with implications in, among others, communication technology, disaster response, and in designing robust communication infrastructure resistant to planned attacks.","title":"ITR: A Twin-Framework To Analyze, Model and Design Robust, Complex Networks Using Biological and Computational Principles","awardID":"0205061","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["410581","559061","551355","452845","560510"],"PO":["521045"]},"73699":{"abstract":"EIA 0215799 <br\/>Stevens, Deborah<br\/>Institute for Women and Technology <br\/><br\/>TITLE: Scholarship and Travel Grants for the Grace Hopper Celebration of Women in Computing 2002<br\/><br\/>On October 9-12, 2002, the fourth Grace Hopper Celebration of Women in Computing (GHC) is being held in Vancouver, British Columbia, Canada. This international conference features talks by some of the most successful women in computing, technical presentations on topics of current interest, as well as panels, workshops, and technology innovation forums for an in-depth look at new issues in computing. This grant provides travel and registration funding for approximately seventy-five people in computing and related fields who otherwise would not be able to attend. The grants are awarded to advanced undergraduate and graduate students.<br\/><br\/>One of the goals of GHC is to encourage women to pursue and stay in the field of computer science by providing support for young women before they leave the pipeline. By providing opportunities for them to attend GHC, they are exposed to women who are creating, improving, and studying advanced computer related technologies and sciences. GHC is an unusual conference that focuses strongly on women in computing and is an excellent venue for worthwhile interactions to develop between those established in the field and others early in their careers. This grant is expected to directly affect the careers of the attendees and to help to reverse the current trend showing declining numbers of women in computing.","title":"Scholarship and Travel Grants for the Grace Hopper Celebration of Women in Computing 2002","awardID":"0215799","effectiveDate":"2002-09-01","expirationDate":"2002-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[190942],"PO":["289456"]},"71158":{"abstract":"This project is advancing the state of art in both computational cosmology and parallel computing simultaneously and synergetically. Breakthroughs in cosmology, which improve our understanding of the formation of galaxies and planets, are enabled by advances in parallel computing being made in this project. Parallel machines with over hundred thousand powerful processors are now being built. NSF's widely accessible TeraScale facilities have already deployed a 3,000 processor machine in 2001. At the same time algorithmic advances have made it possible to solve problems at a much faster rate. Yet the complexity of algorithms combined with the difficulty of parallelizing them on such large machines remains a hindrance to advances in Science and Engineering. This project explores an object based methodology that is simplifying the process of developing highly efficient parallel applications. This approach allows users to write applications at the level of natural entities in the application domain, without explicit regard to which processors will house such entities and<br\/>carry out associated computations. To make this possible, the \"runtime system\" must be able to make fine-grained resource allocation decisions automatically. Advances in parallel computing are being sought to that end. Specifically, application developers may specify a program in terms of a collection of millions of objects that communicate with each other in several stylized patterns. In addition, parallel components can be plugged in and out of running computations, and exchange data with each other in a exible manner. Based on this infrastructure, this project is building a framework that makes it easy to build \"particle-oriented\" parallel programs. In addition to computational cosmology, which predomi-nately involves simulations that represent galaxies, dark matter, stars, planetary bodies and gas as particles, such programs are used in other fields as well. The framework contains highly efficient parallel algorithms that operate on collections of billions of particles, spread across machines with tens of thousands of processors. These advances are being used to carry out scientific studies in cosmology. Large, detailed simulations of structure formation powered by parallel computers are necessary to make quantitative predictions from cosmological theories. By calculating the non-linear gravitational and gas dynamics of the formation of galaxies and clusters of galaxies, we are creating galaxy catalogues, X-ray maps, and other observables that can be compared directly with new satellite and ground-based data, and thereby constrain the parameters of cosmological theories. These parameters include the amount and nature of the dark matter, the existence and equation of state of any dark energy, the total amount of baryons, and the nature of the initial uctuations in the Universe. Similar simulation studies are being used to study how planets form from a proto-solar disk in order to create an ab initio theory of planet formation. The software developed via this project is being made available to a wide community of researchers. Also, the research results of simulations can be downloaded or visualized via the web.","title":"Collaborative Research: Advanced Parallel Computing Techniques with Applications to Computational Cosmology","awardID":"0205611","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["438346","558488"],"PO":["565272"]},"74425":{"abstract":"With National Science Foundation support, Drs. Nancy Ide and Randi Reppen will conduct a three-year project to annotate extensively a 10-million word portion of the American National Corpus (ANC). The ANC consists of both spoken and written language from North America across a range of registers, such as planned speeches, conversations, fiction, and newspapers. This research project uses techniques from both computational linguistics and corpus linguistics to annotate the ANC for a range of grammatical and semantic characteristics. Specifically the project seeks to accomplish three major objectives: 1) develop automatic tools for annotating various elements and structures in the corpus; 2) create a 'gold standard' portion of the ANC, consisting of 10 million words in which the markup, annotation, and parts of speech have been hand-validated; and 3) describe the conceptual and meaning relations among words in the ANC within the framework of the 'semantic web', thus greatly enhancing analysis and retrieval capabilities. The investigators are to carry out this research through a variety of software programs (many created specifically for this project), and through extensive human\/computer interaction to hand-validate the computer assigned labels. <br\/><br\/>This research project is important for several reasons. First, the resulting corpus will be the first publicly available tagged corpus of spoken and written American English. Second, because the annotation of the corpus will be hand-validated, the resulting product will approach 100% accuracy. With this carefully annotated 10-million word corpus, language researchers will be able to address a number of structural and linguistic relationships across texts that previously could not be addressed. Since the corpus will be hand-validated, researchers can use this information to develop models for processing previously unseen texts. The ANC corpus will be readily available to researchers via the web. In addition to the annotated corpus, the project will make available to researchers a suite of tools designed to retrieve information from the corpus.","title":"ITR: American National Corpus: A Primary Resource for Linguistics Research","awardID":"0218609","effectiveDate":"2002-09-01","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["501442","269296"],"PO":["564500"]},"75877":{"abstract":"EIA-0225656<br\/>Reddy, Raj<br\/>Carnegie Mellon University<br\/><br\/>Title: Computational Learning and Discovery in Biological Sequence, Structure and Function Mapping<br\/><br\/>Computer scientists, together with biological chemists will collaborate using statistical and computational tools and methods that the computer scientists have been developing for dealing with human language to better understand the function of proteins. Proteins are major players in the functioning of human and all other living cells. <br\/>As in languages, where sequences of letters determine patterns of words and sentences, sequences of amino acids in proteins determine protein structure, dynamics and function. Such sequences and their constituents can be thought of as syllables or words that have particular properties. Given these sequences, scientists want to be able to predict their geometrical structure and dynamics, and hence their function. A deeper understanding of the relationship between these is required so that the information hidden in the DNA sequences of genes can be used to develop drugs to fight disease. In particular, there is great societal demand to understand and treat degenerative diseases, many of which are based on defective triggers for protein shape and interactions. Work toward these goals requires deep knowledge both in computer science and in biological chemistry, and must therefore be collaborative in nature. Carnegie Mellon computer scientists will therefore be partnering with colleagues with expertise in Biological Chemistry at the University of Pittsburgh, the Massachusetts Institute of Technology (MIT), Boston University and the National Research Council of Canada. Industry collaborators include Mathworks, Inc., and medical bioinformatics company, Medstory, Inc. <br\/>Using tools like statistical language modeling, machine learning methods and high-level language processing for understanding how proteins work inside cells is a relatively new field called computational biolinguistics. At this point, the researchers have been able to detect protein fragment signatures from pathogens by application of statistical language modeling technologies to genome sequences, promising novel strategies in identifying and targeting such pathogens. <br\/>.","title":"ITR: Computational Learning and Discovery in Biological Sequence, Structure and Function Mapping","awardID":"0225607","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1688","name":"ITR LARGE GRANTS"}}],"PIcoPI":[197492],"PO":["565136"]},"72137":{"abstract":"Assurance for distributed systems is based on constantly strengthening the protective boundaries that prevent and detect unauthorized access to computer systems. Accountability, ensuring that principals are liable for their actions, is an equally important issue. This project investigates a programming language approach to tracking accountability in distributed systems, specifically by extending the Java language to maintain a fine-grained audit trail for accountability purposes.<br\/><br\/>The proposed approach is based on associating secrecy (access control) and integrity information with data as it is retrieved and copied over the network. Distributed access control is not just enforced at one point in the network where the data is accessed, but may be enforced wherever a copy of the data is accessed. Distributed information flow types enforce access rights and enforce a form of causality that supports tracking of tracking of accountability for principals. In recognition of the fact that communication may be over an insecure network, sensitive data is assumed to be \"virtually\" signed or encrypted, for integrity and secrecy guarantees, respectively. The computational burden of the ubiquitous application of cryptographic operations is avoided through the use of cryptographic types for static checking where possible.","title":"Distributed Access Control for Accountable Systems","awardID":"0209083","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["551007","549800"],"PO":["521752"]},"71048":{"abstract":"ABSTRACT<br\/>0205625,0205118, 0205429, 0205627 <br\/><br\/>TITLE: Collaborative Research: ITR: Acquiring Accurate Dynamic Field Data Using Lightweight Instrumentation<br\/><br\/>Dynamic analyses, such as testing and profiling, play a key role in state-of-art approaches to software quality assurance (QA). With rare exception, these analyses are performed in-house, on developer<br\/>platforms, using developer-provided input workloads. Shortcomings of this approach include that the results simply cannot be trusted to tell us how the software actually performs in the field.<br\/><br\/>The project goal is to give developers unprecedented insight into the actual runtime behavior of their software, allowing developers (and ultimately the software itself) to change, optimize, and adapt the software based on highly accurate field data. Lightweight, collaborative dynamic analyses conducted around-the-world and around-the-clock form the new platform: (1) lightly instrument fielded software (i.e., each program copy performs a small part of the analysis) (2) collect the partial data from many instances of the software, fusing it to conduct the complete analysis, (3) change the running program instances based on the findings and (4) repeat the process.<br\/><br\/>Seven critical research challenges form the core of the project: <br\/>1. Lightweight instrumentation--Develop instrumentation that is virtually transparent to individual users. 2. Compositional analysis techniques--Develop distributed analysis techniques that decompose<br\/>traditional analyses into smaller steps, distribute the steps among multiple users, and then fuse each user's results into an accurate solution to the original problem. 3. Scalability--Develop storage<br\/>and analysis techniques to deal with the high data volumes we expect to encounter. 4. Anomaly Detection--Define data-driven techniques to automatically identify anomalous behaviors of deployed<br\/>software. 5. Privacy and Security--Incorporate privacy and security safeguards into our data collection and analysis approaches. 6. Dynamic updating mechanisms--Develop techniques to make runtime changes to the location and function of instrumentation, and to parts of the software itself. 7. Validate approach on industrial<br\/>software.","title":"Collaborative Research: ITR: Acquiring Accurate Dynamic Field Data Using Lightweight Instrumentation","awardID":"0205118","effectiveDate":"2002-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["531363"],"PO":["564388"]},"75888":{"abstract":"EIA-0225656<br\/>Reddy, Raj<br\/>Carnegie Mellon University<br\/><br\/>Title: Computational Learning and Discovery in Biological Sequence, Structure and Function Mapping<br\/><br\/>Computer scientists, together with biological chemists will collaborate using statistical and computational tools and methods that the computer scientists have been developing for dealing with human language to better understand the function of proteins. Proteins are major players in the functioning of human and all other living cells. <br\/>As in languages, where sequences of letters determine patterns of words and sentences, sequences of amino acids in proteins determine protein structure, dynamics and function. Such sequences and their constituents can be thought of as syllables or words that have particular properties. Given these sequences, scientists want to be able to predict their geometrical structure and dynamics, and hence their function. A deeper understanding of the relationship between these is required so that the information hidden in the DNA sequences of genes can be used to develop drugs to fight disease. In particular, there is great societal demand to understand and treat degenerative diseases, many of which are based on defective triggers for protein shape and interactions. Work toward these goals requires deep knowledge both in computer science and in biological chemistry, and must therefore be collaborative in nature. Carnegie Mellon computer scientists will therefore be partnering with colleagues with expertise in Biological Chemistry at the University of Pittsburgh, the Massachusetts Institute of Technology (MIT), Boston University and the National Research Council of Canada. Industry collaborators include Mathworks, Inc., and medical bioinformatics company, Medstory, Inc. <br\/>Using tools like statistical language modeling, machine learning methods and high-level language processing for understanding how proteins work inside cells is a relatively new field called computational biolinguistics. At this point, the researchers have been able to detect protein fragment signatures from pathogens by application of statistical language modeling technologies to genome sequences, promising novel strategies in identifying and targeting such pathogens. <br\/>.","title":"Computational Learning and Discovery in Biological Sequence, Structure and Function Mapping","awardID":"0225656","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1688","name":"ITR LARGE GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1994","name":"BIOINFORMATICS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["499671","355022","531367","562858","562859"],"PO":["565136"]},"71059":{"abstract":"EIA- 0205152<br\/>Sharon Dawes<br\/>SUNY Albany<br\/><br\/>Modeling the Social and Technical Processes of Interorganizational Information Integration<br\/><br\/>This grant will develop and test dynamic models of information integration in multi-organizational government settings. Three questions will be addressed: 1) What are the critical factors and processes involved in integrating information across levels and agencies in government? 2) How do the factors and processes vary for different types and degrees of integration? and 3) Can the process of integration be modeled in ways that improve understanding of information system development and of inter-organizational collaboration? Two policy areas in particular will be featured; law enforcement and environmental protection. Both areas include a full range of functions across Federal-State-Local levels of government and both areas have efforts underway to bridge those levels. The project will combine perspectives from organizational behavior, computer and information science, and political science, and will use system dynamics modeling and social processes modeling.","title":"ITR: Modeling the Social and Technical Processes of Interorganizational Information Integration","awardID":"0205152","effectiveDate":"2002-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"H465","name":"SSA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V873","name":"LIB OF CONGRESS-DIGITAL LIBRAR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V986","name":"LIB OF CONGRESS-DIGITAL PRESER"}}],"PIcoPI":["433610","551444","551444","433032",183898],"PO":["565136"]},"74359":{"abstract":"EIA-0219627 Craig Douglas University of Kentucky Collaborative Research: ITR\/AP-Predictive Contaminant Tracking Using Dynamic Data Driven Application Simulation \\(DDDAS\\) Techniques<br\/><br\/>This project will lead to a leap-ahead technology in simulation capabilities. Research in the development of new methods and algorithms for the specific application areas is needed. The dynamic application requirements will dictate computing systems' support that includes systems' software technologies, such as active middleware services for real time, dynamic reconfiguration capabilities, resource discovery, load balancing, security, fault tolerance, quality of service, and dynamic interfaces with field measurement systems. <br\/><br\/>An encoded web stream set of contaminations from actual situations (both above ground and underground) will allow researchers besides us to tap into our virtual reality DDDAS environment. Visualization systems will allow us to work with a variety of real networks, sensors, and environments.","title":"Collaborative Research: ITR\/AP- Predictive Contaminant Tracking Using Dynamic Data Driven Application Simulation (DDDAS) Techniques","awardID":"0218229","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["292276","450789","423015"],"PO":["301532"]},"69926":{"abstract":"Procedural synthesis of natural and contextually appropriate gestures in embodied virtual human agents is challenging. Laban Movement Analysis (LMA) offers a descriptive system for human gesture qualities that fills the gap between pre-defined gesture playback systems and human animator intuition. A computational analog of LMA called EMOTE has been constructed whose parameters modify the performance qualities of arm gesture movements. EMOTE will be developed in several new ways:<br\/><br\/>* Connect EMOTE with an agent model so that an agent's affect, personality, and communicative needs set appropriate EMOTE parameters for gesture performance.<br\/><br\/>* Investigate motion analysis techniques for extracting EMOTE parameters from live dual or single camera views.<br\/><br\/>* Experimentally validate the automated acquisition of EMOTE parameters by using professional LMA notators for ground truth.<br\/><br\/>* Use the extracted parameters to create instances of parameterized actions which may be subsequently used for action, affect, and manner descriptions and, ultimately, for content-directed analysis of existing film or video material.<br\/><br\/>This study will help set synthetic agent animation techniques on a sound empirical footing, provide evidence that computers can in fact observe important motion qualities, and lead to strong connections between internal agent state and external behavior qualities.","title":"Synthesis and Acquisition of Communicative Gestures","awardID":"0200983","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["397034","522465"],"PO":["565215"]},"74712":{"abstract":"This project, which is a collaborative effort between the University of<br\/>California at Riverside and Los Angeles, focuses on processor and<br\/>system architecture issues for Web Switches. Web switches are network<br\/>processing elements that modify network traffic based on content.<br\/>These devices are frequently used to provide load balancing between<br\/>functionally equivalent servers as well as cryptographic services; in<br\/>in the future will be used for a host of new applications including<br\/>active security and multimedia trans-coding. This project will begin<br\/>by developing a benchmarking framework that can be used to evaluate<br\/>the performance of Web switches. The research will then use advanced<br\/>processor simulation tools to study architectural tradeoffs in the<br\/>face of the benchmark workload. In particular, the researchers will<br\/>focus on the efficacy of hardware accelerator blocks that have been<br\/>proposed. Finally, work will be completed to implement the workload<br\/>and capitalize on acquired knowledge in the context of an existing<br\/>test bed for network processors.","title":"ITR: Collaborative Research: Processor Architectures for Web Switches","awardID":"0220100","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[194083],"PO":["559883"]},"74723":{"abstract":"With the growing use of the Internet technology, unintentional faults and intentional intrusions directly on network protocols, such as routing protocols (e.g., BGP, OSPF), have become a serious threat to our Internet-connected society. Over the past few years, the researchers have seen<br\/>many fault or security related instances happening to our Internet and, because of these problems, significant losses occurred one way or the other. In the research communities, such as fault tolerant<br\/>networking, network security, and intrusion detection, many new ideas have been explored to enhance the existing network protocols or, more drastically, to propose a completely new Internet architecture. Some vulnerabilities have been reduced or removed, but yet the researchers expect many more new vulnerabilities and problems to be discovered.<br\/><br\/>The researchers believe that, to effectively monitor and control a large system, they need not only a well-designed and implemented system but also, equally important, a good human interface to know the system after it is deployed and operated. The researchers also believe that, in the foreseeable<br\/>future, human intelligence will play a critical role in managing and maintaining large distributed systems such as the Internet. But, surprisingly few research efforts are currently toward this direction.<br\/><br\/>The main contribution in this project is a human-interactive approach to handle faults and security attacks on the Internet routing protocols such as BGP (Border Gateway Protocol) and OSPF (Open<br\/>Shortest Path First). We will investigate several critical but very difficult (difficult in the sense if we would rely completely on machine intelligence) issues and offer solutions based on an interactive visual-based analysis process. For example, anomaly detection systems for unknown\/novel attacks are hard to build due to the consideration of effectiveness, coverage, and false positive. Also, network event correlation is very difficult because this task normally involves very complicated potential relations among various events on the Internet and the amount of resources to complete the task is prohibitively expensive.<br\/><br\/>This research addresses two very fundamental problems. One is the formulation of typical visual-based anomaly detection processes. The other is the mapping of not only the protocol data but also the analysis process to appropriate visualization representations and associated operations. The resulting visual-based process would allow a human network operator quickly navigate to the right level of details to discover critical facts about the Internet. For the network<br\/>routing protocol management, we study the \"optimal\" boundary between the machine intelligence and the human intelligence on detecting and tracking anomaly that was previously impossible to understand.","title":"ITR: An Interactive Visual Anomaly Detection System for Faults and Intrusions on Network Protocols","awardID":"0220147","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["507838","552243"],"PO":["292741"]},"71104":{"abstract":"Abstract<br\/>0205336<br\/><br\/><br\/>This research pursues the development of a network of robots with cameras and<br\/>their optimal, dynamic positioning for monitoring a cluttered scene, under different conditions of visibility. The robots must discover their neighbors, localize <br\/>themselves with respect to their neighbors and integrate information with that<br\/>available from the other members of the team on the fly. Further this information <br\/>must allow a remotely located human operator to immerse herself in the<br\/>environment. The project addresses the development of enabling algorithms and<br\/>technology tailored to such applications as fire-fighting.","title":"ITR: ANTIDOTE: Adaptive Network of Robots for Threat and Intrusion Detection and Emergency Response","awardID":"0205336","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["553286","456808","517945","553287"],"PO":["561889"]},"74756":{"abstract":"ourier analysis appears in many of the celebrated cornerstones of<br\/>theoretical computer science. It plays essential roles in expander<br\/>graph construction and derandomization, complexity lower bounds,<br\/>probabilistically checkable proof systems, quantum computing, lower<br\/>bounds for distributed computation, and traditional applications to<br\/>computer algebra. The majority of these applications involve the<br\/>familiar framework of commutative Fourier analysis. The proposed<br\/>project brings together a multidisciplinary research team to apply the<br\/>beautiful tools of non-Abelian (that is, noncommutative) Fourier<br\/>analysis to investigate open questions in two areas where non-Abelian<br\/>groups have recently become very important: lower bounds for parallel<br\/>computation and quantum algorithms. The program also further develops<br\/>efficient algorithms for the discrete Fourier transform over finite<br\/>non-Abelian groups.<br\/><br\/>This project focuses on developing tools for separating the complexity<br\/>classes ACC^0 and NC^1, in order to demonstrate that there are natural<br\/>(polynomial-time computable) problems which simply cannot be<br\/>parallelized in the sense of ACC^0. The project applies a new family<br\/>of tools for separating such circuit classes, using non-Abelian<br\/>Fourier analysis to bound their computational power. These tools apply<br\/>also to the problem of solving equations over finite groups, and the<br\/>development of new probabilistically checkable proof systems based on<br\/>non-Abelian groups. In addition, the project applies non-Abelian<br\/>Fourier analysis to develop improved lower bounds on the standard<br\/>Quantum Fourier Transform approach to Graph Isomorphism and study<br\/>quantum Monte Carlo algorithms. Finally, the project focuses on<br\/>adaptations of Bratelli diagrams and quivers to develop classical and<br\/>quantum algorithms for the non-Abelian Fourier transform itself.","title":"ITR Collaborative Research: Complexity-Theoretic Applications of Fourier Analysis","awardID":"0220264","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["486281"],"PO":["279077"]},"71126":{"abstract":"This project is a multidisciplinary, international collaborative research project aimed at developing a fully automated robotic system for on demand and batch scanning of print materials and an open-source software framework that will begin with a printed work and end with digital images, text and musical content suitable for digital libraries.","title":"ITR: A Data Capture Framework and Testbed for Cultural Heritage Materials","awardID":"0205466","effectiveDate":"2002-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["467058","508352","563069",184151,184152],"PO":["433760"]},"74514":{"abstract":"EIA-0219079<br\/>Jouline, Igor B<br\/>Georgia Technology Research Corporation - GIT<br\/><br\/>ITR: Comparative Genomic Analysis of Signal Transduction in Prokaryotes<br\/><br\/>Whole genome sequencing projects revolutionize our understanding of biology and open up new opportunities for fundamental research and its applications to medicine, agriculture and environment. Accumulating genomic data generates the need for rapid biological interpretation of genome sequences and integration of this knowledge into databases of genomic information for immediate use by biomedical and environmental scientists. Proteins comprising signal transduction networks control most vital functions in any given organism, beneficial or harmful. However, current interpretation of genomic data for signal transduction proteins fails to provide sufficient information for understanding their biological role. The goal of this research project is to significantly improve prediction of biological functions for signal transduction proteins and to unravel potentially novel signal transduction mechanisms and pathways in various beneficial and pathogenic microorganisms. This will be achieved through a systematic computational approach, which integrates in-depth analysis of functional elements (domains) of individual proteins and evolutionary and genome context information. The results obtained will be incorporated into primary databases and will allow automated detection of biologically important proteins. The research proposed in this project will contribute to a better understanding of the organization and evolution of signal transduction systems (fundamental aspect). This, in turn, will assist experimental scientists in identification of targets for antimicrobial drug design in pathogens and in improving beneficial capabilities of microorganisms used for biofertilization and bioremediation purposes (applied aspect).","title":"ITR: Comparative Genomic Analysis of Signal Transduction in Prokaryotes","awardID":"0219079","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["347949"],"PO":["565223"]},"72105":{"abstract":"ABSTRACT<br\/>What is the ``typical\" traffic of a link? What constitutes ``abnormal\" traffic, and therefore warrants an alert for suspicious behavior (intrusion)?<br\/>How will the Internet look like next year? These are the questions that the project focuses on.<br\/><br\/>It has two major thrusts:<br\/>The first is to find patterns in the network traffic, and the second is to find trends in the Internet evolution. The technical merit is in the synergy of the networking and data mining fields, pushing the envelope in both:<br\/>The networking field will enjoy novel insights and fast tools to predict the network performance. The data mining field will benefit from new problems<br\/>and new tools (using fractals, power laws, large-graph algorithms), that will be stress-tested on multiple Gigabytes of real, network data. <br\/><br\/>The broader impact of this work will be a novel insight of the network behavior at the micro and macro level. In addition, the work will explore our ability to predict the network behavior and its evolution. As a result, the work will provide new tools to identify abnormal behavior, that could be due to a security breach like a DDoS attack.","title":"Collaborative Research: NetMine: Finding Patterns in Network Data","awardID":"0208950","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["549003"],"PO":["563751"]},"75614":{"abstract":"EIA- 0224377<br\/>Sun, Xian-He<br\/>Illinois Institute of Technology <br\/><br\/>Title: CISE RR: (Collaborative) DOT--Distributed Optical Testbed to Facilitate the Development of Techniques for Efficient Execution of Distributed Applications <br\/><br\/>This collaborative proposal with Northwestern University (Taylor, 02-24427) and the University of Chicago (Foster, 02-24187), acquiring data nodes and compute nodes at five sites, contributes to build a Distributed Optical Testbed (DOT). The DOT system, a product of the paradigm shift from large-scale applications running on large parallel systems at single sites to those running on distributed systems, has come about by the availability of high-speed optical networks (E.g., Starlight, TeraGrid 40 Gb\/s network, the PacificRail 10 Gb\/s network). This shift necessitates techniques that allow applications to efficiently utilize distributed systems. In contrast to parallel systems, these systems must exploit two characteristics:<br\/>Heterogeneity of resources (processors and networks) and <br\/>Dynamic changes in performance of shared resources, especially wide area networks. <br\/>The system, consisting of Linux clusters at six geographically different sites interconnected via two existing research DWDM networks, I-WIRE and OMNInet, involves the following sites: Argonne National Laboratory (ANL), Illinois Institute of Technology (IIT), National Center for Supercomputer Applications (NCSA), Northwester University Chicago Campus (NU-C), Northwestern University Evanston Campus (NU-E), and the University of Chicago (UC). DOT will facilitate the following research activities in the area of distributed applications:<br\/>Dynamic Load Balancing (Taylor)<br\/>Performance Monitoring and Prediction (Dinda, Sun, Taylor)<br\/>Data Management (Choudhary, Foster)<br\/>The first activity develops techniques utilizing network performance predictions that take into consideration the heterogeneity of the processors and networks of distributed systems to dynamically balance the load during execution. The second extends performance monitoring, modeling and prediction techniques that have been focused on parallel systems and broadband network to distributed systems with optical networks and different topologies. The last develops techniques that manage the distributed data such that the actual data location is transparent and the data is accessed efficiently. These research activities are driven by three applications that have been parallelized using MPI, such that the applications can be easily ported to DOT:<br\/>ENZO, an adaptive cosmological application,<br\/>Cactus, an open framework used to solve Einstein's equations, and<br\/>AudioVoice, a virtualized distributed audio application with physical simulations that have real-time deadlines and varying computational demands.<br\/>Each application presents challenges, which include adaptivity, flexible framework, and simulations with real-time deadlines.","title":"Collaborative Research: DOT -- Distributed Optical Testbed to Facilitate the Development of Techniques for Efficient Execution of Distributed Applications","awardID":"0224377","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["557489"],"PO":["557609"]},"72116":{"abstract":"This project will use subjectivity analysis to improve the accuracy of information extraction (IE) systems. IE systems are designed to extract facts, but they are prone to false hits from subjective statements such as accusations, allegations, suspicions, and opinions. The first phase of the research will create a subjectivity classifier that uses learning algorithms to identify linguistic features associated with subjective language. The classifier will use several natural language representations, including extraction patterns, N-grams, and noun phrases. The classifier will be embedded in a bootstrapping architecture so that it can learn from unannotated corpora, requiring only a small amount of annotated data to jumpstart the bootstrapping. In the second phase, the classifier will be integrated into an IE system to measure the impact of subjectivity classification on IE performance. Information extracted from objective sentences will be treated as facts, but information extracted from subjective sentences will be labeled as uncertain or discarded. This research will produce a better understanding of how subjective language is expressed and the role that context plays in recognizing subjectivity. The potential impact of the research is to produce more accurate subjectivity classifiers and to demonstrate that subjectivity analysis can improve the performance of IE systems.","title":"Collaborative: Improving Subjectivity Analysis to Achieve High-Precision Information Extraction","awardID":"0208985","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["451671"],"PO":["565227"]},"74668":{"abstract":"We propose a novel marriage of new fundamentals of data structures and algorithms with the productive tools of generic programming. Together they promise tools that could make high performance computing available to any scientist. The data structure is the Morton-order representation of matrices (and arrays in general), which admits both row, column, and quadrant decompositions. Its benefits are grounded in architecture where it solves problems of locality at all levels of a memory hierarchy. The favored algorithms use divide- and-conquer recursion-a style associated with functional programming-because they address the problems of balanced scheduling and communication of distributed and multiprocessing. Generic programming contributes, also, to this higher-level algebraic view of program construction. The anticipated result is a style for parallel programming without requiring explicit choreography either of memory or of processors. That is, the programmer can specify computations, and eventually new algorithms, with a high-level language closer to mathematics. We propose to develop the tools and the techniques to carry these programs to an efficient parallel implementation.<br\/><br\/>Products will include a new programming style, new efficiencies for parallel and Grid computing, tools to carry old codes into this environment, tools to support the new generation of programs, support for teaching a new generation of programmers, and new algorithms that can only be inspired by this high-level perspective on programming.","title":"ITR: A Paradigm of Parallel Programming for Morton-Ordered Matrices","awardID":"0219884","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["562709","430172"],"PO":["565272"]},"75878":{"abstract":"EIA-0225656<br\/>Reddy, Raj<br\/>Carnegie Mellon University<br\/><br\/>Title: Computational Learning and Discovery in Biological Sequence, Structure and Function Mapping<br\/><br\/>Computer scientists, together with biological chemists will collaborate using statistical and computational tools and methods that the computer scientists have been developing for dealing with human language to better understand the function of proteins. Proteins are major players in the functioning of human and all other living cells. <br\/>As in languages, where sequences of letters determine patterns of words and sentences, sequences of amino acids in proteins determine protein structure, dynamics and function. Such sequences and their constituents can be thought of as syllables or words that have particular properties. Given these sequences, scientists want to be able to predict their geometrical structure and dynamics, and hence their function. A deeper understanding of the relationship between these is required so that the information hidden in the DNA sequences of genes can be used to develop drugs to fight disease. In particular, there is great societal demand to understand and treat degenerative diseases, many of which are based on defective triggers for protein shape and interactions. Work toward these goals requires deep knowledge both in computer science and in biological chemistry, and must therefore be collaborative in nature. Carnegie Mellon computer scientists will therefore be partnering with colleagues with expertise in Biological Chemistry at the University of Pittsburgh, the Massachusetts Institute of Technology (MIT), Boston University and the National Research Council of Canada. Industry collaborators include Mathworks, Inc., and medical bioinformatics company, Medstory, Inc. <br\/>Using tools like statistical language modeling, machine learning methods and high-level language processing for understanding how proteins work inside cells is a relatively new field called computational biolinguistics. At this point, the researchers have been able to detect protein fragment signatures from pathogens by application of statistical language modeling technologies to genome sequences, promising novel strategies in identifying and targeting such pathogens. <br\/>.","title":"ITR: Collaborative Research - Computational Learning and Discovery in Biological Sequence, Structure and Function Mapping","awardID":"0225609","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1688","name":"ITR LARGE GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1994","name":"BIOINFORMATICS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["522530",197495],"PO":["565136"]},"72138":{"abstract":"This project is fundamental research to improve the performance of intelligent software agents, based on the observation that an agent's past experiences are a valuable and generally underutilized database. The goal is to produce algorithms that make stronger use of data than existing reinforcement learning algorithms, enabling a view of the agent's stored experiences as a repository that can be mined for performance-improving information. More generally, the agent may choose to use data obtained by observing other agents, or even from mining the web.<br\/><br\/>The impact of this research may be felt in many areas. For example, software learning agents can be expected to learn in a much more human-like manner; noteworthy experiences will be remembered, and their influence on future performance will not attenuate. There will be no sampling requirements on the data, so it will be possible to learn from watching others and possible to use repositories of stored data to learn new behaviors. Among the likely practical applications of this work are network management and electronic commerce.","title":"Prediction and Planning: Bridging the Gap","awardID":"0209088","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["518533"],"PO":["491702"]},"74437":{"abstract":"This project systematically investigates the value of pedagogical agent features (*image: character, realism, gender, ethnicity; *animation: task-related, expressive; and *pre-defined agent roles: expert, motivational advisor, co-collaborator) in supporting learning-related outcomes. Using Multiple Intelligent Mentors Instructing Collaboratively (MIMIC) as the research environment, the standard experimental research design includes multiple factors and will be analyzed primarily via MANOVA. Additional micro-genetic data from logged agent-learner interactions and supplemental case studies triangulate the findings. All participants are individually randomly assigned to treatment conditions with large sample sizes (125-200 students), including educational technology undergraduate students from both a state university and a historically black university. The instructional content focuses upon the ill-structured domain of instructional planning with diverse learning outcomes, including metacognition, cognitive strategies, attitude\/motivation, as well as traditional performance. Through extensive dissemination of results to the relevant multi-disciplinary communities, this project proposes to: a) illuminate principles of learning with pedagogical agents, b) facilitate computer scientists in prioritizing areas of future development for pedagogical agents; c) inform teachers of the most desirable characteristics of agent-based applications for their<br\/>students; d) refine key features for pedagogical agents within distance learning course nvironments; and, e) advise instructional systems designers in developing training systems for industry and government.","title":"ITR: Systematic experimentation of the role of pedagogical agent features in promoting learning and motivation","awardID":"0218692","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["315063"],"PO":["564456"]},"72028":{"abstract":"Rate-Based Resource Allocation Methods for Real-Time Embedded Systems <br\/><br\/>Proposal #0208924<br\/><br\/> <br\/><br\/>A. Revised Project Summary<br\/><br\/> <br\/><br\/>Run-time executives and operating system kernels for embedded systems have long relied exclusively on static priority scheduling of tasks to ensure timing constraints and other correctness conditions are met. Static priority scheduling is easy to understand and support but it suffers from a number of significant problems such as: the complexity of simultaneously mapping timing and importance constraints onto priority values, dealing with tasks whose execution time is either unknown or may vary over time, dealing with tasks whose execution time (or rate) deviates from the behavior expected at design-time, degrading system performance gracefully in times of overload, and ensuring full utilization of the processor or other resources in tightly resource constrained systems.<br\/><br\/> <br\/><br\/>Rate-based resource allocation schemes offer an attractive alternative to traditional static priority scheduling as they offer flexibility in specifying and managing timing and criticality constraints. In a rate-based system a task is guaranteed to make progress according to a well-defined rate specification such as \"process x samples per second,\" or \"process x messages per second where each message consists of 3-5 consecutive network packets.\" This research investigates the use of rate-based resource allocation methods for constructing embedded systems with real-time execution constraints. <br\/><br\/> <br\/><br\/>The focus of the project is two-fold: an algorithm design and analysis component, and a prototype implementation and use component. In the design\/analysis component, a framework is being developed using taxonomy of rate-based resource allocation consisting of proportional share scheduling, polling server-based scheduling, and rate-based extensions to classical Liu and Layland scheduling. The goal is to relate the different scheduling models and abstractions to one another and to understand the fundamental principles of rate-based resource allocation such as the form and nature of timing guarantees and the algorithmic overhead. In addition, the existing theory of rate-based resource allocation is extended to deal with considerations such as preemption constraints. <br\/><br\/>The implementation and use component of this research explores rate-based resource allocation in operating system kernels and applications. The objective is to assess the fit between the formal task model used to develop a particular allocation algorithm and implementation constraints that arise in practice. <br\/><br\/> <br\/><br\/>Three scheduling problems are considered: application-level scheduling (i.e., scheduling of user programs or application threads), scheduling the execution of system calls made by applications (\"top-half\" operating system-level scheduling), and scheduling asynchronous events generated by devices (\"bottom-half\" operating system-level scheduling). This reflects the logical structure of traditional, monolithic real-time (and general purpose) operating systems and kernels with hardware enforced protection boundaries. The research results will be distributed as an experimental version of FreeBSD that employs different forms of rate-based scheduling and resource allocation at different levels in the system.","title":"Collaborative Research: Rate-Based Resource Allocation Methods for Real-Time Embedded Systems","awardID":"0208619","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["486378"],"PO":["561889"]},"75537":{"abstract":"Embedded software is playing an important role in economy, government, and military. Since such software is often deployed in safety critical applications, correctness and reliability have become issues of utmost importance. Techniques for verification and validation traditionally fall into two main categories. One is formal verification, i.e., model checking and proof methodology. The other is abstract interpretation and static analysis. The goal of formal Verification is to prove that designs meet their specifications. Model Checking an automatic approach to verification, mainly useful when dealing with finite-state systems. Abstract Interpretation is a method for designing and comparing semantics of programs. It has been successfully used to infer run-time program properties that are instrumental for program optimization purposes.<br\/>There are no clear dividing lines in between these different methodologies. In fact, they can be combined. An example is the exciting new research direction that combines abstraction (of infinite-state programs into finite-state ones) with model checking (of the finite-state system), that had produced formal and automatic verification of many complex systems. There is a growing conviction in the research community that hybrid methodologies are imperative for the process of formally verifying analyzing full-fledged reactive systems.","title":"CCR: The First Annual Conference on Verification, Model Checking and Abstract Interpretation 2003","awardID":"0223760","effectiveDate":"2002-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["362818"],"PO":["564388"]},"74338":{"abstract":"EIA-0218142<br\/>George E. Karniadakis <br\/>Brown University<br\/><br\/>ITR\/DDDAS Generalized Polynomial Chaos: Parallel Algorithms for Modeling and Propagating Uncertainty in Physical and Biological Systems<br\/><br\/>The applications we target are prototype problems in bioengineering and in nanotechnology. The coupled nature of such problems and the many parameters involved provide a good testbed for evaluating the performance of the new algorithms at resolutions from 0.1 to 1 billion degrees-of-freedom. The sources of uncertainty may be caused by incomplete knowledge or fluctuations in boundary or initial conditions, geometric domain, transport coefficients, mechanical properties, and other external forcing or volumetric sources.<br\/><br\/>The proposed work will have significant and broad impact as it will establish a composite error bar in large-scale simulations and will enable numerical stochastic approaches to large-scale simulations of physical and biological systems. It will also benefit many other fields including climate and network\/web traffic modeling, where current uncertainty modeling approaches are inadequate. Stochastically simulated responses can serve as sensitivity analysis that could potentially guide experimental work and dynamic instrumentation.","title":"ITR: DDDAS Generalized Polynomial Chaos: Parallel Algorithms for Modeling and Propagating Uncertainty in Physical and Biological Systems","awardID":"0218142","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["517149"],"PO":["301532"]},"76527":{"abstract":"A \"Workshop on Computational Sciences, Mathematics, and Engineering\" is planned for the fall of 2002. The purpose of the workshop is to develop a planning document for future research directions and resources needed to advance the solution of a limited number of significant problems of national interest. These \"core problems,\" which will be selected by the workshop participants, will provide a focus to define the generic issues of a computational science discipline. The core problems will be addressed through collaborations among application scientists, mathematicians, statisticians, and computer scientists. A workshop report will be produced and disseminated that will summarize the discussion and conclusions of the workshop. A web site is planned as part of the effort.","title":"Workshop on Computational Sciences, Mathematics, and Engineering","awardID":"0229259","effectiveDate":"2002-09-15","expirationDate":"2005-03-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4066","name":"PART FOR ADVANCED COMP INFRA"}}],"PIcoPI":["563333"],"PO":["565356"]},"74008":{"abstract":"EIA 02-16661 <br\/> Rafkin, Scot <br\/> Chun, Robert<br\/> San Jose State University <br\/><br\/>Title: MRI\/RUI\/MII: Acquisition of a Linux Cluster Super Computer for Meteorological Modeling and <br\/> Computer Science Research and Education <br\/><br\/>Project Proposed:<br\/><br\/>This proposal from an RUI\/MII institution, establishing a Linux-based parallel computing cluster, aims to simulate meteorological phenomena and study and teach the use of parallel processors. The infrastructure will be used in support of ongoing<br\/>Numerical modeling of the atmosphere of Mars using the Mars Regional Atmospheric Modeling System (MRAMS) and<br\/>Computer Science Research in the parallel and distributed hardware and software.<br\/>The first component will benefit the following current research underway:<br\/>Large eddy simulations (LESs) of the Martian atmosphere to provide insight into the structure and dynamics of the highly unstable convective boundary layer (including the dynamics of dusts devils)<br\/>Mesoscale simulations of past and proposed Mars landing sites<br\/>Simulation of local and regional dust storms, and wind-produced landforms (aids satellite observations)<br\/>Simulations of orographic water ice and carbon dioxide clouds.<br\/>The second component will investigate and\/or explore<br\/>Software optimization of the MRAMS code (tune it for maximum performance on hardware platform) and<br\/>Alternative hardware architectures for high-performance computing<br\/>The cluster will serve as a central research platform to investigate processor-to-processor communication overhead, memory contention of symmetric multiprocessors, cache coherence, and distributed processing. Moreover, performance of novel processor, memory, and network topologies will be evaluated.","title":"MRI: Acquisition of a Linux Cluster Super Computer for Meteorological Modeling and Computer Science Research and Education","awardID":"0216661","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["421700",192084,192085],"PO":["557609"]},"77539":{"abstract":"This SGER grew out of an EU-US workshop held in Venice in October, 2002. The intent of that workshop was to bring together researchers from the US with those from the EU who were working on similar projects related to e-work and e-business and who would like to begin to collaborate together. This SGER will allow for US cooperation with the EU's STAR project, which involves the conduct of dozens of case studies mapping change in a variety of industries across member states of the EU. This project will focus on the home mortgage service sector, in particular specialized lenders, and will bring the US and one its industries into the collection. Case study protocols will be developed that will allow for cross-comparison with the EU case studies that have already been completed. In addition, travel to the EU will allow for a team meeting and coordination of project goals, methods, and analysis.","title":"Collaborative Research: SGER: Exploring the Integration of Electronic Commerce in Industry Value Chains: A Focus on the Home Mortgage Service Sector","awardID":"0233634","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["562605"],"PO":["495796"]},"71852":{"abstract":"Progress in the field of natural language processing (NLP) is currently limited, at least in part, by the speed with which new annotated corpora can be created. In addition, there is evidence that achieving the next level of performance in automated text understanding will require annotated training corpora that are orders of magnitude larger than those currently available. In short, there exists a corpus annotation bottleneck in building robust, accurate NLP system components. The PI proposes, therefore, to investigate machine learning paradigms that will significantly reduce human annotation costs while maintaining or improving the accuracy of the natural language learning algorithms that are trained on the acquired corpora. The project will (1) study the application of active learning (Cohn et al., 1994) and weakly supervised bootstrapping algorithms like co-training (Blum & Mitchell, 1998) on a set of representative problems in natural language processing, (2) identify the benefits and limitations of these approaches for reducing the manual annotation burden during the creation of large training corpora for natural language learning, and (3) develop a cooperative learning framework (Pierce & Cardie, 2002) that combines active and weakly supervised learning in an attempt to more effectively interleave manual and automated linguistic annotation efforts.","title":"Reducing the Corpus Annotation Bottleneck for Natural Language Learning","awardID":"0208028","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}}],"PIcoPI":["548297"],"PO":["565215"]},"73954":{"abstract":"EIA-0216500<br\/>Sharma Chakravarthy<br\/>Yuksel A. Aslandogan; Sajal K. Das; Lawrence B. Holder; Jachoon Yu<br\/>University of Texas Arlington<br\/><br\/>MRI: Acquisition of High Performance Distributed Computing and Storage Infrastructure at UTA<br\/><br\/>This proposal, acquiring high-performance computing and storage infrastructure, aims to satisfy the research needs of several groups that require distributed and parallel computing resources. Involving collaboration from the departments of Computer Science and Engineering (CSE) and Physics at UTA, and Dermatology at UT Southwestern Medical School, the research efforts include:<br\/>a. Database and Data Mining (e.g., visualization of search),<br\/>b. Software Engineering (e.g., formal methods),<br\/>c. Physics (e.g., high energy physics -HEP- experiments),<br\/>d. Dermatology (e.g., image database\/analysis of skin lesion), <br\/>e. Distributed Computing (e.g., scheduling, load balancing on Information Power Grid), and<br\/>f. Networking (e.g., wireless, optical; simulations).<br\/><br\/>The key characteristics involve:<br\/>a. Multi-disciplinary use of common equipment and infrastructure,<br\/>b. Multi-institutional sharing of equipment,<br\/>c. Enhancing current-research efforts and creating new synergy leading to new research ideas,<br\/>d. Combining the high-bandwith of Internet 2 with high-performance computing and storage infrastructure to facilitate large image databases and video streaming research, and access to vast amounts of experimental data from outside the campus.<br\/><br\/>Educational impact is expected by enhancing the experiences of at least 40 CS and 10 physics students and 15 faculty using the resource in an interdisciplinary mode. Joint activities should lead to high quality of inter-disciplinary research fostered by the collaboration.","title":"MRI: Acquisition of High-Performance Distributed Computing and Storage Infrastructure at UTA","awardID":"0216500","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["564777","553596","550149",191879,"520949"],"PO":["557609"]},"70698":{"abstract":"EIA - 0203892<br\/>Smith, Lloyd<br\/>University of Wisconsin <br\/><br\/>TITLE: ITR: Multiple-Word DNA Computing on Surfaces<br\/><br\/><br\/>This effort will extend the scope and power of surface-based DNA computing in two major respects: i) by scale-up of the size of problem addressed experimentally, ii) by increasing computational generality by extending capabilities to the solution of circuit-SAT problems.<br\/><br\/>Goal (i) will be scaling up the computing process using a problem size of 24 bits as a target goal. 24 bits corresponds to a solution space size of 1.7 x 107 elements, a factor of ten million increase over the 4 bit problem addressed previously.<br\/><br\/>Goal (ii) - For a computing model to be general, that is, capable of efficiently simulating algorithms used in conventional electronic computing, it must be able to efficiently simulate circuits. The ability to simulate Boolean formulas is not sufficient. In theoretical work, it is shown that the surface-based approach, when using multiple words and the MARK, DESTROY-UNMARKED, UNMARK, and APPEND operations, is such a generalizable approach to computing, but it has not been implemented experimentally. This proposal seeks to implement this approach experimentally and to apply it to the solution of circuit-SAT problems.","title":"ITR: Multiple-Word DNA Computing on Surfaces","awardID":"0203892","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["471123","369365",183023,183024],"PO":["565136"]},"74713":{"abstract":"The continual and compelling need for accurately and efficiently simulating dynamical behavior of physical systems arising from a wide variety of applications has led to increasingly large and complex models. Reduced-order modeling (ROM), also called model reduction, techniques play an indispensable role in providing efficient computational prototyping tools to replace such large-scale models by approximate smaller models. Such reduced-order models must be capable of capturing critical dynamical behavior and faithfully preserving essential properties of the larger models they approximate. An accurate and effiective reduced-order model can be applied for steady-state analysis, transient analysis, or sensitivity analysis of large-scale models and the physical systems they emulate. Consequently, scientists and engineers can significantly reduce design time and pursue more aggressive design strategies. Designers can try ``what-if\" experiments in hours instead of days.<br\/><br\/>In this proposal, we propose a broad range of synergistic research activities on ROM relating to three interlinking strands: computational theory, reliable algorithms, and high-performance software tools. We will also be actively involved with promoting applications of ROM techniques and testing our methods through existing and new collaborations with researchers in circuit simulation, structural dynamics, control systems, and microelectromechanical systems (MEMS). Specifically, our proposed research activities on computational theory and algorithms include:<br\/><br\/> Accuracy estimation in both time and frequency domains.<br\/><br\/> Sensitivity analysis of linear systems using the techniques of ROM and statistical condition estimation.<br\/><br\/> Development of ROM techniques that directly exploit so-called second-order model structures and generate a reduced-order model in second-order form.<br\/><br\/> Exploration of a framework of ROM techniques for certain types of large-scale nonlinear systems of technological importance.","title":"ITR: Computational Theory and Tools for Reduced-Order Modeling of Very Large Dynamical Systems and Applications","awardID":"0220104","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["301523","562713"],"PO":["565272"]},"74603":{"abstract":"The sheer size of the World-Wide Web mandates the provision of portals, hotlists, and other catalogs that organize Web content in a domain-oriented manner. However, the quality of the information contained is subject to degradation as content changes, sites reorganize, and host connectivity fluctuates. Simply detecting that a resource has changed is easy, but determining whether that change is significant requires understanding of the context in which the resource is used. This project will improve the stability of collections of Web pages, allowing the development of predictable collections that overcome the inherent instability of the World-Wide <br\/>Web. To accomplish this goal, the project will investigate the applicability of semantic descriptors provided by collection creators and implicit contextual information extracted from the collection.","title":"ITR: Long-Lived Information Artifacts Based on Short-Lived Administratively-Decentralized Source Material","awardID":"0219540","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["465209","467562"],"PO":["433760"]},"74614":{"abstract":"Malicious code poses a significant threat to our society, which is becoming increasingly reliant on networked computer systems for commerce and communication. Malicious software, including viruses, worms, and Trojan Horses, has the potential to disrupt communications and threaten the stability of the Internet as a whole. Therefore the objective of this research is analysis, detection, and mitigation of malicious code. The many types of malicious code are being investigated and grouped by exploited vulnerability and effect. This makes it possible selectively to target each exploit class separately. Previous approaches to the analysis of malicious code relied on static reverse engineering, confined execution (via program language sandboxing), or network traces. These approaches are often inadequate for increasingly complex malicious code that may be self-modifying, using run-time encryption or dynamic polymorphism. Dynamic malicious code requires dynamic tools for analysis, detection, and mitigation. Therefore new dynamic tools to permit such analysis are being developed, together with security enhancements to allow detection and mitigation of known malicious code types. The research approach is to use run-time binary translation to achieve transparent code monitoring and rewriting. A prototype implementation of a system for software assurance and security based on binary translation is being developed, and the effectiveness of the solution and its potential deployment cost are being investigated.","title":"ITR: Intrusion Detection and Intrusion Prevention Through Dynamic Binary Translation","awardID":"0219587","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["550110"],"PO":["521752"]},"71105":{"abstract":"This project will develop a new, integrative theory of software problem management by studying software<br\/>problems in their ongoing sociotechnical contexts. The researchers willcomparatively analyze large bodies (gigabytes) of longitudinalproblem-report data from open-source software development projects such as networked computer games, Internet\/Web infrastructure, X-ray astronomy\/deep space imaging, and academic software research, using grounded-theory and automated concept, data, and text-mining<br\/>methods. The project will analyze instances of (mis-)alignment between software artifacts, problem episodes, problem-management activities, problem-management infrastructure, and underlying social<br\/>organization. Explanatory models will be built by linking patterns of (mis-)alignment among these elements to outcomes such as ease-of-repair, persistence of problems, amount of information exchanged, kinds of skills needed, and structure of social organization. The resulting models can guide the development of new<br\/>tools, infrastructures, and organizational practices for software. They will also provide new perspectives on community-wide practices of capturing and managing knowledge. This research will provide a conceptual shift in understanding how system development and use are bound together with the richness, variety, and temporal evolution of the socio-technical contexts provided by the global software industry.","title":"ITR: Collaborative Research: Organizational Dynamics of Software Problems, Bugs, Failures and Repairs","awardID":"0205346","effectiveDate":"2002-09-01","expirationDate":"2008-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["503214"],"PO":["564456"]},"74625":{"abstract":"EIA-0219673<br\/>Devika Subramanian<br\/>William Marsh Rice University<br\/><br\/>Events, Patterns, and Analysis: Forecasting International Conflict in the Twenty-First Century<br\/><br\/>This grant will support work on international conflict prediction using techniques such as data mining, statistical machine learning, and stochastic modeling. News data from such sources as Reuters, AP, cnn.com, and UPI will be used to extract data about political events. Each event will code with a time, list of participants and other standardized characteristics to support the analysis and forecasting.","title":"ITR: Events, Patterns, and Analysis: Forecasting International Conflict in the Twenty-First Century","awardID":"0219673","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[193836,193837],"PO":["565227"]},"73899":{"abstract":"EIA-0216344<br\/>Lee Spector<br\/>Hampshire College<br\/><br\/>MRI\/RUI: Acquisition of Instrumentation for Research in Genetic Programming, Quantum Computation, and Distributed Systems<br\/><br\/>This proposal from a RUI institution, enabling work in genetic programming, quantum computation, and distributed systems, proposes acquiring a 16-node Linux NetworX Evolocity system for use in student and faculty research. The instrumentation will enable advance in multi-type genetic programming by allowing the user to specify a diverse set of primitives and related data types while simultaneously specifying little in the way of parameters. (Early genetic programming systems forced users to restrict all operation to a single data type to ensure the semantic validity of programs undergoing recombination and mutation. \"Strongly typed\" genetic programming systems allow the generation of programs that are able to manipulate diverse types.) For the quantum computation area, genetic and other automatic programming will be used to explore the space of possible quantum algorithms and their speed-ups relative to classical algorithms. Since quantum computer hardware is not yet available, the usual hindrance in so doing involves the time required for simulating the quantum algorithms; fitness must be tested using a quantum computer simulator that runs on conventional hardware. Preliminary promising results on problems with unresolved complexity will be employed to seek scaling algorithms for which asymptotic complexity results can be proved. Distributed systems, a primary focus of student's independent work at Hampshire College, will enable students to pursue the development of innovative software and programming techniques for networked, multi-CPU systems.","title":"MRI\/RUI: Acquisition of Instrumentation for Research in Genetic Programming, Quantum Computation, and Distributed Systems","awardID":"0216344","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["554244"],"PO":["557609"]},"74515":{"abstract":"Ensuring the security of today's computer systems is an urgent and difficult<br\/>problem. The complexity and rapid pace of change in current software systems<br\/>prevents developers from verifying or auditing the code thoroughly enough to<br\/>eliminate vulnerabilities. This project seeks to provide security defenses<br\/>that work in the presence of compromised operating systems and applications.<br\/>Even if an attacker compromises the operating system, these defenses will<br\/>continue to ensure their intended security policies.<br\/><br\/>This new level of security is made possible by adding a virtual-machine layer<br\/>underneath the vulnerable operating system and applications. This additional<br\/>software layer enables new security services that do not depend on the<br\/>integrity of the target software. This project explores four new security<br\/>services that can be added via virtual machines: 1) the ability to replay<br\/>and analyze the complete, instruction-by-instruction execution of a computer<br\/>system, including actions after the point of compromise; (2) the ability to<br\/>recover the system to a prior state after an intrusion; (3) the ability to<br\/>prevent intrusions by safely testing hypothetical \"what if\" scenarios; and (4)<br\/>the ability to detect intrusions by monitoring all actions of the computer<br\/>system.","title":"ITR: Covirt: Security Defenses for Insecure Operating Systems","awardID":"0219085","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["556912"],"PO":["521752"]},"72106":{"abstract":"Schwan, Karsten<br\/>CCR-0208953<br\/>\"InfoFabric: Adaptive Services in Distributed Embedded Systems\" This research is developing <br\/>\"Infofabric\" services to manage multiple shared data streams and enable high performance sensing and <br\/>communication in dynamically reconfigurable sensor nets. For example, in emergency response <br\/>applications, the computing infrastructures employed are rapidly assembled conglomerates of portable and <br\/>handheld end user devices. Multiple communication modes are used to interact across collaborating peers <br\/>and also with local and remote command centers and\/or information repositories. A key problem is that <br\/>such devices typically cannot access, display, and manipulate information with the quality needed by end <br\/>users. An example is an observer `in the field' trying to match visible cloud formations with the <br\/>outputs produced by remotely running weather simulations, the latter using real-time radar data. Unless the <br\/>handheld device can visualize data with high quality and in real-time, field observations cannot be used to <br\/>refine or steer the remote weather prediction programs. Similarly, search and rescue operations can be <br\/>aided by rich (multi-media), real-time communications between team members and by high fidelity <br\/>graphical displays of terrain data available from remote servers.<br\/>The basic technical problems to be solved for the resulting complex, distributed and embedded applications <br\/>include (1) the provision of high levels of flexibility in how, where, and when necessary processing and <br\/>communication actions are performed on the underlying distributed platforms, and (2) the ability to <br\/>continuously meet end user needs despite runtime variations in service locations, platform <br\/>capabilities (e.g., remaining power on end devices), and user requirements. The `InfoFabric' approach <br\/>supports data-intensive, embedded applications with lightweight publish\/subscribe middleware. An end <br\/>user dynamically subscribes to information channels when needed, and the InfoFabric applies the <br\/>processing specified by the user. Processing and communication actions are dynamically mapped to the <br\/>underlying distributed devices and machines. To attain high performance and meet embedded systems <br\/>requirements like such as power, new compiler and runtime binary code generation methods dynamically <br\/>generate and install code on the InfoFabric's platform. Code is specialized to match current user needs to <br\/>available platform resources. To meet dynamic needs and deal with runtime changes in resource <br\/>availability, resource management mechanisms associated with middleware carry the performance, <br\/>usage, and needs information required for runtime adaptation of processing and communication actions. Because the InfoFabric middleware has detailed knowledge of the ways in which information should be transported and manipulated before delivering it to end users, it can employ techniques like automatic <br\/>redundancy and replication, and service (re)location and (re)partitioning to match changing user needs and platform availabilities.","title":"InfoFabric: Adaptive Services in Distributed Embedded Systems","awardID":"0208953","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["523077","532971","550988","501621"],"PO":["561889"]},"71138":{"abstract":"EIA-0205301<br\/>Albert Corbett<br\/>Carnegie-Mellon University<br\/><br\/>ITR: Collaborative Research: Putting a Face on Cognitive Tutors:<br\/>Bringing Active Inquiry into Active Problem Solving<br\/><br\/>Collaborative project with:<br\/>0205506<br\/>Michelene Chi<br\/>University of Pittsburgh<br\/><br\/>This project builds on a growing body of research concerning effective learning and tutoring strategies. The project involves constructing and evaluating educational technology that emulates human tutors by integrating a state-of-the art educational technology called Cognitive Tutors with a innovative interactive questioning environment called Synthetic Interviews to produce an inactive learning environment that rivals the effectiveness of human tutors. Cognitive tutors are built around a cognitive model of problem solving knowledge and provide precisely the support students need to complete problems successfully. Used alone, cognitive tutors do not support the help-seeking and meta-cognitive skills that characterize active learners. By incorporating a novel interactive communication technology called Synthetic Interviews, an Active Learning Environment is offered that rivals the effectiveness of human tutors in supporting deep student learning. Synthetic Interviews allow learners to engage in active inquiry by providing the means for conversing in-depth with an individual. Synthetic Interviews permit knowledge capture in a new form providing utility similar to an expert system but a development effort approaching the simple video taping of a conversation. The Active Learning Environment serves as a research tool to examine both computational and pedagogical challenges and also as an educational environment in classrooms and homes. In particular, the domains of knowledge that are constructed around this learning environment are mathematics and biology courses. The project promises to make important contributions to cognitive science, computer science and educational practice including the following: 1) The analysis of student questions during synthetic interviews will contribute to basic cognitive models of the functional relationship between declarative conceptual knowledge and procedural problem solving knowledge, 2) This project will integrate cognitive models of student knowledge and tutorial dialogue structure. More generally, the project will help define a design and engineering process for intelligent learning environments, 3) The research will inform the design of more effective computer-based learning environments. 4) The research and the active learning environment can support improved professional development both for pre-service and in-service teachers. The Active Learning Environments for mathematics and biology that are developed in this project promise to directly improve educational practice nationally. Current generation cognitive mathematics tutors are already in use in about 2% of middle schools and high schools around the country. The demand for effective mathematics and science education continues to grow. States are increasing mathematics graduation requirements and instituting assessments that govern student graduation and school evaluations. If Active Learning Environments are more effective than current generation Cognitive Tutors, they promise to rapidly enter widespread classroom use.","title":"ITR: Collaborative Research: Putting a Face on Cognitive Tutors: Bringing Active Inquiry into Active Problem Solving","awardID":"0205506","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1688","name":"ITR LARGE GRANTS"}}],"PIcoPI":["423487"],"PO":["551712"]},"71149":{"abstract":"Pnueli, Emerson, and Sistla<br\/>CCR-0205571, CCR-0205483 and CCR-0205365<br\/>\"Towards a Seamless Process for the Development of Embedded Systems\"<br\/><br\/><br\/>Embedded systems are of vital economic importance and are literally<br\/>becoming ubiquitous. They have already become an integral component of<br\/>safety critical systems involving aviation, military,<br\/>telecommunications, and process control applications. Interest in<br\/>embedded systems is growing further due to the expectation that they<br\/>will become a key component of many commonplace consumer appliances.<br\/>Consumers will expect levels of reliability and predictability<br\/>associated with the very best brands of cars, televisions, and<br\/>refrigerators. Glitches, crashes, and general erratic behavior of the<br\/>sort seen with prior generations of consumer PC software products will<br\/>be unacceptable for these embedded applications. It thus becomes<br\/>crucial that these embedded software systems satisfy high levels of<br\/>correctness criteria, well above those of today's large software<br\/>systems, which are often highly error-prone.<br\/><br\/>Besides the requirement of a new standard of functional correctness,<br\/>embedded systems pose additional challenges which were not fully<br\/>addressed by previous validation and verification approaches. These<br\/>include adequate guarantees of timeliness, low or controlled power<br\/>consumption, and low or controlled memory utilization. With the<br\/>spread of embedded systems, and the need to guarantee an acceptable<br\/>level of functionality and reliability of the applications they are<br\/>embedded in, the industry needs an effective and reliable development<br\/>process. Due to market constraints, such a process should also support<br\/>a fast turn-around time as well as enable the easy design of many<br\/>customized variations of the same product.<br\/><br\/>This project is developing the foundation for a seamless design<br\/>process for embedded systems as described below. In particular, it is<br\/>developing:<br\/><br\/> A formal visual language for requirements, including behavioral,<br\/> temporal, and TPM constraints;<br\/><br\/> A methodology for the automatic synthesis of an executable<br\/> specification from the requirement specification language;<br\/><br\/> A methodology for the verification of the intermediate and<br\/> distributed representation of the systems against requirements;<br\/><br\/> A methododology for automatic code-distribution of<br\/> specifications, possibly with some architectural constraints<br\/> provided by the user;<br\/><br\/> A model for representing hardware\/software co-design<br\/> platforms that enables modeling of both loosely- and tightly-coupled<br\/> components as well as compositional reasoning about them;<br\/><br\/> Algorithms for automatically generating <br\/> architecture-optimized code from executable specifications;<br\/><br\/> Methods for translation validation of the<br\/> generated code and run-time validation on the system using<br\/> monitors;<br\/><br\/> The Design of a profiler process which analyzes machine code,<br\/> computes the resulting figures for time, power, and memory, and<br\/> back-associate these figures with their executable specification<br\/> sources, enabling early-stage analysis of these requirements.<br\/><br\/>The impact of the project is to streamline and significantly<br\/>accelerate the time to market of embedded applications of both new<br\/>products and revisions and customizations of existing product lines.<br\/>Another impact is to upgrade the level of dependability and<br\/>predictability of embedded software to new standards, compatible and<br\/>comparable to those expected from the best brands of consumer<br\/>products.","title":"ITR: COLLABORATIVE RESEARCH: Towards a Seamless Process for the Development of Embedded Systems","awardID":"0205571","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["362818","409234","417591"],"PO":["561889"]},"75626":{"abstract":"EIA 0224431<br\/>Belhumeur, Peter N.<br\/>Kriegman, David J.<br\/>Columbia University <br\/><br\/>Title: CISE RR: Instrumentation for Empirical Studies in the Modeling of Visual Appearance <br\/><br\/>This project, supporting experimental validation of computer vision algorithms for shape modeling and analysis, aims at building two independent systems to support computer vision. Methods for shape reconstruction and reflectance recovery, termed Helmholtz reciprocity stereopsis and light field reconstruction that exploit previously neglected physical principles, are able to recover surface shape regardless of the object's BRDF. The two special purpose imaging systems will be built at Columbia University and the University of Illinois at Urbana-Champaign (UIUC). The Columbia rig, composed of sixteen imaging modules that can be arranged in different configurations, directly supports research in Helmholtz reciprocity stereopsis. The UIUC rig, consisting of two arms that move their endpoints over the surface of a sphere, directly supports the light field reconstruction method. The two new pieces of hardware will contribute to the following four projects:<br\/>Helmholtz Stereopsis,<br\/>Light Field Reconstruction,<br\/>Image-Based Modeling and Rendering, and<br\/>Texture and Reflectance Estimation from Small Datasets.<br\/>The first project exploits the symmetries in an object's surface reflectance. The Helmholtz stereopsis method can reconstruct surfaces with complex reflectance, e.g., highly non-Lambertian. The Helmholtz rig will be used to gather datasets of objects in a manner such that they can be processed using the Helmholtz stereopsis shape recovery method. The second uses images gathered from a double covering of a surface's incident light field to reconstruct both the surface shape and an effective bi-directional reflectance distribution on a point-by-point basis. The illumination\/viewpoint rig will be used to gather data in a manner such that it can be processed with the light field reconstruction method. The third utilizes the datasets gathered by both rigs for image-based and modeling projects to render photorealistic images of objects under novel viewpoint and arbitrary illuminations. Datasets of objects, with their 3-D shape reconstructed, are collected and their reflectance is modeled. These models of shape and reflectance are then used to synthesize novel images of the objects and composite them into still pictures and video footage. The objects will be catalogued by their visual appearance. The last project uses the datasets gathered by the light field rendering rig for developing low-dimensional models of texture and reflectance. These models are then used to estimate texture and reflectance properties from a small number of images. Thus, images characterizing reflectance properties of a wide variety of materials will be created and distributed satisfying the following goals to <br\/>Develop, refine, analyze, and empirically validate the method of Helmholtz stereopsis,<br\/>Develop, refine, and analyze the light field reconstruction method,<br\/>Apply the reconstruction methods to image-based rendering, and<br\/>Develop and refine data-driven low-dimensional non-parametric models for surface reflection and textures that vary with viewpoint and lighting.","title":"Instrumentation for Empirical Studies in the Modeling of Visual Appearance","awardID":"0224431","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["426630","519250"],"PO":["557609"]},"77815":{"abstract":"HDCCSR Proposal 0234651<br\/> Improving test suites via generated behavioral abstractions<br\/> Michael Ernst<br\/><br\/>Testing is a key to detecting bugs and increasing software reliability, but generating good test suites is difficult. This project investigates a novel technique for using behavioral differences to improve test suites. The technique compares dynamically generated behavioral abstractions of executions and selects the more complete one -- that is, the test suite that exercises more of the program's semantic behavior. Whereas previous automatic techniques compare dynamic (run-time) behavior to the static structure and text of the program, this new technique considers behavior, which complements structural techniques and is arguably more important.<br\/><br\/>The technique is applied to generating, augmenting, and minimizing test suites. Users provide the program to be tested and a technique for generating test cases (via a grammar, random generation, traces collected from users, or otherwise). Users never need to provide a specification. However, the technique generates a behavioral abstraction that is syntactically identical to a formal specification and that, after being checked and perhaps augmented by a human, can be<br\/>used as a specification. The efficacy of these techniques is investigated and improved, and they are applied in substantial case studies.","title":"Improving Test Suites Via Generated Specifications","awardID":"0234651","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"W379","name":"NASA-HIGHLY DEPENDABLE COMPUTI"}}],"PIcoPI":[202940,"501796"],"PO":["565272"]},"75637":{"abstract":"EIA- 0224453<br\/>Adve, Sarita V.<br\/>Hwu, Wen-mei;<br\/>Kale, Laxmicant V.; <br\/>Padua, David A.; <br\/>Patel, Sanjay J.<br\/>University of Illinois - Urbana\/Champaign <br\/><br\/>CISE RR: Programming Environments and Applications for Clusters and Grids <br\/><br\/>This proposal, building a cluster platform connected by gigabit Ethernet, enables the \"grid\" to be used in the following four research projects:<br\/><br\/>Advanced Programming Environments for Cluster and Grids,<br\/>Parallel Applications for Clusters and Grids,<br\/>Dynamic Sequential Code Optimization, and<br\/><br\/>Architectures for Multimedia and Communications Applications.<br\/><br\/>The configuration permits experimentation on diverse subsystems with varying degrees of heterogeneity, up to three levels of parallelism, and a range of system sizes. The facility will be used in three ways: as an experimental test-bed for systems research on clusters and grids; as a prototype for the development of parallel and distributed applications for clusters and grids; and as a cost-effective production compute server for research in architecture, compilers, and machine learning. The shared facility addresses problems critical to computational infrastructure spanning architecture, compiler, and runtime research on systems ranging from single nodes to grids, covering various application domains.","title":"CISE Research Resources: Programming Environments and Applications for Clusters and Grids","awardID":"0224453","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["533380","345579","558488","551063","322427"],"PO":["557609"]},"75879":{"abstract":"This ITR project is aimed at developing the foundations of a modern systems science that is simultaneously computational and physical; it remarries time, concurrency, robustness, continuums, and resource management to computation. This project, because of its focus on foundations, will provide a fundamentally new paradigm, based on hybrid systems, for modeling and analysis of many complex phenomena that occur in the physical and biological sciences on both microscopic and macroscopic levels. These outcomes of the project are prerequisites for the deployment of embedded, autonomous computing in many safety-critical applications, from medical devices to transportation to national security needs in avionics. The attention to a new education model will create a new generation of engineers who will be able to master the design of complex, heterogeneous systems that will be the backbone of the future IT industry.<br\/><br\/>The proposed ITR has four focus areas of research. (a) Hybrid systems theory. The focus here is on scaling up pioneering approaches that integrate physical modeling with computational systems. (b) Model-based design. The main effort here is to develop a set of models with solid mathematical foundations that allow for the systematic integration of diverse efforts in system specification, design, synthesis, analysis and validation, execution, and design evolution (c) Advanced tool architectures. The deliverables from this project will be a set of reusable, inter-operating software modules, freely distributed as open-source software. (d) Experimental research. The program will leverage existing system-building efforts involving avionics, anti-terrorism technologies, vehicle electronics, and autonomous robots. In addition we will apply our methods to networks of embedded systems for applications such as environment monitoring, building protection, and emergency response. <br\/><br\/>The impact of this change on teaching and research is profound, and will not be confined to the graduate level. Based on the ongoing, groundbreaking effort at UCB, we propose to deliberately re-architect and retool undergraduate teaching at the participating institutions, and to engage in course development at a set of California community colleges with which UCB has established relationships and which have a high enrollment of Hispanic and African American students. Faculty and graduate student researchers from minority and other institutions will be recruited each summer to participate in a program called SIPHER (Summer Internship Program in Hybrid and Embedded Software Research).","title":"ITR: Foundations of Hybrid and Embedded Software Systems","awardID":"0225610","effectiveDate":"2002-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1688","name":"ITR LARGE GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526900"],"PO":["561889"]},"66936":{"abstract":"EIA-0131079<br\/>Hany Ammar<br\/>West Virginia University<br\/><br\/>Digital Government: Automated Dental Identification<br\/><br\/>This grant will support the development of tools for rapid identification of individuals based on dental records. The technology proposed has potential for high impact in investigations, such as the World Trade Center, where only dental records are available to aid in victim identification. Technically, the work will involve the creation of a pilot Digital Image Repository, include image manipulation (feature extraction, image enhancement), high-speed databases (archiving and matching), neural nets, and parallel computation using a network of workstations. The grantee will collaborate in this work with the FBI.","title":"Digital Government: Automated Dental Identification","awardID":"0131079","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["334363","209618",173560],"PO":["371077"]},"75208":{"abstract":"EIA-0221916<br\/>Menon, Madhu<br\/>University of Kentucky<br\/><br\/>TITLE: ITR Large Scale Quantum Mechanical Simulations of Nonomechanics<br\/><br\/><br\/>Large scale quantum mechanical simulations of nanomechanics of carbon<br\/>nanotubes involving atoms in excess of 10,000 is underway using a<br\/>collaborative effort involving material and computer<br\/>scientists. Parallel software tools are being developed to accomplish<br\/>this. The tools are based on a novel pipelined, parallel architecture<br\/>designed to harness grid computing. The goal of the simulations is to<br\/>study the potential benefits of nanomechanical applications of carbon<br\/>nanotubes and use the results to guide experimental investigations.","title":"ITR: Large Scale Quantum Mechanical Simulations of Nanomechanics","awardID":"0221916","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5979","name":"CENTRAL & EASTERN EUROPE PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["490281","550407"],"PO":["563727"]},"77639":{"abstract":"PROPOSAL NO.: 0234002<br\/>PRINCIPAL INVESTIGATOR: Bahar, Ivet<br\/>INSTITUTION NAME: University of Pittsburgh<br\/>TITLE: NIH-NSF BBSI on Simulation and Computer Visualization of Biological Systems at Multiple Scales<br\/><br\/>ABSTRACT <br\/> <br\/>This project is to develop a Bioengineering & Bioinformatics Summer Institute (BBSI) entitled NIH-NSF BBSI on Simulation and Computer Visualization of Biological Systems at <br\/>Multiple Scales. for undergraduate and graduate students with strong analytical and <br\/>quantitative skills, and high potential for careers in Computational Biology, Bioengineering, or Bioinformatics. The BBSI will be a joint program of the University of Pittsburgh (lead institution), the Pittsburgh Supercomputing Center, and Duquesne University, and will also include faculty from Carnegie Mellon University. A major strength of this academic community is the breadth and depth of experience with biological models and simulations, from molecular to multicellular, and from analytical approaches to massively parallel computing. <br\/> <br\/>The objectives are to: (i) provide students with a unique training and research <br\/>experience through a series of cross-disciplinary lectures, computational laboratory sessions, and independent research opportunities not available in traditional undergraduate programs; specifically, to present an integrated view of molecular-to-cellular analytical approaches and fundamental physicochemical, statistical mechanical, and kinetic principles needed for predictive theoretical and computational research; (ii) broaden the student's view of post-genomic computational and mathematical research areas in molecular, cellular, and systems biology, and (iii) motivate students to pursue careers in the field(s). <br\/> <br\/>Applicants will be accepted, from basic life or physical sciences, computer science, mathematics or engineering, and three first year graduate students. A ten-week program will encompass six weeks of lecture and computer lab coursework, three weeks of mentored research activity, and 1 week of student presentations. In addition, a weekly seminar series will cover a wide variety of related topics with presentations from local or invited outside experts, as well as discussions of scientific ethics and career opportunities. Student-organized journal clubs, and involvement of senior or graduate students in teaching activities will ensure efficient communication and contribute to professional growth.","title":"NIH-NSF BBSI on Simulation and Computer Visualization of Biological Systems at Multiple Scales","awardID":"0234002","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1994","name":"BIOINFORMATICS PROGRAM"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1340","name":"ENGINEERING EDUCATION"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"V096","name":"NIH-BIOENG & BIOINF SUMMER RES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"V604","name":"NIH-BIOENG & BIOINF SUM RES &T"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"V952","name":"NIH-SUMMER RESEARCH & TRAIN"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"W302","name":"NIH-SUMMER RES & TRAINING PROG"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1260","name":"INFRASTRUCTURE PROGRAM"}}],"PIcoPI":["305885"],"PO":["560483"]},"65429":{"abstract":"0124616<br\/>Morava<br\/><br\/>This award supports the participation of American scientists in a U.S.-Japan seminar on primes and knots to be held at the Johns Hopkins University in Baltimore, Maryland from March 15-22, 2003. The co-organizers are professors Jack Morava of the Johns Hopkins University and Professor Toshitake Kohno at the University of Tokyo in Japan. The theory of primes and the theory of knots are perhaps the most venerated branches of algebra and of topology, and in many ways, they are both still the most accessible. However, it is only relatively recently that researchers have begun to perceive deep relations between them, via analogies between the Galois groups of number fields and the fundamental groups of link complements. <br\/><br\/>The topic has the advantage of being approachable from many directions and on many levels. The theory of knots and the theory of primes are both intuitively accessible, and the participants expect this seminar to foster the development of a common language between researchers in these areas. A prime resembles a knot, and the ideal generated by an algebraic integer is like the boundary of an embedded surface. In both subjects, relations between abelian constructions such as Alexander invariants are relatively well-understood, and much current research centers on deeper nonabelian questions; for example, it is now known that {5, 41, 61} is the first set of Borromean primes (in which no two are nontrivially linked, but all three are). Seminar organizers have made a special effort to involve younger researchers and graduate students as both participants and observers. The exchange of ideas and data with Japanese experts in this field will enable U.S. participants to advance their own work, and will set the stage for future collaborative projects. Dissemination of information on the seminar will be available on the World Wide Web.","title":"U.S.-Japan Cooperative Research: Primes and Knots","awardID":"0124616","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5978","name":"EAST ASIA AND PACIFIC PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0507","name":"Division of SCIENCE EDUCATION RESOURCES IM","abbr":"SER"},"pgm":{"id":"1267","name":"TOPOLOGY"}}],"PIcoPI":[169335,"366850"],"PO":["449696"]},"71941":{"abstract":"This project aims at developing a survivability framework called PROMISE, which includes procedures for fault recovery for mission critical applications. The idea behind this framework is to divide an active path into several, possibly overlapping active segments, and then protect each active segment with a detour called backup segment. Thus the basic survivability concept is to provide local protection against faults impacting localized segments of the active path. The following research activities will be particularly pursued. First, the project team will investigate how to find the optimal (e.g. most band-width-efficient) active path segments and how to reduce the time complexity of the new survivability algorithms within the framework. For that purpose, new ILP formulations for solving the problems will be used to provide reference data, and a comprehensive study comparing the proposed approaches with other existing protection\/restoration approaches will be conducted. Second, the proposed research will include the investigation of the methods to support differentiated services within the framework, such as partially survivable, unprotected or preemptable connections. Finally, the project will elaborate on survivability issues specific to optical networks based on WDM (Wavelength Division Multiplexing) and IP under the Generalized Multi-protocol Label Switched (G-MPLS) framework, where new algorithms and simulation tools PROMISE are expected to be developed. The project will bring together networking research and theoretic computer science research, and in addition, by incorporating research into educational and training activities will create awareness and interest among students on the issues related to survivability in next-generation communication networks.","title":"PROMISE: A Novel Survivability Framework for High-Speed Networks","awardID":"0208331","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["511691"],"PO":["565090"]},"81533":{"abstract":"Space-Time Coding for Wireless Communications<br\/>Michael P. Fitz and Urbashi Mitra<br\/>Proposal 9980616,<br\/>The Ohio State University<br\/><br\/> This research will extend the state of the art in channel coding for<br\/>multi-antenna communication systems. It has recently been shown that<br\/>the capacity of a wireless communications system can be greatly<br\/>increased if multiple antennae are used both at the transmitter and the<br\/>receiver. Furthermore, a method for achieving such gains is to<br\/>introduce controlled redundancy (coding) in the transmitted data<br\/>sequence spatially as well as temporally, which is the conventional<br\/>scheme. This area of research is still quite new and several key<br\/>problem areas need to be addressed. For example, computationally<br\/>efficient methods for finding space-time codes are necessary. <br\/>Typically, the wireless channel is time-varying and it is not always<br\/>possible to achieve good estimates of the channel conditions; thus<br\/>evaluating the robustness of space-time codes is of value. A related<br\/>project is to consider the interplay of space-time coding and decoding<br\/>methods with algorithms designed to estimate the channel and other key<br\/>communication parameters. Turbo codes have recently emerged as<br\/>powerful codes for achieving near Shannon capacity, thus space-time<br\/>generalizations of such codes will be studied. Finally, much of the<br\/>current work on space-time coding is for narrowband time division<br\/>multiple access systems, thus we shall consider space-time code design<br\/>and decoder design for wideband code-division multiple-access systems<br\/>as well.<br\/><br\/> The first research thrust will focus on the development and analysis<br\/>of improved search techniques for space-time trellis codes. Current <br\/>methods for searching the distance spectrum of space-time trellis codes <br\/>can be computationally expensive. Methods for reducing the size of the <br\/>error state trellis coupled with reduced complexity trellis search schemes<br\/>will be explored. The next focus is on evaluating the robustness of space-time<br\/>codes under realistic channel conditions. In addition, space-time coding <br\/>for parametric channels will be considered. Thus, constrained channel <br\/>uncertainty will exist and code designs for such scenarios will be developed.<br\/>The third research focus will be on space-time turbo codes as one method to <br\/>achieve robustness to a variety of channel conditions. The random--like <br\/>structure of turbo coded schemes hold some promise of mitigating the possible <br\/>interactions between the code structure and the channel characteristics.<br\/>Space-time code designs for CDMA channels will be investigated in the <br\/>fourth research thrust. CDMA signals have a larger dimensionality and<br\/>thus the space-time code design is different from that for single-user <br\/>systems. In addition, CDMA signals in a multipath channel will result <br\/>in different optimal code designs. The final research topic will consider <br\/>receiver designs in the context of space-time coding. That is, channel <br\/>estimation and synchronization for space-time coding and modulation will<br\/>be investigated. Algorithms which exploit the properties of space-time<br\/>codes will be designed. In addition, the performance dependence on accurate<br\/>channel estimates and synchronization will be analyzed.","title":"Space-Time Coding for Wireless Communications","awardID":"0304470","effectiveDate":"2002-09-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["282307"],"PO":["348215"]},"73713":{"abstract":"EIA-0215836<br\/>Gary C. Lewandowski<br\/>Michael Goldweber<br\/>Elizabeth L. Johnson<br\/>Xavier University<br\/><br\/>MRI\/RUI: Acquisition of Wireless, Beowulf, and Distributed Computing Clusters<br\/><br\/>This proposal from an REU institution, establishing a parallel and distributed computing research laboratory for CS faculty and students, includes <br\/> An ad hoc mobile network cluster (handheld PDA and labtops connecting without a server),<br\/> A Beowulf cluster ( a parallel computing cluster composed of off-the-shelf PCs with fast network connections between them), and<br\/> Workstations connected in typical network style.<br\/>With specific research activities that follow, the clusters will support the following areas:<br\/>A. Parallel and Distributed Computation on Ad Hoc Networks<br\/>1. Development of a serverless location protocol<br\/>2. Development of parallel applications for ad hoc networks on top of serverless SLP, and<br\/>3. Utilizing idle cycles of wireless devices<br\/>B. Parallel Algorithms for Graphs Coloring and Applications<br\/>1. Graph coloring heuristics<br\/>2. Historical study of the four-color theorem<br\/>C. Parallel Genetic Algorithms (an optimization techniques based on the idea of \"survival of the fittest\")<br\/>D. Language Support for Distributed Computing over Heterogeneous Networks <br\/>(support for distributed data structures in High Performance C++)<br\/>E. Distributed Database Systems<br\/>F. Distributed Virtual Shared Memory Architectures<br\/>G. High-Energy Astrophysics<br\/>H. Dynamics of complex systems<br\/>Depending on the configuration needed for a particular application, the three clusters will be combined into one heterogeneous distributed network or used as stand-alone parallel\/distributed networks.","title":"MRI: Acquisition of Wireless, Beowulf, and Distributed Computing Clusters","awardID":"0215836","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["233767","527435","532652"],"PO":["557609"]},"70699":{"abstract":"TITLE: Supporting Compiler\/Simulator Co-Evolution for Architectural Exploration and Evaluation<br\/><br\/>The project will address these issues by building a system that constructs key optimizer and simulator components from a common architectural description. Prior work in generating compilers or simulators using only formal architecture descriptions had not succeeded in producing systems capable enough for real work. That difficulty will over-come by not insisting on fully automatic construction. Rather, the project focuses on making it easier for researcher and engineers to extend and modify key components using more specific model descriptions and a flexible, extensible framework. Rather than building components from scratch, makes it easier to evolve components: incremental architectural changes should require incremental effort to support. This is a co-evolution approach since one must evolve both simulators and compilers optimizers simultaneously and consistently.","title":"Supporting Compiler\/Simulator Co-Evolution for Architectural Exploration and Evaluation","awardID":"0203895","effectiveDate":"2002-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["550864","517880"],"PO":["301532"]},"74714":{"abstract":"A new, completely-integrated processor-memory-interconnect (CI-PMI)<br\/>architecture model suitable for a range of data-intensive<br\/>applications is proposed. Compared to the existing processor-in-memory<br\/>(PIM) architectures, the proposed CI-PMI approach integrates more<br\/>completely the processing, memory, and interconnect. This is achieved<br\/>by starting with the classical architecture of high capacity memory,<br\/>namely, a binary tree of decoders with memory modules as leaves, laid<br\/>out as an H-tree. In the proposed model, copies of one or more types<br\/>of application-specific computing elements are added at different<br\/>levels of the memory decoder tree, desired functionality added to the<br\/>memory decoders to augment their role as interconnects as well as to<br\/>support desired computation, and, if necessary, additional interconnects<br\/>added between the application-specific processors, the memory modules,<br\/>and the decoders. The proposed architecture will be developed and<br\/>demonstrated for a data-intensive application, namely motion estimation<br\/>for MPEG encoding.<br\/><br\/>The results of the proposed research will be used to augment one<br\/>advanced class, to be taught at USC as well as UCI. The class will<br\/>take a top-down view of advanced processor-in-memory architectures<br\/>including those developed in this project.<br\/><br\/>The proposed research will advance the state of the art in computer<br\/>architecture, VLSI, and VLSI CAD, leading to faster and cheaper designs<br\/>for day to day computation and information retrieval, exchange, and<br\/>management.","title":"ITR: A Completely Integrated Processor-Memory-Interconnect Architecture for Data Intensive Applications","awardID":"0220106","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["475291","535238"],"PO":["562984"]},"74725":{"abstract":"Hardware-based approaches to accelerate CPU intensive operations that<br\/>arise in the context of non-standard database applications are<br\/>proposed. Two hardware technologies, namely, off-the-shelf graphics<br\/>cards and content addressable memories (CAM) that are used in<br\/>contemporary Network Routers for very fast lookups are identified.<br\/>The graphics functionality designed primarily for display applications<br\/>can be exploited for polygon intersection in spatial databases and for<br\/>distance-based query processing. Content addressable memories (CAM)<br\/>can be gainfully deployed for accelerating join operations in<br\/>databases. In the context of new database applications, the join<br\/>constraint which is generally based on equality is being expanded to<br\/>encompass other conditions such as set-containment. The major goal of<br\/>this research is to develop a general framework for enabling<br\/>fine-grained hardware acceleration within a commercial DBM","title":"ITR: Hardware Acceleration of Database Operations","awardID":"0220152","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["536696","500153"],"PO":["563727"]},"74615":{"abstract":"Efficient reasoning about three-dimensional visibility is a challenging problem in many research areas and applications, including computer graphics (radiosity, virtual reality walkthroughs), robotics (sensor-based navigation, visual surveillance), computer vision (recognition, model building), architecture, urban planning, and visualization in computational biology. Visibility issues have been considered for four decades in these areas however, most early work has focused on computing visibility from a single viewpoint, while modern techniques require more global visibility information. Global visibility describes the visibility relationships etween objects that are more complex than points: visibility from a volumetric region of space, limits of umbra and penumbra with respect to an extended light source, mutual visibility etween pairs of objects, and loci of structural changes of visibility.<br\/><br\/>Although great strides have een made in understanding visibility through the introduction of visibility space partitions and the visibility complex, they have so far had little impact on applications. This is due to several reasons: 1) worst-case theoretical complexity bounds are discouraging 2) there are many degenerate cases that must be handled, making it difficult to make robust implementations 3) equivalences in visibility lead to a four-dimensional cell decomposition, which is difficult to visualize 4) cells can be extremely complicated (some include holes).<br\/><br\/>This work will make 3D visibility computations practical by approaching the problem in two parallel, integrated tracks. One involves the investigation of several key issues that will make 3D visibility algorithms more attractive and practical in applications: 1) performing practical complexity analysis that captures the expected performance for models that are typically used in applications, as opposed to theoretical worst-case ounds derived from uncommon pathological cases 2) rather than taking a generic \"precompute and return everything\" approach, we would like the amount of precomputation, information stored in data structures, and extraction algorithms to be nicely tailored to the number of queries and the type of information arises in a particular application 3) traversal through the space of visibility rays will be facilitated through the development of decomposition algorithms based on critical events and Morse theory 4) we will develop techniques for reasoning about the evolving shadow space (set of points not visible), which is required for many problems that involve moving viewpoints.<br\/><br\/>The second track involves the development of a 3D visibility library ased on robust visibility primitives. We expect to make an immediate impact on applications by making this library available for free to other researchers. The library will serve both as a helpful visualization and evaluation tool during the development of the research, and as a way to stimulate other interest and applications of 3D visibility after the work is completed. This effort, combined with the understanding gained from investigating the key visibility issues, is expected to make a broad impact on a wide array of applications that depend on efficient processing of visibility information.","title":"ITR: Making 3D Visibility Practical","awardID":"0219594","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["517378","468851","553248"],"PO":["532791"]},"71106":{"abstract":"ABSTRACT<br\/><br\/>The establishment of unlicensed communication bands has successfully encouraged innovation, most recently in wireless devices and infrastructure that use unlicensed spectrum to provide connections to the Internet. A key aspect of Internet usage is an almost unlimited capacity for growth. For unlicensed wireless, the transition from 11 Mb\/s 802.11b to 54 Mb\/s 802.11a marks the start of an industry race toward ever-higher data rates. The combination of increasing data rates and a proliferation of devices could easily lead to inefficiency in the use of unlicensed spectrum due to a combination of overuse and failure to develop mechanisms for efficient sharing of this resource. While the overload of any finite band may be inevitable, this project is addressing the increase in capacity of the available unlicensed bands as much as possible, and is developing approaches that can predict overloads and prevent sudden, unexpected failure modes.<br\/><br\/>This multi-disciplinary project seeks efficient use of unlicensed spectrum by combining an engineering and technology perspective with insights from the literatures on regulation, property rights, and economic coordination. The team includes researchers with expertise in property rights, networking fairness, and wireless communications and network engineering. This team is developing a general framework for understanding cooperation in unlicensed band wireless networks by studying the following issues:<br\/><br\/>Property rights as applied to spectrum management<br\/>Protocols for collaboration between technology neutral wireless devices<br\/>Pricing mechanisms for efficient and fair sharing of congested unlicensed spectrum<br\/>Radio-level interference avoidance techniques<br\/><br\/>The above problems are being studied with a combination of formal and conceptual analysis, simulation and experimental methods, including a dynamic spectrum management testbed which implements potential collaboration protocols and cooperation models. The thrust is to preserve the \"creative chaos\" of the unlicensed bands while creating a degree of long term stability and predictability that is appropriate to the size of the investments being made and the strategic importance of these uses to the nation. Results from the project are of value to both policy makers and emerging unlicensed band wireless Internet providers as well as wireless technologists.","title":"ITR: Collaborative Research: Achieving Innovative and Reliable Services in Unlicensed Spectrum","awardID":"0205362","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["564746","463100","475434","466323","348167"],"PO":["348215"]},"71117":{"abstract":"ABSTRACT<br\/>0205625, 0205118, 0205429, 0205627 <br\/><br\/>TITLE: Collaborative Research: ITR: Acquiring Accurate Dynamic Field Data Using Lightweight Instrumentation<br\/><br\/>Dynamic analyses, such as testing and profiling, play a key role in state-of-art approaches to software quality assurance (QA). With rare exception, these analyses are performed in-house, on developer<br\/>platforms, using developer-provided input workloads. Shortcomings of this approach include that the results simply cannot be rusted to tell us how the software actually performs in the field.<br\/><br\/>The project goal is to give developers unprecedented insight into the actual runtime behavior of their software, allowing developers (and ultimately the software itself) to change, optimize, and adapt the software based on highly accurate field data. Lightweight, collaborative dynamic analyses conducted around-the-world and around-the-clock form the new platform: (1) lightly instrument fielded software (i.e., each program copy performs a small part of the analysis) (2) collect the partial data from many instances of the software, fusing it to conduct the complete analysis, (3) change the running program instances based on the findings and (4) repeat the process.<br\/><br\/>Seven critical research challenges form the core of the project: <br\/>1. Lightweight instrumentation--Develop instrumentation that is virtually transparent to individual users. 2. Compositional analysis techniques--Develop distributed analysis techniques that decompose<br\/>traditional analyses into smaller steps, distribute the steps among multiple users, and then fuse each user's results into an accurate solution to the original problem. 3. Scalability--Develop storage and analysis techniques to deal with the high data volumes we expect to encounter. 4. Anomaly Detection--Define data-driven techniques to automatically identify anomalous behaviors of deployed software. 5. Privacy and Security--Incorporate privacy and security safeguards into our data collection and analysis approaches. <br\/>6. Dynamic updating mechanisms--Develop techniques to make runtime changes to the location and function of instrumentation, and to parts of the software itself. 7. Validate approach on industrial software.","title":"Collaborative Research: ITR: Acquiring Accurate Dynamic Field Data Using Lightweight Instrumentation","awardID":"0205429","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["450771"],"PO":["564388"]},"76705":{"abstract":"This proposal is to cover expenses associated with hosting the Digital Libraries Initiative All Projects Meeting in June 2001. The All Projects Meetings have been held semi-annually since the program's inception in 1994 and have been essential to building collaborations between funded projects, establishing and maintaining program identity and direction, and stimulating valuable personal interactions between researchers, graduate students, and information professionals from all sectors. The meeting agenda is structured to allow projects to report and demonstrate research products, and discuss and assess the relative merits and promise of new capabilities.","title":"Digital Libraries Initiative Principal Investigators Meeting at JCDL 2002","awardID":"0229879","effectiveDate":"2002-09-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["289873"],"PO":["564456"]},"75616":{"abstract":"EIA 0224392<br\/> Terveen, Loren<br\/> Konstan, Joseph A.<br\/> Riedl, John<br\/>Shekhar, Shashi<br\/> University of Minnesota Twin Cities <br\/><br\/>Title: CISE RR: Being There: Mobile Devices for Community and Commerce <br\/><br\/>This project, building a mobile computing system, provides a set of mobile, connected, location-aware computing units consisting of Personal Digital Assistants (PDAs) and wearable displays with some input ability to allow experimentation to affect deployment on the types of interfaces, applications, and technologies needed as these devices become commonplace. Devices will carry out a wide range of experimentation, from tightly controlled experiments to broad field studies, from previously planned extensions of existing research to last-minute ideas created by student projects, and from small pilot studies to large deployment studies. The infrastructure supports research projects in human computer interaction (HCI), recommender systems, and spatial data management for environments where users are mobile; specifically, <br\/>Ubiquitous Peripheral Social Interaction (UPSI), <br\/>Location-Aware Recommender Systems, and<br\/>Spatial Data Management for Location Aware Mobile Computing.<br\/>The first project presumes availability of several wireless communication channels. Information, at the periphery of users' attention, is constantly streamed to the device and displayed as a scrolling \"ticker.\" A user carries a pocket computer and wears a Networked Wrist Device linked by Bluetooth. This approach presents challenges in populating and managing the information model driving the interaction, designing the interface for the networked wrist display, coupling the wrist computer and PDA, and identifying the types of tasks for which this interaction paradigm is suitable. Using algorithmic and interface research, pilot tests, real-world experiments, and metrics, the second project looks into suitable applications among wired, disconnected, and wireless connected recommenders. Given local and temporal patterns of users, this project examines when it is appropriate to interrupt its user with a recommendation, how to present recommendations most effectively across multi-device interfaces, and how to compute recommendations when the user is disconnected from the network. The last project looks into the requirements of spatial data management systems for applications like mobile location based recommendation systems. The project gathers a trace-based workload from location aware recommendation systems to evaluate solutions for critical design decisions such as algorithms for map compression and predictive pre-fetching strategies to cache relevant segments of maps based on past spatial queries, scheduled meetings locations, and related information. The educational plan includes integration of the platform into courses and student involvement in summer internships.","title":"CISE Research Resources: Being There: Mobile Devices for Community and Commerce","awardID":"0224392","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["550903","483488","550380","518491"],"PO":["557609"]},"74406":{"abstract":"Many computational problems of practical interest can be posed in terms of search. Examples include discrete optimization problem that arise naturally in many areas of science, engineering and business. The development of a robust network infrastructure coupled with the advent of reasonably-priced computing equipment has helped focus attention on techniques that use multiple processors operating in parallel to improve search performance. Our research focuses on the design, development, implementation and evaluation of scalable, fault-tolerant, distributed search technique and their application, generally in concert with other optimization techniques, to construct hybrid optimization systems. <br\/><br\/>Much of the work described here relies on a unique underlying parallelization paradigm of our own design called nagging. It contrast to more traditional problem partitioning techniques, nagging plays mutiple reformations of a problem --- or portions of a problem --- against each other to improve performance. We will improve and refine our understanding of nagging, including research on adaptive strategies for combining nagging and partitioning strategies; to improve and refine our distributed search infrastructure, including, for example, the use of cryptographic protocols to support authentication and distribution of new applications across management boundaries; and to continue our interdisciplinary collaborative efforts to apply distributed search concert with other optimization techniques to scientific computing problems.","title":"ITR: Distributed Hybrid Optimization Techniques with Applications to Proteomics and Genomics","awardID":"0218491","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["439675"],"PO":["565272"]},"72008":{"abstract":"Recent advances in microbiology such as cloning demonstrate that increasingly complex micromanipulation strategies for manipulating individual biological cells are required. From a robotics standpoint, the manipulation of biological cells presents several interesting research issues which extend well beyond biomanipulation. Biological cells are highly deformable objects, and the material properties of these objects are not well quantified, so developing strategies for manipulating deformable objects must be addressed. Most biological cells are between 1 and 100 microns in diameter, depending on the cell type, so micromanipulation issues must be explored, including the appropriate use of high resolution, low depth-of-field vision feedback and very low magnitude force feedback. Although multi-axis force sensing capabilities would be useful for handling cells by providing information on injection forces as well as tangential forces generated by improperly aligned cell probes, no sensors capable of multi-axis force sensing at the force scales required are available. Robotic devices capable of complex manipulation of biological cells do not exist, and robotic systems capable of integrating a variety of novel sensory information for cell manipulation have not been created. By pursing robotic manipulation of biological cells, many interesting robotics research avenues in micromanipulation, deformable object handling, multi-sensor integration, and force and vision feedback assimilation must be explored. In this project, an autonomous microrobotic system capable of manipulating individual biological cells using real-time vision and force feedback is being developed, and the micromanipulation of deformable biological cells are being investigated.","title":"Microrobotics for Biomanipulation","awardID":"0208564","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["196704","564470","488578"],"PO":["335186"]},"75638":{"abstract":"EIA - 0224458<br\/>Cavallaro, Joseph R.<br\/>Aazhang, Behnaam <br\/>Frantz, Jeremy P.<br\/>Knightly, Edward W.<br\/>Sabharwal, Ashutosh<br\/><br\/>Rice Universiy<br\/><br\/>Title: CISE RR: A Comprehensive Multi-tier Wireless Network Development Platform <br\/><br\/>This proposal, developing an infrastructure within the Center for Multimedia Communication (CMC)<br\/>to enable repeatable fields' experiments in the laboratory, aims to develop integration techniques beyond simulations and other modeling. Using actual field measurement in its emulation, the infrastructure fills a gap to experimentally validate theoretical results under real-world conditions promising seamless wireless content delivery (without any service disruptions). The equipment, mainly consisting of two channel emulators, a logic analyzer, and a spectrum analyzer, benefits three major projects.<br\/>Reconfigurable Wireless Architectures,<br\/>High Data Rate Multiple Antenna Communication, and<br\/>Opportunistic Multi-Tier Wireless Scheduling.<br\/>The first project involves the design of new communication architectures that reconfigure based on the network availability, channel conditions, and data requirements of a handset. The infrastructure will enable a complete suite of efficient prototypes, which will simultaneously connect to next generation wireless LANs, third generation wireless cellular, and Bluetooth personal area networks (PANs), bringing closer the ideal ability of a single device to seamlessly maintain its link to the network using whatever connectivity is available. The second project develops new communications coding and feedback methods for high data rate wireless access by prototyping new algorithms with multiple transmit and receive antennae on reconfigurable baseband platform and stress tested in different wireless configurations for their robustness, performance limits, and power efficiency. The last project involves the design of optimal methods for scheduling data using all the resources available by a multi-tier network, including other mobile nodes connecting the backbone infrastructure. The packet schedulers are being prototyped on a mobile network processor platform and will use the multi-tier network interface (mNIC) prototype developed within CMC in its field trials.<br\/>On the educational side, students will continue their research on these projects, and new developments captured for new courses. Rice University is quite active with under-represented groups.<br\/>.","title":"CISE Research Resources: A Comprehensive Multi-Tier Wireless Network Development Platform","awardID":"0224458","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["542042","50058","548310","548311","312197"],"PO":["557609"]},"77827":{"abstract":"ABSTRACT<br\/>0234690<br\/>Interfaces and Model Checking for Software<br\/>PI: Luca de Alfaro<br\/><br\/>When software is used in critical applications, errors that go undetected in the design phase and occur during actual system operation can have disastrous consequences. The proposed research focuses on the development of techniques for software verification based on the joint use of<br\/>model-checking and interface theories.<br\/><br\/>Software model-checking constructs and analyzes finite abstractions of the software, refining the abstractions until they can be shown to satisfy a property, or until errors are found in the software.<br\/>Interface theories permit the specification of the interaction behavior of software components.<br\/>The proposed research will combine these two techniques into a scalable and compositional approach to software verification, where model-checking is used to analyze individual software components, and interfaces are used to specify and verify the interaction between the<br\/>components in a design. <br\/>The approach will be applied to the verification of the NASA MDS testbed.<br\/><br\/>The intellectual merit of the proposed project consists in the<br\/>development of a compositional approach to software verification based<br\/>on the joint use of methods for single-component and<br\/>multiple-component analysis.<br\/>The broader impact consists in the development of tools and approaches<br\/>for the design-time validation of software, thereby increasing both<br\/>dependability and quality of software systems.","title":"Interfaces and Model Checking for Software","awardID":"0234690","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"W379","name":"NASA-HIGHLY DEPENDABLE COMPUTI"}}],"PIcoPI":["384064"],"PO":["564388"]},"65859":{"abstract":"Clustering technologies enable incremental scaling of Internet server sites at modest cost. It is increasingly common in cluster-based service architectures to distribute incoming request traffic among servers using redirecting intermediaries integrated into the network switching fabric or interposed between the client and servers. However, Internet services and their delivery architectures continue to evolve rapidly. This creates new challenges and opportunities for redirecting intermediaries, and motivates basic research in both the mechanisms for request redirection and the request routing policies for specific service environments.<br\/><br\/>This work will undertake a coordinated research program to expand the potential of redirecting intermediaries as an enabling technology for scalable Internet services. The work focuses primarily on integrating service-aware redirection and request routing as network-level functions in a high-speed switching architecture. The methodology combines simulation, construction of software prototypes, and evaluation of prototypes using synthetic and real workloads.<br\/><br\/>The expected outcomes of the work are: <br\/> An improved understanding of the role of request routing as an enabler for large-scale Internet services, <br\/> Simulation results evaluating these policies in large systems, <br\/> Software prototypes that demonstrate the value of these solutions in practice for Web-based services and network storage services, and <br\/> Opportunities to train students as participants in this research at both the graduate and undergraduate levels. <br\/><br\/>In summary, the research work has the following basic objectives:<br\/><br\/>1. Define protocol features essential for redirection at the level of the transport protocol. The switch routes incoming requests on each transport connection to any active server at the discretion of a service-specific routing policy; referred to as Anypoint communication.<br\/><br\/>2. Implement an Anypoint-capable transport protocol that supports features commonly required by service protocols: reliable communication, ordering and duplicate suppression, and congestion control.<br\/><br\/>3. Define interfaces and capabilities for service-specific policy modules in Anypoint intermediaries. This defines an architecture for decomposing service protocol implementations into a client, a server, and service module to extend the intermediary.<br\/><br\/>4. Evaluate the intermediary architecture defined by Anypoint by constructing software prototypes of virtualized service implementations. The initial targets are HTTP 1.1 application services and NFS.","title":"Request Routing for Scalable Services","awardID":"0126231","effectiveDate":"2002-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["553906","485593"],"PO":["565090"]},"67509":{"abstract":"Proposal Title: PECASE: Multi-antenna communications: Information theory, codes and signal processing<br\/>Institution: California Institute of Technology<br\/><br\/>It is now widely recognized that multiple antennas will figure prominently in future wireless communications systems, since they can significantly boost the channel capacity, as well as lower the probability of error, of a wireless communications link. However, before the above promise can be realized in a practical communications system, there are several key research challenges that must be addressed. This research studies several of the information-theoretic, coding-theoretic, and signal processing challenges encountered, as well as the impact of integrating their solutions into a multi-user wireless network. A common thread encountered throughout is that the tools developed, as well as the results obtained, have implications well beyond multi-antenna communications--both in terms of the introduction of new mathematical methods, as well as in terms of their applicability to more general communication problems.<br\/>The first research challenge addressed is information-theoretic: the actual channel capacity of a multi-antenna wireless link is known only under certain idealized conditions. For most realistic conditions, the channel capacity is unknown and it is not clear how it depends on the speed of the fading, the number of antennas, and the SNR. Nor is it clear what the optimal transmission strategies should be and what the performance of training-based schemes are. This research will focus on these problems for continuously- and block-fading channels, where the analysis appears to be tractable and where the theory of random matrices plays a major role. The second challenge is that of designing space-time codes that deliver on the high data rates promised by theory, have good error performance, and that lend themselves to efficient encoding and decoding. Compared to conventional codes, the added spatial dimension adds a whole new twist to the code design problem, and a variety of information-theoretic, linear-algebraic, and group-theoretic ideas play a prominent role. The signal processing research challenge is to devise algorithms that are efficient, so that all the processing can be done in real time. Recent work by the researcher has analytically demonstrated that, for a wide range of rates and SNRs, polynomial-time maximum-likelihood decoding of several classes of space-time codes is possible. This research will fully pursue the implications of this result, both in terms of the design of new algorithms and codes, as well as in terms of understanding the tradeoffs between maximum-likelihood performance and computational complexity.<br\/><br\/>This project was originally funded as a CAREER award, and was converted to a Presidential Early Career Award for Engineers and Scientists (PECASE) award in May 2004.","title":"PECASE: Multi-antenna Communications: Information Theory, Codes and Signal Processing","awardID":"0133818","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["451966"],"PO":["564898"]},"70721":{"abstract":"EIA-0203958 Anupam Joshi University of Maryland-Baltimore County Agent Oriented Approaches to a Ubiquitous Grid<br\/><br\/>At the level of computing and networking hardware we will see dramatic changes in the next few years. Computing will become pervasive. These developments will lead to wireless networks that will scale all the way from ad hoc body area networks to satellite WANs, and link together supercomputers, \"palmstations\" and embededded sensors & controllers.<br\/><br\/>Given this scenario, our proposed research will seek to extend the computational grid by making it ubiquitous and pervasive. In particular, we will develop agent based runtime systems where each component is autonomous, articulate, social and adaptive. Such a system will seamlessly partition computation across elements of the grid ranging from palmtops to supercomputers. Issues that we will investigate include (i) Component\/Service Discovery, (ii) Dynamic Composition of components, and (iii) computation partition across highly asymmetric and heterogeneous systems.","title":"NGS: Agent Oriented Approaches to a Ubiquitous Grid","awardID":"0203958","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5980","name":"WESTERN EUROPE PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["563576","533183","421169"],"PO":["301532"]},"73824":{"abstract":"EIA-0216137<br\/>Rahul Simha<br\/>George Washington University<br\/><br\/>MRI: Acquisition of Research Infrastructure for Distributed Sensor Applications in the Home of the Future<br\/><br\/>This proposal, developing an infrastructure for applications that can exploit a network of sensors and actuators in the home environment, extends work already in progress on future technologies aiming at launching a long-term research program around the Home-21 theme with a broader base of applications and a stronger research focus. Applications (with respective examples) involve:<br\/>1. Sensors distributed around the home (detecting intrusion),<br\/>2. Sensors on an occupants (helping monitor infirm or disabled occupants), and<br\/>3. Sensors on a service provider (helping a fireman navigate a burning home).<br\/>Faculty with research interests in networking, human-computer interaction, MEMS devices, sensors and biomedical engineering will collaborate on a single infrastructure to support these classes of applications. Although the theme centers on the home of the future, the infrastructure and applications apply to other living environments including, for example, hotels, dormitories, offices, ships, and assisted-living facilities. Special attention will be devoted to applications that will use sensors and actuators on occupants at multiple level of granularity, coarse-grained (location of occupant within the house) and fine-grained (movement of limbs). Such applications involve placing sensors on the occupant that are wireless connected to algorithms that track movement and can, in some cases, also send location-specific feedback (via the actuators) in accordance with the desired objective. Ancillary projects involve Safety (falls, fire, etc.), Security (intrusion monitoring), Health Monitoring Measuring (measuring telemedicine applications, monitoring and relaying vital signs), and RF monitoring (controlling harm from electromagnetic radiation). The equipment, including magnetic trackers, wireless equipment, RF analyzer and software, and support equipment, serves as a testbed for senior design students. Hence, a key component is its focus for undergraduate research and training.","title":"MRI: Acquisition of Research Infrastructure for Distributed Sensor Applications in the Home of the Future","awardID":"0216137","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["562052"],"PO":["557609"]},"74605":{"abstract":"Reducing energy consumption is a key challenge in the design of modern microprocessors. Until recently, the primary source of energy dissipation in CMOS microprocessors has been the dynamic switching of load capacitances, but with continuing reductions in feature size and the accompanying reductions in threshold voltage, static leakage power is increasing exponentially. Most leakage power is dissipated on critical paths, especially after slower, low-leakage transistors are used on non-critical paths. To reduce leakage energy further, it is necessary to dynamically deactivate the fast leaky transistors on critical paths when they are not needed.<br\/><br\/>This project is developing fine-grain dynamic leakage reduction techniques, whereby small pieces of an active processor are put to sleep for short periods of time. The project is investigating circuit-level leakage reduction technique that have low sleep transition energy and rapid wakeup times, together with micro-architectural and compiler techniques that increase the sleep time of micro-architectural components without impacting performance or dynamic power dissipation. Accurate static power models that capture the sleep-time dependence of leakage energy are being developed for use with architectural simulators. This work enables a new class of limited critical activity architectures, where fast but power hungry logic can be selectively enabled to speed critical paths while limiting overall power consumption.","title":"ITR: Fine-Grain Dynamic Leakage Reduction for Microprocessors","awardID":"0219545","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["292937"],"PO":["562984"]},"71107":{"abstract":"Pnueli, Emerson, and Sistla<br\/>CCR-0205571, CCR-0205483 and CCR-0205365<br\/>\"Towards a Seamless Process for the Development of Embedded Systems\"<br\/><br\/><br\/>Embedded systems are of vital economic importance and are literally<br\/>becoming ubiquitous. They have already become an integral component of<br\/>safety critical systems involving aviation, military,<br\/>telecommunications, and process control applications. Interest in<br\/>embedded systems is growing further due to the expectation that they<br\/>will become a key component of many commonplace consumer appliances.<br\/>Consumers will expect levels of reliability and predictability<br\/>associated with the very best brands of cars, televisions, and<br\/>refrigerators. Glitches, crashes, and general erratic behavior of the<br\/>sort seen with prior generations of consumer PC software products will<br\/>be unacceptable for these embedded applications. It thus becomes<br\/>crucial that these embedded software systems satisfy high levels of<br\/>correctness criteria, well above those of today's large software<br\/>systems, which are often highly error-prone.<br\/><br\/>Besides the requirement of a new standard of functional correctness,<br\/>embedded systems pose additional challenges which were not fully<br\/>addressed by previous validation and verification approaches. These<br\/>include adequate guarantees of timeliness, low or controlled power<br\/>consumption, and low or controlled memory utilization. With the<br\/>spread of embedded systems, and the need to guarantee an acceptable<br\/>level of functionality and reliability of the applications they are<br\/>embedded in, the industry needs an effective and reliable development<br\/>process. Due to market constraints, such a process should also support<br\/>a fast turn-around time as well as enable the easy design of many<br\/>customized variations of the same product.<br\/><br\/>This project is developing the foundation for a seamless design<br\/>process for embedded systems as described below. In particular, it is<br\/>developing:<br\/><br\/> A formal visual language for requirements, including behavioral,<br\/> temporal, and TPM constraints;<br\/><br\/> A methodology for the automatic synthesis of an executable<br\/> specification from the requirement specification language;<br\/><br\/> A methodology for the verification of the intermediate and<br\/> distributed representation of the systems against requirements;<br\/><br\/> A methododology for automatic code-distribution of<br\/> specifications, possibly with some architectural constraints<br\/> provided by the user;<br\/><br\/> A model for representing hardware\/software co-design<br\/> platforms that enables modeling of both loosely- and tightly-coupled<br\/> components as well as compositional reasoning about them;<br\/><br\/> Algorithms for automatically generating <br\/> architecture-optimized code from executable specifications;<br\/><br\/> Methods for translation validation of the<br\/> generated code and run-time validation on the system using<br\/> monitors;<br\/><br\/> The Design of a profiler process which analyzes machine code,<br\/> computes the resulting figures for time, power, and memory, and<br\/> back-associate these figures with their executable specification<br\/> sources, enabling early-stage analysis of these requirements.<br\/><br\/>The impact of the project is to streamline and significantly<br\/>accelerate the time to market of embedded applications of both new<br\/>products and revisions and customizations of existing product lines.<br\/>Another impact is to upgrade the level of dependability and<br\/>predictability of embedded software to new standards, compatible and<br\/>comparable to those expected from the best brands of consumer<br\/>products.","title":"ITR: COLLABORATIVE RESEARCH: Towards a Seamless Process for the Development of Embedded Systems","awardID":"0205365","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["550555"],"PO":["561889"]},"74748":{"abstract":"Automatic Analysis of Spontaneous Facial Expressions<br\/>Abstract<br\/>The goal of this project is to develop computer systems for automatic analysis of spontaneous facial expressions, with a focus on the scientific study of the role of facial expressions in deception. A state-of-the-art digital video database of spontaneous facial expressions will be developed. This database will be hand-coded by behavioral scientist experts on facial expressions. This database will be used to develop an array of software tools for automatic analysis of facial expressions from video sequences. These tools will be developed by machine perception scientists in close collaboration with behavioral scientists and will be evaluated and refined for application to the scientific study of facial expressions.<br\/><br\/>The machine perception community is in critical need for standard video databases to train and evaluate systems for automatic recognition of facial expressions. This project will provide one such database and thus could potentially accelerate research in this field. Automated recognition systems would have a tremendous impact on basic research by making facial expression measurement more accessible as a behavioral measure, providing data on the dynamics of facial behavior at resolutions that was previously unavailable. Such systems would also lay the foundations for computers that can understand this critical aspect of human communication.","title":"Collaborative Research: ITR: Automatic Analysis of Spontaneous Facial Expressions","awardID":"0220230","effectiveDate":"2002-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["349177"],"PO":["565227"]},"71118":{"abstract":"ABSTRACT<br\/><br\/>The establishment of unlicensed communication bands has successfully encouraged innovation, most recently in wireless devices and infrastructure that use unlicensed spectrum to provide connections to the Internet. A key aspect of Internet usage is an almost unlimited capacity for growth. For unlicensed wireless, the transition from 11 Mb\/s 802.11b to 54 Mb\/s 802.11a marks the start of an industry race toward ever-higher data rates. The combination of increasing data rates and a proliferation of devices could easily lead to inefficiency in the use of unlicensed spectrum due to a combination of overuse and failure to develop mechanisms for efficient sharing of this resource. While the overload of any finite band may be inevitable, this project is addressing the increase in capacity of the available unlicensed bands as much as possible, and is developing approaches that can predict overloads and prevent sudden, unexpected failure modes.<br\/><br\/>This multi-disciplinary project seeks efficient use of unlicensed spectrum by combining an engineering and technology perspective with insights from the literatures on regulation, property rights, and economic coordination. The team includes researchers with expertise in property rights, networking fairness, and wireless communications and network engineering. This team is developing a general framework for understanding cooperation in unlicensed band wireless networks by studying the following issues:<br\/><br\/>Property rights as applied to spectrum management<br\/>Protocols for collaboration between technology neutral wireless devices<br\/>Pricing mechanisms for efficient and fair sharing of congested unlicensed spectrum<br\/>Radio-level interference avoidance techniques<br\/><br\/>The above problems are being studied with a combination of formal and conceptual analysis, simulation and experimental methods, including a dynamic spectrum management testbed which implements potential collaboration protocols and cooperation models. The thrust is to preserve the \"creative chaos\" of the unlicensed bands while creating a degree of long term stability and predictability that is appropriate to the size of the investments being made and the strategic importance of these uses to the nation. Results from the project are of value to both policy makers and emerging unlicensed band wireless Internet providers as well as wireless technologists.","title":"ITR: Collaborative Research: Achieving Innovative and Reliable Services in Unlicensed Spectrum","awardID":"0205431","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["516972"],"PO":["348215"]},"74506":{"abstract":"Software systems have become increasingly complex, and are expected to<br\/>provide service over wide operating ranges. To meet service goals,<br\/>software developers provide many tuning parameters that must be<br\/>set carefully for the system to provide acceptable performance and<br\/>functionality. Tuning these parameters adequately often requires extensive<br\/>trial-and-error experimentation by system administrators. As workloads and<br\/>operating conditions continually change, the parameters must be endlessly<br\/>re-tuned to provide good performance.<br\/><br\/>This research project will apply feedback control to automate this<br\/>parameter tuning loop in two example systems. The first, a wide-area<br\/>replicated file system, provides variable consistency and performance<br\/>through optimistic concurrency control. Feedback will be used to schedule<br\/>replica reconciliation and data migration to provide acceptable<br\/>performance and consistency to end users. The second system, a database<br\/>engine, offers a large variety of tuning parameters to be considered.<br\/>Feedback control will be used to enable database administrators to manage<br\/>the growing complexity of their server systems.<br\/><br\/> From these two examples and other work, a framework for feedback control of<br\/>dynamic computing systems will begin to emerge. This framework will enable<br\/>future computing systems to offer reliable and robust operation and<br\/>predictable performance, without costly maintenance and continual manual<br\/>tuning.","title":"ITR: Feedback Control of Dynamic Computing Systems","awardID":"0219047","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["502459","530391"],"PO":["561889"]},"72108":{"abstract":"The goal of this project is to develop novel electroencephalogram (EEG) classification methods that result in a practical, real-time brain-computer interfaces (BCI) system. BCIs are hardware and software systems that sample EEG signals from electrodes placed on the scalp and extract patterns from EEG that indicate the mental activity being performed by the person. The long-term goal of this line of research is a new mode of communication for victims of diseases and injuries resulting in the loss of voluntary muscle control, such as amyotrophic lateral sclerosis (ALS), high-level spinal cord injuries or severe cerebral palsy. The autonomic and intellectual functions of such subjects continue to be active. This can result in a \"locked-in\" syndrome in which a person is unable to communicate to the outside world. The interpretation of information contained in EEG may lead to a new mode of communication with which subjects can communicate with their care givers or directly control devices such as televisions, wheel chairs, speech synthesizers and computers.<br\/><br\/>The objectives of this project are the design and testing of an EEG system for experimentation in real-time EEG pattern analysis constructed of off-the-shelf components for under $5,000, development of new techniques for a novel approach to studying the cognitive components of mental tasks and how they vary in time and across subjects, demonstration that real-time feedback to the subject will produce a biofeedback situation in which the subject can learn to modify their EEG to increase classification accuracy, proof by demonstration that accuracy and classification time will be sufficient for two persons to interact over the net in a simple game controlled by two BCI systems. The evaluation of the results of this project in light of these objectives will be based on the accuracy of EEG classification, the speed with which the classification can be performed, and the expense of the EEG system and of its maintenance and extendibility.<br\/><br\/>The most significant impact of this project to the disabled community will be an easier to use, affordable BCI system. The inclusion of a wide range of mental tasks will result in a better understanding of which mental tasks are easiest for subjects to consistently perform and for detection algorithms to reliably identify. Better BCI systems will also be significant for other classes of users who can benefit from augmented communication interfaces in applications that require extremely fast commands. The significance of this project to the BCI research community is the specification and testing of the inexpensive system for experimentation with EEG signal analysis. The system based on off-the-shelf components and software to be developed and made publicly available is expected to allow a number of additional research groups to enter the BCI field. Also, this project's results on the analysis of cognitive components in EEG measured during a wide range of mental tasks will broaden the set of mental activities available to users of BCI systems.","title":"Geometric Pattern Analysis and Mental Task Design for a Brain-Computer Interface","awardID":"0208958","effectiveDate":"2002-09-15","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["549818","551905"],"PO":["565227"]},"74407":{"abstract":"Fault tolerant protocols are essential for providing various services (routing, group communication, broadcasting, multi-casting, etc.) in large, dynamic, distributed systems, where both processors and communication links can malfunction intermittently. For example, in mobile and ad hoc networks, the communication links are unreliable and some nodes may be unreachable for certain amounts of time. Such networks, consisting of mobile hosts that communicate via wireless radio channels, are being increasingly used for local area networks, law enforcement, military operations and a myriad of other applications. <br\/><br\/>The traditional approach in designing fault tolerant protocols assumes an upper bound on the number of faults and involves a worst case design by fault masking. While this approach<br\/>provides 100% system availability under assumed conditions, the implementation becomes very expensive. At the same time there are numerous applications for which the lack of system availability for very short periods is acceptable. Self-stabilization is an ``optimistic'' model to design <br\/>distributed fault tolerant systems; no upper bound on the number of faults is necessary, systems always reach a legitimate global state starting from any arbitrary (possibly illegitimate) state, and no central control is needed. However, system availability is not guaranteed during the convergence period.<br\/><br\/>This research addresses the design and analysis of fault tolerant self-stabilizing protocols for global communication primitives for dynamic distributed systems, especially suitable for mobile ad hoc networks. The research focuses on several aspects:<br\/><br\/>-- Create paradigms and guiding principles for designing self-stabilizing distributed algorithms;<br\/>-- Explore methodologies for translating a conventional algorithm into a self-stabilizing analog;<br\/>-- Discover and analyze self-stabilizing protocols for global communication primitives (resource center location, leader election, etc.) in a network;<br\/>-- Explore fractional (rational) valued self-stabilizing algorithms as a way to obtain improved approximate solutions to otherwise NP-hard problems;<br\/>-- Measure the degree to which self-stabilizing algorithms can contain a single fault.<br\/><br\/>The research takes a combined theoretical and experimental approach, and applies its results to emerging distributed applications for ad hoc networks.","title":"ITR: Self-Stabilizing Networking Protocols for Distributed Systems","awardID":"0218495","effectiveDate":"2002-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["541955","195980","436244"],"PO":["565090"]},"72119":{"abstract":"Hu, Xiaobo<br\/>CCR-0208992<br\/>Title: System-Level Approaches to Reducing Energy Consumption <br\/> in Real-Time Embedded System Design <br\/><br\/>Power-manageable hardware devices are essential for reducing system energy<br\/>consumption. In order to benefit maximally from such devices, new and innovative approaches must be developed to fully exploit the dynamically adjustable power v.s. delay characteristics. The proposed research aims at developing techniques employed at the system level to reduce energy consumption in battery-powered real-time embedded systems composed of power-manageable hardware resources. This project strives to obtain a fundamental understanding on the effect of power-manageable resources on both performance and energy consumption during the execution of real-time tasks. Non-ideal features of real-world power-manageable devices will be considered. <br\/><br\/>The major activities include i) devising high-level allocation and scheduling schemes for systems composed of power-manageable devices, ii) designing and analyzing voltage scheduling algorithms for variable-voltage processors, and iii) developing techniques to predict power\/energy consumed by hardware resources at the micro-architectural level. Training students to prepare them for energy-conscious design challenges is also a major component of the project, which will be achieved through course development and active involvements of both undergraduate and graduate students in the research.","title":"System-Level Approaches to Reducing Energy Consumption in Real-Time Embedded System Design","awardID":"0208992","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["550624","518029"],"PO":["561889"]},"83900":{"abstract":"0085344<br\/>Kalia<br\/>This award supports a Focused Research Group at Louisiana State University for research and education on computational materials. The grant is jointly supported by the Division of Materials Research and the Division for Advanced Computational Infrastructure and Research and is a blend of condensed matter physics, materials science and computer science. The objective of the research is to understand how the bonding between dissimilar materials at the atomic level determines structure and macroscopic properties such as adhesion, friction, stiffness, and fracture toughness. The research will focus on: (1) ceramic composites (SiC fibers coated with silica in a Si3N4 matrix and aluminum oxide matrix containing aluminum oxide fibers coated with LaPO4); (2) metal\/ceramic interfaces (Al\/SiC and Ti\/TiO2) and nanostructured composites of passivated metallic nanoparticles; and (3) oxidation, fracture and nanoindentation in these materials.<br\/><br\/>These applications require a methodology that can describe physical and mechanical processes over several decades of length scales. Quantum mechanical (QM) simulations based on the density functional theory will be preformed in regions where atomic bonds are formed or broken; molecular dynamics (MD) simulations will be carried out in nonlinear regions surrounding the QM region; and the finite-element (FE) approach with constitutive input from QM or MD calculations will be used in regions far away from the process zones. The QM, MD, and FE schemes will be integrated with an approach based on control theory. Algorithms will be designed to carry out these hybrid QM\/MD\/FE simulations in a metacomputing environment with multiple parallel machines, mass storage devices, and immersive and interactive virtual environments on a Grid with high-speed networks.<br\/><br\/>The Concurrent Computing Laboratory for Materials Simulation, where the research will be performed, has a record of innovative educational activities including a joint MS\/PhD program in computer science and physics. Efforts are underway for a joint masters degree in computer science and applied physics. In addition, a web-based computational physics course is being taught simultaneously at LSU and the Delft University of Technology in The Netherlands. As part of this grant, a workshop will be established to mentor and recruit minority students.<br\/>%%%<br\/>This award supports a Focused Research Group at Louisiana State University for research and education on computational materials. The grant is jointly supported by the Division of Materials Research and the Division for Advanced Computational Infrastructure and Research and is a blend of condensed matter physics, materials science and computer science. The objective of the research is to understand how the bonding between dissimilar materials at the atomic level determines structure and macroscopic properties such as adhesion, friction, stiffness, and fracture toughness. <br\/><br\/>The Concurrent Computing Laboratory for Materials Simulation, where the research will be performed, has a record of innovative educational activities including a joint MS\/PhD program in computer science and physics. Efforts are underway for a joint masters degree in computer science and applied physics. In addition, a web-based computational physics course is being taught simultaneously at LSU and the Delft University of Technology in The Netherlands. As part of this grant, a workshop will be established to mentor and recruit minority students.<br\/>***","title":"FRG: Multiscale Simulation of Atomistic Processes in Nanostructured Materials","awardID":"0314054","effectiveDate":"2002-09-01","expirationDate":"2005-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1765","name":"CONDENSED MATTER & MAT THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["490010"],"PO":["145396"]},"70854":{"abstract":"This research develops an integrated strategy for the effective<br\/>testing of ubiquitous software systems accessed by the massive user<br\/>population, such as those used to support the Internet and World Wide Web (WWW),<br\/>to ensure their satisfactory performance and reliability from the users'<br\/>perspective. This strategy includes three important components:<br\/><br\/>1. Development of a set of high-level operational profiles (OPs),<br\/>which enumerates major functions to be supported by a software and their<br\/>usage frequencies by target users, organized in groups of related user<br\/>functions.<br\/><br\/>2. For each high-level function group above, a Markov chain based<br\/>model is constructed to exhaustively test high-level operations and<br\/>selectively test important low-level implementations, with the testing results<br\/>analyzed to identify system bottlenecks for reliability improvement.<br\/><br\/>3. Reliability of the critical parts identified above can be assured<br\/>using traditional testing techniques or other quality assurance techniques. <br\/><br\/>This research will involve industrial partners, including IBM, Nortel <br\/>Networks, and Lockheed-Martin Aeronautics, for result validation, <br\/>software tool support, and future deployment.","title":"An Integrated Strategy for Testing User-Oriented Software Systems","awardID":"0204345","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["491097"],"PO":["564388"]},"73912":{"abstract":"EIA-0216375<br\/>Patrick A. Tebbe<br\/>Lisa Grega<br\/>The College of New Jersey<br\/><br\/>MRI\/RUI: Acquisition of Computational Modeling Facilities for Research and Education in Engineering<br\/><br\/>This proposal from an REU institution, advancing the computational infrastructure of the institution (TCNJ) in Engineering, aims at improving the areas of computer aided design and numerical modeling (structural and thermal fluids) in both research and education. Three high performance workstations with 3-D graphics and visualization capabilities and expanded dynamic memory are requested along with licenses and training for two industry finite element modeling packages. The proposal addresses two strategic areas of national importance:<br\/><br\/> High Performance Computing and<br\/> Advanced Materials and Processing.<br\/><br\/>The former will be addressed through the infrastructure and training aspects; while the latter will be addressed through the research of the following topics:<br\/> Numerical Study of Transient and Interfacial Effects in Physical Vapor Transport and<br\/> Process Modeling of the Warm Forming of Aluminum.<br\/>Modeling will be done using commercial code such as ANSYS and FLUENT. Education and training activities are also planned. The project also addresses educational outreach and curriculum integration opportunities. <br\/><br\/>The funds requested include the equipment listed below and associated expenses.<br\/> Sun Blade 1000 workstations<br\/> ANSYS RFD upgrade license<br\/> FIDAP and Exceed software<br\/> Training for maintaining the packages<br\/><br\/>The equipment will support educational outreach programs and will be integrated with the curriculum to involve high school student, undergraduates and underrepresented groups.","title":"MRI\/RUI: Acquisition of Computational Modeling Facilities for Research and Education in Engineering","awardID":"0216375","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["412396","420410"],"PO":["557609"]},"70546":{"abstract":"PROPOSAL NUMBER: 0203285<br\/>TITLE: Testing UML Designs<br\/>PI: Robert France<br\/><br\/>The proposed research is concerned with developing mechanisms that support the generation of design-level test cases from UML design models. The generated test cases are intended to be used in UML design reviews and inspections as a means for evaluating UML models and identifying errors<br\/>in software designs. <br\/><br\/>Developing a UML design testing approach and test generation support requires addressing the following issues: (1) Providing an analyzable representation of UML models and test artifacts, and (2) providing a flexible test generation mechanism. To address these issues the proposed research effort is structured into the following research activities:<br\/><br\/>(1) Deriving test objectives from test-oriented formalizations of Class and Collaboration Diagrams. <br\/><br\/>(2) Defining strategies for creating test objectives. These strategies will be expressed in terms of model coverage goals.<br\/><br\/>(3) Providing techniques that can be partially automated for systematically generating test cases from test objectives.<br\/><br\/>(4) Assessing the effectiveness of the design testing technique developed in this research.<br\/><br\/>This research will produce results that can be used to develop industrial-strength techniques and tools for evaluating UML designs. The results produced by this research will also deepen understanding of how OO designs can be formally interpreted and evaluated.","title":"Testing Unified Modeling Language (UML) Designs","awardID":"0203285","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["554621","557996","291896"],"PO":["564388"]},"73836":{"abstract":"EIA 02-16165<br\/>Skormin, Victor A.<br\/>SUNY - Binghamton <br\/><br\/>MRI: Development of an Advanced Laser Communications Research Facility with Internet Accessible Instrumentation <br\/><br\/>This proposal, developing an experimental research laboratory, expands a concept of sharing advanced scientific equipment in \"cyberspace.\" This technology facilitates the access to equipment via the Internet offering the most advanced instrumentation and relevant interactive instruction to diverse groups of population; thus enhancing engineering education and training. This development will set unique space-qualified laser equipment intended for space communication and offer carefully designed \"fixed\" and \"open-ended\" experiments nation- and world-wide. The proposed project is not a virtual lab, offering instead enhanced \"real\" infrastructure of the laser communications research lab. The new development involves upgrading the equipment and auxiliary systems and enhancing its reliability, accuracy and rate of operation. Hence the facility developed will be suitable for unlimited global access via the Internet, enabling universities, industries, high schools, and individual users worldwide to perform advanced experiments in real-time and to collect data for analysis and interpretation. This project specifically enables and services an often forgotten population, the disabled. The Laser Communication Research Laboratory (LCRL), where the development will take place, contributes to satellite communication technology by addressing, among others, the following technical research problems:<br\/><br\/>1. Modeling, Characterization, and Control of Electromechanical Beam Steering Systems,<br\/>2. Free Space Propagation, Diffraction and Alignment of Laser Beams,<br\/>3. Optical Beam Modulation and Steering,<br\/>4. Rejection of Atmospheric Effects in Communication Systems,<br\/>5. Experimental Analysis, Modeling and Control of Acousto-Optic Laser Beam Steering Systems with Bragg Cells,<br\/>6. Gimbals Systems, and<br\/>7. Liquid Crystal Technology.","title":"MRI: Development of an Advanced Laser Communications Research Facility with Internet Accessible Instrumentation","awardID":"0216165","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5979","name":"CENTRAL & EASTERN EUROPE PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1545","name":"RES IN DISABILITIES ED"}}],"PIcoPI":[191435],"PO":["557609"]},"73605":{"abstract":"EIA -0215531<br\/>Krim, Hamid<br\/>North Carolina State University<br\/><br\/>TITLE: Workshop Proposal: Genomic Signal Processing and Statistics<br\/><br\/>This grant provides partial support for a Workshop on Genomic Signal Processing ands Statistics (GENSIPS). The workshop is being held October 12 and 13, 2002, near the North Carolina State University campus. The goals of the workshop are 1) to identify potential areas of research collaboration between the biological, statistical and signal processing communities and 2) to explore potential new avenues of research in genetics by exploiting synergies in research between signal processing, statistics, and genonomics. The workshop brings together a diverse set of outstanding researchers from each of these areas to address the challenges of the multidisciplinary area of genomics. Twelve internationally known researchers are presenting plenary and invited talks and the workshop also features poster sessions and round-table discussions of the key topics.","title":"Workshop on Genomic Signal Processing and Statistics (GENSIPS), October 12-13, 2002, Raleigh, North Carolina","awardID":"0215531","effectiveDate":"2002-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0504","name":"Division of MICROELECTRONIC INFOR PROCESS","abbr":"MIP"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["518008"],"PO":["329035"]},"74705":{"abstract":"Fourier analysis appears in many of the celebrated cornerstones of<br\/>theoretical computer science. It plays essential roles in expander<br\/>graph construction and derandomization, complexity lower bounds,<br\/>probabilistically checkable proof systems, quantum computing, lower<br\/>bounds for distributed computation, and traditional applications to<br\/>computer algebra. The majority of these applications involve the<br\/>familiar framework of commutative Fourier analysis. The proposed<br\/>project brings together a multidisciplinary research team to apply the<br\/>beautiful tools of non-Abelian (that is, noncommutative) Fourier<br\/>analysis to investigate open questions in two areas where non-Abelian<br\/>groups have recently become very important: lower bounds for parallel<br\/>computation and quantum algorithms. The program also further develops<br\/>efficient algorithms for the discrete Fourier transform over finite<br\/>non-Abelian groups.<br\/><br\/>This project focuses on developing tools for separating the complexity<br\/>classes ACC^0 and NC^1, in order to demonstrate that there are natural<br\/>(polynomial-time computable) problems which simply cannot be<br\/>parallelized in the sense of ACC^0. The project applies a new family<br\/>of tools for separating such circuit classes, using non-Abelian<br\/>Fourier analysis to bound their computational power. These tools apply<br\/>also to the problem of solving equations over finite groups, and the<br\/>development of new probabilistically checkable proof systems based on<br\/>non-Abelian groups. In addition, the project applies non-Abelian<br\/>Fourier analysis to develop improved lower bounds on the standard<br\/>Quantum Fourier Transform approach to Graph Isomorphism and study<br\/>quantum Monte Carlo algorithms. Finally, the project focuses on<br\/>adaptations of Bratelli diagrams and quivers to develop classical and<br\/>quantum algorithms for the non-Abelian Fourier transform itself.","title":"ITR Collaborative Research: Complexity-Theoretic Applications of Fourier Analysis","awardID":"0220070","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["531365"],"PO":["499399"]},"74716":{"abstract":"This project addresses some fundamental aspects of the theory and practice of wireless networking. An integrated approach, combiningphysical layer innovations with new protocols for medium access control and scheduling, while accounting for application requirements and transport protocol dynamics, is employed for solving the research problems that are identified. Two major research thrusts are considered. In the first research thrust, the concept of ``pseudocellular'' wireless networks, which combine the best features of cellular and ad hoc networks, is considered as a paradigm for plug-and-play fourth generation (4G) wireless networks. Such a flexible architecture is clearly critical for quick set-up of wireless networks in emergency situations, in which stationary, or perhaps even mobile, base stations are deployed at convenient (but not optimized)<br\/>sites to serve both slow-moving and fast-moving users. However, it is also a key ingredient of our vision of achieving a quantum jump in wireless link speeds, by going beyond the current cellular frequency bands of 1-2 GHz to the large bandwidths available in frequency bands in the 10s of GHz. The path loss in such bands is high, forcing the use of a dense network of base stations on the one hand, and enabling more aggressive frequency reuse on the other. The focus of the research is to support a mix of user mobilities, and a mix of real-time and non real-time applications, over a packetized pseudocellular infrastructure. This setting differs from conventional cellular networks, in that the cell sizes are small, and cells may have substantial overlap. It differs from wireless Local Area Networks (WLANs), in that it allows for rapidly mobile users despite the small cell sizes. Instead of a conventional hierarchical structure (i.e., large cells for fast-moving users, overlaid on small cells for slow-moving users) to deal with a range of mobility, a mobile-centric approach, which combines handoffs and reservation-based medium access control, is considered to allow for flexible deployment. A novel idea to be investigated is the support of priorities on the reservation channel, so as to allow, for example, highly mobile users with real-time calls in progress to rapidly reserve resources when entering a new pseudocell, thus implicitly achieving a handoff. Another important issue is transceiver optimization of the reservation channel, which requires solution of new problems in multiuser communications.<br\/><br\/>The second research thrust is motivated by the well-known observation that Internet traffic has a heavy-tailed distribution, which typically calls for more conservative resource provisioning than for traditional Markovian traffic models. Since overprovisioning is unattractive in resource-constrained wireless environment, the approach considered is toemploy a new Quality of Service (QoS) framework that allows foraggressive resource utilization, by serving the bulk of the<br\/>transactions (which are short) rapidly, and penalizing the small fraction of long transactions that contribute to the heavy tails. Scheduling disciplines that achieve this goal are very different from<br\/>popular round robin or fair queueing schedulers, and were considered in the queueing theory literature more than three decades ago. The implication of these results for heavy-tailed Internet<br\/>traffic is explored for the first time (to the best of our knowledge) in this project. The scheduling strategy is extended to a shared wireless channel, where fairness is traded off against system<br\/>efficiency, with the latter dictating that users seeing the best channels are the ones that should get link access. The tradeoff is expected to be biased towards efficiency in order to support<br\/>heavy-tailed traffic effectively. The interaction between scheduling and the dynamics of TCP connections (TCP is the Internet data transport protocol on top of which most transactions run) is explored, keeping in mind that a TCP connection that is starved of network resources can get locked out of the network due to repeated timeouts and rate cutbacks. Finally, the dependence of scheduling on mobility is explored, with the concept of assigning priority to highly mobile<br\/>users (who have a smaller chance of getting access to the link during their sojourn in a given pseudocell), while keeping overall QoS and fairness in mind. The scheduling methods we develop place a high importance on overall system efficiency, and are therefore well-suited to flat rate pricing, which is arguably an effective mechanism of promoting usage growth in wireless data networks.","title":"ITR: Cross-Layer Optimization For 4G Wireless Networks: Heavy-Tailed Traffic, Multiuser Channels, and Pseudocells","awardID":"0220118","effectiveDate":"2002-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["549356"],"PO":["7594"]},"74617":{"abstract":"This project develops a decision-theoretic framework for planning and control of multi-agent systems by formalizing the problem as decentralized Markov process. It applies to a wide range of application domains in which decision-making must be performed by multiple collaborating agents such as information gathering, distributed sensing, coordination of multiple robots, as well as the operation of complex human organizations. While substantial progress has been made in planning and control of single agents using MDPs, a similar formal treatment of multi-agent systems has been lacking. Existing techniques tend to avoid a central issue: agents typically have different information about the overall system and they cannot share all this information all the time. Sharing information has a cost that must be factored into the overall decision process. Three approaches to communication are studied based on (1) a cost\/benefit analysis of the amount of communication, (2) search in policy space, and (3) transformations of the more tractable centralized policies into decentralized policies. The resulting techniques are evaluated in the context of several realistic applications. This research facilitates a better understanding of the strengths and limitations of existing heuristic approaches to coordination and, more importantly, it includes new approaches based on more formal underpinnings.","title":"ITR: A Formal Study of Coordination and Control of Collaborative Multi-Agent Systems Using Decentralized MDPs","awardID":"0219606","effectiveDate":"2002-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["485994","485591"],"PO":["564456"]},"74628":{"abstract":"Evaluation and Personalization of Synthetic Voices<br\/><br\/>Abstract<br\/><br\/>This project addresses two key issues in the generation of natural sounding spoken output by computer. The first aspect provides an evaluation strategy for synthetic voices. With no clear objective measure for speech synthesis quality, it is hard to show improvement in systems and compare techniques. This work provides a detailed list of evaluation techniques for sub-parts of the synthesis process including: text analysis, lexical pronunciation, prosody, and phonetic quality. The techniques are designed to act on existing and newly developed voices in other languages, where measures are often harder to come by. Appropriate human experimentation is used to justify the given metrics.<br\/>The second aspect of this work is to improve modeling of speaker-specific acoustic phonetics. In unit selection synthesis techniques, matching the lexicon with the actual spoken form of a particular speaker can introduce significant noise in the selection process. Speakers will have particular idiolects for their dialect and style. Using data-driven techniques, within knowledge-based frameworks, we derive appropriate segmentation types for unit selection synthesis.<br\/>Results are released through CMU's http:\/\/festvox.org site.","title":"ITR: Evaluation and Personalization of Synthetic Voices","awardID":"0219687","effectiveDate":"2002-09-01","expirationDate":"2005-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["396893"],"PO":["565215"]},"72109":{"abstract":"During the last decade, a revolutionary new computer paradigm has emerged that, unlike conventional ones such as the von Neumann model, is based on quantum mechanics rather than classical physics. Quantum computers can, in principle, solve some hitherto intractable problems including factorization of large numbers, a central issue in secure data encryption. The quantum unit of information is the qubit and n qubits can store 2^n binary numbers simultaneously thus facilitating a type of massive parallelism. Qubits support powerful forms of interaction such as entanglement that have no counterpart in classical computers. On the other hand, quantum states are fragile, nanoscale entities, whose measurement is inherently nondeterministic and does not retrieve all 2^n stored numbers simultaneously. As a result, quantum and classical computers pose fundamentally different design problems. Although several promising physical technologies for quantum computers have been demonstrated, they can handle only a small number of qubits and their scalabilty is severely limited. The logic circuits they employ are essentially combinational quantum circuits, which function as a kind of co-processor within an otherwise classical computer. Once quantum computers with 15 -20 qubits can be built, quantum architectures that fully exploit their computational capabilities and also meet practical design and implementation constraints will be needed. These issues motivate the research proposed here, as well as related problems in classical computers that are implemented using nanoscale technologies such as molecular architectures.<br\/><br\/>The overall goal of this proposal is to develop practical methods to design sequential quantum circuits that require much less hardware than current quantum circuits and can be more easily interfaced with classical architectures. The time-space trade-off achievable in classical logic design by using sequential rather than combinational methods is well-known. In the quantum domain, however, it is not obvious that such a trade-off is even possible, since the act of measuring a register's state can destroy its contents. As a result, little or no research has been directed at sequential design methods. However, recent theoretical work on quantum automata by Ambianis et al. demonstrates the feasibility of such methods and points to the possibility of substantial cost savings over conventional approaches. We propose to study the design of quantum sequential circuits starting with exponentially more efficient counters and culminating with application-specific processor designs that realize important applications such as Grover's search algorithm. We will pursue multiobjective optimization, including minimization of the number of qubits, the number of gates, or the circuit depth. We will also take into account the constraints imposed by the most promising physical technologies. Moreover, we will study ways to combine small quantum circuits with large classical circuits to obtain scalable hybrid architectures. Both quantum performance speed-up and conventional scalability then become possible. Novel hybrid designs of this type are expected to play a central role in interfacing quantum processors with classical computers, both conventional and nanoscale. As in traditional computer architecture studies, simulation and other computer-aided design (CAD) methods will, along with the appropriate analytic methods, serve as our principal research tools.","title":"Sequential Architectures for Quantum Computation","awardID":"0208959","effectiveDate":"2002-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["549712","508348"],"PO":["325495"]},"75618":{"abstract":"EIA 0224410<br\/>PI(s): Wong, Tan F.<br\/> Fang, Yuguang; Shea, John M.<br\/>Institution: University of Florida <br\/><br\/>Title: CISE RR: Reconfigurable Multi-Node Wireless Communication Testbed <br\/><br\/>This proposal, developing a real-time wireless communication testbed of six reconfigurable transceiver nodes that operate in the 900MHz or 2.4GHz ISM band, enables conducting experiments on network protocols and communications techniques. Performing real-time experiments over real-life wireless communication channels, the infrastructure enables three projects.<br\/><br\/>Collaborative Communications,<br\/>Wireless Medium Access Control Protocol Design and Experiments, and<br\/>Reliability-Based Hybrid ARQ.<br\/><br\/>The first project concerns collaborative transmission and reception among multiple nodes in a wireless network. Techniques of distributed space-time coding and distributed and iterative decoding will be employed respectively to achieve transmit and receive diversity. The second project uses the test-bed to test new medium access control (MAC) protocols that employ a set of back-off algorithms designed to avoid potential \"future\" collisions and reduce the percentage of idle slots. These MAC protocols have the advantage of fast collision resolution and hence give much higher throughput. The last project develops and investigates a new hybrid automatic repeat request (ARQ) scheme that can take advantage of reliability estimates generated by soft-input, soft-output (SISO) decoders. This ARQ scheme transmits additional information for the unreliable bits, and this information is used to do additional decoding. The test-bed will be utilized to perform real-time experiments on a real-life channel to examine the throughput and delay performance of this ARQ scheme, which can be evaluated via simulations otherwise.<br\/>On the educational side, the platform provides integrated design training to undergraduate students. Conducting simulation studies on algorithms developed on the research projects, students will employ the test-bed to perform off-line experiments over a real communication channel to identify possible weaknesses of the algorithms developed based on theoretical models and then fine tune the algorithms to produce a real-time FPGA implementation.","title":"CISE Research Resources: Reconfigurable Multi-Node Wireless Communication Testbed","awardID":"0224410","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["560200","550716","518031"],"PO":["557609"]},"75629":{"abstract":"EIA 02-24434<br\/>Luebke, David P.<br\/>Skadron, Kevin; Stan, Mircea R.<br\/>University of Virginia <br\/><br\/>CISE RR: A High-Performance Shared-Purpose Cluster for Computer Architectural Simulation and Perceptual Interactive Ray Tracing <br\/><br\/><br\/>This proposal, building a cluster platform (with high computing and memory requirements, and graphics and display hardware) to support research in computer graphics and architecture, enables projects studying interactive rendering, computer architecture, and temperature-aware computing. A 16-node rack-mounted cluster with dual CPUs, large memory (4 GB), gigabit networking, and high-end graphics is expected to facilitate the research. Specifically, the infrastructure supports the following three research projects:<br\/><br\/>Perceptually Driven Interactive Ray Tracing,<br\/><br\/>Thermal Simulation of Computer Architecture with Graphics Hardware, and<br\/><br\/>Large-Memory Architectural Simulations.<br\/>The computer graphics research investigates new scene rendering algorithms motivated by models of human perception, and requiring flexible (programmable) graphics hardware. This work investigates unconventional rendering techniques that exploit the ability to vary sample location, density, and frequency. Examples include frameless (replaces double buffering with randomized update of pixels), interruptible (unifies spatial and temporal error for a principles fidelity\/performance tradeoff), and gaze-directed (varies detail and resolution according to user's attention) rendering. Thermal modeling is directed towards solving heat transfer equations for studying the run-time thermal behavior of microprocessors, especially multithreaded (SMT) and single chip (SCC) systems. The computer architecture component involves performance of SMT and SCC systems and investigation of aggressive branch prediction techniques using distant correlations.<br\/>The educational aspects involve folding relevant topics into the current graduate seminars and students in the research.","title":"Research Resources: A High-Performance Shared-Purpose Cluster for Computer Architectural Simulation and Perceptual Interactive Ray Tracing","awardID":"0224434","effectiveDate":"2002-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["560683","451003","489873"],"PO":["557609"]},"75409":{"abstract":"This project lays out our plan for research and development aimed atdramatically improving the process<br\/>and outcome of scientific data analysis and visualization. The improvement will be achieved by coupling an expressive and extensible metadata management framework with novel visualization interfaces that facilitate<br\/>effective reuse, sharing, and cross-exploration of visualizationinformation and thus will make a profound<br\/>impact on a broad range of scientific applications. The process of scientific visualization is inherently iterative. A good visualization comes from experimenting with visualization and rendering parameters to bring out the most relevant information in the data.<br\/>This raises a question. Considering the computer and human time we routinely invest for exploratory and<br\/>production visualization, are there methodologies and mechanisms to enhance not only the productivity of<br\/>scientists but also their understanding of the visualization process anddata used?<br\/>Recent advances in the field of data visualization have been made mainly in rendering and display<br\/>technologies (such as realtime volume rendering and immersive environments), but little in coherently managing, representing, and sharing information about the visualization process<br\/>and results (images and insights).<br\/>Naturally, the various information about data exploration should be shared and reused to leverage<br\/>the knowledge and experience scientists gain from visualizing scientific data. A visual representation of the<br\/>data exploration process along with expressive models for recording and querying task specific information<br\/>help scientists keep track of their visualization experience and findings, use it to generate new visualizations, and share it with others.<br\/>While previous research has addressed some related issues, a more comprehensive study remains to be<br\/>done. Thus, we propose two complementary avenues of research: (1) new user interfaces for data visualization tasks, and (2) expressive metadata models supporting the recording and<br\/>querying of information related to data exploration tasks. In addition, a set of user studies will be<br\/>conducted on a Web-based visualization testbed realizing (1) and (2) in order to refine the proposed<br\/>methodologies and designs.<br\/>Traditional user interfaces cannot support the increasingly complex process of scientific data exploration.<br\/>A fundamental change in the conventional designs and functionality must be made to offer more<br\/>intuitive interaction, guidance, and enhanced perception. We will begin our study with enriching the graphbased and spreadsheet-like interfaces we have developed, and also investigate alternative designs. An expressive and extensible metadata model representing the data exploration process and its embedded data visualization process is needed. Such a model along with an appropriate user interface makes it possible to manage diverse information about the input and results of the visualization process, analyze parameter coverage and usage, identify unexplored visualization spaces, and incorporate findings on the process and results in form of visualization metadata. The model is independent of the actual visual interface used and is open in that its realization in form of a metadata repository can be loosely coupled with a variety of different visualization tools. A set of interfaces and protocols to the repository will be designed to manage, query, and analyze visualization metadata gathered from and utilized by different visualization tools.<br\/>Our goal is ambitious and can only be accomplished by working closely with application scientists.<br\/>They will help us understand application-dependent and independent visualization requirements, processes,<br\/>and information. In return, we will offer them a new and greatly improved way to understand their scientific<br\/>data, which will help them lead to new discoveries quicker, likely with reduced cost.","title":"VISUALIZATION: A Metadata-Driven Visualization Interface Technology for Scientific Data Exploration","awardID":"0222991","effectiveDate":"2002-09-01","expirationDate":"2007-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["552243","388358"],"PO":["565272"]},"70844":{"abstract":"There has been much recent work on scheduling techniques that<br\/>ensure fairness, temporal isolation, and timeliness among<br\/>applications multiplexed on the same resource. Many systems that<br\/>could benefit from the use of fair scheduling principles have<br\/>workloads that necessitate the use of multiple processors; consider,<br\/>for example, the proliferation of Internet service providers that<br\/>host third-party websites on multiprocessor servers. Unfortunately,<br\/>most prior work on multiprocessor fair scheduling has been rooted<br\/>in task models that are too rigid to apply in many settings. The<br\/>little research on more flexible models that has been done has been<br\/>almost entirely experimental in nature, with little or no formal<br\/>analysis of the scheduling algorithms being tested.<br\/><br\/>In this project, fair scheduling algorithms based on rate-based<br\/>scheduling principles will be developed and analyzed, both formally<br\/>and experimentally. Specific project objectives include the<br\/>development of (i) fair scheduling algorithms that minimize task<br\/>migrations; (ii) extensions to these algorithms that allow tasks to<br\/>synchronize and share resources; (iii) extensions that allow real-time<br\/>and non-real-time applications to execute under a common framework;<br\/>and (iv) techniques for managing dynamically-changing workloads in<br\/>which tasks may join and leave the system.","title":"Flexible Fair Scheduling on Multiprocessors","awardID":"0204312","effectiveDate":"2002-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["31436","518412"],"PO":["309350"]},"70855":{"abstract":"Distributed, heterogeneous (DH) software systems are critical for<br\/>the operation of modern, globalized organizations. <br\/>Like all software, DH systems come under evolutionary<br\/>pressure as organizational needs evolve. Adapting DH systems to meet <br\/>changing needs in areas such as security is challenging:<br\/>Co-ordinated changes, made in different languages, and on different<br\/>platforms must still preserve type-safety, and must not increase<br\/>complexity and\/or complicate maintenance. <br\/>This project investigates <br\/>enhancements to standards-based middleware (e.g., CORBA) <br\/>to support evolution.<br\/>We preserve and enhance the core IDL-based heterogeneous <br\/>philosophy of middleware. First, <br\/>interface-description language (IDL),<br\/>used to model the architecture-level interfaces of <br\/>components, is enhanced to support<br\/>modeling of the evolutionary changes made to a DH systems. Location<br\/>of changes, types and life-times of new information <br\/>to be created are all explicitly modeled in an <br\/>aspect-oriented style at the IDL level. <br\/>Code generation supports<br\/>a wide range of implementation choices to<br\/>realize these architectural change-models. All implementations<br\/>are fully inter-operable. Finally, change-models<br\/>and implementations can be \"compononentized\", <br\/>packaged up and added to existing systems. Like this research,<br\/>our educational plans also span<br\/>several topics areas, including functional programming,<br\/>object-orientation, and architecture. We <br\/>develop practically-grounded pedagogy on software evolution,<br\/>comparing the varying approaches to separation of concerns in<br\/>object-orientation, higher-order polymorphism (including<br\/>monadic programming), connectors, and aspects.","title":"Managing Evolution in Distributed, Heterogeneous Systems","awardID":"0204348","effectiveDate":"2002-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["562714"],"PO":["564388"]},"70745":{"abstract":"Developing a Resource-Aware Adaptive Compilation System for High-Performance Distributed Computing<br\/><br\/>The goal of our work is to combine successful Grid infrastructure with novel program compilation and optimization techniques to support portable and high-performance distributed computing. We plan to develop adaptive compilation and runtime techniques that are guided by the dynamic performance characteristics of underlying Grid resources. To investigate these techniques, we will use language environments that come from Internet computing (Java and .Net) as development vehicles.<br\/><br\/>The framework we propose, a Resource-Aware Adaptive Compilation System, makes resource performance and availability predictions, e.g. for networks, CPUs, memory, disk, etc., available to a dynamic compilation system so that programs compiled \"just-in-time\" achieve minimum overall execution time adaptively. That is, we will adapt the level of program optimization (and subsequent execution time tradeoff) dynamically, based on the instantaneous performance profile of the Grid resources at hand.<br\/><br\/>To address this problem of achieving portable high-performance using the Grid, we propose to investigate adaptive program compilation and on-the-fly optimization of high-performance distributed applications using Computational Grid resources. We will guide runtime and compiler optimization using predicted resource performance (generated by the Network Weather Service) and re-optimize code to adapt to changes.","title":"Developing a Resource-Aware Adaptive Compilation System for High-Performance Distributed Computing","awardID":"0204019","effectiveDate":"2002-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["402357","561463"],"PO":["301532"]}}