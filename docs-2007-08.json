{"128436":{"abstract":"The project investigates and develops autonomic mechanisms for<br\/>reducing system downtime due to software maintenance and upgrades.<br\/>The project addresses operating system upgrades and also application<br\/>upgrades, focusing on standalone binary-executable applications. The<br\/>main goal is to lessen the possibility that patches and updates will<br\/>``break'' expected functionality of the environment that worked fine<br\/>together with the old version -- overall maximizing availability and<br\/>reliability both during and after maintenance while imposing little<br\/>management overhead. The contributions stem primarily from a<br\/>virtualization architecture that decouples application instances from<br\/>operating system instances, enabling either to be independently<br\/>updated. The results, disseminated via web download, will improve<br\/>availability of legacy applications, with no source code access,<br\/>modification, recompilation, relinking or application-specific<br\/>semantic knowledge, and perform efficiently and securely on commodity<br\/>operating systems and hardware.","title":"CSR---VCM: Autonomic Mechanisms for Reducing System Downtime due to Maintenance and Upgrades","awardID":"0717544","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["541922","508477"],"PO":["493916"]},"127347":{"abstract":"This project considers the problem of simultaneously solving multiple<br\/>component-level natural language processing problems. Such<br\/>component-level tasks are necessary as building blocks for large-scale<br\/>applications (eg., automatic document summarization, machine<br\/>translation, etc.), but are typically solved independently. These<br\/>independent solutions ignore the natural connections that relate the<br\/>output of one problem to the output of the other. This research<br\/>explores the ability to exploit such output correspondences to aid<br\/>machine learning algorithms, termed \"Cross-Task Learning.\" These<br\/>output correspondences provide strong prior information about the<br\/>relationship between the desired outputs of multiple problems. This<br\/>prior knowledge can potentially serve to improve task-level<br\/>performance, even when large amounts of training data are unavailable.<br\/>The research exploits such prior knowledge using a k-best methodology<br\/>so as to maximize the applicability of these techniques. It also<br\/>develops new techniques for semi-supervised learning based on the idea<br\/>of output correspondences in order to capitalize on the vast amounts<br\/>of unannotated data that are available. In addition, the proposed techniques<br\/>are analyzed in the context of computational learning theory. The outcome <br\/>will be a set of techniques for learning across multiple natural language processing<br\/>tasks. This technology will be empirically evaluated in the context<br\/>of low-level tasks such as shallow parsing and named entity<br\/>recognition, as well as the high-level tasks of discourse analysis and<br\/>automatic document summarization.","title":"Cross-Task Learning for Natural Language Processing","awardID":"0712764","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550878"],"PO":["565215"]},"128205":{"abstract":"There is an alarming trend that elusive malware is armed with techniques that detect, evade, and subvert malware detection facilities of the victim. On the defensive side, a fundamental limitation of traditional host-based anti-malware systems is that they run inside the very hosts they are protecting, making them vulnerable to malware's counter-detection and subversion. To address this limitation, solutions using virtual machine (VM) technologies advocate placing the malware detection facility outside of the protected VM. However, a dilemma exists between these two approaches: The \"\"out of the box\"\" approach gains tamper resistance at the cost of losing the native, semantic view of the host enjoyed by the \"\"in the box\"\" approach. To resolve the above dilemma, a new approach called OBSERV (\"\"Out of the Box with SEmantically Reconstructed View\"\") is introduced to achieve the advantages of both camps by reconstructing the semantic internal view of a VM from external, low-level observations. OBSERV enables two exciting malware defense opportunities: (1) malware detection by view comparison and (2) real-time detection and stoppage of kernel-level rootkits. The broader impact of this research is two-fold: (1) It will enhance the trustworthiness and effectiveness of widely deployed anti-malware systems. Moreover, OBSERV is expected to be viewed favorably by the anti-virus software industry because of its support for existing off-the-shelf anti-virus software. (2) Results from this research will lead to the development of education materials for undergraduate and graduate courses and for professional training sessions.","title":"CT-ISG: Collaborative Proposal : Enabling Detection of Elusive Malware by Going Out of the Box with Semantically Reconstructed View (OBSERV)","awardID":"0716444","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["518557"],"PO":["561889"]},"128216":{"abstract":"Spam has become a prominent problem in every important communications medium. Most email users face spam every day. An entire industry has sprung to \"improve\" search engine rankings of web sites. Further, automatically generated spam has invaded blogs, social networks, online advertising, and VoIP connections. Spam is a rapidly growing practical problem due to the easy adaptation of attacking tools that bypass defense mechanisms. For example, useful defense techniques such as statistical learning filters and collaborative filtering are capable of distinguishing spam from legitimate email. However, attackers have been using automated tools to bypass these defense mechanisms, resulting in a seemingly endless \"arms race\" between attacks and defenses. For example, randomizing spam tokens and inserting legitimate text as camouflage can significantly reduce the effectiveness of statistical learning filters. Although there is no known general solution for the arms race, known as Adversarial Learning, a defense based on the exploitation of the semantic necessity of spam email to contain strong spam tokens such as VIAGRA (or its misspellings) has been found and demonstrated to end the camouflage arms race. This project seeks additional evidence to support the hypothesis that such structural (inherent) characteristics can be found and used in the identification of many kinds of spam attacks. The first research thrust focuses on the development of defense methods resilient to adaptive spam attacks. The second research thrust investigates the combination of spam attacks in distinct areas (e.g., email and web spam) and combined defenses. Success in these thrusts will significantly and permanently reduce the effectiveness of spam attacks.","title":"CT-T: Collaborative Research: Adaptive Attacks and Defenses in Denial of Information","awardID":"0716484","effectiveDate":"2007-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["532971"],"PO":["529429"]},"128227":{"abstract":"Due to global economy pressures, fabrication of advanced integrated circuits (ICs) is migrating to foreign foundries. It has become a common trend for many fab-less companies and government agencies to ship their designs offshore for low-cost fabrication. These trends have raised serious concerns regarding possible threats or attacks on US military systems, critical sites and even household appliances that rely on high performance chips. There are various potential vulnerabilities to such systems caused by malicious alterations of hardware processes that might make these vital systems inoperable at some future time. Such malicious manipulation of ICs slated for installation in US weapon systems cannot be tolerated.<br\/><br\/>The focus of this research is on the development of automatic test pattern generation (ATPG) and signal analysis techniques for detecting and locating malicious alterations, e.g. the insertion of Trojan circuits, during wafer probe aor package test as a means of improving the level of trustworthiness of the chip. In particular, techniques that significantly improve the resolution of quiescent current and transient current techniques for detecting and locating Trojan circuits are investigated. A second focus of the project is on the development of ATPG methods designed to detect hidden alterations of the chip, e.g., inserted or weakened wires or transistors which cause the chip to fail later in the field.","title":"CT-ISG: Collaborative Research: Detection and Isolation of Malicious Inclusions in Secure Hardware (DIMINISH)","awardID":"0716535","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560771"],"PO":["564388"]},"129206":{"abstract":"Many of the conveniences of modern life are made possible by embedded computing systems. This project is developing new methods to make such systems use their limited resources more efficiently, increasing performance, reducing costs and energy requirements. <br\/><br\/>Modern general-purpose computers (PCs, servers, etc.) owe most of their high processing speed to caches. These memory system components fetch data from the slow (but inexpensive) main memory for the fast processor before it even realizes it needs it. Unfortunately the performance offered by caches is very difficult to guarantee, greatly complicating the prediction of a program's worst-case performance. This prediction is essential for a broad class of embedded and control systems ? those with real-time requirements. Such systems must respond to inputs before a deadline elapses or else something will fail. Hence such systems must be over-provisioned to cover the ?margin of ignorance?, raising costs and energy requirements.<br\/><br\/>This project is developing methods to provide memory accesses as fast as with a cache, but without any of the timing uncertainty, making this technology suitable for real-time systems. The research team uses a unified approach which cuts across compilers, operating systems, and computer architecture to create a much more efficient solution than possible by considering the problems separately. The fundamental insight is that by limiting preemption among threads, one can reduce the total memory required, allowing more data to be stored in fast memory. This speeds thread execution, allowing further reduction of preemptions (and hence memory requirements) leading to a repeatable, virtuous cycle.","title":"CSR-EHS: Integrated Memory Allocation and Scheduling for Real-Time Embedded Systems","awardID":"0720797","effectiveDate":"2007-08-01","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518384","485952"],"PO":["561889"]},"128007":{"abstract":"Proposal #: CNS 07-15342<br\/>PI(s): Park, Haesun <br\/>Institution: Georgia Institute of Technology<br\/> Alanta, GA 30332-0002<br\/>Title: SGER: Effective Network Anomaly Detection based on Adaptive Machine Learning<br\/><br\/>Project Proposed:<br\/><br\/>This project, developing innovative adaptive machine learning algorithms for detecting network intrusions, especially anomaly detection, aims to increase the detection rate and speed of detection for dynamically changing data sets without recomputing the solutions from scratch. Instead, the existing solutions are utilized and updated with new data. By detecting more data in training without compromising data privacy, the algorithms are designed to increase the detection capability. The work addresses the following challenging aspects of machine learning based methods for network anomaly detection:<br\/>. Development of Adaptive Machine Learning Algorithms,<br\/>. Hierarchical Dimension Reduction and Clustering, and<br\/>. Privacy Preserving Distributed Data Mining for Effective Utilization of Private Intrusion Detection Data Sets.<br\/>The former, responding to the change of data over time, designs\/creates efficient algorithms to delete the influence of old data and incorporate the new data, without recomputing the solution. The second, addressing the fact that typically data sets are intrinsically unbalanced when the problem is considered as a binary problem, generalizes further the cluster preserving dimension reduction methods to reflect the hierarchical cluster structure in dimension reduction. The latter, responding to data privacy, designs machine learning based anomaly detection algorithms by integrating locally generated results into one integrated solution without revealing the critical information in each local data set, thereby preserving privacy.<br\/><br\/>Broader Impacts: The research produces methods that are likely to have great impact on a broad range of applications in very high-dimensional spaces. Their adaptability allows significant reduction in the computational complexity substantially improving the possibility of detailed study of data which has been prohibitively expensive. Involving an HBCU institution in the area, this female faculty PI leads an effort to engage more women and minority students.","title":"SGER: Effective Network Anomaly Detection Based on Adaptive Machine Learning","awardID":"0715342","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["562362"],"PO":["557609"]},"129228":{"abstract":"Some of the most exciting cyber technologies on the research horizon involve sophisticated digital systems that interact with the physical world. Examples include remote surgery, physical manipulation of nano-structures, autonomous (ground and air) vehicular travel, and space and terrestrial exploration. Because such applications interact directly with the physical world, it is imperative their physical safety be assured. This project is developing a comprehensive formal framework for producing controllers for cyber-physical systems, with machine checkable proofs of their physical safety. The project brings together ideas from control theory, language design, program verification, program generation, software engineering, and real-time and embedded systems to build a framework that can be applied to challenging applications. The framework promotes an efficient, rigorous engineering process for producing embedded controllers, incorporating explicit models not only of the controller itself, but also of the physical context in which it operates, the required stability conditions, the platform on which it will run, and the associated real-time constraints. The results of the project are being demonstrated and evaluated in the context of a tele-surgery application. This application is currently being developed at the Mechatronics and Haptic Interfaces Lab in the Mechanical Engineering Department at Rice University.","title":"Collaborative Research:\u00a0 CSR\/EHS Building Physically Safe Embedded Systems","awardID":"0720856","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518598"],"PO":["561889"]},"129239":{"abstract":"Release of chemicals or biological agents in the subsurface often results in plumes migrating in the medium, posing risk to human and ecological environments. Temporal and spatial monitoring of the plume concentrations are needed to assess risk, make decisions and take remedial action. Current underground contaminant plume monitoring technologies are inefficient, expensive and ineffective. Wireless sensor technologies have the potential to dramatically improve this process. <br\/>A closed-loop system integrating wireless sensor network based monitoring with numerical models for plume tracking is being developed, in which sensor data continuously calibrates and validates the system identification and prediction models, while the output from these models direct the sensor network operation to optimize constraints such as accuracy and power consumption. The system is based on a novel virtual sensor network architecture with broader applicability beyond plume tracking. Algorithms and protocols being developed support the formation, usage, adaptation and maintenance of dynamic subsets of collaborating sensors, named Virtual Sensor Networks (VSNs). VSN protocols for collaboration among groups of sensors will greatly ease the task of deploying sensor networks, especially in environments where multiple geographically overlapping applications are deployed. A proof-of-concept laboratory test bed that captures the complex subsurface processes is used for integration and evaluation of VSN protocols. This interdisciplinary project will significantly advance the state-of-the art in subsurface plume tracking and sensor networking technologies. It will stimulate a unique partnership of electrical engineers, computer scientists and environmental researchers, and demonstrate closed-loop operation of computer models and sensor networks to solve complex environmental problems.","title":"Collaborative Research: CSR---CSI: A Virtual Sensor Network Based","awardID":"0720889","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[342438],"PO":["535244"]},"129129":{"abstract":"The process of deploying, installing, and using software upgrades (also called updates or patches) is riddled with problems resulting from a poor integration between upgrade development, deployment, and remote (user-site) testing. Thus, we are building a distributed framework, called Mirage, for integrating deployment and remote testing into a structured and efficient upgrade development cycle that encompasses both software vendors (as well as software contributors and distributors) and users. When completed, our framework will produce upgrades that behave properly with high confidence when widely deployed, thereby reducing the exposure of users to problematic upgrades and facilitating the debugging of problems by the vendors. Given these benefits and the extreme importance of upgrades for most computer users and vendors, the practical impact of Mirage can be significant. We will disseminate our findings and source code through our educational program, over the Web, and through scientific publications in major conferences and journals.","title":"CSR-PDOS: Integrated World-Wide Software Upgrade Deployment and Testing","awardID":"0720568","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["556616"],"PO":["493916"]},"130284":{"abstract":"A new form of social interaction among humans has gained tremendous importance over the last decade: computer games. A recent trend is to blur the boundary between game designers and game players, by allowing game players to modify the game and to give free range to their own expressiveness. In modern games, players can extend or modify the game terrain, as well as the look and feel of the game characters. The involvement of game players in the creative part of game design has also been extended to the most important part of the game, namely the behavior of the game as expressed through its non-player characters (NPCs). Game players can alter the behavior of NPCs by modifying scripts that control them. Unfortunately, this aspect of today's computer games still suffers from a severe limitation, in that there are either just a few highly sophisticated NPCs, or a large number of very simple NPCs. The ultimate goal, of having the game scale to a large number of sophisticated NPCs, is not an option today. In this research, the PI will try to address this limitation by seeking answers to questions such as the following. What are suitable languages for scripting NPCs that are highly expressive yet permit sufficiently interesting character behavior? What are suitable processing algorithms for games with a large number of NPCs? How can designers fine-tune their games to balance performance with game-play? To gain a better understanding of these issues, the PI will develop a novel language (complete with optimizing compiler) that is expressive, but which can be processed efficiently with multi-query optimization from the database literature. And he will design tools for game designers to create expressive NPCs, which include techniques to allow the designers to easily adjust the quality of the simulation to improve performance. Stratagues, an open-source game engine, will serve as the concrete testbed for the initial implementation of the PI's ideas; a second implementation in a new toolkit for fast creation of scalable simulations is also planned. Finally, the PI will explore how his ideas relating to and lessons learned from games can be applied to simulations of virtual worlds beyond games, such as disaster recovery scenarios or simulation of animals and their environment. The PI expects to convincingly demonstrate that ideas and technology developed initially for programming virtual worlds (i.e., simulations) relating to computer games, can benefit and have a huge impact on scientists who currently labor to write simulations in low-level programming languages.<br\/><br\/>Broader Impacts: The outcomes of this research will empower scientists to quickly generate realistic simulations of scenarios involving large numbers of humans and\/or animals while achieving performance comparable to that of specialized code requiring orders of magnitude more time to write. To this end, the PI will distribute the software he creates in this project as open source, and will furthermore develop a toolkit for rapid-prototyping of scientific simulations of rescue and disaster recovery operations.","title":"Design Methodologies for Scalability in Computer Games","awardID":"0725260","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":[345714,"448955","466933"],"PO":["565227"]},"125851":{"abstract":"This project is a collaborative effort between the Massachusetts Institute of Technology Media Laboratory and the Groden Center to develop and evaluate wearable social-emotional technology that helps individuals with high-functioning autism or Asperger syndrome acquire an affinity for the social domain and improve their overall social abilities. The project will develop the first wearable camera system capable of perceiving and visualizing social-emotional information in real-time human interaction. Using a small wearable camera and video-pattern analysis algorithms, the system analyzes video of the wearer or interaction partner and tags it at multiple granularities (facial actions, communicative facial or head gestures, and emotions). <br\/><br\/>The wearable system aims to: (1) facilitate learning and systemizing of social-emotional cues; (2) promote self-reflection and perspective-taking; (3) allow wearers to study subtle nonverbal cues and share experiences with peers, family members, and caregivers; and (4) contribute new computational models and theories of social-emotional intelligence in machines. A clinical study will compare the efficacy of the wearable system to current gold standard interventions for autism spectrum disorders (ASD). A participatory approach to the co-design and use of technology draws on the experiences of individuals with ASD and their solutions to systematizing social interactions, thereby empowering them to enhance their relationships, while participating in the development of next-generation social-emotional intelligent technologies.<br\/><br\/>The project will make significant contributions to the difficult challenge of developing machine intelligence that is robust at handling human social interaction. When people or machines fail to perceive, understand, and act on social-emotional cues they are hindered in their ability to interact with and learn from others. The results of this interdisciplinary work can be leveraged in human-computer interaction, robotics, and technologies with social-emotional intelligence. The research will also provide investigators with a new tool to study nonverbal communication outside of laboratory settings. <br\/><br\/>This project brings together the overlapping and converging goals and challenges of autism research and affective computing, both already interdisciplinary in nature, and demonstrates how a collaboration could lead to several mutually beneficial outcomes ? from developing new tools to assist people with ASD in understanding and functioning in the social-emotional world, to developing new computational models and theories that enable technology to provide an overall better experience to those who use it. This work also promotes the training and education of students and people with ASD by involving them in cutting-edge scientific research.","title":"HCC: Collaborative Research: Social-Emotional Technologies for Autism Spectrum Disorders","awardID":"0705647","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["457547","457546"],"PO":["565227"]},"133485":{"abstract":"This is funding to enable the PI to explore an unexpected opportunity that has come to light during research funded under his current award (0414754) entitled \"Interacting with Human Physiology.\" The new work will extend the scope of the project in a timely and important new direction. GSR (Galvanic Skin Response) is the most sensitive and specific physiological sensing mode for stress quantification during human-computer interaction. Under the existing grant, the PI has demonstrated that periorbital and supraorbital sensing can also quantify stress and be used in interactivity experiments. More importantly, periorbital and supraorbital sensing can be carried out at a distance (via thermal imaging) and on an easily accessible tissue area (the face). These are tremendous advantages, because the user is left undisturbed. Recently, the PI has identified a channel on the maxillary area, which is of the same cholinergic nature as the palm channel that GSR measures, and has begun to develop a comprehensive theory that accounts for all facial channels (periorbital, supraorbital, and maxillary) and quantifies them against GSR, the emerging result being a \"facial GSR channel-at-a-distance.\" This is a potential breakthrough, as it identifies a contact-free measurement method that can provably perform as well as the best contact method (GSR) in psycho-physiological studies. This funding will allow the PI to address initially technical challenges that remain unsolved, which relate to degradation of the facial signals due to residual imperfections in segmentation and tracking. The major portion of the new effort will concentrate on exploration of interactivity issues where the integrated methodology will be compared vis-a-vis the traditional GSR technology, with a focus on mission critical software. <br\/><br\/>Broader Impacts: A portion of this funding will provide for the organization of the first workshop of its kind on \"Physiological Monitoring 24\/7 and its Interactivity Potential\" that will be hosted in late August at the IEEE Engineering in Medicine and Biology Conference to be held in Lyon, France. The University of Lyon has kindly provided a conference room for this event and identified a few dorm rooms that can be used to house graduate student participants, which will greatly reduce the cost to NSF.","title":"Interacting with Human Physiology","awardID":"0741581","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["532471"],"PO":["565227"]},"126610":{"abstract":"Networking research has long relied on simulation as the primary vehicle for demonstrating the effectiveness of proposed protocols and mechanisms. Typically, one simulates network hardware and software in software using, for example, the widely used ns-2 simulator. Experimentation proceeds by simulating the use of the network by a given population of users using applications such as ftp or web browsers. Synthetic workload generators are used to inject data into the network according to a model of how the applications or users behave.<br\/><br\/>In order to perform realistic network simulations, one needs a traffic generator that is capable of generating realistic synthetic traffic in a closed-loop fashion that ?looks like? traffic found on an actual network. Unfortunately, the networking community suffers from a lack of validated tools and models suitable for synthetic traffic generation. As a result, all too often, networking technology is evaluated using ad hoc workloads with an unknown relationship to traffic seen on real links and hence begs the question of how believable the results of the evaluation are.<br\/><br\/>This project is a collaborative effort to develop a synthetic traffic generation resource for the experimental networking research community. The resource consists of (1) synthetic traffic generators for the ns-2, ns-3, and GTNets software simulators, and Linux and BSD-based testbeds, (2) a repository of datasets to be used by the traffic generators to generate traffic that is statistically equivalent to traffic found on a variety of network links including campus networks, wide-area backbone networks, corporate intranets, wireless networks, etc, and (3) a set of traffic analysis tools to enable researchers to generate empirical models of traffic on network links of interest and to use these models to drive the synthetic traffic generation process.","title":"Collaborative Research: CRI: CRD: Synthetic Traffic Generation Tools and Resources: A Community Resource for Experimental Networking Research","awardID":"0709058","effectiveDate":"2007-08-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["485668"],"PO":["493916"]},"126500":{"abstract":"Proposal #: CNS 07-08767 07-08437<br\/>PI(s): Conklin, Megan Crowston, Kevin<br\/>Institution: Elon University Syracuse University<br\/> Elon, NC 27244-2010 Syracuse, NY 13244-1200<br\/><br\/>Project Proposed:<br\/><br\/>This collaborative project, developing FLOSSmole, a distributed collaborative community resource in the form of a broadly-shared data and analysis archive, enables research on Free\/Libre Open Source Software (FLOSS) and its development. With the goals of improving the reproducibility and consistency of the research and expanding access to the data, FLOSSmole collects, organizes, and shares comparable data and analyses of FLOSS development. A framework for organizing a system for facilitating access to the massive amounts of data collected by many simultaneous and currently unconnected FLOSS research efforts, FLOSSmole is designed to be a piece of research infrastructure. Because FLOSS development provides examples of successful computer-supported collaborative work, the project is relevant to various areas of research such as Human-Centered Computing and Cyberinfrastructure. It enables cooperation in data collection, aggregation and sharing. Furthermore, serving as a potential training ground for software developers, its development should teach us about software evolution and the understanding of how developers join and work in these teams.<br\/><br\/>Broader Impacts: Supporting improvement of a piece of collaborative research used by academics, practitioners in the software industry, and by society in general, the infrastructure promotes international collaboration and data sharing among research teams. Indeed, sharing code, data, schemas, queries, and experience promotes teaching and learning. The project should benefit students who work on it impacting courses and projects. Moreover, as an open source project itself the resource contributes to open and share data promoting collaboration, reducing duplicative efforts, and promoting compatibility between research teams.","title":"Collaborative Research: CRI: CRD: Data and analysis archive for research on Free and Open Source Software and its development","awardID":"0708437","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["565342"],"PO":["564456"]},"126621":{"abstract":"Abstract <br\/>Proposal #: CNS 07-09140 07-08307 07-08820 <br\/>PI(s): Brockman, Jay B. Bader, David A. Gao, Guang R. <br\/>Barabasi,Albert-Laszlo;Chawla,Nitesh;Kogge,PeterM. Vetter, Jeffrey S. <br\/>Institution: University of Notre Dame Georgia Institute Tech U.Delaware <br\/>Notre Dame, IN 46556-5602 Atlanta, GA 30332-0002 Newark, DE 19716-1551 <br\/>Proposal #: CNS 07-09385 07-09111 07-09254 <br\/>PI(s): Gilbert, John R. Upchurch, Edwin T. Yelick, Katherine A. <br\/>Wolski, Richard. <br\/>Institution: UC-Santa Barbara California Inst Tech UC-Berkeley <br\/>Santa Barbara, CA 93106-2050 Pasadena, CA 91125-0600 Berkeley, CA 94704-5940 <br\/>Title: Colla Rsch:IAD:Dev Rsch Infr. for Multithreaded Computing Community Using Cray Eldorado Platform <br\/><br\/>Project Proposed: <br\/><br\/>This collaborative project, developing a shared infrastructure needed to broaden its impact for developing software to run on the next generation of computer hardware, brings a diverse group of researchers from six universities in a joint effort. The work responds to the trend towards multicore processors where developers envision placing tens to hundreds of cores on a single die, each running multiple threads (in contrast to the currently dominant message-passing architectures resulting from the advent of MPI and Linux clusters). Three objectives are proposed: <br\/>. Acquiring computer hardware as a shared community resource capable of efficiently running, in experimental and production modes, complex programs with thousands of threads in shared memory; <br\/>. Assembling software infrastructure for developing and measuring performance of programs running on the hardware; and <br\/>. Building stronger ties between the people themselves, creating ways for researchers at the partner institutions to collaborate and communicate their findings to the broader community. <br\/>The Cray XMT system, scheduled for delivery in 2007 serves as an ideal platform. The second bullet includes algorithms, data sets, libraries, languages, tools, and simulators to evaluate performance of program running on the hardware focusing on applications that benefit from large numbers of threats, massively data intensive, \"\"sparse-graph\"\" problems that are difficult to parallelize using conventional message-passing on clusters. Each university contributes a piece to the infrastructure, using it for support of projects. Sandia National Laboratories has agreed to host the system and provide supplementary funding. Each university will use the Cray XMT system in courses. <br\/><br\/>Broader Impacts: The infrastructure measures performance providing a basis for the community to improve sharin, and build strong ties for collaboration and communication. Courses will be created and materials will be made available. Workshops for dissemination of the findings are also planned.","title":"Collaborative Research: CRI: IAD: Development of a Research Infrastructure for the Multithreaded Computing Community Using the Cray Eldorado Platform","awardID":"0709111","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[335987],"PO":["557609"]},"125895":{"abstract":"Abstract<br\/><br\/>Title: Collaborative Research: Hierarchical Models of Time-Varying natural Images<br\/>PIs: Bruno Olshausen, University of California-Berkeley and David Warland, University of California-Davis<br\/><br\/>The goal of this project is to advance the state of the art in image analysis and computer vision by building models that capture the robust intelligence exhibited by the mammalian visual system. The proposed approach is based on modeling the structure of time-varying natural images, and developing model neural systems capable of efficiently representing this structure. This approach will shed light on the underlying neural mechanisms involved in visual perception and will apply these mechanisms to practical problems in image analysis and computer vision.<br\/><br\/>The models that are to be developed will allow the invariant structure in images (form, shape) to be described independently of its variations (position, size, rotation). The models are composed of multiple layers that capture progressively more complex forms of <br\/>scene structure in addition to modeling their transformations. <br\/>Mathematically, these multi-layer models have a bilinear form in which the variables representing shape and form interact multiplicatively with the variables representing position, size or other variations. The parameters of the model are learned from the statistics of time-varying natural images using the principles of sparse and efficient coding.<br\/><br\/>The early measurements and models of natural image structure have had a profound impact on a wide variety of disciplines including visual neuroscience (e.g. predictions of receptive field properties of retinal ganglion cells and cortical simple cells in visual cortex) and image processing (e.g. wavelets, multi-scale representations, image denoising). The approach outlined in this proposal extends this interdisciplinary work by learning higher-order scene structure <br\/>from sequences of time-varying natural images. Given the <br\/>evolutionary pressures on the visual cortex to process time-varying images efficiently, it is plausible that the computations performed by the cortex can be understood in part from the constraints imposed by efficient processing. Modeling the higher order structure will also advance the development of practical image processing algorithms by finding good representations for image-processing tasks such as video search and indexing. Completion of the specific goals described in this proposal will provide (1) mathematical models that can help elucidate the underlying neural mechanisms involved in visual perception and (2) new generative models of time-varying images that better describe their structure.<br\/><br\/>The explosion of digital images and video has created a national priority of providing better tools for tasks such as object recognition and search, navigation, surveillance, and image analysis. The models developed as part of this proposal are broadly applicable to these tasks. Results from this research program will be integrated into a new neural computation course at UC Berkeley, presented at national multi-disciplinary conferences, and published in a timely manner in leading peer-reviewed journals. Participation in proposed research is available to both graduate and undergraduate levels, and the PI will advise Ph.D. students in both neuroscience and engineering as part of this project.<br\/><br\/>URL: http:\/\/redwood.berkeley.edu\/wiki\/NSF_Funded_Research","title":"RI: Collaborative Research: Hierarchical Models of Time-Varying Natural Images","awardID":"0705939","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["483816"],"PO":["564316"]},"126632":{"abstract":"Proposal #: CNS 07-09168 07-07365 <br\/>PI(s): Dinda, Peter A. Maccabe, Arthur B.<br\/> Bustamante, Fabian E.; Joseph, Russel E. <br\/>Institution: Northwestern University University of New Mexico<br\/> Evanston, IL 60208-1110 Albuquerque, NM 87131<br\/>Title: Colla Rsch:CRD: Community Resource Development: An Open Source<br\/><br\/>Project Proposed:<br\/>This collaborative project, developing an extensible open source Virtual Machine Monitor (VMM) for modern architectures (those that support the Intel VT or AMD Pacifica virtualization extensions), aims to maintain a small codebase size while supporting extensive extensibility. The approach combines compile-time composition of major modules to configure the VMM with run-time extensibility akin to a microkernel. The project is expected to produce a fundamental tool for research in systems and architecture, an open source extensible virtual machine monitor. Expecting to meet the needs within the high-end computing community identified by the FAST-OS effort, the VMM will be used as a shared community resource.<br\/><br\/>Broader Impacts: The infrastructure will be useful in research and education and production context. It will be free and available to all in source code form. Underrepresented groups are impacted through Northwestern's AGEP program and through U NM, a minority serving university.","title":"Collaborative Research: CRI: CRD: An Open Source Extensible Virtual Machine Monitor","awardID":"0709168","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["540138","518224","485831"],"PO":["557609"]},"138732":{"abstract":"In this project, we address issues related to providing system support for remote visualization of time-varying data. A majority of the existing remote visualization systems have adopted the client-server model. The server may become a bottleneck due to the centralized data access and visualization computation. In addition, the network can be easily overloaded because of the large volume of visualization data to be transmitted. To overcome these problems, researchers have proposed various methods to decentralize the remote visualization computation by shifting workload to the clients. The effect of such a workload migration however, is limited since the client 92s computation power is often constrained. Another alternative to reduce the server bottleneck is to deploy multiple servers in the network. However, deployment and management of multiple servers is very expensive, and may raise some policy issues.<br\/><br\/>Our objective is to develop a scalable, lightweight, and easily deployable architecture, which is capable of providing a certain degree of quality of services (QoS) to remote visualization of time-varying data. To achieve this objective, we propose a Peer-to-peer (P2P) system-based architecture. Generally speaking, each node in a P2P system is considered equal, and hence this model is technically different from the client-server one. The highlights of our architecture are (1) Server data and workload are distributed to the groups of volunteer nodes in the Internet which are willing to share their resources. These nodes compose multiple virtual servers. (2) The client is allowed access to the server group via anycast service. Anycast automatically finds the best server in the group, and returns the data to the requesting client. The best server is supposed to provide the best quality of services (i.e. in terms of the minimum delay in data access). (3) A spatio temporal multi-resolution data structure, called Time-Space Partitioning (TSP) tree, where multiple resolution blocks are stored and the data on the sub-trees are independent of each other, is employed. By storing multiple resolution blocks in the tree, a client is permitted more choices in making the selection of best server, which may vary with the system dynamics.<br\/><br\/>In this project, we plan to fully design, analyze, implement, and evaluate the P2P-based<br\/>architecture for remote visualization of time-varying data. We will carry out the following research tasks (1) design, analysis, and implementation of QoS-aware anycast services in the overlay networks; (2) enhancement of the TSP tree structure, especially its data encoding schemes; (3) design, evaluation, and realization of an efficient algorithm for distribution of time-varying data among the volunteer nodes; (4) construction and evaluation of a prototype system based on the proposed architecture.","title":"Collaborative Research: Visualization: Overlay Network Support for Remote Visualization of Time-Varying Data","awardID":"0808417","effectiveDate":"2007-08-31","expirationDate":"2009-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["453727",368857],"PO":["532791"]},"126412":{"abstract":"Proposal #: CNS 07-07975 07-07944 07-08420 <br\/>PI(s): Abdelzaher, Tarek F.; Johnson Scott D.; Goddard, Stephen M.; Ci, Song; Lu, Chenyang <br\/> Kumar,Panganamala R.;Sullivan,William C.;Vaidya,Nitin H. Peng,Dongming;Perez,Lance C.;Shariff,Hamid R.Roman, Gruia C.<br\/>Institution: U Illinois- UC U Nebraska-Lincoln Washington U.<br\/> Champaign, IL 61820-7402- Lincoln NE 68588-0439 St. Louis, MO 63130-4899<br\/>Title: Collab Rsch:CRD\/IAD:Towadrs Cyber-Physical Computing at Scale: A Life-Size Experimental Facility for Applied Sensor Networks Research<br\/><br\/>Project Proposed:<br\/>This collaborative project, developing a large experimental outdoors facility (consisting of a large sensor network) to promote cyber-physical computing research, stimulates several areas of practical cyber-physical computing research, including:<br\/>. Software engineering for cyber-physical systems;<br\/>. Sensor Network development tools and programming abstractions;<br\/>. Low-level communication challenges;<br\/>. Embedded and real-time computing; and<br\/>. Data mining of the physical world (to identify anomalous or interesting patterns in streams of real-time data).<br\/>Cyber-physical systems enhance our interaction with the external environment in a similar fashion to the way the Internet changed how we communicate. Hence cyber-physical computing represents an era in computing where logical processing is more tightly intertwined with the external physical world. These systems offer a myriad of new challenges that stem from combining processing, communication, and physical interaction with the external world. Promoting practical cyber-physical computing research entails adequate experimental testbeds that allow evaluation, validation, and fine tuning of different ideas. The fine-granularity instrumentation required serves as a unifying theme across various studies. Sensor network technology is expected to economically address this need once key sensor network research impediments are resolved. This research facility is likely to be unique in the nation in its scale.<br\/><br\/>Broader Impacts: This work creates opportunities for interdisciplinary research where problems are solved utilizing CS\/CE technology in the context of real applications drawn from environmental and atmospheric science, biology, anthropology, geology, agriculture, etc. The facility enables, among others, studies of infectious disease propagation, climate change, deforestation, and global warming. Additionally, the infrastructure offers active learning educational opportunities.","title":"Collaborative Research: CRI: IAD: Towards Cyber-Physical Computing at Scale: A Life-Size Experimental Facility for Applied Sensor Networks Research","awardID":"0707975","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["541861","553537","487045","553633","556579"],"PO":["564778"]},"129811":{"abstract":"Proposal #: CNS 07-23054<br\/>PI(s): Fox, Geoffrey C.<br\/> Hayden, Linda B.; LeCompte, Malcolm; Pierce, Marlon E.; Stewart, Craig A.<br\/>Institution: Indiana University <br\/> Bloomington, IN 47402-1847<br\/>Title: MRI\/Acq.: Acquisition of Polar Grid: Cyberinfrastructure for Polar Science<br\/> <br\/>Project Proposed:<br\/><br\/>This project, acquiring a sophisticated instrument that addresses crucial ice-sheet science, enables a new generation of high resolution ice-sheet models with realistic boundary conditions that requires distributed PolarGrid Cyberinfrastructure to gather and process data and assimilate these with large simulations. PolarGrid consist of an intermittently disconnected field and base grids feeding information to \"lower 48\" data and computing resources. True real-time processing at the field camp is backed up with increasing fidelity, but increasing delay at the base and \"lower 48\" systems. The requested system includes an expedition grid consisting of ruggedized laptops in a field grid to a low power multi-core based camp cluster. A prototype and two production grids feed into a Teraflops system at Indiana and Elizabeth City State Universities. PolarGrid will be integrated with TeraGrid for both resource utilization and curricula sharing. Modern open data access standards will be followed so that raw processes, and simulated data can be archived outside PolarGrid by and for the science and engineering community. The innovative architecture of PolarGrid with intermittently disconnected components also has applications to other power- and bandwidth-challenged applications. The instrument responds to the recent polar satellite observations that show disintegration of ice shelves in Antarctica and the speed-up of several glaciers in Greenland.<br\/><br\/>Broader Impact: The infrastructure addresses an important current problem that touches all beings in one way or another, the key issue of polar ice disintegration. Strong educational activities are involved, mainly through the training of students. ECSU, a historically black university, involves undergraduate students through new curricula and research experiences.","title":"MRI: Acquisition of PolarGrid: Cyberinfrastructure for Polar Science","awardID":"0723054","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["558523","511575","538992",344336,"538991"],"PO":["557609"]},"128964":{"abstract":"Emerging nanodevices, such as carbon nanotubes, have been recognized as very promising for future technology scaling. A recent innovation has enabled the fabrication of nanotube-based non-volatile random-access memory (NRAM) that has the promise to become a universal memory. NRAMs are suitable for both standalone and embedded memory applications and are fabricated using traditional lithography-compatible manufacturing processes. An NRAM is considerably faster and denser than DRAM, has much lower power consumption than DRAM or flash, has similar speed to SRAM and is highly resistant to environmental forces (temperature, magnetism).<br\/><br\/>The aim of this project is to explore an NRAM-based class of programmable computer architectures, known as a field-programmable gate array (FPGA) family. Initial work in the PI's group on such FPGAs has shown the feasibility of increasing the logic density by over an order of magnitude compared to traditional FPGAs, using the novel concept of fine-grain temporal logic folding, which makes cycle-by-cycle dynamic reconfiguration feasible.<br\/><br\/>The objectives of this project include design space exploration of the NRAM-based FPGA space using a parameterized technology mapping and temporal logic folding tool that takes a mixed register-transfer\/gate level description of a circuit and maps it to an NRAM-based FPGA family instance. The research will also explore the applicability of such FPGAs to computation-unit integrated memories for memory-intensive multimedia applications.<br\/><br\/>The proposed work will make a well-characterized and highly versatile family of NRAM-based FPGAs and associated mapper\/folder available to industry. The material will be included in a new senior-level course on Design with Nanotechnologies. Undergraduate students are expected to participate in this research. Female and minority students will be attracted to this research through Princeton's Presidential Fellowship Program.","title":"CSR---EHS: Non-volatile Carbon Nanotube RAM based FPGA Architectures","awardID":"0719936","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550002"],"PO":["561889"]},"126588":{"abstract":"This project is annotating a corpus of American English for a variety of linguistic features, including syntactic structures and semantic information. The semantic information includes frame information based on FrameNet together with sense information based on WordNet. <br\/>The annotations in the corpus are manually assigned by human annotators to ensure their reliability. Bootstrapping methods, using portions of the hand validated annotations, are being used to improve the performance of automatic annotation tools. The corpus is drawn from the materials in the American National Corpus, which consists of written data and speech transcriptions generated y native speakers of American English and representing a broad range of genres. All of the annotations are represented in a common format to enable merging different annotation layers, so that interactions among different linguistic phenomena can be studied.<br\/><br\/>The manually annotated corpus will provide an unparalleled resource for computational linguists and linguists who seek to identify patterns of syntactic and semantic usage that can feed the development of language models. This information can be used to train software to automatically annotate unseen data, which in turn enhances applications such as information retrieval and extraction and machine translation. Usage patterns for American English are also invaluable for the development of materials and tools to support English language learning. The resulting corpus and its annotations, together with tools for manipulating the data, will be made freely available for research purposes through the Linguistic Data Consortium.","title":"CRI: CRD A Richly Annotated Resource for Language Processing and Linguistics Research","awardID":"0708952","effectiveDate":"2007-08-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["501442"],"PO":["565215"]},"129866":{"abstract":"Proposal #: CNS 07-23281<br\/>PI(s): Kallmann, Marcelo<br\/> Matlock, Teenie; Newsam, Shawn<br\/>Institution: University of California - Merced<br\/> Merced, CA 95343-5001<br\/>Title: MRI\/Acq.: A Cognitive Sensorium and Visualization Facility at UC-Merced<br\/><br\/><br\/>Project Proposed:<br\/><br\/>This project, acquiring equipment to build a cognitive sensorium and visualization facility, integrates real-time eye tracking and motion capture devices with a large high-resolution display. Aiming to lead to advances in human cognition, perception and action, image processing, intelligent systems, and human-computer interaction, the infrastructure enables interdisciplinary research on novel computational models of visual parsing, categorization, cognition, and as well as research for motor planning and execution. Aiming to achieve novel computational models for implementing humanlike intelligent systems, the project supports research in understanding visual processing in humans during task execution. The instrumentation is composed of three modules: A<br\/>. High-resolution immersive screen where virtual scenarios can be simulated for sensing human performances,<br\/>. Head-mounted eye tracker system for accurately tracking the navigation of the user's visual attention point, and<br\/>. Full-body occlusion-free inertial motion-capture equipment for capturing the motions of the user during performances.<br\/>Understanding human-like intelligence is key for the development of seamless and fully integrated attentive user interfaces, affective collaborative work, and many human-computer interaction (HCI) applications needed in the future. Connected to a software architecture dedicated to the motion control and graphical simulation of human-like virtual agents already under development, the equipment supports interdisciplinary research activities such as:<br\/>. Analyzing the visual parsing of features in images,<br\/>. Analyzing the interactions between gaze and gestures for describing features and procedures, and<br\/>. Developing new vision-based motor control algorithms for the coordination of locomotion and reaching during grasping tasks.<br\/><br\/>Broader Impacts: The infrastructure greatly benefits the newest campus of the UC system. The institution services an underrepresented population where the students are usually first generation college students. The facility provides valuable programming and lab skills that contribute to success in high tech jobs and graduate schools. It also improves instruction and development of courses and enables research for many application domains, including training, delivery of instruction, ergonomics, entertainment, HCI, and education.","title":"MRI: Acquisition of Equipment to Establish a Cognitive Sensorium and Visualization Facility at UC Merced","awardID":"0723281","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["543484","502374","543485"],"PO":["557609"]},"126599":{"abstract":"Proposal #: CNS 07-08498 07-09946 07-08420<br\/>PI(s): Preisig, James C Ye,Wei Stojanovic, Milica<br\/>Lee, Freitag Heidenmann, John S.<br\/>Institution: Woods Hole Oceanographic Inst U Southern California Mass Inst Tech<br\/>Woods Hole, MA 02543-1041 Los Angeles, CA 90089-1147 Cambridge, MA<br\/>02139-4307<br\/>Proposal #: CNS 07-09005 07-08938 07-08467<br\/>PI(s): Cui, Jun-Hong (June) Levine, Brian; Kurose,James F. Freitag, Lee<br\/>Rajasekaran,Sanguthevar;Shi, Zhijie;Willett,Peter K.;Zhou,Shengli<br\/>Institution: University of Connecticut U of Massachusetts WHOI<br\/>Storrs, CT 06269-1133 Amherst, MA 01003-9242 Woods Hole, MA 02543-1041<br\/>Title: Collab Rsch:CRD\/IAD:Open Research Testbed for Underwater Ad Hoc and<br\/>Sensor Networks (ORTUN)<br\/><br\/>This collaborative project, developing the first open testbed infrastructure for the<br\/>underwater networking community, enables open access with the capability to conduct<br\/>experiments remotely. The infrastructure, based on open research platforms, consists of<br\/>a testbed that enables wide and systematic experimental evaluation and comparison of<br\/>underwater acoustic networks. The work, involving this rapidly deployable testbed that<br\/>can be shared by the underwater networking community, aims to demonstrate the ability<br\/>of the facility to facilitate field experiments. The project represents a higher-level<br\/>collaborative that arose from two collaborative groups. One group developing the<br\/>facility, the other working mainly on the experiments utilizing the facility. The testbed is<br\/>expected to be a buoy-based system that can be easily taken to different environments.<br\/>When operational, these systems will be deployed 5 or 6 times a year. The<br\/>infrastructure will consist of two types of nodes with different capabilities. The first type<br\/>of node of the rapidly deployable testbed will offer a fixed physical layer capability using<br\/>acoustic modems such as the WHOI micromodem or the ISI S-modem to implement a<br\/>physical layer with limited reconfigurability interfaced to a reconfigurable network<br\/>processor. This network processor will support algorithm\/protocol implementation and<br\/>testing at higher network layers. The Network functions on the Fixed Physical Layer<br\/>testbed will be hosted by a Gumstix processor which will then communicate with<br\/>physical layer modems such as the WHOI Micromodem or USC\/ISI S-modem via a<br\/>serial port. Ten to fifteen fixed physical layer nodes will be built including up to 3<br\/>gateway nodes. Each gateway node of the testbed will be equipped with wireless RF<br\/>communication enabling real-time monitoring and control of network performance. The<br\/>fixed physical layer nodes will be smaller and more easily deployed than the second<br\/>type of node which is the all-layer node. The all-layer node is a more capable node that<br\/>will ultimately support algorithm\/protocol implementation and acoustic data collection at<br\/>all networking layers. In addition to the equipment included in the fixed physical layer<br\/>nodes (i.e., a gumstix network processor and the ability to support relatively fixed<br\/>physical layer modems such as the WHOI Micromodem and the ISI S-modem), the<br\/>all-layer nodes will also include a general purpose data acquisition system (D\/A and<br\/>A\/D) with substantial disk storage and in-situ processing capability. The MIT r-modem<br\/>software will be implemented on this general purpose hardware and, along with<br\/>MATLAB, will enable user implementation and testing of algorithms and the gathering of<br\/>acoustics data at the physical layer in addition to the testing at higher network layers<br\/>that it will share in common with the fixed physical layer nodes. Three to five all-layer<br\/>nodes will be built. The rapidly deployable testbed, using two types of nodes with<br\/>varying capabilities, should significantly enhance research at all network layers while<br\/>setting the stage for future infrastructure improvements.<br\/><br\/>Many research groups investigating fundamental questions about how to design such<br\/>networked systems that utilize acoustic communications in complex underwater<br\/>environments have had their overall effort significantly slowed by the lack of common<br\/>means to test and compare protocols under realistic environmental conditions. This<br\/>infrastructure responds to the need for consensus on analytic or simulation models for<br\/>underwater networks where researchers need the ability to gather experimental data<br\/>under real world conditions in order to make progress.<br\/><br\/>The network stack will be modular by design with sockets used to enable cross layer<br\/>control and communication. The physical, MAC, Network and Application layers will be<br\/>populated with sample components to enable users test their own algorithms or<br\/>protocols without having to populate the entire stack. Users will be able to write modules<br\/>to test their own algorithms or ","title":"Collaborative Research: CRI: IAD: Developing a Novel Infrastructure for Underwater Acoustic Sensor Networks","awardID":"0709005","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[335915,"559638","546033","526410","550179"],"PO":["557609"]},"126489":{"abstract":"As a result of increased logic capacity, reconfigurable logic devices, such as field programmable gate arrays (FPGAs), have become increasingly important components in many digital systems. The programmable structure of these devices offer designers the opportunity to quickly map parallel designs to silicon while customizing circuitry to exactly the functionality desired. The successful use of this circuitry relies heavily on design mapping flows of intricate and complex computer-aided design tools and compilers. As the programming models used by designers to target reconfigurable logic devices become more diverse, the need to optimize tools both individually and jointly becomes more important. It is widely recognized that researchers in this reconfigurable computing field will require easy access to representative tool sets, documentation describing how to combine them into mapping flows, and a collection of representative benchmarks in the near future to sustain research progress.<br\/><br\/>The need for greater accessibility to freely-available reconfigurable computing CAD tools forms the cornerstone of this proposal. Upon completion of the project, designers will have access to a well-organized repository of documented tools and compilers including documentation on how to coordinate multiple tools together into complete design mapping flows. This infrastructure will allow researchers to optimize existing tools for new design goals and develop new, more advanced tools which use the current infrastructure as a basis. All resources in the infrastructure will be hosted in web-based repositories at the University of Massachusetts, Amherst and the University of Wisconsin, Madison. Funding for this project will be used to acquire needed computer hardware and web-based resource distribution materials, and to support graduate student researchers who will organize the infrastructure. Upon completion, the infrastructure will be made publicly-available and will be widely publicized to researchers in a variety of research fields.<br\/><br\/>This proposal outlines a series of development steps to achieve this goal including the acquisition of existing CAD tools and compilers, the construction of a web-based infrastructure, the integration of the individual tools into a series of end-to-end mapping flows, and the development of an infrastructure deployment strategy. The proposed development work is closely tied to learning opportunities for graduate and undergraduate students. These students will have the opportunity to become familiar with state-of-the-art design tools and advanced web-design and database building techniques. Preliminary contact with researchers in both academic and commercial settings has indicated strong interest. It is expected that as the project progresses external parties will assist in offering technical direction and support in terms of CAD tools and benchmarks. As the project nears completion, a consortium of academic and industry partners will be solicited to continue support for the infrastructure.","title":"Collaborative Proposal: CRI: CRD: Computer-aided Design Tool and Compiler Repository for Reconfigurable Computing","awardID":"0708377","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["377736"],"PO":["565272"]},"137149":{"abstract":"Abstract<br\/>--------<br\/><br\/> Digital communication, embodied in such applications as cell phones and wireless Internet, by now pervades our daily lives, while digital storage devices, such as CDs, DVDs, and computer disk drives, have become the principal means of preserving our information. In the \"information age\" in which we all now live, the need for reliable transmission and storage of digital data is of paramount importance. What makes such reliable transmission and storage possibles are error-correcting codes, first conceived by Claude Shannon over 50 years ago. Indeed, as you are reading these lines, millions of error-correcting codes are decoded every minute, using efficient algorithms implemented in custom VLSI circuits. At least 75% of these circuits decode Reed-Solomon codes, invented by Irving Reed and Gustave Solomon in the 1960s. In the four decades since their invention, Reed-Solomon codes have been extensively studied and ingenious decoding algorithms for these codes have been developed. What has been realized only recently, however, is that Reed-Solomon codes can correct many more errors than previously thought possible! In a series of theoretical breakthroughs, Sudan, Guruswami-Sudan, and Koetter-Vardy have made state-of-the-art Reed-Solomon decoders out of date. At least in principle, we can now achieve much better performance with the same codes. The goal of this project is to follow-up on this exciting recent work and to follow this line of research through to its ultimate potential, in theory as well as in practice.<br\/><br\/> In order to attain this goal, we plan a broad line of attack. On one hand, the proposed investigation will address deep theoretical questions. Can one exceed the Guruswami-Sudan decoding radius? What is the optimal multiplicity assignment for algebraic soft-decision decoding? How can iterative decoding methods be applied to Reed-Solomon codes? On the other hand, we intend to go all the way to the first-ever VLSI implementation of a soft-decision Reed-Solomon decoder. The proposed VLSI architecture aims for high speed and low power dissipation. Thus complexity considerations, inherently motivated by the practice of VLSI design, will be paramount throughout our investigation. Specifically, The main topics to be investigated are: (1) Multivariate interpolation decoding beyond the Guruswami-Sudan radius; (2) Probabilistic model and multiplicity assignment schemes for algebraic soft-decision decoding; (3) Iterative methods for soft decision decoding of Reed-Solomon codes; (4) Analytic bounds on the performance of maximum-likelihood and suboptimal decoders; and (5) Complete VLSI implementation of a state-of-the-art soft-decision Reed-Solomon decoder in an FPGA and\/or ASIC.","title":"Next Generation Decoders for Reed-Solomon Codes -- Collaborative Research","awardID":"0801255","effectiveDate":"2007-08-30","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["485936","385127"],"PO":["432103"]},"139118":{"abstract":"The investigator studies three new coding-theoretic paradigms arising during the processes of genetic data acquisition, analysis, and modeling. The biological principles governing the systems for which coding solutions are sought are DNA and RNA sequence hybridization and self-hybridization. The bio-chemical property supporting hybridization is the affinity of bases in single DNA and RNA strands to form hydrogen bonds with their complementary bases, defined in terms of the Watson- Crick rule. By forming such bonds, paired bases generate planar or spatial structures that are comprised of two complementary strands or one single strand. Bonded structures have increased stability, but they also serve an important role in regulating various cellular functions, including pre-mRNA editing or post-transcriptional gene silencing. In certain cases, specific self-hybridization patterns in DNA sequences represent precursors to sequence breakage and are closely associated with genetic diseases such as cancer. <br\/><br\/>Besides its chemical and physical properties, the process of sequence hybridization has distinctly combinatorial features. These combinatorial features are used by the investigator to establish a rigorous mathematical framework in which to analyze technological and biological systems operating on the principle of sequence hybridization. Several classical coding schemes are analyzed in new biological settings, including superimposed designs, balanced codes, and run-length constrained codes. Such schemes are generalized, combined, and optimized for a given application. Furthermore, some new coding-theoretic and algorithmic problems are introduced that lead to challenging and interesting new research directions in algebraic coding theory. The outlined interdisciplinary research efforts are expected to have significant impact on the development of cDNA and aptamer microarrays and are also expected to lead to the creation of a new educational program at the University of Colorado, Boulder.","title":"CAREER: Coding Theoretic Problems in Genetic Data Acquisition, Modeling and Analysis","awardID":"0809895","effectiveDate":"2007-08-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["518457"],"PO":["564898"]},"128239":{"abstract":"Privacy protection challenges arising from location-based services (LBS) are critical to users as well as service providers. This project concentrates on designing and evaluating privacy protection techniques in LBS. The important departure of this project from the existing research is in its emphasis of the role of request contexts. A context refers to the external information\/knowledge that the attacker may use, together with the requests themselves, to gain user private information. For example, with the external knowledge of a user's approximate location at a particular time, the attacker may single out the user of a particular LBS request and thus link the private information in the request to the user. By its nature, context changes from requests to requests and different contexts may call for different privacy protection techniques. The technical objectives of the project are therefore to (1) systematically categorize privacy contexts, (2) analyze existing defense strategies, and (3) design and evaluate new defense strategies. <br\/><br\/>From an educational perspective, the project involves graduate students and exposes them to leading-edge researches, and incorporates research results into classrooms. In addition, the project provides a platform for active collaborations among a broader set of researchers of the two institutions. The results from this project will have a positive impact on protecting user privacy and on people's willingness to adopt LBS in enhancing their living and working conditions. Research results will be disseminated through technical reports, publications at conferences and journals, and the websites at http:\/\/csis.gmu.edu\/NSFLBSprivacy and http:\/\/www.cs.uvm.edu\/~xywang\/NSFLBSprivacy.","title":"COLLABORATIVE RESEARCH: CT-ISG - A Context-Aware Approach to the Design and Evaluation of Privacy Preservation Techniques in Location-Based Services","awardID":"0716575","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":[339916,"427499"],"PO":["565136"]},"129218":{"abstract":"While mobile embedded systems usually operate in a dynamic ecosystem that includes ambulatory users and changing network conditions, their ability to sense the physical world is limited. Leveraging findings from research in human factors and cost-effective, low-power sensors, this project seeks to enhance sensing capability and provide adequate system support for mobile sensing, and to explore energy-efficient system policies and novel applications that can benefit from this work. <br\/><br\/>This research project is building an open-source system framework that incorporates user information into system resource management. This user-aware framework will enable a mobile embedded system such as an enhanced cell phone or PDA to adapt processing, sensing, communicating in a coordinated fashion, and to support the manner in which these tasks interface for higher operational efficiency. To build this framework, this project investigates energy-efficient integration of low-power sensing, studies system mechanisms to accommodate user information, and provides open-source implementation and programming interfaces. This project applies the user-aware framework to the energy-efficient management of wireless data, particularly within the context of mobile healthcare. In collaboration with health scientists, the project seeks to devise system policies based on the user-aware framework and build prototypes from commercial-off-the-shelf (COTS) components for evaluation under realistic conditions and through field studies. This project is expected to produce enabling technologies for new applications of mobile embedded systems. Through the global penetration of mobile phones, this research hopes to empower low-income populations with relevant applications that go well beyond voice communication, with particular emphasis in healthcare. The research results are being incorporated into undergraduate and graduate courses in mobile embedded systems. Research tools, collected data, and educational content are made open-source and on-line.","title":"CSR---EHS: Coordinated Energy Optimization of Mobile Embedded Systems with User Information","awardID":"0720825","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["548312"],"PO":["561889"]},"129108":{"abstract":"Internet services have become an important class of driving applications for scalable and quality aware distributed computing technologies. Service differentiation is to provide different quality levels to satisfy requirements of Internet services by allocating resources to classified user requests in a biased way. In this research project, the investigators take an analytical and organized approach to examine resource management techniques for quantitative service differentiation in popular multi-tier server clusters. Multi-tier clusters provide new computing opportunities but also challenges such as cross-tier performance dependencies and concurrency limits. The project designs sound differentiation models that consider both system-wide resource allocation optimization and user-side fair service quality provisioning. It provides service differentiation and system performance analysis from a new important metric, slowdown, defined as the ratio of a job's delay to its service time. The deliverables are innovative resource allocation approaches for predictable and controllable service differentiation and performance isolation on multi-tier server clusters, based on the foundations of queuing theory and control theory. The significance of the research is to provide quality aware Internet computing techniques. The impacts lie in renewing the understandings of computer system performance from the unique slowdown perspective and in quality control for scalability and dependability enhancements of the distributed systems. Potential applications include an artifact against flash-crowds traffic. The research results will be disseminated to the public as published technical reports. The project will help the society develop quality aware applications and salable computing technologies for popular Internet services.","title":"CSR-PDOS: Resource Allocation Optimization for Quantitative Slowdown Differentiation in Multi-tier Server Clusters","awardID":"0720524","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550728"],"PO":["535244"]},"129229":{"abstract":"Some of the most exciting cyber technologies on the research horizon involve sophisticated digital systems that interact with the physical world. Examples include remote surgery, physical manipulation of nano-structures, autonomous (ground and air) vehicular travel, and space and terrestrial exploration. Because such applications interact directly with the physical world, it is imperative their physical safety be assured. This project is developing a comprehensive formal framework for producing controllers for cyber-physical systems, with machine checkable proofs of their physical safety. The project brings together ideas from control theory, language design, program verification, program generation, software engineering, and real-time and embedded systems to build a framework that can be applied to challenging applications. The framework promotes an efficient, rigorous engineering process for producing embedded controllers, incorporating explicit models not only of the controller itself, but also of the physical context in which it operates, the required stability conditions, the platform on which it will run, and the associated real-time constraints. The results of the project are being demonstrated and evaluated in the context of a tele-surgery application. This application is currently being developed at the Mechatronics and Haptic Interfaces Lab in the Mechanical Engineering Department at Rice University.","title":"Collaborative Research: CSR\/EHS: Building Physically Safe Embedded Systems","awardID":"0720857","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["495364","495365","532891"],"PO":["561889"]},"132760":{"abstract":"This award supports a workshop to enable public presentation and discussion of the final report of the study on \"Sufficient Evidence? Building Certifiably Dependable Systems,\" conducted under the auspices of the National Academies. Critical systems are often subject to certification: a formal assurance that the system has met relevant technical standards designed to assure it will not unduly endanger the public, and can be depended upon to deliver its intended service safely and securely. Today, certification of the dependability of a software-based system usually relies more on assessments of the process used to develop the system than on the properties of the system itself. Although these assessments can be useful, few would dispute that direct observation of the artifact ought to provide a stronger kind of assurance than the credentials of its production method. Yet the complexity of software systems, as well as the discontinuous way that they behave, renders them extremely difficult to analyze unless great care has been taken with their structure and maintenance. This workshop provides a forum in which the conclusions from the study report will be presented and invited panels of discussants will be asked to react to the report and consider implications and next steps for relevant R&D and user communities in government, the private sector, and universities.","title":"Sufficient Evidence: Building Certifiably Dependable Systems--A Workshop","awardID":"0738120","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"T919","name":"NSA-SOFT WARE SYSTEM"}}],"PIcoPI":["560890"],"PO":["561889"]},"129119":{"abstract":"This research effort is focused on developing formal methods for modeling dynamics and supporting robustness analysis of cyber-physical systems, using tools from dynamical systems theory, control theory and computer science. Specifically, the project addresses the need to develop efficient techniques for uncertainty propagation that exists due to operational uncertainties arising from time-varying task sets and control impediments present in cyber-physical systems. The approach is to abstract cyber-physical systems as distributed embedded systems with heterogeneous architecture platforms and multi-functional paradigms. Such abstractions are required to accomplish real-time, multi-mode operations with tasks allocated at run-time, and in the presence of uncertainty. The operational uncertainties considered include those due to varying task loads caused by operational mode changes, the failure of a few elements when deployed in a hostile environment, transient computational overloads and communication delays. Key technical thrusts in this research include developing methods for uncertainty management in embedded systems based on methods of ergodic theory, set-oriented numerical techniques, multi-scale Markov chain approximations of dynamics and spectral graph partitioning and aggregation concepts; modeling of cyber-physical tasks using sampling methods and finite horizon estimation techniques; and providing Lyapunov certificates for robust performance of cyber-physical systems. Using such a framework in system development is expected to significantly improve the reliability of cyber-physical systems.","title":"CSR---CPS: Design of Robust and Energy Efficient Cyber-Physical Systems Using Dynamical Systems and Control Theory","awardID":"0720541","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["426973","560356","562656"],"PO":["561889"]},"130252":{"abstract":"This project, involving collaboration between North Carolina State University and Purdue University, addresses the design of Healthcare information systems. Such systems are becoming ubiquitous and thus increasingly subject to attack, misuse and abuse. Specifications and designs of these systems often neglect security and privacy concerns. Moreover, regulations such as HIPAA (Health Insurance Portability and Accountability Act) as well as security and privacy policies are difficult for users to understand and complex for software engineers to use as guides when designing and implementing systems. This project defines mechanisms that are needed to help analysts disambiguate regulations so that they may be clearly specified as software requirements. In addition, regulations are increasingly requiring organizations to comply with the law and account for their actions. Individuals responsible for ensuring compliance and accountability currently lack sufficient guidance and support to manage their legal obligations within relevant information systems. Software controls are needed to provide assurances that business processes adhere to specific requirements, especially those derived from government regulations.<br\/><br\/>To address these challenges, the proposed work takes a holistic view of the design of transparent and legally compliant software systems. Key research questions that are addressed include: <br\/>-How should system requirements be specified so they may be realized in design and implementation to ensure legal and regulatory compliance? <br\/>-Given that software designs need to satisfy multiple stakeholders (organizations, law\/policy makers, government agencies, public citizens, etc.) having contradictory, inconsistent and difficult to understand objectives, how can the design process of these systems be improved to lead to convergence and satisfaction of these requirements in a transparent and auditable fashion? <br\/><br\/>This project articulates a requirements management framework that enables executives, business managers, software developers and auditors to distribute legal obligations across business units and\/or personnel with different roles and technical capabilities. This framework improves accountability by integrating traceability throughout the policy and requirements lifecycle. The broader impacts of this project are expected to be far reaching as law and regulations govern the collection, use, transfer and removal of information from software systems in many spheres of society.","title":"SoD: Collaborative Research: Transparency and Legal Compliance in Software Systems","awardID":"0725144","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":["517936"],"PO":["564388"]},"130274":{"abstract":"Computer science is, in many ways, a design discipline. Computer scientists design algorithms, interfaces, interactions, specifications, programs, systems and simulations. The studio method of instruction is prevalent in the preparation of professionals within a variety of other design disciplines, such as architecture and industrial design. Although a few innovative computer science programs have implemented the studio method, and the logistics and procedures involved have been well-documented, little is known about which components of the studio experience are critical to successful outcomes. Research on effective learning strategies and the characteristics of innovative work groups could further illuminate the group processes and classroom environment that contribute to successful design studio experiences. We have much to gain by examining techniques that are effective in the preparation of other designers in order to strengthen the preparation of computer science professionals who are capable of meeting the critical software design challenges of the 21st century. Toward this end, the PIs will leverage knowledge about design education from architecture and industrial design, to develop new educational models and materials for the design of software-intensive systems, specifically in the area of Human Computer Interaction (HCI). In the first two years of the project the PIs will focus on research involving data collection and analysis to examine in detail the impact of the studio method on how students learn HCI design. The data analysis will be informed by the literature on cognitive apprenticeship teaching methods and characteristics of innovative work groups, in order to illuminate the group processes and environment that contribute to successful outcomes within design studio experiences. Through an investigation of the design process used within an interdisciplinary studio-based project and HCI courses that incorporate a modified studio method, the PIs will formulate guidelines for implementing the studio method in HCI courses and will derive principles that can be applied to the education of future computer science professionals. In the third year, the effectiveness of the curriculum guidelines will be evaluated through pilot testing in HCI classrooms, and revised based on the results of the formative evaluation. Research outcomes and curriculum guidelines will be disseminated through presentations, publications, and a project web site.<br\/><br\/>Broader Impacts: Based on an investigation of factors that contribute to creative group processes and products within an academic design studio environment, the PIs will advance software design research and education through the development of new models and methods that are supported by empirical evidence and that are teachable. In this way, the PIs will develop a strong intellectual foundation for teaching software design, which has the potential to transform the teaching of HCI, and ultimately for improving the processes of constructing, evaluating, and modifying software-intensive systems across a variety of computer science specialty areas.","title":"Collaborative Research: Investigating and Refining the Studio Experience as a Method for Teaching Human Computer Interaction","awardID":"0725215","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":[345687],"PO":["565227"]},"132342":{"abstract":"A digital library (http:\/\/recovery.dlib.vt.edu) is designed to support a wide range of research studies, as well as inquiries from the general public, related to the tragedy that occurred during the morning of April 16, 2007 on the Virginia Tech campus in Blacksburg, VA when 33 members of the university community were killed by a student turned gunman. There is a catalog of related content, along with selected data and multimedia information, submitted from a variety of sources. These will be incorporated in the \"\"Virginia Tech 4-16-07 Library Archive\"\", permanently supported by University Libraries.<br\/><br\/>The target audience includes those interested in how technology aids detection, prevention, and responding to disasters in highly connected settings (e.g., in Virginia's largest university community, at the heart of the Blacksburg Electronic Village). A key question is how digital libraries can work in rapid-response settings, as well as for studying the aftermath of tragedies. <br\/><br\/>The thrust of this project is development of rapidly prototyped tailored systems for diverse user communities using the 5S theory (i.e., with formally defined underlying concepts: Streams, Structures, Spaces, Scenarios, and Societies), which provides a foundation for integration of distributed content and services. This project will lead to development of the theory and software support for large scale digital libraries that also allow researchers to apply closely-coupled data mining and visualization services, e.g., so that archived content can be efficiently and conveniently analyzed, and so that trends and outliers can be spotted. Computer and information scientists, following legal, policy, and human-subject guidelines, can study portions, or the whole complex, of the resulting testbed - of content, services, usage logs, etc.<br\/><br\/>Wide use of the digital library by scholars and the public, as well as dissemination of results, through the WWW, publications, and presentations, will ensure the broadest impact.","title":"SGER: DL-VT416: A Digital Library Testbed for Research Related to 4\/16\/2007 at Virginia Tech","awardID":"0736055","effectiveDate":"2007-08-15","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["550463","550462","498314","518252","387907"],"PO":["563751"]},"125841":{"abstract":"III-CXT: Learning from graph-structured data: new algorithms for <br\/>modeling physical interactions in cellular networks<br\/><br\/>The complex behavior of the cell derives from an intricate network of <br\/>molecular interactions of thousands of genes and their products. <br\/>Understanding how this network operates and predicting its behavior <br\/>are primary goals of biology and have broad implications for life <br\/>science, medicine and biotechnology.<br\/><br\/>The genomic information revolution of the last ten years has enabled <br\/>new systems-level and data-driven approaches for studying cellular <br\/>networks. In particular, using machine learning to model gene <br\/>regulatory networks---the switching on and off of genes by regulatory <br\/>proteins that bind to non-coding DNA---has emerged as a central <br\/>problem in systems biology. Now, an explosion of new high-throughput <br\/>technologies for measuring physical interactions between proteins and <br\/>between protein and DNA provides a new data integration challenge for <br\/>computational modeling of gene regulation. These new data can all be <br\/>viewed as graph-structured data, or physical interaction networks.<br\/><br\/>The central computational goal of this project is to develop new <br\/>machine learning learning algorithms for exploiting graph-structured <br\/>data, including: (1) boosting with efficient graph mining; (2) graph <br\/>kernels based on subgraph histogramming; and (3) information-based <br\/>graph partitioning. These new algorithms will be used to integrate <br\/>physical interaction network data into models of gene regulation in <br\/>order to better represent underlying biological mechanisms. The <br\/>focus will be two fundamental modeling problems: inferring signal <br\/>transduction pathways and modeling cis regulatory modules at the <br\/>level of DNA sequence and interacting regulatory proteins. The <br\/>algorithms will be applied both to publicly available data and to <br\/>primary gene expression data provided by one of the investigators to <br\/>study the hypoxia in yeast and the response to environmental toxins <br\/>in mammalian neural cells.<br\/><br\/>This project will learn systems-level models that lead to new insight <br\/>into the underlying mechanisms of gene regulation and open the way to <br\/>broader biological discoveries. All data, results and source code <br\/>will be publicly available via the Web (http:\/\/www.cs.columbia.edu\/ <br\/>compbio\/cellular-networks) and disseminated through courses and <br\/>bioinformatics software packages. The project will also create <br\/>undergraduate research opportunities for joint dry and wet lab <br\/>projects and outreach activities to introduce New York City public <br\/>high school students to new interdisciplinary areas of science.","title":"III-CXT: Learning from graph-structured data: new algorithms for modeling physical interactions in cellular networks","awardID":"0705580","effectiveDate":"2007-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["490501","543344","384160"],"PO":["563727"]},"125786":{"abstract":"The goal of the proposed research is to create analytical and computational tools that explicitly address the time and order of social interactions between individuals. The proposed approach combines ideas from social network analysis, Internet computing, distributed computing, and machine learning to solve problems in population biology. The diverse computational tasks of this project include design of algorithmic techniques to identify social entities such as a communities, leaders, and followers, and to use these structures to predict social response patterns to danger or disturbances. Nowhere is the impact of social structure likely to be greater than when species come in<br\/>contact with predators. Thus, the accuracy and predictive power of the proposed computational tools will be tested by characterizing the social structure of horses and zebras (equids) both before and after human- or predator-induced perturbations to the social network. The proposed interdisciplinary research will have broader impacts on a wide range of research communities. New methods for analysis of social interactions in animal populations will be useful for behavioral biologists in such diverse fields as behavioral ecology, animal husbandry, conservation biology, and disease ecology. The machine learning algorithms that will be develop are relevant to many studies in which researchers need to classify temporal interaction data. The proposed network methods have broader relevance to human societies: disease transmission, dissemination<br\/>of ideas, and social response to crises are all dynamic processes occurring via social networks. Further, through teaching and participation in outreach, students and school teachers will gain access to opportunities for hands-on, interdisciplinary experiences in a new area of computational biology. The research and software resulting from the proposed project will be disseminated both in computational and biological communities and enhanced by cross-disciplinary training activities and will serve to train a new generation of interdisciplinary scientists.","title":"III-CXT: Collaborative Research: Computational Methods for Understanding Social Interactions in Animal Populations","awardID":"0705311","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["522280"],"PO":["565136"]},"126655":{"abstract":"Proposal #: CNS 07-09285<br\/>PI(s): Huang, Yan<br\/> Acevedo, Miguel F.; Fu, Shengli; Li, Xinrong; Thompson, Ruthanne<br\/>Institution: University of North Texas<br\/> Denton, TX 76203-5250<br\/>Title: IAD: Infr for Environmental Monitoring and Modeling using Large-Scale Sensor Networks<br\/><br\/>Project Proposed:<br\/>This project, developing a publicly available environmental monitoring computer research infrastructure, incorporates open sensor network platforms and tools with intertwined wired and wireless sensors and actuators to support computing research and education. Through the one-stop web interface, users will be able to perform over-the-air programming on the wireless sensor networks and collect, model, and visualize real-time environmental data about water, land, and air from thousands of miles away. A channel measurement toolbox will be developed to capture propagation characteristics for the field of wireless sensor networks. Extensive data, including RF signal strength and throughput, will be collected for different scenaris. The work contributes to develop the Texas Environmental Observatory (TEO) that builds upon and goes beyond the ECOPLEX (Environmental Conditions Online of DFW MetroPLEX). TEO provides a real life testbed for projects that would be impossible without the deployment of large-scale environmental monitoring sensor networks and the fine-grained spatio-temporal sensor data.<br\/><br\/>Broader Impacts: The infrastructure enables immediate interdisciplinary research and education projects that include energy efficient map interpolation, robust localization models, code designs for cooperative communication in wireless sensor networks, high resolution near real time environmental monitoring and modeling, and modeling for K-12 teachers\/students.","title":"CRI: IAD Infrastructure for Environmental Monitoring and Modeling using Large-Scale Sensor Networks","awardID":"0709285","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["465581",336094,"547799","494076","451487"],"PO":["557609"]},"126457":{"abstract":"We propose to build a Digital Imaging Laboratory that will support research, teaching and cross-disciplinary collaboration at the boundary of Art, Engineering, Law and Science. Four primariy research projects will be supported by this Laboratory: (1) Distinguishing between real and computer generated images and video; (2) Building compact and intuitive representations of human motion; (3) Art authentication; and (4) Lighting art. The Laboratory will also be made available to students enrolled in the newly created Digital Arts minor. And, faculty and students across the Dartmouth campus will be able to take advantage of the Digital Imaging Laboratory. Progress reports for this project will be regularly updated at www.cs.dartmouth.edu\/farid.","title":"CRI: IAD: Digital Imaging Laboratory at Dartmouth","awardID":"0708209","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["511583","517794",335491,"357221"],"PO":["564316"]},"127447":{"abstract":"In order to understand the genetic factors underlying complex diseases, disease association studies are performed, where cases and controls are collected and their DNA variants (SNPs) are compared. One of the main growing concerns in disease association studies is that population substructure may raise spurious discoveries, especially with the recent advances in technology where thousands of individuals are genotyped over the whole genome. In particular, if the cases and controls are collected from populations with different ethnic composition, the differences between the SNP variations in the two groups may be due to the population structure and not due to the disease. The main goal of this project is to develop efficient and accurate tools for population stratification methods, under different scenarios, and to integrate those tools in case control studies. The existing methods are either too slow or do not accurately predict the population substructure, and they lack rigorous analysis that proves their correctness. The new algorithms will consider cases in which the population is a collection of populations, populations in which individuals may have a mixed ancestry and use haplotype correlations to improve the algorithms. The impact of this proposed project stems from the fact that many current results reported in association studies are spurious due to population substructure, resulting in an incorrect understanding of the biological mechanisms causing a disease. The algorithms developed in this project will help to avoid such spurious results, thus improving our understanding of human biology and disease. The project involves the training of a graduate student and six summer students. The collaborative nature of the project will expose the students to the medical and genetics worlds, and at the same, it will improve their abilities to design and implement complex algorithmic problems. The software developed in this project will be integrated with the existing publicly available webserver HAP, which was developed by the PIs and has been used more than 9000 by geneticists worldwide.","title":"III-CXT: Population Stratification Methods","awardID":"0713254","effectiveDate":"2007-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["561682","517894"],"PO":["565136"]},"128207":{"abstract":"Mobile ad hoc networks (MANETs) are finding growing applications in time-critical and mission-critical scenarios such as disaster rescue?C public safety and military operations. The purpose of this project is to investigate two very important but mostly untouched MANET security issues: user unlocatability and communication anonymity. Without solving them, mobile users can be easily tracked or their communication patterns can be easily gathered for user profiling, which would jeopardize the user privacy and make them vulnerable to pinpoint attacks. In this project, a novel overlay-based approach OverUCA, an anonymous network overlay composed of nodes that anonymously communicate with one another atop the underlying MANET substrate, will be investigated to achieve user unlocatability, source anonymity, destination anonymity, source-destination unlinkability, and full compatibility with existing routing and MAC protocols. The success of this research will have a tremendous impact on advancing the deployments of MANETs in security-critical commercial, civilian, and military applications. This research will provide a viable way to fight against pinpoint attacks, advance the state-of-the-art in the wireless security research, and spark new research activities in securing MANETs. Moreover, the results from this research will be disseminated widely through high-quality conference and journal publications and public talks. Furthermore, the research outcome will be integrated into the educational curricula across two institutions. Finally, a couple of minority (female) students will work for their Ph.D. degrees, and hence this project will train the minority professionals for the national work force.","title":"COLLABORATIVE RESEARCH: CT-ISG: Overlay-Based User Unlocatability and Communication Anonymity in Mobile Ad Hoc Networks","awardID":"0716450","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560200"],"PO":["497499"]},"128229":{"abstract":"0716540 CT-ISG: Certified Runtime Code Manipulation<br\/>PI: Zhong Shao <br\/>Yale University<br\/><br\/>Runtime Code Manipulation (RCM) refers broadly to any programming<br\/>construct that purposely loads, generates, or mutates code at<br\/>runtime. A large number of today's systems software and virtual<br\/>machines use various forms of the RCM constructs---many of which are<br\/>often targets for security attacks. Unfortunately, existing<br\/>logic-based formal methods---including both program verification and<br\/>model checking---all assume that program code is immutable. This<br\/>project aims to fix this major limitation so that existing<br\/>verification technologies can also be used to certify important<br\/>software that use RCM functionalities (e.g., OS boot loader, virtual<br\/>machine, JIT compiler, dynamic linker and loader). The PI will adapt<br\/>and extend ideas from recent work on certified programming and<br\/>proof-carrying code, develop new methodologies for verifying runtime<br\/>code generation, linking, and mutation, and show how to scale our<br\/>approach to real-world system applications. Successful research on<br\/>certifying general RCM constructs will remove a critical (yet<br\/>bug-prone) piece of software from the trusted computing base in many<br\/>of today's mission-critical systems. The machine-checkable<br\/>specifications and proofs will make it easier to understand and<br\/>maintain existing RCM implementations and to adapt them to satisfy<br\/>particular needs of sophisticated application software. The PI will<br\/>also develop new instructional material for certified RCM constructs<br\/>and provide tutorial training to the general public.","title":"CT-ISG: Certified Runtime Code Manipulation","awardID":"0716540","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["550517"],"PO":["521752"]},"129219":{"abstract":"Parallel machines of high capability are being designed and built to run Software for scientific and engineering modeling. This project is conducting research to create a simulation environment that allows applications to be developed, tested and tuned via simulation of the future machine, while allowing machine designers to tune their architectural choices to benefit a specific collection<br\/>of applications. It aims at simulating petascale machines with over a million processor cores. The project builds upon previous research on migratable objects, and a preliminary simulation system developed in earlier research. The software developed in this project is being distributed via the Internet, and consists of an emulator and a simulator. The emulator allows application developers to develop and test their application in a realistic petascale environment and generate traces for the simulator. The simulator uses the traces, along with a model of the architecture, to generate detailed performance data that can be used to tune the applications and to analyze the architectural choices under realistic application loads.<br\/><br\/>Software for Scientific and Engineering modeling can make a significant impact on society through better understanding of physical phenomenon and improved design of engineered artifacts. The results of this project, including the simulation software, will lead to effective use of the petascale computing facilities being developed and deployed nationally, for such software. It will reduce delays in software tuning. The project will also help train a new generation in techniques for effectively harnessing large parallel machines to society's goals.","title":"CSR---SMA: BigSim: Performance Prediction for Petascale Machines and Applications","awardID":"0720827","effectiveDate":"2007-08-01","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558488"],"PO":["535244"]},"129109":{"abstract":"Embedded systems are of vital economic importance and are literally becoming ubiquitous. They have already become an integral component of safety critical systems involving aviation, military, telecommunications, and process control applications. Interest in embedded systems is growing further due to the expectation that they will become a key component of many commonplace consumer appliances. Consumers will expect levels of reliability and predictability associated with the very best brands of cars, televisions, and refrigerators. Glitches, crashes, and general erratic behavior of the sort seen with prior generations of consumer PC software products will be unacceptable for these embedded applications. It thus becomes crucial that these embedded software systems satisfy high levels of correctness criteria, well above those of today's large software systems, which are often highly error-prone. This project will engage in research and development of a novel methodology for the systematic development of embedded systems, starting at a high-level property-based specification of system requirements and proceeding in a seamless and rigorous manner towards a running code. Central to the proposed design flow is the utilization of powerful new effective methods for the automatic synthesis of running code from behavioral (i.e., temporal) specifications. This technology will be used in two places: first, in order to determine whether a given property-based specification is realizable. Then, selected modules of the design, whose performance is not critical, will be generated by automatic synthesis. Automatic synthesis can also be used for rapid prototyping of larger portions of the design.<br\/>In view of this master plan, the following main research activities are pursued:<br\/>(1) development of a formal property-based language for specifying requirements, including behavioral, temporal, and structural constraints; supported by effective algorithms for the analysis of large specifications for consistency and realizability; development of a methodology for the automatic synthesis of an executable specification from the requirements specification language, to be used both for checking the realizability of large specifications, and the automatic construction of selected modules of the design; and (3) development of methods for the verification of the intermediate representations of the systems against requirements, using the techniques of translation validation. The property-based development approach has been recently applied successfully to the derivation of hardware designs. In view of this success, the application to the systematic construction of embedded systems is highly promising. This research pursues the generalization of the specification language to include real-time elements and continuous signals, and extends the synthesis approach to accommodate real-time and hybrid systems. With these capabilities, this project is expected to enable systematic co-design of software\/hardware for the construction of embedded systems.","title":"Collaborative Research: CSR--EHS: Property-Based Development of Reactive and Embedded Systems","awardID":"0720525","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["362818","550555"],"PO":["557609"]},"130253":{"abstract":"Computer science is, in many ways, a design discipline. Computer scientists design algorithms, interfaces, interactions, specifications, programs, systems and simulations. The studio method of instruction is prevalent in the preparation of professionals within a variety of other design disciplines, such as architecture and industrial design. Although a few innovative computer science programs have implemented the studio method, and the logistics and procedures involved have been well-documented, little is known about which components of the studio experience are critical to successful outcomes. Research on effective learning strategies and the characteristics of innovative work groups could further illuminate the group processes and classroom environment that contribute to successful design studio experiences. We have much to gain by examining techniques that are effective in the preparation of other designers in order to strengthen the preparation of computer science professionals who are capable of meeting the critical software design challenges of the 21st century. Toward this end, the PIs will leverage knowledge about design education from architecture and industrial design, to develop new educational models and materials for the design of software-intensive systems, specifically in the area of Human Computer Interaction (HCI). In the first two years of the project the PIs will focus on research involving data collection and analysis to examine in detail the impact of the studio method on how students learn HCI design. The data analysis will be informed by the literature on cognitive apprenticeship teaching methods and characteristics of innovative work groups, in order to illuminate the group processes and environment that contribute to successful outcomes within design studio experiences. Through an investigation of the design process used within an interdisciplinary studio-based project and HCI courses that incorporate a modified studio method, the PIs will formulate guidelines for implementing the studio method in HCI courses and will derive principles that can be applied to the education of future computer science professionals. In the third year, the effectiveness of the curriculum guidelines will be evaluated through pilot testing in HCI classrooms, and revised based on the results of the formative evaluation. Research outcomes and curriculum guidelines will be disseminated through presentations, publications, and a project web site.<br\/><br\/>Broader Impacts: Based on an investigation of factors that contribute to creative group processes and products within an academic design studio environment, the PIs will advance software design research and education through the development of new models and methods that are supported by empirical evidence and that are teachable. In this way, the PIs will develop a strong intellectual foundation for teaching software design, which has the potential to transform the teaching of HCI, and ultimately for improving the processes of constructing, evaluating, and modifying software-intensive systems across a variety of computer science specialty areas.","title":"Collaborative Research: Investigating and Refining the Studio Experience as a Method for Teaching Human-Computer Interaction","awardID":"0725145","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":[345635],"PO":["565227"]},"122762":{"abstract":"The PI will work on the numerical analysis aspects of discrete exterior calculus. This is a class of numerical methods for solving partial differential equations (PDEs) and these methods attempt to preserve the geometric and algebraic structures of the physics being modeled. One ingredient of this project will be the use of algebraic topology and differential geometry to create and analyze discretizations of objects and operators of exterior calculus that appear in important PDEs. Several discretizations will be derived and the convergence and stability of the resulting numerical methods will be studied. In addition to this, the PI will develop algorithms and software to make it easier to conduct experimental studies involving such discretizations. All of this will be done in the context of several physical problems.<br\/><br\/>Numerical solution of partial differential equations is a core part of numerical analysis and its applications in engineering and science. Some of the equations that the PI will work on have applications in ground water contamination, oil exploration, weather modeling, nuclear fusion, star and planet formation and formation of solar flares and storms. The research in this project will use pure mathematics topics like differential geometry and algebraic topology as well as computational mathematics. Thus it will be a unique vehicle with which to introduce these topics to students in mathematics as well as computer science. Due to the wide appeal of the applications mentioned above, the PI will use animations, images and concepts produced in this research to create interest in mathematics and science amongst primary school students.","title":"CAREER: Algebraic Topology and Exterior Calculus in Numerical Analysis","awardID":"0645604","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["474979"],"PO":["565027"]},"135841":{"abstract":"0716511<br\/>Rebecca Wright<br\/>Stevens Institute of Technology<br\/><br\/>0716564<br\/>Aaron Jaggard<br\/>Tulane University<br\/><br\/>Collaborative Research: CT-ISG: Mitigating Exploits of the Current<br\/>Interdomain-Routing Infrastructure<br\/><br\/>This project addresses fundamental flaws in Internet-routing<br\/>infrastructure using both theoretical analysis and practical tools.<br\/>The results not only improve the security of the current Internet, but<br\/>also advance principles of secure routing design useful for<br\/>next-generation protocols. The project advocates a different approach<br\/>than previous work in this area by formally defining comprehensive<br\/>requirements for protocol security, rather than imposing new<br\/>technologies to address one or two specific exploits.<br\/><br\/>The Border Gateway Protocol (BGP) provides best-effort connectivity<br\/>between the component networks of the Internet, a task called<br\/>interdomain routing. However, BGP lacks any security mechanism,<br\/>allowing accidental router misconfiguration or intentional attacks<br\/>that have far-reaching effects on network stability and traffic<br\/>flow. Furthermore, simply adding security mechanisms is insufficient<br\/>because BGP also lacks the guarantee that specification-compliant<br\/>inputs always produce stable routes across the network.<br\/><br\/>This project addresses these shortcomings through research on various<br\/>assumptions that guarantee good routing behavior and on methods to<br\/>verify or enforce these assumptions to prevent deviation from that<br\/>behavior. We identify and address attacks that have previously been<br\/>studied as well as new attacks that have not yet received attention in<br\/>the literature. We target incremental-deployment benefits and<br\/>computational efficiency as primary desiderata; thus, our solutions<br\/>can offer incentives for immediate adoption without system-wide<br\/>changes. Through its educational component, our project introduces<br\/>students to cross-disciplinary research. This encourages collaboration<br\/>in research projects and allows development of coursework integrating<br\/>security, networking, and theory for a timely application domain.","title":"Collaborative Research: CT-ISG: Mitigating Exploits of the Current Interdomain Routing Infrastructure","awardID":"0753061","effectiveDate":"2007-08-08","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["540234","550960"],"PO":["565239"]},"144289":{"abstract":"A highly publicized report by the American Cancer Society noted that cancer has surpassed heart disease to become the number one killer of adults under the age of 85 in the United States today. At the top of the list was lung cancer, a disease that is eminently preventable. Addressing public health threats like cancer are acute, system-wide challenges that would benefit from network-centric approaches. For example, when the tobacco research community realized it had taken over a decade to discover that they had already collected substantial empirical evidence, distributed across its network of tobacco researchers, indicating that 'light' (low-tar\/low-nicotine brands) cigarettes reduced neither exposure to nor risk of cancer, researchers began to understand the importance of effectively sharing resources and information across the entire community. In response, government agencies involved in public health have made a substantial foundational investment in developing a digital government cyberinfrastructure--Tobacco Systems integration Grid (TobacSIG)--to enable collaboration within the Tobacco Surveillance, Epidemiology, and Evaluation Network (TSEEN). While such an underlying cyberinfrastructure is a prerequisite, delays in discoveries (such as the carcinogenic effects of 'light' cigarette mentioned above) have prompted the TSEEN community to underscore the need for social network referral tools as a crucial component of any effort to enhance the efficacy of their collaboration system.<br\/><br\/>This project will develop, deploy and assess social networking tools to enhance collaboration among members of TSEEN using the TobacSIG cyberinfrastructure. The proposed project brings together researchers in information science, social science, and public health who have established strong collaborations with government partners on the development of networks to support transdisciplinary research in public health. The researchers have assisted the government partners in formulating the challenges and envisioning solutions; hence the research team is will positioned to leverage the substantial financial and human resources being invested by NIH National Cancer Institute and its partner government agencies in the TobacSIG cyberinfrastructure.<br\/><br\/>Intellectual Merit: The proposed project is a pioneering effort at incorporating social network referral tools as an integral part of collaborative systems within the context of digital government. First, the proposed project will extend theoretical understanding of the emergence of collaboration network structures involving multidimensional networks, where nodes may be individuals, documents, data sets, services (such as visual-analytic tools), or keywords\/concepts. Second, it will pioneer theory development and testing about the influence of network referral systems on collaboration outcomes. Specifically, the proposed project will assess the extent to which collaboration outcomes are influenced by (i) different theoretically-derived structures of network referrals, (ii) different incentive structures provided to users of the network referral system, (iii) different types of network data used to generate referrals, and (iv) different information visualizations used to represent network referrals. Third, the research will extend the exponential random graph modeling techniques that have been largely used to estimate structural dependencies in relatively small (typically no larger than 500) one-dimensional networks. The proposed project will extend these techniques to multidimensional networks containing over 10,000 nodes.<br\/><br\/>Broader Impacts: As cyberinfrastructure is deployed to support collaboration among large communities in government and elsewhere, it is increasingly obvious that social network tools have immense potential. In this project the researchers will seek to respond to the refrain 'if only the Tobacco Surveillance Epidemiology Evaluation Network knew what it knew.' Generalizing the relevance of this same refrain to a wide spectrum of other contexts is suggestive of the broader impacts of the proposed research. The findings and deliverables of the proposed research will be immediately generalizable to the design and deployment of social network referral tools to support collaboration among other digital government efforts within public health and beyond. Further, the government and non-government partners in this project are exceptionally well-equipped to incorporate into their regularly scheduled education, training, and outreach workshops the skill sets of collaborative fluency afforded by the judicious use of network referral systems. Finally, by definition, social network referral systems have the potential to increase the likelihood of drawing in more diverse constituents within the public health community (in terms of gender, ethnicity, age, seniority, disciplinary perspectives) than heretofore possible. This extended network will also offer op","title":"Collaborative Research: Social Networking Tools to Enable Collaboration in the Tobacco Surveillance, Epidemiology, and Evaluation Network (TSEEN)","awardID":"0836262","effectiveDate":"2007-08-15","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"I387","name":"National Institutes of Health"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J367","name":"National Cancer Institute"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T628","name":"NIH-TOBACCO INF GRID (TO BIG)"}}],"PIcoPI":["532398"],"PO":["543481"]},"126623":{"abstract":"This proposal seeks to establish a high capacity computing infrastructure to support advanced research in biological networks ongoing at Boston University in the departments of Biology, Biomedical Engineering, Chemistry, Computer Science, and the Bioinformatics Graduate Program. The PI and Co-PIs, who form the computational core faculty of the interdisciplinary Bioinformatics program, are all involved in CPU and memory intensive research aimed at development and application of tools to mine, integrate and analyze genomic, proteomic and metabolic data. The algorithms, software, and data sets produced with the computing cluster will directly enhance the infrastructure for research in biological networks. As with other bio-analysis resources developed by researchers in the Bioinformatics program, all computer tools resulting from this proposal will be made freely available to the research community through a high capacity, dedicated web server maintained in the Bioinformatics program. The chosen cluster architecture is most compatible with the data-centric characteristics of this Bioinformatics research, as well as the flexibility requirement of configuring a queuing system to accommodate both memory-intensive and CPU-intensive algorithms. Any unused CPU cycles will be made available to other researchers at Boston University. The algorithms, software, and data sets produced with the computing cluster will directly enhance the infrastructure for research in biological networks. As with other bio-analysis resources developed by researchers in the Bioinformatics program, all computer tools resulting from this proposal will be made freely available to the research community through a high capacity, dedicated webserver maintained in the Bioinformatics program.","title":"CRI: Acquisition of a Linux Cluster for Bioinformatics Research and Education","awardID":"0709115","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[335993,"421823","421823","529556","451346","393336"],"PO":["565136"]},"127503":{"abstract":"Given a collection of organisms (or taxa), the objective of a phylogenetic analysis is to produce an evolutionary tree describing the genealogical relationships between the taxa. Inferring a phylogenetic tree that represents a good hypothesis of the truth is a difficult problem. Phylogenetic heuristics attempt to search a very small fraction of the exponentially-sized tree space for good approximations of the true evolutionary tree. The overall goal of the proposed research project is to develop information-rich methods for analyzing the large collection of trees encountered during a phylogenetic search. A better understanding of search behavior can drive the design of better heuristics, which ultimately lead to more accurate reconstructions of phylogenetic trees. Specific research objectives include: (i) developing a search history repository that contains all of the trees examined by a phylogenetic heuristic; (ii) designing algorithms for exploiting informative patterns in a search history repository; and (iii) developing visualization tools that provide informative views of the data residing in the repository. The novel data analysis and visualization techniques developed for this research project will complement existing NSF-funded efforts to build phylogenies such as \"\"The Tree of Life\"\", the evolutionary history of all known organisms. Moreover, the proposed work will provide mentoring and interdisciplinary training to a diverse group of students.","title":"III-CTX: Large-Scale Analysis of Collections of Phylogenetic Trees","awardID":"0713618","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["513229"],"PO":["565136"]},"129813":{"abstract":"Proposal #: CNS 07-23060<br\/>PI(s): Gloster, Jr., Clay<br\/> Boyack, Kevin W.; Davidson, George S.; Ramanathan, Murali; Zacharski, Ron <br\/>Institution: Howard University <br\/> Washington, DC 20059-0001<br\/>Title: MRI\/Acq.: Terascale Data Analytic Platforms for Research in the Combinatorial and Graph Sciences Consortium<br\/><br\/>Project Proposed:<br\/><br\/>This project, acquiring analytic platforms for research in combinatorial and graph sciences, attacks a critical problem, that of extracting information from massive sets of data. The requested instrumentation, a large system for production (Netezza Performance Server(s)), are to be housed at Howard and Sandia National Lab and serve scientific projects on DNA binding mechanisms, protein structure prediction, data mining for computational science at Sandia, multi-dimensional visualization at SUNY-Buffalo, and natural language processing at NMSU. The work responds to the data deluge\/tsunami\/explosion\/avalanche<br\/>that presently overwhelms the scientific community. The data intensive computer resource, National Terabyte Data Analysis Centers (NTDAC), provides the ability to analyze tera-scale data sets 10 to 100 times faster than current alternatives at a lower cost. Over time, NTDAC is expected to house and analyze peta-bytes of raw data, to have back-up and support capabilities, and to use parallel relational data warehouse appliance technology that is orders of magnitude faster and easier to use. The initial focus, exploitation of massively parallel relational database appliance technology, enables solution problems in computational biology, chemistry, physics, text mining, bibliographic coupling, and natural language processing.<br\/><br\/>Broader Impact: The infrastructure benefits all areas of science through faster data analysis. The interrogation of massive data sets allows practitioners and students to deliver\/gain new knowledge at a more rapid pace, and to create needed solutions. Moreover, the institution is an HBCU, where minority students are likely to gain from the experience.","title":"MRI: Acquisition of Tera-Scale Data Analytic Platforms for Research in the Combinatorial and Graph Sciences Consortium","awardID":"0723060","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[344342,344343,"499034",344345,344346],"PO":["557609"]},"129604":{"abstract":"The project ``Texnh: A New Approach to the B.A. Degree in Computer Science,'' was funded by the NSF (CISE\/EIA) in 2003. Texnh is the Greek word for art. It is also the root of the Greek and English words for technology. The objective of the Texnh project is to establish a strong connection between arts and sciences in teaching computing. Based upon this work, the School of Computing at Clemson University has structured the first two years of its undergraduate curricula according to the Texnh approach, whose focus is problem-based instruction in the domain of computer-generated visual media.<br\/><br\/>The objective of this project is to build upon the Texnh foundation in a manner consistent with the objectives of the EAE program. Partners at Western Carolina University and UNC Wilmington will employ the Texnh approach in selected courses for at least two years. The Texnh approach will be extended to senior division courses at Clemson University. A rigorous assessment mechanism incorporating environmental assessment, dynamic assessment, and other mechanisms identified by the project's external evaluator working with the CPATH evaluators will be used by all partners.","title":"CPATH EAE: TEXNH - Evaluation, Adoption and Extension","awardID":"0722313","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["490673",343491,"408667","485200","436245"],"PO":["565264"]},"129615":{"abstract":"Lab-centric instruction is a substantial extension to the widely advocated use of supervised closed labs as a required part of the course. In lab-centric courses, lecture and recitation time is traded wholly or in large part for supervised, structured labs that become the primary resource for student learning. Berkeley has offered lab-centric instruction in CS1 and CS2, and instructors have observed numerous benefits over and above those claimed for lab-augmented instruction. The vision is to significantly expand the use of lab-centric instruction into all CS courses (especially upper division) and academic settings. We propose a three-year project with the following goals. 1. Assemble a diverse team of leaders in communities related to lab-centric instruction: CS curriculum, pedagogy, teacher education, digital repositories, and educational technology. 2. Evaluate the state of lab usage and barriers to adoption of lab-centric formats in courses across the range of higher-educational instructional contexts. 3. Create an online space to support the growth and functioning of the lab-centric community. 4. Recruit instructors to develop and refine a small number of lab-centric segments for inclusion in upper-division CS courses, and to evaluate the effectiveness of the supporting tools and materials for this development and wider community interaction. 5. Provide outreach for the lab-centric community and the online center and dissemination of the project results through a variety of educational forums. The Berkeley lab-centric courses appeared particularly to benefit students traditionally underrepresented in CS courses. Extension of these results to other institutions through the efforts of the proposed community would have a significant impact on CS education. Lab-centric materials should be readily sharable, and therefore contribute greatly to educational infrastructure. We will provide broad outreach and dissemination to instructors, and encourage leaders to pursue new, related avenues of research. The benefits of lab-centric instruction should be extensible to lab instruction in other science and engineering disciplines, encouraging collaboration and cross-fertilization between community members and educators in these outside disciplines.","title":"CPATH-CB: A community for lab-centric computer science instruction","awardID":"0722339","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["489422"],"PO":["565136"]},"132696":{"abstract":"Distributed systems are increasingly deployed over Multiple Administrative Domains (MADs) in which no single authority controls all participating nodes. Traditionally, nodes in distributed systems deviate from their specification because they are broken (e.g., because of bugs, hardware failures, configuration errors, or even malicious attacks). MAD systems add a new dimension: without a central administrator ensuring that each unbroken node follows the assigned protocol, nodes may deviate to selfishly maximize their utility.<br\/><br\/>Byzantine Fault Tolerance handles broken nodes well. However, the Byzantine model classifies all deviations as faults and requires a bound on the number of faults that is impossible to establish when nodes can be selfish. Conversely, traditional game-theoretic models handle selfish nodes well, but are vulnerable to arbitrary disruptions if even one broken node behaves irrationally.<br\/><br\/>The goal of the FuDiCo III international workshop, held from June 4th to June 7th 2007, is to identify the conceptual and practical foundations on which to build dependable MAD distributed systems. The workshop, the third in the prestigious Future of Distributed Computing (FuDiCo) series, brings together leading senior researchers and promising graduate students from different areas (security, distributed computing, artificial intelligence, networking, and economics) for a ?multicultural? approach to this challenging and multi-faceted problem. The objective is to produce a series of written reports (targeted for SIGACT and SIGOPS News) that provide a snapshot of the current research in the area and identify promising avenues for future research.","title":"Travel and Registration Support for Third Bertinoro Workshop on Future of Distributed Computing","awardID":"0737816","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["466840"],"PO":["561889"]},"130276":{"abstract":"Designs of experts are better than those of novices, but it is not clear why. Here, we provide new methods for understanding software design expertise and how it develops. The methods, which involve analyzing diagrams to reveal the cognitive structures of designers, have been developed in other disciplines that rely on sketches and visualizations to realize and fine-tune design. They have not yet been applied to the design of software-intensive systems. A unique and valuable aspect of the project is that it is embedded in a course in design, an opportunity to study design as it happens and to improve design instruction at the same time. The project will also study expert designers practicing in the field. Our efforts focus on the following broad research questions: What differentiates expert software designers from novices? How do experts and novices represent problems and solutions? Which teaching techniques are most successful in increasing the skills of novices? And, most generally, how can we improve our capacity to design? <br\/><br\/>Bad design, and the resulting bad software, impedes coordination in many government and corporate institutions. Any improvement in the education of designers may be amplified by their efforts in practice and in mentoring other designers over the length of their careers. Specific impacts should include improving software-intensive systems design education, consequently improving the efficacy of software and social systems created by graduates of this and other design programs. For this reason, possible impacts include better homeland security, better economic growth, better social services, and other effects of improved systems design. Thus, insights in this domain may help us improve a broad range of human activities.","title":"Externalizing Thought: Improving the design of software through diagrams","awardID":"0725223","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":["402519","397898","514875"],"PO":["565227"]},"125810":{"abstract":"Abstract<br\/><br\/>Title: Collaborative Research: Hierarchical Models of Time-Varying natural Images<br\/>PIs: Bruno Olshausen, University of California-Berkeley and David Warland, University of California-Davis<br\/><br\/>The goal of this project is to advance the state of the art in image analysis and computer vision by building models that capture the robust intelligence exhibited by the mammalian visual system. The proposed approach is based on modeling the structure of time-varying natural images, and developing model neural systems capable of efficiently representing this structure. This approach will shed light on the underlying neural mechanisms involved in visual perception and will apply these mechanisms to practical problems in image analysis and computer vision.<br\/><br\/>The models that are to be developed will allow the invariant structure in images (form, shape) to be described independently of its variations (position, size, rotation). The models are composed of multiple layers that capture progressively more complex forms of <br\/>scene structure in addition to modeling their transformations. <br\/>Mathematically, these multi-layer models have a bilinear form in which the variables representing shape and form interact multiplicatively with the variables representing position, size or other variations. The parameters of the model are learned from the statistics of time-varying natural images using the principles of sparse and efficient coding.<br\/><br\/>The early measurements and models of natural image structure have had a profound impact on a wide variety of disciplines including visual neuroscience (e.g. predictions of receptive field properties of retinal ganglion cells and cortical simple cells in visual cortex) and image processing (e.g. wavelets, multi-scale representations, image denoising). The approach outlined in this proposal extends this interdisciplinary work by learning higher-order scene structure <br\/>from sequences of time-varying natural images. Given the <br\/>evolutionary pressures on the visual cortex to process time-varying images efficiently, it is plausible that the computations performed by the cortex can be understood in part from the constraints imposed by efficient processing. Modeling the higher order structure will also advance the development of practical image processing algorithms by finding good representations for image-processing tasks such as video search and indexing. Completion of the specific goals described in this proposal will provide (1) mathematical models that can help elucidate the underlying neural mechanisms involved in visual perception and (2) new generative models of time-varying images that better describe their structure.<br\/><br\/>The explosion of digital images and video has created a national priority of providing better tools for tasks such as object recognition and search, navigation, surveillance, and image analysis. The models developed as part of this proposal are broadly applicable to these tasks. Results from this research program will be integrated into a new neural computation course at UC Berkeley, presented at national multi-disciplinary conferences, and published in a timely manner in leading peer-reviewed journals. Participation in proposed research is available to both graduate and undergraduate levels, and the PI will advise Ph.D. students in both neuroscience and engineering as part of this project.<br\/><br\/>URL: http:\/\/redwood.berkeley.edu\/wiki\/NSF_Funded_Research","title":"RI: Collaborative Research: Hierarchical models of time varying natural images","awardID":"0705427","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[333910],"PO":["564316"]},"130298":{"abstract":"P0725336: SOFTSIM - a Testbed for Process-Driven and Simulation-Based Knowledge Conglomeration in Enterprise Software Development<br\/>PI: J. Leon Zhao, Dept. of Management Information Systems, University of Arizona<br\/>Co-PI: Brian McGough, Kuali Foundation, Indiana University<br\/>Co-PI: Keith Provan, Dept. of Management and Organizations, University of Arizona <br\/>Co-PI: Young-Jun Son, Dept. of Systems and Industrial Engineering, University of Arizona<br\/>Software development is a complex endeavor, especially for enterprise software systems that require the collaboration of many stakeholders that form a complex social network. This project focuses on developing a testbed for process-driven and simulation-based knowledge conglomeration in enterprise software development called \"Saguaro Software Simulation Testbed\" (or simply SOFTSIM). Essentially, SOFTSIM is a live knowledgebase that is capable of supporting effective communication in a complex social network in the context of enterprise software development. In particular, the project situates the development and validation of the conceptual framework and software system in the context of Kuali, which is a community-based open source project currently under development by a consortium of nine major universities ( www.kuali.org). The SOFTSIM testbed will lead to better tools that enable more effective management of knowledge in software engineering. Further, SOFTSIM will help derive teaching modules in several related areas such as software engineering, systems analysis and design, knowledge management, workflow management, and simulation. Finally, this research will contribute to the development of better and less expensive software systems.","title":"SoD (NSF 07-505): SOFTSIM - a Testbed for Process-Driven and Simulation-Based Knowledge Conglomeration in Enterprise Software Development","awardID":"0725336","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":["345753",345753,"536867","536867",345756,345757],"PO":["564388"]},"122455":{"abstract":"Sencun Zhu<br\/>Pennsylvania State University<br\/>0643906<br\/>CAREER: Combating Worm Propagation in Emergent Networks<br\/>Panel ID: 070111<br\/><br\/>Abstract<br\/><br\/><br\/>Worms have emerged as one of the leading threats to our<br\/>information systems and critical infrastructures. Despite the<br\/>tremendous research effort in combating worms, new computer and<br\/>system vulnerabilities are continuously reported and new worm<br\/>attacks keep succeeding. Another significant trend in worm attacks<br\/>is that the number of worm attacks against emergent networks, such<br\/>as P2P networks, cellphone networks, and sensor networks, is<br\/>rapidly growing. Because of the unique communication models and\/or<br\/>resource constraints of the emergent networks, most of the<br\/>existing solutions for Internet worm defenses are not directly<br\/>applicable.<br\/><br\/>The objective of this project is to combat worm propagation in<br\/>these emergent networks. Specifically, various approaches are<br\/>designed for rapidly distributing security patches to P2P nodes<br\/>infected by worms propagating via file sharing applications and<br\/>topological scanning. Also, both device and network sides defenses<br\/>are used to contain cellphone worms that propagate through either<br\/>multimedia messaging services or Bluetooth interfaces. Finally, it<br\/>includes mechanisms to confine worms that propagate by exploiting<br\/>the monoculture of sensor programs in sensor networks. The<br\/>proposed research will provide fundamental services and tools to<br\/>combat worms in emergent networks. It draws upon a variety of<br\/>topics including cryptography, graph theory (graph coloring,<br\/>percolation theory, partition, dominating set), system (mobile<br\/>systems), networking (P2P, cellular network, sensor network) and<br\/>statistics. The results of the project will be disseminated widely<br\/>through publications and talks, and the proposed research will<br\/>also be integrated with the education curricula.","title":"CAREER: Combating Worm Propagation in Emergent Networks","awardID":"0643906","effectiveDate":"2007-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550918"],"PO":["565327"]},"125975":{"abstract":"Biological nanomachines are the assemblies that carry out all the basic biological processes in a living organism. Electron cryo-microscopy (cryoEM) is the most appropriate structural tool to determine molecular structures of biological nanomachines that generally consist of multiple protein subunits and\/or nucleic acids with a total mass greater than 0.5 million Daltons. The goal is to develop information discovery and integration methodologies for deriving atomic models of nanomachines. Such models will be derived from 3-dimensional (3-D) cryoEM mass density function (i.e. a volumetric density map) in conjunction with physics of protein folding and informatics data. This project is made possible by an integration of the expertise of five investigators in computer graphics, computational biophysics, structural informatics and cryoEM. The intellectual merit of this research is highlighted by the computational approaches of extracting structural information from low-resolution, complex cryoEM volume densities and integrating this information into classical protein structure modeling paradigms, such as comparative modeling and ab initio modeling, for understanding biological nanomachines. The three research goals involve information discovery, information integration and validation of the proposed algorithms. The proposed research will have significant impacts in three disparate disciplines: computer science, molecular modeling, and cryoEM. Furthermore, the team will disseminate their resulting tools freely to the academic community and will host a workshop towards the end of the project. To enhance the impact of their research, the investigators will integrate research with education at each member institution with an eye towards diversity. In particular, these investigators will develop a virtual didactic course in modeling of biological nanomachines for graduate and senior undergraduate students at the five participating institutions.","title":"III-CXT: Collaborative Research: Integrated Modeling of Biological Nanomachines","awardID":"0706347","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["555090"],"PO":["565136"]},"125876":{"abstract":"Severe motor disabilities, including locked-in syndrome and paralysis, impact the quality of life for millions of people worldwide. The PIs' prior work in brain-computer interfaces based on functional near-infrared (fNIR) imaging has shown great promise for restoring communication and environmental control to people with such disabilities. Currently, typical control interfaces for these systems are simple discrete selection paradigms, which have proven to be effective but limited in information throughput rates. Innovative control interfaces based on continuous control paradigms, which dynamically map brain signal levels to control signals, have not been adequately studied for fNIR imaging. Depending upon the extent to which brain signals can be effectively mapped to continuous control, adding this feature to existing discrete control could significantly increase the range of tasks that can be performed by users of an fNIR-based direct brain interface (e.g., positional selection or 2-D drawing). In this work, the PIs will explore innovative direct brain-computer interfaces for continuous control and use them to develop applications for creative expression. For people with severe motor disabilities, creative expression can provide an emotional outlet as well as mental exercise to improve quality of life. The tasks inherent in creating visual art, such as drawing, coloring, and texturing, cannot be accomplished with discrete controls. Therefore, visual art provides an ideal experimental platform to study fNIR-based continuous control interfaces. It also provides an engaging and motivating platform for training that will improve users' abilities to control a direct brain interface. To these ends, the PIs will study non-traditional control interfaces for continuous and discrete selection such as wheels, dials, and gauges, to determine to what extent fNIR signals can be mapped to continuous control. The PIs will explore continuous methods for selection and control of art media such as brushes, colors, textures, and shapes, and investigate to what extent continuous brain signals can be translated into visual art gestures (drawing, shading, coloring). The advice of a professional, internationally-known artist who has ALS will guide the user requirements of the control interfaces. Quantitative and qualitative user performance data will be collected, and will among other things be used to compare learning effects with a visual art paradigm against traditional, discrete selection exercises to determine if training time and performance can be improved. Project outcomes will add to the body of knowledge for assistive technology and human-computer interfaces.<br\/><br\/>Broader Impacts: Methods for translating cortical oxygenation signals into continuous control signals for user interfaces will have mainstream applications for assistive technologies by essentially \"smoothing\" noisy input signals. Such developments could be applied for use by those with reduced motor coordination, including the elderly, young children, and those with motor diseases such as Parkinson's disease. Mainstream users may benefit from a hands-free interface, and neural control could provide added dimensions to the creative process.","title":"HCC: Collaborative Research: Continuous Control Brain-Computer Interfaces for Creative Expression","awardID":"0705804","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[334091],"PO":["565227"]},"126503":{"abstract":"Proposal #: CNS 07-07975 07-07944 07-08420 <br\/>PI(s): Abdelzaher, Tarek F.; Johnson Scott D.; Goddard, Stephen M.; Ci, Song; Lu, Chenyang <br\/> Kumar,Panganamala R.;Sullivan,William C.;Vaidya,Nitin H. Peng,Dongming;Perez,Lance C.;Shariff,Hamid R.Roman, Gruia C.<br\/>Institution: U Illinois- UC U Nebraska-Lincoln Washington U.<br\/> Champaign, IL 61820-7402- Lincoln NE 68588-0439 St. Louis, MO 63130-4899<br\/>Title: Collab Rsch:CRD\/IAD:Towadrs Cyber-Physical Computing at Scale: A Life-Size Experimental Facility for Applied Sensor Networks Research<br\/><br\/>Project Proposed:<br\/>This collaborative project, developing a large experimental outdoors facility (consisting of a large sensor network) to promote cyber-physical computing research, stimulates several areas of practical cyber-physical computing research, including:<br\/>. Software engineering for cyber-physical systems;<br\/>. Sensor Network development tools and programming abstractions;<br\/>. Low-level communication challenges;<br\/>. Embedded and real-time computing; and<br\/>. Data mining of the physical world (to identify anomalous or interesting patterns in streams of real-time data).<br\/>Cyber-physical systems enhance our interaction with the external environment in a similar fashion to the way the Internet changed how we communicate. Hence cyber-physical computing represents an era in computing where logical processing is more tightly intertwined with the external physical world. These systems offer a myriad of new challenges that stem from combining processing, communication, and physical interaction with the external world. Promoting practical cyber-physical computing research entails adequate experimental testbeds that allow evaluation, validation, and fine tuning of different ideas. The fine-granularity instrumentation required serves as a unifying theme across various studies. Sensor network technology is expected to economically address this need once key sensor network research impediments are resolved. This research facility is likely to be unique in the nation in its scale.<br\/><br\/>Broader Impacts: This work creates opportunities for interdisciplinary research where problems are solved utilizing CS\/CE technology in the context of real applications drawn from environmental and atmospheric science, biology, anthropology, geology, agriculture, etc. The facility enables, among others, studies of infectious disease propagation, climate change, deforestation, and global warming. Additionally, the infrastructure offers active learning educational opportunities.","title":"Collaborative Research: CRI: IAD: Towards Cyber-Physical Computing at Scale: A Life-Size Experimental Facility for Applied Sensor Networks Research","awardID":"0708460","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["384032","560533"],"PO":["564778"]},"126404":{"abstract":"Proposal #: CNS 07-07975 07-07944 07-08420 <br\/>PI(s): Abdelzaher, Tarek F.; Johnson Scott D.; Goddard, Stephen M.; Ci, Song; Lu, Chenyang <br\/> Kumar,Panganamala R.;Sullivan,William C.;Vaidya,Nitin H. Peng,Dongming;Perez,Lance C.;Shariff,Hamid R.Roman, Gruia C.<br\/>Institution: U Illinois- UC U Nebraska-Lincoln Washington U.<br\/> Champaign, IL 61820-7402- Lincoln NE 68588-0439 St. Louis, MO 63130-4899<br\/>Title: Collab Rsch:CRD\/IAD:Towadrs Cyber-Physical Computing at Scale: A Life-Size Experimental Facility for Applied Sensor Networks Research<br\/><br\/>Project Proposed:<br\/>This collaborative project, developing a large experimental outdoors facility (consisting of a large sensor network) to promote cyber-physical computing research, stimulates several areas of practical cyber-physical computing research, including:<br\/>. Software engineering for cyber-physical systems;<br\/>. Sensor Network development tools and programming abstractions;<br\/>. Low-level communication challenges;<br\/>. Embedded and real-time computing; and<br\/>. Data mining of the physical world (to identify anomalous or interesting patterns in streams of real-time data).<br\/>Cyber-physical systems enhance our interaction with the external environment in a similar fashion to the way the Internet changed how we communicate. Hence cyber-physical computing represents an era in computing where logical processing is more tightly intertwined with the external physical world. These systems offer a myriad of new challenges that stem from combining processing, communication, and physical interaction with the external world. Promoting practical cyber-physical computing research entails adequate experimental testbeds that allow evaluation, validation, and fine tuning of different ideas. The fine-granularity instrumentation required serves as a unifying theme across various studies. Sensor network technology is expected to economically address this need once key sensor network research impediments are resolved. This research facility is likely to be unique in the nation in its scale.<br\/><br\/>Broader Impacts: This work creates opportunities for interdisciplinary research where problems are solved utilizing CS\/CE technology in the context of real applications drawn from environmental and atmospheric science, biology, anthropology, geology, agriculture, etc. The facility enables, among others, studies of infectious disease propagation, climate change, deforestation, and global warming. Additionally, the infrastructure offers active learning educational opportunities.","title":"Collaborative Research: CRI: IAD: Towards Cyber-Physical Computing at Scale: A Life-Size Experimental Facility for Applied Sensor Networks Research","awardID":"0707944","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["412870","475237","340694","486378","500372",335362],"PO":["561889"]},"127504":{"abstract":"There is a silent revolution underway in scientific practice: Science is becoming computational. The abundance of computational power and state-of-the-art modeling software is a crucial driving force behind this sea change in scientific research. But that is only part of the story; there is also a fundamental new perspective. Scientists are focusing on the modeling of individual atoms, cells or animals in addition to the more traditional focus on macroscopic attributes of systems. Out of this perspective have emerged Agent-Based Modeling (ABM) languages and tools, which enable researchers to realize their conceptual models of multiple interacting individual entities in a computational format. This advance in computational science is poised to dramatically change the theory, practice and professional motivation of scientists and engineers. This project will build on the NetLogo agent-based modeling environment to develop frameworks, tools, and curricula to further bring the ABM revolution to classrooms and research labs. This research will be applicable not only within engineering, but will greatly affect the theory, use, and teaching of agent-based modeling in both the academic and business worlds in many disparate fields including the natural and social sciences.<br\/><br\/>Computational agent-based science is less about purely numerical outputs and more about emergent behaviors and qualitative larger-scale patterns, less about static and deterministic equilibria and more about dynamic and stochastic processes; therefore its very nature encourages the modeling of complex systems. This new mindset entails the development of computer architectures, methodologies, technologies and learning tools to carry forward and develop this work. This project will take up that challenge. First, it will develop frameworks describing what ABM is, how to use it, and how it interfaces with other modeling and analysis technologies. Second, this project will create and improve tools that implement the frameworks and enable ABM to take advantage of multiple input\/output devices, such as sensors, actuators, and scientific imaging devices. Third, this project will generate course materials, utilize those materials and evaluate their effectiveness to teach new scientists and engineers how to utilize ABM. Doing this research simultaneously affords synergies. Through the development of frameworks to ground agent-based modeling, tools to facilitate agent-based modeling, and curriculum development to teach new scientists and engineers, our goal is to create a common conceptual and technical foundation for agent-based modeling. This foundation will facilitate a shared understanding needed for interdisciplinary collaboration and will reduce duplicated effort between the disciplines.","title":"HCC: Advancing the Science of Agent-based Modeling Through Frameworks, Tools, and Pedagogies","awardID":"0713619","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["501314"],"PO":["565227"]},"129825":{"abstract":"Proposal #: CNS 07-23093<br\/>PI(s): Dickens, Phillip M.<br\/> Chawathe, Sudarshan S.; Fastook, James L.; Segee, Bruce E.; Zhu, Yifeng <br\/>Institution: University of Maine<br\/> Orono, ME 04469-5717<br\/>Title: MRI\/Acq.: High Performance Cluster for University of Maine Scientific Grid Portal<br\/><br\/>Project Proposed:<br\/>This project, acquiring a cluster to establish a scientific grid portal in Maine, aims to enable projects requiring large datasets. The work makes available to the wider community results such as widely-used whole-ice sheet models, tools for climate change research, prototype versions of object-based caching system (bundled with MPI-IO implementation developed at Argonne National Lab), the data management system, real-time animations, videos, etc. Additionally, the portal provides the larger community the compute power, storage capacity, and rendering engine to execute very high-resolution models, and receive animations and other visualized information in real time.<br\/><br\/>Broader Impact: The infrastructure enhances understanding of global issues and contributes in the development of educational tools for K-12 students. The scientific grid portal contributes in the dissemination of important scientific discoveries. The portal also provides a show-case for research being performed in the state.","title":"MRI: Acquisition of a High Performance Cluster for the University of Maine Scientific Grid Portal","awardID":"0723093","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[344397,"481809",344399,"456688","486060"],"PO":["557609"]},"126569":{"abstract":"Proposal #: CNS 07-08797 07-08856 <br\/>PI(s): Chapman, Barbara; Gao, Guang R. <br\/>Institution: University of Houston University of Delaware <br\/>Houston, TX 77204-2015 Newark, DE 19716-1551 <br\/>Title: Planning: A Research Compiler Infrastructure Based on Open64 <br\/><br\/>This collaborative project, laying the groundwork for building, deploying, and demonstrating the usage of a robust and extensible parallelizing\/optimizing compiler and runtime software infrastructure (mainly for high-end computing), facilitates the preparation of a future community resource for a variety of computer science research. Present work often relies on source-to-source transformation that ignores the effect of code generation, or addresses only one language. However, since new architectures imply challenges for languages, compilers, and tools as impending architectures incorporate an unprecedented amount of parallelism in the form of chip multithreading, shared memory parallelism, and clusters, the community can benefit from higher levels of integration between compilers and a variety of tools and other utilities in a programming environment. The project extends work based on the Open64 compiler suite, a robust, industry quality, state-of-the-art optimizing and parallelizing compiler that permits end-to-end experimentation and compiler research at all levels, including advanced computer architectures, parallel programming languages, compiler\/runtime software, system software, application development, performance modeling\/tuning, as well as grid computing. The work involves assessing the needs of other groups to address the challenges posed by increasingly complex programming paradigms and architectures. <br\/>This planning project will develop a strategy for creating an open source, robust compiler framework that enables research on existing and future technologies, supports real-world experimentation with existing and novel language features, and provides the means for interaction with programming tools and environments. <br\/><br\/>Broader Impacts: Reducing the effort in performing realistic compiler related experiments, the planned infrastructure should make compiler technologies broadly available. Moreover, it will be used as a teaching platform for courses and outreach education programs.","title":"CRI: Planning a Research Compiler Infrastructure Based on Open64","awardID":"0708856","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["475422"],"PO":["557609"]},"129858":{"abstract":"Proposal #: CNS 07-23263<br\/>PI(s): Kumar, Sunil<br\/> Nagaraj, Santosh V.; Sarkar, Mahasweta<br\/>Institution: San Diego State University <br\/> San Diego, CA 92115-1338<br\/>Title: MRI\/Acq.: Test-bed for Next Generation Cognitive radio Wireless Networks<br\/> <br\/>Project Proposed:<br\/>This project, acquiring a state-of-the-art cognitive radio test bed on which the protocols that exploit the merits of cognitive radios at the physical, MAC, transport, and routing layers can be tested, includes verification on a practical testbed or prototype to validate the theoretical and simulations work needed for the development of wireless networks, especially cross layer architectures. The work involves <br\/>. Addressing the needs of commercial platforms that often do not allow any changes in the underlying framework and seldom provide researchers full control of the RF, PHY, and lower MAC functionalities. <br\/>. Obtaining new and realistic models for spectrum hole detection and spectrum usage pattern providing real data depicting trend and patterns of spectrum usage which will contribute significantly in building prototypes (Simulation results are only as good as the models that use them.)<br\/>. Recreating concepts from a model of primary users studying the characteristics in licensed bands and then recreating those primary users in the ISM bands by emulating their characteristics for testing the dynamic spectrum access algorithms.<br\/>Intelligent cognitive radios sniff the radio frequency (RF) medium and identify bands of unused spectrum. These bands are then \"scavenged\" and information can be transmitted over them utilizing orthogonal frequency division multiplexing (OFDM) loading possibly non-contiguous bands of available frequencies. Federal Communication Commission (FCC) has recognized the importance of cognitive radio in spectrum management in the coming years, and has even opened the television band for the purpose of cognitive radio networks. Thus, the project creates a hardware platform to investigate cognitive radio systems and builds a test bed to analyze the physical, MAC, routing and transport layers to enable research in the area. The models are developed for hole detection and spectrum usage patterns. The overall approach combines modeling and re-creation (in the ISM bands) via emulation.<br\/><br\/>Broader Impacts: This test bed enables many applications such as pervasive networks, remote patient monitoring, inter-vehicular communications, emergency communications, airborne networks, and surveillance systems. Dissemination of results should have major impact on research and development in the areas of cognitive radio networks. Research will be transferred to wireless communication industry on San Diego through SDSU's industry partnerships. Curricular improvements are expected to enhance the technological skills and employment prospects of students (many from underrepresented groups).","title":"MRI: Acquisition of a Test-bed for Next Generation Cognitive Radio Wireless Networks","awardID":"0723263","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["547701","528321","547702"],"PO":["557609"]},"129408":{"abstract":"Highway congestion due to traffic incidents costs billions of dollars in lost productivity and billions of gallons in wasted fuel. With advance notification of traffic congestion, drivers could make educated decisions about taking alternate routes, thus saving time and fuel. Recently, systems using vehicular ad-hoc networks (VANETs) that employ vehicle-to-vehicle (V2V) communications have been proposed for this purpose. Unfortunately, relying solely on V2V communications has the undesired side effect of inviting the introduction of false alerts and misleading messages.<br\/><br\/>This project takes a novel look at solving the problem of propagating traffic-related information in VANETs in a secure and privacy-preserving manner. The goal of this project is to develop and evaluate an architecture for the Notification of Traffic Incidents and Congestion (NOTICE). NOTICE consists of sensor belts embedded in the roadway at regular intervals. Vehicles passing over a belt will provide information about their travel directly to the belt. The collective information stored by the belts will be used to make intelligent inferences about the occurrence of traffic incidents. NOTICE will provide secure and privacy-preserving communications between vehicles and the belts, efficiently propagate incident information to vehicles, and infer the presence of traffic congestion without driver intervention.<br\/><br\/>The results of this research will be disseminated through journal and conference publications. The broader impacts of this project include providing a basis for a deployable incident notification system and the development of new courses in vehicular networks, sensor networks, security, and embedded and distributed systems.","title":"NeTS-WN: An Architecture for the Notification of Traffic Incidents and Congestion (NOTICE)","awardID":"0721586","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["485667","485668"],"PO":["564993"]},"128209":{"abstract":"Tele-healthcare could largely reduce national healthcare cost through remote self-managed patient monitoring. Cardiac Sensor Networks (CSNs) could be used to deploy such a system. Moreover, the integration of RFID into CSN could play an important role for elder healthcare because RFID could be used to monitor elders' medicine taking behaviors. On the other hand, the disclosure of RFID information during RFID tag-to-reader communications can cause the violation of patients' privacy. This research aims to achieve trustworthiness in a practical RFID-assisted CSN platform. This project will make the following three contributions: (1) Error-resistant ECG transmission: A trustworthy CSN should be able to overcome the impacts of radio interference and propagation distortions that can lead to frequent ECG transmission errors. This research will use the receiver-only local ECG processing to overcome ECG errors\/loss. It will conduct a comparative study of two promising anti-interference methods, Kalman Filter and Tempo-spatial Regression. (2) Low-overhead RFID security: This research will design a lightweight RFID security scheme based on Linear Congruential Generator (LCG) and a mutual authentication scheme. The RFID security will be tested in our current CSN hardware platform. (3) CSN temporal accountability: In ECG sensor applications, all ECG anomaly detections depend on accountable time interval analysis between different ECG signal segments. This research will achieve CSN temporal accountability through the following two technical approaches: i) design a receiver-only clock uncertainty prediction model to avoid wireless communication overhead; and ii) design a history-aware, reputation based trust model to capture the evolutionary timing attacks.","title":"Collaborative Research: CT-ISG: Error-resistant, Accountable, RFID-assisted Wireless Sensor Networks for Elder Cardiac Tele-healthcare","awardID":"0716455","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["513708"],"PO":["529429"]},"133511":{"abstract":"This project will develop a computer system which will solve problems creatively and will be based on the extension, abstraction and generalization of human cognitive processes. A model of cognitive processes exists as a computer program for simple knowledge-based problem solving using a highly parallel architecture with components for processing goals, plans, memory and perception. In order to extend this model it will be necessary to extend its various components to incorporate new types of knowledge that are to be used creatively and to introduce new mechanisms for conceptual representations and their manipulation. The new method of representing knowledge allows knowledge to be flexibly abstracted or constrained as required to discover new problem solutions. The highly parallel nature of the existing model will allow many different kinds of knowledge to be activated concurrently thereby allowing a large set of potential solutions to be considered, but it will also allow a large set of constraints to be applied concurrently to find the best solutions.<br\/><br\/>The intellectual merit of the project will be in advancing our understanding of the important area of creativity by showing how different knowledge-based processes work together to creatively solve problems. Its broader impact will be in showing how to develop systems which support and enhance human creativity in the design of commercial products, in artistic and cultural activities, in understanding the development of creativity in our children, in educating our students to be more creative, and to have marketable creative skills.","title":"A Computational Model of Creative Problem Solving","awardID":"0741702","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":[354961],"PO":["424970"]},"145633":{"abstract":"This major inter-disciplinary research effort will use virtual worlds as an exploratorium to theoretically extend and empirically model the dynamics of group behavior. In the process it will develop novel computational techniques for analyzing large-scale networks, which will have applicability across a wide variety of domains.<br\/><br\/>The most important and complex decisions made by governments and organizations occur in group contexts. A central challenge, spurred by new developments in information technologies (IT), is that the nature of groups and how they operate has changed radically. Today, many groups ? in social, political, and economic contexts - are ad hoc, agile, transient entities that emerge from a larger primordial network of relationships. For a short time, these groups accomplish a variety of tasks, and then they dissolve, only to be reconstituted later with a different configuration. While there is growing awareness of the socio-economic consequences of these groups, our understanding of how they form and their impact on effectiveness is severely limited.<br\/><br\/>This project will address this limitation by developing a theoretical framework that reflects the contemporary conceptualizations of groups. It proposes a network approach to modeling the eco-system of overlapping and constantly changing groups that constitute the fabric of contemporary society. It recognizes that empirically testing such a model poses formidable data collection challenges. However, a unique resource available to the research team is access to all behavioral traces (server logs) from one of the world''s largest Massively Multiplayer Online (MMO) games, EverQuest 2, which is particularly well-suited to theorize and empirically model the dynamics of group behavior. MMOs comprise tens of thousands of players who are at any one point in time coalescing in thousands of groups to accomplish \"\"\"\"quests\"\"\"\" and \"\"\"\"raids\"\"\"\" that involve a variety of activities similar to tasks we undertake in real life ? finding information or materials, making, selling or buying products and services. <br\/><br\/>Beyond the data collection challenge, the scale of the proposed research enterprise also poses significant computational challenges in uncovering and analyzing the complexities that govern the dynamics of group behavior in these virtual worlds. Using advanced computing applications and technologies, this project seeks to capture, infer, and model the networks that explain how groups emerge and how they function. Specifically, the researchers will use temporally evolving graphs to model such networks, and develop scalable algorithms to compute metrics of group behavior on them. Tying these complex and shifting individual and networked behaviors to traditional forms of analyses represents a novel interdisciplinary challenge in both scope and complexity.<br\/><br\/>The project will expand our knowledge of how groups form and operate in larger ecosystems of groups, individuals, and organizations. The analysis of logs generated from Virtual Worlds poses novel challenges from a computational perspective. This interdisciplinary investigation will result in new (1) information models for modeling the Virtual World, (2) data structuring and algorithmic techniques for data access and analysis, and (3) techniques for computational efficiency.<br\/><br\/> The knowledge and tools developed in this research will allow researchers to understand more fully, and practitioners to cultivate more effectively, the emergence and performance of ad hoc groups in contemporary society. It will also provide other disciplines with new computational and statistical modeling methodologies and tools, which should have considerable positive implications for future research in other disciplinary areas. The findings and deliverables of the proposed research will be immediately generalizable to training and education related to groups (beyond just MMOs or Virtual Worlds), social networks, and online games.","title":"Collaborative Research: DHB Virtual Worlds: An Exploratorium for Theorizing and Modeling the Dynamics of Group Behavior","awardID":"0841583","effectiveDate":"2007-08-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["532398"],"PO":["564456"]},"135843":{"abstract":"Decentralized networks offer two main advantages: no single point of failure and no capacity limitation. The more nodes added, the more potential gain in accumulative computing power and contents that the network can bring to the users. The amount of these distributed resources, however, grows tremendously over time. As such, an important problem, yet challenging, is how to manage the resources efficiently and be able to find them quickly when necessary in a network that is highly dynamic with frequent node membership changes. Many works attempt to address this problem, but only partially. If built together, they could provide a good set of services useful for the users. Unfortunately, such a combination is hardly feasible as most of these techniques differ fundamentally in system architectural design. This project develops a unified system infrastructure, that is scalable, self-organizing, and facilitates a comprehensive set of fast, accurate, and efficient information retrieval services for the users of decentralized networks. This infrastructure contains five components: (1) communication, (2) indexing, (3) search, (4) ranking\/aggregation, and (5) security. The expected outcome includes a software implementation of the infrastructure with built-in technologies for these components. The development results will be disseminated via the Web, seminars, publications, and industrial collaborations. The educational plan is designed to significantly advance students' knowledge, at both undergraduate and graduate levels, and prepare them well for future professional endeavors. The project is applicable to any large-scale distributed information-sharing network deployed in the scientific, commercial, and homeland-security fields, to name some.","title":"CSR-PDOS: A Scalable and Self-Organizing System Architecture for Fast and Efficient Information Retrieval in Large-Scale Decentralized Networks","awardID":"0753066","effectiveDate":"2007-08-09","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485752"],"PO":["493916"]},"131366":{"abstract":"The 2007 IEEE Workshop on Statistical Signal Processing is tentatively planned for August 26-29, 2007, at the beautiful Monona Terrace Convention Center in Madison, Wisconsin. The purpose of this workshop is to bring together researchers and scientists from the IEEE Signal Processing Society and related fields, for a two-and-one-half-day workshop focused on statistical methods in signal and image processing. The workshop will feature regular contributed paper sessions, special invited paper sessions, and a small number of plenary lectures covering basic theory, methods and algorithms, and applications in statistical signal processing. Areas of interest include array processing, telecommunications, distributed signal processing and networks, biosignal processing and bioinformatics, Monte Carlo methods, statistical image analysis, and machine learning.<br\/><br\/>One of the themes to be highlighted in the 2007 IEEE SSP Workshop is the theory and applications of the compressed sensing, and the role that compressed sensing can play in signal analysis and processing. Compressed Sensing was first proposed in 2004 by Professor Emmanuel Candes of Caltech. Candes, who received the National Science Board's prestigious Alan T. Waterman Award for his work, will present a one hour plenary lecture on this subject at the workshop. The workshop will provide an ideal forum for researchers to exchange ideas and relate research progress in this and other emerging areas of vital importance.","title":"2007 IEEE Workshop on Statistical Signal Processing","awardID":"0730272","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T952","name":"CIA- WORKSHOP"}}],"PIcoPI":["518179"],"PO":["564898"]},"122456":{"abstract":"Patrick McDaniel<br\/>Pennsylvania State University<br\/>cAREER: Realizing Practical High Assurance through Security-Typed Information Flow Systems<br\/>0643907<br\/>Panel ID:070111<br\/><br\/>Abstract<br\/><br\/><br\/>This grant supports an investigation of formal models, algorithms,<br\/>methods, tools, and infrastructure that build upon the information<br\/>flow guarantees of security-typed languages to achieve high assurance<br\/>software systems. The information flow guarantees of security-typed<br\/>languages provide a practical avenue to achieving system security by<br\/>producing proofs of an implementation's compliance with a specified<br\/>policy. However, these languages are simply tools for restricting<br\/>information flow through source-code annotations: they provide no<br\/>theory or practice to indicate how such annotations can be used to<br\/>implement security in real systems. This work bridges the theoretical<br\/>and practical gap between systems security and security-typed<br\/>languages. In this, the following three central research thrusts are<br\/>under investigation: a) the mapping of high-level policies to secure<br\/>implementations through models and algorithms that enable the<br\/>generation of semantically equivalent policies and the automated<br\/>instrumentation of code to enforce them, b) the study of services and<br\/>languages that govern application and infrastructure information flow,<br\/>and c) the exploration of tools to instrument legacy systems with<br\/>information flow policy. Demonstrative stand-alone, distributed, and<br\/>multi-user applications and systems are being be developed and<br\/>evaluated with respect to a broad range of security goals. The<br\/>evaluation efforts include pursing formal proofs of correctness and<br\/>empirical analysis of performance and security tradeoffs.","title":"CAREER: Realizing Practical High Assurance through Security-Typed Information Flow Systems","awardID":"0643907","effectiveDate":"2007-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["521556"],"PO":["564388"]},"125723":{"abstract":"Many information workers are swamped with unfamiliar collections of text. One challenge is to obtain an accurate overview of a large text collection, such as the public comments collected in ''''''''notice and comment'''''''' rulemaking. No single tool currently provides a sufficiently diversified picture of such a corpus, and no adequate theory exists to help people explore and form a deep and nuanced understanding of such a text collection. This research seeks to develop a computational framework that allows further exploration of this problem from multiple, integrated perspectives. All the assembled perspectives will be brought together into a single overall supra-document structure that is dynamically constructed under user guidance. In this structure, hierarchical topic clusters will be cross-linked by opinion and argumentation links, using two classes of text analysis engines: one for topics and subtopics, and the other for argument structures. The research team will design, develop, build, and systematically test an overall text exploration framework, an application to support federal regulation writersone called the Rule-Writers Workbench. There is a strong collaboration with Federal government officials who will provide data and participate in user testing. The three PIs have successfully collaborated on a related project under previous NSF funding. <br\/><br\/>Intellectual Merit: This is a sustainable collaboration between computer science and political\/social science research, rooted in a challenging and important real world application and informed by years of end user research. Dynamic, user-driven subtopic definition and clustering algorithms coupled with<br\/>language modeling are an innovative yet reachable set of goals. The framework to be developed will be grounded in the humanities disciplines'' expertise in rhetoric, discourse structure, and subjectivity.<br\/><br\/>Broader Impacts: The Rule-Writers Workbench will allow federal government regulation writers to employ a suite of technical tools that perform independent analyses of public responses to proposed regulations, including near-duplicate detection and clustering, user-based topic selection from dynamically extracted keywords, opinion identification, and subtopic clustering. These capabilities will open new avenues for federal comment analysis.","title":"Collaborative Research III-COR: From a Pile of Documents to a Collection of Information: A Framework for Multi-Dimensional Text Analysis","awardID":"0705091","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543277"],"PO":["563751"]},"135535":{"abstract":"NSF 0524139 \/ 0524030<br\/><br\/>Collaborative Research: Incentive-Compatible Protocols<br\/><br\/>Rebecca N. Wright, Stevens Institute and Sheng Zhong, State University of New York at Buffalo<br\/><br\/>The rapid expansion of the Internet has changed the way we communicate, with ever-increasing aspects of our daily life involving computation and data communication. However, many communications protocol designs assume that all participants will follow the specified protocols, and do not maintain their desirable properties if they don't. One approach to this problem is to design for a world in which some parties may maliciously deviate from their protocols in arbitrary ways. However, the resulting designs are typically expensive or impossible to achieve, and in many cases overestimate the kinds of misbehavior one is likely to encounter. Weaker security goals are more achievable, but often underestimate the willingness of participants to cheat.<br\/><br\/>This project studies an intermediate notion of security, known as incentive compatibility. In many practical settings, it is reasonable to assume that users will tend to act in their own best interests. Therefore, if one can design and use protocols that are incentive-compatible, in that following the protocol produces outcomes for participants at least as good as deviating from the protocol, then one can in many settings avoid misbehavior. Incentive compatibility, which borrows ideas from economics and game theory, is a more finely tunable notion of security than traditional security models, allowing different kinds of participants motivated by different incentives. Such solutions can provide better trust and assurance than protocols secure only against passive adversaries, at a potentially lower cost than protocols secure against an arbitrarily malicious adversary. This allows incentive-compatible protocols to provide the \"right\" level of security, at the \"right\" cost.<br\/><br\/>Four areas studied are: incentive-compatible ad hoc networks, incentive-compatible data mining, (both of which can significantly benefit from introducing incentive-compatible solutions), testing tools for incentive compatibility, and foundations of incentive compatibility.","title":"Collaborative Research: CT-ISG: Incentive-Compatible Protocols","awardID":"0751674","effectiveDate":"2007-08-31","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["540234"],"PO":["529429"]},"135898":{"abstract":"Consumers of health information have access to increasingly large numbers of sources from which to gather this information. Privacy preserving access to high quality health information will be an important adjunct to personal healthcare management. This project is developing a \"patient-centered\" approach to handle search complexity and provide personalized access to high quality health information while preserving the patient's privacy at all times. This research brings together an interdisciplinary team of computer and information scientists and health experts to develop a test-bed and simulation environment to support research in this emerging area.<br\/><br\/>The broader impact of the research will be twofold. Locally Indiana University offers a graduate degree in Health Informatics. This project will help inform and educate the next generation of health informaticians. The larger health informatics community will benefit from the availability of a test-bed to advance information retrieval in this important area.","title":"A test-bed for personalized, privacy-preserving and high quality health information delivery","awardID":"0753288","effectiveDate":"2007-08-16","expirationDate":"2008-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["486226"],"PO":["565136"]},"126614":{"abstract":"Networking research has long relied on simulation as the primary vehicle for demonstrating the effectiveness of proposed protocols and mechanisms. Typically, one simulates network hardware and software in software using, for example, the widely used ns-2 simulator. Experimentation proceeds by simulating the use of the network by a given population of users using applications such as ftp or web browsers. Synthetic workload generators are used to inject data into the network according to a model of how the applications or users behave.<br\/><br\/>In order to perform realistic network simulations, one needs a traffic generator that is capable of generating realistic synthetic traffic in a closed-loop fashion that ?looks like? traffic found on an actual network. Unfortunately, the networking community suffers from a lack of validated tools and models suitable for synthetic traffic generation. As a result, all too often, networking technology is evaluated using ad hoc workloads with an unknown relationship to traffic seen on real links and hence begs the question of how believable the results of the evaluation are.<br\/><br\/>This project is a collaborative effort to develop a synthetic traffic generation resource for the experimental networking research community. The resource consists of (1) synthetic traffic generators for the ns-2, ns-3, and GTNets software simulators, and Linux and BSD-based testbeds, (2) a repository of datasets to be used by the traffic generators to generate traffic that is statistically equivalent to traffic found on a variety of network links including campus networks, wide-area backbone networks, corporate intranets, wireless networks, etc, and (3) a set of traffic analysis tools to enable researchers to generate empirical models of traffic on network links of interest and to use these models to drive the synthetic traffic generation process.","title":"Collaborative Research: CRI: CRD Synthetic Traffic Generation Tools and Resources: A Community Resource for Experimental Networking Research","awardID":"0709081","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["554765","491562"],"PO":["493916"]},"126625":{"abstract":"Proposal #: CNS 07-09122<br\/>PI(s): Adve, Vikram S.<br\/>Institution: University of Illinois - Urbana-Champaign<br\/> Champaign, IL 61820-7406<br\/>Title: CRD:A Compiler-Based Virtual Machine Infrastructure for System Software <br\/><br\/>Project Proposed:<br\/><br\/>This project, building and distributing a compiler-based virtual monitor machine (VMM) for system software, combines virtualization and compiler techniques. This infrastructure supports safety and verifiability for both high-level applications and low-level system code and includes a compiler-based virtual machine (LLVA) that can host an entire OS and all its applications, the Linux kernel (ported to the LLVA architecture), and development tools to compile and work with LLVA code. Building on techniques developed in the SAFECode in-house project, this virtual machine will enforce a safe execution environment for applications and even for legacy systems. The flexibility of the infrastructure permits individual components to be used separately and to be integrated into other systems. Important components include the LLVA instruction set, a run-time library implementing the kernel support functions, compiler modules, development tools, a Just-in-Time (JIT) engine for managing JIT compilation and caching, and the SAFECode compiler for enforcing memory safety for C programs and the kernel. The infrastructure also includes examples of course projects pre-packaged for instructor to use. Beginning with the prototype, major developments consist of modifying the compiler and JIT engine to be able to run without system services, assembling the components into a complete usable system, improving the robustness and performance, and adding usability features such as documentation, auto-configuration, automatic testing, bug tracking, and pre-packaged course projects. The infrastructure aims to enable approaches to intrusion detection and prevention, cross-program information flow, compilation certification, and formal verification of system software.<br\/><br\/>Broader Impacts: This work enables research groups to undertake prohibitively difficult research providing new solutions that tackle hard problems such as insider threats, building scalable secure systems, information provenance, and security and privacy. Moreover, in addition to contributing to train students in the area, the infrastructure facilitates development of new and\/or more ambitious course projects and education topics in OS, compiler, architecture, embedded and distributed systems","title":"CRI: CRD: A Compiler-Based Virtual Machine Infrastructure for System Software","awardID":"0709122","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["542046"],"PO":["557609"]},"134017":{"abstract":"This workshop will bring together knowledgeable computer and information scientists in the human-computer interaction and computer-supported work fields, as well as experts from the game and online research community, to assess the current status and likely future development of massively multiplayer online worlds (MMOWs) in work applications. MMOWs are three-dimensional electronic environments in which members create embodied characters and interact with each other through text and voice chat. Frequently categorized as technologies of play, MMOWs range from games such as World of Warcraft with a set of specific, goal-oriented game activities, to open environments such as Second Life, in which players create any content they desire. Increasingly, corporations, educators, and the military are recognizing these online spaces as legitimate communication media, thereby blurring the lines between work and play. However, it is unclear whether the passion players bring to games such as World of Warcraft or virtual worlds such as Second Life will translate to non-play contexts. The objective of this workshop is to advance our understanding of relations between work and play in online virtual environments.<br\/> <br\/>The results of this workshop will be disseminated through a website and a special issue of a scholarly journal. A primary benefit of the workshop will be the cultivation of working relationships for development of critical tools for incorporating play into work environments in a productive manner. This is essential, as interactive games become an increasingly important part of our culture. The combination of these two - building the literature and building the scientific community - will play a significant role in advancing the state of the art.","title":"Productive Play: The Convergence of Play and Labor in Online Games and Virtual Worlds","awardID":"0744197","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["561204"],"PO":["564456"]},"126515":{"abstract":"Proposal #: CNS 07-08498 07-09946 07-08420 <br\/>PI(s): Preisig, James C Ye,Wei Stojanovic, Milica<br\/> Lee, Freitag Heidenmann, John S.<br\/>Institution: Woods Hole Oceanographic Inst U Southern California Mass Inst Tech<br\/> Woods Hole, MA 02543-1041 Los Angeles, CA 90089-1147 Cambridge, MA 02139-4307<br\/>Proposal #: CNS 07-09005 07-08938 07-08467<br\/>PI(s): Cui, Jun-Hong (June) Levine, Brian; Kurose,James F. Freitag, Lee<br\/> Rajasekaran,Sanguthevar;Shi, Zhijie;Willett,Peter K.;Zhou,Shengli <br\/>Institution: University of Connecticut U of Massachusetts WHOI<br\/> Storrs, CT 06269-1133 Amherst, MA 01003-9242 Woods Hole, MA 02543-1041 <br\/>Title: Collab Rsch:CRD\/IAD:Open Research Testbed for Underwater Ad Hoc and Sensor Networks (ORTUN)<br\/><br\/>This collaborative project, developing the first open testbed infrastructure for the underwater networking community, enables open access with the capability to conduct experiments remotely. The infrastructure, based on open research platforms, consists of a testbed that enables wide and systematic experimental evaluation and comparison of underwater acoustic networks. The work, involving this rapidly deployable testbed that can be shared by the underwater networking community, aims to demonstrate the ability of the facility to facilitate field experiments. The project represents a higher-level collaborative that arose from two collaborative groups. One group developing the facility, the other working mainly on the experiments utilizing the facility. The testbed is expected to be a buoy-based system that can be easily taken to different environments. When operational, these systems will be deployed 5 or 6 times a year. The infrastructure will consist of two types of nodes with different capabilities. The first type of node of the rapidly deployable testbed will offer a fixed physical layer capability using acoustic modems such as the WHOI micromodem or the ISI S-modem to implement a physical layer with limited reconfigurability interfaced to a reconfigurable network processor. This network processor will support algorithm\/protocol implementation and testing at higher network layers. The Network functions on the Fixed Physical Layer testbed will be hosted by a Gumstix processor which will then communicate with physical layer modems such as the WHOI Micromodem or USC\/ISI S-modem via a serial port. Ten to fifteen fixed physical layer nodes will be built including up to 3 gateway nodes. Each gateway node of the testbed will be equipped with wireless RF communication enabling real-time monitoring and control of network performance. The fixed physical layer nodes will be smaller and more easily deployed than the second type of node which is the all-layer node. The all-layer node is a more capable node that will ultimately support algorithm\/protocol implementation and acoustic data collection at all networking layers. In addition to the equipment included in the fixed physical layer nodes (i.e., a gumstix network processor and the ability to support relatively fixed physical layer modems such as the WHOI Micromodem and the ISI S-modem), the all-layer nodes will also include a general purpose data acquisition system (D\/A and A\/D) with substantial disk storage and in-situ processing capability. The MIT r-modem software will be implemented on this general purpose hardware and, along with MATLAB, will enable user implementation and testing of algorithms and the gathering of acoustics data at the physical layer in addition to the testing at higher network layers that it will share in common with the fixed physical layer nodes. Three to five all-layer nodes will be built. The rapidly deployable testbed, using two types of nodes with varying capabilities, should significantly enhance research at all network layers while setting the stage for future infrastructure improvements.<br\/><br\/>Many research groups investigating fundamental questions about how to design such networked systems that utilize acoustic communications in complex underwater environments have had their overall effort significantly slowed by the lack of common means to test and compare protocols under realistic environmental conditions. This infrastructure responds to the need for consensus on analytic or simulation models for underwater networks where researchers need the ability to gather experimental data under real world conditions in order to make progress. <br\/><br\/>The network stack will be modular by design with sockets used to enable cross layer control and communication. The physical, MAC, Network and Application layers will be populated with sample components to enable users test their own algorithms or protocols without having to populate the entire stack. Users will be able to write modules to test their own algorithms or protocols at different layers and selectively replace the sample modules with their own. While the development of the modular architecture and sample modules for the network stack will","title":"Collaborative Research: CRI: CRD: Open Research Testbed for Underwater Ad Hoc and Sensor Networks","awardID":"0708498","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["478411","462528"],"PO":["557609"]},"126636":{"abstract":"Networking research has long relied on simulation as the primary vehicle for demonstrating the effectiveness of proposed protocols and mechanisms. Typically, one simulates network hardware and software in software using, for example, the widely used ns-2 simulator. Experimentation proceeds by simulating the use of the network by a given population of users using applications such as ftp or web browsers. Synthetic workload generators are used to inject data into the network according to a model of how the applications or users behave.<br\/><br\/>In order to perform realistic network simulations, one needs a traffic generator that is capable of generating realistic synthetic traffic in a closed-loop fashion that ?looks like? traffic found on an actual network. Unfortunately, the networking community suffers from a lack of validated tools and models suitable for synthetic traffic generation. As a result, all too often, networking technology is evaluated using ad hoc workloads with an unknown relationship to traffic seen on real links and hence begs the question of how believable the results of the evaluation are.<br\/><br\/>This project is a collaborative effort to develop a synthetic traffic generation resource for the experimental networking research community. The resource consists of (1) synthetic traffic generators for the ns-2, ns-3, and GTNets software simulators, and Linux and BSD-based testbeds, (2) a repository of datasets to be used by the traffic generators to generate traffic that is statistically equivalent to traffic found on a variety of network links including campus networks, wide-area backbone networks, corporate intranets, wireless networks, etc, and (3) a set of traffic analysis tools to enable researchers to generate empirical models of traffic on network links of interest and to use these models to drive the synthetic traffic generation process.","title":"Collaborative Research: CRI: CRD: Synthetic Traffic Generation Tools and Resources: A Community Resource for Experimental Networking Research","awardID":"0709185","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["485593"],"PO":["434241"]},"128957":{"abstract":"CSR-AES: Machine Learning Based Library Generation Techniques for Multi-core<br\/>Processors and GPUs<br\/><br\/>The goal of this research program is to develop adaptive library generation and optimization technology for emerging high-performance computer platforms - Multi-core processors and GPUs. Compared to the state-of-the-practice in library generations, the libraries for the new high-performance computation platforms will be optimized for extreme level of parallelism and be searched from a much larger design space. While many library generators have been proposed for existing computers, there has been little work towards a comprehensive approach to automatically generate libraries for the new platforms. The proposed research is meant to help fill this gap.<br\/><br\/>Specifically, this work proposes a framework of computation primitives that can systematically define the program design space for the new parallel architectures, and a synergistic search strategy that couples machine learning algorithms with computer architecture modeling to efficiently search the best form of library routines on multi-core processors and GPUs. The new code generation framework combines the flexibility and the capabilities of machine learning to handle complex search space, with the superior accuracy and the low overhead that architecture models provide. Furthermore, this project studies the software design tradeoffs between locality, parallelism, communication and design complexity. In particular, the new framework will be applied to important kernel routines, including matrix multiplication, Fast Fourier Transform (FFT), and sorting, so that users of the new high-performance computing platforms can readily exploit the high performance provided by the platforms.","title":"CSR--AES: Machine Learning Based Library Generation Techniques for Multi-core Processors and GPU's","awardID":"0719909","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["525208"],"PO":["493916"]},"127516":{"abstract":"Robotics has the potential of positively impacting quality of life, especially for people with special needs. If we are to meet the demand for personalized one-on-one care for the growing populations of elderly individuals and those with special cognitive and social needs throughout life, great strides must be made in human-robot interaction (HRI) in order to bring robotics into everyday application domains. This interdisciplinary project identifies a specific set of HRI research questions in socially assistive robotics, the study of robotic systems capable of providing help through social rather than physical interaction. The research foci of the study are: embodiment, personality, empathy, and adaptivity toward the development of an assistive HRI model for customized time-extended assistive interaction. The research will be grounded in the stroke rehabilitation domain, where personalized and dedicated care is needed to provide supervision, motivation, and training during the critical post-stroke period and beyond, and where assistive HRI can play a key role. Specifically, a novel assistive HRI model will be developed based on personality matching between the user and the robot, in order to optimize the user's task performance on rehabilitation exercises. The model will be evaluated on multiple testbeds with a large pool of human subjects from the stroke patient population. An online learning algorithm will enable the robot to adapt to the user both over the course of short-term interactions during a single therapy sessions (e.g., in response to mood and fatigue), and time-extended interactions over multiple therapy sessions (e.g., in response to the evolving recovery process over months of rehabilitation). The work is the first to study the role of personality and empathy in assistive HRI with human subjects, as well as to engage in longitudinal assistive HRI research to assess time-extended human-machine interaction in the assistive context. An important contribution of the research is the unified and tightly integrated end-to-end approach, which combines key HRI issues of embodiment, personality, empathy and adaptivity in hypothesis-testing experiments. Project outcomes will also include a large and unique corpus of multi-modal data, which will be collected and analyzed, and made available to researchers across the relevant disciplines. The scientific impact will go well beyond novel insights toward a better understanding of the fundamentals of assistive HRI, and the role and potential for assistive human-machine interaction for stroke patient populations and rehabilitation in general.<br\/><br\/>Broader Impacts: Currently there are about 750,000 new strokes per year in the United States, and some expect the number to double in the next twenty years with the growing elderly population. Project outcomes will provide pilot data necessary for translating the methodologies developed toward clinical applications.","title":"HRI: Personalized Assistive Human-Robot Interaction: Validation in Socially-Assisted Post-Stroke Rehabilitation","awardID":"0713697","effectiveDate":"2007-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7632","name":"HUMAN-ROBOT INTERACTION"}}],"PIcoPI":["558935",338154],"PO":["565227"]},"127406":{"abstract":"Imagine a virtual environment so realistic that within it one could practice a violin technique such as vibrato, or how to filet a freshly caught halibut, or a surgical procedure using patient specific data. Such applications, and countless others, would require a high quality haptic device for the hands through which realistic forces could be applied to convincingly simulate touch. Today's haptic interfaces - information technology that supports human touching and manipulation of virtual or remote objects - are still in their infancy compared to human haptic capabilities. The typical haptic device is connected to a single finger, or supports interaction through a pen-like stylus. In an effort to dramatically advance the state of the art, the PI has developed an exciting prototype multi-finger device of high resolution and bandwidth. In this project he will determine the limits of the prototype and refine the technology so that it is useful for evaluation in applications. To these ends, the PI will explore the requirements on high-fidelity haptic technology imposed by human perception. He will measure user thresholds {i.e., the smallest forces which they can perceive with multiple fingers), and will study multi-finger and bi-manual behavior and performance in exploring and manipulating objects and materials. These data will enable the PI to reconfigure his multi-finger haptic device and create software modifications as necessary, and also to develop a new haptic rendering algorithm and study how it interacts with human perception. Project outcomes will include engineering requirements for successful yet cost-effective haptic devices, along with some of the knowledge necessary to achieve future high quality multi-finger haptic interface applications<br\/><br\/>Broader Impacts: The technology to be developed in this project will ultimately give people who are visually impaired access to the many images and 3D datasets and models which are accessible only in electronic form. Additionally, haptics is an important enabling technology for medical simulations; better medical simulators will lead to fewer medical errors and more efficient training of medical personnel. Haptics is expected to have a significant impact on the appreciation and the conservation of works of art. Demonstrations of applications in these and other fields will be byproducts of this research.","title":"HCC: Multi-Finger High Fidelity Haptic Exploration","awardID":"0713028","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["434705"],"PO":["565227"]},"126339":{"abstract":"Proposal #: CNS 07-07612<br\/>PI(s): Jackson, Daniel <br\/>Institution: Massachussets Institute of Technology<br\/> Cambridge, MA 02139-4307 <br\/>Title: CRD: Collab Rsch: Development of Alloy Tools, Technology, and Materials<br\/><br\/>Project Proposed:<br\/>This collaborative project, developing a new Alloy infrastructure, aims to exploit further this approach.<br\/>Alloy, an approach to modeling and analyzing software that comprises a language and a suite of tools (in particular the Alloy Analyzer, a tool for exploring and checking software designs), brings together a classical idea, the representation of complex systems with relational logic, and a recent idea, the use of SAT solvers for exploring huge cases. Alloy has been used in a wide variety of design analyses. Researchers use Alloy as a tool or back-end for their own tools; over thirty courses use Alloy today. It was recently used to model and check the transfer protocol of Mondex, an electron purse system. Twenty five students built the Analyzer over 5 years ago. However, the infrastructure suffers serious deficiencies, partly due to the fact that its individual components are not cleanly separated. Now this Analyzer has become fragile and bloated. This infrastructure aims to correct this situation. Its development comprises:<br\/>- Tools and components,<br\/>- Educational Materials, including course modules, case studies, sample problems, and common patterns, and a <br\/>- Community Repository, allowing the sharing of tools, components, educational materials, and research papers.<br\/>End-user applications will include a new version of the Alloy Analyzer, a tool for checking code against Alloy specifications, and an example-based modeling tool. The applications will be built on all-documented, cleanly separated components that will be made available to researchers: a new engine that can handle large configurations in addition to model constraints, a code front-end, a visualizer, and a translator for JML to Alloy. This infrastructure aims to create and enable a community that will use Alloy as an intellectual sandbox to explore fundamental and far-reaching questions faced by the field.<br\/><br\/>Broader Impacts: Because the Alloy Analyzer itself, with its concrete and immediate visual feedback, plays the role of a very critical but constructive tutor, Alloy is particularly well suited to formal methods education in small college settings. Moreover, Alloy serves the larger community of educators and researchers.","title":"CRI: CRD -- Development of Alloy Tools, Technology and Materials","awardID":"0707612","effectiveDate":"2007-08-01","expirationDate":"2015-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[335202],"PO":["557609"]},"130300":{"abstract":"P0725340<br\/><br\/>SoD: Design of Service-based Software Systems with QoS Monitoring and Adaptation<br\/><br\/>Stephen S. Yau (Principal Investigator)<br\/>Hessam S. Sarjoughian (Co-Principal Investigator)<br\/>Nong Ye (Co-Principal Investigator)<br\/><br\/>Service-Oriented Architecture (SOA) enables the rapid composition of distributed applications and integration of the \"system of systems\", and hence is quickly adopted in distributed computing systems. Due to lack of comprehensive understanding of tradeoffs among multiple QoS features associated with service operations in service-based systems (SBS), existing software engineering techniques cannot effectively support the design of SBS satisfying multiple QoS features simultaneously.<br\/><br\/>The objective of this research is to develop a framework effectively incorporating QoS Monitoring and Adaptation (M\/A) capabilities in SBS to handle tradeoffs among four important QoS features (timeliness, throughput, accuracy and security) in the design of SBS. To achieve this objective, research on the design of M\/A capabilities in Adaptable SBS<br\/>(ASBS) and simulation-based validation of ASBS design will be conducted.<br\/>Expected research results include new scientific knowledge about the cause-effect dynamics of activity-state-event-QoS tradeoffs, innovative design support for M\/A capabilities, and new simulation principles and methods to support model configurability and scalable simulation of ASBS designs.<br\/><br\/>These results will not only strengthen the scientific rigor of software design and reduce the gap between software design and system design, but also improve the education in software engineering, advanced information systems, and software modeling and simulation.","title":"SoD: Design of Service-based Software Systems with QoS Monitoring and Adaptation and Adaptation","awardID":"0725340","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":["487903",345762,"547801"],"PO":["564388"]},"135943":{"abstract":"Although digitization of health information and IT applications in health care have received significant focus in recent years (mainly from government officials interested in improving care while achieving more cost efficiencies), the concerns of patients and their needs, as they relate to information access, have not received a similar level of attention. There is a gap in expectation with regard to the role of health information systems between the general public, who are increasingly becoming more computer- and Web savvy, and health IT professionals. A deeper consideration of the gap is expected to help clarify the challenges and point to potential means for developing effective information systems that deliver health information.<br\/><br\/>The main goal of this national workshop is to focus on key challenges involved in delivering high quality digital health information directly to citizens and health care providers. The challenges cover many areas encompassing access, interpretation, decision-making, security\/privacy, evaluation, and economic issues. A goal of the workshop is to create a forum where multi-disciplinary perspectives are supported to develop a scope for research in this area, identify critical research topics, and establish associated knowledge resources that may be helpful.","title":"NSF Frontiers in Health Information Delivery Workshop","awardID":"0753490","effectiveDate":"2007-08-16","expirationDate":"2009-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["486226"],"PO":["565136"]},"124734":{"abstract":"0700341<br\/>Patricia Johann<br\/>Rutgers U <br\/><br\/>Initial Algebra Packages for GADTs: Principled Tools for Structured Programming<br\/><br\/>Generalized algebraic data types (GADTs) are at the cutting edge of functional programming, and become more widely used every day. Nevertheless, the foundations of GADTs are not well understood. This research aims to show that GADTs support the same kind of initial algebra semantics as other advanced data types, and to use this semantics to derive collections of expressive and principled tools --- called initial algebra packages --- for understanding GADT structures, structuring programs which manipulate those structures, reasoning about properties of those programs, and automatically improving the performance of modularly constructed such programs. The research employs a three-part approach to deriving initial algebra semantics and packages for GADTs. First, an equivalent nested type is derived for each GADT.<br\/><br\/>Secondly, initial algebra semantics and packages for these nested types are derived. Finally, the initial algebra semantics and packages for the nested types are used to derive initial algebra semantics and packages for their corresponding GADTs. By providing reasoning, programming, and optimization tools for GADTs, this research has the potential to offer programmers a wider range of options for effectively handling data than is currently available, and thus to improve programming by enabling programs to better structure and manipulate data.","title":"RUI:Initial Algebra Packages for GADTs: Principled Tools for Structured Programming","awardID":"0700341","effectiveDate":"2007-08-01","expirationDate":"2009-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":[331030],"PO":["564388"]},"125647":{"abstract":"Many information workers are swamped with unfamiliar collections of text. One challenge is to obtain an accurate overview of a large text collection, such as the public comments collected in ''''''''notice and comment'''''''' rulemaking. No single tool currently provides a sufficiently diversified picture of such a corpus, and no adequate theory exists to help people explore and form a deep and nuanced understanding of such a text collection. This research seeks to develop a computational framework that allows further exploration of this problem from multiple, integrated perspectives. All the assembled perspectives will be brought together into a single overall supra-document structure that is dynamically constructed under user guidance. In this structure, hierarchical topic clusters will be cross-linked by opinion and argumentation links, using two classes of text analysis engines: one for topics and subtopics, and the other for argument structures. The research team will design, develop, build, and systematically test an overall text exploration framework, an application to support federal regulation writersone called the Rule-Writers Workbench. There is a strong collaboration with Federal government officials who will provide data and participate in user testing. The three PIs have successfully collaborated on a related project under previous NSF funding. <br\/><br\/>Intellectual Merit: This is a sustainable collaboration between computer science and political\/social science research, rooted in a challenging and important real world application and informed by years of end user research. Dynamic, user-driven subtopic definition and clustering algorithms coupled with<br\/>language modeling are an innovative yet reachable set of goals. The framework to be developed will be grounded in the humanities disciplines'' expertise in rhetoric, discourse structure, and subjectivity.<br\/><br\/>Broader Impacts: The Rule-Writers Workbench will allow federal government regulation writers to employ a suite of technical tools that perform independent analyses of public responses to proposed regulations, including near-duplicate detection and clustering, user-based topic selection from dynamically extracted keywords, opinion identification, and subtopic clustering. These capabilities will open new avenues for federal comment analysis.","title":"Collaborative Research III-COR: From a Pile of Documents to a Collection of Information: A Framework for Multi-Dimensional Text Analysis","awardID":"0704210","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"H233","name":"US FISH AND WILDLIFE SERVICE"}}],"PIcoPI":["541869"],"PO":["563751"]},"125229":{"abstract":"0702603<br\/>Ranjit Jhala<br\/>University of California - SD<br\/>Collaborative: Software Verification for Hardware Models<br\/><br\/>Modern microprocessors are some of the most complex engineering artifacts ever constructed, and their design complexity has been increasing in every generation. Correctness is a fundamental concern for microprocessors: all software applications implicitly assume correct operation of the processor. As demonstrated by the infamous Pentium division bug, the cost of bugs in the final system is prohibitive. Validating these complex designs is a real challenge. Current practice of extensive simulation for design validation is inadequate as it can only exercise a small portion of the state space, leaving many key properties unchecked.<br\/><br\/>This research applies techniques from formal verification to verifying the correctness of higher-level models of complex processors. Higher level processor models written in programming languages like C, C++, or SystemC, are becoming more and more prevalent as golden reference models for subsequent hardware implementations. While hardware and processor verification have been an active area of research, the novelty of this research is to merge the high-level design structure and powerful automated abstraction techniques developed in software verification (such as Predicate Abstraction, Shape Analysis, and Atomicity) with the insights from hardware verification (such as proof decomposition and memory abstraction). Instead of the usual bit-level models used in hardware verification, the combined techniques are likely to produce more compact models, helping the reasoning to scale to large systems, such as the complete description of a modern microarchitecture.<br\/><br\/>The research will tie in with the investigators' educational objectives of developing graduate level courses that combine the principles of formal verification with the principles of reliable system design.","title":"Collaborative: Software Verification for Hardware Models","awardID":"0702603","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["529115"],"PO":["564388"]},"127418":{"abstract":"The goal of this research project is to research a new information seeking paradigm called Proactive Personalized Information Integration and Retrieval. It differs from traditional search in one major aspect:<br\/>proactivity. A proactive retrieval agent acts in anticipation of the information needs of the user and recommends information to the user without requiring the user to make an explicit query. The project tackles the challenges in developing the agent based on a unified theoretical framework, Bayesian Graphical Models. In particular, the project includes research to:<br\/>(1) learn the optimization goal of the proactive agent as a user-specific, multi-attribute utility function that approximates the user criteria beyond relevance; (2) learn user model as a probabilistic graphical model that integrates multiple forms of information such as the context of the user;<br\/>(3) adaptively learn the user model with explicit and implicit feedback from the user as well as other users using Bayesian inference; and (4) proactively recommend documents or queries to the user to optimize the multi-attribute utility based on Bayesian decision theory. Together, these four integrated research thrusts provide a solid foundation for building a proactive personalized search agent.<br\/><br\/>The project will advance the state of the art in Information Retrieval through the development a unified framework for the new paradigm of Proactive Personalized Information Integration and Retrieval. The research results will also enhance the current information retrieval curricula.<br\/><br\/>Broader impacts of this work are expected to be very significant because of a variety of applications related personalization or recommendation techniques. The project Web site (http:\/\/www.soe.ucsc.edu\/~yiz\/piir) will be used to disseminate resulting publications, open-source code and annotated test data sets to broad communities for researchers, educators, students and industry practitioners.","title":"III-COR: Proactive Personalized Information Integration and Retrieval","awardID":"0713111","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["547825"],"PO":["563751"]},"132930":{"abstract":"Second Life is a massive multiplayer online game (virtual world) that can potentially offer an environment for social interactions regardless of disabilities, gender, race or age. However, at the present time people who are unable to see or unable to use a mouse miss out on this unique experience, though it could benefit them the most. Second Life currently has more than 6 million \"residents\" and is growing fast. Although there are certainly ethical, legal and financial justifications for developing an accessible client to this environment, the PI's goal is to improve the quality of life for millions of people in the United States with disabilities of the types mentioned above. In this exploratory project, he will develop a prototype client for Second Life that offers a basic level of accessibility, and which will allow him to assess the feasibility of and technical requirements for a client that is fully accessible to blind players. The prototype client will initially allow blind players to navigate the environment using voice commands alone; it will then be enhanced and extended, as time and resources allow, so as to enable these players to interact in meaningful ways with other players. Achieving these objectives is not straightforward, because the client and server of Second Life have only recently been made open source and no one has yet attempted to create an accessible client for the environment. The PI has identified a number of issues that need to be investigated and resolved, including how to extract relevant information from the environment in order to provide meaningful output. This funding will allow the PI to explore alternative strategies in this regard, and also to run accessibility studies with the basic client in order to identify other problems. The open source community is slowly starting to add new features to Second Life; the PI's experience with the basic client may allow him to make timely recommendations (e.g., objects descriptions may need to be much richer than they are now, to better accommodate an accessible client). <br\/><br\/>Broader Impacts: The technology developed in this project can be leveraged to other massive multiplayer online games (such as the popular World of Warcraft), not to mention games in general. Voice navigation can make first person shooters or 3D adventure games accessible to physically disabled players. The PI will take advantage of his experiences in this project to contribute to the formulation of accessibility guidelines for games, similar in spirit to those developed by the W3C for websites, which will enable future games to be developed in an inclusive way for the benefit of all members of society.","title":"Developing an Accessible Client for Second life","awardID":"0738921","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["486609"],"PO":["565227"]},"133810":{"abstract":"Datasets originating from many different real-world domains can be <br\/>represented in the form of interaction networks in a concise and meaningful fashion. <br\/>Examples abound, ranging from gene expression networks to social networks, <br\/>and from the World Wide Web to protein-protein interaction networks. <br\/>The study of these complex interaction networks, which are often evolving, <br\/>can provide insight into their structure, properties and behavior. <br\/><br\/>Identifying the portions of the network that are changing, <br\/>characterizing the type of change and extracting relevant patterns <br\/>that can help predict future events and behavior are all critical <br\/>challenges that need to be met in this context. <br\/>To this end the PI plans to explore and design an event-driven <br\/>methodology to study the evolutionary behavior of such interaction <br\/>networks from the perspective of node-level and community-level <br\/>viewpoints. Incorporating semantic information and leveraging <br\/>graph grammars in a structured manner will also be explored in this context.<br\/><br\/>The main scientific outcome of this research will include the <br\/>ability to extract, analyze and understand key patterns and features <br\/>of such dynamic interaction networks in the context of end <br\/>applications drawn from clinical and social settings. <br\/>The broader outcomes of this work will be to train capable <br\/>graduate and undergraduate students in the fields of network <br\/>analysis and data mining. Women and minorities will be especially <br\/>encouraged to participate and existing interactions with <br\/>a local HBCU will be strengthened.<br\/><br\/>Project Page: http:\/\/www.cse.ohio-state.edu\/~srini\/SGER\/information","title":"SGER: An Event-Driven Approach for Analyzing Interaction Networks","awardID":"0742999","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["527873"],"PO":["563727"]},"130257":{"abstract":"This project, involving collaboration between North Carolina State University and Purdue University, addresses the design of Healthcare information systems. Such systems are becoming ubiquitous and thus increasingly subject to attack, misuse and abuse. Specifications and designs of these systems often neglect security and privacy concerns. Moreover, regulations such as HIPAA (Health Insurance Portability and Accountability Act) as well as security and privacy policies are difficult for users to understand and complex for software engineers to use as guides when designing and implementing systems. This project defines mechanisms that are needed to help analysts disambiguate regulations so that they may be clearly specified as software requirements. In addition, regulations are increasingly requiring organizations to comply with the law and account for their actions. Individuals responsible for ensuring compliance and accountability currently lack sufficient guidance and support to manage their legal obligations within relevant information systems. Software controls are needed to provide assurances that business processes adhere to specific requirements, especially those derived from government regulations. <br\/><br\/>To address these challenges, the proposed work takes a holistic view of the design of transparent and legally compliant software systems. Key research questions that are addressed include: <br\/>-How should system requirements be specified so they may be realized in design and implementation to ensure legal and regulatory compliance? <br\/>-Given that software designs need to satisfy multiple stakeholders (organizations, law\/policy makers, government agencies, public citizens, etc.) having contradictory, inconsistent and difficult to understand objectives, how can the design process of these systems be improved to lead to convergence and satisfaction of these requirements in a transparent and auditable fashion? <br\/><br\/>This project articulates a requirements management framework that enables executives, business managers, software developers and auditors to distribute legal obligations across business units and\/or personnel with different roles and technical capabilities. This framework improves accountability by integrating traceability throughout the policy and requirements lifecycle. The broader impacts of this project are expected to be far reaching as law and regulations govern the collection, use, transfer and removal of information from software systems in many spheres of society.","title":"SoD: Collaborative Research: Transparency and Legal Compliance in Software Systems","awardID":"0725152","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":["522969"],"PO":["564388"]},"132699":{"abstract":"CCF - 0737840 Effective Theories of System Design<br\/>Smith, Douglas R.<br\/>Kestrel Institute <br\/><br\/>Effective Theories of System Design <br\/><br\/>The overarching objective of this research is to develop scientific foundations for the mechanization of software system design. These foundations lead to tools that mechanize a significant fraction of the work in developing correct and efficient software systems from specifications of their requirements. The research focuses on the capture and reuse of design knowledge. Design know-how is the prime intellectual capital of an organization, and capturing it in mathematical form enables both machine application in current design projects and communicating design knowledge to younger workers. <br\/><br\/>The research seeks to integrate requirements engineering, formal specifications, mechanized refinement, and generation of correct-by-construction system code. The least developed aspect of this approach is tool support for the mechanization of refinement steps, which incrementally add implementation detail. Refinement machinery must be informed by codification of best-practice design knowledge about system architectures, algorithms, data structures, GUIs, and so on. The specific technical objective is to codify system design knowledge by developing the upper reaches of a taxonomy of abstract system designs, generalizing previous research on taxonomies of algorithm theories, data structures, and others. A taxonomy of system design theories would not only organize a large body of design knowledge, but would directly support mechanized design by providing incremental access to knowledge that is relevant to a specified design problem.","title":"SGER: Effective Theories of System Design","awardID":"0737840","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":["561160"],"PO":["564388"]},"134899":{"abstract":"This 12-month standard award is to support a Doctoral Consortium program at the ACM Conference on Human Factors in Computing Systems to be held in Florence, Italy on April 5-10, 2008 (http:\/\/www.chi2008.org\/). This will bring together fifteen dissertation-stage doctoral students in the field of human-computer interaction (HCI) for two days of presentations and interactions with five faculty members selected from among distinguished HCI researchers. The students represent an intellectually diverse and excellent sample of the next generation of scholars, embodying a broad cross-section of HCI subfields and reflecting the geographic and demographic diversity of the community. <br\/><br\/>The CHI Doctoral Consortium, which began in 1986, has been highly successful in providing a forum for the initial socialization into the field of young doctoral scholars. Many of today?s leading HCI researchers participated in earlier Consortia as students. This project provides support for the travel and lodging of the students as well as some of the direct expenses of putting on the Doctoral Consortium at the CHI 2008 meeting.<br\/><br\/>Intellectual Merit:<br\/>The focus of the CHI Doctoral Consortium is the students? doctoral dissertation research. Since the students are selected chiefly on grounds of research excellence, this research represents the state-of-the-art in the field of HCI. The Consortium provides an opportunity both for these projects to be shaped and improved through intellectual exchange as well as for the students to present and communicate the character of their work to a key group of their peer professionals.<br\/><br\/>Broader Impact:<br\/>The CHI Doctoral Consortium brings together the best of the next generation of HCI researchers. This allows them to create a social network both among themselves and with several senior researchers, which plays a major role in their enculturation into the profession. Since the students and faculty are a diverse group on several dimensions (geography, scientific discipline, research specialization, demographics), the students? horizons are broadened at a critical stage in their professional development.","title":"IIS Workshop: Human-Computer Interaction Doctoral Research Consortium at ACM CHI 2008: Human Factor in Computing Systems","awardID":"0749033","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["550380"],"PO":["388678"]},"125835":{"abstract":"Biological nanomachines are the assemblies that carry out all the basic biological processes in a living organism. Electron cryo-microscopy (cryoEM) is the most appropriate structural tool to determine molecular structures of biological nanomachines that generally consist of multiple protein subunits and\/or nucleic acids with a total mass greater than 0.5 million Daltons. The goal is to develop information discovery and integration methodologies for deriving atomic models of nanomachines. Such models will be derived from 3-dimensional (3-D) cryoEM mass density function (i.e. a volumetric density map) in conjunction with physics of protein folding and informatics data. This project is made possible by an integration of the expertise of five investigators in computer graphics, computational biophysics, structural informatics and cryoEM. The intellectual merit of this research is highlighted by the computational approaches of extracting structural information from low-resolution, complex cryoEM volume densities and integrating this information into classical protein structure modeling paradigms, such as comparative modeling and ab initio modeling, for understanding biological nanomachines. The three research goals involve information discovery, information integration and validation of the proposed algorithms. The proposed research will have significant impacts in three disparate disciplines: computer science, molecular modeling, and cryoEM. Furthermore, the team will disseminate their resulting tools freely to the academic community and will host a workshop towards the end of the project. To enhance the impact of their research, the investigators will integrate research with education at each member institution with an eye towards diversity. In particular, these investigators will develop a virtual didactic course in modeling of biological nanomachines for graduate and senior undergraduate students at the five participating institutions.","title":"III-CXT: Collaborative Research: Integrated Modeling of Biological Nanomachines","awardID":"0705538","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["550459"],"PO":["565136"]},"125879":{"abstract":"The goal of the proposed research is to create analytical and computational tools that explicitly address the time and order of social interactions between individuals. The proposed approach combines ideas from social network analysis, Internet computing, distributed computing, and machine learning to solve problems in population biology. The diverse computational tasks of this project include design of algorithmic techniques to identify social entities such as a communities, leaders, and followers, and to use these structures to predict social response patterns to danger or disturbances. Nowhere is the impact of social structure likely to be greater than when species come in contact with predators. Thus, the accuracy and predictive power of the proposed computational tools will be tested by characterizing the social structure of horses and zebras (equids) both before and after human- or predator-induced perturbations to the social network. The proposed interdisciplinary research will have broader impacts on a wide range of research communities. New methods for analysis of social interactions in animal populations will be useful for behavioral biologists in such diverse fields as behavioral ecology, animal husbandry, conservation biology, and disease ecology. The machine learning algorithms that will be develop are relevant to many studies in which researchers need to classify temporal interaction data. The proposed network methods have broader relevance to human societies: disease transmission, dissemination of ideas, and social response to crises are all dynamic processes occurring via social networks. Further, through teaching and participation in outreach, students and school teachers will gain access to opportunities for hands-on, interdisciplinary experiences in a new area of computational biology. The research and software resulting from the proposed project will be disseminated both in computational and biological communities and enhanced by cross-disciplinary training activities and will serve to train a new generation of interdisciplinary scientists.","title":"III-CXT: Collaborative Research: Computational Methods for Understanding Social Interactions in Animal Populations","awardID":"0705822","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["533275"],"PO":["565136"]},"126627":{"abstract":"This award is to acquire a low-energy, small-object X-ray computed tomographic<br\/>scanner, an instrument also referred to as a ?desktop? or micro-CT scanner. This<br\/>instrument will extend the capabilities of a multidisciplinary team of researchers at the University of Texas High-Resolution X-ray Computed Tomography Facility (UTCT), and help better accommodate the diverse external research community now served by the facility. The new instrument will speed and improve analysis of the most popular class of samples moving through our facility, which are small and require our high-resolution scanning capabilities. With a relatively small investment in capital equipment,<br\/>this additional instrument will nearly double the productivity of the facility and will help to further reduce the per-sample costs of CT scanning. The new instrument will enhance the ability to measure local and dispersed volume properties in geological and engineering samples, such as tiny vesicles, micro-fracture patterns, and porosity and connectivity in fine grained sediments. It will also empower an ability for quantitative characterization of three-dimensional fabrics and textures at fine scales of resolution. With this instrument, the team can generate many new computational datasets for our digital library Digital Morphology (www.DigiMorph.org). The datasets generated by the new instrument will provide the raw materials to extend the current tool suite of CT data manipulation and quantification software, to exploit fully the scientific potential of micro-CT datasets. The team will refine algorithms and procedures that have been developed over UTCT''''s decade of service to the scientific community, to improve analyses of the new class of datasets generated by these new scanners. They will also contribute solutions to the challenges of archiving and distributing these large datasets, while refining the design and role of communal repositories. In the process, they will train students in instrument operation and software application, in the context of focused scientific questions that span problems in geology, biology, engineering, and informatics.","title":"CRI: IAD Acquisition of a High Resolution Micro X-ray Computed Tomographic Scanner","awardID":"0709135","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["536899","536900","536901"],"PO":["561889"]},"127606":{"abstract":"Switching networks serve as the core of network switches and routers, and communication <br\/>subsystems of multiprocessor and multi-computer computing systems. There has been a <br\/>growing interest in developing high-speed switches for multicasting. A wide class of <br\/>applications, such as teleconferencing, video distribution, LAN bridging and distributed <br\/>data processing, require multicasting communications. The essential network components <br\/>for such applications are multicast switches. Rearrangeable nonblocking (RNB) multicast <br\/>switching networks are used for packet switching, and strictly nonblocking (SNB) and <br\/>wide-sense nonblocking (WSNB) multicast switching networks are used for circuit switching. <br\/>Optimal RNB multicast switching networks have been constructed for a long time, and it <br\/>was shown that the lower bound for the cost SNB multicast switching network is O(N^2)<br\/>in 1980. Thus, for scalable circuit switching applications minimum-cost WSNB multicast <br\/>switching networks are the only solution. Multicast networks (a.k.a. generalized <br\/>connection networks, generalized connectors, distribution networks) were first formally <br\/>introduced in English literature by Masson and Jordan in 1972. Until now, the WSNB <br\/>multicast switching network with lowest cost remains to be Pippenger's network designed <br\/>in 1973. It has been a general belief that Pippenger's network is very difficult to <br\/>improve. One of the major goals of this proposed research is to seek WSNB multicast <br\/>switching networks better than Pippenger's network. In addition, we also consider <br\/>constructing optimal or near-optimal nonblocking multicast switching networks under <br\/>routability and optical implementation constraints. All problems considered are <br\/>constrained optimization problems with important implications. This proposed work not <br\/>only has significant theoretical importance but is also of practical value.<br\/>In the last 33 years, no progress on WSNB multicast switching networks better than <br\/>Pippenger's network has been reported. The intellectual merit of the proposed research <br\/>lies in the attempt of tackling a long-standing open theoretical problem, and its related <br\/>problems arising in new network technologies.","title":"SGER: Toward Optimal Structures of Wide-Sense Nonblocking Multicast Switching Networks","awardID":"0714057","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[338379],"PO":["399214"]},"127507":{"abstract":"IIS - 0713637<br\/>Freire, Juliana<br\/>University of Utah<br\/>III-COR Discovering and Organizing Hidden-Web Sources<br\/><br\/>The Web is estimated to contain millions of online databases. As the number of online databases grows, there has been an increased need for techniques and tools that allow users and applications to leverage the high-quality information that is hidden behind their Web form interfaces. This project will address the problem of discovering and organizing hidden-Web data sources, a necessary step to large-scale retrieval and integration of Web information. Scalability of novel techniques over very large volumes of data will be explored. New machine learning techniques will be applied to the problem of locating and organizing Web site fronts to databases and the overall strategy of locating and organizing web forms that serve as user interfaces to databases. These would then be clustered to discover domains<br\/>(categories) of databases the domains would be used to organize the collected forms into a searchable collection. That collection will allow users with particular interests to located databases that serve their needs.","title":"III-COR: Discovering and Organizing Hidden-Web Sources","awardID":"0713637","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["521992"],"PO":["565136"]},"127419":{"abstract":"Proposal 0713118<br\/>\"RI: High Performance Algorithms for Probablistic and Deterministic graphical Models<br\/>PI: Rina Dechter<br\/>University of California--Irvine<br\/><br\/>ABSTRACT<br\/><br\/>The goal of this project is to develop powerful algorithms that can help computer programs make sophisticated decisions when faced with real-life problems. The project's novelty is its specific focus on automated reasoning where the relevant information is a combination of certain (deterministic) and uncertain (probabilistic) information. The need to accommodate both types of information is motivated by many real world problems such as scheduling of operating rooms and the diagnosing the nature of a disease, where situation assessment, planning or decision-making often involve taking into consideration both hard constraints and probabilistic information. A unique aspect of the project is that its algorithms will be founded upon a single theoretical framework--AND\/OR search, developed by the investigator--which is driven by the graphical representation of the problems and often results in exponentially reduced complexities. The guiding principle behind the algorithms is the exploitation of useful structural features of a given problem instance, such as decomposability, sub-problem equivalence, and sub-problem irrelevance. The work proposed here promises to enhance problem-solving knowledge not just in the field of artificial intelligence, but also in the scientific community in general. As they are completed, the new algorithms will be posted on a publicly available Web site.","title":"RI: High Performance Algorithms for Probabilistic and Deterministic Graphical Models","awardID":"0713118","effectiveDate":"2007-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["475511"],"PO":["562760"]},"132810":{"abstract":"The future of quantum information depends on the progress in quantum algorithms and material systems capable of implementing these algorithms. The two areas should develop in close cooperation. The goal of the proposed workshop is to bring together leading experts in these areas in order to discuss the future directions and the ways of strengthening collaboration between scientists working on quantum algorithms and nanosystems. The workshop should help to shape, focus, and potentially expand the interdisciplinary program on quantum information processing at the NSF. The workshop will last for two days. The program will include presentations by the invited speakers ? the experts on quantum algorithms and condensed matter theory and experiment. These presentations will be followed by the presentations of the scientists currently supported by the EMT program. A panel discussion will follow with the objective of formulating a broad program of research on quantum information processing and nanoscale systems.","title":"Workshop on Quantum Information Processing and Nanoscale Systems, Washington, DC; Sept 10-11,2007.","awardID":"0738338","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["398856"],"PO":["565223"]},"130874":{"abstract":"The objective of this proposed research is the development of novel algorithms for large-scale nonlinear optimization that are based on fast estimation of active inequality constraints. Many important methods for nonlinear optimization seek to determine which inequality constraints hold as equalities at the solution, so that the problem can be simplified to an equality constrained problem. As the number of inequality constraints grows, the standard approaches, which use quadratic programming, become too slow. Thus one needs to predict the correct active constraints in a more efficient way. The active-set identification techniques developed in this project will be based on the solution of linear programming subproblems and will allow the estimate of the active constraint set to change by many constraints at a time. New general purpose nonlinear optimization algorithms will be developed using these active-set identification techniques. This project will develop software implementations of these algorithms, as well as a general theory of active-set identification that covers these algorithms.<br\/><br\/>If successful, the proposed research will allow for the solution of significantly larger nonlinear optimization models (particularly problems with many inequality constraints) than can currently be solved using active-set methods. These more powerful algorithms may be applied to previously intractable models arising in areas such as medical imaging, classification, signal processing, chemical process control, power systems management, integrated circuit design and finance. In addition, active set approaches like this will be more effective at making use of a warm start compared with interior point methods. This will be beneficial for quickly solving subproblems that arise in branch and bound methods for mixed integer nonlinear programming. The theoretical framework for active-set identification developed as part of this project will provide a basis for exploring the development of future active-set based algorithms.","title":"Collaborative Research: Investigation and Development of Active Set Prediction Techniques for Nonlinear Optimization","awardID":"0728036","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":["347460"],"PO":["502772"]},"130104":{"abstract":"This project investigates (a) how immersive 3D technology will motivate, encourage, and stimulate dance collaborators in their creative processes through a model of dance, (b) identify new elements of the IT technology that support new choreography, e.g., new view management capabilities, new synchronization protocols, and (c) characterize two different interfaces for two very different groups of users: the dancers and the choreographers.<br\/><br\/>By studying dance we can learn about non-verbal communication among people in general. There is no other art form that comes as close as dance to everyday human activity and yet intensifies, amplifies, and transforms that everydayness into extra-ordinary activity. The significance of dance as a means of analysis of a creative process include the following: dance's coded and choreography's conventions can be understood as a means of communication that is practiced across racial, cultural, ethnic, and socio-economic boundaries; one can view dance as a shared human activity; dance is a form of expression that uses bodily movements that are rhythmic, patterned, spatial, dynamic, expressive, shaped, felt, improvised, etc. dance is often accompanied by music; one of the oldest art forms, dance is found in every culture and is performed for purposes ranging from ceremonial, liturgical and magical to the theoretical, social, and aesthetic; dance has also been used to effect change in bodily or social conditions for religious and\/or political circumstances; in human time, dance has been used as an effective form of communication that went beyond boundaries of linguistic sign systems; dance has a potential shared by music and virtual arts to transform human behavior; dance lends itself to analysis because it exists in a triangle of communication: choreographer, dancer and viewer.<br\/><br\/>Intellectual Merit: This project will validate two major hypotheses: (1) Dancers will be able to learn faster new choreographies in the 3D tele-immersive spaces than via 2D video technologies, and (2) 3D tele-immersive spaces will allow choreographers to explore new choreographic elements when utilizing Digital Options not possible in co-located environments (e.g., different scales of dancers dancing together). The intellectual merit will be in understanding the creativity process in choreography domain, and in IT domain. These two hypotheses requires the development of IT tools for support of creative processes, i.e., flexible configurations of views for individual dancers, new synchronization protocols in spatial and temporal domain as the tele-immersive sides merge into one tele-immersive (TI space), and new interfaces for dancers and choreographers to access the new Digital Options in an easy manner.<br\/><br\/>Broader Impact: This project will impact developments in the 3D tele-immersive technology as well as the dancing area. From the IT perspective, the new algorithms, protocols, interfaces and corresponding tools will allow users interested in creativity processes to work with and manipulate different views, scales, numbers, backgrounds, shapes, and other digital options needed in visual arts creative processes. In the domain of dance, we will have a better understanding of the learning and the creative processes of dance choreographers. This project will also impact education. Teaching students the art of choreography requires that they expand their perceptions of the body in time and space. Often it takes the student years to learn how to do this. With the help of the 3D tele-immersive system, the student will be given tools to immediately start experimenting with bodies in space. This expansion of perception will have huge implications within the creative process itself, allowing students to see and experience new ways of being in the world, and recombining the human forms in infinitely new relationships to space and to other forms.","title":"SGER: Collaborative Research: Interactive Choreography in 3D Tele-Immersive Spaces","awardID":"0724464","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["561784"],"PO":["424970"]},"125803":{"abstract":"Andy Ruina's group at Cornell will master the use of foot<br\/>placement as a means for balance in robotic walking. Ruina's<br\/>previous research shows that, in principle, a robot could walk,<br\/>say, 10-20 km on a single battery charge much like a person can<br\/>walk a similar distance on energy from a good meal. In practice,<br\/>however, typical robots today only walk tens of meters. The<br\/>efficient machines fall down too often. The stable machines run<br\/>out of energy. Today's robots are either efficient or stable,<br\/>but not both. This shortcoming represents a lack of understanding<br\/>of the nature of balance using foot placement.<br\/><br\/>Ruina's approach will build on his Cornell lab's success in<br\/>making bipedal robots whose energy use, per unit distance and<br\/>mass, is comparable to that of humans. The new robots will<br\/>improve on the robustness in the previous efficient machines by<br\/>using controlled foot placement for balance.<br\/><br\/>Successful design and construction of the proposed new robots<br\/>will demonstrate the utility of holding energetic efficiency,<br\/>control simplicity and control robustness paramount in the design<br\/>of humanoid mechanisms. Further, general understanding of<br\/>machine efficiency and stability will be enhanced.","title":"RI: Robust implementation of foot placement for balance of 3D bipedal walking","awardID":"0705390","effectiveDate":"2007-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["549677"],"PO":["543539"]},"125825":{"abstract":"Biological nanomachines are the assemblies that carry out all the basic biological processes in a living organism. Electron cryo-microscopy (cryoEM) is the most appropriate structural tool to determine molecular structures of biological nanomachines that generally consist of multiple protein subunits and\/or nucleic acids with a total mass greater than 0.5 million Daltons. The goal is to develop information discovery and integration methodologies for deriving atomic models of nanomachines. Such models will be derived from 3-dimensional (3-D) cryoEM mass density function (i.e. a volumetric density map) in conjunction with physics of protein folding and informatics data. This project is made possible by an integration of the expertise of five investigators in computer graphics, computational biophysics, structural informatics and cryoEM. The intellectual merit of this research is highlighted by the computational approaches of extracting structural information from low-resolution, complex cryoEM volume densities and integrating this information into classical protein structure modeling paradigms, such as comparative modeling and ab initio modeling, for understanding biological nanomachines. The three research goals involve information discovery, information integration and validation of the proposed algorithms. The proposed research will have significant impacts in three disparate disciplines: computer science, molecular modeling, and cryoEM. Furthermore, the team will disseminate their resulting tools freely to the academic community and will host a workshop towards the end of the project. To enhance the impact of their research, the investigators will integrate research with education at each member institution with an eye towards diversity. In particular, these investigators will develop a virtual didactic course in modeling of biological nanomachines for graduate and senior undergraduate students at the five participating institutions.","title":"III-CXT: Collaborative Research: Integrated Modeling of Biological Nanomachines","awardID":"0705474","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["509169"],"PO":["565136"]},"125737":{"abstract":"Machine-readable lexical resources are essential to Natural Language<br\/>Processing applications such as information extraction and machine translation. <br\/>The largest lexicon is WordNet, with <br\/>semantic information about more than 150,000, or lexical units (LUs). <br\/>A smaller, independently developed resource is FrameNet, <br\/>which provides detailed information about the syntactic patterns for LUs. <br\/>The project investigates the ways in which these complementary resources <br\/>can be combined using the semantic-syntactic information from<br\/>FrameNet (FN) where available and falling back on less detailed<br\/>entries from WordNet (WN) in other cases. <br\/><br\/>WN and FN exhibit fundamentally different design principles. <br\/>WN groups (near) synonymous LUs into <br\/>\"synsets,\" which are interconnected via conceptual and lexical relations <br\/>to form a semantic network. FN groups LUs according to the<br\/>\"semantic frame\" they evoke, which is a type of event, relation or<br\/>state along with the participants involved in the event. Thus,<br\/>while antonyms such as _praise_ and _blame_ may be in the same FN frame <br\/>they are in different, though interlinked, WN synsets. Moreover, FN frames <br\/>cover semantically related nouns, verbs and adjectives; WN synsets<br\/>do not mix part of speech. Crucially for NLP applications, the resources <br\/>differ with respect to sense distinctions.<br\/>Alignment will be investigated for the following differences: <br\/>lexical coverage, sense distinctions, taxonomic and<br\/>other semantic relations, and scalar frames for adjectives.<br\/>Some 1,000 word senses are examined in detail so as to provide an idea of<br\/>the distribution of each of these phenomena over the entire lexicon. <br\/><br\/>This theoretical work lays the foundation for constructing a unique, <br\/>invaluable resource for the NLP community.","title":"RI: Collaborative Proposal: Complementary Lexical Resources: Towards an Alignment of WordNet and FrameNet","awardID":"0705155","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}}],"PIcoPI":["353897","561714"],"PO":["565215"]},"126507":{"abstract":"Proposal #: CNS 07-08498 07-09946 07-08420<br\/>PI(s): Preisig, James C Ye,Wei Stojanovic, Milica<br\/>Lee, Freitag Heidenmann, John S.<br\/>Institution: Woods Hole Oceanographic Inst U Southern California Mass Inst Tech<br\/>Woods Hole, MA 02543-1041 Los Angeles, CA 90089-1147 Cambridge, MA<br\/>02139-4307<br\/>Proposal #: CNS 07-09005 07-08938 07-08467<br\/>PI(s): Cui, Jun-Hong (June) Levine, Brian; Kurose,James F. Freitag, Lee<br\/>Rajasekaran,Sanguthevar;Shi, Zhijie;Willett,Peter K.;Zhou,Shengli<br\/>Institution: University of Connecticut U of Massachusetts WHOI<br\/>Storrs, CT 06269-1133 Amherst, MA 01003-9242 Woods Hole, MA 02543-1041<br\/>Title: Collab Rsch:CRD\/IAD:Open Research Testbed for Underwater Ad Hoc and<br\/>Sensor Networks (ORTUN)<br\/><br\/>This collaborative project, developing the first open testbed infrastructure for the<br\/>underwater networking community, enables open access with the capability to conduct<br\/>experiments remotely. The infrastructure, based on open research platforms, consists of<br\/>a testbed that enables wide and systematic experimental evaluation and comparison of<br\/>underwater acoustic networks. The work, involving this rapidly deployable testbed that<br\/>can be shared by the underwater networking community, aims to demonstrate the ability<br\/>of the facility to facilitate field experiments. The project represents a higher-level<br\/>collaborative that arose from two collaborative groups. One group developing the<br\/>facility, the other working mainly on the experiments utilizing the facility. The testbed is<br\/>expected to be a buoy-based system that can be easily taken to different environments.<br\/>When operational, these systems will be deployed 5 or 6 times a year. The<br\/>infrastructure will consist of two types of nodes with different capabilities. The first type<br\/>of node of the rapidly deployable testbed will offer a fixed physical layer capability using<br\/>acoustic modems such as the WHOI micromodem or the ISI S-modem to implement a<br\/>physical layer with limited reconfigurability interfaced to a reconfigurable network<br\/>processor. This network processor will support algorithm\/protocol implementation and<br\/>testing at higher network layers. The Network functions on the Fixed Physical Layer<br\/>testbed will be hosted by a Gumstix processor which will then communicate with<br\/>physical layer modems such as the WHOI Micromodem or USC\/ISI S-modem via a<br\/>serial port. Ten to fifteen fixed physical layer nodes will be built including up to 3<br\/>gateway nodes. Each gateway node of the testbed will be equipped with wireless RF<br\/>communication enabling real-time monitoring and control of network performance. The<br\/>fixed physical layer nodes will be smaller and more easily deployed than the second<br\/>type of node which is the all-layer node. The all-layer node is a more capable node that<br\/>will ultimately support algorithm\/protocol implementation and acoustic data collection at<br\/>all networking layers. In addition to the equipment included in the fixed physical layer<br\/>nodes (i.e., a gumstix network processor and the ability to support relatively fixed<br\/>physical layer modems such as the WHOI Micromodem and the ISI S-modem), the<br\/>all-layer nodes will also include a general purpose data acquisition system (D\/A and<br\/>A\/D) with substantial disk storage and in-situ processing capability. The MIT r-modem<br\/>software will be implemented on this general purpose hardware and, along with<br\/>MATLAB, will enable user implementation and testing of algorithms and the gathering of<br\/>acoustics data at the physical layer in addition to the testing at higher network layers<br\/>that it will share in common with the fixed physical layer nodes. Three to five all-layer<br\/>nodes will be built. The rapidly deployable testbed, using two types of nodes with<br\/>varying capabilities, should significantly enhance research at all network layers while<br\/>setting the stage for future infrastructure improvements.<br\/><br\/>Many research groups investigating fundamental questions about how to design such<br\/>networked systems that utilize acoustic communications in complex underwater<br\/>environments have had their overall effort significantly slowed by the lack of common<br\/>means to test and compare protocols under realistic environmental conditions. This<br\/>infrastructure responds to the need for consensus on analytic or simulation models for<br\/>underwater networks where researchers need the ability to gather experimental data<br\/>under real world conditions in order to make progress.<br\/><br\/>The network stack will be modular by design with sockets used to enable cross layer<br\/>control and communication. The physical, MAC, Network and Application layers will be<br\/>populated with sample components to enable users test their own algorithms or<br\/>protocols without having to populate the entire stack. Users will be able to write modules<br\/>to test their own algorithms or ","title":"Collaborative Research: CRI: IAD: Developing a Novel Infrastructure for Underwater Acoustic Sensor Networks","awardID":"0708467","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["462528"],"PO":["557609"]},"126628":{"abstract":"Proposal #: CNS 07-09140 07-08307 07-08820 <br\/>PI(s): Brockman, Jay B. Bader, David A. Gao, Guang R. <br\/> Barabasi,Albert-Laszlo;Chawla,Nitesh;Kogge,PeterM. Vetter, Jeffrey S. <br\/>Institution: University of Notre Dame Georgia Institute Tech U.Delaware<br\/> Notre Dame, IN 46556-5602 Atlanta, GA 30332-0002 Newark, DE 19716-1551<br\/>Proposal #: CNS 07-09385 07-09111 07-09254 <br\/>PI(s): Gilbert, John R. Upchurch, Edwin T. Yelick, Katherine A.<br\/> Wolski, Richard. <br\/>Institution: UC-Santa Barbara California Inst Tech UC-Berkeley<br\/> Santa Barbara, CA 93106-2050 Pasadena, CA 91125-0600 Berkeley, CA 94704-5940<br\/>Title: Colla Rsch:IAD:Dev Rsch Infr. for Multithreaded Computing Community Using Cray Eldorado Platform<br\/><br\/>Project Proposed:<br\/><br\/>This collaborative project, developing a shared infrastructure needed to broaden its impact for developing software to run on the next generation of computer hardware, brings a diverse group of researchers from six universities in a joint effort. The work responds to the trend towards multicore processors where developers envision placing tens to hundreds of cores on a single die, each running multiple threads (in contrast to the currently dominant message-passing architectures resulting from the advent of MPI and Linux clusters). Three objectives are proposed:<br\/>. Acquiring computer hardware as a shared community resource capable of efficiently running, in experimental and production modes, complex programs with thousands of threads in shared memory; <br\/>. Assembling software infrastructure for developing and measuring performance of programs running on the hardware; and<br\/>. Building stronger ties between the people themselves, creating ways for researchers at the partner institutions to collaborate and communicate their findings to the broader community.<br\/>The Cray XMT system, scheduled for delivery in 2007 serves as an ideal platform. The second bullet includes algorithms, data sets, libraries, languages, tools, and simulators to evaluate performance of program running on the hardware focusing on applications that benefit from large numbers of threats, massively data intensive, \"sparse-graph\" problems that are difficult to parallelize using conventional message-passing on clusters. Each university contributes a piece to the infrastructure, using it for support of projects. Sandia National Laboratories has agreed to host the system and provide supplementary funding. Each university will use the Cray XMT system in courses.<br\/><br\/>Broader Impacts: The infrastructure measures performance providing a basis for the community to improve sharin, and build strong ties for collaboration and communication. Courses will be created and materials will be made available. Workshops for dissemination of the findings are also planned.","title":"Collaborative Research: CRI: IAD: Development of a Research Infrastructure for the Multithreaded Computing Community Using the Cray Eldorado Platform","awardID":"0709140","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["507932",336016,"385731","537738"],"PO":["557609"]},"129928":{"abstract":"CSR?CSI?SGER: Sensor Systems Technologies for Dynamic Data-Driven Scientific Applications <br\/><br\/>The overall goal of this research project is to develop sensor system middleware and programming support that will enable distributed networks of sensors to function, not only as passive measurement devices, but as intelligent data processing instruments, capable of data quality assurance, statistical synthesis and hypotheses testing as they stream data from the physical environment to the computational world. Specifically, this exploratory project will address the following research components: investigate a programming system that will support the development of in-network data processing mechanisms, and will enable scientific\/engineering applications to discover, query, interact with, and control instrumented physical systems using semantically meaningful abstractions; investigate services for active in-network data processing that will generate appropriate data\/information to drive novel algorithms for modeling, interpretation and decision making, as well as algorithms for information acquisition with dynamic qualities and properties from streams of data from the physical environment, and explore how applications can control data acquisition; and investigate middleware services for the application-driven dynamic management of sensor systems for physical instrumentation, including overlay sensor system runtime management and adaptation, computation\/communication\/power tradeoffs and dynamic load-balancing. The proposed research activities will be performed driven and validated with two different applications: (1) subsurface modeling and geo-system management and control and (2) contaminant management and geo-system remediation. A key deliverable of this research will be an experimental infrastructure that will build on the NSF Orbit wireless sensor network testbed at Rutgers University and develop the software infrastructure that will enable scientists and engineers to experiment with different aspects of dynamic data-driven application systems (DDDAS), and will design this simulation environment in close collaboration with the 2 different application groups so that it closely emulates their DDDAS requirements.","title":"Sensor Systems Technologies for Data-Driven Dynamic Scientific Applications","awardID":"0723594","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["522465","558205"],"PO":["493916"]},"127409":{"abstract":"PI: Aleix Martinez<br\/>Institution: Ohio State University<br\/><br\/>Title: RI: Computer Vision Algorithms for the Study of Facial Expressions of Emotions in Sign Languages<br\/><br\/>It is known that there exist important perceptual differences between deaf native users of American Sign Language (ASL) and hearing people with no prior exposure to ASL. This project will systematically investigate the differences between these two groups as they observe and classify images of faces with regard to the displayed emotion. <br\/>These perceptual differences may have they roots in the distinct manner in which native users of ASL and non-users code and analyze 2D and 3D motion patterns. We will thus study how these differences relate to the perception of movement. Finally, we will develop a face avatar that can emulate the facial movements of users and non-users of ASL. To achieve this goal, we will develop a set of computer vision algorithms that can be used to study the differences in production of facial expressions of emotions in native users of ASL and non-signers. A necessary step for this is to collect a database of facial expressions of emotions as produced by users of ASL. This will reveal differences at the production level and will allow for the study of perceptual differences.<br\/><br\/>The research described above addresses several critical issues. <br\/>First, these studies are fundamental to fully understand the underlying mechanisms used by the brain to analyze, code and recognize facial expressions of emotions. While research on facial expressions of emotion has proven extremely challenging to date, most of the studies have only targeted the hearing. This proposal will study the underlying mechanisms associated to code, produce and interpret facial expression of emotions of native users of ASL. <br\/>Unfortunately, the computer vision algorithms necessary to carry out these studies are not available. The research in this project is set to remedy this shortcoming.<br\/><br\/>The facial analysis studies that will be conducted during the course of this proposal can be used in a large number of applications, for example, from human-computer interaction systems where the computer interprets expressions form its user, and to study the role that each facial feature plays in the grammar of ASL. Furthermore, the study of emotional gestures will be valuable to those anthropologists attempting to understand and model the evolution of emotions, and could be used to develop mechanisms to detect lies and deceit. The database of facial expressions collected during the course this project will be made available to the research community and to educators of ASL. We will open collaborations with the School for the Deaf and encourage deaf students to pursue careers in computing and engineering.<br\/><br\/>URL:<br\/>http:\/\/cbcsl.ece.ohio-state.edu\/research\/","title":"RI: Computer Vision Algorithms for the Study of Facial Expressions of Emotions in Sign Languages","awardID":"0713055","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[337900],"PO":["564316"]},"132877":{"abstract":"The proposed research is aimed at using the technology of Integer Linear Programming (ILP) for exploring controlled mobility in wireless networks. We consider multi-hop wireless networks were a large number of nodes are statically placed and only some of them can move. By using ILP techniques we want to show that routes and schedules for the mobile nodes can be found that optimize crucial network performance metrics, such as the network lifetime and the end-to-end data packet latency. Contributions of the proposed research are multifold. We expect to advance the state of the art in wireless networks where some nodes are mobile. Furthermore, we will test and push the current capabilities in ILP modeling and solution technology. Among the expected outcome of the proposed research we will define complex models of realistic (in size, parameters, etc.) network scenarios; we will develop and test heuristics to make the ILP formulations more scalable; we will determine provable performance bounds on metrics of interests for wireless network, and we will compare heuristic solutions to these bounds for rigorous benchmarking and protocol design and optimization.","title":"SGER: Integer Linear Programming Models for Mobility in Wireless Networks","awardID":"0738720","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["499280"],"PO":["434241"]},"133526":{"abstract":"Advances in spoken dialogue systems rely on studies of how some strategic system change affects real user behavior. Since any change to a dialogue system provokes a change in what users say, it is probable that non-live, pre-recorded dialog corpora cannot measure what that change will be. This feasibility study, Let's Go Lab, explores the alternative possibility of using a common dialogue platform. The Let's Go system is being made available as a proof-of-concept speech research community resource for dialogue studies. Let's Go answers the phone for the Port Authority of Allegheny County to give scheduling information from 7pm to 6am every day to an average of 60 callers.<br\/>Researchers propose a study and work with the Let's Go Lab team to modify the base system as needed, run offline tests, and finally \"go live\", testing their hypotheses on significant quantities of dialogues with real users. The project will explore whether both minor changes (replacing one system utterance) and major ones (changing the dialogue management architecture) are feasible. The Let's Go team is also examining how to lessen startup costs for each new study by reusing past modules, refining \"go live\" criteria, and training researchers to participate in the preparatory work. If this project is successful, it will pave the way for a new, powerful community resource where results can be compared on a common platform, statistically significant numbers of real users can be tested and new researchers can enter the field easily.","title":"SGER: Let's Go Lab","awardID":"0741773","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["561898","396893"],"PO":["565215"]},"130149":{"abstract":"This project investigates (a) how immersive 3D technology will motivate, encourage, and stimulate dance collaborators in their creative processes through a model of dance, (b) identify new elements of the IT technology that support new choreography, e.g., new view management capabilities, new synchronization protocols, and (c) characterize two different interfaces for two very different groups of users: the dancers and the choreographers.<br\/><br\/>By studying dance we can learn about non-verbal communication among people in general. There is no other art form that comes as close as dance to everyday human activity and yet intensifies, amplifies, and transforms that everydayness into extra-ordinary activity. The significance of dance as a means of analysis of a creative process include the following: dance's coded and choreography's conventions can be understood as a means of communication that is practiced across racial, cultural, ethnic, and socio-economic boundaries; one can view dance as a shared human activity; dance is a form of expression that uses bodily movements that are rhythmic, patterned, spatial, dynamic, expressive, shaped, felt, improvised, etc. dance is often accompanied by music; one of the oldest art forms, dance is found in every culture and is performed for purposes ranging from ceremonial, liturgical and magical to the theoretical, social, and aesthetic; dance has also been used to effect change in bodily or social conditions for religious and\/or political circumstances; in human time, dance has been used as an effective form of communication that went beyond boundaries of linguistic sign systems; dance has a potential shared by music and virtual arts to transform human behavior; dance lends itself to analysis because it exists in a triangle of communication: choreographer, dancer and viewer.<br\/><br\/>Intellectual Merit: This project will validate two major hypotheses: (1) Dancers will be able to learn faster new choreographies in the 3D tele-immersive spaces than via 2D video technologies, and (2) 3D tele-immersive spaces will allow choreographers to explore new choreographic elements when utilizing Digital Options not possible in co-located environments (e.g., different scales of dancers dancing together). The intellectual merit will be in understanding the creativity process in choreography domain, and in IT domain. These two hypotheses requires the development of IT tools for support of creative processes, i.e., flexible configurations of views for individual dancers, new synchronization protocols in spatial and temporal domain as the tele-immersive sides merge into one tele-immersive (TI space), and new interfaces for dancers and choreographers to access the new Digital Options in an easy manner.<br\/><br\/>Broader Impact: This project will impact developments in the 3D tele-immersive technology as well as the dancing area. From the IT perspective, the new algorithms, protocols, interfaces and corresponding tools will allow users interested in creativity processes to work with and manipulate different views, scales, numbers, backgrounds, shapes, and other digital options needed in visual arts creative processes. In the domain of dance, we will have a better understanding of the learning and the creative processes of dance choreographers. This project will also impact education. Teaching students the art of choreography requires that they expand their perceptions of the body in time and space. Often it takes the student years to learn how to do this. With the help of the 3D tele-immersive system, the student will be given tools to immediately start experimenting with bodies in space. This expansion of perception will have huge implications within the creative process itself, allowing students to see and experience new ways of being in the world, and recombining the human forms in infinitely new relationships to space and to other forms.","title":"SGER: Collaborative Research: Interactive Choreography in 3D Tele-immersive Spaces- Expanding Human Perception through Creative Practice","awardID":"0724681","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["563532",345344],"PO":["424970"]},"136837":{"abstract":"Context<br\/>The goal of this grant is to 1) form a computer-aided system to improve decision-making for traumatic pelvic injuries and 2) support research on a number of data integration topics in computer science. Trauma is the leading cause of death for Americans under the age of 45. Traumatic pelvic injuries can be fatal due to severe hemorrhage, and care givers treating these injuries need to consider several types of data, including biomedical signals, images, trauma scores, laboratory results, diagnosis\/treatment, injury specifics, and demographics during the decision making process. Integrating simple types of data such as lab results and demographics is not easy, but the decision-making process shows its true complexity when trying to integrate more complex types of patient data such as biomedical signals and images. <br\/><br\/>Intellectual Merit<br\/>The project is challenging in the following aspects: <br\/>o It constructs a traumatic pelvic injury database that includes all relevant biomedical signals\/images, trauma scores, lab results, diagnosis, treatment, demographics, and injury specifics for each patient. This database will have two significant advantages over existing databases: 1) it will contain not only patient demographics and trauma scores but also time-series (signals) of physiological measures and images; and 2) in the new database, instead of including only raw data, patient information is processed and transformed into a set of features that can be directly used for decision making. <br\/>o A variety of novel biomedical signal and image processing methods will be formed to extract relevant features. These computational methods will include both the improved versions of computational methods in signal and image processing (e.g., segmentation techniques for CT images), and feature extraction methods for specific signals and images (e.g., defining the total area of the pelvic ring captured from CT as a feature). <br\/>o The project constructs a rule database where all derived features for patients in the feature database are analyzed with outcomes, resulting in a set of rules to describe logical relationships among the input features and resulting outcomes\/recommendations, using non-linear classification and regression tree. The project is novel in its rule validation; besides using typical statistical methods such as cross-validation and measures of sensitivity and specificity used in existing systems, a new statistical framework based on computational learning theory will be used to allow a more comprehensive comparison of the new system with other methods such as neural networks and Bayesian classifiers.<br\/><br\/>Broader Impacts<br\/>This project brings together computer scientists with trauma experts and will produce a system that can be replicated at other hospital systems. This methodology can be used for other types of trauma cases, such as brain injuries. Educationally, project results will be included in regular seminars to teach healthcare providers across the spectrum of the trauma care the latest techniques used in trauma care. The PI will align the research project with undergraduate and graduate research and outreach activities managed by the University of North Carolina at Charlotte''s Diversity in IT Institute, whose mission is to increase enrollment and retention of women and underrepresented groups within IT with a focus on facilitating graduate and undergraduate interdisciplinary programs, and two NSF-funded programs housed within the institute: 1) The Students & Technology in Academia, Research, and Service Alliance: A Southeastern Partnership for Broadening Participation in Computing, and 2) Computing Research for Undergraduates.","title":"III-CXT: Information Integration and Processing for Computer-Aided Trauma Decision Making","awardID":"0758410","effectiveDate":"2007-08-16","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[363602],"PO":["543481"]},"126926":{"abstract":"Pacific Rim Experiences for Undergraduates: Creating a Sustainable Model for International Undergraduate Research <br\/>This award provides the University of California-San Diego (UCSD) with a three-year renewal of Pacific Rim Experiences for Undergraduates PRIME NSF #0407508 which is built on a collaborative framework in grid applications previously supported by NSF, Pacific Rim Applications Grid and Middleware Assembly (PRAGMA NSF #0314015 and NSF #0627026)\". The overarching goal of PRIME is to prepare students to work in the global market place by providing them with a research apprenticeship coupled with a culturally immersive experience at a PRAGMA host site. The initial award developed a prototype for such research and cultural experiences for undergraduates. The current award will explore how to create a sustainable model for international undergraduate research. Two key objectives with this award are to integrate and sustain the PRIME program within a specific disciplinary framework, the bioengineering department at UCSD's Jacobs School of Engineering, to understand the role of a department in creating a sustainable model. In addition, this project also plans to deepen the quality of the student experience through web-based, cultural awareness curriculum, and developing tools to evaluate the impact of that curriculum. Consistent with the existing PRIME model, the research themes of the projects involve the use or development of cyberinfrastructure tools, specifically grid-computing. The project will disseminate its findings to help inform other programs that focus on international research and cultural experiences for undergraduate and graduate students.","title":"Pacific Rim Experiences for Undergraduates: Creating a Sustainable Model for International Undergraduate Research","awardID":"0710726","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7316","name":"EAPSI"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7731","name":"OTHER GLOBAL LEARNING & TRNING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0603","name":"Division of EARTH SCIENCES","abbr":"EAR"},"pgm":{"id":"1581","name":"CONTINENTAL DYNAMICS PROGRAM"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"5345","name":"BIOMEDICAL ENGINEERING"}}],"PIcoPI":["547710",336793,336794,336795],"PO":["553073"]},"125859":{"abstract":"Severe motor disabilities, including locked-in syndrome and paralysis, impact the quality of life for millions of people worldwide. The PIs' prior work in brain-computer interfaces based on functional near-infrared (fNIR) imaging has shown great promise for restoring communication and environmental control to people with such disabilities. Currently, typical control interfaces for these systems are simple discrete selection paradigms, which have proven to be effective but limited in information throughput rates. Innovative control interfaces based on continuous control paradigms, which dynamically map brain signal levels to control signals, have not been adequately studied for fNIR imaging. Depending upon the extent to which brain signals can be effectively mapped to continuous control, adding this feature to existing discrete control could significantly increase the range of tasks that can be performed by users of an fNIR-based direct brain interface (e.g., positional selection or 2-D drawing). In this work, the PIs will explore innovative direct brain-computer interfaces for continuous control and use them to develop applications for creative expression. For people with severe motor disabilities, creative expression can provide an emotional outlet as well as mental exercise to improve quality of life. The tasks inherent in creating visual art, such as drawing, coloring, and texturing, cannot be accomplished with discrete controls. Therefore, visual art provides an ideal experimental platform to study fNIR-based continuous control interfaces. It also provides an engaging and motivating platform for training that will improve users' abilities to control a direct brain interface. To these ends, the PIs will study non-traditional control interfaces for continuous and discrete selection such as wheels, dials, and gauges, to determine to what extent fNIR signals can be mapped to continuous control. The PIs will explore continuous methods for selection and control of art media such as brushes, colors, textures, and shapes, and investigate to what extent continuous brain signals can be translated into visual art gestures (drawing, shading, coloring). The advice of a professional, internationally-known artist who has ALS will guide the user requirements of the control interfaces. Quantitative and qualitative user performance data will be collected, and will among other things be used to compare learning effects with a visual art paradigm against traditional, discrete selection exercises to determine if training time and performance can be improved. Project outcomes will add to the body of knowledge for assistive technology and human-computer interfaces.<br\/><br\/>Broader Impacts: Methods for translating cortical oxygenation signals into continuous control signals for user interfaces will have mainstream applications for assistive technologies by essentially \"smoothing\" noisy input signals. Such developments could be applied for use by those with reduced motor coordination, including the elderly, young children, and those with motor diseases such as Parkinson's disease. Mainstream users may benefit from a hands-free interface, and neural control could provide added dimensions to the creative process.","title":"HCC: Collaborative Research: Continuous Control Brain-Computer Interfaces for Creative Expression","awardID":"0705679","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["554219"],"PO":["565227"]},"127839":{"abstract":"The complexity of modern large-scale systems has caused a transition<br\/>from a purely perimeter-based defensive model to one where security<br\/>mechanisms pervade the infrastructure. However, there has not been a<br\/>corresponding evolution in the model under which security policy<br\/>operates in such environments: policies must still make independent<br\/>decisions using only partial information: just what is known by that<br\/>component at the time the decision is made. Thus, security policy must<br\/>operate under certain assumptions that often cannot be validated. Such<br\/>unchecked assumptions offer a way for attackers to bypass security by<br\/>exploiting unforeseen loopholes. Consequently, administrators often<br\/>use additional security mechanisms, such as intrusion-detection<br\/>systems, that are poorly integrated with each other and with the<br\/>explicit system access-control policy.<br\/><br\/>This project is exploring the use of coordinated security policy<br\/>mechanisms in heterogeneous, large-scale distributed environments. The<br\/>assumptions on which security policy decisions are based are always<br\/>checked against current facts. Changes of these facts are signaled by<br\/>events propagated to other security-critical elements. Security<br\/>mechanisms become dynamic, allowing for coordinated and continuous<br\/>policy re-evaluation throughout the duration of an entity's<br\/>interactions with the various components of the system. This model<br\/>naturally integrates access control, intrusion detection and other<br\/>defensive mechanisms, allowing for the unification of protection and<br\/>reaction under the auspices of a common security policy. The result is<br\/>a more reliable and robust computing infrastructure that is resilient<br\/>to new threats and attacks, and bridge the gap between the<br\/>capabilities offered by advanced defense mechanisms and the inability<br\/>of security policy to take advantage of them in a coherent,<br\/>coordinated manner.","title":"CT-ISG: Integrated Enterprise Security Management","awardID":"0714647","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["564223"],"PO":["529429"]},"131931":{"abstract":"This CISE Special Project award provides funding for approximately sixty undergraduate, graduate student, and MSI faculty to attend the 2007 Richard Tapia Celebration of Diversity in Computing Conference which will be held on October 14-17, 2007 in Orlando, Florida. <br\/><br\/>The intellectual merit of this proposal involves enabling a larger number of students to attend and benefit from the unique environment provided by the Tapia Conference. They will have access to the many researchers and technical presentations at the conference. In addition, the students themselves can present their own work in a poster session (part of a national competition sponsored by the ACM) and at a PhD Consortium, giving them the opportunity to get feedback from discipline specialists. The Tapia Conference provides an incredibly supportive environment for students from the under-represented groups in Computing ? Native Americans, Hispanics, and African Americans ? to engage in intellectual discourse with a range of researchers. Students will also meet many of their peers from other institutions which will enable them to build their personal networks and form professional relationships that can last for their entire career. This award will also fund travel support for some faculty at MSIs, giving them the opportunity to accompany their student mentees and make important technical contacts for themselves.<br\/><br\/>The broader impacts of this proposal include outreach and opportunities for a diverse set of students and faculty in computing. Students and faculty who attend the Tapia Conference will be exposed to role models, mentors, and professional peers. The experience will strengthen their commitment to and skills in computing, increasing their persistence and professional success.","title":"The Richard Tapia Celebration of Diversity in Computing Conference 2007","awardID":"0733230","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["554552","363758"],"PO":["564181"]},"133813":{"abstract":"Abstract<br\/><br\/>The goal of this SGER proposal is to investigate the feasibility of using a segmentation tree as a general purpose multiscale representation of image structure, and assess the value of this representation for higher-level tasks such as object recognition. <br\/>This objective requires demonstrating the stability of such a tree under changes in object viewing conditions, and developing robust algorithms for matching segmentation trees to find corresponding regions in multiple views of the same object. The motivation to explore this line of thinking has come from the recent work of the PIs, which has indicated that segmentation trees have the potential of making a significant impact on the state of the art in object recognition. This finding is controversial as it contradicts a widely held belief in the vision community that since low-level image segmentation varies somewhat with imaging conditions, algorithms that use regions as image features cannot offer a reliable basis for image understanding.<br\/>The main goal of this proposal is to address those concerns and obtain conclusive results to firmly establish or reject the PIs' <br\/>preliminary conclusions.","title":"SGER: Segmentation Trees and Their Robust Matching as Core Technologies for Recognition","awardID":"0743014","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["499628","542093"],"PO":["564316"]},"132845":{"abstract":"Abstract<br\/><br\/>IIS - 0738543<br\/>Lagoze, Carl J.<br\/>Cornell University<br\/>SGER: Advancing the State of eChemistry: Workshop and Pilot Study<br\/><br\/>This project requests funding for two main efforts over a one-year period. The first is an international eChemistry workshop bringing together innovators in the chemistry and chemical informatics community in order to understand more exactly the nature and parameters of the current state and the requirements for the collection and communication of experimental and scholarly data within the discipline. Computing and network technologies, digital data capture, techniques, and advances in data mining and machine learning algorithms offer the potential for enabling new communication paradigms, as well as new collaborative models for research, and social networks for knowledge building. The physics and astronomy communities are noted for having exploited and benefited from deployment of new information technologies. Based on the outcome of the workshop, a whitepaper will be created to lay the basis for future research activities to investigate notions such as virtual laboratories, data-centric publishing, and semantically-based data integration in chemistry. The second effort is a pilot study of chemistry subcommunities using ethnographic and quantitative methods.","title":"SGER: Advancing the State of eChemistry: Workshop and Pilot Study","awardID":"0738543","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["541699"],"PO":["433760"]},"132229":{"abstract":"Abstract<br\/><br\/><br\/>Proposal ID: IIS-0735129<br\/>PI: Garcia-Molina, Hector<br\/>Institution: Stanford University<br\/>Title: SGER Year 2: A Web Sociologist's Workbench<br\/><br\/><br\/>This SGER project is constructing integrated tools that will help social scientists analyze large time series snapshots of World Wide Web content. Such data offer social scientists new means for conducting research into new topics. The exploratory work brings together Stanford's Computer Science department and Political Science faculty at the university. The computing faculty have developed an operational Web archive gathering and storage system. This facility specializes on repeatedly collecting materials from the same Web sites and storing them for subsequent time series analysis. This is considered an important new resource for social sciences research. The central problem for computer science is the large scale of the collected material and the heterogeneity of the content.","title":"SGER, year II: A Web Sociologist's Workbench","awardID":"0735129","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["447448"],"PO":["433760"]},"125827":{"abstract":"The goal of the proposed research is to create analytical and computational tools that explicitly address the time and order of social interactions between individuals. The proposed approach combines ideas from social network analysis, Internet computing, distributed computing, and machine learning to solve problems in population biology. The diverse computational tasks of this project include design of algorithmic techniques to identify social entities such as a communities, leaders, and followers, and to use these structures to predict social response patterns to danger or disturbances. Nowhere is the impact of social structure likely to be greater than when species come in<br\/>contact with predators. Thus, the accuracy and predictive power of the proposed computational tools will be tested by characterizing the social structure of horses and zebras (equids) both before and after human- or predator-induced perturbations to the social network. The proposed interdisciplinary research will have broader impacts on a wide range of research communities. New methods for analysis of social interactions in animal populations will be useful for behavioral biologists in such diverse fields as behavioral ecology, animal husbandry, conservation biology, and disease ecology. The machine learning algorithms that will be develop are relevant to many studies in which researchers need to classify temporal interaction data. The proposed network methods have broader relevance to human societies: disease transmission, dissemination<br\/>of ideas, and social response to crises are all dynamic processes occurring via social networks. Further, through teaching and participation in outreach, students and school teachers will gain access to opportunities for hands-on, interdisciplinary experiences in a new area of computational biology. The research and software resulting from the proposed project will be disseminated both in computational and biological communities and enhanced by cross-disciplinary training activities and will serve to train a new generation of interdisciplinary scientists.","title":"III-CXT: Collaborative Research: Computational Methods for Understanding Social Interactions in Animal Populations","awardID":"0705477","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["551090"],"PO":["565136"]},"125849":{"abstract":"This research proposes to help students work more effectively in global software teams. The project will involve researchers from Turkey, Panama, and England along with industrial advisors from Travelocity and Lockheed and will focus on issues related to teaching undergraduate computer science students how to use computer-supported collaborative tools to work together to develop large software applications. Researchers will enhance a Web service infrastructure that can support collaborative software tools and use it in advanced programming courses offered at each of the four Universities. The courses will allow researchers to examine how 'distance' factors such as time, geography and culture affect globally distributed student learners. Data gathered from student interactions will then be used to create strategies that will improve collaboration among the culturally, spatially, and temporally dispersed learning teams. The result of this research will be a model and technology that will focus on the problems related to teaching global software development. These problems include teaching students how to use collaborative software, be members of a culturally diverse work team, manage time, organize ideas, and chat (communicate) with one another. <br\/><br\/>This project will examine ways to use technology to help students learn how to overcome barriers of time, space and culture. The proposed research represents an important contribution by teaching students how to work in culturally mixed dispersed teams. It will also contribute to practical knowledge about how to support distributed learning teams by determining which specific individual, spatial-temporal, and cultural factors are important and how they interact in the context of a computer supported collaborative environment. It will also test whether specific problems can be remediated through direct or indirect intervention, and whether these remediation strategies actually improve group performance. Although this study will occur in the context of a programming course, the results will have implications for geographically distributed collaborative learning teams in general. It should also have an effect on broadening the experiences of all students who participate in the study by exposing them to people from different cultures and nationalities","title":"HCC: Improving the Performance of Global Software Development Learning Teams","awardID":"0705638","effectiveDate":"2007-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["350925",334005],"PO":["564456"]},"126619":{"abstract":"Low-cost, portable lab-on-a-chip systems capable of rapid automated biochemical analysis can impact a wide variety of applications including genetic analysis (medical diagnostics, newborn screening, DNA fingerprinting), biological research (genomics, proteomics, glycomics, drug discovery), in vitro biomolecule production (e.g., heparin), and biochemical sensing (pathogen detection, air and water monitoring, chemical explosives detection). There is an emerging opportunity in developing algorithms and computational tools for the design, simulation, and performance evaluation of digital microfluidics systems (DMFS), a paradigm changing class of lab-on-a-chip systems that manipulate discrete droplets. The proposed research will develop specialized routing and scheduling algorithms for the coordination of droplets on a DMFS. The team will develop general principles for designing scalable grid layouts and coordinating droplets that work across different hardware implementations. The algorithms will enable robust and user friendly operation of digital microfluidics systems, offering end users tremendous flexibility and the ability to exercise unprecedented spatial and temporal control over reactions. This research will enable reconfigurable lab-on-a-chip systems for use in a wide variety of applications including biohazard detection, clinical diagnostics, and environmental monitoring. It can potentially lead to more effective ways of synthesizing heparin, a therapeutically important compound, and point-of-care newborn screening. The proposed research will involve graduate students in research, and will be integrated into graduate courses taught by the PIs. Outreach activities include after-school Lego robotics activities and summer robotics camps for middle school students in collaboration with RPI's Center for Initiatives in Pre-College Education.","title":"CRI: IAD: A Digital Microfluidic Testbed for Combinatorial Biosynthesis and Screening","awardID":"0709099","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["349045","429784","429784","553786","551019"],"PO":["565136"]},"128929":{"abstract":"Simulation environments are an indispensable tool in the design, prototyping,<br\/>performance evaluation, and analysis of computer systems. Simulator must be able<br\/>to faithfully reflect the behavior of the system being analyzed. To ensure the<br\/>accuracy of the simulator, it must be verified and determined to closely match<br\/>empirical data. Modern processors provide enough performance counters to<br\/>validate the majority of the performance models; nevertheless, the information<br\/>provided is not enough to validate power consumption, thermal models, and<br\/>process variability.<br\/><br\/>Temperature and power consumption are first order design parameters for modern<br\/>high performance architectures. High operational temperatures and large power<br\/>consumption present possible limits to performance and manufacturability. While<br\/>temperature and power are dominant factors on processor design, process<br\/>variability is becoming another major constraint.<br\/><br\/>In order to address some of the difficulties associated with the validation of<br\/>power, thermal models, and process variability, we propose to use an infrared<br\/>measurement setup to capture run-time power consumption and thermal<br\/>characteristics of modern chips.<br\/><br\/>A detailed thermal model can use the measured temperatures to generate a power<br\/>detailed power consumption. The same thermal measurements will be used to<br\/>measure process variability from of-the-shelf processors. In addition, the<br\/>resulting infrastructure will be use to develop a verified thermal simulation<br\/>infrastructure and process variability models.","title":"Collaborative Research: SMA: Accurate Temperature Measurement Infrastructure and Methodology for Power, Variability, and Reliability Analysis","awardID":"0719790","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["548271"],"PO":["493916"]},"131943":{"abstract":"This project will undertake exploratory research on the relationships between digital conversion guidelines for Image Digital Libraries (IDL) and end-user judgments about the quality, integrity, and value of IDL content. The locus of the research is on significant collections of digitized surrogates of photographic resources in the Library of Congress's American Memory collection, a very large, internationally significant library. The focus of investigation in this exploratory research is the judgments of \"\"visually intelligent\"\" expert-scholars in several distinct disciplines, an area that has received little or no attention in the research literature but that is becoming increasingly central to the assessment of the value added through the creation of image digital libraries.","title":"Beyond Image Retrieval: Bridging Digitization Processes and End-User Judgments in a Large-Scale Image Digital Library","awardID":"0733279","effectiveDate":"2007-08-15","expirationDate":"2009-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[350465],"PO":["433760"]},"132978":{"abstract":"Proposal 0739122<br\/>\"\"Active Structures Support Problem-driven Learning for Constraint Satisfaction\"\"<br\/>PI: Susan L. Epstein<br\/>CUNY Hunter College<br\/><br\/><br\/><br\/>ABSTRACT<br\/><br\/>Many important large-scale, real-world problems can be readily represented, solved and understood as constraint satisfaction problems (CSPs). However, different kinds of CSPs respond to different combinations of solution methods. As a result, there is a persistent bottleneck in constraint satisfaction problem solving: the need for a human expert armed with hard-to-extract domain knowledge and with expert knowledge about CSP methods to select, combine, and tune available techniques into an appropriate CSP solver for the problem at hand. Furthermore, such solvers are typically not re-used to solve similar problems or to reformulate seemingly unsolvable problem into solvable ones.<br\/><br\/>The long-range goal is to understand how to build advanced CSP tools that combine \"\"class-based learning\"\" that tailors solution methods to classes of similar problems and \"\"problem-driven learning\"\" that tailors solution methods to an individual problem. Problem-driven learning involves detection of \"\"active\"\" structures, that is, the most informative and often conflict-ridden sub-problems detected during search and constraint-satisfaction problem solving, particularly in difficult or one-of-a-kind problems, and the use of these structures to generate a class of similar problems from which methods and heuristics for the class can be learned and then applied back to the problem at hand. The specific focus of this project is the detection and harnessing of active structures in problem-driven learning.<br\/><br\/>The project involves collaboration among the PI, the Cork Constraint Computation Center in Ireland, and an expert on visual representation. Results of the project will be made available on a publicly accessible website. The resulting knowledgebase of active structures will help support other research projects on CSP.","title":"Active Structures Support Problem-driven Learning for Constraint Satisfaction","awardID":"0739122","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["528943"],"PO":["387198"]},"125828":{"abstract":"IIS - 0705491<br\/>Christel, Michael G.<br\/>Carnegie Mellon University<br\/>III-CXT: Enhancing Digital Video Libraries through the Evaluation and Transition<br\/>of Automated Techniques for Visual Processing, Indexing, and Access<br\/><br\/><br\/>The proposed work will deliver Informedia audio and video technologies (developed under the Digital Libraries Initiatives) and other non-text access methods to existing digital video libraries. Digital video is a critical and growing multimedia information source, one that is seen as an important to means for universal access to audio and video resources. The web is experiencing exponential video traffic as YouTube, Yahoo, Time Warner, Viacom, and others are presenting an opportunity for migrating advanced research digital video library capabilities into practice. This trend will likely to continue as network bandwidth increases and becomes more widely available. This project will evaluate fielded systems through human computer interaction (HCI) techniques. A primary impact of the project will be in the development and deployment of digital video library toolkits, curriculum support materials, and automated processing and access techniques. These resources will support building other digital video libraries and contribute to the education of those that create and manage these. Automated assistance for curators of audiovisual collections helps to increase the number and types of collections available, while reducing associated costs. The projects collaborators bring important collections to the project - broadcast news archives and oral history archives of African American leaders.","title":"III-CXT: Enhancing Digital Video Libraries through the Evaluation and Transition of Automated Techniques for Visual Processing, Indexing and Access","awardID":"0705491","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[333951,"371225"],"PO":["565136"]},"125729":{"abstract":"Teleoperated assistive robots in home environments have the potential to dramatically improve quality of life for older adults and\/or people who experience disabling circumstances due to chronic or acute health conditions. It could similarly aid clinicians and healthcare professionals providing treatment. The success of these applications though will critically depend on the ease with which a robot can be commanded to perform common manipulation tasks within a home environment. Thus, the focus of the proposed research is to addresses this key challenge in two significant ways. First, by learning from teleoperated manipulation (i.e. teleoperative-based instruction), robots can acquire the ability to perform elements of common tasks with greater autonomy and reliability. Second, by automatically mapping new modalities (e.g. voice and gesture commands) to the robot's user interface, a wider variety of people will be able to use the robot more easily. The resulting multimodal interfaces may be especially important for people who have difficulty using a single modality, such as vision. These two fundamental research components underlie the basis of our approach to enable manipulation of everyday objects in an unstructured human environment.","title":"Hri: Robot Learning From Teleoperative-based Instruction And Multimodal Interaction","awardID":"0705130","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7632","name":"HUMAN-ROBOT INTERACTION"}}],"PIcoPI":[333704,"444191","558854","502390","482361"],"PO":["565227"]},"132957":{"abstract":"Special Project: Building Relationships with Asia to Foster Research Exchanges and Student Training in Scientific Data Visualization and Modeling<br\/><br\/>Abstract<br\/><br\/>The purpose of this project is to build and strengthen relationships with scientists in Asia to foster research exchanges and student training in scientific data modeling, analysis and visualization. This is accomplished by visits to Asia which will allow for 1) concentrated research seminars with already established research collaborators, 2) a series of lectures to promote the topics of data modeling, analysis and visualization in search of new collaborators and student exchanges and 3) workshops to explore the organization of a jointly sponsored east\/west conference on data modeling, analysis and visualization to be held in Asia. The analyses, understanding and extraction of knowledge from extremely large and complex data sets is an opportunity with tremendous benefits for all of society. The recent past has seen a good deal of research targeted towards data visualization, but now it is time to emphasize the analysis of data. The techniques of analyzing data used in the past do not scale to the tremendously large and complex data sets of today. World wide collaborations, exchanges and student training enhance the chances for progress in this important area of scientific research.","title":"Special Project: Building Relationships with Asis to Foster Research Exchanges and Student Training in Scientific Datea Visualization and Modeling","awardID":"0739023","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[353596],"PO":["532791"]},"125829":{"abstract":"This project is a collaborative effort between the Massachusetts Institute of Technology Media Laboratory and the Groden Center to develop and evaluate wearable social-emotional technology that helps individuals with high-functioning autism or Asperger syndrome acquire an affinity for the social domain and improve their overall social abilities. The project will develop the first wearable camera system capable of perceiving and visualizing social-emotional information in real-time human interaction. Using a small wearable camera and video-pattern analysis algorithms, the system analyzes video of the wearer or interaction partner and tags it at multiple granularities (facial actions, communicative facial or head gestures, and emotions). <br\/><br\/>The wearable system aims to: (1) facilitate learning and systemizing of social-emotional cues; (2) promote self-reflection and perspective-taking; (3) allow wearers to study subtle nonverbal cues and share experiences with peers, family members, and caregivers; and (4) contribute new computational models and theories of social-emotional intelligence in machines. A clinical study will compare the efficacy of the wearable system to current gold standard interventions for autism spectrum disorders (ASD). A participatory approach to the co-design and use of technology draws on the experiences of individuals with ASD and their solutions to systematizing social interactions, thereby empowering them to enhance their relationships, while participating in the development of next-generation social-emotional intelligent technologies.<br\/><br\/>The project will make significant contributions to the difficult challenge of developing machine intelligence that is robust at handling human social interaction. When people or machines fail to perceive, understand, and act on social-emotional cues they are hindered in their ability to interact with and learn from others. The results of this interdisciplinary work can be leveraged in human-computer interaction, robotics, and technologies with social-emotional intelligence. The research will also provide investigators with a new tool to study nonverbal communication outside of laboratory settings. <br\/><br\/>This project brings together the overlapping and converging goals and challenges of autism research and affective computing, both already interdisciplinary in nature, and demonstrates how a collaboration could lead to several mutually beneficial outcomes ? from developing new tools to assist people with ASD in understanding and functioning in the social-emotional world, to developing new computational models and theories that enable technology to provide an overall better experience to those who use it. This work also promotes the training and education of students and people with ASD by involving them in cutting-edge scientific research.","title":"HCC: Collaborative Research: Social-Emotional Technologies for Autism Spectrum Disorders","awardID":"0705508","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["457548"],"PO":["565227"]},"132924":{"abstract":"0738898 Karabatis, George Univ. of Maryland Baltimore County<br\/><br\/>The team of PIs will investigate technologies that utilize context and self-modifying graphs containing semantic information (semantic networks) to decrease the time to locate historical design information highly relevant to a proposed change request. The research will explore the usefulness of this innovative approach to provide an improved search mechanism for software development artifacts. Such improved searches will be applicable in many circumstances.<br\/>This project is exploratory and proposes a set of preliminary research tasks on untested and novel ideas. The results will offer a new way to search for existing support information and historical design information that can help avoid or significantly limit project delays due to software changes. The innovative approach consists of techniques which take advantage of contextual information (e.g., user, project, application, environment, and other contexts) and of semantic networks which store relationships between software artifacts and traceability information. The results of the new search approach will provide a more contextualized, applicable, and targeted recommendation for relevant information to software engineers.<br\/>The project will employ one graduate student and one undergraduate student who will be actively engaged in the research project.","title":"Using Context and Semantic Networks to support Software Engineers","awardID":"0738898","effectiveDate":"2007-08-15","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["526040",353502,353503,353504],"PO":["564388"]},"133948":{"abstract":"The proposed workshop, 'Probabilistic Models of Cognition: The Mathematics of Mind,' will bring together leaders from cognitive science, computer science, mathematics, and statistics who are interested in developing a common mathematical framework for all aspects of cognition, and review how it explains empirical phenomena such as vision, memory, reasoning, learning, planning, and language. This program is motivated by recent advances which offer the promise of modeling human cognition mathematically. The workshop will entail presentations by leading faculty-level lecturers and an audience of graduate students, postdoctoral researchers, and more senior researchers interested in focusing their efforts on probabilistic models of cognition and their applications. Attendees will represent a number of disciplines, including cognitive science, neuroscience, computer science, mathematics, physics, statistics, engineering, and education. Researchers interested in education should be equipped with a wide range of new computational, mathematical and statistical tools that can be used to improve educational technology, curriculum design and assessment, through the development of qualitatively more powerful models of human learning. Researchers in all of these fields, as well as basic cognitive-science researchers, should benefit immensely from interacting with each other and learning about this new generation of cognitive modeling approaches in an unprecedented interdisciplinary environment, with both basic and applied research themes represented among the lectures and discussions.","title":"IPAM\/Statistics Graduate Workshop","awardID":"0743835","effectiveDate":"2007-08-15","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":["535441","549461"],"PO":["533965"]},"132749":{"abstract":"Motivation for this SGER project is to examine the ability of a robot to deliver a controlled impact force for evolving human-robot-interaction (HRI) tasks such as robotic rehabilitation and robotic medical imaging applications. Efforts in this project will focus on model development and experimental verification of impact models between a robotic system and a deformable surface. These models will be included in new control designs to enable a robot to rapidly transition from non-contact to contact with a human tissue phantom. Unlike discontinuous and infinitely rigid ?hard-on-hard? impact models developed for manufacturing applications, the continuous impact models in this project will target impact of a robot with deformable tissue. As a result new continuous controllers can be developed that include the impact dynamics in the control design. The experiments proposed in this project will be used to support the idea of imparting controlled impact forces. The scientific outcomes of the SGER and subsequent efforts will provide an inroad to new applications where humans and robots share a common working envelope where contact is beneficial.","title":"SGER: Impact Modeling and Control for Human Robot Interaction","awardID":"0738091","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["380056","561494"],"PO":["403839"]},"122508":{"abstract":"PROJECT ABSTRACT:<br\/><br\/>The proposal addresses the challenge of flexibly and efficiently managing the allocation of shared caches and shared memory bandwidth among applications\/threads for diverse sharing scenarios (co-operative, competitive and adversarial) in multicore systems. The proposed solution which spans the hardware, operating system (OS) and application layers, consists of two parts, one at the hardware-OS boundary and another at the OS-application boundary. The first part proposes a hardware-assisted, OS-driven resource allocation technique that effectively combines the flexibility of OS-based resource management with the efficiency of hardware resource management. The second part proposes adoption of currency-based market mechanisms at the application\/OS boundary wherein contenders negotiate\/bid for access to resources in exchange for some notional currency. Market mechanisms, which have been studied for other resource allocation problems, incentivize good behavior because it is in the participants' interest to make efficient use of resources and release resources that are not used. <br\/>In the specific context of shared caches and shared memory bandwidth, market mechanisms allow development of sophisticated management policies with prioritization across and within applications. With appropriate interfaces, they also enable several other optimizations at the OS and application layers such as (a) adaptive applications that modify their behavior according to resource availability, (b) co-scheduling of sharers with complementary resource needs and (c) demand-driven pricing\" of resources.<br\/><br\/>The key components of the education plan include (a) integration of parallelism and multicore concepts into the graduate and undergraduate computer architecture related courses, (b) development of a graduate-level, advanced computer architecture course to focus on architecture design patterns recurring architecture optimizations similar to the high-level, object-oriented programming design patterns\" <br\/>captured by Gamma et.al. and (c) fostering research participation at both undergraduate and graduate levels.","title":"CAREER: Cross-Layer Schemes For Flexible Resource Sharing in Multicore Systems","awardID":"0644183","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518316"],"PO":["366560"]},"129190":{"abstract":"On a multi-tasked system, the CPU cycles through a number of processes every few milliseconds. Some of the processes are memory-intensive, but most are non-intensive support processes and other user programs such as text-editors, email clients, and instant messengers. A typical system cycles through a few memory-intensive processes, each of which replaces several cache blocks from the level-2 cache from other processes. This results in a large number of demand misses for the L2, and ties up the memory subsystem preventing effective prefetching.<br\/><br\/>This project investigates a possible solution to this problem by modifying the OS to prefetch to the L2 out of context, i.e. when the CPU is executing a non memory-intensive process. (ideally, just before the memory-intensive process will be brought in for execution). Thus, when this process resumes execution, it will have low L2 cache misses which in turn will keep the memory-bus free in order to prefetch even more blocks. Out-of-context prefetching aims to shift from a predominantly demand-fetched paradigm to a predominantly prefetched paradigm.<br\/><br\/>In conjunction with accurate predictors for prefetching, this work has the potential to greatly mitigate the performance CPU-memory gap problem on a system-wide level. The expected outcome of the project is a Linux implementation of out-of-context prefetching on a full-system simulator, and a website that documents all the assumptions, the source code, and extensive project results beyond those published in the corresponding research literature. All researchers, operating system designers, and processor manufacturers will have access to the website and the research findings to freely incorporate them as they wish.","title":"CSR-PDOS: Out-of-Context Prefetching for L2 Caches","awardID":"0720741","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["543415"],"PO":["535244"]},"129091":{"abstract":"This research focuses on one of the most fundamental issues that defines the architecture of Cyber Physical Systems (CPS) - heterogeneity. Unlike the Internet where heterogeneity is normally addressed for the sake of functional interoperability, CPS systems are normally regarded as special-purpose systems of systems, designed mostly for critical infrastructures that require global regulation and performance assurance. Therefore, heterogeneity must be addressed not only for the sake of functional interoperability, but also for policy regulation and performance assurance.<br\/>To address functional interoperability, a distributed framework, called the CPS-Bus, is proposed to flexibly interconnect different CPS subsystems. To support policy regulation, a policy specification language is developed to regulate the relationship between context, operation and rules. To achieve performance assurance over heterogeneous subsystems, a novel run-time combination of reflective interfaces and a distributed control framework is invented to address evolving performance dynamics and required on-demand functional (compositional) changes. This work will allow the effective interconnection of computation and physical processes to reveal the useful correlations among different phenomena and to conduct effective control across the boundary of CPS subsystems. For developers, this work will significantly reduce the design and development costs for building CPS systems. For end users, the resultant CPS systems will lead to exciting applications such as assisted living that will fundamentally improve the quality of every-day life.","title":"Collaborative Research: CSR-CPS: Multi-Level Heterogeneity in Large-Scale Cyber-Physical Systems","awardID":"0720465","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526936"],"PO":["561889"]},"128080":{"abstract":"Electronic commerce plays an important role in the US economy. However, current electronic commerce applications such as online auction systems are not trustworthy due to a lack of effective trust management mechanisms. A trustworthy online auction system requires a dynamic trust management system that can detect abnormal bidding activities in real-time, notify the involved users, and cancel the corresponding auction immediately.<br\/><br\/>This project investigates an agent-based approach for dynamic trust management in online auctions. The approach supports real-time monitoring, analyzing, and detection of abnormal bidding behaviors in online auction systems so the trustworthiness of such systems can be ensured. Specific problems to be addressed in this project include 1) investigating efficient formal methods, such as model checking techniques, for analysis of real-time auction data; 2) defining a real-time trust model that supports trust re-evaluation; and 3) formulating intelligent agents that support reasoning with uncertainty and incomplete information. The research activities will result in a loosely coupled agent-based trust management (ATM) module in online auction systems. The project will have favorable broader impacts on trustworthy computing research, education, as well as industrial applications. The results from this project can help to develop trustworthy systems in electronic commerce, and will contribute to boost the US economy by providing a safe and trusted environment for Internet-based trading.","title":"Collaborative Research: CT-ISG: Agent-Based Trust Management for Trust Re-Evaluation in Online Auctions","awardID":"0715648","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[339521],"PO":["529429"]},"128290":{"abstract":"0716452<br\/>Jelena Mirkovic<br\/>University of Delaware<br\/><br\/>0716829<br\/>Peter Reiher<br\/>UCLA<br\/><br\/>CT-ISG: Collaborative Research: Enabling Routers to Detect and Filter Spoofed Traffic<br\/><br\/><br\/>IP spoofing exacerbates many security threats.If spoofing were eliminated or sufficiently reduced, defenses against DDoS, distributed scanning and intrusions would be much simplified and more effective. Of particular interest are spoofing defenses that will be both practical (cheap to deploy and operate) and effective (provide significant benefit in sparse deployment. This project develops two such defense mechanisms: (1) Clouseau, which enables routers on asymmetric paths to accurately infer associations between the route descriptor and the source address. It will support multiple associations (in case of multipath routing) and will promptly update associations when routes change. Clouseau will be integrated with two very effective spoofing defenses: route-based filtering and hop-count filtering, and will protect deploying networks from spoofed traffic. (2) RAD, which helps networks protect themselves from reflector attacks.<br\/><br\/>Clouseau and RAD will operate completely autonomously. <br\/>Deployment of Clouseau at as few as 50 chosen Internet autonomous systems, together with RBF or HCF, will reduce amount of spoofed traffic on the Internet to less than 3%. In isolated deployment, Clouseau with RBF or HCF will reduce spoofed traffic received by the deploying network to less than 3%. RAD system will offer a significant protection from reflector attacks in isolated deployment and an almost perfect protection when RAD is deployed in the Internet core. <br\/><br\/>This research is leading to a significant reduction of spoofed traffic in the Internet. All code will be released to the public, and graduate and undergraduate students will receive valuable training from participation in this project.","title":"Collaborative Research: CT-ISG. Enabling Routers to Detect and Filter Spoofed Traffic","awardID":"0716829","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["485932"],"PO":["529429"]},"127091":{"abstract":"Advances in networks, sensors, storage, computing, and high throughput data acquisition, have led to a proliferation of autonomous, distributed data sources in many areas of human activity. New discoveries in biological, physical, and social sciences and engineering are being driven by our ability to discover, share, integrate and analyze disparate types of data. Statistically-based machine learning algorithms offer some of the most cost-effective approaches to discovery of experimentally testable predictive models and hypotheses from data. However, the large size, distributed nature, and autonomy of the data sources (and the attendant differences in access, queries allowed, processing capabilities, structure, organization, and underlying data models and data semantics) present hurdles to effective utilization of machine learning. This research aims to overcome these hurdles by developing efficient, resource-aware distributed algorithms and software services to support collaborative, integrative knowledge acquisition such a setting. The research team will implement, deploy, and evaluate the resulting algorithms using benchmark data sets, associated data models and ontologies, and user-specified inter-ontology mappings on a distributed test-bed of networked databases and services at Iowa State University and Kansas State University. The resulting open-source software can potentially transform collaborative e-science in the same way that Web has transformed information sharing. Broader impacts of this research include enhanced opportunities for research-based training of graduate and undergraduate students, interdisciplinary collaborations, participation of under-represented groups, and development of increasingly sophisticated software to support collaborative, integrative e-science. The project web site (http:\/\/www.cild.iastate.edu\/projects\/indus.html) provides access to information about the project, benchmark data, publications, software, and documentation.","title":"Collaborative Research: Learning Classifiers From Autonomous, Semantically Heterogeneous, Distributed Data","awardID":"0711356","effectiveDate":"2007-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560586","499317"],"PO":["565223"]},"129170":{"abstract":"Modeling complex real world problems in the national and homeland security domains require multi-disciplinary thinking and utilize multiple analytical approaches to represent massive numbers of entities, their behaviors, and the emergent interactions among them. As such, the traditional approach to building comprehensive, requirements-driven simulations does not work for such problems. This project uses a Society-based Approach to Integration using a ?shared but self-managed? paradigm, wherein, autonomous members collaborate in a society while sharing only a part of their knowledge. Component simulations self-assemble into realistic synthetic environments. The self-assembly of simulations is achieved through a domain-specific ontology, simulation specifications, and semantic matching between diverse members. New members join an existing society or an existing member modify its interaction needs without requiring the society to reconfigure. Using knowledge discovery, each member determines what aspects of entities in the society to interact with. In this way, a society is automatically configured into a synthetic environment. <br\/>Broader impacts of this project include: creation and deployment of large scale synthetic environments by bridging new and existing models and simulations from diverse disciplines; leverage knowledge generated by the wider DDDAS community in creating complex synthetic environments at scales and diversity much greater than the state-of-the-art; facilitate rapid integration across diverse systems and paradigms, such as, discrete event simulations with agent based simulations, in a semantically consistent manner; and develop open source technology that will benefit the community at large with broader application to simulation based engineering, education, and decision analytics.","title":"CSR--CSI: Composing Large-Scale Synthetic Environments through Self-Assembly of Heterogeneous Simulations","awardID":"0720677","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[342230],"PO":["535244"]},"129192":{"abstract":"This project seeks to enable model-driven optimizations spanning<br\/>multiple levels of a computing system including the architecture,<br\/>compiler, algorithm and application layers, for multiple objectives<br\/>such as performance, power and productivity. A primary goal is to<br\/>develop a comprehensive framework for model-driven multilevel,<br\/>multiobjective optimizations with a focus on chip multiprocessors<br\/>(CMPs) and large-scale, sparse engineering and scientific applications.<br\/>Key activities concern developing (i) parameterized models to<br\/>compose models of the application, architecture and compiler<br\/>transformations, (ii) an optimization framework to determine<br\/>multiobjective, optimal or pareto-optimal designs while modeling<br\/>uncertainties, and (iii) undergraduate and graduate courses on the<br\/>methodology for multilevel optimizations of computing systems, <br\/><br\/>The proposed techniques yield metrics at coarse- and medium-scales<br\/>that can be used with stochastic optimization techniques to determine<br\/>optimal design choices. The medium-scale metrics are obtained by<br\/>simulating a concatenated discrete time Markov Chain model (C-DT-MCM)<br\/>which incorporates both the deterministic and stochastic aspects<br\/>of multilevel optimizations and their impacts. Such C-DT-MCMs can<br\/>be simulated very efficiently to obtain traces which can then be<br\/>compared using statistical techniques with those from detailed<br\/>hardware simulation. Using this approach, only promising design<br\/>options need be studied in detail, using current modalities, such<br\/>as detailed hardware simulators, which can be prohibitively slow<br\/>for larger CMP architectures.","title":"CSR-SMA: Toward Model-Driven Multilevel Analysis and Optimization of Multicomponent Computer Systems","awardID":"0720749","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["507752","550407","542016","554666","558870"],"PO":["565255"]},"129093":{"abstract":"Recent wildfires have highlighted the serious threat from wildfires to communities and ecosystems throughout the world. There is a need for new systems software tools to assist in effective fire management regarding where and when to deploy limited firefighting resources. This project develops an integrated data acquisition, modeling, simulation, and optimization software environment for effective wildfire management. This environment integrates real-time acquisition of weather and fire-front position data, fast simulation of fire spread to predict fire behavior, just in-time optimization to compute firefighting resource deployment, and modeling and simulation of firefighting to assess strategies of fire suppression. Integrating these components that are usually treated in isolation enables a novel comprehensive software system to effectively support real-time optimal decision-making for fire management and minimize firefighting risk and cost. Specific research objectives include developing system architecture and a software environment that integrates real time data acquisition, fire spread simulation, stochastic optimization, and firefighting simulation for dynamical data driven wildfire management, and developing runtime environment to support efficient computation and seamless communication among the different functional components in a distributed computing environment. The integrated systems software environment will provide a needed decision support tool to assist in firefighting decision making. The software environment will also serve as a valuable training and planning tool for fire management, and will provide a multidisciplinary educational tool for students and researchers at large.","title":"CSR-CSI: System Integration of Dynamical Data Driven Wildfire Spread and Firefighting Modeling, Simulation, and Optimization","awardID":"0720470","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["429450"],"PO":["535244"]},"129160":{"abstract":"Current software design for safety-critical embedded systems requires stringent compliance with coding standards to ensure safety and reliability. A key additional requirement for real-time embedded systems is predictable timing behavior of software components, which requires that bounds on the worst-case execution time (WCET) of embedded software be determined. While static timing analysis yields verifiable bounds on the WCET, it cannot keep pace with architectural innovations and hardware performance variation due to chip fabrication scaling. <br\/><br\/>This work contributes a fundamentally new approach to bounding the WCET with three major contributions: (1) Instead of simulating execution, actual execution in hardware is promoted to assess the WCET of a task. This approach not only renders tedious hardware modeling unnecessary but also confirms correct behavior regardless of architectural complexity or hardware variation. (2) The approach and its complexity are evaluated by FPGA synthesis. This assesses the feasibility of the design and validates a prototype implementation. (3) The impact of advanced architectural features is studied in a co-design space exploration, aimed to provide predictability and tight WCET bounds. The research conducted in this project advances existing science and technology through novel techniques in hardware and software design for safety-critical embedded real-time systems by providing high-confidence bounds on execution times; enhancing hardware architectures with support to assess execution times; and customizing hardware features via co-design to improve predictability. These capabilities directly benefit safety and reliability of software controlling, for example, aircraft and components of cars, thereby aiding the high-confidence design of embedded systems.","title":"CSR--EHS: Collaborative Research: Hybrid Timing Analysis via Multi-Mode Execution","awardID":"0720659","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518504"],"PO":["561889"]},"128082":{"abstract":"Electronic commerce plays an important role in the US economy. However, current electronic commerce applications such as online auction systems are not trustworthy due to a lack of effective trust management mechanisms. A trustworthy online auction system requires a dynamic trust management system that can detect abnormal bidding activities in real-time, notify the involved users, and cancel the corresponding auction immediately.<br\/><br\/>This project investigates an agent-based approach for dynamic trust management in online auctions. The approach supports real-time monitoring, analyzing, and detection of abnormal bidding behaviors in online auction systems so the trustworthiness of such systems can be ensured. Specific problems to be addressed in this project include 1) investigating efficient formal methods, such as model checking techniques, for analysis of real-time auction data; 2) defining a real-time trust model that supports trust re-evaluation; and 3) formulating intelligent agents that support reasoning with uncertainty and incomplete information. The research activities will result in a loosely coupled agent-based trust management (ATM) module in online auction systems. The project will have favorable broader impacts on trustworthy computing research, education, as well as industrial applications. The results from this project can help to develop trustworthy systems in electronic commerce, and will contribute to boost the US economy by providing a safe and trusted environment for Internet-based trading.","title":"Collaborative Research: CT-ISG: Agent-Based Trust Management for Trust Re-Evaluation in Online Auctions","awardID":"0715657","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[339525],"PO":["497499"]},"129182":{"abstract":"Concurrent opportunistic sensor environments (COPSE) aim to create a decentralized peer-to-peer platform for harnessing the computational resources within a geographic area for mobile and pervasive services. <br\/>The nodes within an area can be a mix of fixed elements like access points and highly mobile devices like mobile phones. Nodes contribute resources such as virtual machine hosting or Internet connectivity voluntarily and can revoke resources without notification. Services execute across a heterogeneous set of elements and are composed of individual virtual machine instantiations. Depending on the nodes running them, service instantiations may execute across different energy budgets, communication technologies, and storage quotas. For COPSE to succeed, it must marshal enough volunteered resources for services to run and expose information about the rapidly changing availability of resources so that services can adapt to churn. This requires meeting research challenges in two broad areas. The first area is virtual machine interfaces that expose changes in local resources and co-located nodes; these interfaces will allow services to reconfigure themselves in response to resource churn. The second area is minimizing the opportunity costs of participating in cooperative mobile systems like COPSE; pocket hypervisors must provide mechanisms and policies that protect device owners and concurrently running services from buggy or malicious instantiations.","title":"CSR---VCM: Managing a Concurrent Opportunistic Sensor Environment with Pocket Hypervisors","awardID":"0720717","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["451799","462630"],"PO":["493916"]},"129193":{"abstract":"Peta-scale systems are needed to meet the computational demands of distributed simulations. The heat produced by the components in these systems continues to grow despite extensive research in power- and thermal-aware computing. Tight coupling of tens of thousands of these components produces enough heat to increase failure rates and trigger system slowdowns. Dissipating the heat requires costly, dedicated cooling systems. Techniques are needed to reduce the heat produced by large-scale systems.<br\/><br\/>We are building an infrastructure to enable automated thermal management in advanced execution systems. Specifically, we have two research goals: <br\/>1) create a framework for distributed runtime thermal profiling; and 2) create proactive control techniques to reduce distributed application and system thermals on individual high-end components. We are integrating our research in new courses, targeting and recruiting minority students for research activities through the VT MAOP program, and conducting outreach activities to encourage student research in high-end computing.<br\/><br\/>We are creating technologies that will improve the efficiency and reliability of distributed simulations generally. All of our software tools and techniques will be open source and made available to the public in our website repository. This impacts a broad range of disciplines that perform simulation-based experimentation including computational physics, biology, and chemistry. Additionally, reducing the heat dissipation of large-scale applications will reduce operational costs for computational centers, increase system reliability, and impact the environment indirectly through energy conservation.","title":"CSR-AES: Thermal Conductors: Runtime software support for proactive heat management in advanced execution systems","awardID":"0720750","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563791","402035"],"PO":["493916"]},"129094":{"abstract":"This project pursues the vision of a community that shares resources in an open<br\/>manner. Similar to today's web publication and discovery of documents, computer<br\/>applications, machine cycles, and databases can be announced openly and used by<br\/>others worldwide.<br\/><br\/>A big issue in realizing this vision is to create facilities that help manage<br\/>the diversity of available resources and adapt them to the users' needs. Thus,<br\/>published software modules may be adapted to compose new application programs;<br\/>discovered programs may be tuned to the user's platform; distributed<br\/>applications may run at high performance, as they adapt to changing bandwidth<br\/>and latency characteristics of the target environment. This project develops<br\/>such facilities. Building on results of prior NSF support, an adaptive<br\/>engine will dynamically improve the performance of distributed computer<br\/>applications; it will adaptively compose software modules from components; and<br\/>it will support computer applications that roam across discovered machine<br\/>platforms. These components are being integrated in the iShare Internet sharing<br\/>system, which provides the environment for resource publication, discovery, and<br\/>remote use.<br\/><br\/>Components of this system are being created in related NSF projects, which synergistically complement the present project.<br\/><br\/>This work addresses a fundamental problem in computer system and software<br\/>design: optimal design decisions are often impossible because insufficient<br\/>information is available at design-time. The adaptive engine moves design<br\/>decisions to the time application software executes, when this information becomes<br\/>available.<br\/><br\/>The project is expected to yield significant performance improvements of the<br\/>involved compilers, composers, and application software, substantially facilitating the way the involved resources can be shared by the global community.","title":"CSR-AES: Adaptive Optimization for Dynamically Discovered Hardware and Software Resources","awardID":"0720471","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558595"],"PO":["535244"]},"138291":{"abstract":"The recent years have seen unprecedented deployments of high-speed transport networking technologies, particularly based on advanced, next-generation synchronous optical networks (SONET) and wavelength division multiplexing. While related carrier provisioning methods for these specific technologies have been well-studied, the emergence of more expansive applications-grid computing, storage networking, virtual private networks-is driving the need for dynamic service provisioning across multiple network domains and granularity layers. This CAREER proposal focuses on research in the area of heterogeneous, high-performance, high-bandwidth, multi-domain networks comprising hundreds of nodes and fielding dynamic connection demands, refereed to as \"Bandwidth-on-Demand\" Services. The key efforts include scalable inter-domain routing, path selection and traffic grooming, service survivability, and high-performance network infrastructure expansion. Overall, this project is expected to yield fundamental insights into the operation of large-scale, distributed, multi-domain, circuit-switched infrastructures. As such, it will help accelerating the development of robust next-generation cyber-infrastructure, thereby facilitating the emergence of a wide range of new services and applications.","title":"CAREER: Dynamic Multi-Domain\/Multi-Granularity Network Provisioning","awardID":"0806637","effectiveDate":"2007-08-13","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[367485],"PO":["564993"]},"129590":{"abstract":"Proposal Number 0722259<br\/><br\/>TITLE CPATH CB: Living In the KnowlEdge Society (LIKES)<br\/><br\/>PI Edward A. Fox <br\/><br\/>The Living In the KnowlEdge Society (LIKES) Community Building project, led by four sites (Virginia Tech, Villanova, NC A&T, and U. Texas El Paso), is transforming computing education for the 21st Century. The LIKES community, in collaboration with those from other disciplines, is identifying key computing concepts in these disciplines, then developing and implementing tools and techniques that enable learning of both computing concepts and the concepts of the disciplines. <br\/><br\/>Through a series of four workshops, related online community discussions, and our own research, the LIKES community is discovering key computing related issues in core disciplines and engaging leaders nationwide in brainstorming about their computing (education) needs. This aids faculty members, in computing-related education programs, such as Computer Science and Information Systems Departments, and in core \/ liberal education courses, engage with each other to build the global Knowledge Society. Deliverables include (1) new pedagogies in computing education; (2) integration of computing concepts into non-computing disciplines; (3) principles, guidelines, and techniques for integrating computing and non-computing curriculums; and (4) formation of new communities for enhancing that integration. This transforming of education in computing-related disciplines will yield a next generation of builders of the Knowledge Society.","title":"Collaborative Research: CPATH CB: Living In the KnowlEdge Society (LIKES)","awardID":"0722259","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["550462","550465",343439,"387907",343441],"PO":["565264"]},"129491":{"abstract":"Can ten or a hundred compromised BGP routers create Internet-wide instability? How how can we protect against it? BGP routing problems are hard to study, for the following reasons: (a) a lack of complete and accurate BGP topology, (b) difficulty in simulating with regards to computational complexity and accuracy, and (c) difficulty of deploying new tools to improve the BGP security.<br\/><br\/>The goal of this project is exactly to address the above issues, and specifically to measure, model and guard against BGP routing problems. The overarching vision is to provide the foundation for not only improving the current BGP, but also for providing new insight and guidelines for the design of novel inter-domain routing approaches.<br\/><br\/>The work focuses on three related research tasks. In the first task, the work will develop and maintain a relatively complete and accurate BGP topology as an ongoing effort and to generate small realistic topologies for simulations purposes, with provable topological properties. In the second task, the project will use and extend epidemic spreading techniques to model the network-wide propagation of BGP instability. In the third task, the project will develop a comprehensive reactive framework to detect erroneous BGP updates, which could be readily deployed today.<br\/><br\/>Broader Impact. This work is an important step towards a more robust Internet. It is widely feared that the next generation of cyber-attacks could target the control plane. However, even today, BGP routing has its share of vulnerabilities and problems which cost millions of dollars in service disruption.","title":"Collaborative Research: NETS-NBD: RIDR: Towards Robust Inter-Domain Routing: Measurements, Models, and Deployable Tools","awardID":"0721889","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["549003"],"PO":["565090"]},"128281":{"abstract":"Society is dependent on many engineered systems whose increasing<br\/>complexity and inter-connectedness have, in turn, increased their<br\/>vulnerability to adversarial attacks. In many of these systems,<br\/>protecting the execution of their computations is as crucial as<br\/>ensuring the security of their data. This research investigates how<br\/>to maintain survivable operation of such systems, even in the face of<br\/>invasive attacks where computations are intentionally subverted to<br\/>interfere with other computations' execution constraints.<br\/><br\/>The goal of this research is to develop new techniques for isolating<br\/>the effects of interactions among computations through specific<br\/>resources in these systems, including: flexible specification and<br\/>rigorous enforcement of computations' execution constraints; explicit<br\/>control of all OS kernel components under a single scheduler; detailed<br\/>on-line monitoring of computations and their supporting OS kernel<br\/>components; automated learning to discover previously unknown<br\/>interactions among computations; and formal modeling and verification<br\/>of computations, execution constraints, and system components and<br\/>resources.<br\/><br\/>The expected benefits of this project include: a novel approach to<br\/>non-bypassable isolation of computations from the effects of<br\/>adversarial attack in which isolation can be enforced flexibly<br\/>according to the system-specific execution constraints that must be<br\/>satisfied; a high quality open-source software implementation of<br\/>kernel-level scheduling and monitoring services that provide and<br\/>measure such non-bypassable isolation; new formal models, analyses,<br\/>and methodologies for verifiably correct configuration and management<br\/>of those services; and empirical studies of the services' ability to<br\/>protect computations from interference under a wide range of<br\/>adversarial attacks.","title":"CT-ISG: Collaborative Research: Non-bypassable Kernel Services for Execution Security","awardID":"0716764","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["536564","556687"],"PO":["529429"]},"127192":{"abstract":"Title: Text-to-Picture Synthesis<br\/><br\/>PIs: Xiaojin (Jerry) Zhu and Charles Dyer<br\/>Institution: University of Wisconsin-Madison<br\/><br\/>Abstract<br\/><br\/>One challenge in artificial intelligence is to enable natural <br\/>interactions between people and computers via multiple modalities. <br\/>It is often desirable to convert information between modalities. One example is the conversion between text and speech using speech synthesis and speech recognition. However, such conversion is rare between other modalities. In particular, relatively little research has considered the transformation from general text to pictorial representations. This project will develop general-purpose Text-to- Picture synthesis algorithms that automatically generate pictures from natural language sentences so that the picture conveys the main meaning of the text. Unlike prior systems that require hand-crafted narrative descriptions of a scene, algorithms will generate static or animated pictures that represent important objects, spatial relations, and actions for general text. Key components include extracting important information from text, generating corresponding images for each piece of information, composing the images into a coherent picture, and evaluation. The proposed approach uses statistical machine learning and draws ideas from automatic machine translation, text summarization, text-to-speech synthesis, computer vision, and graphics. This research will produce computational methods as well as working systems.<br\/><br\/>Text-to-picture synthesis is likely to have a number of important broad impacts. First, it has the potential for improving literacy across a range of groups including children who need additional support in learning to read, and adults who are learning a second language. Second, it may be used as an assistive communication tool for people with disabilities such as dyslexia and brain damage, and as a universal language when communication is needed simultaneously to many people who speak different languages. Third, it can be a summarization tool for rapidly browsing long text documents. This research will foster collaboration between researchers in computer <br\/>science and other disciplines, including psychology and education. <br\/>Results of the project will be disseminated through technical publications, public web pages and software, seminars and talks, and classroom education.<br\/><br\/>URL: http:\/\/www.cs.wisc.edu\/~jerryzhu\/ttp\/","title":"RI: Text-to-Picture Synthesis","awardID":"0711887","effectiveDate":"2007-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["501477","560208"],"PO":["564316"]},"129183":{"abstract":"With the demand for high memory performance from multi-core processors, memory subsystem has become a new thermal concern after processor and hard drive. Smooth and efficient memory thermal management schemes must be developed to meet the challenge. There also lack memory thermal models and simulation tools in the public domain for research and education. This project proposes memory thermal models and thermal simulators for DRAM memory subsystems as well as efficient DTM (dynamic thermal management) methods. The investigators develop a simple and accurate dynamic thermal model based on fully buffered DIMM and an accurate and fast two-level simulator estimating the thermal behavior of a memory subsystem. They also study several new, system-level DTM schemes that coordinate DRAM thermal management with processor performance throttling. Several new DTM methods are to be developed. The first method, Adaptive Core Gating, adjusts the number of active cores according to the memory thermal status.<br\/>The second method, Coordinated DVFS (dynamic voltage and frequency scaling), proactively scales down the processor frequency and voltage upon memory thermal emergency, reducing both the DRAM heat generation and the processor power consumption. Furthermore, thermal-aware OS job scheduling smoothes memory traffic and DRAM heat generation by mixing jobs with different memory demands appropriately. The thermal model is validated to execution on hardware platforms; and the proposed methods are evaluated on real systems.","title":"Collaborative Research: CSR --- SMA: Thermal Modeling, Simulation and Management of Memory Subsystems for Multi-Core Systems","awardID":"0720719","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["432712"],"PO":["551712"]},"129095":{"abstract":"Future microprocessors will consist of billions of nanoscale transistors organized as multi-core multithreaded microarchitectures. Since nano-sized transistors are sensitive to external events and manufacturing variabilities, there is a non-negligible probability of one or more faults occurring in one of billions of transistors and affecting one of many threads. High data-integrity and availability requirements make reliability as important for computers as performance, power consumption, and yield. This project studies techniques for characterizing and mathematically modeling the vulnerability of system-level components (i.e. at the microarchitecture, OS and program levels) to soft-errors.<br\/><br\/>Today's design methodologies optimize the performance and power of multi-core and\/or multithreaded architectures, but largely ignore reliability in the presence of soft errors. An important and urgent research task is to develop frameworks, models and techniques to characterize and estimate the deleterious impact of soft errors. This research addresses the above challenge by 1) developing a unified, reliability-aware simulation framework to quantify microarchitecture soft-error vulnerability of simultaneous-multithreading and multi-core systems consisting of a wide range of heterogeneous hardware and software components; and 2) creating fast and accurate analytical models to estimate and forecast soft-error vulnerabilities of hardware and software components without using lengthy and detailed simulations; <br\/><br\/>Frameworks that can quantitatively study soft error vulnerability will enable reliability-aware designs and research for emerging simultaneous-multithreading and multi-core architectures. The PIs will use the concepts, tools, techniques and other results of this research project to introduce graduate and undergraduate students to the nature of soft errors and their impact on execution environments. These teaching activities will lead to improvements in courses on computer architecture, fault-tolerant computing and nanocomputing. The tools developed in this project are accessible and usable over the Web, using equipment and middleware developed by the PIs laboratory. This makes it straightforward for other academics and engineers to use them in their own work.","title":"CSR---SMA: Characterizing, Modeling and Mitigating Soft Error Vulnerability in Multithreaded and Multi-core Execution Environments","awardID":"0720476","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["540130","550720"],"PO":["493916"]},"129591":{"abstract":".Proposal Number: 0722261<br\/><br\/>Title: CPATH CB: Revitalizing Computer Science Education through the Science of Digital Media<br\/><br\/>PI: Jennifer Burg<br\/><br\/>While computers have become indispensable in communication, social networking, creativity, business, science, academics, and research, the number of students majoring in computer science has fallen dramatically in recent years. Clearly, computer science educators are not taking advantage of the exciting and relevant nature of their discipline. This project investigates ways to make computer science curriculum more interesting and relevant to today's students by linking it to the science of digital media. The interdisciplinary nature of digital media ? with connections to the visual arts, engineering, music, scientific visualization, movies, television, and mobile media ? will be explored through workshops at seven colleges\/universities throughout the United States. Representatives from business and industry and diverse academic fields will be asked to identify the knowledge and skills they would like to see in computer scientists involved with them in interdisciplinary collaborations. Over a three-year period, a proposal for college-level computer science curriculum changes will be made that reflects input from educators, industry representatives, artists, and practitioners in areas involving digital media. The resulting curriculum is intended to have a strong scientific base linked to practice in other disciplines in ways that motivate learning and take advantage of the centrality of digital media in modern-day life.","title":"CPATH: Revitalizing Computer Science Education through the Science of Digital Media","awardID":"0722261","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["552411",343444],"PO":["565264"]},"129371":{"abstract":"Network survivability is an important requirement that must be provided by network operators. In general, survivability techniques attempt to achieve two objectives, namely increasing (a) the agility of detecting and recovering from failure and (b) resource efficiency. However, these two objectives are in most cases contradictory and are difficult to achieve simultaneously. This is mainly because agility requires the use of expensive pre-provisioned protection circuits, which cannot be used by working connections.<br\/><br\/>In this project, network coding will be used to provide protection as a means of achieving survivable network operation that satisfies the above two objectives. In particular, pre-provisioned protection circuits will be shared by multiple connections where all such connections transmit their signals simultaneously and on the shared circuits. Network coding, where signals are combined before transmission, avoids the contention and collision between the signals, while simultaneously providing backup copies of the signals such that if failures take place, the signals can be easily and instantaneously extracted from the combined signals. The purpose of this project is to establish the theory and techniques for using network coding to support survivable network operation through protection. After rigorously formulating the problem of network survivability under network coding, a theory for network protection using network coding under single link failures will be introduced. The theory will then be extended to also handle the cases of multiple link and\/or node failures. Stronger results for specific types of network connections will be developed. The theory will then be applied to develop implementation strategies for network coding-based protection for wireline and wireless networks, using different protocols at different layers.<br\/><br\/>The intellectual merit of this project is that it will provide the theoretical bases for the use of network coding to support protection in an agile, and resource efficient way, and will also introduce implementation methods for network coding-based protection. <br\/><br\/>The broader impact of this research is that it will provide an overarching approach for network coding-based survivability, which will extend and apply to several networking environments. The PIs expect that the developed techniques will be considered by network equipment manufacturers for adoption in their equipment and by the network operators for use in their networks, as this approach will provide cost efficiency, agility and flexibility. The project will also train graduate students in a new area of research, and in exploring novel applications of the new technique of network coding.","title":"NeTS-NBD: Network Coding-Based Protection","awardID":"0721453","effectiveDate":"2007-08-01","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["417502","550838"],"PO":["564993"]},"128161":{"abstract":"Proposal Number: 0716342<br\/>PI: Scott Shenker<br\/>Institution: International Computer Science Institute, University of California Berkeley<br\/>Lead<br\/><br\/>Proposal Number: 0716278<br\/>PI: Nicholas Feamster<br\/>Institution: Georgia Institute of Technology<br\/>Sub<br\/><br\/>Proposal Number: 0716287<br\/>PI: David Andersen<br\/>Institution: Carnegie Mellon University<br\/>Sub<br\/><br\/>Proposal Number 0716273<br\/>PI: Hari Balakrishnan<br\/>Institution: Massachusetts Institute of Technology<br\/>Sub<br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Towards a More Accountable Internet<br\/><br\/>Abstract<br\/><br\/><br\/><br\/>The goal of this project is to design, implement, and <br\/>test an internetwork architecture called the Accountable Internet <br\/>Protocol (AIP). AIP retains much of the elegance and simplicity of <br\/>IP, but is far better equipped to thwart malicious adversaries. To <br\/>provide this protection, AIP incorporates three kinds of <br\/>accountability: source accountability, control-plane accountability, <br\/>and dataplane accountability. Together, these three forms of <br\/>accountability ensure that any host, router, and autonomous network <br\/>can identify misbehaving components.<br\/><br\/>Operationally, this results in: an Internet in which any spoofing or <br\/>forgery of source addresses is detectable (from source <br\/>accountability); a partial defense against flooding attacks from <br\/>compromised hosts (also from source accountability); an Internet <br\/>where route hijacking and other security compromises to inter-domain <br\/>routing are impossible (from control-plane accountability); and the <br\/>ability for end hosts and operators to pinpoint locations where <br\/>packets are being lost or excessively delayed even when the problems <br\/>are in other networks (from data-plane accountability).<br\/><br\/>The cornerstone of AIP is its use of a self-certifying address <br\/>format. All AIP addresses are of the form AD:EID, where AD is the <br\/>identifier for the autonomous domain that the host belongs to, and <br\/>EID is a globally unique host identifier. Both address components are <br\/>derived from public keys held by the domain and host, respectively, <br\/>allowing other entities to verify the authenticity and provenance of <br\/>packets and messages. AIP's self-certifying addressing allows simple <br\/>protocols to realize the above benefits.","title":"Collaborative Research: CT-T: Towards an Accountable Internet Architecture","awardID":"0716278","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["561756"],"PO":["565327"]},"129492":{"abstract":"Internet measurements are crucial for enhancing and administering the Internet infrastructure as well as for grounded Internet performance research. Yet obtaining high quality representative measurements remains a daunting task, requiring expertise and professional connections that relatively few possess. The goal of this research is to explore an approach for providing diverse, representative, and easily accessible on-demand Internet measurements. Specifically, the approach in this project involves designing, prototyping, and studying a system named DipZoom (for ?Deep Internet Performance Zoom-in?), which is based on two key ideas. First, recognizing the difficulty any single provider would face in building a platform representative of the scale and diversity of the Internet, DipZoom implements a matchmaking service instead, using P2P concepts to bring together experimenters in need of measurements with external measurement providers. Thus, DipZoom leverages experimenters themselves in deploying a large number and variety of measuring points. Second, DipZoom provides a unified view over the entire network of measurement providers, which is accessible and controllable from a participant?s local machine. By removing the need to recruit and interact with individual measuring probes, DipZoom should drastically lower the barrier of entry for conducting quality Internet performance research. The intellectual merit of this project lies in the above ideas and in a number of new concepts and techniques these ideas entail, such as ranking of measurement providers, selective calibration of measuring hosts, selection of measuring hosts for a given measurement, identification of potential attacks and development of countermeasures, and so on. <br\/><br\/>The broader impact includes making high-quality network measurements accessible to a wide technical community, and enhancing undergraduate education in computer networks by allowing networking courses to incorporate complex network measurement experiments.","title":"NBD: Dipzoom: A Global Ecosystem for Internet Measurements","awardID":"0721890","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["409444"],"PO":["565090"]},"128282":{"abstract":"The Secure Virtual Architecture (SVA, formerly called LLVA for <br\/>low-level virtual architecture)<br\/>project is developing a novel framework to improve operating<br\/>system security and reliability. The two broad goals of the<br\/>project are (a) to develop a compiler-enforced virtual machine<br\/>that is safe, low-level, efficient, and capable of hosting a<br\/>standard C\/C++-based operating system and all its applications;<br\/>and (b) to investigate how this organization can improve overall<br\/>system security and provide new security capabilities. The SVA<br\/>approach will provide important capabilities not currently<br\/>available for widely-used commodity systems, including a \"\"safe execution<br\/>environment,\"\" inescapable logging of kernel activity, and a<br\/>purely software approach to keep application data secret even<br\/>from the underlying operating system. The software tools developed <br\/>under this project will be made available to the research and education <br\/>communities in operating systems and security.","title":"CT-ISG: Improving System Security with a Compiler-based Virtual Machine for Operating System Kernels","awardID":"0716768","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["563534","542046","548692"],"PO":["565327"]},"129140":{"abstract":"Software radio promises substantial benefits to real-world systems by making them more flexible, interoperable, and easily upgradeable. Interoperability and upgradeability are particularly important to first responders, who need to quickly establish communications with a diverse and predictable set of agencies in a very short amount of time.<br\/><br\/>This project is developing new computational models and architectures for software radio. While software radio systems have received considerable attention, many of the design methods in use today are ad hoc. The goal is to develop a principled approach that works from models of computation through synthesis down to architecture-related cost models. This approach treats reconfiguration, the reallocation of architectural resources on-the-fly during execution, as a first-class design concept. The new methodology provides an abstract model for software radio algorithms that is suitable for algorithm designers as well as cost models that allow sophisticated architectural optimizations and hardware\/software co-design. The project validates its models of computation and implementation models using realistic systems. <br\/><br\/>As part of this project, the team is developing curricular materials on software radio, including both lecture materials and labs that provide a complete, senior-level capstone design experience. This project also enables research and education collaborations between George Fox University students and faculty and their counterparts at the University of Maryland at College Park and the Georgia Institute of Technology.","title":"Collaborative Research: CSR-EHS: Foundations for Deisgn and Implementation of Software Radio Platforms","awardID":"0720596","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["539717"],"PO":["561889"]},"128172":{"abstract":"Project Abstract<br\/><br\/>Wireless sensor networks have received tremendous attention in the past few years and have been envisioned as the key enabling technology for the future ubiquitous computing environment. To successfully realize such a vision, mechanisms that allow a large number of (mobile) users, in addition to a small number of (fixed) sink nodes, to securely and efficiently access the wireless sensor networks are indispensable. <br\/><br\/>This project is to develop security mechanisms to secure broadcast\/multicast communications in a multi-user wireless sensor networks since broadcast\/multicast is the most important communication type when a user attempts to access a wireless sensor network, either to retrieve desired information or to request some actions taken by some sensor\/actuator nodes. More specifically, this project is focused on two major security tasks: broadcast\/multicast authentication and encryption. <br\/><br\/>The first task is on multi-user broadcast authentication, which aims to provide effective, efficient, scalable, and secure broadcast authentication mechanisms that support a large number of mobile users to broadcast to a wireless sensor network anytime from anywhere in the network. Efficient cryptographic tools will be integrated with public key operations to minimize the overall computation and communication overhead and achieve higher security strength for various application scenarios. The second task is on semantics-based dynamic multicast encryption, which aims to provide a more efficient solution to handle the group membership dynamics. The idea is based on a novel semantics-based elementary group concept and efficient multicast encryption schemes that integrate energy-efficient geographical multicast routing techniques will be devised.","title":"CT-ISG: Broadcast\/Multicast Security in Multi-User Wireless Sensor Networks","awardID":"0716306","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550273","564847"],"PO":["497499"]},"128183":{"abstract":"Proposal Number: 0716342<br\/>PI: Scott Shenker<br\/>Institution: International Computer Science Institute, University of California Berkeley<br\/>Lead<br\/><br\/>Proposal Number: 0716278<br\/>PI: Nicholas Feamster<br\/>Institution: Georgia Institute of Technology<br\/>Sub<br\/><br\/>Proposal Number: 0716287<br\/>PI: David Andersen<br\/>Institution: Carnegie Mellon University<br\/>Sub<br\/><br\/>Proposal Number 0716273<br\/>PI: Hari Balakrishnan<br\/>Institution: Massachusetts Institute of Technology<br\/>Sub<br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Towards a More Accountable Internet<br\/><br\/>Abstract<br\/><br\/><br\/><br\/>The goal of this project is to design, implement, and <br\/>test an internetwork architecture called the Accountable Internet <br\/>Protocol (AIP). AIP retains much of the elegance and simplicity of <br\/>IP, but is far better equipped to thwart malicious adversaries. To <br\/>provide this protection, AIP incorporates three kinds of <br\/>accountability: source accountability, control-plane accountability, <br\/>and dataplane accountability. Together, these three forms of <br\/>accountability ensure that any host, router, and autonomous network <br\/>can identify misbehaving components.<br\/><br\/>Operationally, this results in: an Internet in which any spoofing or <br\/>forgery of source addresses is detectable (from source <br\/>accountability); a partial defense against flooding attacks from <br\/>compromised hosts (also from source accountability); an Internet <br\/>where route hijacking and other security compromises to inter-domain <br\/>routing are impossible (from control-plane accountability); and the <br\/>ability for end hosts and operators to pinpoint locations where <br\/>packets are being lost or excessively delayed even when the problems <br\/>are in other networks (from data-plane accountability).<br\/><br\/>The cornerstone of AIP is its use of a self-certifying address <br\/>format. All AIP addresses are of the form AD:EID, where AD is the <br\/>identifier for the autonomous domain that the host belongs to, and <br\/>EID is a globally unique host identifier. Both address components are <br\/>derived from public keys held by the domain and host, respectively, <br\/>allowing other entities to verify the authenticity and provenance of <br\/>packets and messages. AIP's self-certifying addressing allows simple <br\/>protocols to realize the above benefits.","title":"Collaborative Research: CT-T: Towards a More Accountable Internet","awardID":"0716342","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560562"],"PO":["565327"]},"129173":{"abstract":"Some of the most exciting cyber technologies on the research horizon involve sophisticated digital systems that interact with the physical world. Examples include remote surgery, physical manipulation of nano-structures, autonomous (ground and air) vehicular travel, and space and terrestrial exploration. Because such applications interact directly with the physical world, it is imperative their physical safety be assured. This project is developing a comprehensive formal framework for producing controllers for cyber-physical systems, with machine checkable proofs of their physical safety. The project brings together ideas from control theory, language design, program verification, program generation, software engineering, and real-time and embedded systems to build a framework that can be applied to challenging applications. The framework promotes an efficient, rigorous engineering process for producing embedded controllers, incorporating explicit models not only of the controller itself, but also of the physical context in which it operates, the required stability conditions, the platform on which it will run, and the associated real-time constraints. The results of the project are being demonstrated and evaluated in the context of a tele-surgery application. This application is currently being developed at the Mechatronics and Haptic Interfaces Lab in the Mechanical Engineering Department at Rice University.","title":"Collaborative Research: CSR\/EHS: Building Physically Safe Embedded Systems","awardID":"0720682","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["541946"],"PO":["561889"]},"128690":{"abstract":"The objectives of this project are to explore how task, process, and interrelationship conflicts affect creative processes and what specific forms of conflict avoidance, management, and resolution strategies are conducive to promoting creative processes and organizational innovation. Computational models of specific individual, group, and organization characteristics will be used to define project configuration, which will influence the group and organizational dynamics in hypothetical Open Source Software development societies and cultures. Each such project entails a virtual organization and a community of practice, the members of which collaborate and coordinate their activities to design and develop innovative and creative software products. The simulation study is expected to generate hypotheses regarding mechanisms that open source software development societies could implement to improve organizational creativity at multiple resolutions, including human, team, and organization levels. The hypotheses will be generalized to suggest principles for design cognition and IT tool support that facilitates implementation of the selected strategies. Simulation-based design of such IT strategies will be enabled based on the developed testbed.<br\/><br\/>Broader Impact. During the period of the study, the PI will organize informal meetings at Auburn University to raise awareness on creativity research to facilitate development of an interdisciplinary group of researchers across engineering and social sciences faculty. The findings of the study will be transferred to the software modeling and design class offered by the PI at the Auburn University. This will enhance design learning and cognition via improved processes and activities (e.g., styles of collaborative problem solving) that will be hypothesized to be conducive to design creativity. A minority student, who is already working on an Open Source Software Development Process Simulation project as part of his master thesis under the supervision of the PI, will be funded as a graduate research assistant. This opportunity will increase the level of diversity in the Auburn Modeling and Simulation Group that is led by the PI.","title":"SGER: The Synergy of Conflict and Creativity in Open Source Software Development Communities","awardID":"0718648","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["381198"],"PO":["424970"]},"127480":{"abstract":"In this project, the interdisciplinary team proposes to develop a set of algorithmic tools to facilitate the study of three important biological problems: (a) Chromosome organization; (b) Dynamics of chromatin domains in the nucleus of living cells; (c) Mobility properties of functional sites (such as replication and transcription sites). The core of this project is to use computational geometry and optimization techniques to develop efficient algorithms for solving a set of challenging computational problems, such as ensemble clustering, median graph, generalized maximum common subgraphs, geometric fitting, matching, and rigid substructure extraction. This project will yield a set of efficient algorithms and optimization methods for the proposed problems. The designed algorithms and techniques will be used as automatic (or semi-automatic) tools to accurately and reliably analyze the nucleus organization and dynamics, and help understanding the coordination of genomic expression. The set of algorithms and techniques will be implemented and tested using randomly generated data and real biological data. The algorithmic tools and optimization methods from this project will be used to study the nucleus of living cells. It could potentially lead to significant biological discoveries and help us to better understand the mechanism cancers and their relationship with chromosome organization and dynamics. This project will bring research and educational opportunities to both graduate and undergraduate students. It will involve several graduate students and undergraduate students, from both Computer Science and Engineering and Biological Sciences Departments.","title":"III-CXT:Algorithmic Tools for Determining the Organization and Dynamics of the Cell Nucleus","awardID":"0713489","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["485149","485150"],"PO":["565136"]},"128250":{"abstract":"As network environments become increasingly hostile, even well protected distributed information systems, constructed with security in mind, are likely to be compromised. Hence, architecting large-scale distributed systems that function correctly and provide adequate performance even when parts of them are compromised is one of the most important challenges.<br\/> Byzantine replication is emerging as a promising direction to mitigate server compromise. Experience with Byzantine replication protocols reveals considerable shortcomings in the underlying theoretical foundation. Namely, existing fault models, metrics, and correctness criteria used to reason about and construct Byzantine replication algorithms, fail to capture properties that manifest themselves in wide-area environments. Since all existing Byzantine replication algorithms were designed to meet the standard safety and liveness criteria, they all exhibit critical vulnerabilities not covered by the standard models. <br\/>This project will develop the theoretical foundation, architectural framework, and algorithmic techniques for a scalable wide-area Byzantine replication system that provides strong performance guarantees under attack. This includes: (1) expanding the existing theoretical fault models to better encapsulate the unique characteristics and performance vulnerabilities associated with scalable wide-area Byzantine replication systems; (2) defining useful metrics for evaluating and comparing different architectures, configurations, and algorithms with a focus on their performance under sophisticated attacks; (3) developing an architectural framework for scalable Byzantine replication that can be customized to topology, performance, and resiliency requirements of specific wide-area systems; and (4) developing specific algorithms for wide-area environments that provide strong performance guarantees under attack.","title":"CT-ISG Scalable Byzantine Replication under Attack","awardID":"0716620","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[339946],"PO":["564388"]},"128184":{"abstract":"CT-ISG: Collaborative Research: Trustworthy Enforcement<br\/>of Domain-independent Run-time Policies<br\/>Abstract<br\/>Run-time monitors are a common and pervasive mechanism for ensuring that software and<br\/>systems adhere to security policies. Anti-virus and anti-spyware programs, personal firewalls,<br\/>intrusion-detection tools, Java's stack inspection, and even mechanisms that trap operatingsystem<br\/>exceptions in order to show a ?blue screen of death? can all be thought of as run-time<br\/>monitors. Although they differ greatly in their complexity and scope of policies that they can<br\/>enforce, these mechanisms all observe the behavior of a running system and detect and react<br\/>to potentially dangerous events. Despite the pervasiveness and real-world importance of runtime<br\/>monitors, their use has far outpaced theoretical work that makes it possible to rigorously<br\/>reason about monitors and the policies that they enforce, particularly in distributed settings.<br\/>This project develops models, tools, and mechanisms for reasoning about and implementing<br\/>distributed, concurrently executing run-time monitors. The research adopts a holistic,<br\/>four-prong approach that spans the breadth of the space between theoretical models and<br\/>practical systems for enforcing run-time policies. Specifically, this project (1) creates a<br\/>framework for reasoning about enforcement that permits the possibilities of concurrent, distributed<br\/>computations; (2) develops a type-safe policy-specification language that ensures<br\/>that specified policies compile into well-behaved monitoring mechanisms; (3) designs trustworthy<br\/>algorithms for automatically translating a desired overall policy into node-specific<br\/>policies that can be distributed and enforced throughout a network; and (4) designs, implements,<br\/>and tests a prototype system for specifying and enforcing run-time policies with<br\/>support for concurrently executing computations. Taken together, these research tasks enable<br\/>formal modeling and automatic enforcement of run-time security policies in concurrent<br\/>and distributed settings.","title":"CT-ISG: Collaborative Research: Trustworthy Enforcement of Domain-independent Run-time Policies","awardID":"0716343","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["432066","382087"],"PO":["497499"]},"129174":{"abstract":"SRAM memories are essential to improving run-time, energy use and real-time bounds. Many embedded processors contain Scratch Pad Memory (SPM), unenhanced SRAM that is mapped to a portion of the address space. They offer better real-time guarantees than caches, an alternate SRAM memory type. Compiler methods to allocate objects automatically to SPM have existed for a decade, but a recent survey did not find even a single commercial compiler that does automatic SPM allocation. Instead, programmers manually specify the SPM allocation using annotations. Reasons may include developer unawareness of SPM, unwillingness to include another feature in the toolchain, and the expense of repeated implementation in each compiler. <br\/><br\/>This research is developing a SPM allocation strategy that is completely implemented inside a binary rewriter. This binary rewriter is called automatically by the operating system the first time the program is loaded to memory. Subsequent executions derive the benefits of SPM with no additional overhead. This approach makes SPM a run-time-provided resource for the first time, much like cache and virtual memory are, making it ubiquitous and transparent to the software toolchain. The broader impacts of the research are (i) embedded systems that achieve high speed and real-time behavior at lower cost; (ii) portable devices with lower energy use, hence longer battery life; (iii) programs that are portable to any SPM size ? an important practical advantage; (iv) an educational and outreach program including graduate student training, undergraduate and graduate courses, internships, and a workshop on memory management.","title":"CSR-EHS: Memory management as a run-time service","awardID":"0720683","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["540124"],"PO":["561889"]},"128085":{"abstract":"The increasing adoption of the Trusted Platform Module (TPM) as a standard component in commodity PCs, mobile devices, and servers, offers exciting new possibilities in secure scalable and distributed computing. This project aims to drive the evolution of future TPMs by investigating new applications of TPMs, and by proposing new features that can be added to future versions of the TPM to enable an even wider variety of useful applications. <br\/><br\/> This project begins by exploring what new applications are possible with the current generation of TPM (TPM 1.2) -- without requiring that the Central Processing Unit (CPU), Operating System (OS), or other components of the hardware be trusted. Shrinking the required trusted computing base to only the TPM itself improves security, and allows more users to immediately and more easily benefit from TPMs. A particular idea being studied is that of implementing \"\"virtual monotonic counters\"\", and in turn using these to enable many applications, including secure virtual storage on untrusted servers, and one-time-use digital certificates for authentication, access, or delegation applications.<br\/><br\/> Going beyond existing TPMs, this project proposes built-in TPM support for \"\"count-limited objects\"\", which can have many forms and applications, such as count-limited keys for personal digital sharing and permissions management, and count-limited tokens for offline personal electronic commerce and trade.<br\/><br\/> Finally, this project proposes and details the evolution of the TPM into a Trusted Execution Module (TEM). Unlike a TPM which can only accept a small set of instructions (mainly for cryptographic operations), a TEM can accept and count-limit encrypted packets of arbitrary instructions. A TEM enables many new applications, including generalized count-limited cryptography, and secure mobile agents with offline clients.","title":"CT-ISG: Applications and Evolution of Trusted Platform Module Technology","awardID":"0715680","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["561979",339532,339533],"PO":["497499"]},"129196":{"abstract":"This project addresses issues in grids and metacomputing systems arising <br\/>from (1) heterogeneity in resource types, (2) difficulties in preparing <br\/>and staging applications, and (3) intrinsically high levels of dynamicity <br\/>common in grids. Strategies to reconcile different resource classes, and <br\/>to dynamically prepare resources that become available during application <br\/>execution are the focus of this research. The approach adopted is based on <br\/>is based on client-centric overlay software that provides unified access <br\/>to diverse resources, complemented by runtime systems that substantially <br\/>automate setup and configuration. The overlay unifies heterogeneous resources <br\/>through service drivers or mediators that operate analogously to device <br\/>drivers. New resources and variations in availability are handled through <br\/>self-deployment of mediators and their service daemon counterparts, enabling <br\/>the overlay to adaptively present applications with coherent aggregated <br\/>projections of the underlying resources. This framework, termed Unibus, is <br\/>being designed to accommodate multiple resource classes, ranging in access <br\/>type from virtualization systems to interactive shells, job schedulers, and <br\/>metaschedulers. Unification abstractions are based on identifying commonalities within resource classes and presenting uniform interfaces to them. Dynamic environment conditioning builds upon open standards in autonomic software deployment, with specifications of application structure and dependencies driving platform preparation with assistance from mediators and service daemons. This approach adopted by the Unibus system is expected to substantially enhance the prevalence of resource sharing across multiple resource classes and multiple administrative domains. By alleviating tedious setup requirements and reconciling resource diversity, will contribute significantly to realizing the true vision of grids and metacomputing.","title":"CSR - AES Integrative Approaches to Next-Generation Heterogeneous Computing","awardID":"0720761","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["489599"],"PO":["535244"]},"126260":{"abstract":"Proposal Title: Collaborative Research: CRI: CRD: An Open Source Extensible<br\/>Virtual Machine Monitor<br\/>Institution: Northwestern University<br\/>Abstract Date: 04\/23\/2007<br\/>Proposal #: CNS 07-09168 07-07365<br\/>PI(s): Dinda, Peter A. Maccabe, Arthur B.<br\/>Bustamante, Fabian E.; Joseph, Russel E.<br\/>Institution: Northwestern University University of New Mexico<br\/>Evanston, IL 60208-1110 Albuquerque, NM 87131<br\/>Title: Colla Rsch:CRD: Community Resource Development: An Open Source<br\/>Project Proposed:<br\/>This collaborative project, developing an extensible open source Virtual Machine<br\/>Monitor (VMM) for modern architectures (those that support the Intel VT or AMD<br\/>Pacifica virtualization extensions), aims to maintain a small codebase size while<br\/>supporting extensive extensibility. The approach combines compile-time composition of<br\/>major modules to configure the VMM with run-time extensibility akin to a microkernel.<br\/>The project is expected to produce a fundamental tool for research in systems and<br\/>architecture, an open source extensible virtual machine monitor. Expecting to meet the<br\/>needs within the high-end computing community identified by the FAST-OS effort, the<br\/>VMM will be used as a shared community resource.<br\/>Broader Impacts: The infrastructure will be useful in research and education and<br\/>production context. It will be free and available to all in source code form.<br\/>Underrepresented groups are impacted through Northwestern's AGEP program and<br\/>through U NM, a minority serving university.","title":"Collaborative Research: CRI: CRD: An Open Source Extensible Virtual Machine Monitor","awardID":"0707365","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":["334998",334998,334999],"PO":["557609"]},"136061":{"abstract":"To resolve the apparent scarcity of available prime radio spectrum (300 MHz - 3 GHz), the dynamic spectrum access paradigm was proposed to improve spectrum utilization. By enabling temporary, unlicensed wireless access to the unoccupied licensed spectrum, called \"spectrum holes\", a larger number of wireless transmissions can be supported by the same spectrum while simultaneously respecting the rights of the incumbent license holders. However, this paradigm heavily depends on the location and size of these spectrum holes, which can vary randomly with respect to time, frequency, and geography. The objective of this project is: (i) to accurately characterize the availability of prime spectrum in mid-size US cities, i.e. the average and most common case, for secondary access via theoretical and experimental techniques, (ii) to quantitatively determine the long-term behavior and trends of spectrum occupancy and spectrum hole availability, and (iii) to understand and obtain insight into the electrospace characteristics (time, frequency, spatial) over a large urban area.<br\/><br\/>The quantitative assessment and characterization of available prime spectrum is important for providing access to new and growing wireless services. Understanding how this essential resource is utilized will greatly assist spectrum regulators and users to plan future deployments and the overall growth of the wireless industry. Since modern society depends on communication networks in order to function properly, conducting research into spectrum availability is important. Knowledge of how much spectrum is actually available and where those opportunities are located in frequency is of vital importance to the wireless industry, which has experienced rapid growth over the past several years and continues to accelerate.","title":"NeTS-WN: Quantification of Spectrum Availability for Wireless Network Access","awardID":"0754315","effectiveDate":"2007-08-29","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["515456"],"PO":["557315"]},"127492":{"abstract":"Severe physical and cognitive disabilities make it difficult or impossible to perform activities of daily living (ADL). The primary objective of the proposed interdisciplinary research and development effort is to assist persons with physical disabilities to perform ADLs using a smart 9-degree-of-freedom modular wheelchair-mounted robotic arm system. The user interface will employ a haptic device with force reflection. Advanced control algorithms for combining the mobility of the wheelchair with the manipulation of the robotic arm will be developed; and sensor-based velocity scaling and assist functions will be used to enhance manipulation range and accuracy for the severely disabled. This will be done by addressing a set of fundamental human-robot coordination and control issues: (1) design of system architecture for sensor assisted scaled teleoperation and (2) combined mobility and manipulation in a task-optimized control scheme. This work will provide a broader impact to both the engineering community and the health sciences community by innovative research in rehabilitation robotics and its integration with education at the undergraduate and graduate levels. Besides assisting people with disabilities to do activities of daily living, the proposed project would strengthen their job prospects by providing better solutions to improve work place performance.","title":"HRI: Maximizing Manipulation Capabilities of Persons with Disabilities Using a Smart Wheelchair-Mounted Robotic System","awardID":"0713560","effectiveDate":"2007-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7632","name":"HUMAN-ROBOT INTERACTION"}}],"PIcoPI":["522399"],"PO":["565227"]},"128020":{"abstract":"This project is developing the notion of Virtual Node Layers (VNLayers) as a foundation for implementing embedded applications in dynamic networks, such as mobile wireless networks. VN Layers are programming abstraction layers consisting of abstract machines called Virtual Nodes (VNs), plus Client Nodes, which are counterparts of physical computing nodes, plus a local communication service connecting Virtual and Client Nodes. VN Layers vary in their assumptions about timing and failures. A VN Layer may be emulated over a physical network, using replicated-state-machine, leader-based, or quorum-based strategies. Such a layer can provide a simple, well-behaved platform for programming dynamic network applications, a task which is currently difficult.<br\/><br\/>Virtual Node Layers appear to be especially well suited for implementing control and coordination applications, including mobile robot coordination, intelligent highway management, and air-traffic management applications. Here, VNs can collect real-world information, exchange information with other VNs, plan activities for real-world entities, and disseminate the plans. For example, a system of VNs programmed as traffic lights can be used to manage the activity of cars in a highway system.","title":"CSR-EHS: Virtual Node Abstraction Layers for Designing Embedded Systems","awardID":"0715397","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["517826"],"PO":["561889"]},"129120":{"abstract":"Sensor networks are considered one of the \"10 Emerging Technologies That Will Change the World\". Teaching sensor network concepts is challenging because the field draws upon a disparate set of computing disciplines. For sensor network programming education, some \"tutorials\" exist, but their target audience is largely graduate students and professional researchers.<br\/><br\/>The PIs' experience shows that the presentation of these tutorials is difficult for undergraduate students as they do not have the prerequisite knowledge necessary. In the past, no lab exercises were available that are appropriate for activity-based teaching of this new and exciting field to undergraduates.<br\/><br\/>To fill this void, this CSR-CSI project is developing exemplary laboratory exercises at two institutions: Lewis & Clark College, a small private liberal arts institution, and Portland State University, a Ph.D.-granting research university. With input from students, industrial advisors, and an educational consultant, the PIs are developing exemplary lab exercises, identifying topics that are appropriate, clarifying prerequisite knowledge and preparatory material, and presenting the material in a format that is suitable for undergraduates.<br\/><br\/>The intellectual merits of this work are in clarifying the prerequisite knowledge to employing and programming sensor networks, and building a foundation for teaching these topics to undergraduates. This project also enriches the scientific and engineering research capability of the US, and provide undergraduates with activity-based learning. The effectiveness of the materials is tested on undergraduates at institutions serving a large population of minorities and women.","title":"Collaborative Project: CSR-CSI Making Sensor Networks Accessible to Undergraduates Through Activity-Based Laboratory Materials","awardID":"0720545","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["357733"],"PO":["493916"]},"128163":{"abstract":"Proposal Number: 0716342<br\/>PI: Scott Shenker<br\/>Institution: International Computer Science Institute, University of California Berkeley<br\/>Lead<br\/><br\/>Proposal Number: 0716278<br\/>PI: Nicholas Feamster<br\/>Institution: Georgia Institute of Technology<br\/>Sub<br\/><br\/>Proposal Number: 0716287<br\/>PI: David Andersen<br\/>Institution: Carnegie Mellon University<br\/>Sub<br\/><br\/>Proposal Number 0716273<br\/>PI: Hari Balakrishnan<br\/>Institution: Massachusetts Institute of Technology<br\/>Sub<br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Towards a More Accountable Internet<br\/><br\/>Abstract<br\/><br\/><br\/><br\/>The goal of this project is to design, implement, and <br\/>test an internetwork architecture called the Accountable Internet <br\/>Protocol (AIP). AIP retains much of the elegance and simplicity of <br\/>IP, but is far better equipped to thwart malicious adversaries. To <br\/>provide this protection, AIP incorporates three kinds of <br\/>accountability: source accountability, control-plane accountability, <br\/>and dataplane accountability. Together, these three forms of <br\/>accountability ensure that any host, router, and autonomous network <br\/>can identify misbehaving components.<br\/><br\/>Operationally, this results in: an Internet in which any spoofing or <br\/>forgery of source addresses is detectable (from source <br\/>accountability); a partial defense against flooding attacks from <br\/>compromised hosts (also from source accountability); an Internet <br\/>where route hijacking and other security compromises to inter-domain <br\/>routing are impossible (from control-plane accountability); and the <br\/>ability for end hosts and operators to pinpoint locations where <br\/>packets are being lost or excessively delayed even when the problems <br\/>are in other networks (from data-plane accountability).<br\/><br\/>The cornerstone of AIP is its use of a self-certifying address <br\/>format. All AIP addresses are of the form AD:EID, where AD is the <br\/>identifier for the autonomous domain that the host belongs to, and <br\/>EID is a globally unique host identifier. Both address components are <br\/>derived from public keys held by the domain and host, respectively, <br\/>allowing other entities to verify the authenticity and provenance of <br\/>packets and messages. AIP's self-certifying addressing allows simple <br\/>protocols to realize the above benefits.","title":"Collaborative Research: CT-T: Toward a More Accountable Internet","awardID":"0716287","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548263"],"PO":["529429"]},"129142":{"abstract":"With the demand for high memory performance from multi-core processors, memory subsystem has become a new thermal concern after processor and hard drive. Smooth and efficient memory thermal management schemes must be developed to meet the challenge. There also lack memory thermal models and simulation tools in the public domain for research and education. This project proposes memory thermal models and thermal simulators for DRAM memory subsystems as well as efficient DTM (dynamic thermal management) methods. The investigators develop a simple and accurate dynamic thermal model based on fully buffered DIMM and an accurate and fast two-level simulator estimating the thermal behavior of a memory subsystem. They also study several new, system-level DTM schemes that coordinate DRAM thermal management with processor performance throttling. Several new DTM methods are to be developed. The first method, Adaptive Core Gating, adjusts the number of active cores according to the memory thermal status.<br\/>The second method, Coordinated DVFS (dynamic voltage and frequency scaling), proactively scales down the processor frequency and voltage upon memory thermal emergency, reducing both the DRAM heat generation and the processor power consumption. Furthermore, thermal-aware OS job scheduling smoothes memory traffic and DRAM heat generation by mixing jobs with different memory demands appropriately. The thermal model is validated to execution on hardware platforms; and the proposed methods are evaluated on real systems.","title":"Collaborative Research: CSR --- SMA: Thermal Modeling, Simulation and Management of Memory Subsystems for Multi-Core Systems","awardID":"0720609","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["486357"],"PO":["551712"]},"129153":{"abstract":"With the proliferation of the battery-powered portable\/embedded devices, effective energy management became extremely important and the research community has recently developed various energy management techniques. However, there is an urgent need to incorporate reliability requirements to these frameworks, in view of the ever-increasing transient fault rates linked to scaled technology sizes and reduced design margins. This is particularly important for safety-critical real-time embedded systems. Recent reports indicating that the problem is exacerbated by the widely-popular energy management technique, dynamic voltage and frequency scaling (DVFS), which has an alarmingly negative effect on system reliability because of increased transient fault rates associated with operation at low supply voltages.<br\/><br\/>This project undertakes a comprehensive study of the interplay between energy management and transient fault recovery in real-time embedded systems. First, a generalized transient fault model for DVFS-enabled systems is being developed that considers the effects of radiation, temperature and electromagnetic interference. Second, focusing on operating-system-level algorithms and tools, the project is developing an integrated, reliability-aware power management framework for different types of embedded and real-time systems. The framework enables a trade-off analysis for energy savings and aggregate reliability to be carried out. Adaptive schemes that dynamically improve the system performance by monitoring system's execution at run-time are also investigated. The project is expected to have a substantial technological impact as energy-efficiency and reliability are known to be fundamental requirements for next generation real-time and embedded systems.","title":"Collaborative Research: CSR-EHS: Towards an Integrated Framework for Low Power Reliable Real-Time Embedded Systems","awardID":"0720647","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485622"],"PO":["561889"]},"129164":{"abstract":"3D tele-immersive collaborative environments are becoming a reality. The emerging tele-immersive (TI) technology empowers and enables collaborative interactions and a plethora of new applications among geographically distributed sites. TI technology allows creation of a cyber TI room, where geographically separated users can jointly perform physical activities such as dance or exercise. This project is working to take this vision further and allow users to participate in simultaneous TI sessions and to cyber-walk between TI rooms. To achieve the TI rooms vision, the underlying cyber-physical infrastructure must consider both (a) streams of 3D data as a first class object in its design and in its deployment, and (b) holistic end-to-end management of the multi-stream environments for each TI room. Hence, the project is developing a Holistic Multi-stream Environment for Distributed Immersive Applications (H-MEDIA). They will investigate (a) system architectures with correlated multi-streaming; (b) real-time virtualization of resources for resource isolation between individual TI rooms and switching (cyber-walk) between rooms; (c) end-to-end configurable, robust and fault-tolerant virtual networks for different rooms; and (d) adaptive configuration and system management that will yield customizable, stable, adaptable, available and robust individual TI rooms. H-MEDIA research will have impact on communities in computer science and also on medical, social science and other domains. The H-MEDIA project will also result in educational benefits such as involving graduate students research in very novel TI technologies, inclusion of undergraduate students, and impact on education in other disciplines such as new teaching of choreography in TI environments, as well as many others.","title":"CSR-EHS: Collaborative Research: H-Media: The Holistic-Multistream Environment for Distributed Immersive Applicatons","awardID":"0720665","effectiveDate":"2007-08-01","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518557"],"PO":["561889"]},"129175":{"abstract":"This project reexamines systems problems in interactive client\/server computing through the concept of having systems software optimize directly for the expressed satisfaction of the individual user. Satisfaction with a particular configuration or choice of parameters at the system software level varies dramatically from user to user. The project tests the hypothesis that a thin, nonintrusive user interface, in some cases combined with learning algorithms, can convey the individual user's satisfaction level, or other guidance, directly to the systems software with sufficient detail to allow the systems software to effectively customize its decisions to that individual user. To gather evidence about the hypothesis, the project is applying the concept to several systems problems that arise in contexts such as thin clients, desktop replacement systems, and modern web applications. These include: dynamic voltage and frequency scaling algorithms in power management; speculation in remote display systems; thread, process, and VM scheduling; and thread assignment\/migration in multicore processors. The work in these areas is unified through: (1) the design, implementation, and evaluation (through user studies) of effective user interfaces to systems software, (2) seeking to determine an appropriate mix of explicit and implicit user feedback, and (3) determining the role of learning to minimize the amount of explicit feedback. If the hypothesis holds, it will illustrate a new way to build systems that are more satisfying for individual users.","title":"CSR-PDOS: Optimizing the Client\/Server Environment Subject to User Satisfaction","awardID":"0720691","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["540138","409687","550572"],"PO":["565255"]},"129186":{"abstract":"Wireless sensor networks (WSNs) are transforming many areas of modern science, from ecology, to civil engineering, and public health. At the same time, experiments with WSN testbeds have exposed a number of shortcomings of the current technologies that hamper the wider adoption of this technology by domain scientists. In particular, inexpensive sensor transducers used as sensors often fail intermittently in complex and unexpected ways. Moreover, given the small number of sensors, their hardware limitations, and the complexity of tracking unexpected phenomena, sensor networks may fail to accurately record punctuated events (e.g. flash floods and hailstorms). <br\/><br\/>In this project we compare the effectiveness and efficiency of different statistical methods used to detect whether sensors are misbehaving. We investigate both off-line and on-line techniques that can be implemented on resource-limited sensor nodes to detect faults in real time. We also investigate the use of similar techniques for learning the inherent characteristics of the physical phenomena that the network is monitoring. This knowledge can be used to dynamically detect and report the onset of punctuated events and modify the behavior of the network accordingly. We will evaluate the performance of these algorithms using archived data and implement them on the nodes of a wireless sensor network used for soil monitoring. The outcome of this project will be a set of algorithms that can be broadly used to build responsive and efficient wireless sensor networks for sensor-based science.","title":"CSR---CSI: Adaptive end-to-end software infrastructure for sensor-based science","awardID":"0720730","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["538211","530044","530045"],"PO":["493916"]},"129087":{"abstract":"The recent resurgence of research in server virtualization <br\/>has created a lot of interest among providers of large-scale<br\/>data centers in employing this technology to design improved <br\/>solutions for managed hosting. Virtualization holds the promise of increased<br\/>degrees of resource consolidation with accompanying reduction in<br\/>operational costs of administration, repair, and electricity. <br\/>Designing efficient virtualized data centers <br\/>is therefore a desirable and worthy endeavor in multiple ways. <br\/>The transition from traditional hosting models <br\/>to a virtualized model is, however, not a trivial one. Realizing<br\/>the consolidation-related benefits that virtualization has to<br\/>offer requires a re-consideration of: (i) schedulers within the VMM,<br\/>(ii) mechanisms for resource usage monitoring and accounting, and <br\/>(iii) system-wide dynamic resource provisioning mechanisms. <br\/>This proposal identifies the key challenges that arise on<br\/>all these fronts in a virtualized data center, and <br\/>develops a comprehensive solution, called River, to address them. <br\/><br\/>River will make the following specific contributions: (i) improved<br\/>resource management algorithms <br\/>within the virtual machine monitor (VMM) that use both <br\/>horizontal (between the schedulers in the VMM) and vertical <br\/>(between VMM and hosted OS schedulers) co-operation, <br\/>(ii) efficient and stable dynamic resource provisioning, and <br\/>(iii) systems primitives that would provide new opportunities<br\/>to the provisioning algorithms for improved cost-cutting via <br\/>reduction of virtualization overheads. A prototype River data center based<br\/>on Xen will be developed and resulting code <br\/>made available to the community. Finally, we will<br\/>re-design the labs associated with the systems courses at Penn State to <br\/>employ virtualized hosting of class projects.","title":"CSR: PDOS: RIVER: Resource Management Infrastructure for Consolidated Hosting in Virtualized Data Centers","awardID":"0720456","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["541886","542015"],"PO":["565255"]},"127482":{"abstract":"Proposal 0713499<br\/>\"RI: Extending the Reach of SAT Technology - Quantification, Counting, and Sampling\"<br\/>PI: Bart Selman<br\/>Cornell Univsersity<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Many real-world computational problems require a search through an exponentially large space of potential solutions. Examples of such problems can be found in a diverse range of areas, for example, in hardware and software design and verification, planning and scheduling, and artificial intelligence (AI). Many such problems can be translated into a common representation, called the Boolean Satisfiability (SAT) formulation. This formulation consists of a set of Boolean (True\/False) variables and logical constraints among these variables. The challenge is to find an assignment to the variables such that all constraints are satisfied. In recent years, we have seen tremendous progress in the development of SAT solvers, which search for satisfying assignments. Current SAT solvers handle problem instances with over one million variables and several millions of constraints. An intriguing research question is whether the advances in SAT technology can be exploited for other key reasoning tasks central to AI. <br\/><br\/>This project considers three such tasks: (1) quantified Boolean reasoning, key in multi-agent reasoning and reasoning in adversarial settings, (2) counting of the number of satisfying assignments, which has many applications in probabilistic inference, and (3) sampling from the set of satisfying assignments, which is closely related to model counting. The broader impact of the proposal will be the design and development of efficient solvers for quantified Boolean formulas (QBF) and algorithms for model counting and sampling applicable to a wide range of users working in areas as diverse as verification, planning, adversarial reasoning, and probabilistic reasoning.","title":"RI: Extending the Reach of SAT Technology - Quantification, Counting, and Sampling","awardID":"0713499","effectiveDate":"2007-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560669","560670"],"PO":["491702"]},"127372":{"abstract":"This project develops algorithms and methods which allow agents to identify and analyze teamwork by the observation of other embodied agents. The goal is to learn from these observations (a) which agents are acting as a team? (b) what collaborative action are they currently executing? and (c) what is the structure of the team, what roles do each of the team members play? The project first creates a corpus of annotated scenarios for training, testing and validation of teamwork learning algorithms. The project then develops a set of algorithms which can detect teamwork between a set of embodied agents by modeling their movement based on reverse force fields. The project also develops algorithms for the robust recognition of known patterns of teamwork using Hidden Markov Models. Finally methods to detect teamwork using the semantic correlation between observations described through semi-formal action descriptions are developed.<br\/><br\/>The research described in this proposal has immediate practical applications. Recognizing teamwork can help robotic teammates integrate in human teams, with immediate applicability in fields such as disaster response. The analysis of the behavior of the team, as well as successful other teams can be an important feedback in training. In homeland security and surveillance applications, recognizing team action in a crowd can help identify terrorist threats.","title":"HCC: Learning teamwork from observation","awardID":"0712869","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[337812],"PO":["565227"]},"128241":{"abstract":"Policy-based access control is one of the most fundamental and widely used mechanisms for achieving privacy and security at both application and network levels. Given the high importance and delicacy of security policies, ensuring the correctness of these policies is important, and yet difficult. A tiny error in security policies could lead to irreparable, if not tragic, consequences. Therefore, identifying discrepancies between policy specifications and their intended function is a crucial task. To achieve this goal, this project pursues a new approach to testing and verification of security policies, including application-level security policies (such as XACML policies) and network-level security policies (such as firewall policies). To accomplish this, this project is defining two unified representations for security policies: program code representation and decision tree representation. Second, the project is developing a suite of rigorous and systematic security policy testing techniques. Third, this project is pursuing efficient and scalable verification and change-impact analysis techniques for security policies. Fourth, this project explores methods for testing and verifying stateful security policies. The project is developing frameworks and techniques for testing and verifying both application-level and network-level security policies. The project will also produce concepts and theories that fundamentally advance the knowledge and understanding of security policies. The concepts, theories, algorithms, and tools produced by this NSF-supported research are expected to promote rigorous security policy testing and verification practice, which will lead to better policy quality and higher security assurance in general. Furthermore, the results of this research will enable further innovations in related fields that depend on the correctness of security policy.","title":"CT-ISG: Collaborative Research: A New Approach to Testing and Verification of Security Policies","awardID":"0716579","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"H208","name":"NATIONAL INSTITUTE OF STANDARD"}}],"PIcoPI":["562727"],"PO":["561889"]},"129110":{"abstract":"Software radio promises substantial benefits to real-world systems by making them more flexible, interoperable, and easily upgradeable. Interoperability and upgradeability are particularly important to first responders, who need to quickly establish communications with a diverse and predictable set of agencies in a very short amount of time.<br\/><br\/>This project is developing new computational models and architectures for software radio. While software radio systems have received considerable attention, many of the design methods in use today are ad hoc. The goal is to develop a principled approach that works from models of computation through synthesis down to architecture-related cost models. This approach treats reconfiguration, the reallocation of architectural resources on-the-fly during execution, as a first-class design concept. The new methodology provides an abstract model for software radio algorithms that is suitable for algorithm designers as well as cost models that allow sophisticated architectural optimizations and hardware\/software co-design. The project validates its models of computation and implementation models using realistic systems. <br\/><br\/>As part of this project, the team is developing curricular materials on software radio, including both lecture materials and labs that provide a complete, senior-level capstone design experience. This project also enables research and education collaborations between George Fox University students and faculty and their counterparts at the University of Maryland at College Park and the Georgia Institute of Technology.","title":"Collaborative Research: CSR---EHS: Foundations for Design and Implementation of Software Radio Platforms","awardID":"0720526","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[342072],"PO":["561889"]},"128263":{"abstract":"As our society increasingly relies upon networked computers for people's day-to-day life, cyber security has become a major concern. In order to have a meaningful security management strategy, one has to balance the risk of opening an access and the benefit of having the access. This is extremely difficult for a large system. All sizable organizations depend upon networked computers to provide essential services. One service may depend upon another, which may not be on the same computer. A seemingly legitimate configuration setting at one machine could cause unexpected security exposure at another. A seemingly moderate security control at one service could be too draconian for another service to operate smoothly. In determining a \"\"good\"\" configuration setting for an enterprise system, one has to consider all possible interactions among the system's components to ensure that accesses are opened in a way that usability and risk are well balanced. <br\/><br\/>This research will develop a logic-based methodology to automate enterprise security management. The formal model-based approach makes sure that security knowledge can be shared in a machine-readable format, and consumed by automated tools to assist in reaching configuration settings that both satisfy legitimate business needs and protect the information systems adequately. The successful result from the research will enable management workforce to leverage an open management knowledge base, and be liberated from the mundane management jobs by tools that can automatically apply the generic knowledge to specific situations in an organization to reach a secure and usable configuration setting.","title":"CT-ISG: Model-based, Automatic Network Security Management","awardID":"0716665","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548367"],"PO":["529429"]},"129363":{"abstract":"Wireless sensor networks are ideal candidates for a wide range of<br\/>applications, such as monitoring of critical infrastructures, data<br\/>acquisition in hazardous environments, and military operations. It is<br\/>usually necessary to reprogram sensor nodes after they are deployed<br\/>through wireless links. This project is aimed at investigating secure,<br\/>robust, and DoS-resilient remote programming of sensor nodes through<br\/>wireless links. First, this project develops a novel reliability<br\/>mechanism that integrates proactive transmission and NACK mechanisms<br\/>to tolerate packet losses during code dissemination efficiently.<br\/>Second, this research integrates efficient authentication mechanisms<br\/>into this approach to guarantee the integrity of disseminated code<br\/>images. Third, this project develops weak authentication mechanisms<br\/>to mitigate the potential DoS attacks aimed at consuming the resources<br\/>(particularly the battery power) of sensor nodes. Fourth, this project<br\/>extends the above techniques to provide secure, proactively robust,<br\/>and DoS-resilient code dissemination in hybrid sensor networks, where<br\/>there are both high-end nodes (e.g., PDAs, Intel mote 2) connected<br\/>through high-capacity wireless links (e.g., 802.11) and low-end nodes<br\/>(e.g., MicaZ motes) connected via low-power wireless links (e.g.,<br\/>802.15.4). To achieve a thorough understanding of these techniques,<br\/>this project implements all the proposed techniques and evaluates them<br\/>in a hybrid wireless sensor network test-bed named WiSeNeT at North<br\/>Carolina State University.","title":"NeTS-NOSS: Secure, Robust and DoS-Resilient Code Dissemination in Wireless Sensor Networks","awardID":"0721424","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["553866"],"PO":["557315"]},"129132":{"abstract":"In this project the investigators focus on improving the reliability of replicated data stores using an efficient and unconventional parity-based replication scheme the investigators call SSPiRAL. SSPiRAL (Survivable Storage using Parity in Redundant Array Layouts) is a data redundancy scheme that is easily tailored to the underlying infrastructure. SSPiRAL can be tailored to available resources and desired levels of fault-tolerance, capable of surviving multiple node failures with almost no degradation in performance. SSPiRAL is a near-optimal algorithm in terms of storage utilization, and yet it is distinguished by its adaptability to the available resource constraints, and its ability to sustain high performance in spite of the loss of component storage nodes.<br\/><br\/>SSPiRAL has applications at multiple scales: improving the reliability of small storage arrays; improving the performance of large storage arrays; enabling more efficient grid storage; improving the reliability and maintainability of distributed storage; and enabling a novel approach to the construction of collaborative archival and backup stores. A prototype SSPiRAL layout is the focus in this project. Individual storage nodes for the prototype SSPiRAL system are built using commodity computers. The project aims to develop and refine the system for distributing data to the individual storage nodes, and to demonstrate the advantages in reliability and manageability offered by the SSPiRAL scheme.","title":"CSR-PDOS: Hardening Distributed Data Stores for Disaster Recovery","awardID":"0720578","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554329","517914"],"PO":["535244"]},"128285":{"abstract":"Over the next few years, the basic architecture of the next generation of Internet will be decided, hopefully with a much greater emphasis on security. In a network, security and communication are interdependent. Cryptographic tools will be required to ensure that communication is dependable despite hackers' denial-of-service attacks and other sabotage. On the other hand, proper communications architecture could provide primitives that make powerful cryptographic tools for security, such as secure multiparty computation, e_cient enough to be implemented. Unfortunately, research on reliable communications and computation in a network has traditionally been studied without consideration of security, and vice versa. This research examines a model of communication channels that includes security considerations in a robust way. In this model, protocols can be simultaneously evaluated for the two dual objectives of secrecy and reliability. This model unites previous approaches to these questions from the points of view of cryptography, distributed systems, and error-correction. The model also unites information-theoretic techniques (with security based on the attacker's inability to access certain information) with complexitytheoretic approaches (based on the attacker's inability to solve intractable computational problems). Possible constructions of channels with stronger properties (increased privacy, authentication, or reliability) from those with weaker properties will be explored. For example, is it possible to take an arbitrary channel that gives only slightly more information to the intended receiver than to an attacker and use it to build a highly reliable and almost completely secret channel? Can we use a channel for secret, reliable communication to create a channel emulating a virtual broadcast? What is the relationship between secrecy and anonymity?","title":"CT-ISG: Amplifying both security and reliability","awardID":"0716790","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["515842"],"PO":["565264"]},"129143":{"abstract":"Computer systems are growing rapidly in scale, complexity, distribution, and heterogeneity. For these reasons, it is increasingly important for engineers to reason quantitatively about a system's properties during design, before significant resources have been expended on implementing the system. This project is focusing on design-time evaluation of software systems' architectures with respect to one key property ? reliability. Reliability is defined as the probability that the system will perform its intended functionality under specified design limits. The approach developed in this project results in a multi-faceted, hierarchical model of a system, which allows assessment of the system's reliability in an incremental, scalable fashion. The approach combines standard software design models with stochastic models used to assess system reliability. Although several software reliability techniques exist, they either assume the availability of a running software system or fail to take into account the properties of the firmware underlying the software system. This project addresses both these deficiencies in the context of several representative case studies. The results of this research are evaluated along two measures of interest: tractability (intended to address scalability issues existing in real, complex systems) and sensitivity (intended to address issues of confidence in our predictions under numerous uncertainties existing at design time). The project's results are applied to real problems in mobile robotics, a domain that is representative of many complex, distributed, and embedded systems. The results are also actively transferred into the classroom.","title":"CSR-SMA: Engineering Reliability into Hybrid Systems: A Compositional and Hierarchical Approach","awardID":"0720612","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["410098","551145"],"PO":["493916"]},"127097":{"abstract":"Advances in networks, sensors, storage, computing, and high throughput data acquisition, have led to a proliferation of autonomous, distributed data sources in many areas of human activity. New discoveries in biological, physical, and social sciences and engineering are being driven by our ability to discover, share, integrate and analyze disparate types of data. Statistically-based machine learning algorithms offer some of the most cost-effective approaches to discovery of experimentally testable predictive models and hypotheses from data. However, the large size, distributed nature, and autonomy of the data sources (and the attendant differences in access, queries allowed, processing capabilities, structure, organization, and underlying data models and data semantics) present hurdles to effective utilization of machine learning. This research aims to overcome these hurdles by developing efficient, resource-aware distributed algorithms and software services to support collaborative, integrative knowledge acquisition such a setting. The research team will implement, deploy, and evaluate the resulting algorithms using benchmark data sets, associated data models and ontologies, and user-specified inter-ontology mappings on a distributed test-bed of networked databases and services at Iowa State University and Kansas State University. The resulting open-source software can potentially transform collaborative e-science in the same way that Web has transformed information sharing. Broader impacts of this research include enhanced opportunities for research-based training of graduate and undergraduate students, interdisciplinary collaborations, participation of under-represented groups, and development of increasingly sophisticated software to support collaborative, integrative e-science. The project web site (http:\/\/www.cild.iastate.edu\/projects\/indus.html) provides access to information about the project, benchmark data, publications, software, and documentation.","title":"Collaborative Research: Learning Classifiers From Autonomous, Semantically Heterogeneous, Distributed Data","awardID":"0711396","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["559271"],"PO":["565136"]},"129044":{"abstract":"Abstractions currently used in computing hide timing properties of software. As a consequence, computer scientists have developed techniques that deliver improved average-case performance and\/or design convenience at the expense of timing predictability. For embedded software, which interacts closely with physical processes, timing is usually an essential property. Lack of timing in the core abstractions results in brittle and non-portable designs. Moreover, as embedded software becomes more networked, the prevailing empirical test-based approach to achieving real-time computing becomes inadequate.<br\/><br\/>This project reintroduces timing predictability as a first-class property of embedded processor architectures. It tackles the problem from the hardware design perspective, developing precision timed (PRET) machines as soft cores on FPGAs. It shows that software on PRET machines can be integrated with what would traditionally have been purely hardware designs. This project seeks to reinvigorate research in an area of computer science and computer architecure that have stagnated in research due to maturing industrial practice. This is expected to provide a starting point for a decades-long revolution that will once again make timing predictability an essential feature of processors. This project addresses the core abstractions of computing. Rather than attempting to correct the lack of timing in these abstractions with more layers of abstraction, this project has the goal of showing that embedded processors can deliver both predictable timing and high performance. It opens up the field to new computing abstractions that include timing as a first-class property.","title":"Collaborative Research: CSR---CORE---EHS: PRET: Precision Timed Architectures","awardID":"0720292","effectiveDate":"2007-08-01","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["530445"],"PO":["561889"]},"125282":{"abstract":"Advances in enabling technologies, such as wireless networking and communication, have brought computer systems into almost every aspect of daily life. Many areas of individual and mass transportation have become almost completely dependent on the correct functioning of software services. Cars, for instance, rely heavily on the complex interplay of hundreds to thousands of software functions that are distributed over dozens of networked computer systems. Some of these functions manage highly safety-relevant aspects of the vehicle. Service-oriented software and systems engineering has emerged as a promising approach to managing the integration complexity of high-quality, feature-rich systems-of-systems. This research focuses on a novel methodology for service-oriented development of highly interactive software systems. At the core of the methodology is the understanding that services, and their composition, emerge from the interplay of interacting components. This gives rise to a fresh look at the composition and refinement of services and components as composition and refinement, respectively, of corresponding interaction aspects. Besides theoretical foundations for interaction-based software-services and their composition, intuitive description techniques, an architectural definition language, component synthesis algorithms, and practical development guidelines for service-oriented software development are investigated. The research is validated using case studies from the automotive domain.","title":"ASOSA: Automotive Service-Oriented Software & Systems Engineering","awardID":"0702791","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["438188"],"PO":["564388"]},"129210":{"abstract":"Timely delivery of data streams is important to time-critical<br\/>applications relying on streams of dynamic data. Drastic reduction<br\/>on the sending rates of data streams typically has negative impact on<br\/>the operations of such applications. Effective rate adaptation is<br\/>needed to make data streams adapt to network congestion through slowly<br\/>varying their sending rate. This research project is motivated by<br\/>the need of streaming dynamic radar data at the required rates from<br\/>radars to a control center in the surveillance application using ganged<br\/>ground-based radars. This application is crucial to the operation<br\/>of the unmanned aerial vehicles.<br\/><br\/>In this research project, an adaptive data pulling framework is<br\/>studied to support stable data streaming. This framework consists<br\/>of a transport-layer congestion control scheme and an<br\/>application-layer data pulling control mechanism. The<br\/>application-layer data pulling control mechanism allows the<br\/>application actively fetch data from sources. The transport-layer<br\/>congestion control scheme adopts a new rate control method which<br\/>provides weighted fairness to data streams. Weighted fairness<br\/>among data streams is the desired feature for controlling the sending<br\/>rates of streams carrying layered encodings. Weighted fairness<br\/>means that the throughput of a stream is degraded reversely<br\/>proportional to its priority when the network becomes congested.<br\/>Weighted fairness brings new vision on rate control for data<br\/>streaming. Stability and responsiveness to congestion indications<br\/>are the two key research questions of the new rate control scheme.","title":"CSI - An Adaptive Data Pulling Framework for Supporting Time-Critical Streaming Media Applications","awardID":"0720809","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["302533"],"PO":["493916"]},"129100":{"abstract":"Current software design for safety-critical embedded systems requires stringent compliance with coding standards to ensure safety and reliability. A key additional requirement for real-time embedded systems is predictable timing behavior of software components, which requires that bounds on the worst-case execution time (WCET) of embedded software be determined. While static timing analysis yields verifiable bounds on the WCET, it cannot keep pace with architectural innovations and hardware performance variation due to chip fabrication scaling. <br\/><br\/>This work contributes a fundamentally new approach to bounding the WCET with three major contributions: (1) Instead of simulating execution, actual execution in hardware is promoted to assess the WCET of a task. This approach not only renders tedious hardware modeling unnecessary but also confirms correct behavior regardless of architectural complexity or hardware variation. (2) The approach and its complexity are evaluated by FPGA synthesis. This assesses the feasibility of the design and validates a prototype implementation. (3) The impact of advanced architectural features is studied in a co-design space exploration, aimed to provide predictability and tight WCET bounds. The research conducted in this project advances existing science and technology through novel techniques in hardware and software design for safety-critical embedded real-time systems by providing high-confidence bounds on execution times; enhancing hardware architectures with support to assess execution times; and customizing hardware features via co-design to improve predictability. These capabilities directly benefit safety and reliability of software controlling, for example, aircraft and components of cars, thereby aiding the high-confidence design of embedded systems.","title":"CSR--EHS: Collaborative Research: Hybrid Timing Analysis via Multi-Mode Execution","awardID":"0720496","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553590"],"PO":["561889"]},"129232":{"abstract":"Release of chemicals or biological agents in the subsurface often results in plumes migrating in the medium, posing risk to human and ecological environments. Temporal and spatial monitoring of the plume concentrations are needed to assess risk, make decisions and take remedial action. Current underground contaminant plume monitoring technologies are inefficient, expensive and ineffective. Wireless sensor technologies have the potential to dramatically improve this process. <br\/>A closed-loop system integrating wireless sensor network based monitoring with numerical models for plume tracking is being developed, in which sensor data continuously calibrates and validates the system identification and prediction models, while the output from these models direct the sensor network operation to optimize constraints such as accuracy and power consumption. The system is based on a novel virtual sensor network architecture with broader applicability beyond plume tracking. Algorithms and protocols being developed support the formation, usage, adaptation and maintenance of dynamic subsets of collaborating sensors, named Virtual Sensor Networks (VSNs). VSN protocols for collaboration among groups of sensors will greatly ease the task of deploying sensor networks, especially in environments where multiple geographically overlapping applications are deployed. A proof-of-concept laboratory test bed that captures the complex subsurface processes is used for integration and evaluation of VSN protocols. This interdisciplinary project will significantly advance the state-of-the art in subsurface plume tracking and sensor networking technologies. It will stimulate a unique partnership of electrical engineers, computer scientists and environmental researchers, and demonstrate closed-loop operation of computer models and sensor networks to solve complex environmental problems.","title":"Collaborative Research: CSR---CSI: A Virtual Sensor Network Based","awardID":"0720875","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["512149","172368","465792"],"PO":["493916"]},"129485":{"abstract":"A major task of a wireless sensor network is to disseminate sensor readings back to a centralized host, called the sink node. As such, a core functionality of the sensor network is energy-efficient, timely, robust, and secure dissemination of data from data sources to the sink. This project aims to create a new sensor network architecture, AIDA, that uses antenna arrays of the distributed sensor nodes to create directional radio waves that can reach order-of-magnitude farther than individual antennas of the sensor nodes. Such a distributed antenna array is created by aligning antennas of multiple sensor nodes and transmitting the same information simultaneously at different phases.<br\/><br\/>The project explores a complete and coherent strategy for designing and implementing energy-efficient data dissemination based on dynamic distributed antenna array forming in randomly deployed sensor networks. The pursued strategy simultaneously addresses issues from the physical to the MAC to the routing layers, including sensor node size, antenna design including size and efficiency, sensor synchronization, sensor localization, low-power radio, and MAC and routing protocols. The PIs will prototype sensor nodes that integrate the new radios and antennas and field test a small-scale AIDA sensor network at Purdue.<br\/><br\/>Broader Impact: The results will advance our understanding of the fundamental limits of distributed antenna array forming and applications in large-scale sensor networks. The algorithms, protocols, and system architectures developed in this project, and the theory underlying them, will have a significant impact on the sensor network technologies. Through the Center for Wireless Systems and Applications at Purdue, the PIs will actively share their findings with industrial collaborators. Students supported on this project will have a balanced exposure to a wide variety of system design techniques that will be valuable in their future careers.","title":"NeTS-NOSS: AIDA: Autonomous Information Dissemination in RAndomly Deployed Sensor Networks","awardID":"0721873","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550994","540778","531741","451621"],"PO":["557315"]},"128275":{"abstract":"Society is dependent on many engineered systems whose increasing<br\/>complexity and inter-connectedness have, in turn, increased their<br\/>vulnerability to adversarial attacks. In many of these systems,<br\/>protecting the execution of their computations is as crucial as<br\/>ensuring the security of their data. This research investigates how<br\/>to maintain survivable operation of such systems, even in the face of<br\/>invasive attacks where computations are intentionally subverted to<br\/>interfere with other computations' execution constraints.<br\/><br\/>The goal of this research is to develop new techniques for isolating<br\/>the effects of interactions among computations through specific<br\/>resources in these systems, including: flexible specification and<br\/>rigorous enforcement of computations' execution constraints; explicit<br\/>control of all OS kernel components under a single scheduler; detailed<br\/>on-line monitoring of computations and their supporting OS kernel<br\/>components; automated learning to discover previously unknown<br\/>interactions among computations; and formal modeling and verification<br\/>of computations, execution constraints, and system components and<br\/>resources.<br\/><br\/>The expected benefits of this project include: a novel approach to<br\/>non-bypassable isolation of computations from the effects of<br\/>adversarial attack in which isolation can be enforced flexibly<br\/>according to the system-specific execution constraints that must be<br\/>satisfied; a high quality open-source software implementation of<br\/>kernel-level scheduling and monitoring services that provide and<br\/>measure such non-bypassable isolation; new formal models, analyses,<br\/>and methodologies for verifiably correct configuration and management<br\/>of those services; and empirical studies of the services' ability to<br\/>protect computations from interference under a wide range of<br\/>adversarial attacks.","title":"CT-ISG: Collaborative Research: Non-bypassable Kernel Services for Execution Security","awardID":"0716740","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[340015],"PO":["565327"]},"129133":{"abstract":"Data-driven applications in computational science react in real time to their environment in a complex detect-analyze-response cycle. These computations can often be viewed as complex data flow graphs having components that are both data- and computationally- intensive, and requiring access to live data feeds and access to large-scale computational resources. A user may cycle through multiple graphs accessing data from sensors, instruments, databases, and large collections of files in the process of discovering new knowledge. This research investigates a programming model and framework for knowledge discovery in data-driven applications. Users program the system by declarative specification of detect-analyze-response behavior. Underlying the programming model is a continuous rule-based events processor and workflow orchestration engine organized as Web services. The research formalizes an abstract model of interaction and will map the higher-level conceptualization to the events processing and workflow runtime components. It demonstrates that the model supports a unique adaptive framework where knowledge gained from the computational and data analysis can be fed back to the data event streams. The approach is validated experimentally through quantifiable metrics and by its application to two model problems: severe storm prediction where a weather forecast is triggered based on data mining results from mining radar or model data, and adaptive resource management where hardware and software resources and environment data streams are monitored for on-the-fly resource requirements<br\/>prediction.","title":"CSR---CSI. An Adaptive Programming Framework for Data and Event Driven Computation","awardID":"0720580","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["565242","380554"],"PO":["535244"]},"127087":{"abstract":"Croft, W. Bruce<br\/>University of Massachusetts Amherst<br\/>III-COR Searching Archives of Community Knowledge<br\/><br\/>The problem of recognizing or finding questions has received little attention, but is an important problem that is conceptually different than typical document search. The use of text transformation models learned from the Q&A archives has the potential of considerably advancing our knowledge of how models that have been very successful in machine translation applications can be applied to improve the effectiveness of search. This project will use two large archives of questions and answers to develop, test, and compare algorithms for more effective retrieval of questions that are semantically similar to the question posed by a current user and look to retrieve answers with a high probability of relevance. One aspect of addressing this challenge will be to apply text transformation techniques developed to support machine translation to the Q&A archives in order to learn probabilities to associate with word substitution in identifying semantically similar queries. The techniques will be evaluated for both English and Korean (since one of the Q&A archives is in Korean). Over a dozen alternative approaches to developing similarity measures will be tried and compared using a variety of performance metrics, primarily metrics that focus on the precision\/relevance of results returned at the top of a ranked list. Development of successful approaches to the problem of retrieval of appropriate answers from archives of questions and answers will benefit many application areas","title":"III-COR: Searching Archives of Community Knowledge","awardID":"0711348","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H228","name":"CIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["562750","507668"],"PO":["563751"]},"129155":{"abstract":"With the proliferation of the battery-powered portable\/embedded devices, effective energy management became extremely important and the research community has recently developed various energy management techniques. However, there is an urgent need to incorporate reliability requirements to these frameworks, in view of the ever-increasing transient fault rates linked to scaled technology sizes and reduced design margins. This is particularly important for safety-critical real-time embedded systems. Recent reports indicating that the problem is exacerbated by the widely-popular energy management technique, dynamic voltage and frequency scaling (DVFS), which has an alarmingly negative effect on system reliability because of increased transient fault rates associated with operation at low supply voltages.<br\/><br\/>This project undertakes a comprehensive study of the interplay between energy management and transient fault recovery in real-time embedded systems. First, a generalized transient fault model for DVFS-enabled systems is being developed that considers the effects of radiation, temperature and electromagnetic interference. Second, focusing on operating-system-level algorithms and tools, the project is developing an integrated, reliability-aware power management framework for different types of embedded and real-time systems. The framework enables a trade-off analysis for energy savings and aggregate reliability to be carried out. Adaptive schemes that dynamically improve the system performance by monitoring system's execution at run-time are also investigated. The project is expected to have a substantial technological impact as energy-efficiency and reliability are known to be fundamental requirements for next generation real-time and embedded systems.","title":"Collaborative Research: CSR-EHS: Towards an Integrated Framework for Low Power Reliable Real-Time Embedded Systems","awardID":"0720651","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["451043"],"PO":["561889"]},"128187":{"abstract":"Spam has become a prominent problem in every important communications medium. Most email users face spam every day. An entire industry has sprung to \"improve\" search engine rankings of web sites. Further, automatically generated spam has invaded blogs, social networks, online advertising, and VoIP connections. Spam is a rapidly growing practical problem due to the easy adaptation of attacking tools that bypass defense mechanisms. For example, useful defense techniques such as statistical learning filters and collaborative filtering are capable of distinguishing spam from legitimate email. However, attackers have been using automated tools to bypass these defense mechanisms, resulting in a seemingly endless \"arms race\" between attacks and defenses. For example, randomizing spam tokens and inserting legitimate text as camouflage can significantly reduce the effectiveness of statistical learning filters. Although there is no known general solution for the arms race, known as Adversarial Learning, a defense based on the exploitation of the semantic necessity of spam email to contain strong spam tokens such as VIAGRA (or its misspellings) has been found and demonstrated to end the camouflage arms race. This project seeks additional evidence to support the hypothesis that such structural (inherent) characteristics can be found and used in the identification of many kinds of spam attacks. The first research thrust focuses on the development of defense methods resilient to adaptive spam attacks. The second research thrust investigates the combination of spam attacks in distinct areas (e.g., email and web spam) and combined defenses. Success in these thrusts will significantly and permanently reduce the effectiveness of spam attacks.","title":"CT-T: Collaborative Research: Adaptive Attacks and Defenses in Denial of Information","awardID":"0716357","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["557662","555591"],"PO":["497499"]},"128198":{"abstract":"Policy-based access control is one of the most fundamental and widely used mechanisms for achieving privacy and security at both application and network levels. Given the high importance and delicacy of security policies, ensuring the correctness of these policies is important, and yet difficult. A tiny error in security policies could lead to irreparable, if not tragic, consequences. Therefore, identifying discrepancies between policy specifications and their intended function is a crucial task. To achieve this goal, this project pursues a new approach to testing and verification of security policies, including application-level security policies (such as XACML policies) and network-level security policies (such as firewall policies). To accomplish this, this project is defining two unified representations for security policies: program code representation and decision tree representation. Second, the project is developing a suite of rigorous and systematic security policy testing techniques. Third, this project is pursuing efficient and scalable verification and change-impact analysis techniques for security policies. Fourth, this project explores methods for testing and verifying stateful security policies. The project is developing frameworks and techniques for testing and verifying both application-level and network-level security policies. The project will also produce concepts and theories that fundamentally advance the knowledge and understanding of security policies. The concepts, theories, algorithms, and tools produced by this NSF-supported research are expected to promote rigorous security policy testing and verification practice, which will lead to better policy quality and higher security assurance in general. Furthermore, the results of this research will enable further innovations in related fields that depend on the correctness of security policy.","title":"CT-ISG: Collaborative Research: A New Approach to Testing and Verification of Security Policies","awardID":"0716407","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["562296"],"PO":["561889"]},"128099":{"abstract":"Proposal: 0715833<br\/>CT-ISG: Towards Trustworthy Peer-to-Peer Overlay Networks<br\/>Sanjay G. Rao<br\/>Purdue University<br\/><br\/><br\/>This project seeks to create trustworthy peer-to-peer overlay <br\/>systems through fundamental advances to the state-of-the-art <br\/>in the design of Internet-scale, overlay networks for performance-demanding<br\/>applications in the presence of adversaries. <br\/>Design limitations in popular peer-to-peer systems today may be<br\/>exploited to cause large-scale denial of service attacks on nodes <br\/>not even part of the overlay system. Further, adversaries may<br\/>control the overlay construction to create a crippling impact on <br\/>application performance. To tackle this, the project will<br\/>(i) Design robust and attacker resilient adaptation protocols <br\/>contributing to an emerging science of trustworthy adaptability<br\/>that defines a new shift in building distributed systems; <br\/>(ii) Obtain fundamental insights into the interplay between the design <br\/>of group management algorithms and their vulnerability to being<br\/>exploited to launch distributed denial of service attacks on the<br\/>Internet; (iii) Explore the interactions between peer-to-peer design, <br\/>resulting traffic characteristics, and implications for distinguishing<br\/>normal peer-to-peer traffic patterns from anomalous ones; <br\/>and (iv) Design mechanisms for reliable, scalable and <br\/>adversary-resilient key dissemination to help ensure confidentiality and <br\/>integrity of application-specific data.<br\/><br\/>The project will demonstrate and validate the novel proposed mechanisms in<br\/>the context of mature and widely deployed peer-to-peer systems.<br\/>Peer-to-peer video broadcasting will be used to <br\/>promote online education in the Lafayette area, and to<br\/>broadcast a security-related seminar series. <br\/>The project will benefit the design of large-scale testbeds such <br\/>as GENI. The PIs will communicate with developers of popular <br\/>peer-to-peer systems to alert them to critical design vulnerabilities in <br\/>their systems.","title":"CT-ISG: Towards Trustworthy Peer-to-Peer Overlay Networks","awardID":"0715833","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["519699","508447"],"PO":["497499"]},"126471":{"abstract":"As a result of increased logic capacity, reconfigurable logic devices, such as field programmable gate arrays (FPGAs), have become increasingly important components in many digital systems. The programmable structure of these devices offer designers the opportunity to quickly map parallel designs to silicon while customizing circuitry to exactly the functionality desired. The successful use of this circuitry relies heavily on design mapping flows of intricate and complex computer-aided design tools and compilers. As the programming models used by designers to target reconfigurable logic devices become more diverse, the need to optimize tools both individually and jointly becomes more important. It is widely recognized that researchers in this reconfigurable computing field will require easy access to representative tool sets, documentation describing how to combine them into mapping flows, and a collection of representative benchmarks in the near future to sustain research progress.<br\/><br\/>The need for greater accessibility to freely-available reconfigurable computing CAD tools forms the cornerstone of this proposal. Upon completion of the project, designers will have access to a well-organized repository of documented tools and compilers including documentation on how to coordinate multiple tools together into complete design mapping flows. This infrastructure will allow researchers to optimize existing tools for new design goals and develop new, more advanced tools which use the current infrastructure as a basis. All resources in the infrastructure will be hosted in web-based repositories at the University of Massachusetts, Amherst and the University of Wisconsin, Madison. Funding for this project will be used to acquire needed computer hardware and web-based resource distribution materials, and to support graduate student researchers who will organize the infrastructure. Upon completion, the infrastructure will be made publicly-available and will be widely publicized to researchers in a variety of research fields.<br\/><br\/>This proposal outlines a series of development steps to achieve this goal including the acquisition of existing CAD tools and compilers, the construction of a web-based infrastructure, the integration of the individual tools into a series of end-to-end mapping flows, and the development of an infrastructure deployment strategy. The proposed development work is closely tied to learning opportunities for graduate and undergraduate students. These students will have the opportunity to become familiar with state-of-the-art design tools and advanced web-design and database building techniques. Preliminary contact with researchers in both academic and commercial settings has indicated strong interest. It is expected that as the project progresses external parties will assist in offering technical direction and support in terms of CAD tools and benchmarks. As the project nears completion, a consortium of academic and industry partners will be solicited to continue support for the infrastructure.","title":"Collaborative Proposal: CRI: CRD: Computer-aided Design Tool and Compiler Repository for Reconfigurable Computing","awardID":"0708273","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["549952"],"PO":["565272"]},"125283":{"abstract":"Proposal ID: 0702792<br\/>Title: Modeling and Optimization of Thermal and Energy Efficient Processing in Multi-Core System-Chips<br\/>PI name: Rajesh Gupta<br\/>PI Inst: UC SanDiego<br\/><br\/><br\/>Multi-Core System-Chips, or Chip Multi Processors (CMPs), represent both an opportunity as well as a challenge to the new generation of computer system architects and implementers. However, the exploitation of additional processing resources in an energy efficient manner is a challenge due to lack of scalability of the heat dissipation capabilities of the integrated chips. Use of best known methods for low power design at various circuit, logic or architectural design levels is not enough to realize the potential for multi-core performance improvement. Instead, systems must be architected to push the thermal limits to take the maximum advantage of the available heat dissipation limits, both statically as well as dynamically. This proposal seeks to build a framework for energy-efficient CMP systems that enables the system architect to make various power related decisions from the choice of shutdown and slowdown states to architectural support for speed scaling and load balancing -- in a systematic manner. The approach relies upon the formulation of the speed scaling problem and its different instances under various constraints as an optimization problem. The optimization problem takes into account not only package effects, but also spatial distribution of heat dissipation across the CMP die. Particular attention is paid to leakage power, given its growing importance due to the advancing processes, low voltage (e.g., sub-threshold) circuit operations and due to 'architectural leakage' caused by blocks that are not subject to shutdown or slowdown measures. The PIs treatment of leakage is based on two key concepts: efficient runtime determination of a critical speed that provides optimum energy efficient processing; and scheduling methods that takes a global view of the system level power consumption and exploit the flexibility to make power state changes to achieve effective load-balancing and latency hiding effects. The PI also seek to capture the application intent by enabling the application developer to explicitly program important application-specific 'metadata' using a power-aware API (that, for instance, may change algorithms, precision based on current energy availability profile). The intellectual merit of the project is in optimization techniques that seek a judicious balance of multiple slowdown and shutdown states for the most efficient utilization of energy while pushing the thermal limits supported by the physical placement and packaging constraints. The broader impact of the proposed research is its contribution to an infrastructure of various courses and projects related to the topic of thermally aware energy efficient embedded processing. The project seeks to provide students chance to learn and experiment with the OS internals, memory interfaces and time-bound computations.","title":"Modeling and Optimization of Thermal and Energy Efficient Processing in Multi-Core System-Chips","awardID":"0702792","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["457653"],"PO":["562984"]},"125174":{"abstract":"Collaborative Proposal ID: 0702343, 0702204<br\/>PI name(s): Subhasish Mitra, Chongwu Zhou<br\/>Institution(s): Stanford University, University of Southerm California<br\/>Title: Design, Modeling, Automation and Experimentation of Imperfection Immune Carbon Nanotube Field Effect Transitor Circuits<br\/><br\/>ABSTRACT:<br\/>One-dimensional nanodevices such as Carbon Nanotube Field-Effect Transistors (CNFETs) are promising candidates as extensions to traditional Silicon transistors due to excellent device performance. Device scaling of silicon transistors has been the fundamental basis for the phenomenal success of the semiconductor and electronics industry. While there have been significant accomplishments in scientific discovery in recent years at the single-device level at the nanoscale, a major gap exists between such single-device-level results and the research required to harness the science into practical design technologies competitive with silicon technologies at the end of device scaling. This project uses an interdisciplinary approach to overcome fundamental challenges by combining novel CNFET-based robust imperfection-immune design and automation techniques together with new CNFET modeling and processing techniques. The ideas developed in this project will be experimentally validated through working CNFET-based circuits. This research program also integrates research and education required to explore novel, nanoscale electronic designs through graduate and undergraduate training, and public education on nanotechnology.","title":"Collaborative Research: Design, Modeling, Automation and Experimentation of Imperfection Immune Carbon Nanotube Field Effect Transitor Circuits","awardID":"0702343","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["559405","549505"],"PO":["562984"]},"127363":{"abstract":"The goal of the project is to develop an approach to the problem of security and privacy for eHealth applications based on policy-driven security services. The project achieves its goal using the following approaches: (1) Develop an architectural framework supporting the interoperation of security services. The framework combines the service oriented architecture paradigm with the event-based model and also includes a context-management service; (2) Develop an identity management service based on the life-cycle of digital identities;(3) Develop an authentication service supporting multi-factor authentication policies;(4) Develop a privacy-aware role-based access control (RBAC) service able to support content-based authorization;(5) Develop policy modularization and policy activation\/deactivation mechanisms to support emergency situations and the ''break-the-glass'' principle that are relevant for eHealth applications; and (6) Prototype the framework and the services and integrate them with a Web-based prototype of a Personal Health Record (PHR) management system being developed by one of the Co-PIs.<br\/><br\/>The results of the project will benefit the IT providers of eHealth solutions by offering enhanced architectural solutions for security and privacy, as well as insights about their complexity, their manageability and their interoperability. The results will provide useful insights for those eHealth IT providers wanting to evaluate the feasibility of the ''Software As A Service'' (SAAS) model for security and privacy, as well as for IT security managers of caregiver organizations. This project supports Ph.D and master students to pursue research in security architectures and services, and in advanced IT systems for eHealth. Several course modules will be developed based on the project results, including modules on: HIPAA - Security and Privacy Requirements; Security Architectures for eHealth; Security as a Service - Concepts, Architectures, and Techniques. Publications, technical reports, and software from this research will be disseminated via the project web site (http:\/\/www.cs.purdue.edu\/homes\/bertino\/IIS-eHealth)","title":"IPS: Security Services for Healthcare Applications","awardID":"0712846","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["529959","556632",337791,337792],"PO":["497499"]},"127484":{"abstract":"There has been much previous research in the general area of brain-computer interfaces (BCI), which has primarily aimed to help people with severe motor disabilities interact with their environment by translating their brain activity into specific device control signals. Users who are completely paralyzed (\"locked-in\") or those who lack muscle control (e.g., people with cerebral palsy or stroke victims) can use BCIs to answer simple questions, to control their environment, and for word processing. But the variety of brain imaging techniques that have been tried to date for BCIs have all suffered from serious drawbacks, so that communicating through such systems is currently time consuming and mentally demanding. Open research challenges concern the accuracy of BCIs (systems often misinterpret a user's intentions), and the information transfer rate of such systems (which is often too slow for use in real world settings). In this project, the PIs will build on their experience in designing, implementing, and evaluating non-command, adaptive user interfaces (e.g., based on eye movement), to advance BCI by bringing to bear emerging technology for measuring brain activity using functional near infrared (fNIR) spectroscopy coupled with machine learning to analyze user data in human-computer interaction. While fNIR technology is still in its infancy, the PIs expect its use as a real-time input to an adaptive interface to break new ground. The PIs believes that this combination will also lead to new, more objective methods for evaluating next generation interaction styles for HCI in general. The PIs' approach is a natural extension of and will exploit their prior work relating to the concept of reality-based interaction, which focuses on the ways that new interaction styles exploit the user's pre-existing skills and expectations from the real world more than trained computer skills, while at the same time helping to differentiate mental effort devoted to interface-related or syntactic aspects from that devoted to the underlying task or semantic aspects.<br\/><br\/>Broader Impacts: This project will develop technologies of immediate benefit to users with motor disabilities. Additionally, the work will open up a new area of HCI research (namely, relating to interfaces that can dynamically adapt in real time to the user's cognitive load), and will advance the theory and evaluation of interaction styles in general.","title":"HCC: Human-Computer Interaction and Brain Measurement Using fNIR Spectroscopy","awardID":"0713506","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["519872","475295"],"PO":["565227"]},"125185":{"abstract":"The project investigates the integration of types and verification as complementary techniques for building robust, reliable, and maintainable software. Types provide the foundation for the composition of systems from independently reusable components by providing a rich language of invariants governing programs and data. Verification provides the foundation for reasoning about the run-time behavior of programs, especially their effect on the execution environment.<br\/><br\/>To integrate these two methods the project is developing new dependent type systems capable of expressing behavioral specifications and new methods for checking conformance with such rich type constraints. To ensure that the integration is sound, the project is developing its theoretical foundations using mechanized proof assistants. To assess the practicality of the integration, the project is implementing a programming language that integrates types and verification, and is developing applications that illustrate its use.<br\/><br\/>The primary intellectual contribution of the project is to investigate the design and implementation of programming languages that support the specification and verification of strong correctness properties of programs. A broader contribution of the project is to promote through education the use of formal methods to improve the reliability and maintainability of software systems.","title":"Collaborative Research: Integrating Types and Verification","awardID":"0702381","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["339844","485877"],"PO":["564388"]},"127495":{"abstract":"Text summarization generates a concise summary of documents to<br\/>help a user quickly digest information and has become increasingly important due to the <br\/>explosive growth of information. Most existing summarization methods <br\/>can only generate an unstructured summary with a simple list of sentences. <br\/>In many applications, however, we want to generate a (more structured)<br\/>multi-faceted comparative summary, in which sentences are grouped into <br\/>multiple facets and compared across different views. For example, a summary about laptop opinions <br\/>may group sentences into facets such as ``battery life'' and ``memory'' and separate sentences<br\/>with positive and negative opinions in each facet. <br\/><br\/>This project aims to systematically study this new summarization problem (called multi-faceted<br\/>comparative summarization). The PI will develop general probabilistic approaches that can <br\/>be applied to multiple instances of the problem in different domains. <br\/>The basic idea is to use probabilistic mixture models to model and extract<br\/>the multiple facets and multiple views of each facet in a set of text documents to be summarized.<br\/>The extracted facets and views are then used to generate facet labels and select sentences for<br\/>different facet-view combinations. <br\/><br\/>The proposed research will open up a new research direction in text summarization. <br\/>The developed methods can be directly applied to provide more useful<br\/>product opinion retrieval service on the Web to all people and help scientists in multiple fields<br\/>to digest scientific literature more effectively, thus speeding up scientific discovery.<br\/>All research resources and results will be disseminated to the research community <br\/>through publications and downloadable software and data. The research results will also<br\/>enhance the current curriculum in information retrieval, <br\/>leading to improved education of the information technology workforce.","title":"RI: Multi-Faceted Comparative Text Summarization","awardID":"0713571","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["456699"],"PO":["565215"]},"129442":{"abstract":"This project investigates the design and applications of Autonomous Mobile Underwater SEnsor networks (AMUSE) consisting of a variable number of sonars (sensors) and vehicles that are deployed to perform collaborative tasks over a given area. Underwater acoustic sensor networks (UWA-SNs) are envisioned to enable applications for environmental monitoring of physical and chemical\/biological indicators, tactical surveillance, disaster prevention, undersea exploration, and assisted navigation, etc. The major tasks under exploration include UWA-SN self-organization and deployment, self-reconfiguring (MAC, physical layer, and cross-layer design), and mission-aware waveform design\/diversity with applications to target recognition, target tracking, and event detection. The AMUSE project is motivated by and targets to solve the following challenges: 1) the sensors in UWA-SN are expensive and mobile, therefore sound self-organization and self-deployment algorithms are needed; 2) waveform design and diversity for UWA-SNs with active sonars are still in its infancy; 3) the transmit and receive data rates are highly asymmetric, which requires new MAC layer design; 4) the underwater channel is impaired by fading, multipath, and doppler shift; 5) the GPS receivers do not work properly in underwater, thus new localization\/navigation algorithms are required.<br\/><br\/>The success of the AMUSE project is able to benefit the two areas of urgent national interests: (1) Instrumentation for monitoring\/prediction of natural ocean disasters including storm surges, hurricanes, tsunami, etc. (2) Harbor environments and security. In addition, this project can serve as a vehicle to promote cross-disciplinary graduate and undergraduate research and education, and to encourage the participation of under-represented and female students.","title":"Collaborative Research: NOSS: Autonomous Mobile Underwater SEnsor networks (AMUSE): Design and Applications","awardID":"0721669","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560587"],"PO":["564993"]},"128232":{"abstract":"Summary Statement, Biometric Identification Red Team (BIRT)<br\/>The BIRT methodology will aid biometric system designers in making effective refinements in their systems. The measurement of biological characteristics (biometrics) such as fingerprints and facial images provides a means of identification that neither needs to be carried nor remembered. Evaluation of biometrics has traditionally been focused on the ability of biometric systems to identify members from a population, e.g., for purposes of authentication. As these systems come into more widespread use, attempts will naturally be made to test and frustrate their ability to identify individuals. Understanding these attempts requires a fundamental new analytic approach, based on modeling the capabilities of an adversary with full generality. BIRT develops the adversary model using the information controlled by the adversary, e.g., for recognition, the clothing, glasses and makeup they wear. BIRT uses disinformation theory to abstractly model the adversary capabilities to mask their identity from an interested observer. Disinformation theory is inspired by Shannon's information theoretic model for communications systems, but views the ?noise source? as controlled by the adversary, abstractly modeling the capacity of the adversary to control the noise in the channel (for example, by transforming the image ?signal?) between the biometric sender being identified and the biometric system receiving the identifying information. Face recognition systems will be used to gain experience with and refine the disinformation theory models, with a variety of disguises used as disinformation sources.","title":"CT-ISG: BIRT - Biometric Identification Red Team","awardID":"0716552","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["426074","527253"],"PO":["565327"]},"128243":{"abstract":"With the increasing amount of confidential information being handled<br\/>by computer software, ensuring privacy of personal information is<br\/>becoming a great concern. To address this concern, this project<br\/>investigates mechanisms that track<br\/>the use of sensitive data handled by software programs with the goal of<br\/>preventing unauthorized disclosure.<br\/>The technical focus is on the use of runtime mechanisms that track the<br\/>use of sensitive data. There are three thrust areas investigated in<br\/>this proposal (a) mechanisms for process based separation and<br\/>runtime checking for enforcing confidentiality policies<br\/>(b) techniques for erasing sensitive data from programs<br\/>after their intended use and (c) techniques for tracking implicit<br\/>information flows. The project uses novel ideas that build on the PI's<br\/>prior work in language based techniques for addressing<br\/>fundamental research questions in these thrust areas.<br\/>To maximize impact, this project will also implement tools<br\/>that will apply these techniques to large scale software<br\/>applications. These tools will enable programmers and end users<br\/>to retrofit programs in order to safeguard their<br\/>confidential data. These tools will be distributed using the<br\/>Web for the widest possible dissemination and further enhancement.<br\/>With regards to education, this project aims to train both graduate and<br\/>undergraduate students to perform research in the the application of<br\/>language based methods for computer security and privacy.","title":"CT-ER : Runtime Techniques for protecting confidential data in large scale software","awardID":"0716584","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["532213"],"PO":["529429"]},"127396":{"abstract":"Context<br\/>The remote sensing data that consists of satellite observations of the land surface, biosphere, solid Earth, atmosphere, and oceans, combined with historical climate records and predictions from ecosystem models, offers new opportunities for understanding how the Earth is changing, for determining what factors cause these changes, and for predicting future changes. In turn, this could provide an unprecedented opportunity for predicting and preventing future ecological problems by managing the ecology and health of our planet. Data mining and knowledge discovery techniques can aid this effort by discovering patterns that capture complex interactions among ocean temperature, air pressure, surface meteorology, and terrestrial carbon flux. <br\/><br\/>Intellectual Merit<br\/>The goals of this work are twofold: 1) to better understand global scale patterns in biosphere processes, particularly patterns in the global carbon cycle and climate system. More specifically, the proposed data mining research is driven by the need to address the following two challenges: (i) understanding how ocean, atmosphere and land processes are coupled and (ii) detecting and predicting ecosystem disturbances such as fires, floods, and hurricanes. 2) to support innovative Computer Science (CS) research in data mining. In particular, the spatio-temporal nature of Earth Science data means that standard CS data mining techniques often cannot be directly applied. As an example, in Earth Science research, a key step is the selection of the locations and time periods that are to be used to investigate possible relationships between two Earth Science phenomena, e.g., El Nino and milder winters in the Midwestern United States. Currently, this selection is based on domain knowledge, but automating this process would be very beneficial. The proposed work will develop new data mining techniques that address the high dimensionality, large size, and spatio-temporal nature of the data. <br\/><br\/>Broader Impacts: New algorithms and techniques for the analysis of large spatio-temporal data sets developed in this project will be made available to other researchers within the Earth Science community. To a large extent, this project will encapsulate these algorithms within easy to use visual tools so that users will be able to more easily extract useful knowledge from Earth Science data sets. Although the focus will be on Earth Science data, the data mining techniques that are developed will be applicable to a wide variety of other fields that have data collected over time on a spatial grid. To give a specific example, spatio-temporal clustering has been used to track cyclones and animal migrations, and to model mobile phone users and neuronal activities in the brain, and the new spatio-temporal clustering techniques could also prove useful for these applications.","title":"III-CTX: Collaborative Research: Spatio-Temporal Data Mining For Global Scale Eco-Climatic Data","awardID":"0712987","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["475632"],"PO":["563751"]},"129112":{"abstract":"This project is developing a novel capability-based security infrastructure for wide-area collaborative systems, especially file systems. The new capability-based approach (chits) provides the ability to enforce several strong security invariants, without compromising the traditional advantages of capabilities in localized control and efficiency. The resulting functionality addresses a number of issues that have previously prevented capabilities from being widely used in distributed systems.<br\/><br\/>This system is based around the concept of a chit, which is a new form of capability that permits fine-grained manipulation of both the set of data that is the chit's target, and of the set of rights that the chit materializes. Chits also support defining and verifying flexible identities, allowing them to implement security policies that range from allowing anonymous access to providing strict accountability.<br\/>Chits permit remote delegation, allowing users to, without contacting a server, derive new chits that will grant other users (limited) access to (a subset of) the data. Remote delegation decouples the specification of access control policy from its application. Chits permit fine grained revocation, allowing a chit holder to deny accesses to (a subset of) data.<br\/><br\/>Chits provide an effective means of creating collaborative applications in which users, not servers and administrators, define policy and grant access to other users. A formal taxonomy of chit operations and rights is being developed, the chits are being embedded a general chit library, and the library is being used to build a collaborative file system.","title":"CSR---PDOS: Distributed Capability Systems","awardID":"0720528","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["409678"],"PO":["535244"]},"128144":{"abstract":"The correct behavior and reliable operation of an information system<br\/>relies not only on what users are permitted to do, but oftentimes on<br\/>what users are required to do. Such obligatory actions are integral<br\/>to the security procedures of many enterprises. The management of<br\/>obligations in security policies imposes significant technical<br\/>challenges since obligations bear quite different properties from<br\/>traditional access control. For example, obligations assigned to<br\/>users often cannot be enforced. Thus, even if a system\u00a1\u00afs reference<br\/>monitor is trusted, the failure of obligations must be considered,<br\/>and appropriate remedies need to be an integral part of security<br\/>policies. Also, the interaction between obligations and other<br\/>components of security policies (e.g., access control) must be<br\/>considered to ensure their consistency.<br\/><br\/>This project develops a comprehensive framework for the management<br\/>of obligations in security policies, which covers the full life<br\/>cycle of obligations, including obligation modeling, specification,<br\/>analysis, monitoring and discharges. Specifically, the project<br\/>formally identifies the desirable security objectives that are<br\/>characteristic of systems that involve obligations, and<br\/>systematically investigates dynamic and static means to maintaining<br\/>these objectives while such systems evolve. Though the framework is<br\/>formal in nature, and is designed on purpose to be general, the<br\/>evaluation of its usefulness and effectiveness is firmly grounded on<br\/>real applications, in particular, in the context of privacy policy<br\/>enforcement in health care systems.<br\/><br\/>This project aims to establish a solid foundation for the management<br\/>of obligations, and significantly improve the understanding and<br\/>practice of obligations in information systems. The societal benefit<br\/>of the project also results from the development and dissemination<br\/>of education resources on new types of security policies beyond<br\/>traditional access control.","title":"CT-ISG: Collaborative Research: A Framework for the Modeling and Management of Obligations in Security Policies","awardID":"0716210","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548078"],"PO":["565327"]},"129475":{"abstract":"Mobility has created an increasing demand for information local to the user in a challenging and information-rich environment, demanding new capabilities from information services and network protocols. The Wireless Knowledge Infrastructure (WiKI) project develops an extensible general-purpose system layer based on new ideas for applying concepts from programming languages and database systems - the use of declarative languages and composable views of router, network and host state - to allow monitoring, event detection and triggering based on extant network conditions and policies. Declarative routing algorithms take into account application, session and network state information to set up adaptive routes among mobile devices and wired infrastructure nodes. Cross-layer and cross-domain integrated views of data streams expose and abstract data from different subsystems and layers, providing a step towards a \"Knowledge Plane\" for networks. WiKI takes an exploratory approach, namely building a small-scale software infrastructure using 802.11 to understand the wireless challenges of heavily populated urban areas in Philadelphia, and to develop prototype services based on a WiKI model. WiKI services are incrementally refined as the research progresses. <br\/><br\/>Broader Impact: The end goal is incorporation of WiKI platforms, software and services into the \"Wireless Philadelphia\" municipal WiFI effort, notable for its integral Digital Inclusion program which attempts to reach economically disadvantaged households in our city.","title":"FIND: Wireless Knowledge Infrastructure (WiKI)","awardID":"0721845","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["527253","517980","518109"],"PO":["565090"]},"128265":{"abstract":"Proposal: 0716676<br\/>CT-ISG: Provably Scalable and Robust Peer-to-Peer System<br\/>Baruch Awerbuch<br\/>Johns Hopkins University<br\/><br\/>This proposal addresses the following fundamental question: how can one provably learn from the mistakes and successes of others in an extremely adversarial environment?<br\/><br\/>Informally, imagine that different agents make irreversible decisions, and ``pay'' for their mistakes. It makes a lot of sense for the agents collectively to avoid making the same mistakes multiple times, rather than just individually. Clearly, leveraging trust or shared taste enables a community of users to be more productive, as it allows them to repeat each other's good decisions while avoiding unnecessary repetition of mistakes. In this case, the job of exploring different options can be ``distributed'' among cooperative users. The question is whether it is possible to design an algorithmic tool for learning from the experience of others while minimizing repeating their mistakes. This is certainly possible if all the agents that can cooperate and trust one another, namely consider the same actions to be mistakes, know about each other.<br\/><br\/><br\/>However, in general, the above assumptions may be problematic, since reliable agents in the system must be able to divide the job of exploring different options, and the cost of mistakes associated with such exploration, among themselves, without knowing in advance whose advice can be trusted. This appears to be ``mission impossible'' if adversaries are in a majority; yet this is exactly what we will accomplish in this research effort. Notice that with adversarial majority, any attempt to use classic tools in distributed computing such as Byzantine agreement is hopeless. The main idea is that we only strive to optimize the overall performance, rather than perfectly reconstruct the preferences or discover the coalitions of honest users. Informally, this can be stated via the notion of ``regret'': one can analyze their decision in hindsight, determine the best dynamic prescient strategy that they wish they had followed, and estimate the performance gap versus this strategy.","title":"CT-ISG Provably Scalable and Robust Peer-to-Peer Systems","awardID":"0716676","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["343097"],"PO":["493916"]},"129596":{"abstract":"Proposal Number 0722276<br\/><br\/>TITLE CPATH CB: Living In the KnowlEdge Society (LIKES)<br\/><br\/>PI Robert E. Beck <br\/><br\/>The Living In the KnowlEdge Society (LIKES) Community Building project, led by four sites (Virginia Tech, Villanova, NC A&T, and U. Texas El Paso), is transforming computing education for the 21st Century. The LIKES community, in collaboration with those from other disciplines, is identifying key computing concepts in these disciplines, then developing and implementing tools and techniques that enable learning of both computing concepts and the concepts of the disciplines. <br\/><br\/>Through a series of four workshops, related online community discussions, and our own research, the LIKES community is discovering key computing related issues in core disciplines and engaging leaders nationwide in brainstorming about their computing (education) needs. This aids faculty members, in computing-related education programs, such as Computer Science and Information Systems Departments, and in core \/ liberal education courses, engage with each other to build the global Knowledge Society. Deliverables include (1) new pedagogies in computing education; (2) integration of computing concepts into non-computing disciplines; (3) principles, guidelines, and techniques for integrating computing and non-computing curriculums; and (4) formation of new communities for enhancing that integration. This transforming of education in computing-related disciplines will yield a next generation of builders of the Knowledge Society.","title":"Collaborative Research: CPATH CB: Living In the KnowlEdge Society (LIKES)","awardID":"0722276","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["537383"],"PO":["565264"]},"129123":{"abstract":"As the scale of high performance computing continues to grow, application robustness becomes increasingly important. Checkpointing is the conventional method for fault tolerance. However, it only deals with failures after their occurrence through rollback. In case of one process failure, all processes including non-faulty processes have to be restarted from the previously saved state prior to the failure. Thus, significant performance loss can be incurred due to the work loss and failure recovery. Proactive approaches take preventive actions (e.g. preemptive process migration) before failures, thereby avoiding failures with low cost. Nevertheless, its effectiveness relies on perfect fault prediction, which is hardly achievable in practice. <br\/><br\/>This project investigates a new approach called adaptive fault management by intelligently integrating proactive and reactive robustness techniques such that it will enable applications to avoid anticipated faults if possible, and in the case of unforeseeable faults, to tolerate these faults in such a way that their impact is kept to a minimum. The project consists of three major components: (1) cooperative anomaly diagnosis (CAD) to improve fault prediction in large-scale systems by developing meta-learning methods; (2) adaptive control manager (ACM) to allow runtime decision making in response to imperfect fault prediction; and (3) integrated runtime support (IRS) to enable cost-effective coordination of fault handing techniques at runtime. The resulting framework will enhance robustness of high performance computing applications by improving their performance in the presence of failures. This project also enhances the systems-area curriculum at Illinois Institute of Technology and helps train the future-generation scientific computing workforce.","title":"CSR\/AES: Enhancing Application Robustness via Adaptive and Cooperative Methods","awardID":"0720549","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550730"],"PO":["535244"]},"129244":{"abstract":"Cyber Physical Systems (CPS) interact with their surroundings and may, through malfunction or design oversights, cause or allow harm to people, property, the environment, or national security. Certification is the process for providing assurance that deploying a given system does not pose an unacceptable risk of adverse consequences. Current certification methods, which largely rely on recommended practices, extensive documentation, and human review, are costly and burdensome, worryingly fallible, and a barrier to innovation.<br\/><br\/>This research is advancing emerging new certification practices based on explicit goal based assurance cases. It is developing the scientific foundations of certification based on multi-legged arguments in which some of the legs can be generated automatically using advanced formal methods. Furthermore, the research is developing methods by which certification can be performed compositionally, allowing the development of certified components and easing the certification of systems based on these.<br\/><br\/>Certification requires anticipation, at the time of design and review, of all the circumstances that a system will encounter in its lifetime. Future cyber physical system will configure or even assemble themselves dynamically, so the research is developing methods by which some of the anticipation of future circumstances can be performed at runtime, and harmful outcomes avoided by runtime adaptation. Much of the assurance required for certification is thereby moved to runtime, yielding \"just-in-time certification.\" The technical foundations for these methods lie in automated abstractions of hybrid systems, controller synthesis, and mechanizations of these based on high performance SMT solvers.<br\/><br\/>The project engages with certification bodies so that its research results can inform future certification practices.","title":"CSR-CPS Just In Time Certification","awardID":"0720908","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["384061"],"PO":["561889"]},"128276":{"abstract":"CT-ISG: Cooperative Security Mechanisms for DNS<br\/><br\/>The Domain Name System (DNS) is a very valuable component in the Internet infrastructure as it provides a mapping between domain names and IP addresses for nearly all major Internet applications. Unfortunately, DNS was not designed with security in mind and has numerous vulnerabilities. Insecurity of the proxy servers and the inherent hierarchical structure<br\/>of DNS makes it susceptible to the poisoning attacks. Contemporary techniques for securing DNS operations are predominantly based on cryptographic solutions. In this project, the Principal Investigator (PI) is examining cooperative techniques for enhancing security of DNS as an alternative to cryptographically secured communications as in DNSSEC. Ongoing efforts of the PI on the Domain Name Cross-referencing (DoX) have validated the potential benefits of the cooperation-based security approach. Leveraging on this effort, he is focusing on the development of an enhanced framework for guarding against the poisoning attacks on DNS.<br\/>The research covers a variety of areas including a comprehensive measurement based evaluation of cooperative security, selection and maintenance of peer-groups used for cooperative security, definition and evaluation of DNS quality of service metrics through analytical modeling, and selective use of cryptographic techniques to make cooperative security mechanisms more robust. These efforts will help in developing techniques to reduce security threats such as phishing, pharming, and denial of service attacks on the DNS. In the context of broader impact, the proposed research will have a very positive impact on the Internet community in general by reducing the attacks and security threat against DNS.","title":"CT-ISG: Cooperative Security Mechanisms for DNS","awardID":"0716741","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550540"],"PO":["565264"]},"129134":{"abstract":"Embedded systems are of vital economic importance and are literally becoming ubiquitous. They have already become an integral component of safety critical systems involving aviation, military, telecommunications, and process control applications. Interest in embedded systems is growing further due to the expectation that they will become a key component of many commonplace consumer appliances. Consumers will expect levels of reliability and predictability associated with the very best brands of cars, televisions, and refrigerators. Glitches, crashes, and general erratic behavior of the sort seen with prior generations of consumer PC software products will be unacceptable for these embedded applications. It thus becomes crucial that these embedded software systems satisfy high levels of correctness criteria, well above those of today's large software systems, which are often highly error-prone. This project will engage in research and development of a novel methodology for the systematic development of embedded systems, starting at a high-level property-based specification of system requirements and proceeding in a seamless and rigorous manner towards a running code. Central to the proposed design flow is the utilization of powerful new effective methods for the automatic synthesis of running code from behavioral (i.e., temporal) specifications. This technology will be used in two places: first, in order to determine whether a given property-based specification is realizable. Then, selected modules of the design, whose performance is not critical, will be generated by automatic synthesis. Automatic synthesis can also be used for rapid prototyping of larger portions of the design.<br\/><br\/>In view of this master plan, the following main research activities are pursued:<br\/>(1) development of a formal property-based language for specifying requirements, including behavioral, temporal, and structural constraints; supported by effective algorithms for the analysis of large specifications for consistency and realizability; development of a methodology for the automatic synthesis of an executable specification from the requirements specification language, to be used both for checking the realizability of large specifications, and the automatic construction of selected modules of the design; and (3) development of methods for the verification of the intermediate representations of the systems against requirements, using the techniques of translation validation. The property-based development approach has been recently applied successfully to the derivation of hardware designs. In view of this success, the application to the systematic construction of embedded systems is highly promising. This research pursues the generalization of the specification language to include real-time elements and continuous signals, and extends the synthesis approach to accommodate real-time and hybrid systems. With these capabilities, this project is expected to enable systematic co-design of software\/hardware for the construction of embedded systems.","title":"Collaborative Research: CSR--EHS: Property-Based Development of Reactive and Embedded Systems","awardID":"0720581","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["409234","417591"],"PO":["493916"]},"129387":{"abstract":"This project investigates the design and applications of Autonomous Mobile Underwater SEnsor networks (AMUSE) consisting of a variable number of sonars (sensors) and vehicles that are deployed to perform collaborative tasks over a given area. Underwater acoustic sensor networks (UWA-SNs) are envisioned to enable applications for environmental monitoring of physical and chemical\/biological indicators, tactical surveillance, disaster prevention, undersea exploration, and assisted navigation, etc. The major tasks under exploration include UWA-SN self-organization and deployment, self-reconfiguring (MAC, physical layer, and cross-layer design), and mission-aware waveform design\/diversity with applications to target recognition, target tracking, and event detection. The AMUSE project is motivated by and targets to solve the following challenges: 1) the sensors in UWA-SN are expensive and mobile, therefore sound self-organization and self-deployment algorithms are needed; 2) waveform design and diversity for UWA-SNs with active sonars are still in its infancy; 3) the transmit and receive data rates are highly asymmetric, which requires new MAC layer design; 4) the underwater channel is impaired by fading, multipath, and doppler shift; 5) the GPS receivers do not work properly in underwater, thus new localization\/navigation algorithms are required.<br\/><br\/>The success of the AMUSE project is able to benefit the two areas of urgent national interests: (1) Instrumentation for monitoring\/prediction of natural ocean disasters including storm surges, hurricanes, tsunami, etc. (2) Harbor environments and security. In addition, this project can serve as a vehicle to promote cross-disciplinary graduate and undergraduate research and education, and to encourage the participation of under-represented and female students.","title":"Collaborative Research: NOSS: Autonomous Mobile Underwater SEnsor networks (AMUSE): Design and Applications","awardID":"0721515","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["531713"],"PO":["564993"]},"129398":{"abstract":"It has long been recognized that the Internet lacks the flexibility to provide enhanced services. While proposals to augment the Internet abound, efforts to modify its infrastructure have essentially failed. As a response, overlay networking gained attention as a viable an approach to provide enhanced Internet services. Another response has been the push to define a new clean-slate Internet architecture. Network virtualization is emerging as a promising new central feature of the future Internet architecture. Interestingly, but perhaps not surprisingly, the use of overlay networking in the current Internet, as well as the potential deployment of network virtualization in a future Internet both result in what we dub as multi-layered networks. The goal of this project is to undertake a systematic investigation of this paradigm, focusing primarily on routing functions. The research aims to provide a unified understanding that will be applicable in both current and future Internet environments. The project also aims to articulate fundamental differences between current and future environments that will affect how we use or design multi-layered networks. A central concern is the interaction between routing protocols in the multiple layers. <br\/><br\/>Broader Impact: Since the project considers both the current and a future Internet, results from this project will more broadly help improve our understanding of network virtualization in a future Internet and how it can achieve its full potential. The PI is also committed to activities with additional broader impact including: development of modules based on our research for classes and continued emphasis on inclusion of under-represented groups within the research.","title":"Nets-NBD: Routing in Multi-Layered Networks","awardID":"0721559","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550428"],"PO":["565090"]},"129189":{"abstract":"The objective of this SGER project is to pursue novel and radical approaches to investigate fundamental issues related to critical infrastructure protection and enable reliable delivery of legitimate traffic to end-users, even when the system is under attack. It is the tenet of this research project that these goals are best met using the concept of Dynamic Data-Driven Application Systems (DDDAS), as it provides the foundation for the development of a dynamic, data-driven intrusion detection systems for high-performance collaborative environments.<br\/><br\/>The proposed exploratory research focuses on four fundamental research thrusts: Dynamic, collaborative defense infrastructure for intrusion detection and response, comprising of a network of peers, dynamically and collaboratively defend against intrusions and denial of service attacks based on resource efficient algorithms for probabilistic inspection of packets for detection and algorithms for collaborative sentinel deployment to guarantees optimal network coverage for scalable response to attacks.<br\/><br\/>Data Driving the IDS -Intrusion Assessment Information Base (IAIB): We propose development of an information base (repository of assessment trees) that will be used to assist the detection and defense process. And Algorithms and Framework for Collaborative IDS for Disruption Detection, Containment & Recovery, explored within the paradigm of DDDAS, allowing exploration of the feasibility and design requirements of distributed mechanisms for intrusion isolation, damage containment and adaptive recovery.<br\/><br\/>Network security is of increasing concern, and static methods to address security are limiting. The project brings technical aspects traditionally disjoint, and integrates interdisciplinary work from various disciplines including probabilistic algorithms, AI techniques, data bases, networks and collaborative systems, and driven the DDDAS concept. The proposed methods and systems software capabilities can have impact on fundamental issues how to architect security in systems in an adaptive way. The project includes education and outreach plans. Additional broader impacts include advancing the state of the art in the stated scope of the project is important, and the project has the potential to set directions for future and novel methods.","title":"CSR: SGER: Dynamic Data Driven Defense Mechanisms for Cybersecurity","awardID":"0720737","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["531589","531589","194325","466424","456313"],"PO":["432103"]},"134590":{"abstract":"Proposal No: 0747477<br\/>PI: Laurent Itti<br\/><br\/>Award Abstract:<br\/><br\/>This award supports the preparation and sharing of computational neuroscience data as part of an exploratory activity aimed at catalyzing rapid and innovative advances in computational neuroscience and related fields. The data to be shared in this project are recordings of eye movements of subjects watching video clips under natural free viewing conditions. Data will be made available in both raw and processed forms, along with the corresponding video stimuli. Code will be provided for calibration of traces. Code, training data, and validation data will be provided to facilitate the development of prediction algorithms. These data were originally collected for development of an information-theoretic model of visual saliency and visual attention. It is anticipated that they will be useful for a broad range of questions in neuroscience, cognitive psychology, and computer vision. Saliency maps and raw feature maps tied to the information-theoretic model will also be made available, to allow users interested in quantifying which low-level visual features may more strongly attract human attention and gaze to easily perform quantitative analyses.","title":"CRCNS data sharing: Human eye movements under natural free viewing","awardID":"0747477","effectiveDate":"2007-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["549488"],"PO":["564318"]},"126560":{"abstract":"Proposal #: CNS 07-08797 07-08856<br\/>PI(s): Chapman, Barbara Gao, Guang R.<br\/>Institution: University of Houston University of Delaware<br\/> Houston, TX 77204-2015 Newark, DE 19716-1551<br\/>Title: Planning: A Research Compiler Infrastructure Based on Open64<br\/><br\/>This collaborative project, laying the groundwork for building, deploying, and demonstrating the usage of a robust and extensible parallelizing\/optimizing compiler and runtime software infrastructure (mainly for high-end computing), facilitates the preparation of a future community resource for a variety of computer science research. Present work often relies on source-to-source transformation that ignores the effect of code generation, or addresses only one language. However, since new architectures imply challenges for languages, compilers, and tools as impending architectures incorporate an unprecedented amount of parallelism in the form of chip multithreading, shared memory parallelism, and clusters, the community can benefit from higher levels of integration between compilers and a variety of tools and other utilities in a programming environment. The project extends work based on the Open64 compiler suite, a robust, industry quality, state-of-the-art optimizing and parallelizing compiler that permits end-to-end experimentation and compiler research at all levels, including advanced computer architectures, parallel programming languages, compiler\/runtime software, system software, application development, performance modeling\/tuning, as well as grid computing. The work involves assessing the needs of other groups to address the challenges posed by increasingly complex programming paradigms and architectures.<br\/>This planning project will develop a strategy for creating an open source, robust compiler framework that enables research on existing and future technologies, supports real-world experimentation with existing and novel language features, and provides the means for interaction with programming tools and environments.<br\/><br\/>Broader Impacts: Reducing the effort in performing realistic compiler related experiments, the planned infrastructure should make compiler technologies broadly available. Moreover, it will be used as a teaching platform for courses and outreach education programs.","title":"CRI: Planning A Research Compiler Infrastructure Based on Open64","awardID":"0708797","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":["506602"],"PO":["557609"]},"127440":{"abstract":"Context<br\/>The recent loss of lives, and traffic jams stretching for tens of miles as hurricanes Rita and Katrina approached the Gulf Coast demonstrate the difficulty of evacuating urban areas. Mass evacuations are among the most difficult problem areas in Transportation Science because they violate key assumptions underlying traditional theories, e.g., Wardrop equilibrium among selfish commuters. A key challenge in this domain is to develop an understanding of non-equilibrium traffic dynamics over transportation networks to aid in the design of emergency traffic management techniques. This is a formidable task due to the data-intensive nature of the problem, and the semantic gap between current database management systems and transportation science. The goal of this project is to research novel and scalable data management concepts in partnership with the development of novel transportation science models and theories to understand emergency traffic. New collaborative computer science research is proposed to probe innovative database concepts underlying network non-equilibrium dynamics data and queries.<br\/><br\/>Intellectual Merit<br\/>These approaches to time-variant graphs and spatio-temporal database support for flow networks significantly differ from the traditional approaches in the database literature. Th project is expected to create innovations in the following areas: 1) graph-aggregates, a novel representation of time-varying graphs, 2) database support for flow network operations, e.g. min-cut, and max-flow, 3) the proposed database concepts will be designed and evaluated in collaboration with domain scientists and professionals using grand challenge problems (e.g., emergency traffic management) and datasets (e.g. large urban evacuation scenarios, population distributions, and flow networks). The hope is to significantly enhance scientists' ability to understand and manage non-equilibrium network behavior, not only in Transportation Science, but also in many other important domains including logistics, telecommunication networks, electric power grids, and distribution networks for gas, water, etc. <br\/><br\/>Broader Impact<br\/>Teaching materials (e.g., slides, software prototypes) to facilitate incorporation of research results in courses and classroom activities will be prepared. This project will broaden the participation of underrepresented groups at many levels: one PI has a track record of participation in summer institutes involving undergraduate students from historically black colleges and universities. If successful, the results wil benefit society by reducing evacuation time, which may save lives and reduce exposure of vulnerable populations in the face of man-made and\/or natural disasters.","title":"III-CXT: Spatio-temporal Graph Databases for Transportation Science","awardID":"0713214","effectiveDate":"2007-08-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["454844","550903"],"PO":["543481"]},"127462":{"abstract":"Representation and planning for complex physical tasks involving spatial relationships are key challenges facing the robotics community. This project proposes to develop new theoretical and algorithmic approaches to important cases of these challenges. The researchers will apply a new, general geometric and topological approach to the study of system parameterization, constraint formulation, and configuration space structures of linkage systems. They will also develop and perform benchmark evaluations of motion planning algorithms. While this project focuses on manipulation systems and knots, the addressed issues and developed techniques will be applicable to a wide range of linkages including both physical linkages (such as articulated robots or protein molecules) and virtual linkages (such as groups of points or swarms of mini-robots) under various kinds of geometric constraints. The project will also contribute to the development of human infrastructure in science and technology, by allowing the researchers to continue and expand their successful training and involvement of undergraduate students in mathematical and algorithmic aspects of robotics research.","title":"RI: Practical Parametrization and Efficient Motion Planning of Linkage Systems","awardID":"0713335","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[338023,"456147"],"PO":["543539"]},"127474":{"abstract":"Context<br\/>The goal of this grant is to 1) form a computer-aided system to improve decision-making for traumatic pelvic injuries and 2) support research on a number of data integration topics in computer science. Trauma is the leading cause of death for Americans under the age of 45. Traumatic pelvic injuries can be fatal due to severe hemorrhage, and care givers treating these injuries need to consider several types of data, including biomedical signals, images, trauma scores, laboratory results, diagnosis\/treatment, injury specifics, and demographics during the decision making process. Integrating simple types of data such as lab results and demographics is not easy, but the decision-making process shows its true complexity when trying to integrate more complex types of patient data such as biomedical signals and images. <br\/><br\/>Intellectual Merit<br\/>The project is challenging in the following aspects: <br\/>o It constructs a traumatic pelvic injury database that includes all relevant biomedical signals\/images, trauma scores, lab results, diagnosis, treatment, demographics, and injury specifics for each patient. This database will have two significant advantages over existing databases: 1) it will contain not only patient demographics and trauma scores but also time-series (signals) of physiological measures and images; and 2) in the new database, instead of including only raw data, patient information is processed and transformed into a set of features that can be directly used for decision making. <br\/>o A variety of novel biomedical signal and image processing methods will be formed to extract relevant features. These computational methods will include both the improved versions of computational methods in signal and image processing (e.g., segmentation techniques for CT images), and feature extraction methods for specific signals and images (e.g., defining the total area of the pelvic ring captured from CT as a feature). <br\/>o The project constructs a rule database where all derived features for patients in the feature database are analyzed with outcomes, resulting in a set of rules to describe logical relationships among the input features and resulting outcomes\/recommendations, using non-linear classification and regression tree. The project is novel in its rule validation; besides using typical statistical methods such as cross-validation and measures of sensitivity and specificity used in existing systems, a new statistical framework based on computational learning theory will be used to allow a more comprehensive comparison of the new system with other methods such as neural networks and Bayesian classifiers.<br\/><br\/>Broader Impacts<br\/>This project brings together computer scientists with trauma experts and will produce a system that can be replicated at other hospital systems. This methodology can be used for other types of trauma cases, such as brain injuries. Educationally, project results will be included in regular seminars to teach healthcare providers across the spectrum of the trauma care the latest techniques used in trauma care. The PI will align the research project with undergraduate and graduate research and outreach activities managed by the University of North Carolina at Charlotte''s Diversity in IT Institute, whose mission is to increase enrollment and retention of women and underrepresented groups within IT with a focus on facilitating graduate and undergraduate interdisciplinary programs, and two NSF-funded programs housed within the institute: 1) The Students & Technology in Academia, Research, and Service Alliance: A Southeastern Partnership for Broadening Participation in Computing, and 2) Computing Research for Undergraduates.","title":"III-CXT: Information Integration and Processing for Computer-Aided Trauma Decision Making","awardID":"0713419","effectiveDate":"2007-08-01","expirationDate":"2007-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[338051,"363602"],"PO":["371077"]},"127254":{"abstract":"Proposal 0712253 <br\/>PI: Amit Roy Chowdhury<br\/>Institution: University of California - Riverside<br\/>Co-PI: Gopi Meenakshisundaram<br\/>Institution: University of California - Irvine<br\/><br\/>Title: Integrating Illumination, Motion and Shape Models for Video Analysis<br\/><br\/>This project involves a fundamental research program in video analysis that is built upon a novel framework for integrating different independent modalities of image formation - illumination conditions, object shape, motion and surface reflectance. We focus on the problem of pose and illumination invariant object recognition in video, based on learned models of lighting, motion and shape. We also develop novel scene relighting methods using the illumination models learned from natural videos. The proposed research proceeds by first developing a mathematical framework that relates the appearance of a video sequence with the lighting conditions, motion of the objects being imaged, and their shape and surface properties. Thereafter, it addresses the inverse problem of recognition from video. The overall mathematical approach is to combine precise geometrical models with statistical data analysis tools, thus combining accuracy and robustness.<br\/><br\/>This research will benefit a large number of existing applications and create new ones that rely on efficient object tracking under changing environmental conditions. They include applications in national priority areas like homeland security, monitoring of nuclear installations and border security, in commercial interests like video communications, multimedia databases and entertainment, in social causes like wildlife and environmental monitoring, and in medical and biological applications relying on video analysis. Scene relighting by learning the motion and illumination of objects from natural videos will also have a significant impact in creation of realistic virtual environments.<br\/><br\/>Progress on this project will be regularly updated at http:\/\/www.ee.ucr.edu\/~amitrc\/JMIS.htm","title":"RI: Integrating Illumination, Motion and Shape Models for Video Analysis","awardID":"0712253","effectiveDate":"2007-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["370962","553702"],"PO":["564316"]},"129102":{"abstract":"Time predictability is vital to the correctness of hard real-time and safety-critical systems, such as automotive and aircraft control systems. However, the architectural design of modern microprocessors has mainly concentrated on improving the average-case performance by using techniques such as cache memory, branch prediction, and speculative execution, which can significantly compromise the time predictability of computing and make the accurate worst-case execution time (WCET) analysis extremely difficult. This project is designing a highly time-predictable VLIW architecture while keeping the advantages of VLIW architectures in terms of high performance and hardware simplicity. The project also studies novel compiler techniques to support the time-predictable VLIW architecture, including scheduling-aware scratch-pad memory management, full and partial if-conversion with implicit path enumeration (IPE), compiler-directed nop insertion to remove pipeline timing effects, and WCET-oriented compiler optimizations. The success of this project is expected to accelerate the design, implementation, and deployment of time-predictable VLIW processors for a wide range of hard real-time applications, which can benefit both the embedded processor industry and the society. The developed software packages are made publicly available through the PI's research website.","title":"CSR---EHS: A VLIW Architecture and Compiler Framework for Time Predictability","awardID":"0720502","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["121660"],"PO":["561889"]},"129223":{"abstract":"This project has the goal of developing a new family of embedded architectures optimized specifically for feed-back digital (software) controllers, with the aim of decreasing the required power by more than an order of magnitude and delivering real-time performance at levels that currently cannot be achieved from software. This is done by exploiting many kinds of redundancies peculiar to feedback controllers but that are not exploited by any current processing architecture. The work is in collaboration with on-site micro-electro-mechanical systems (MEMS) researchers to develop practical solutions for software control in that environment. The broader impact of this work also includes the development of better architectural design metrics applicable to control system design as well as opening new engineering areas to the benefits of low-power digital control. Since much of this work can be tested in FPGA emulation, we plan to include the participation of undergraduates in the construction of multi-threaded controller software to test these ideas using tools developed for this work.","title":"CSR---EHS: Low Power, High Performance, Embedded Digital Feedback Control","awardID":"0720840","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["384054"],"PO":["561889"]},"128134":{"abstract":"CT-ER: On the Use of Security Metrics to Identify and Rank the Risk of Vulnerability- and Exploit-Prone Components<br\/>Decades of software engineering research has shown the effectiveness of the use software metrics to identify fault- and failure-prone components and to predict the overall quality of a system early in the software development lifecycle. Software development organizations use this knowledge to prioritize their redesign and validation and verification efforts. In this research, we extend this work to examine the corresponding power of software security metrics to effectively identify vulnerability-prone and exploit-prone components early in the software development lifecycle. The technical objective of this research is to create and validate a predictive model that uses security metrics to identify and rank the risk of vulnerability-prone and exploit-prone components in a software product. The results of this model can be used to inform risk management and to prioritize re-design and validation and verification efforts in the later phases of the life cycle. The expected result from guiding software development efforts via the predictive model is the production of more secure software. The educational objective is to incorporate these research results into resources for educating students to engineer secure software products.","title":"CT-ER: On the Use of Security Metrics to Identify and Rank the Risk of Vulnerability- and Exploit-Prone Components","awardID":"0716176","effectiveDate":"2007-08-01","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["549909"],"PO":["529429"]},"129465":{"abstract":"As data communication has become increasingly important to our society, demands on the networking infrastructure have reached a point where it is desirable to implement an optical packet switching core. The prohibitive cost of large optical buffers has lead to many optical network designs with small buffers on routers. A major challenge in this context is to envision efficient operation scenarios that justify these small buffer networks. This project aims at developing an architecture that implements packet spacing on network links such that suitable statistical properties of network traffic can be ensured and small-buffer networks can be operated efficiently. The specific goals of this project are: (1) understanding of packet spacing and its network-wide impact, (2) development of a pacing node prototype, and (3) consideration of network-wide deployment. The packet spacing architecture developed in this project can help in promoting the broad deployment of optical packet switching technology.<br\/>Intellectual Merit: The intellectual merit of this project includes three aspects. First, the research will further our understanding of the impact of packet spacing on the whole network (rather than being limited to a single buffer analysis). Second, the pacing architecture will help improve the efficiency of operation of optical core networks and thus improve the Internet as a whole. Third, the cross-disciplinary research covering queuing analysis, network measurements, system design, and prototype implementation and deployment sets up an agenda to address real-world network issues.<br\/>Broader Impact: Guarantees on traffic statistics that a packet pacing architecture can provide are an essential step in the process to convince the Internet community, especially Internet service providers, to adopt and deploy optical networks. A wide-spread adoption of such networks in the U.S. could increase the availability of high-bandwidth data communication and improve wide-spread access to modern communication services and applications.","title":"NeTS-NBD: Packet Spacing in Small-Buffer Networks","awardID":"0721790","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["526867","485542"],"PO":["565090"]},"129113":{"abstract":"The goal of this project is to lay out strategies and abstractions for developing lower-level system modeling and parameter tuning techniques, and for linking these to higher-level architectural and system management approaches. The project also aims to back existing post-manufacturing tuning techniques with deeper analytic methods, and to augment these one-time adjustments with more dynamic management techniques that are ongoing as the system is in use. To make the shift from very static (one-time) tuning towards very dynamic (ongoing) power-performance tuning, one needs models whose detail and abstraction vary. This allows fast, but abstract models to be used dynamically by the operating system, in order to dynamically adjust power\/thermal behavior in order to stay within budget while also meeting performance goals. Microarchitectural techniques can also be employed, but likewise need to be informed by good models and measurement techniques to guide their use. The project will address these modeling issues and the associated on-the-fly management techniques.<br\/><br\/>The research program pursues broad impact in several ways. First, the project has an important component for knowledge dissemination and technology transfer. The modeling and management techniques proposed in this project will be disseminated and released for free use. Building on a record of strong support for undergraduate research and underrepresented groups, the PIs will continue and broaden such activities through this collaboration. Because of the geographic proximity of CMU and Princeton, group meetings unifying the two efforts will be possible throughout the project.","title":"Collaborative Research: CSR---EHS: Cross-System Modeling and Management for Variation-Adaptive Computing","awardID":"0720529","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554462"],"PO":["561889"]},"129234":{"abstract":"This project is developing new methods for coverage-driven directed automatic test generation for real-time embedded systems. The research addresses both, the theoretical foundations of automatic test generation, and practical test and coverage tools for real-time embedded systems. Many signals affecting system behavior may not be observable, or may be difficult to measure online without affecting system behavior, and the system itself may not be easily reset to an initial state to drive different tests. In this research, tasks in the system are modeled as event automata, and the joint event automaton represents the composition of event automata for all tasks in the system. The research is exploring game and control-theoretic techniques to synthesize, from an automatically constructed abstract interaction graph of the implementation, a test director. The test director introduces variable delays in the execution of the system such that a maximal number of coverage goals are met. A testing tool, DIRECT, implements directed real-time testing for embedded systems, combining static analysis (interaction graph construction), control theory (test director construction) and dynamic analysis (online system monitoring in the presence of the test director) to achieve high interaction coverage. In particular, these problems would be studied in a resource-constrained setting, where both online measurements and test director implementation must be optimized for time and space. The tools and techniques would be evaluated on two testbeds available to us: an embedded development platform on top of Lego Mindstorm robots developed by one of the PIs at UC Santa Cruz and a sensor board for marine tracking developed at UC Santa Cruz.","title":"CSR---EHS: Collaborative: Directed Real-Time Testing","awardID":"0720881","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["460594"],"PO":["561889"]},"128145":{"abstract":"Tele-healthcare could largely reduce national healthcare cost through remote self-managed patient monitoring. Cardiac Sensor Networks (CSNs) could be used to deploy such a system. Moreover, the integration of RFID into CSN could play an important role for elder healthcare because RFID could be used to monitor elders' medicine taking behaviors. On the other hand, the disclosure of RFID information during RFID tag-to-reader communications can cause the violation of patients' privacy. This research aims to achieve trustworthiness in a practical RFID-assisted CSN platform. This project will make the following three contributions: (1) Error-resistant ECG transmission: A trustworthy CSN should be able to overcome the impacts of radio interference and propagation distortions that can lead to frequent ECG transmission errors. This research will use the receiver-only local ECG processing to overcome ECG errors\/loss. It will conduct a comparative study of two promising anti-interference methods, Kalman Filter and Tempo-spatial Regression. (2) Low-overhead RFID security: This research will design a lightweight RFID security scheme based on Linear Congruential Generator (LCG) and a mutual authentication scheme. The RFID security will be tested in our current CSN hardware platform. (3) CSN temporal accountability: In ECG sensor applications, all ECG anomaly detections depend on accountable time interval analysis between different ECG signal segments. This research will achieve CSN temporal accountability through the following two technical approaches: i) design a receiver-only clock uncertainty prediction model to avoid wireless communication overhead; and ii) design a history-aware, reputation based trust model to capture the evolutionary timing attacks.","title":"Collaborative Research: CT-ISG: Error-resistant, Accountable, RFID-assisted Wireless Sensor Networks for Elder Cardiac Tele-Healthcare","awardID":"0716211","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["472085"],"PO":["497499"]},"129597":{"abstract":"The Team proposes to use Social Robotics as a mechanism to deliver a revitalized Computer Science (CS) education. Robots are a fantastic platform for students to learn key CS concepts, begin to program and get immediate feedback, and to learn about both hardware and software, and the interplay between the two. Robotics has a widespread base of appeal to students, academics and the general public alike. A Social Robot is one that interacts and communicates with humans by following the social rules attached to its role. The role and its rules are defined through society. For example, a robotic waiter would have to comply with established rules of good service. It should be anticipating, reliable and most of all discreet. A social robot must be aware of these rules and comply with them. There are many aspects to the evolution of Social Robots, which need to draw on elements of Design, Psychology, Cognitive Science, Communication and Philosophy in addition to, and in harmony with, traditional Computer Science and Engineering principles. The multi-school team plans to use this proposal to build a community of stakeholders in Social Robotics in the Capital Region of upstate New York. On top of planned regular meetings, and the gathering and collection of information, they will hold four open workshops at a local public Museum, to bring together the stakeholders with academics, students, and representatives from industry and members of the public, to outline a program in Social Robotics. The central aim of the program is to design alternative mechanisms of entry into, and routes through, a Social Robotics curriculum designed to enable students with a wide variety of skills and interests to interact. Both Pull mechanisms, drawing students into a Computer Science program and Push mechanisms, to deliver key concepts in other majors are planned. This plan leverages the collaboration of schools and colleges in the Capital region, as no one school is ideally placed to deliver such an education. The outcome of this proposal will be a plan of implementing a program in Social robotics, which can be implemented both locally, and nationally.","title":"CPATH CB: Social Robotics","awardID":"0722277","effectiveDate":"2007-08-01","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["443288","543064",343459,343460,343461,343462],"PO":["565136"]},"129245":{"abstract":"Computer-aided-design systems for digital circuits interfaces with computing technologies and fabrication processes that exhibit high levels of variations, defect densities and noise susceptibility. A direct extrapolation and ad-hoc application of existing defect-tolerance (DT) and fault-tolerance (FT) techniques erodes much of the benefits of new technologies. The objective of this research is to develop a systematic framework for design and test of digital systems that optimizes a specified combination of cost, performance and power for nanometer technologies.<br\/><br\/>A framework for efficient application of existing and new DT and FT techniques, including the use of spares, task rescheduling, coding and DFM rules is being developed. This framework works in conjunction with existing design flows and includes components spanning the levels of technology (variations\/defects), layout, circuit, logic, architecture and system. Key innovations are embodied in new techniques for identifying efficient ways of assigning spares, reconfiguring around faulty modules, and modifying selected parts of a module to improve yield. To obtain optimality, a design explorer is being developed to efficiently search the space of alternative designs. <br\/>This research will provide the first framework for design of digital systems for the remaining years of CMOS scaling and beyond. We will train graduate and undergraduate students in this methodology of the future and share our results with academic and industrial colleagues. <br\/><br\/>This research will provide immense benefits to society by being a key enabler of an era of inexpensive and powerful digital devices with significant educational, health and security functions.","title":"CSR---SMA: A CAD framework to support the effective application of redundancy at the switch\/architectural level for future technologies having high defect rates and variations","awardID":"0720909","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["451942","535238"],"PO":["493916"]},"129487":{"abstract":"In this project, the researchers will pursue new algorithmic and mathematical tools that may redesign the basic components of a new Internet architecture, starting from a clean slate, rather than finding incremental solutions, compatible to the legacy infrastructure. This approach will introduce rather radical and unconventional approaches. In fact, the work is inspired by the work that is done, almost entirely, outside of the networking community. Specifically, they plan to leverage a number of algorithmic breakthroughs in the fields of learning theory, combinatorial optimization, distributed computing, and online algorithms that provide a different perspective for designing many components of a new Internet architecture.<br\/><br\/>Since the topologies, traffic patterns, and application requirements on future clean-slate networks are highly uncertain at the moment, this suggests creating a technology-independent architecture of the future Internet, with the emphasis on solving basic intellectual challenges in a rigorous analytical way. The researchers will thus pursue a systematic study of technology-independent, theoretically-validated, and model-independent components of the future Internet architecture.<br\/><br\/>In this proposal, the researchers will focus on the basic architectural components, such as maintaining the Routing Metric and designing proper flow control mechanisms. These components must be capable of supporting heterogeneous resources allocation, including the wireless periphery. Additional important consideration is security: protecting the routing structure against Denial-of-Service (DoS) and potentially even Byzantine attacks. They issues are closely related to each other. For example flow control must ensure stability of distributed load sensitive re-routing which is essential for security.<br\/><br\/>Broader Impact: As a result of this work, the future Internet will be much more robust, both in terms of security and in terms of ability to support applications with quality of service guarantees. Many applications, e.g., medical teleconferencing, virtual classrooms, military applications and others will be enabled by new Internet architecture. These new applications will have broad impacts on society as a whole.","title":"FIND Algorithmic Foundation for Future Internet","awardID":"0721877","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[343097,"530045",343099],"PO":["565090"]},"129179":{"abstract":"3D tele-immersive collaborative environments are becoming a reality. The emerging tele-immersive (TI) technology empowers and enables collaborative interactions and a plethora of new applications among geographically distributed sites. TI technology allows creation of a cyber TI room, where geographically separated users can jointly perform physical activities such as dance or exercise. This project is working to take this vision further and allow users to participate in simultaneous TI sessions and to cyber-walk between TI rooms. To achieve the TI rooms vision, the underlying cyber-physical infrastructure must consider both (a) streams of 3D data as a first class object in its design and in its deployment, and (b) holistic end-to-end management of the multi-stream environments for each TI room. Hence, the project is developing a Holistic Multi-stream Environment for Distributed Immersive Applications (H-MEDIA). They will investigate (a) system architectures with correlated multi-streaming; (b) real-time virtualization of resources for resource isolation between individual TI rooms and switching (cyber-walk) between rooms; (c) end-to-end configurable, robust and fault-tolerant virtual networks for different rooms; and (d) adaptive configuration and system management that will yield customizable, stable, adaptable, available and robust individual TI rooms. H-MEDIA research will have impact on communities in computer science and also on medical, social science and other domains. The H-MEDIA project will also result in educational benefits such as involving graduate students research in very novel TI technologies, inclusion of undergraduate students, and impact on education in other disciplines such as new teaching of choreography in TI environments, as well as many others.","title":"CSR-- EHS: Collaborative Research: H-Media: The Holistic-Multistream Environment for Distributed Immersive Applications","awardID":"0720702","effectiveDate":"2007-08-01","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["563534","561784","542023"],"PO":["561889"]},"133590":{"abstract":"Typically when a teacher wants to probe a student's understanding of a concept, she asks him to write about it. In science students write lab reports, in reading they write book reports; even in math, students often have to write how they solved the math problem. Unfortunately, many students do not enjoy writing and therefore do not necessarily give the teacher the insight she is looking for. In currently funded NSF work at Tufts University, researchers are developing a software toolset that allows students to build stop action movies (SAM) as a means for representing ideas about math and science. SAM is not meant to replace the standard reporting methods, but rather to augment them. Tufts investigators, looking at how students learn differently as a result of the difference in reporting mechanism, are finding that animation can even motivate and drive the learning (because students want to improve their movies). This ongoing work has reached the halfway point, and is starting to show preliminary successes in the classroom. Changing the reporting methodology has resulted in students being excited about coming to class. They willingly stay after class to complete their \"reports\", and will actively discuss the science they are learning with each other and with the teacher. This exploratory grant will allow the PI to join the Tufts team, as it were, so that the project can branch out into other learning environments while still in the development stage. The PI will extend the research to non-school-based learning environments, with particular concentration on reaching out to African-American and Latino communities. The timing of this work is critical for both institutions, and the results will be mutually beneficial. Outcomes of this exploratory project will enable Tufts to improve the user interface while their SAM software is still in development, and thereby potentially open up a new learning market. UCSD, on the other hand, will acquire new tools to teach logical thinking and elementary programming to disadvantaged populations, exploiting the substantial infrastructure and expertise they already have in place. <br\/><br\/>Broader Impacts: This research will extend the SAM approach into non-traditional educational settings (e.g., the after-school learning environment) for disadvantaged students, and will further help our understanding in general of how kids learn in different environments.","title":"Growing SAM: Bringing Animation into Informal STEM Educational Settings","awardID":"0742069","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[355215],"PO":["565227"]},"122271":{"abstract":"CCF-0642911<br\/><br\/>CAREER: A Framework for Customizable Program Flow Analysis<br\/><br\/>Ana Milanova<br\/><br\/>Today's software systems are large, complex and costly and research on program flow analysis for software productivity and software quality is increasingly relevant. Tools based on flow analysis can aid and improve software tasks such as development, testing, program understanding, verification, debugging, reverse engineering, and restructuring. This wide variety of tasks demands a wide variety of customized flow analyses with different degrees of precision and cost.<br\/><br\/>This research builds technology that will allow specifying and developing customized flow analyses that support software tasks on large and complex software systems. There are three contributions. First, we develop the theory of contextual set constraints, a flexible declarative formalism for specifying flow analyses. Second, we design and implement a novel engine for resolution of set constraint which takes advantage of efficient Binary Decision Diagram (BDD) technology for set representation and set manipulation. Third, we build an analysis framework based on contextual set constraints and efficient constraint resolution. The framework is used to specify and develop new flow analyses that target long-standing problems related to software security and software dependability.","title":"CAREER: A Framework For Customizable Program Flow Analysis","awardID":"0642911","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550382"],"PO":["523800"]},"126671":{"abstract":"Abstract <br\/>Proposal #: CNS 07-09140 07-08307 07-08820 <br\/>PI(s): Brockman, Jay B. Bader, David A. Gao, Guang R. <br\/>Barabasi,Albert-Laszlo;Chawla,Nitesh;Kogge,PeterM. Vetter, Jeffrey S. <br\/>Institution: University of Notre Dame Georgia Institute Tech U.Delaware <br\/>Notre Dame, IN 46556-5602 Atlanta, GA 30332-0002 Newark, DE 19716-1551 <br\/>Proposal #: CNS 07-09385 07-09111 07-09254 <br\/>PI(s): Gilbert, John R. Upchurch, Edwin T. Yelick, Katherine A. <br\/>Wolski, Richard. <br\/>Institution: UC-Santa Barbara California Inst Tech UC-Berkeley <br\/>Santa Barbara, CA 93106-2050 Pasadena, CA 91125-0600 Berkeley, CA 94704-5940 <br\/>Title: Colla Rsch:IAD:Dev Rsch Infr. for Multithreaded Computing Community Using Cray Eldorado Platform <br\/><br\/>Project Proposed: <br\/><br\/>This collaborative project, developing a shared infrastructure needed to broaden its impact for developing software to run on the next generation of computer hardware, brings a diverse group of researchers from six universities in a joint effort. The work responds to the trend towards multicore processors where developers envision placing tens to hundreds of cores on a single die, each running multiple threads (in contrast to the currently dominant message-passing architectures resulting from the advent of MPI and Linux clusters). Three objectives are proposed: <br\/>. Acquiring computer hardware as a shared community resource capable of efficiently running, in experimental and production modes, complex programs with thousands of threads in shared memory; <br\/>. Assembling software infrastructure for developing and measuring performance of programs running on the hardware; and <br\/>. Building stronger ties between the people themselves, creating ways for researchers at the partner institutions to collaborate and communicate their findings to the broader community. <br\/>The Cray XMT system, scheduled for delivery in 2007 serves as an ideal platform. The second bullet includes algorithms, data sets, libraries, languages, tools, and simulators to evaluate performance of program running on the hardware focusing on applications that benefit from large numbers of threats, massively data intensive, \"\"sparse-graph\"\" problems that are difficult to parallelize using conventional message-passing on clusters. Each university contributes a piece to the infrastructure, using it for support of projects. Sandia National Laboratories has agreed to host the system and provide supplementary funding. Each university will use the Cray XMT system in courses. <br\/><br\/>Broader Impacts: The infrastructure measures performance providing a basis for the community to improve sharin, and build strong ties for collaboration and communication. Courses will be created and materials will be made available. Workshops for dissemination of the findings are also planned.","title":"Collaborative Research: CRI: IAD Development of a Research Infrastructure for the Multithreaded Computing Community Using the Cray Eldorado Platform","awardID":"0709385","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["436116","402357"],"PO":["557609"]},"126330":{"abstract":"Few methods exist for automated RNA motif discovery, due to the difficulty in predicting correct RNA structures and doing alignments where substantial computing costs are involved. This project will implement a new tool for motif discovery using algorithmically efficient alignment methods. The first thrust of the proposal is based on an extension of the loop model commonly used in RNA structure prediction. An extended model achieves better efficiency that current algorithms and allows a biologist to annotate conserved regions and incorporate these into the process, thereby obtaining more meaningful results. The second thrust applies the alignment algorithms to feature selection and motif discovery. This is an essential step in RNA mining, choosing a set of significant substructure from a set of molecules. The subset can be used alone or in combination with kernel methods to build new tools for RNA classification and clustering. The work will be validated and can advance interdisciplinary data mining and develop human resources by training graduate and undergraduate students. A new undergraduate course will also be developed, and selected materials also used for high school students.","title":"III-CXT: Structure Comparison and Mining for RNA Genomics","awardID":"0707571","effectiveDate":"2007-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[335170,335171],"PO":["565136"]},"126583":{"abstract":"Proposal #: CNS 07-08498 07-09946 07-08420<br\/>PI(s): Preisig, James C Ye,Wei Stojanovic, Milica<br\/>Lee, Freitag Heidenmann, John S.<br\/>Institution: Woods Hole Oceanographic Inst U Southern California Mass Inst Tech<br\/>Woods Hole, MA 02543-1041 Los Angeles, CA 90089-1147 Cambridge, MA<br\/>02139-4307<br\/>Proposal #: CNS 07-09005 07-08938 07-08467<br\/>PI(s): Cui, Jun-Hong (June) Levine, Brian; Kurose,James F. Freitag, Lee<br\/>Rajasekaran,Sanguthevar;Shi, Zhijie;Willett,Peter K.;Zhou,Shengli<br\/>Institution: University of Connecticut U of Massachusetts WHOI<br\/>Storrs, CT 06269-1133 Amherst, MA 01003-9242 Woods Hole, MA 02543-1041<br\/>Title: Collab Rsch:CRD\/IAD:Open Research Testbed for Underwater Ad Hoc and<br\/>Sensor Networks (ORTUN)<br\/><br\/>This collaborative project, developing the first open testbed infrastructure for the<br\/>underwater networking community, enables open access with the capability to conduct<br\/>experiments remotely. The infrastructure, based on open research platforms, consists of<br\/>a testbed that enables wide and systematic experimental evaluation and comparison of<br\/>underwater acoustic networks. The work, involving this rapidly deployable testbed that<br\/>can be shared by the underwater networking community, aims to demonstrate the ability<br\/>of the facility to facilitate field experiments. The project represents a higher-level<br\/>collaborative that arose from two collaborative groups. One group developing the<br\/>facility, the other working mainly on the experiments utilizing the facility. The testbed is<br\/>expected to be a buoy-based system that can be easily taken to different environments.<br\/>When operational, these systems will be deployed 5 or 6 times a year. The<br\/>infrastructure will consist of two types of nodes with different capabilities. The first type<br\/>of node of the rapidly deployable testbed will offer a fixed physical layer capability using<br\/>acoustic modems such as the WHOI micromodem or the ISI S-modem to implement a<br\/>physical layer with limited reconfigurability interfaced to a reconfigurable network<br\/>processor. This network processor will support algorithm\/protocol implementation and<br\/>testing at higher network layers. The Network functions on the Fixed Physical Layer<br\/>testbed will be hosted by a Gumstix processor which will then communicate with<br\/>physical layer modems such as the WHOI Micromodem or USC\/ISI S-modem via a<br\/>serial port. Ten to fifteen fixed physical layer nodes will be built including up to 3<br\/>gateway nodes. Each gateway node of the testbed will be equipped with wireless RF<br\/>communication enabling real-time monitoring and control of network performance. The<br\/>fixed physical layer nodes will be smaller and more easily deployed than the second<br\/>type of node which is the all-layer node. The all-layer node is a more capable node that<br\/>will ultimately support algorithm\/protocol implementation and acoustic data collection at<br\/>all networking layers. In addition to the equipment included in the fixed physical layer<br\/>nodes (i.e., a gumstix network processor and the ability to support relatively fixed<br\/>physical layer modems such as the WHOI Micromodem and the ISI S-modem), the<br\/>all-layer nodes will also include a general purpose data acquisition system (D\/A and<br\/>A\/D) with substantial disk storage and in-situ processing capability. The MIT r-modem<br\/>software will be implemented on this general purpose hardware and, along with<br\/>MATLAB, will enable user implementation and testing of algorithms and the gathering of<br\/>acoustics data at the physical layer in addition to the testing at higher network layers<br\/>that it will share in common with the fixed physical layer nodes. Three to five all-layer<br\/>nodes will be built. The rapidly deployable testbed, using two types of nodes with<br\/>varying capabilities, should significantly enhance research at all network layers while<br\/>setting the stage for future infrastructure improvements.<br\/><br\/>Many research groups investigating fundamental questions about how to design such<br\/>networked systems that utilize acoustic communications in complex underwater<br\/>environments have had their overall effort significantly slowed by the lack of common<br\/>means to test and compare protocols under realistic environmental conditions. This<br\/>infrastructure responds to the need for consensus on analytic or simulation models for<br\/>underwater networks where researchers need the ability to gather experimental data<br\/>under real world conditions in order to make progress.<br\/><br\/>The network stack will be modular by design with sockets used to enable cross layer<br\/>control and communication. The physical, MAC, Network and Application layers will be<br\/>populated with sample components to enable users test their own algorithms or<br\/>protocols without having to populate the entire stack. Users will be able to write modules<br\/>to test their own algorithms or ","title":"Collaborative Research: CRI: IAD: Developing a Novel Infrastructure for Underwater Acoustic Sensor Networks","awardID":"0708938","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["499259","451830"],"PO":["557609"]},"125142":{"abstract":"Collaborative Proposal ID: 0702343, 0702204<br\/>PI name(s): Subhasish Mitra, Chongwu Zhou<br\/>Institution(s): Stanford University, University of Southerm California<br\/>Title: Design, Modeling, Automation and Experimentation of Imperfection Immune Carbon Nanotube Field Effect Transitor Circuits<br\/><br\/>ABSTRACT:<br\/>One-dimensional nanodevices such as Carbon Nanotube Field-Effect Transistors (CNFETs) are promising candidates as extensions to traditional Silicon transistors due to excellent device performance. Device scaling of silicon transistors has been the fundamental basis for the phenomenal success of the semiconductor and electronics industry. While there have been significant accomplishments in scientific discovery in recent years at the single-device level at the nanoscale, a major gap exists between such single-device-level results and the research required to harness the science into practical design technologies competitive with silicon technologies at the end of device scaling. This project uses an interdisciplinary approach to overcome fundamental challenges by combining novel CNFET-based robust imperfection-immune design and automation techniques together with new CNFET modeling and processing techniques. The ideas developed in this project will be experimentally validated through working CNFET-based circuits. This research program also integrates research and education required to explore novel, nanoscale electronic designs through graduate and undergraduate training, and public education on nanotechnology.","title":"Collaborative Research: Design, Modeling, Automation and Experimentation of","awardID":"0702204","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["442245"],"PO":["562984"]},"125263":{"abstract":"0702724<br\/>Vikram S. Adve<br\/>University of Illinois @ Urbana<br\/><br\/>Most new consumer computers today contain at least two cores, high-end ones have as many as eight, and major vendor road-maps foresee hundreds of cores. To exploit this processing power, parallel computing, once a narrow specialty, must become mainstream. Parallel programming, however, is notoriously difficult. To avoid an expensive decline in programmer productivity, programming languages, libraries, and tools must make parallel programming nearly as easy as sequential programming. One powerful way to achieve this goal will be to enable a deterministic style of parallel programming, meaning that a program is guaranteed to produce the same output whenever it is run with a particular input. Determinism eliminates the hardest problems of parallel programming such as data races and deadlocks. Most importantly, it makes quality assurance easier because only one execution for each input must be tested and because errors are easier to reproduce. While deterministic programming models exist, they have limited expressivity and do not handle most programs written in widely-used languages such as Java and C#.<br\/><br\/>This research is developing simple, expressive language and runtime mechanisms for deterministic parallelism, using a thread-parallel style with aliasing of mutable objects. The design combines recent advances in type systems for declaring and checking memory regions and effects, falling back on runtime speculation in cases that are burdensome or impossible to express using the type system. The project is also developing mechanisms to allow ``locally non-deterministic'' constructs such as associative reductions and commutative data structure updates. Finally, the project will develop experience with writing realistic parallel programs in a deterministic style, to answer many practical questions about the expressivity, ease-of-use, and performance implications of the deterministic language features.","title":"General Language Mechanisms for Deterministic Parallel Programming","awardID":"0702724","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["542046"],"PO":["564388"]},"125274":{"abstract":"Proposal 702764<br\/>A Transformational Approach to Clone Refactoring <br\/>PI - Jeff Gray<br\/><br\/>Surveys indicate that 10% of the code in many commercial applications may contain clones, which represent fragments of code that are duplicated throughout various source files. This presents a maintenance and evolution challenge when a code clone is changed because it is likely that the other corresponding clones require similar adaptation. This research project will investigate program analysis and transformation techniques to support the categorization, selection, and refactoring of code clones. The topic of clone detection has been investigated in the past by many researchers. However, scientific foundations to support analysis and automated transformation of the results reported from a clone detection tool are still lacking and often require a manual approach to clone refactoring. The key focus of this research is an investigation into the foundational analysis and transformation techniques that will provide a software engineer with the proper tool support to increase their productivity while improving the correctness of adaptive changes in the presence of clones. This project has potential for broad impact across many domains in critical application areas (e.g., scientific and ?e-science,? as well as middleware for enterprise software). In addition, contributions toward educational objectives are core to the proposed research plan.","title":"A Transformational Approach to Clone Refactoring","awardID":"0702764","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["440747","555863"],"PO":["564388"]},"125176":{"abstract":"The project investigates the integration of types and verification as complementary techniques for building robust, reliable, and maintainable software. Types provide the foundation for the composition of systems from independently reusable components by providing a rich language of invariants governing programs and data. Verification provides the foundation for reasoning about the run-time behavior of programs, especially their effect on the execution environment.<br\/><br\/>To integrate these two methods the project is developing new dependent type systems capable of expressing behavioral specifications and new methods for checking conformance with such rich type constraints. To ensure that the integration is sound, the project is developing its theoretical foundations using mechanized proof assistants. To assess the practicality of the integration, the project is implementing a programming language that integrates types and verification, and is developing applications that illustrate its use.<br\/><br\/>The primary intellectual contribution of the project is to investigate the design and implementation of programming languages that support the specification and verification of strong correctness properties of programs. A broader contribution of the project is to promote through education the use of formal methods to improve the reliability and maintainability of software systems.","title":"Collaborative Research: Integrating Types and Verification","awardID":"0702345","effectiveDate":"2007-08-15","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["518022"],"PO":["564388"]},"129664":{"abstract":"Proposal #: CNS 07-22515<br\/>PI(s): Cruz, Alfredo<br\/> Farahat, Nader.; Lopez-Bonilla, Roman.; Zaharov, Viktor<br\/>Institution: Polytechnic University of PR<br\/> San Juan, PR 00919-2017<br\/>Title: MRI\/Acq.: Infrastructure to Enhance Research in Computer Science and Engineering in HPC <br\/>Project Proposed:<br\/>This project, enhancing an existing cluster to serve a diverse set of projects that fall within the domains of ECE\/CS and require high performance computing (HPC), requests funds for a memory and processor upgrade to be utilized for multidisciplinary research, enhancing the HPC center, increasing access of students and faculty, and fostering integration of research and education. The instrumentation enables the institution to assist in the scientific, technological and economic transformation of the jurisdiction, mainly populated by an underrepresented group in CISE areas. The facility supports research and education in diverse research areas such as evolutionary algorithms, neural networks, visualization, face recognition, smart antennas, etc. It specifically contributes to the following research projects.<br\/>. Genetic Algorithms and Parallel Processing; Very Large Neural Networks;<br\/>. 3D Face Recognition; Pattern Visualization and High Performance Visualization;<br\/>. Computational Modeling and Simulation of Smart Antennas; Smart Antennas;<br\/>. Return Loss Prediction of Various Antennas Using Different Signal Processing and Modeling Techniques; and<br\/>. Meta Classifiers and Clustering Techniques<br\/><br\/>Broader Impact: The infrastructure contributes to develop a recognized center that can collaborate with other institutions and industries, paving the way to building more balanced (ethnical and racial) technological enterprises. The institution services a large number of female and minority students. While promoting research, the center is expected to act as a prototype of educational experiences for other minority-serving institutions.","title":"MRI: Acquisition of Infrastructure to Enhance Research in Computer Science and Engineering in HPC in Puerto Rico","awardID":"0722515","effectiveDate":"2007-08-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[343709,343710,343711,343712],"PO":["557609"]},"127486":{"abstract":"Low-cost, portable lab-on-a-chip systems capable of rapid automated biochemical analysis can impact a wide variety of applications including biological research (genomics, proteomics, glycomics, drug discovery), genetic analysis (medical diagnostics, newborn screening, DNA fingerprinting), in vitro biomolecule production (e.g., heparin), and biochemical sensing (pathogen detection, air and water monitoring, chemical explosives detection). Since the simultaneous coordination of even tens of droplets on the array is extremely difficult to program manually, algorithms to automatically enable the flexible coordination of hundreds or even thousands of droplets are essential. This project will develop algorithms that will be the automation enabler of digital microfluidic system technology. The droplet coordination algorithms, integrated with digital microfluidic hardware, will provide unprecedented spatial and temporal control over biochemical reactions using nanoliter droplets. An interdisciplinary team of computer scientists, biochemists, and biomedical engineers will develop algorithms for the control of devices, and apply these devices. The proposed research will develop specialized routing and scheduling algorithms for the coordination of droplets on a microfluidic biochip. General principles for designing scalable grid layouts and droplet coordination algorithms that work across different hardware implementations will be developed. The algorithms will enable robust and user friendly operation of digital microfluidics systems, offering end users flexibility and the ability to exercise precise spatial and temporal control over reactions. The proposed research will involve undergraduate and graduate students in research, and will be integrated into graduate courses taught by the PIs. Outreach activities include after-school Lego robotics activities and summer robotics camps for middle school students in collaboration with RPI's Center for Initiatives in Pre-College Education.","title":"III-CXT: Enabling Automated Digital Microfluidic Biochips for Combinatorial Biosynthesis and Screening","awardID":"0713517","effectiveDate":"2007-08-01","expirationDate":"2010-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["349045","349045","553786"],"PO":["565136"]},"127497":{"abstract":"IIS - 0713581<br\/>Zhai, ChengXiang<br\/>University of Illinois at Urbana-Champaign<br\/>III-COR: QueryClinic: Improve Search Accuracy for Difficult Queries<br\/><br\/><br\/>This project aims to develop an interactive search environment (called QueryClinic) to better support a user in<br\/>finding information in large information spaces. The goal is to make the search process a collaborative process in which QueryClinic software and a user would interact with each other and work together toward improving<br\/>search results. This is in contrast with the current search process in which a search engine passively responds to a<br\/>user's query with some search results. Specifically, QueryClinic would actively involve a user in the search process so<br\/>that the user can give more input to the search process and also receive more guidance and assistance in reformulating queries. In this way, the system would be able to collect more informative feedback information and analyze the entire interaction session as a whole (rather than just a few words in the query) to understand more precisely the user's information need, which in turn helps the system better direct the search process and improve search accuracy.","title":"III-COR: QueryClinic: Improve Search Accuracy for Difficult Queries","awardID":"0713581","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["456699"],"PO":["469867"]},"128113":{"abstract":"The emergence of peer-to-peer (P2P) systems has enabled rapid<br\/>deployment of Internet-scale distributed applications over the<br\/>Internet. This project focuses on cooperative peer-to-peer systems, in<br\/>which peer nodes form a \"\"community of common interest\"\" with shared<br\/>goals and mutual benefits. Services that can be supported by<br\/>cooperative P2P systems cover the gamut of networked<br\/>applications and distributed computing. Since the value and utility <br\/>of a cooperative P2P system is in the<br\/>service it offers to its users, ensuring its correct and efficient<br\/>operation despite the existence of potentially untrustworthy nodes is<br\/>of utmost importance. <br\/><br\/>The goal of this project is to understand and address the challenges<br\/>and problems in building large-scale, robust cooperative P2P systems<br\/>that are trustworthy, accountable and secure. The project includes<br\/>developing implementations of several innovative concepts and<br\/>mechanisms: efficient and correct \"\"Distributed Hash Table\"\" routing,<br\/>randomly rotating \"\"witness\"\" nodes, and virtualized protocol<br\/>evaluation.","title":"CT-ISG: A Framework for Trustworthy Cooperative P2P Applications","awardID":"0716025","effectiveDate":"2007-08-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["543509","422435","548224"],"PO":["497499"]},"129213":{"abstract":"Both users and administrators of computing grids are presented with enormous challenges in debugging and troubleshooting. Diagnosing a problem with one application on one machine is hard enough, but diagnosing problems in workloads of millions of jobs running on thousands of machines is a problem of a new order of magnitude. Suppose that a user submits one million jobs to a grid, only to discover some time later that half of them have failed. Each individual failure could be the manifestation of one of many kinds of error: a job specification error, a machine configuration error, a transient system state, and many others. It does little use to investigate any one instance of failure. Rather, users of large scale systems need tools that describe the overall situation, indicating what problems are commonplace versus occasional, and which are deterministic versus random. <br\/><br\/>Machine learning techniques can be used to debug these kinds of problems in large scale systems. The proposal poses the following research questions: What sort of failures is most common in grids? What data must be collected to identify these failures? What innovations in machine learning algorithms are required to be successful in this domain? This project will generate new understanding by collecting large amounts of production data from TeraGrid and OSG, developing novel analysis techniques, and working closely with end users to produce useful diagnoses. The results will provide both new understanding of complex large scale computer systems, as well as innovations in machine learning algorithms to tackle such scenarios.","title":"CSR-AES: Troubleshooting Large Scale Computing Grids with Machine Learning Techniques","awardID":"0720813","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["538222","563538","565244","537738"],"PO":["551712"]},"129455":{"abstract":"Can ten or a hundred compromised BGP routers create Internet-wide instability? How how can we protect against it? BGP routing problems are hard to study, for the following reasons: (a) a lack of complete and accurate BGP topology, (b) difficulty in simulating with regards to computational complexity and accuracy, and (c) difficulty of deploying new tools to improve the BGP security.<br\/><br\/>The goal of this project is exactly to address the above issues, and specifically to measure, model and guard against BGP routing problems. The overarching vision is to provide the foundation for not only improving the current BGP, but also for providing new insight and guidelines for the design of novel inter-domain routing approaches.<br\/><br\/>The work focuses on three related research tasks. In the first task, the work will develop and maintain a relatively complete and accurate BGP topology as an ongoing effort and to generate small realistic topologies for simulations purposes, with provable topological properties. In the second task, the project will use and extend epidemic spreading techniques to model the network-wide propagation of BGP instability. In the third task, the project will develop a comprehensive reactive framework to detect erroneous BGP updates, which could be readily deployed today.<br\/><br\/>Broader Impact. This work is an important step towards a more robust Internet. It is widely feared that the next generation of cyber-attacks could target the control plane. However, even today, BGP routing has its share of vulnerabilities and problems which cost millions of dollars in service disruption.","title":"Collaborative Research: NETS-NBD: RIDR: Towards Robust Inter-Domain Routing: Measurements, Models, and Deployable Tools","awardID":"0721736","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548220"],"PO":["565090"]},"129235":{"abstract":"Abstractions currently used in computing hide timing properties of software. As a consequence, computer scientists have developed techniques that deliver improved average-case performance and\/or design convenience at the expense of timing predictability. For embedded software, which interacts closely with physical processes, timing is usually an essential property. Lack of timing in the core abstractions results in brittle and non-portable designs. Moreover, as embedded software becomes more networked, the prevailing empirical test-based approach to achieving real-time computing becomes inadequate.<br\/><br\/>This project reintroduces timing predictability as a first-class property of embedded processor architectures. It tackles the problem from the hardware design perspective, developing precision timed (PRET) machines as soft cores on FPGAs. It shows that software on PRET machines can be integrated with what would traditionally have been purely hardware designs. This project seeks to reinvigorate research in an area of computer science and computer architecure that have stagnated in research due to maturing industrial practice. This is expected to provide a starting point for a decades-long revolution that will once again make timing predictability an essential feature of processors. This project addresses the core abstractions of computing. Rather than attempting to correct the lack of timing in these abstractions with more layers of abstraction, this project has the goal of showing that embedded processors can deliver both predictable timing and high performance. It opens up the field to new computing abstractions that include timing as a first-class property.","title":"Collaborative Research: CSR-EHS: Pret: Precision Timed Architectures","awardID":"0720882","effectiveDate":"2007-08-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"K156","name":"Central Intelligence Agency"}}],"PIcoPI":[342424,"71498",342426],"PO":["561889"]},"128146":{"abstract":"CT-ISG: Collaborative Research: Trustworthy Enforcement<br\/>of Domain-independent Run-time Policies<br\/>Abstract<br\/>Run-time monitors are a common and pervasive mechanism for ensuring that software and<br\/>systems adhere to security policies. Anti-virus and anti-spyware programs, personal firewalls,<br\/>intrusion-detection tools, Java's stack inspection, and even mechanisms that trap operatingsystem<br\/>exceptions in order to show a ?blue screen of death? can all be thought of as run-time<br\/>monitors. Although they differ greatly in their complexity and scope of policies that they can<br\/>enforce, these mechanisms all observe the behavior of a running system and detect and react<br\/>to potentially dangerous events. Despite the pervasiveness and real-world importance of runtime<br\/>monitors, their use has far outpaced theoretical work that makes it possible to rigorously<br\/>reason about monitors and the policies that they enforce, particularly in distributed settings.<br\/>This project develops models, tools, and mechanisms for reasoning about and implementing<br\/>distributed, concurrently executing run-time monitors. The research adopts a holistic,<br\/>four-prong approach that spans the breadth of the space between theoretical models and<br\/>practical systems for enforcing run-time policies. Specifically, this project (1) creates a<br\/>framework for reasoning about enforcement that permits the possibilities of concurrent, distributed<br\/>computations; (2) develops a type-safe policy-specification language that ensures<br\/>that specified policies compile into well-behaved monitoring mechanisms; (3) designs trustworthy<br\/>algorithms for automatically translating a desired overall policy into node-specific<br\/>policies that can be distributed and enforced throughout a network; and (4) designs, implements,<br\/>and tests a prototype system for specifying and enforcing run-time policies with<br\/>support for concurrently executing computations. Taken together, these research tasks enable<br\/>formal modeling and automatic enforcement of run-time security policies in concurrent<br\/>and distributed settings.","title":"CT-ISG: Collaborative Research: Trustworthy Enforcement of Domain-Independent Run-Time Policies","awardID":"0716216","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["563508"],"PO":["529429"]},"129125":{"abstract":"The secured Internet service is one driving force behind the continuous exponential growth of the Internet. Fundamental to the build of robust and high-performance secured Internet services is a thorough understanding of the characteristics of the end-to-end performance perceived by remote users. Moreover, there is increasing demand for performance management in secured Internet services to provide statistical quality of service (QoS) guarantees. This project investigates a set of innovative techniques to passively monitor and to actively manage end-to-end performance of secured Internet services. These techniques rely on the service characteristics derived by analyzing interactions between networks and servers. Aided by such an characterization, the set of proposed techniques accurately monitor the real-time performance. With the support of the real-time performance, the proposed techniques then adaptively provide QoS guarantees. The contributions of the project include devising effective and efficient techniques for performance monitoring and<br\/>management. It involves a comprehensive behavior characterization of browsers, networks, and servers based on new findings of secured Internet services as well as results from previous research. This project also explores ways of utilizing the derived behavior characteristics to design innovative techniques to monitor service performance. Techniques for adaptive performance management are also developed. Broader impacts of the project include the publication and dissemination of research results and developed software artifacts. The research enables collaborative research opportunities for students and faculty in the program, as well as undergraduate science and<br\/>engineering students in South Dakota, an EPSCoR state.","title":"CSR-PDOS: Non-Intrusive Monitoring and Management of End-to-End Performance for Secured Internet Service","awardID":"0720560","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[342108],"PO":["535244"]},"129246":{"abstract":"Simulation environments are an indispensable tool in the design, prototyping,<br\/>performance evaluation, and analysis of computer systems. Simulator must be able<br\/>to faithfully reflect the behavior of the system being analyzed. To ensure the<br\/>accuracy of the simulator, it must be verified and determined to closely match<br\/>empirical data. Modern processors provide enough performance counters to<br\/>validate the majority of the performance models; nevertheless, the information<br\/>provided is not enough to validate power consumption, thermal models, and<br\/>process variability.<br\/><br\/>Temperature and power consumption are first order design parameters for modern<br\/>high performance architectures. High operational temperatures and large power<br\/>consumption present possible limits to performance and manufacturability. While<br\/>temperature and power are dominant factors on processor design, process<br\/>variability is becoming another major constraint.<br\/><br\/>In order to address some of the difficulties associated with the validation of<br\/>power, thermal models, and process variability, we propose to use an infrared<br\/>measurement setup to capture run-time power consumption and thermal<br\/>characteristics of modern chips.<br\/><br\/>A detailed thermal model can use the measured temperatures to generate a power<br\/>detailed power consumption. The same thermal measurements will be used to<br\/>measure process variability from of-the-shelf processors. In addition, the<br\/>resulting infrastructure will be use to develop a verified thermal simulation<br\/>infrastructure and process variability models.","title":"SMA: Accurate Temperature Measurement Infrastructure and Methodology for Power, Variability, and Reliability Analysis","awardID":"0720913","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["429867","561096","556721","511551"],"PO":["493916"]},"128278":{"abstract":"The correct behavior and reliable operation of an information system<br\/>relies not only on what users are permitted to do, but oftentimes on<br\/>what users are required to do. Such obligatory actions are integral<br\/>to the security procedures of many enterprises. The management of<br\/>obligations in security policies imposes significant technical<br\/>challenges since obligations bear quite different properties from<br\/>traditional access control. For example, obligations assigned to<br\/>users often cannot be enforced. Thus, even if a system\u00a1\u00afs reference<br\/>monitor is trusted, the failure of obligations must be considered,<br\/>and appropriate remedies need to be an integral part of security<br\/>policies. Also, the interaction between obligations and other<br\/>components of security policies (e.g., access control) must be<br\/>considered to ensure their consistency.<br\/><br\/>This project develops a comprehensive framework for the management<br\/>of obligations in security policies, which covers the full life<br\/>cycle of obligations, including obligation modeling, specification,<br\/>analysis, monitoring and discharges. Specifically, the project<br\/>formally identifies the desirable security objectives that are<br\/>characteristic of systems that involve obligations, and<br\/>systematically investigates dynamic and static means to maintaining<br\/>these objectives while such systems evolve. Though the framework is<br\/>formal in nature, and is designed on purpose to be general, the<br\/>evaluation of its usefulness and effectiveness is firmly grounded on<br\/>real applications, in particular, in the context of privacy policy<br\/>enforcement in health care systems.<br\/><br\/>This project aims to establish a solid foundation for the management<br\/>of obligations, and significantly improve the understanding and<br\/>practice of obligations in information systems. The societal benefit<br\/>of the project also results from the development and dissemination<br\/>of education resources on new types of security policies beyond<br\/>traditional access control.","title":"CT-ISG: Collaborative Research: A Framework for the Modeling and Management of Obligations in Security Policies","awardID":"0716750","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["438804"],"PO":["565327"]},"129169":{"abstract":"Recent wildfires have highlighted the serious threat from wildfires to communities and ecosystems throughout the world. There is a need for new systems software tools to assist in effective fire management regarding where and when to deploy limited firefighting resources. This project develops an integrated data acquisition, modeling, simulation, and optimization software environment for effective wildfire management. This environment integrates real-time acquisition of weather and fire-front position data, fast simulation of fire spread to predict fire behavior, just in-time optimization to compute firefighting resource deployment, and modeling and simulation of firefighting to assess strategies of fire suppression. Integrating these components that are usually treated in isolation enables a novel comprehensive software system to effectively support real-time optimal decision-making for fire management and minimize firefighting risk and cost. Specific research objectives include developing system architecture and a software environment that integrates real time data acquisition, fire spread simulation, stochastic optimization, and firefighting simulation for dynamical data driven wildfire management, and developing runtime environment to support efficient computation and seamless communication among the different functional components in a distributed computing environment. The integrated systems software environment will provide a needed decision support tool to assist in firefighting decision making. The software environment will also serve as a valuable training and planning tool for fire management, and will provide a multidisciplinary educational tool for students and researchers at large.","title":"CSR-CSI: System Integration of Dynamical Data Driven Wildfire Spread and Firefighting Modeling, Simulation, and Optimization","awardID":"0720675","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["426827","426420"],"PO":["493916"]},"130291":{"abstract":"Computer science is, in many ways, a design discipline. Computer scientists design algorithms, interfaces, interactions, specifications, programs, systems and simulations. The studio method of instruction is prevalent in the preparation of professionals within a variety of other design disciplines, such as architecture and industrial design. Although a few innovative computer science programs have implemented the studio method, and the logistics and procedures involved have been well-documented, little is known about which components of the studio experience are critical to successful outcomes. Research on effective learning strategies and the characteristics of innovative work groups could further illuminate the group processes and classroom environment that contribute to successful design studio experiences. We have much to gain by examining techniques that are effective in the preparation of other designers in order to strengthen the preparation of computer science professionals who are capable of meeting the critical software design challenges of the 21st century. Toward this end, the PIs will leverage knowledge about design education from architecture and industrial design, to develop new educational models and materials for the design of software-intensive systems, specifically in the area of Human Computer Interaction (HCI). In the first two years of the project the PIs will focus on research involving data collection and analysis to examine in detail the impact of the studio method on how students learn HCI design. The data analysis will be informed by the literature on cognitive apprenticeship teaching methods and characteristics of innovative work groups, in order to illuminate the group processes and environment that contribute to successful outcomes within design studio experiences. Through an investigation of the design process used within an interdisciplinary studio-based project and HCI courses that incorporate a modified studio method, the PIs will formulate guidelines for implementing the studio method in HCI courses and will derive principles that can be applied to the education of future computer science professionals. In the third year, the effectiveness of the curriculum guidelines will be evaluated through pilot testing in HCI classrooms, and revised based on the results of the formative evaluation. Research outcomes and curriculum guidelines will be disseminated through presentations, publications, and a project web site.<br\/><br\/>Broader Impacts: Based on an investigation of factors that contribute to creative group processes and products within an academic design studio environment, the PIs will advance software design research and education through the development of new models and methods that are supported by empirical evidence and that are teachable. In this way, the PIs will develop a strong intellectual foundation for teaching software design, which has the potential to transform the teaching of HCI, and ultimately for improving the processes of constructing, evaluating, and modifying software-intensive systems across a variety of computer science specialty areas.","title":"Collaborative Research: Investigating and Refining the Studio Experience as a Method for Teaching Human Computer Interaction","awardID":"0725290","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":[345730,"519261",345732,345733,345734],"PO":["565227"]},"132392":{"abstract":"Abstract<br\/><br\/><br\/>IIS - 0736476<br\/>Seales, William B.<br\/>University of Kentucky<br\/>Changing the Center of Gravity: Transforming Classical Studies through Cyberinfrastructure<br\/><br\/>This project requests funds to support a two-day workshop to be held at the University of Kentucky focussed on computational humanities. The purpose of the workshop is to understand how new computational tools and resources have been taken up by humanists and applied to problems long considered out of reach, and at the same time revealed new challenges and desired capabilities for information technologies research. This meeting will bring together approximately 25 participants representing a diverse and experienced group of domain and IT scholars and practitioners. These scholars from diverse fields have all contributed to shaping through their work a vision for how computation, tools and underlying technical infrastructure can shape the future of research and scholarship in the Classics and humanities more generally. Artifacts and manuscripts essentially inaccessable for broad scholarly use in their physical form have been accurately rendered in digital form and distributed widely for examination and analysis by students and researchers. A specific expected outcome is an articulated description of the emerging state of cyberinfrastructure for the Classics and how it has been shifting the center of gravity away from the traditional structures and practices in the field, which has been in printed materials. The current and evolving set of tools based on technology (computational algorithms; digitization; databases; network access; tagged, indexed and cross-referenced archives) is substantial and collectively forms an impressive shift away from the traditional forms defined by print. A second expected outcome is identifying the global production and refinement of computing\/humanities collaborative work and elucidate state-of-the-art progress in a number of areas.","title":"Changing the Center of Gravity: Transforming Classical Studies Through Cyberinfrastructure","awardID":"0736476","effectiveDate":"2007-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["467058","494196","463789"],"PO":["433760"]},"125880":{"abstract":"In today's rapidly expanding disciplines, scientists and scholars are constantly faced with the daunting task of keeping up with knowledge in their field. In addition, the increasingly interconnected nature of real-world tasks often requires experts in one discipline to rapidly learn about other areas in a short amount of time. Cross-disciplinary research requires scientists in such areas as linguistics, biology, and sociology to learn about computational approaches and applications. Both students and educators must have access to accurate surveys of previous work, ranging from short summaries to in-depth historical notes. Government decision-makers must learn about different scientific fields to determine funding priorities.<br\/><br\/>The goal of iOPENER (Information Organization for PENning Expositions on Research) is to generate readily-consumable surveys of different scientific domains and topics, targeted to different audiences and levels, e.g., expert specialists, scientists from related disciplines, educators, students, government decision makers, and citizens including minorities and underrepresented groups. Surveyed material is presented in different modalities, e.g., an enumerated list of articles, a bulleted list of key facts, a textual summary, or a visual presentation with zoom and filter capabilities. The original contributions of this research are in the creation of an infrastructure for automatically summarizing entire areas of scientific endeavor by linking three available technologies: (1) bibliometric lexical link mining; (2) summarization techniques; and (3) visualization tools for displaying both structure and content.<br\/><br\/>The iOPENER software and resulting surveys will be made publicly available via the project Web site (http:\/\/tangra.si.umich.edu\/clair\/iopener\/) and research results will be presented at conferences such as the ACL, SIGIR, and ASIST, as well as to broader audiences, e.g., expert specialists, students, educators, and government decision makers. Application areas include digital government, emergency response, and public health issues.","title":"III-COR: iOPENER - A Flexible Framework to Support Rapid Learning in Unfamiliar Research Domains","awardID":"0705832","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["527292","527292",334101,334102,"466946","518100"],"PO":["563751"]},"128971":{"abstract":"Most current general-purpose processors have two to four cores, and <br\/>the number of cores on processor chips is expected to double every <br\/>one and half years. Applications run efficiently on such processors <br\/>only if they exploit coarse-grain parallelism. However, parallel programming<br\/>has so far been successful only for applications that deal with structured data<br\/>such as arrays and relations; unfortunately, most general-purpose applications deal with unstructured data such as graphs and trees. This project is focused<br\/>on the exploitation of a particular kind of data parallelism in irregular<br\/>applications that arises from the use of unordered and ordered worklists. Optimistic parallelization is the key mechanism for obtaining parallelism in such applications. A runtime system is used to manage the optimistic parallelism, and compiler analyses are used to optimize parallel execution. Finally, programs are further optimized using dynamic code specialization as the program executes. To investigate the scalability of this approach, the project uses multicore hardware prototypes based on field-programmable gate-arrays. If successful, the project will go a long way towards solving the pressing problem of writing software for multicore processors.","title":"CSR-AES: Optimizations for Optimistic Parallelization Systems","awardID":"0719966","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["556730","519591"],"PO":["551712"]},"127893":{"abstract":"Icosahedral viral shell assembly starting from identical protein monomers is an outstanding but poorly understood example of symmetric macromolecularself-assembly occuring in nature. We propose to develop and biochemically validate a novel multiscale mathematical and computational model and associated<br\/>software tools to answer focused questions about viral shell assembly pathways. The proposed approach is based on 3 novel ingredients. <br\/>(i) Formalization of carefully focused questions about the structureof assembly pathways, which depend only on static geometric and symmetry constraints. Avoidance of dynamics facilitates computational tractability and an intuitive theory of pathway structure.<br\/>(ii) Development of a modular, two-scale virus assembly model that makes the mathematics transparent and leads to new directions in geometric complexity and algebraic combinatorics.<br\/>(iii)Independent biochemical validation of the 2 separate scales of the model, using known data as well as new experiments.<br\/><br\/><br\/>An array of applications in nanoscience and engineering, biosensor and gene therapy follow from effective models of symmetric macromolecular assembly pathways. Such models would additionally help arrest viral self-assembly and hence numerous plant and animal diseases. Opensource software built atop the PI's FRONTIER geometric constraint solving opensource software suite, and benchmark virus data will be developed for prediction and visualization of self-assembly pathways and for rigorous comparisons. The grant will foster a closely interacting, interdisciplinary group of students and will expose each of them to research in mathematics, structural biology, theoretical computer science, algorithms and software development. Outreach is planned via an interdisciplinary workshop at DIMACS or at IMA and in university press releases.","title":"Multiscale Macromolecular Assembly Pathways via Algebraic Combinatorics","awardID":"0714912","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["488681","564569","488683"],"PO":["565309"]},"127431":{"abstract":"Parameter-Sensitive and Dynamics-Aware Methods for Object Detection, Pose Estimation, and Tracking<br\/><br\/>The main goal of the proposed effort is to develop algorithms for simultaneous detection, parameter estimation, tracking, and classification of objects that exhibit high variability. While the aim is to develop a general framework time-varying objects, particular emphasis will be placed on modeling of articulated objects, like the human hand and human body. This research will focus on: (1) methods for dimensionality reduction that incorporate knowledge of object dynamics, (2) models that combine a collection of simpler local models to efficiently and accurately approximate nonlinear motion dynamics in a state-based model for tracking,<br\/>(3) algorithms that can detect an instance of the object class in the image, and at the same time estimate the object's parameters.<br\/><br\/>The resulting algorithms will be deployed in a prototype system that will support detection, parameter estimation, tracking and motion classification for video sequences of human motion. The methods will be tested with various motion capture and real-world video datasets of human motion: <br\/>full<br\/>body motion and gait, surveillance video, gestural communication, sports video, etc. Synthetic sequences, generated via computer graphics rendering from motion capture data, will be used in quantitative experiments where ground truth is required.<br\/><br\/>The methods developed in this project would enable numerous applications that are valuable to society, for instance: homeland security; video- based analysis of human biomechanics for occupational safety, as well as dance and sports training; archive management and analysis for news, entertainment, and sports video; and non-intrusive monitoring of the motion patterns of handicapped, infirm, or elderly people to detect decline, danger, or to alert caregivers when needed.<br\/><br\/>Keywords: Computer vision; object detection; articulated tracking; human motion analysis<br\/><br\/>URL: http:\/\/www.cs.bu.edu\/groups\/ivc\/ParameterSensitive\/","title":"RI: Parameter-Sensitive and Dynamics-Aware Methods for Object Detection, Pose Estimation, and Tracking","awardID":"0713168","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["472054"],"PO":["564316"]},"137001":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI: Collaborative: Next Generation CiteSeer <br\/><br\/>Collaborative Proposal<br\/>Lead Proposal: CNS 0454052<br\/>PI: C. Lee Giles<br\/>Institution: Pennsylvania State University University Park<br\/><br\/>Proposal CNS 0454121<br\/>PI: Susan Gauch<br\/>Institution: University of Kansas Center for Research Inc <br\/><br\/><br\/>This community resource project builds on the CiteSeer project that provides access to over 700,000 academic articles in computer science with search methods that access authorship, citations, and other structural aspects of the articles. CiteSeer is currently freely available to the public for use, getting over one million hits per day. This project will support a Next Generation CiteSeer that will address performance and reliability in the existing system and support research and education in the national research community interested in search, citation studies, user studies, and related areas. Specific strategies for the project include increased server capacity, redesigning CiteSeer software, developing a Web Services architecture, expanding the collection, learning from user and search patterns, supporting collaborative usage, evaluation, and addressing sustainability. In broader impacts, this community resource will provide a realistic scale model for researchers and students across the nation to use in research and education. The project will also improve CiteSeer's core capabilities for use in bibliographic tasks in research.","title":"CRI: Collaborative: Next Generation CiteSeer","awardID":"0800562","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["468587"],"PO":["563751"]},"125154":{"abstract":"The power dissipation problem is causing a shift of commodity microprocessor architectures towards multi-core chips. By industry's forecast, the number of cores, also known as computation engines, on a single chip is to increase at an exponential rate at least for the decade ahead of us. How to use multiple processors simultaneously for a single application problem is no longer an issue unique to the supercomputing domain but also to software that runs on commodity microprocessors. This project investigates the execution model, task scheduling methods and compiler techniques to achieve the goal of efficient use of multiple processors on a single chip.<br\/><br\/>The focus of this project concerns the mapping between program operations and the complex architectures which offer parallelism and data locality in various forms on a single chip. Such intricate parallelism and localities make optimal deployment of computational tasks difficult for programmers to manage without associated compiler support and related programming tools. A critical research objective of this proposal is to design and implement a parametric approach to parallel code generation and scheduling on multi-core architectures. Based on this approach, an adaptive scheme for computation offloading is employed on heterogeneous multi-core (HMC) chips. The scheme is novel in two major aspects. Firstly, it has a single unified framework for several different system architectures of HMC, abstracting various architecture differences by a set of parameters plugged into a task partitioning mathematical system. Secondly, the code it generates, as the result of task partitioning, has the ability to adapt to the change in the program's execution context, including the data sizes and the execution options, which is often unpredictable at compile time.","title":"Parametric Compiler Optimization for Multi-Core Architectures","awardID":"0702245","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["408878"],"PO":["565272"]},"127464":{"abstract":"The objective of this project is to develop an adaptable multi-functional end effector for a micro robotic manipulation system. The end effector will be able to sense a micro contact force at an unprecedented accuracy and dynamic range, and to on-line regulate the both micro contact force and position. This research will provide a solution for the long outstanding problem in micro force sensing, i.e. solving the conflict between the sensitivity and dynamic range. The approach is based on measuring the rate of the micro force instead of directly measuring the force itself, and obtaining the force information via real-time data processing. As a result, highly accurate force measurements can be obtained without imposing any limitation on the dynamic range of the sensor. This research will also provide the theoretical foundation and implementation scheme for the application of the infinite dimensional system theory to the hybrid force\/position control in micromanipulation. The results of this project will lead to the development of an efficient and effective micro robotic manipulation system for the automation in the assembly of micro sensors, actuators and other devices, and micro injection and manipulation in biomedical research and applications.","title":"RI: Adaptable Multi-Functional End Effector for a Micro Robotic Manipulator","awardID":"0713346","effectiveDate":"2007-08-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550894"],"PO":["543539"]},"127234":{"abstract":"ABSTRACT<br\/><br\/>Knowledge representation formalisms are precisely defined languages designed for expressing declarative knowledge (assertions), just as typical programming languages are used to express procedural knowledge (algorithms). Because of the important role of declarative knowledge in intelligent behavior, the theory of knowledge representation is a key part of artificial intelligence. Nonmonotonic knowledge representation languages are particularly valuable in view of the fact that they allow reasoning about defaults and exceptions. Research on nonmonotonic knowledge representation is becoming increasingly experimental and applied, in connection with the emergence of efficient answer set solvers--software systems for computing stable models.<br\/><br\/>The goal of this project is to reformulate the semantics of variables in nonmonotonic logic in a way that will bring this theory closer to the reality of state-of-the-art implementations. This will be achieved using a new definition of a stable model that is based on translating logic programs with variables into classical logic. This work seeks to clarify and simplify the semantics of several knowledge representation languages that are used in applications of artificial intelligence to many areas of science and technology.","title":"RI: Nonpropositional Nonmonotonic Languages for Knowledge Representation","awardID":"0712113","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[337516],"PO":["491702"]},"128114":{"abstract":"Proposal: 0716039<br\/>Tontong Ellen Li<br\/>CT-E: Secure Communication System Design for Wireless Networks<br\/>Michigan State University<br\/><br\/><br\/>This project aims to develop advanced design methodologies for inherently secure wireless networks through tight secure access control and strong privacy protection. First, for secure access control, it establishes a resilient and highly reliable wireless interface to strengthen or replace the current device-based and\/or password-based security by the highly secure user-based access control. The major challenge lies in that user based access control generally requires reliable transmission of several orders of magnitude more bits than the traditional user verification process. In this project, resilient security protocols and high capacity access control protocols are designed for effective credential information transmission and real time user authentication. Second, in current privacy protection schemes, information confidentiality is mainly performed at the network layer independent of the PHY layer, and thus is far from adequate for multimedia wireless communications. This research enhances the PHY layer built-in security by integrating cryptographic techniques into the transmitter-receiver design. Based on both cryptographic techniques and inherent ambiguity in signal detection over multiple access channels, this project formulates a joint PHY layer and upper layer privacy protection mechanism. Finally, overall system integration and validation will be performed through a reconfigurable simulation platform. By directly addressing multiple pivotal wireless security concerns, it is anticipated the important technological advances to be achieved in this project will contribute significantly to the design and development of a new generation of highly secure wireless networks. Additionally, by integrating the technological advances into the undergraduate\/graduate curricula, and through outreach activities, significant impacts are expected from this project on training a highly-skilled and diverse workforce in the areas of wireless communications and network security, and on educating the public with respect to the need for secure and ethical operations in wireless communications.","title":"CT-ER: Secure Communication System Design for Wireless Networks","awardID":"0716039","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["523634","523780"],"PO":["529429"]},"129577":{"abstract":"This CPATH grant addresses the potential of non-computing majors to make significant contributions to computing applications within their fields by offering them opportunities to learn how computing influences their own disciplines and to contribute in open source projects that are authentically valuable with those disciplines.<br\/><br\/>Two programs to be developed under this grant will be a Masters Seminar Series and a Center for Open Source Solutions. The Masters Seminar Series, modeled on conservatory Masters Classes in the arts, allow students to interact with professionals from a wide variety of fields whose contributions in those field have advanced the use of computation and technology. Visits consist of a combination of general audience lectures and demonstrations and more intensive Masters Classes with selected students in the appropriate disciplines. Masters Seminars are planned for a wide variety of disciplines including computational biology and chemistry as well as in the arts and humanities.<br\/><br\/>The Center for Open Source Solutions (COSS) will provide both physical space for collaboration and a virtual clearinghouse of resources for development of open source solutions in various disciplines. The growing open source community offers undergraduates many opportunities to contribute solutions to problems within a variety of fields. However, students are not typically in a position to evaluate the feasibility of a particular contribution. The Center will help students assess the potential for a successful project contribution and will facilitate communication with open source projects at various other institutions.<br\/>This project will serve as a model of how to increase participation in computing by students and faculty from traditional non-computing disciplines by engaging them in computational ideas within their own disciplines.","title":"CPATH CB: Supporting Non-CISE Majors in a Computing Community","awardID":"0722209","effectiveDate":"2007-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[343383,343384,343385],"PO":["565136"]},"129104":{"abstract":"The research tasks of this project aim at building a sound knowledge base and systematic design framework for dependable and predictable integration of next generation COTS-based embedded systems. In modern computer architectures, peripherals autonomously can initiate data transfers and contend for bus transactions. Most of the real-time systems literature is focused mainly on how to properly partition CPU cycles paying less attention to the co-scheduling problem of the CPU and I\/O ``smart'' peripherals. Unfortunately, temporal isolation guaranteed at the CPU level can be globally violated whenever the CPU tries to access the shared bus which is currently locked by another master device. To guarantee the dependable and predictable behavior of next generation embedded systems, the following research tasks are pursued: <br\/><br\/>1) The research introduces the novel idea of a ``hardware server,'' implemented on a customized smart bridge. In the architecture being developed, a smart bridge separates a group of peripherals from the rest of the system shielding the system itself from undesirable behaviors of peripherals. The smart bridge is implemented using a FPGA-based full system-on-chip (SoC).<br\/><br\/>2) Relevant bus transactions from untrusted components are montiored<br\/>since it can be very hard or impossible to be shown that commercial off-the-shelf (COTS) devices satisfy system assumptions. The rationale is to optimistically assume that all assumptions hold and then to monitor the runtime behavior of COTS components against their assumed specifications. If violations are detected, then an appropriate recovery measure is taken. Monitoring is decentralized: events are filtered and communicated to FPGA-based monitors by corresponding smart bridges. In addition, specifications are synthesized into low-level monitors via translations to intermediate timed automata.","title":"CSR-EHS: Monitor and Control: Towards Dependable COTS-based Real-Time Embedded Systems","awardID":"0720512","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["549774","542023"],"PO":["561889"]},"129588":{"abstract":"CSITES will build a community of practitioners from Massachusetts, Virginia and Indiana who are actively working to define and implement new models that provide for seamless advancement from 2-year to 4-year programs. Convening relevant administrators, faculty, and local business partners within each of the three regions, the CSITES team will research current transfer models (successful and unsuccessful), identify exemplary frameworks (such as common learning outcomes identified in SIGITE's model IT curriculum) and identify the variables that lead to enhanced upward progression.<br\/><br\/>With information gathered during the investigative stage, the CSITES team will provide process documentation regarding the model 2 and 4-year curriculum implementation strategies in use. Efficient ways to deal with ongoing changes in the curricula will be researched and documented. Evaluative criteria to determine the effectiveness of the solutions associated with identified variables will be developed and applied to data collected on student advancement to measure the success of the models. Summits for stakeholders will be held in each of the three regions to disseminate information about identified effective transfer models. The compilation of attributes that contribute to seamless community college\/university transfer will be assembled into a replicable model and made available to other schools around the country.","title":"CPATH CB: A Community Addressing Seamless Information Technology Education for Students (CSITES)","awardID":"0722237","effectiveDate":"2007-08-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["558309",343429,343430,"425170",343432,"425171"],"PO":["565264"]},"129115":{"abstract":"Most current general-purpose processors have two to four cores, and <br\/>the number of cores on processor chips is expected to double every <br\/>one and half years. Applications run efficiently on such processors <br\/>only if they exploit coarse-grain parallelism. However, parallel programming<br\/>has so far been successful only for applications that deal with structured data<br\/>such as arrays and relations; unfortunately, most general-purpose applications deal with unstructured data such as graphs and trees. This project is focused<br\/>on the exploitation of a particular kind of data parallelism in irregular<br\/>applications that arises from the use of unordered and ordered worklists. Optimistic parallelization is the key mechanism for obtaining parallelism in such applications. A runtime system is used to manage the optimistic parallelism, and compiler analyses are used to optimize parallel execution. Finally, programs are further optimized using dynamic code specialization as the program executes. To investigate the scalability of this approach, the project uses multicore hardware prototypes based on field-programmable gate-arrays. If successful, the project will go a long way towards solving the pressing problem of writing software for multicore processors.","title":"CSR-AES: Optimizations for Optimistic Parallelization Systems","awardID":"0720531","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["475422"],"PO":["561889"]},"129236":{"abstract":"This project is developing new methods for coverage-driven directed automatic test generation for real-time embedded systems. The research addresses both, the theoretical foundations of automatic test generation, and practical test and coverage tools for real-time embedded systems. Many signals affecting system behavior may not be observable, or may be difficult to measure online without affecting system behavior, and the system itself may not be easily reset to an initial state to drive different tests. In this research, tasks in the system are modeled as event automata, and the joint event automaton represents the composition of event automata for all tasks in the system. The research is exploring game and control-theoretic techniques to synthesize, from an automatically constructed abstract interaction graph of the implementation, a test director. The test director introduces variable delays in the execution of the system such that a maximal number of coverage goals are met. A testing tool, DIRECT, implements directed real-time testing for embedded systems, combining static analysis (interaction graph construction), control theory (test director construction) and dynamic analysis (online system monitoring in the presence of the test director) to achieve high interaction coverage. In particular, these problems would be studied in a resource-constrained setting, where both online measurements and test director implementation must be optimized for time and space. The tools and techniques would be evaluated on two testbeds available to us: an embedded development platform on top of Lego Mindstorm robots developed by one of the PIs at UC Santa Cruz and a sensor board for marine tracking developed at UC Santa Cruz.","title":"CSR---EHS: Collaborative: Directed Real-Time Testing","awardID":"0720884","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["384064"],"PO":["561889"]},"129126":{"abstract":"The goal of this project is to lay out strategies and abstractions for developing lower-level system modeling and parameter tuning techniques, and for linking these to higher-level architectural and system management approaches. The project also aims to back existing post-manufacturing tuning techniques with deeper analytic methods, and to augment these one-time adjustments with more dynamic management techniques that are ongoing as the system is in use. To make the shift from very static (one-time) tuning towards very dynamic (ongoing) power-performance tuning, one needs models whose detail and abstraction vary. This allows fast, but abstract models to be used dynamically by the operating system, in order to dynamically adjust power\/thermal behavior in order to stay within budget while also meeting performance goals. Microarchitectural techniques can also be employed, but likewise need to be informed by good models and measurement techniques to guide their use. The project will address these modeling issues and the associated on-the-fly management techniques.<br\/><br\/>The research program pursues broad impact in several ways. First, the project has an important component for knowledge dissemination and technology transfer. The modeling and management techniques proposed in this project will be disseminated and released for free use. Building on a record of strong support for undergraduate research and underrepresented groups, the PIs will continue and broaden such activities through this collaboration. Because of the geographic proximity of CMU and Princeton, group meetings unifying the two efforts will be possible throughout the project.","title":"Collaborative Research: CSR---EHS: Cross-System Modeling and Management for Variation-Adaptive Computing","awardID":"0720561","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["495323"],"PO":["561889"]},"129247":{"abstract":"Sensor networks are considered one of the \"10 Emerging Technologies That Will Change the World\". Teaching sensor network concepts is challenging because the field draws upon a disparate set of computing disciplines. For sensor network programming education, some \"tutorials\" exist, but their target audience is largely graduate students and professional researchers.<br\/><br\/>The PIs' experience shows that the presentation of these tutorials is difficult for undergraduate students as they do not have the prerequisite knowledge necessary. In the past, no lab exercises were available that are appropriate for activity-based teaching of this new and exciting field to undergraduates.<br\/><br\/>To fill this void, this CSR-CSI project is developing exemplary laboratory exercises at two institutions: Lewis & Clark College, a small private liberal arts institution, and Portland State University, a Ph.D.-granting research university. With input from students, industrial advisors, and an educational consultant, the PIs are developing exemplary lab exercises, identifying topics that are appropriate, clarifying prerequisite knowledge and preparatory material, and presenting the material in a format that is suitable for undergraduates.<br\/><br\/>The intellectual merits of this work are in clarifying the prerequisite knowledge to employing and programming sensor networks, and building a foundation for teaching these topics to undergraduates. This project also enriches the scientific and engineering research capability of the US, and provide undergraduates with activity-based learning. The effectiveness of the materials is tested on undergraduates at institutions serving a large population of minorities and women.","title":"Collaborative Project: CSR-CSI Making Sensor Networks Accessible to Undergraduates Through Activity-Based Laboratory Materials","awardID":"0720914","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["498383"],"PO":["535244"]},"129148":{"abstract":"This research focuses on one of the most fundamental issues that defines the architecture of Cyber Physical Systems (CPS) - heterogeneity. Unlike the Internet where heterogeneity is normally addressed for the sake of functional interoperability, CPS systems are normally regarded as special-purpose systems of systems, designed mostly for critical infrastructures that require global regulation and performance assurance. Therefore, heterogeneity must be addressed not only for the sake of functional interoperability, but also for policy regulation and performance assurance.<br\/>To address functional interoperability, a distributed framework, called the CPS-Bus, is proposed to flexibly interconnect different CPS subsystems. To support policy regulation, a policy specification language is developed to regulate the relationship between context, operation and rules. To achieve performance assurance over heterogeneous subsystems, a novel run-time combination of reflective interfaces and a distributed control framework is invented to address evolving performance dynamics and required on-demand functional (compositional) changes. This work will allow the effective interconnection of computation and physical processes to reveal the useful correlations among different phenomena and to conduct effective control across the boundary of CPS subsystems. For developers, this work will significantly reduce the design and development costs for building CPS systems. For end users, the resultant CPS systems will lead to exciting applications such as assisted living that will fundamentally improve the quality of every-day life.","title":"Collaborative Research: CSR--CPS: Muti-Level Heterogeneity in Large Scale Cyber-Physical Systems","awardID":"0720640","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550342"],"PO":["561889"]},"126651":{"abstract":"Abstract <br\/>Proposal #: CNS 07-09140 07-08307 07-08820 <br\/>PI(s): Brockman, Jay B. Bader, David A. Gao, Guang R. <br\/>Barabasi,Albert-Laszlo;Chawla,Nitesh;Kogge,PeterM. Vetter, Jeffrey S. <br\/>Institution: University of Notre Dame Georgia Institute Tech U.Delaware <br\/>Notre Dame, IN 46556-5602 Atlanta, GA 30332-0002 Newark, DE 19716-1551 <br\/>Proposal #: CNS 07-09385 07-09111 07-09254 <br\/>PI(s): Gilbert, John R. Upchurch, Edwin T. Yelick, Katherine A. <br\/>Wolski, Richard. <br\/>Institution: UC-Santa Barbara California Inst Tech UC-Berkeley <br\/>Santa Barbara, CA 93106-2050 Pasadena, CA 91125-0600 Berkeley, CA 94704-5940 <br\/>Title: Colla Rsch:IAD:Dev Rsch Infr. for Multithreaded Computing Community Using Cray Eldorado Platform <br\/><br\/>Project Proposed: <br\/><br\/>This collaborative project, developing a shared infrastructure needed to broaden its impact for developing software to run on the next generation of computer hardware, brings a diverse group of researchers from six universities in a joint effort. The work responds to the trend towards multicore processors where developers envision placing tens to hundreds of cores on a single die, each running multiple threads (in contrast to the currently dominant message-passing architectures resulting from the advent of MPI and Linux clusters). Three objectives are proposed: <br\/>. Acquiring computer hardware as a shared community resource capable of efficiently running, in experimental and production modes, complex programs with thousands of threads in shared memory; <br\/>. Assembling software infrastructure for developing and measuring performance of programs running on the hardware; and <br\/>. Building stronger ties between the people themselves, creating ways for researchers at the partner institutions to collaborate and communicate their findings to the broader community. <br\/>The Cray XMT system, scheduled for delivery in 2007 serves as an ideal platform. The second bullet includes algorithms, data sets, libraries, languages, tools, and simulators to evaluate performance of program running on the hardware focusing on applications that benefit from large numbers of threats, massively data intensive, \"\"sparse-graph\"\" problems that are difficult to parallelize using conventional message-passing on clusters. Each university contributes a piece to the infrastructure, using it for support of projects. Sandia National Laboratories has agreed to host the system and provide supplementary funding. Each university will use the Cray XMT system in courses. <br\/><br\/>Broader Impacts: The infrastructure measures performance providing a basis for the community to improve sharin, and build strong ties for collaboration and communication. Courses will be created and materials will be made available. Workshops for dissemination of the findings are also planned.","title":"Collaborative Research: CRI: IAD: Development of a Research Infrastructure for the Multithreaded Computing Community Using the Cray Eldorado Platform","awardID":"0709254","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["436421"],"PO":["557609"]},"133196":{"abstract":"Abstract<br\/><br\/>IIS - 0740093<br\/>Workshop on The Living Heritage of Artificial Intelligence Sussman, Gerald J. <br\/>Massachusetts Institute of Technology<br\/><br\/>This proposal is to convene a workshop and begin an extended dialogue on the emergence of \"Artificial Intelligence\", it's topical evolution over the past 50 years and begin a process of developing possible roadmaps of future work in AI informed by an analysis of the successes and failures of the past. Simultaneously, it will produce a plan and suggest processes for the preservation of key materials from past research milestones in ways that facilitate new discoveries and new perspectives. From a preservation research perspective, special challenges exist with regard to artifactual materials such as tapes, punch cards, documents, hardware and the interfaces to the materials. One theme of the workshop will address current preservation efforts from a variety of perspectives and backgrounds.","title":"Workshop on The Living Heritage of Artificial Intelligence","awardID":"0740093","effectiveDate":"2007-08-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[354238,"551967","485691"],"PO":["565136"]},"128961":{"abstract":"Virtualization is a key technology for safeguarding security and fault-tolerance purposes in networked systems. Hardware support for virtualization allows subsystem isolation to be achieved that can greatly limit the damage caused by an attacker or by hardware and software failures. This project studies two issues that address severe limitations on current virtualization technology: to properly support a real-time operating system, and to allow for recursive virtualization in the design of the hypervisor, the system layer that enforces isolation. The project is conducting a detailed study of a design framework whereby the hypervisor is capable of running hard real-time guests and also capable of participating in recursive virtualization. More importantly, the transparency of the hypervisor is maintained to support hierarchical virtualization, so that off-the-shelf commercial operating systems can be run without having to modify their code. For non-preemptive real-time resource scheduling, various resource partitioning algorithms and their implications on meeting timing constraints are considered, including I\/O needs. The goal of this project is a hierarchical hypervisor that is real-time ready. The result of this project is expected to impact the successful deployment of many types of real-time embedded applications that are increasingly networked. These applications span transportation systems, medical devices, assisted living for the elderly, environmental monitoring, military systems and others too many to mention. Success in this project is expected to provide the foundational technologies for deploying secure and fault-tolerant sensor\/actuator networks that will benefit society at large. Technical insights from this project are being incorporated into university computer science classes.","title":"CSR-EHS: Real-Time Hierarchical Hypervisors","awardID":"0719925","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["527002"],"PO":["561889"]},"126563":{"abstract":"Abstract <br\/>Proposal #: CNS 07-09140 07-08307 07-08820 <br\/>PI(s): Brockman, Jay B. Bader, David A. Gao, Guang R. <br\/>Barabasi,Albert-Laszlo;Chawla,Nitesh;Kogge,PeterM. Vetter, Jeffrey S. <br\/>Institution: University of Notre Dame Georgia Institute Tech U.Delaware <br\/>Notre Dame, IN 46556-5602 Atlanta, GA 30332-0002 Newark, DE 19716-1551 <br\/>Proposal #: CNS 07-09385 07-09111 07-09254 <br\/>PI(s): Gilbert, John R. Upchurch, Edwin T. Yelick, Katherine A. <br\/>Wolski, Richard. <br\/>Institution: UC-Santa Barbara California Inst Tech UC-Berkeley <br\/>Santa Barbara, CA 93106-2050 Pasadena, CA 91125-0600 Berkeley, CA 94704-5940 <br\/>Title: Colla Rsch:IAD:Dev Rsch Infr. for Multithreaded Computing Community Using Cray Eldorado Platform <br\/><br\/>Project Proposed: <br\/><br\/>This collaborative project, developing a shared infrastructure needed to broaden its impact for developing software to run on the next generation of computer hardware, brings a diverse group of researchers from six universities in a joint effort. The work responds to the trend towards multicore processors where developers envision placing tens to hundreds of cores on a single die, each running multiple threads (in contrast to the currently dominant message-passing architectures resulting from the advent of MPI and Linux clusters). Three objectives are proposed: <br\/>. Acquiring computer hardware as a shared community resource capable of efficiently running, in experimental and production modes, complex programs with thousands of threads in shared memory; <br\/>. Assembling software infrastructure for developing and measuring performance of programs running on the hardware; and <br\/>. Building stronger ties between the people themselves, creating ways for researchers at the partner institutions to collaborate and communicate their findings to the broader community. <br\/>The Cray XMT system, scheduled for delivery in 2007 serves as an ideal platform. The second bullet includes algorithms, data sets, libraries, languages, tools, and simulators to evaluate performance of program running on the hardware focusing on applications that benefit from large numbers of threats, massively data intensive, \"\"sparse-graph\"\" problems that are difficult to parallelize using conventional message-passing on clusters. Each university contributes a piece to the infrastructure, using it for support of projects. Sandia National Laboratories has agreed to host the system and provide supplementary funding. Each university will use the Cray XMT system in courses. <br\/><br\/>Broader Impacts: The infrastructure measures performance providing a basis for the community to improve sharin, and build strong ties for collaboration and communication. Courses will be created and materials will be made available. Workshops for dissemination of the findings are also planned.","title":"Collaborative Research: CRI: IAD: Development of a Research Infrastructure for the Multithreaded Computing Community Using the Cray Eldorado Platform","awardID":"0708820","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["475422"],"PO":["557609"]},"129610":{"abstract":"Educational research provides strong evidence that active and collaborative learning result in a deeper and more integrated understanding of concepts, as well as significant improvement in student retention in degree programs. Engaged students remember concepts longer, enjoy the learning process more, and are more likely to continue. Collaborative learning builds important communication, teamwork, and leadership skills. In addition, active learning in the classroom provides an opportunity to teach the creative design process through discussion and critique of student work. The proposed transformation will serve as a testbed for further study and development of active learning in the context of computer science and engineering. Several forms of active learning (including inquiry-based, problem-based, and collaborative learning)<br\/>will be applied and studied in partnership with educational experts. The proposed transformation will apply teaching methodology historically used in art and architecture design studios. Through an educational partnership with the College of Architecture, computer science and engineering faculty will learn these teaching techniques in order to adapt and apply them to computer science and engineering studios. Finally, the process of making the curriculum more accessible to individuals outside the discipline will result in an unprecedented carefully interwoven framework of concepts that will support novel approaches to the study of computer science and engineering. Both the transformation process and the resulting program will serve as models for other institutional transformations to active learning. Tools, teaching practices, and other artifacts developed to support the transformation will be disseminated for adoption. The modularized curriculum structure resulting from this transformation will support ongoing outreach efforts in K-12 education by enabling efficient targeted professional development for K-12 teachers.","title":"CPATH T: Active Learning for Transformation of the Undergraduate Experience","awardID":"0722328","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["511556","427427",343516,"547864","547864","556687"],"PO":["565136"]},"127432":{"abstract":"Dynamic programming is a very general, powerful, and robust problem solving paradigm in artificial intelligence and computer science. Dynamic programming is an algorithm schema that includes a number of well-known systematic search algorithms in Artifical Intelligence, including breadth-first search, Dijkstra''s algorithm, A*, value iteration and policy iteration for Markov decision processes, as well as many polynomial-time algorithms for combinatorial problems, and pseudo-polynomial-time algorithms for numeric NP-complete problems. These algorithms are extremely robust, in that they are guaranteed to find a solution to a problem if one exists, and often an optimal solution.<br\/><br\/>Most dynamic programming algorithms are limited in the size of problems they can solve by the amount of storage available. While semiconductor memory costs about $100 per gigabyte, magnetic disk storage costs less than 40 cents per gigabyte, and single disks with one terabyte of storage are now available. In practice, the available storage on a modern workstation can be increased by three orders of magnitude with multiple disks, at moderate cost. Unfortunately, you can''t simply replace memory with disk storage in a dynamic programming algorithm. The reason is that it takes about ten milliseconds to access a single byte on disk, compared to about 100 nanoseconds for main memory.<br\/>However, large blocks of data on disk can be read or written sequentially at high speed. This work will develop, implement, and experiment with dynamic programming algorithms that store their data on magnetic disk. The main research challenge is to design these algorithms so that all data access is sequential. By shifting the resource bottleneck from space to time, parallelizing these algorithms to run on multiple processors or multiple cores becomes an additional research challenge. The PI has had some success with this paradigm, implementing large-scale breadth-first and heuristic searches that run for months at a time. The techniques will be broadened to cover other classes of dynamic programming algorithms. The proposed challenge problems include numeric NP-complete problems, finding the radius and diameter of various problem spaces, and amino acid and DNA sequence alignment in computational biology. If successful, in addition to engaging students at UCLA, the work can have impact throughout computer science. The idea of extending memory with disk storage is potentially applicable to any memory-intensive algorithm and can be used to speed up computations that reside entirely in memory by improving cache performance.","title":"RI: Large-Scale Dynamic Programming","awardID":"0713178","effectiveDate":"2007-08-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["558173"],"PO":["565136"]},"127322":{"abstract":"The proposed research aims to understand fundamental surgical interactions so that technologies can be improved to make the interactions as consistent and intuitive as possible across interfaces. Teleoperative robotic systems and virtual environment simulations can make it easier to learn and perform surgery. With current technology, however, robotic surgery feels different from open surgery, which is quite different from minimally invasive surgery, and simulated procedures often fail to behave realistically like any of these.<br\/><br\/>Two of the most difficult aspects of minimally invasive techniques are limited haptic feedback and working dexterously under the kinematic constraints of the instruments. The most time-consuming portions of surgical procedures are typically dissection, which is hampered by poor haptics, and repair by suturing, which is made challenging by limited dexterity. These two skills will be studied in parallel thrusts. In each thrust, the skill will be modeled from experimental data. The models will be tested in simulation and robotic testbeds, then used to optimize the design of teleoperative surgical systems and virtual training environments.<br\/><br\/>This research is expected to have significant impact on the technology and teaching of minimally invasive surgery, allowing wider usage of beneficial techniques while improving medical outcomes and reducing errors.","title":"HRI: Modeling Fundamental Interactions in Robotic, Simulated, and Real Surgery","awardID":"0712595","effectiveDate":"2007-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7632","name":"HUMAN-ROBOT INTERACTION"}}],"PIcoPI":[337700],"PO":["565227"]},"127443":{"abstract":"Context<br\/>The remote sensing data that consists of satellite observations of the land surface, biosphere, solid Earth, atmosphere, and oceans, combined with historical climate records and predictions from ecosystem models, offers new opportunities for understanding how the Earth is changing, for determining what factors cause these changes, and for predicting future changes. In turn, this could provide an unprecedented opportunity for predicting and preventing future ecological problems by managing the ecology and health of our planet. Data mining and knowledge discovery techniques can aid this effort by discovering patterns that capture complex interactions among ocean temperature, air pressure, surface meteorology, and terrestrial carbon flux. <br\/><br\/>Intellectual Merit<br\/>The goals of this work are twofold: 1) to better understand global scale patterns in biosphere processes, particularly patterns in the global carbon cycle and climate system. More specifically, the proposed data mining research is driven by the need to address the following two challenges: (i) understanding how ocean, atmosphere and land processes are coupled and (ii) detecting and predicting ecosystem disturbances such as fires, floods, and hurricanes. 2) to support innovative Computer Science (CS) research in data mining. In particular, the spatio-temporal nature of Earth Science data means that standard CS data mining techniques often cannot be directly applied. As an example, in Earth Science research, a key step is the selection of the locations and time periods that are to be used to investigate possible relationships between two Earth Science phenomena, e.g., El Nino and milder winters in the Midwestern United States. Currently, this selection is based on domain knowledge, but automating this process would be very beneficial. The proposed work will develop new data mining techniques that address the high dimensionality, large size, and spatio-temporal nature of the data. <br\/><br\/>Broader Impacts: New algorithms and techniques for the analysis of large spatio-temporal data sets developed in this project will be made available to other researchers within the Earth Science community. To a large extent, this project will encapsulate these algorithms within easy to use visual tools so that users will be able to more easily extract useful knowledge from Earth Science data sets. Although the focus will be on Earth Science data, the data mining techniques that are developed will be applicable to a wide variety of other fields that have data collected over time on a spatial grid. To give a specific example, spatio-temporal clustering has been used to track cyclones and animal migrations, and to model mobile phone users and neuronal activities in the brain, and the new spatio-temporal clustering techniques could also prove useful for these applications.","title":"III-CTX: Collaborative Research: Spatio-Temporal Data Mining For Global Scale Eco-Climatic Data","awardID":"0713227","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563607","563608"],"PO":["563751"]},"129401":{"abstract":"As cognitive radio (CR) technology becomes more mature in the near future, it is not hard to foresee that CR will eventually play a pivotal role in wireless networking, such as mesh and ad hoc networks. However, due to its unique characteristics in spectrum usage, a CR network differs significantly from the existing multi-channel multi-radio (MCMR) network. As a result, networking problems for CR networks are much more challenging and interesting.<br\/><br\/>A major objective of this project is to develop network theoretical bounds and performance limits for future cognitive radio networks. Such efforts are not only of theoretical interest, but also offer fundamental understanding of the potential and limits of such networks, as well as provide performance benchmarks for the design and evaluation of distributed algorithms and protocols. New performance metrics such as Bandwidth-Footprint Product (BFP), which is unique to CR, will be employed, along with traditional performance metrics (e.g., network capacity). Special consideration will be given to interference modeling, power control, scheduling, and routing. An analytical framework will be developed that allows one to unify the multi-dimensional cross-layer design space into a tractable, understandable research problem. We will develop efficient computational procedures by employing powerful optimization techniques for given network instances. In addition to theoretical study of performance bounds, we also plan to develop distributed algorithms for optimal radio resource utilization.<br\/><br\/>The educational objective of this project is to develop teaching materials for future CR-based wireless networks. The investigator aims to develop a new course that intersects networking, communications, and software curricula in both the ECE and CS departments. Special efforts will be made to involve students from underrepresented groups in the form of wireless summer school to encourage participation in this project.","title":"NeTS-WN: Network Performance Limits for Future Cognitive Radio Networks","awardID":"0721570","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564848"],"PO":["557315"]},"127477":{"abstract":"Abstract<br\/>Proposal 0713442 <br\/>PIs: Amy Briggs and Daniel Scharstein<br\/>Institution: Middlebury College<br\/><br\/>Title: RUI: Visual Navigation from Circular Feature Sequences<br\/><br\/>Navigating the world from visual input alone is still one of the greatest challenges for mobile robots. Vision provides the richest but also most difficult input, since unambiguous and stable features that can serve as landmarks for navigation are hard to obtain. <br\/>Challenges include the rich geometry of the world, changing scenes and obstacles, occlusion, lighting changes, specular and transparent surfaces, to name a few. Maintaining an accurate 3D model of world features and using them for localization and navigation is difficult due to the sheer amount of data to be processed.<br\/><br\/>To face these challenges, this project presents a framework for navigation from one-dimensional circular feature sequences extracted from 2D panoramic images. Since many real-world navigation tasks of mobile entities are in the plane (e.g., walking in a single building floor, driving in the city), the goal is to identify a reduced feature set sufficient for navigation that uses little storage space and can be processed quickly.<br\/><br\/>The key motivation for this work is to develop a simplified visual feature model that allows robust navigation in the plane but avoids most of the difficulties associated with extracting, modeling, and matching true 3D features and solving the associated six degree-of- freedom structure-from-motion problem. This work advances the state of the art in vision-based navigation on several fronts, with novel contributions in both robotics and computer vision. Specific algorithmic contributions include new feature descriptors invariant to planar motion, fast circular feature matching algorithms that allow both unmatched features and ordering reversals, probabilistic topological motion planning methods that include explicit modeling of the reliability of feature detection and identification, and strategies for graph-based world modeling and selective feature storage.<br\/><br\/>The proposed techniques have wide applicability, ranging from autonomous robot navigation in unknown environments to camera-based navigation aides for pedestrians, bicyclists, and cars. The project also provides an opportunity to expose undergraduates at a liberal- arts college to the world of research, experimentation, and discovery.<br\/><br\/>Undergraduate students at Middlebury College - an undergraduate institution in rural Vermont - will be actively involved in all components of this research. The student researchers will also join the PIs in authoring papers and attending conferences. Other students will benefit from the research activities through the integration of current research topics into the curriculum and through use of the lab facilities enhanced by the project. Tight integration of research and education is a central career goal of the PIs. Based on experience gained in prior and current collaboration with undergraduates, robotics and computer vision research is ideally suited to excite and challenge students.<br\/><br\/>Progress on this project will be regularly reported at http:\/\/ vision.middlebury.edu\/navigation","title":"RUI: Visual Navigation from Circular Feature Sequences","awardID":"0713442","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["531309","550972"],"PO":["564316"]},"128698":{"abstract":"This proposal is for seed money to enable research in the area of limited resource sharing systems. The goal is to establish enough results so as to warrant the submission of a full proposal in 12 months.<br\/><br\/>In limited resource sharing systems, the degree of sharing between jobs is limited. An example is a time-sharing (processor-sharing) system, such as a CPU, where a fixed Multi-Programming-Limit (MPL) is imposed, so that only MPL number of jobs can share the CPU at a time.<br\/>Another example is the classic M\/G\/k multiserver queueing system, with a fixed limit, k, on the number of servers.<br\/><br\/>Although such limited resource sharing systems are quite prevalent in computer systems and manufacturing systems, their analysis has stymied researchers for decades. This proposal makes a breakthrough in the analysis of such systems, by observing that the third moment of the job size distribution plays a critical role in their analysis -- a fact that has gone unnoticed all these years. The proposal seeks to understand this effect and find more accurate analyses of these important systems.<br\/><br\/>This proposal is a collaboration between two schools, Carnegie Mellon University and Georgia Institute of Technology, and thus a portion of the funds will be used to pay for travel between the two universities.","title":"COLLABORATIVE RESEARCH: CSR---SMA: New Breakthrough in Analyzing Limited Resource Sharing Systems","awardID":"0718701","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["556026","367082"],"PO":["551712"]},"127488":{"abstract":"Proposal 0713540<br\/>\"RI: Foundations of Active Learning\"<br\/>PI: Sanjoy Dasgupta<br\/>University of California-San Diego<br\/><br\/>ABSTRACT<br\/><br\/>The goal of this project is to characterize several important problems in active learning from a theoretical perspective. Active learning is a kind of machine learning, a key aspect of Robust Intelligence. A central aim of machine learning is to develop techniques that construct models of data in order to help make predictions in future situations. The past decades have seen huge advances in machine learning that uses labeled data. However, labels are often difficult to obtain. Active learning addresses situations in which the data are unlabeled, and any labels must be explicitly requested and paid for. The aim of active learning is to learn a good classifier with as few labels as possible. Despite its practical importance, active learning is a comparatively underdeveloped area in machine learning.<br\/><br\/>This project will rigorously investigate the potential of intelligent querying, and develop practical, label-efficient learning algorithms. It will bring together a diversity of student talent, from theoreticians to domain experts in biology and vision applications. The resulting algorithms will be made widely available, and have the potential to increase the applicability of machine learning to the many large-scale problems in which difficulty of labeling is a critical bottleneck.","title":"RI: Foundations of Active Learning","awardID":"0713540","effectiveDate":"2007-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["525613"],"PO":["491702"]},"129105":{"abstract":"One of the fundamental advances in computing in the next decade will occur at the interface between the logical and physical realms. Future computing systems will see increased convergence of computation, communication, and sensing. They will be marked by massive distribution and will augment the physical environment, interacting with it under constraints of real time and space. This project develops a fundamental theory for computing the real-time capacity of such future systems which quantifies their ability to do timely work. A mathematical foundation is developed for composing real-time capacity expressions given application flow graphs, time constraints and resource topology. This foundation utilizes a small set of composition rules to arrive at application-aware capacity expressions. The project also considers the limits when system components become infinitesimal and the number of components needed for an application grows to infinity. Once a capacity region is constructed for a distributed system running a set of applications, various optimizations can be performed such as finding the point of maximum throughput within the capacity region.","title":"CSR-EHS: An Extended Theory for Temporal Composition of Distributed Real-Time Computing Systems","awardID":"0720513","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553633"],"PO":["561889"]},"128269":{"abstract":"While the mathematical study of cryptography has yielded a rich theory, and while the use of cryptography has become quite widespread, there is unfortunately still a significant gap between the theory and practice of cryptography. The goal of this research is to try to bridge this gap. The emphasis is on the design and analysis of fundamental cryptographic primitives that are practical yet theoretically sound. This research focuses on two specific areas: the design and use of secure hash functions, and the design of more efficient privacy-preserving protocols. <br\/><br\/>Because of recently discovered weaknesses in industry-standard hash functions, there is renewed interest and urgency to study the basic design principles of hash functions, as well as how such hash functions should be appropriately used in applications. Indeed, although hash functions were originally designed to serve as message digests, which should provide a form of security known as collision resistance, they are actually used in many different types of applications where the security requirements may be somewhat different: <br\/>sometimes the security requirement of the hash function in a given application may be weaker than, stronger than, or perhaps just incomparable to collision resistance. This project investigates new methodologies for constructing hash functions that satisfy the various security requirements required in applications, as well as how the applications themselves may be adapted so as to minimize the security requirements placed on the hash function. <br\/><br\/>With the widespread use of computers and the Internet in daily transactions, concerns about privacy issues have taken on new urgency. One key aspect of privacy is deniability: if a user runs a protocol, it should not be possible for an eavesdropper, or even another participant in the protocol, to convince a third party that the transaction actually occurred. While there are compelling reasons to focus on this area for its own sake, there are also a number of technical issues that arise that overlap with some of the subproblems associated with hash functions.","title":"CT-ISG: On the Design of Secure Hash Functions and Privacy-Preserving Protocols","awardID":"0716690","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550227",340000],"PO":["565264"]},"128159":{"abstract":"Proposal Number: 0716342<br\/>PI: Scott Shenker<br\/>Institution: International Computer Science Institute, University of California Berkeley<br\/>Lead<br\/><br\/>Proposal Number: 0716278<br\/>PI: Nicholas Feamster<br\/>Institution: Georgia Institute of Technology<br\/>Sub<br\/><br\/>Proposal Number: 0716287<br\/>PI: David Andersen<br\/>Institution: Carnegie Mellon University<br\/>Sub<br\/><br\/>Proposal Number 0716273<br\/>PI: Hari Balakrishnan<br\/>Institution: Massachusetts Institute of Technology<br\/>Sub<br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Towards a More Accountable Internet<br\/><br\/>Abstract<br\/><br\/><br\/><br\/>The goal of this project is to design, implement, and <br\/>test an internetwork architecture called the Accountable Internet <br\/>Protocol (AIP). AIP retains much of the elegance and simplicity of <br\/>IP, but is far better equipped to thwart malicious adversaries. To <br\/>provide this protection, AIP incorporates three kinds of <br\/>accountability: source accountability, control-plane accountability, <br\/>and dataplane accountability. Together, these three forms of <br\/>accountability ensure that any host, router, and autonomous network <br\/>can identify misbehaving components.<br\/><br\/>Operationally, this results in: an Internet in which any spoofing or <br\/>forgery of source addresses is detectable (from source <br\/>accountability); a partial defense against flooding attacks from <br\/>compromised hosts (also from source accountability); an Internet <br\/>where route hijacking and other security compromises to inter-domain <br\/>routing are impossible (from control-plane accountability); and the <br\/>ability for end hosts and operators to pinpoint locations where <br\/>packets are being lost or excessively delayed even when the problems <br\/>are in other networks (from data-plane accountability).<br\/><br\/>The cornerstone of AIP is its use of a self-certifying address <br\/>format. All AIP addresses are of the form AD:EID, where AD is the <br\/>identifier for the autonomous domain that the host belongs to, and <br\/>EID is a globally unique host identifier. Both address components are <br\/>derived from public keys held by the domain and host, respectively, <br\/>allowing other entities to verify the authenticity and provenance of <br\/>packets and messages. AIP's self-certifying addressing allows simple <br\/>protocols to realize the above benefits.","title":"Collaborative Research: CT-T: Towards a More Accountable Internet","awardID":"0716273","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["508283"],"PO":["565264"]},"129149":{"abstract":"Many software system reliability issues are caused by incorrect usage of application programming interfaces (APIs). But API developers often do not document details or usage properties of APIs required by static verification, because specifying a large number of API properties for static verification is often inaccurate or incomplete besides being tedious. This research develops new techniques and tools for mining API properties from static traces generated by applying a model checker on system code repositories. These mined properties can be used for static verification and other software development tasks. The research fundamentally advances knowledge and understanding of applying software engineering and mining techniques in improving system reliability. The research explores new approaches with novel applications of advanced mining algorithms for mining properties from system code repositories. The benefits of this research to society are two-fold. First, the research should lead to verified practices for mining software-artifact data in improving software system reliability. Second, innovations in new mining and software analysis tend to propagate quickly across application or task domains within or even beyond the software engineering or systems discipline.","title":"CSR---SMA: Improving Software System Reliability via Mining Properties for Software Verification","awardID":"0720641","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562727"],"PO":["551712"]},"132394":{"abstract":"Abstract<br\/><br\/>IIS - 0736480<br\/>Manaris, Bill Z.<br\/>College of Charleston<br\/>A Music Search Engine based on Aesthetic Similarity<br\/><br\/><br\/>This SGER project aims to develop a prototype music search engine based on identifying aesthetic similarities. This engine will utilize power-law metrics to extract statistical proportions of music-theoretic and other attributes of music pieces (e.g., Pitch, Duration, Pitch Distance, Duration Distance, Melodic Intervals, Harmonic Intervals, Melodic Bigrams, etc.).<br\/>The engine searches for pieces that are aesthetically similar to the input piece using a mean squared error (MSE) approach. Preliminary testing has been done using the Classical Music Archives corpus (14,695 MIDI pieces), combined with 500+ MIDI pieces from other styles (e.g. Jazz, Rock, Country, etc.). Similar metrics have already been validated on aesthetic attributes of textual materials. Text results (author attribution, style identification, and pleasantness prediction) indicated an high level of accuracy. Assessment and validation experiments will be conducted to compare to computational findings indicating aesthetic similarity of retrieved pieces. These experiments will be conducted by Prof. Dwight Krehbiel (subaward, Bethel College), a specialist in cognitive neuroscience and psychology of music, who has extensive experience in measuring emotional and physiological responses to music.","title":"SGER: A Music Search Engine Based on Aesthetic Similarity","awardID":"0736480","effectiveDate":"2007-08-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["556149","552414"],"PO":["563751"]},"125860":{"abstract":"Proposal 0705681<br\/>\"RI: Synergistic Machine Learning: Collaboration and Topology Exploitation in Dynamic Environments.\"<br\/>PI: Terran Lane<br\/>University of New Mexico<br\/><br\/>ABSTRACT<br\/><br\/>The goal of this project is to investigate a new generation of machine learning methods for networks comprised of a large number of inexpensive, lightweight, powerful nodes that integrate computation, sensing, and communication. Embedded in the physical world, these nodes will self-assemble into environmentally-aware networks to assist with environmental monitoring, safety, workflows, education, and entertainment. To achieve these goals, such ubiquitous computing networks need to be able to integrate diverse streams of sensor information into coherent views of the environment. This project seeks to create a new generation of machine learning methods to address the resulting data fusion and environmental awareness challenges. The project will develop topology-aware machine learning methods that (a) learn and exploit the topological structure of the environment, and (b) enable collaborative learning among distributed learning agents. This project will test these new machine learning methods on live sensor networks currently installed at two active volcanos: Kilauea (Hawaii) and Mt. Erebus (Antarctica). This project will involve undergraduate and graduate students via research assistantships. Further, this project will involve pre-college students as investigators through middle-school student workshops at the Sally Ride Festival. This work seeks to transform both machine learning and ubiquitous computing by opening up a vast space of novel machine learning problems that are beyond current techniques, and by inspiring development of new capabilities for ubiquitous computing systems.","title":"RI: Synergistic Machine Learning: Collaboration and Topology Exploitation in Dynamic Environments","awardID":"0705681","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["456810","491701"],"PO":["491702"]},"132163":{"abstract":"An NSF-sponsored Symposium on Cyber-Enabled Discovery and Innovations (SCDI) is proposed. The purpose of this proposed Symposium is to gather approximately 100 leaders, researchers, and developers from academia, industry, and government for concept discussions and technical exchanges on emerging ideas and critical issues related to the NSF Cyber-Enabled Discover and Initiatives (CDI). It is anticipated that the Symposium program will consist of an exciting mix of invited keynote talks, technical paper presentations, panels, poster sessions, and a PhD. student forum. The proposed symposium is expected to have a broad impact on the computing research community, and will help energize the community to focus its research and development issues related to cyber-enabled discoveries and innovations, thereby improving the nation''s R&D productivity and increasing competitiveness.","title":"A Symposium on Cyber-Enabled Discoveries and Innovations","awardID":"0734828","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["453727"],"PO":["399214"]},"125750":{"abstract":"Biological nanomachines are the assemblies that carry out all the basic biological processes in a living organism. Electron cryo-microscopy (cryoEM) is the most appropriate structural tool to determine molecular structures of biological nanomachines that generally consist of multiple protein subunits and\/or nucleic acids with a total mass greater than 0.5 million Daltons. The goal is to develop information discovery and integration methodologies for deriving atomic models of nanomachines. Such models will be derived from 3-dimensional (3-D) cryoEM mass density function (i.e. a volumetric density map) in conjunction with physics of protein folding and informatics data. This project is made possible by an integration of the expertise of five investigators in computer graphics, computational biophysics, structural informatics and cryoEM. The intellectual merit of this research is highlighted by the computational approaches of extracting structural information from low-resolution, complex cryoEM volume densities and integrating this information into classical protein structure modeling paradigms, such as comparative modeling and ab initio modeling, for understanding biological nanomachines. The three research goals involve information discovery, information integration and validation of the proposed algorithms. The proposed research will have significant impacts in three disparate disciplines: computer science, molecular modeling, and cryoEM. Furthermore, the team will disseminate their resulting tools freely to the academic community and will host a workshop towards the end of the project. To enhance the impact of their research, the investigators will integrate research with education at each member institution with an eye towards diversity. In particular, these investigators will develop a virtual didactic course in modeling of biological nanomachines for graduate and senior undergraduate students at the five participating institutions.","title":"Integrated modeling of biological nanomachines","awardID":"0705196","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[333760],"PO":["565136"]},"127961":{"abstract":"The development of effective algorithms for analyzing and characterizing the behavior of groups of individuals requires that two main challenges be addressed. The first challenge is to represent the group behavior as the interaction of the behavior of individuals. This interaction can be complex, with coordinated behavior being: simultaneous, sequential, or temporally separated; driven primarily by a prearranged script or through signaling cues (e.g.,<br\/>visual, auditory, and electronic); and spatially localized or distributed. Lastly, the breadth of possible coordinated behavior requires strategies to create robust representations. The PIs will develop a sensor-independent symbolic description of human behavior that is readily derivable from sensor data yet can be algorithmically manipulated. This effort will develop a comprehensive framework for inferring behavior of individuals and groups of individuals using hierarchical interpretation of probabilistic context free grammars, a formalism originally developed for speech understanding. This framework will take low-level sensor measurements such as location, motion and interaction with the environment to hierarchically construct models of what is happening in the physical world, exploiting analogs between behavior understanding and speech understanding. The second challenge is to develop strategies to manage computational complexity, both the selection complexity of identifying an unknown number of conspirators out of a large background population, and the association complexity of managing the uncertainty of associating the newly observed individual behaviors with established behavioral trajectories, given imperfect tracking of individuals. Multiple strategies will be developed and applied to address this challenge. The selection complexity will be addressed by clustering the population into sub-populations based on statistical metrics, behavior classification, spatial distance, and line-of-sight constraints. The association complexity will be addressed by exploiting unique features of conspiratorial behaviors to relax the requirements on perfect data association in tracking. Successful development of these capabilities will have substantial benefits to the automated monitoring, analysis and classification of group behaviors in many potential application domains. These application domains include crowd assessment and control, riot prevention\/response, prison safety, VIP protection, and building\/installation defense. In addition, the algorithms and strategies developed will apply to group behaviors that are not limited to physical movements, but can extend to other forms of behavior, such as electronic communication, financial transactions, and purchasing behavior.","title":"Detection of Conspiratorial Behavior [04P07JHUAPLTerz]","awardID":"0715180","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H186","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I331","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T768","name":"DIA -MASINT RESEARCH PROJECT"}}],"PIcoPI":["530045","399674",339229],"PO":["565136"]},"129600":{"abstract":"The HarambeeNet project's goal is to change courses and perceptions of introductory computer science. The incredible growth in statistics courses at all levels, in contrast with the decline of students taking computer science courses, points to the potential for introducing computer science in variety of venues without emphasizing the process of programming: leverage the expertise and role-models provided by educators from other fields by studying topics that arise from the science of networks and modeling to introduce computer science as an alternative to the traditional programming approach. The project team will develop modules that will be incorporated into existing courses in math, statistics, computer science, sociology, economics, and related fields. These modules will be developed and evaluated by faculty learning communities based at Duke. The work from these faculty learning communities will be supplemented by educators who will attend workshops at Duke and use a social network model to disseminate the modules to colleagues who will continue to assess and develop them. An advisory board with expertise in computer science and social networks will oversee module development which will ultimately lead to a new paradigm for introducing computer science at a wide variety of schools at all levels.","title":"CPATH CB: Building Community via the Science of Networks","awardID":"0722288","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["465198","465198","560704"],"PO":["565136"]},"126586":{"abstract":"Proposal #: CNS 07-08498 07-09946 07-08420 <br\/>PI(s): Preisig, James C Ye,Wei Stojanovic, Milica <br\/>Lee, Freitag Heidenmann, John S. <br\/>Institution: Woods Hole Oceanographic Inst U Southern California Mass Inst Tech <br\/>Woods Hole, MA 02543-1041 Los Angeles, CA 90089-1147 Cambridge, MA 02139-4307 <br\/>Proposal #: CNS 07-09005 07-08938 07-08467 <br\/>PI(s): Cui, Jun-Hong (June) Levine, Brian; Kurose,James F. Freitag, Lee <br\/>Rajasekaran,Sanguthevar;Shi, Zhijie;Willett,Peter K.;Zhou,Shengli <br\/>Institution: University of Connecticut U of Massachusetts WHOI <br\/>Storrs, CT 06269-1133 Amherst, MA 01003-9242 Woods Hole, MA 02543-1041 <br\/>Title: Collab Rsch:CRD\/IAD:Open Research Testbed for Underwater Ad Hoc and Sensor Networks (ORTUN) <br\/><br\/>This collaborative project, developing the first open testbed infrastructure for the underwater networking community, enables open access with the capability to conduct experiments remotely. The infrastructure, based on open research platforms, consists of a testbed that enables wide and systematic experimental evaluation and comparison of underwater acoustic networks. The work, involving this rapidly deployable testbed that can be shared by the underwater networking community, aims to demonstrate the ability of the facility to facilitate field experiments. The project represents a higher-level collaborative that arose from two collaborative groups. One group developing the facility, the other working mainly on the experiments utilizing the facility. The testbed is expected to be a buoy-based system that can be easily taken to different environments. When operational, these systems will be deployed 5 or 6 times a year. The infrastructure will consist of two types of nodes with different capabilities. The first type of node of the rapidly deployable testbed will offer a fixed physical layer capability using acoustic modems such as the WHOI micromodem or the ISI S-modem to implement a physical layer with limited reconfigurability interfaced to a reconfigurable network processor. This network processor will support algorithm\/protocol implementation and testing at higher network layers. The Network functions on the Fixed Physical Layer testbed will be hosted by a Gumstix processor which will then communicate with physical layer modems such as the WHOI Micromodem or USC\/ISI S-modem via a serial port. Ten to fifteen fixed physical layer nodes will be built including up to 3 gateway nodes. Each gateway node of the testbed will be equipped with wireless RF communication enabling real-time monitoring and control of network performance. The fixed physical layer nodes will be smaller and more easily deployed than the second type of node which is the all-layer node. The all-layer node is a more capable node that will ultimately support algorithm\/protocol implementation and acoustic data collection at all networking layers. In addition to the equipment included in the fixed physical layer nodes (i.e., a gumstix network processor and the ability to support relatively fixed physical layer modems such as the WHOI Micromodem and the ISI S-modem), the all-layer nodes will also include a general purpose data acquisition system (D\/A and A\/D) with substantial disk storage and in-situ processing capability. The MIT r-modem software will be implemented on this general purpose hardware and, along with MATLAB, will enable user implementation and testing of algorithms and the gathering of acoustics data at the physical layer in addition to the testing at higher network layers that it will share in common with the fixed physical layer nodes. Three to five all-layer nodes will be built. The rapidly deployable testbed, using two types of nodes with varying capabilities, should significantly enhance research at all network layers while setting the stage for future infrastructure improvements. <br\/><br\/>Many research groups investigating fundamental questions about how to design such networked systems that utilize acoustic communications in complex underwater environments have had their overall effort significantly slowed by the lack of common means to test and compare protocols under realistic environmental conditions. This infrastructure responds to the need for consensus on analytic or simulation models for underwater networks where researchers need the ability to gather experimental data under real world conditions in order to make progress. <br\/><br\/>The network stack will be modular by design with sockets used to enable cross layer control and communication. The physical, MAC, Network and Application layers will be populated with sample components to enable users test their own algorithms or protocols without having to populate the entire stack. Users will be able to write modules to test their own algorithms or protocols at different layers and selectively replace the sample modules with their own. While the development of the modular architecture and sample modules for the network stack","title":"CRI: CRD: Collaborative Research: Open Research Testbed for Underwater Ad Hoc and Sensor Networks","awardID":"0708946","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["377594","377594","376299"],"PO":["493916"]},"136024":{"abstract":"Articulatory inversion is the problem of recovering the sequence of<br\/>vocal tract shapes that produce a given acoustic utterance. <br\/>Articulatory representations are useful for automatic speech<br\/>recognition, speech production research, language therapy, and<br\/>language learning. Articulatory inversion is a hard problem because<br\/>different vocal tract shapes can produce the same acoustics, yet the<br\/>articulatory trajectory must obey the mechanical constraints of the<br\/>human vocal tract. Other examples of inversion problems over a<br\/>sequence, which share the multivalued nature of the mappings and the<br\/>existence of constraints, are: the recovery of facial gestures<br\/>associated with a speech utterance; the inverse kinematics of a robot<br\/>arm; and the recovery of 3D motion from video.<br\/><br\/>This project approaches articulatory inversion from a machine learning<br\/>standpoint, based on a framework introduced by the PI. The<br\/>low-dimensional manifold in articulatory-acoustic space is represented<br\/>in a probabilistic way by a density model estimated from data<br\/>(recorded using a microphone and electromagnetic articulography). <br\/>Multivalued mappings are explicitly represented by the modes of<br\/>conditional distributions of this density, and the articulatory<br\/>trajectory is disambiguated using a continuity constraint.<br\/><br\/>The project introduces new problems in dimensionality reduction,<br\/>density estimation and regularization (such as multivalued regression<br\/>and graph-learning from noisy data), and new models and algorithms. <br\/>The expected results of this work are: performing basic research in<br\/>machine learning, and introducing mapping inversion problems to<br\/>research and education; improving articulatory inversion (for which<br\/>code will be made freely available); and advocating data-driven<br\/>approaches in speech production research and education.","title":"CAREER: machine learning approches for articulatory inversion","awardID":"0754089","effectiveDate":"2007-08-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[361353],"PO":["565215"]},"128786":{"abstract":"This proposal is for seed money to enable research in the area of limited resource sharing systems. The goal is to establish enough results so as to warrant the submission of a full proposal in 12 months.<br\/><br\/>In limited resource sharing systems, the degree of sharing between jobs is limited. An example is a time-sharing (processor-sharing) system, such as a CPU, where a fixed Multi-Programming-Limit (MPL) is imposed, so that only MPL number of jobs can share the CPU at a time.<br\/>Another example is the classic M\/G\/k multiserver queueing system, with a fixed limit, k, on the number of servers.<br\/><br\/>Although such limited resource sharing systems are quite prevalent in computer systems and manufacturing systems, their analysis has stymied researchers for decades. This proposal makes a breakthrough in the analysis of such systems, by observing that the third moment of the job size distribution plays a critical role in their analysis -- a fact that has gone unnoticed all these years. The proposal seeks to understand this effect and find more accurate analyses of these important systems.<br\/><br\/>This proposal is a collaboration between two schools, Carnegie Mellon University and Georgia Institute of Technology, and thus a portion of the funds will be used to pay for travel between the two universities.","title":"COLLABORATIVE RESEARCH: CSR---SMA: New Breakthrough in Analyzing Limited Resource Sharing Systems","awardID":"0719106","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["555524"],"PO":["551712"]},"129765":{"abstract":"Proposal #: CNS 07-22856<br\/>PI(s): Fu, Xinwen; Graham, Steven; Halverson, Thomas; Streff, Kevin<br\/>Institution: Dakota State University <br\/> Madison, SD 57042-1799<br\/>Title: MRI\/Acq.: An Information Assurance Infrastructure for Research and Education at DSU<br\/>Project Proposed:<br\/>This project, acquiring computing devices for storing and analyzing collected data to be used for information assurance (mainly, traffic analysis for anonymity research), addresses issues requiring extensive simulation, precise timing control and measurement of network traffic, and large amounts of data and data analysis. The equipment supports projects that address issues critical to the nation's security, including:<br\/>. Degradation of Anonymous Protocols and Countermeasures,<br\/>. Improving Quality of Service (QoS) of TCP-based Anonymous Communication, and<br\/>. Anonymity Constrained QoS Routing in the Tor Anonymous Communication Network.<br\/>The project, based on previous work that systematically studies traffic analysis attacks in flow-based anonymous communication systems, involves unifying different metrics for measuring anonymity. The QoS research utilizes previous work in investigating Transmission Control Protocol (TCP) performance theoretically and experimentally in flow based anonymous communication systems. Since systems can ignore characteristics of TCP traffic, deployed anonymous systems such as Tor suffer from severe throughput degradation. (Tor's server loading strategies tend to produce bottlenecks.)<br\/><br\/>Broader Impacts: Enhancing information assurance research and education, the infrastructure contributes to integrate security and privacy research into the curriculum. New courses on privacy, anonymous communications, and traffic analysis are under development. The work also promotes close ties with regional industry, mainly in banking and health care. Other universities in the states, including those serving Native Americans, will benefit.","title":"MRI: Acquisition of Equipment to Establish an Information Assurance Infrastructure for Research and Education at Dakota State University","awardID":"0722856","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["344142",344142,"462913","539562","363790"],"PO":["557609"]},"127345":{"abstract":"The main objective of this project is the development of scalable,<br\/>systematic approaches to the synthesis of adaptive sampling strategies<br\/>by mobile sensor networks. In particular, the research challenges have<br\/>been identified with a specific application in mind: the study of<br\/>atmospheric aerosol-dust-cloud-radiation interactions, and how<br\/>aerosols and dust affect cloud microphysics and, more generally,<br\/>climate dynamics. The successful completion of the project requires<br\/>progress on the development of distributed data fusion algorithms that<br\/>help estimate spatio-temporal processes and coordination algorithms<br\/>that exploit these environmental filters. The resulting motion plans<br\/>will be adapted for the sampling of aerosols and dust on clouds across<br\/>areas of the Pacific Ocean.<br\/><br\/>The novel conceptual tools developed in the framework of this project<br\/>will allow the further development of mobile robotic networks with<br\/>capabilities that are well beyond those offered by the current<br\/>technology. Algorithms and motion plans will be adapted and tested in<br\/>a multi-UAV system specially developed to monitor atmospheric<br\/>processes. The possibility of having a network of mobile robotic<br\/>vehicles collecting in-situ data in real time will greatly extend our<br\/>abilities for remote measurement and actuation. In particular, the<br\/>dynamic adaptive gathering of atmospheric data by groups of UAVs will<br\/>provide a much needed insight into how human activity affects climate<br\/>change.","title":"RI: Adaptive Motion Coordination of Multiple Unmanned Aerial Vehicles for the Monitoring of Aerosol-Dust-Cloud-Radiation Interactions","awardID":"0712746","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["523704"],"PO":["543539"]},"127466":{"abstract":"This project investigates bacteria assisted propulsion of a hybrid (biotic\/abiotic) swimming micro-robot as a novel micro-robot actuation approach. An inorganic micro-robot body is propelled by the helical flagella of microorganisms such as bacteria attached to it. Prokaryotic bacteria will propel a micro-robot body robustly and efficiently with on\/off speed control. The motility power source and actuation will be harvested from the bacteria by supplying and controlling the required biochemical energy source and environmental conditions to them. The research breakthrough of this work is the coupling of the nanoscale machine already in nature (i.e., the flagella) to microscale robotic bodies. This work would advance the micro-robotics field by developing this new actuation principle and design methodology for micro-scale swimming robots. Moreover, our understanding of biotic and abiotic object interactions would be improved. Three research objectives are proposed: 1) Integration of bacteria to an inorganic micro-robot body; 2) On\/off robot propulsion speed control; 3) Modeling and characterization of flagellar propulsion. Highly interdisciplinary research work in this project would be transferred to many educational activities in robotics and engineering. It would support graduate students whom would be chosen from female students and underrepresented minorities, and underrepresented minority undergraduate students would be trained.","title":"RI: Bacteria Assisted Propulsion of Swimming Micro-Robots","awardID":"0713354","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["549509"],"PO":["543539"]},"127478":{"abstract":"Previous approaches to statistical machine translation (SMT) have<br\/>employed phrase-based models which represent phrases as sequences of<br\/>fully-inflected words, and are otherwise devoid of linguistic<br\/>detail. Such approaches are unable to generalize and essentially<br\/>rely on memorizing the translations of words and phrases that are<br\/>observed in training data.<br\/><br\/>This project aims to improve the quality of SMT through the<br\/>introduction of more sophisticated models which represent phrases<br\/>using multiple levels of information. This can include basic<br\/>linguistic information such as part of speech, lemmas, and agreement<br\/>information (case, number, person), as well as more sophisticated<br\/>linguistic detail including semantic classes, argument structure,<br\/>co-reference, phrase boundaries, and information propagated from<br\/>syntactic heads.<br\/><br\/>By annotating all data with this information and extending models<br\/>appropriately, there is the potential to learn much more from<br\/>training than was possible under previous approaches. There is now<br\/>the potential to learn translations of unseen words if other forms of<br\/>the words occur; it is now possible to learn general facts about a language's<br\/>word order; it is now feasible to use linguistic context to generate<br\/>grammatical output. Such generalization has the potential to result<br\/>in much higher quality translation, especially for languages that<br\/>only have small amounts of training data. It therefore represents a<br\/>significant advance over previous approaches to SMT.<br\/><br\/>Multi-level models have the potential for wide-ranging impact on<br\/>all language technologies. Simultaneous modeling of different<br\/>levels of representation is an extremely useful and natural way of<br\/>describing language. This project is developing a general framework<br\/>for the creation of multi-level probabilistic models of language and<br\/>translation, and exploring its application to tasks beyond<br\/>translation including generation, paraphrasing, and the automatic<br\/>evaluation of natural language technologies.","title":"RI: Multi-Level Modeling of Language and Translation","awardID":"0713448","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["445169","532696"],"PO":["565215"]},"128226":{"abstract":"Digital societies and markets increasingly mandate consistent procedures for the access, processing and storage of information. In the United States alone, over 10,000 such regulations can be found in financial, life sciences, health-care and government sectors, including the Gramm-Leach-Bliley Act, Health Insurance Portability and Accountability Act, and Sarbanes-Oxley Act. A recurrent theme in these regulations is the need for regulatory-compliant storage as an underpinning to ensure data confidentiality, access integrity and authentication; provide audit trails, guaranteed deletion, and data migration; and deliver Write Once Read Many<br\/>(WORM) assurances, essential for enforcing long-term data retention and life-cycle policies.<br\/><br\/>Unfortunately, current compliance storage WORM mechanisms are fundamentally vulnerable to faulty behavior or insiders with incentives to alter stored data because they rely on simple enforcement primitives such as software and\/or hardware device-hosted on\/off switches, ill-suited to their target threat model.<br\/><br\/>In this project, we will build a strongly compliant storage system for realistic adversarial settings, delivering guaranteed document retention and deletion, quick lookup, and compliant migration, together with support for litigation holds and several key aspects of data confidentiality.<br\/><br\/>Recent compliance regulations are intended to foster and restore humans trust in digital information records and, more broadly, in our businesses, hospitals, and educational enterprises. As increasing amounts of information are created and live digitally, compliance storage will be a vital tool in restoring this trust and ferreting out corruption and data abuse at all levels of society. This project will greatly advance the state of the art and create a strong foundation for secure regulatory compliant designs.","title":"CT-ISG: COLLABORATIVE RESEARCH: SecureWORM: Strong Regulatory-Compliant Storage","awardID":"0716532","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["438346"],"PO":["565327"]},"128237":{"abstract":"Privacy protection challenges arising from location-based services (LBS) are critical to users as well as service providers. This project concentrates on designing and evaluating privacy protection techniques in LBS. The important departure of this project from the existing research is in its emphasis of the role of request contexts. A context refers to the external information\/knowledge that the attacker may use, together with the requests themselves, to gain user private information. For example, with the external knowledge of a user's approximate location at a particular time, the attacker may single out the user of a particular LBS request and thus link the private information in the request to the user. By its nature, context changes from requests to requests and different contexts may call for different privacy protection techniques. The technical objectives of the project are therefore to (1) systematically categorize privacy contexts, (2) analyze existing defense strategies, and (3) design and evaluate new defense strategies. <br\/><br\/>From an educational perspective, the project involves graduate students and exposes them to leading-edge researches, and incorporates research results into classrooms. In addition, the project provides a platform for active collaborations among a broader set of researchers of the two institutions. The results from this project will have a positive impact on protecting user privacy and on people's willingness to adopt LBS in enhancing their living and working conditions. Research results will be disseminated through technical reports, publications at conferences and journals, and the websites at http:\/\/csis.gmu.edu\/NSFLBSprivacy and http:\/\/www.cs.uvm.edu\/~xywang\/NSFLBSprivacy.","title":"CT-ISG: Collaborative Research: A Context-Aware Approach to the Design and Evaluation of Privacy Preservation Techniques in Location-Based Services","awardID":"0716567","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["540637",339912],"PO":["565136"]},"128248":{"abstract":"Digital societies and markets increasingly mandate consistent procedures for the access, processing and storage of information. In the United States alone, over 10,000 such regulations can be found in financial, life sciences, health-care and government sectors, including the Gramm-Leach-Bliley Act, Health Insurance Portability and Accountability Act, and Sarbanes-Oxley Act. A recurrent theme in these regulations is the need for regulatory-compliant storage as an underpinning to ensure data confidentiality, access integrity and authentication; provide audit trails, guaranteed deletion, and data migration; and deliver Write Once Read Many<br\/>(WORM) assurances, essential for enforcing long-term data retention and life-cycle policies.<br\/><br\/>Unfortunately, current compliance storage WORM mechanisms are fundamentally vulnerable to faulty behavior or insiders with incentives to alter stored data because they rely on simple enforcement primitives such as software and\/or hardware device-hosted on\/off switches, ill-suited to their target threat model.<br\/><br\/>In this project, we will build a strongly compliant storage system for realistic adversarial settings, delivering guaranteed document retention and deletion, quick lookup, and compliant migration, together with support for litigation holds and several key aspects of data confidentiality.<br\/><br\/>Recent compliance regulations are intended to foster and restore humans trust in digital information records and, more broadly, in our businesses, hospitals, and educational enterprises. As increasing amounts of information are created and live digitally, compliance storage will be a vital tool in restoring this trust and ferreting out corruption and data abuse at all levels of society. This project will greatly advance the state of the art and create a strong foundation for secure regulatory compliant designs.","title":"CT-ISG: COLLABORATIVE RESEARCH: SecureWORM: Strong Regulatory-Compliant Storage","awardID":"0716608","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553485"],"PO":["529429"]},"128138":{"abstract":"Abstract: Home computer security is a daunting problem. Hackers gain control over millions of home machines to build &#65533;botnets&#65533;. The social costs are enormous because bots are used to attack millions of other machines.&#65533;&#65533; Botnets are now responsible for over 80% of spam, and increasing criminal activity including extortion and information theft.&#65533;&#65533; Home computers are more vulnerable than necessary because users are insufficiently motivated to install and maintain best current security software. The weakest link in security often is the user, not the technology.<br\/>&#65533;<br\/>This project focuses on users of security technology. It relies on the novel, multi-disciplinary approach of incentive-centered design (ICD), which draws on game theory, microeconomics and social psychology. Technology ICD often addresses problems of hidden information, hidden action, and externalities. Botnets exhibit these: intruders know more about the purpose of their intrusion than do the computer&#65533;s owners; users are cajoled to take precautions but their actual effort is not directly observable; and the costs of poor home security are borne more by others (who suffer from bot attacks) than by the owner of the compromised machine (a negative externality). This project will identify the underlying incentives problems, use the ICD design toolkit to build security technology that provides effective incentives for improved user behavior, and test the designs in human-subject experiments and\/or field implementations.<br\/>&#65533;<br\/>Combining technical and social design techniques to create pragmatic security technology that respects user motivations and induces more effective behavior can have a major effect on this pernicious and socially costly","title":"CT-ER: Incentive-Centered Technology Design for Home User Security","awardID":"0716196","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["361939"],"PO":["529429"]},"129117":{"abstract":"Software radio promises substantial benefits to real-world systems by making them more flexible, interoperable, and easily upgradeable. Interoperability and upgradeability are particularly important to first responders, who need to quickly establish communications with a diverse and predictable set of agencies in a very short amount of time.<br\/><br\/>This project is developing new computational models and architectures for software radio. While software radio systems have received considerable attention, many of the design methods in use today are ad hoc. The goal is to develop a principled approach that works from models of computation through synthesis down to architecture-related cost models. This approach treats reconfiguration, the reallocation of architectural resources on-the-fly during execution, as a first-class design concept. The new methodology provides an abstract model for software radio algorithms that is suitable for algorithm designers as well as cost models that allow sophisticated architectural optimizations and hardware\/software co-design. The project validates its models of computation and implementation models using realistic systems. <br\/><br\/>As part of this project, the team is developing curricular materials on software radio, including both lecture materials and labs that provide a complete, senior-level capstone design experience. This project also enables research and education collaborations between George Fox University students and faculty and their counterparts at the University of Maryland at College Park and the Georgia Institute of Technology.","title":"Collaborative Research: CSR---EHS: Foundations for Design and Implementation of Software Radio Platforms","awardID":"0720536","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["431683"],"PO":["561889"]},"129007":{"abstract":"Many embedded systems handle sensitive data or perform critical functions, making security an important consideration. While some of these threats are common in desktop systems, the general-purpose nature of a desktop and the commodity nature of the components comprising it prevent the deployment of meaningful architectural countermeasures. Such restrictions are less stringent in embedded systems, permitting the investigation of new security approaches, covering all aspects of system architecture design. However, such systems are severely resource-constrained in processing and battery capacities. Thus, purely software security solutions can overwhelm these capacities. Providing a secure implementation requires security measures that span various components in the system-on-chip (SoC), including hardware and software.<br\/><br\/>The aim of this research is to develop design methodologies to obtain efficient hardware\/software implementations that can facilitate secure program execution or implement a given security policy in embedded systems. The first objective includes developing hardware\/software design methodologies to support trusted platform module (TPM) functionality in resource-constrained embedded systems. TPM acts as a root of trust for the system that contains it, providing capabilities for secure storage, secure reporting of platform configuration measurements, and cryptographic key generation, among other functions. It is reported that by 2010, shipments of TPMs will reach 250 million, giving impetus to this research. The second objective includes design of a security-aware SoC communication architecture that can enforce a system-level security policy. The third objective includes developing techniques to facilitate the deployment of type-safe software","title":"CSR---EHS: Hardware\/Software Architectures for Secure Embedded Systems","awardID":"0720110","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["550002"],"PO":["561889"]},"134881":{"abstract":"The First Young Investigators Summer Research Institute will be the launch activity of the planned Consortium for the Science of Socio-Technical Systems (CSST). CSST was born out of a series of workshops sponsored by NSF involving over forty faculty members in diverse fields, such as social informatics, social computing, computer supported cooperative work (CSCW), computational social science, human-computer interaction (HCI), and information science. Workshop participants, recognizing the growing importance of research on the interplay of humans and technology, or socio-technical systems, proposed the CSST as a mechanism for promoting and supporting important research on social aspects of technological change. An identified high priority, even in advance of the formal creation of CSST, was initiation of an annual series of summer research institutes targeted at people entering the field of socio-technical systems research. This proposal seeks funding for the first of these institutes to be held on the campus of the University of Michigan in July, 2008. Student participants will include up to 30 advanced doctoral students and pre-tenure faculty doing research on socio-technical systems. Up to ten instructors will be drawn from senior faculty, including participants in the original NSF-supported workshops on socio-technical systems. This project will support the travel, meals, and accommodations for all Institute participants.<br\/><br\/>Intellectual Merit<br\/>The focus of the Institute will be on participants? research programs (e.g., dissertation for doctoral students). The Institute provides both an opportunity for these programs to be shaped through intellectual exchange with experienced researchers as well as enhanced through collaboration with other young researchers. In addition, the Institute will help spread ideas about research on socio-technical systems within the US and around the world.<br\/><br\/>Broader Impact<br\/>The Institute will bring together the best of the next generation of socio-technical system researchers. This allows them to create a social network both among themselves and with several senior researchers, which will play a major role in their professional development and in the evolution of the field of socio-technical systems research. The diversity of Institute participants (e.g., institutional, disciplinary), will broaden participant?s perspectives at a critical stage in their careers.","title":"First Young Investigators Summer Research Institute of the Consortium for the Science of Socio-Technical Systems","awardID":"0748965","effectiveDate":"2007-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["498457"],"PO":["388678"]},"144110":{"abstract":"III-CXT: Learning from graph-structured data: new algorithms for <br\/>modeling physical interactions in cellular networks<br\/><br\/>The complex behavior of the cell derives from an intricate network of <br\/>molecular interactions of thousands of genes and their products. <br\/>Understanding how this network operates and predicting its behavior <br\/>are primary goals of biology and have broad implications for life <br\/>science, medicine and biotechnology.<br\/><br\/>The genomic information revolution of the last ten years has enabled <br\/>new systems-level and data-driven approaches for studying cellular <br\/>networks. In particular, using machine learning to model gene <br\/>regulatory networks---the switching on and off of genes by regulatory <br\/>proteins that bind to non-coding DNA---has emerged as a central <br\/>problem in systems biology. Now, an explosion of new high-throughput <br\/>technologies for measuring physical interactions between proteins and <br\/>between protein and DNA provides a new data integration challenge for <br\/>computational modeling of gene regulation. These new data can all be <br\/>viewed as graph-structured data, or physical interaction networks.<br\/><br\/>The central computational goal of this project is to develop new <br\/>machine learning learning algorithms for exploiting graph-structured <br\/>data, including: (1) boosting with efficient graph mining; (2) graph <br\/>kernels based on subgraph histogramming; and (3) information-based <br\/>graph partitioning. These new algorithms will be used to integrate <br\/>physical interaction network data into models of gene regulation in <br\/>order to better represent underlying biological mechanisms. The <br\/>focus will be two fundamental modeling problems: inferring signal <br\/>transduction pathways and modeling cis regulatory modules at the <br\/>level of DNA sequence and interacting regulatory proteins. The <br\/>algorithms will be applied both to publicly available data and to <br\/>primary gene expression data provided by one of the investigators to <br\/>study the hypoxia in yeast and the response to environmental toxins <br\/>in mammalian neural cells.<br\/><br\/>This project will learn systems-level models that lead to new insight <br\/>into the underlying mechanisms of gene regulation and open the way to <br\/>broader biological discoveries. All data, results and source code <br\/>will be publicly available via the Web (http:\/\/www.cs.columbia.edu\/ <br\/>compbio\/cellular-networks) and disseminated through courses and <br\/>bioinformatics software packages. The project will also create <br\/>undergraduate research opportunities for joint dry and wet lab <br\/>projects and outreach activities to introduce New York City public <br\/>high school students to new interdisciplinary areas of science.","title":"III-CXT: Learning from graph-structured data: new algorithms for modeling physical interactions in cellular networks","awardID":"0835494","effectiveDate":"2007-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[384160],"PO":["560586"]},"125850":{"abstract":"Biological nanomachines are the assemblies that carry out all the basic biological processes in a living organism. Electron cryo-microscopy (cryoEM) is the most appropriate structural tool to determine molecular structures of biological nanomachines that generally consist of multiple protein subunits and\/or nucleic acids with a total mass greater than 0.5 million Daltons. The goal is to develop information discovery and integration methodologies for deriving atomic models of nanomachines. Such models will be derived from 3-dimensional (3-D) cryoEM mass density function (i.e. a volumetric density map) in conjunction with physics of protein folding and informatics data. This project is made possible by an integration of the expertise of five investigators in computer graphics, computational biophysics, structural informatics and cryoEM. The intellectual merit of this research is highlighted by the computational approaches of extracting structural information from low-resolution, complex cryoEM volume densities and integrating this information into classical protein structure modeling paradigms, such as comparative modeling and ab initio modeling, for understanding biological nanomachines. The three research goals involve information discovery, information integration and validation of the proposed algorithms. The proposed research will have significant impacts in three disparate disciplines: computer science, molecular modeling, and cryoEM. Furthermore, the team will disseminate their resulting tools freely to the academic community and will host a workshop towards the end of the project. To enhance the impact of their research, the investigators will integrate research with education at each member institution with an eye towards diversity. In particular, these investigators will develop a virtual didactic course in modeling of biological nanomachines for graduate and senior undergraduate students at the five participating institutions.","title":"III-CXT:Collaborative Research: Integrated Modeling of Biological Nanomachines","awardID":"0705644","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[334007],"PO":["565136"]},"125751":{"abstract":"Machine-readable lexical resources are essential to Natural Language<br\/>Processing applications such as information extraction and machine translation. <br\/>The largest lexicon is WordNet, with <br\/>semantic information about more than 150,000, or lexical units (LUs). <br\/>A smaller, independently developed resource is FrameNet, <br\/>which provides detailed information about the syntactic patterns for LUs. <br\/>The project investigates the ways in which these complementary resources <br\/>can be combined using the semantic-syntactic information from<br\/>FrameNet (FN) where available and falling back on less detailed<br\/>entries from WordNet (WN) in other cases. <br\/><br\/>WN and FN exhibit fundamentally different design principles. <br\/>WN groups (near) synonymous LUs into <br\/>\"synsets,\" which are interconnected via conceptual and lexical relations <br\/>to form a semantic network. FN groups LUs according to the<br\/>\"semantic frame\" they evoke, which is a type of event, relation or<br\/>state along with the participants involved in the event. Thus,<br\/>while antonyms such as _praise_ and _blame_ may be in the same FN frame <br\/>they are in different, though interlinked, WN synsets. Moreover, FN frames <br\/>cover semantically related nouns, verbs and adjectives; WN synsets<br\/>do not mix part of speech. Crucially for NLP applications, the resources <br\/>differ with respect to sense distinctions.<br\/>Alignment will be investigated for the following differences: <br\/>lexical coverage, sense distinctions, taxonomic and<br\/>other semantic relations, and scalar frames for adjectives.<br\/>Some 1,000 word senses are examined in detail so as to provide an idea of<br\/>the distribution of each of these phenomena over the entire lexicon. <br\/><br\/>This theoretical work lays the foundation for constructing a unique, <br\/>invaluable resource for the NLP community.","title":"RI: Collaborative Proposal: Complementary Lexical Resources: Towards an Alignment of WordNet and FrameNet","awardID":"0705199","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["511536"],"PO":["565215"]},"122385":{"abstract":"The goal of this project is to investigate the use of virtual humans (VH) to enhance medical student training with respect to patient ethnicity\/race, gender, and age sensitivity issues. As virtual \"partners\" in interpersonal scenarios, this project implements VHs to augment role-playing and expert-observation for communication skills instruction. Research will be conducted in three stages. First, research will be conducted to effectively characterize a student's VH interaction. This involves tracking the student's primary verbal and non-verbal communication cues (gaze, gesture, posture, words spoken, and audio frequency) and correlating them with medical expert coding of the student-VH interaction. Second, after-action reviews will be developed to visualize the tracked communication cues. Students and instructors will be able to review and replay the student-VH interaction from both the student and the VH's viewpoint. This has the special potential of allowing poor performing students to vicariously experience \"what it was like to talk to themselves.\" The after-action reviews will also be used to study VH interactions, understand how people perceive VHs, and provide educators with tools for identifying students that require remediation. Third, student communication with diverse patients will be investigated through analyzing student interactions with VHs of varied ethnic\/race, age, and gender backgrounds. Overall, the system will be used to study if the VH's appearance and demeanor impacts behavior, and provide tools for educators to enhance communication skills towards people of varied backgrounds.<br\/><br\/>With respect to broader impact, this research with virtual humans has the potential to enhance the communication skills curricula of medical, nursing and physician assistant students. Initially, the VH system will be installed at two Southeast medical schools. As part of a communications skills course, students will interact with virtual humans to learn communication and diversity concepts. As the system evolves, presentations at medical simulation conferences will detail how to replicate the VH system at other medical schools and integrate their results into a database of VH interactions. Prior research has indicated that the majority of students reported that they would practice with such a system weekly. Integration into the medical school curricula has the potential to impact thousands of health care students and educators. The focus on communication skills with diverse patients has the potential to improve both patient care for under-represented minorities as well as within other domains such as customer service, the military, and law enforcement.","title":"CAREER: Studying Diversity Issues with Immersive Virtual Humans","awardID":"0643557","effectiveDate":"2007-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["553729"],"PO":["565227"]},"127951":{"abstract":"The in-band detection and characterization of a laser beam is a difficult problem because its directionality severely limits the ability to place an intercept sensor in the mainbeam and the amount of sidelobe energy available for intercept. However, the potential exists to detect and characterize a laser beam by exploiting changes it induces in the atmosphere. As a high-power laser propagates through the atmosphere, it changes the index of refraction of the air and this change will disturb the propagation of radio frequency (and microwave) signals. The laser-induced discontinuity in the index of refraction serves as a radar target. The meteorological community has used radar for many years to detect and characterize changes in the index of refraction on the same order as the changes induced by a high-power laser beam. The purpose of the proposed work is to investigate and characterize the atmospheric changes induced by a high-power laser and the radio frequency scattering from those induced changes, which will support a study on the feasibility of detecting and characterizing high-power laser beams using radar. This research establishes a solid foundation for the development of a unique method based on radar to provide an out-of-band, off-axis laser detection and characterization capability. Because the radar method does not rely on in-band sidelobe or scattered energy, it should not need precision cueing (time and location) information and thus, has the potential for a search capability. The results of this research project will provide an enduring capability for the community by characterizing and modeling the atmospheric changes induced by the high-power laser and the electromagnetic scattering from those changes. These results form the basis for developing the capability to sense high-power laser through indirect means. The results of the radar feasibility study will provide foundation for assessing and guiding the development of high-power laser sensing methods and systems.","title":"Off-Axis Laser Detection and Characterization Using Radar (11U07GTRIBerg)","awardID":"0715148","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H186","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H187","name":"DEFENSE INTELLIGENCE AGENCY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I153","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T768","name":"DIA -MASINT RESEARCH PROJECT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T885","name":"DIA-MASINT"}}],"PIcoPI":[339203],"PO":["565136"]},"127500":{"abstract":"Rapport has been argued to be one of the central, if not the central, constructs necessary to understanding successful helping relationships and to explaining the development of personal relationships. Through systematic experimentation with humans and virtual (computer-based) humans, this project seeks to deepen understanding of the factors underlying rapport by looking more closely at the synchronization (i.e., process entrainment). The research will employ emotionally expressive virtual humans that are responsive to human participants' (i) respiratory patterns, (ii) facial feature and gaze tracking, and (iii) optical flow. If \"unilateral entrainment\" (of humans to virtual humans) produces rapport-like social consequences, it would greatly simplify interface agent design, obviating the need for sophisticated sensing and generation of matching behavior. Alternatively, it may promote certain undesirable social attributions -- incompetence, resentment, and dislike -- that could conflict with the goals of the application. This project investigates this fundamental question for human-computer interaction and virtual agent design. <br\/><br\/>This technology has the potential to facilitate the establishment of rapport between humans and virtual humans and to achieve the broader range of socially desirable consequences including improved computer-mediated learning and health interventions. As rapport is a key social moderator found to influence outcomes in a variety of settings that require teaching or persuasion, this research could inform the development of virtual training in the areas of negotiation, conflict resolution and cultural awareness. Finally, this project has broad dissemination potential given that rapport is inherently interdisciplinary, involving the domains of social psychology, business, communication and computer science.","title":"HCC: Building Rapport with Virtual Humans","awardID":"0713603","effectiveDate":"2007-08-15","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["514860"],"PO":["565227"]},"126554":{"abstract":"Proposal #: CNS 07-08767 07-08437<br\/>PI(s): Conklin, Megan Crowston, Kevin<br\/>Institution: Elon University Syracuse University<br\/> Elon, NC 27244-2010 Syracuse, NY 13244-1200<br\/><br\/>Project Proposed:<br\/><br\/>This collaborative project, developing FLOSSmole, a distributed collaborative community resource in the form of a broadly-shared data and analysis archive, enables research on Free\/Libre Open Source Software (FLOSS) and its development. With the goals of improving the reproducibility and consistency of the research and expanding access to the data, FLOSSmole collects, organizes, and shares comparable data and analyses of FLOSS development. A framework for organizing a system for facilitating access to the massive amounts of data collected by many simultaneous and currently unconnected FLOSS research efforts, FLOSSmole is designed to be a piece of research infrastructure. Because FLOSS development provides examples of successful computer-supported collaborative work, the project is relevant to various areas of research such as Human-Centered Computing and Cyberinfrastructure. It enables cooperation in data collection, aggregation and sharing. Furthermore, serving as a potential training ground for software developers, its development should teach us about software evolution and the understanding of how developers join and work in these teams.<br\/><br\/>Broader Impacts: Supporting improvement of a piece of collaborative research used by academics, practitioners in the software industry, and by society in general, the infrastructure promotes international collaboration and data sharing among research teams. Indeed, sharing code, data, schemas, queries, and experience promotes teaching and learning. The project should benefit students who work on it impacting courses and projects. Moreover, as an open source project itself the resource contributes to open and share data promoting collaboration, reducing duplicative efforts, and promoting compatibility between research teams.","title":"Collaborative Research: CRI: CRD: Data and analysis archive for research on Free and Open Source Software and its development","awardID":"0708767","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[335779],"PO":["564456"]},"137213":{"abstract":"This project addresses the development of general principled methods<br\/>to efficiently include domain knowledge expressed as constraints into <br\/>clustering algorithms. This not only allows improved clustering quality <br\/>and algorithm performance but also finding insights that are novel and <br\/>useful with respect to existing domain expertise. For example, phylogenetic <br\/>trees built using hierarchical clustering should be consistent with existing <br\/>domain knowledge such as that several species could not have evolved from <br\/>one another. <br\/><br\/>Existing clustering under constraints work has focused on non-hierarchical <br\/>clustering with conjunctions of must-link and cannot-link constraints that <br\/>assert that two objects must or must not be in the same cluster. This work <br\/>can be interpreted as expressing knowledge using a limited logic comprised <br\/>of instances as objects, two binary relations (must-link and cannot-link) <br\/>and a single connector (and).<br\/><br\/>This project will make three primary contributions. Firstly, it will examine <br\/>a more complete logic to represent knowledge by adding in new relations, a <br\/>complete set of connectives (not, and, or, implication), universal and <br\/>existential quantifiers and new objects. This logic can express a large <br\/>variety of knowledge such as minimum\/maximum cluster separation, cluster <br\/>width and even forcing distributions of certain objects across clusters. <br\/>Secondly, it will investigate incorporating constraints beyond non-hierarchical <br\/>clustering algorithms into algorithms for hierarchical agglomerative clustering, <br\/>graph and social network clustering, and feature selection for clustering. <br\/>Lastly, it will explore the computational challenges of using constraints by <br\/>identifying easy to satisfy sets of constraints and developing a framework to <br\/>explain why some constraint sets are more useful than others. <br\/><br\/>This project will demonstrate and validate its technical contributions on two <br\/>core application domains: analysis of pandemic micro-simulations results to <br\/>aid in disaster preparation and image mining. The long term vision is to <br\/>incorporate knowledge efficiently in a principled manner into other data mining <br\/>tasks such as classification, anomaly detection and association rules. <br\/><br\/>Project outreach for high school and undergraduates students will be in the <br\/>form of hands-on discovery learning courses with emphasis on the two core <br\/>application domains. For graduate students and researchers the tutorial slides, <br\/>papers, datasets and software generated from the project will be freely <br\/>available. <br\/><br\/>Further information on this project may be found at the URLs <br\/>http:\/\/www.constrained-clustering.org and http:\/\/www.cs.albany.edu\/~davidson.","title":"CAREER: Knowledge Enhanced Clustering Using Constraints","awardID":"0801528","effectiveDate":"2007-08-17","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[364548],"PO":["560586"]},"126565":{"abstract":"Networking research has long relied on simulation as the primary vehicle for demonstrating the effectiveness of proposed protocols and mechanisms. Typically, one simulates network hardware and software in software using, for example, the widely used ns-2 simulator. Experimentation proceeds by simulating the use of the network by a given population of users using applications such as ftp or web browsers. Synthetic workload generators are used to inject data into the network according to a model of how the applications or users behave.<br\/><br\/>In order to perform realistic network simulations, one needs a traffic generator that is capable of generating realistic synthetic traffic in a closed-loop fashion that ?looks like? traffic found on an actual network. Unfortunately, the networking community suffers from a lack of validated tools and models suitable for synthetic traffic generation. As a result, all too often, networking technology is evaluated using ad hoc workloads with an unknown relationship to traffic seen on real links and hence begs the question of how believable the results of the evaluation are.<br\/><br\/>This project is a collaborative effort to develop a synthetic traffic generation resource for the experimental networking research community. The resource consists of (1) synthetic traffic generators for the ns-2, ns-3, and GTNets software simulators, and Linux and BSD-based testbeds, (2) a repository of datasets to be used by the traffic generators to generate traffic that is statistically equivalent to traffic found on a variety of network links including campus networks, wide-area backbone networks, corporate intranets, wireless networks, etc, and (3) a set of traffic analysis tools to enable researchers to generate empirical models of traffic on network links of interest and to use these models to drive the synthetic traffic generation process.","title":"Collaborative Research: CRI: CRD Synthetic Traffic Generation Tools and Resources: A Community Resource for Experimental Networking Research","awardID":"0708828","effectiveDate":"2007-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["402290"],"PO":["434241"]},"129601":{"abstract":"Proposal Number 0722289<br\/><br\/>TITLE CPATH CB: Living In the KnowlEdge Society (LIKES)<br\/><br\/>PI Edward Carr<br\/><br\/>The Living In the KnowlEdge Society (LIKES) Community Building project, led by four sites (Virginia Tech, Villanova, NC A&T, and U. Texas El Paso), is transforming computing education for the 21st Century. The LIKES community, in collaboration with those from other disciplines, is identifying key computing concepts in these disciplines, then developing and implementing tools and techniques that enable learning of both computing concepts and the concepts of the disciplines. <br\/><br\/>Through a series of four workshops, related online community discussions, and our own research, the LIKES community is discovering key computing related issues in core disciplines and engaging leaders nationwide in brainstorming about their computing (education) needs. This aids faculty members, in computing-related education programs, such as Computer Science and Information Systems Departments, and in core \/ liberal education courses, engage with each other to build the global Knowledge Society. Deliverables include (1) new pedagogies in computing education; (2) integration of computing concepts into non-computing disciplines; (3) principles, guidelines, and techniques for integrating computing and non-computing curriculums; and (4) formation of new communities for enhancing that integration. This transforming of education in computing-related disciplines will yield a next generation of builders of the Knowledge Society.","title":"Concepts and Paradigms for the Knowledge Society Workshop","awardID":"0722289","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["366191"],"PO":["565264"]},"127445":{"abstract":"The goal of this research project is to systematically address the human factors in energy-efficient design of mobile computing systems. The project consists of three components. First, it will study how mobile users deal with and adapt to limited battery lifetime. It will subsequently apply the new knowledge to the design of system algorithms and their user interfaces for users to manually make effective tradeoffs between battery and other aspects of system usability. Second, this project will investigate the user impact of power-saving mechanisms and its context dependence. It will employ the Orbit body-area sensor nodes and mobile phone-based in situ survey tools to collect context information and subsequently build models of the context-dependent user impact. Using these models, the research project will employ information from user interfaces and body-area sensors to automatically apply power-saving mechanisms and adapt the system in a user-friendly way. Third, this project will explore tools and methodologies for designing energy-efficient graphical user interfaces on emerging OLED and bistable display technologies, which have dramatically different power characteristics from the conventional liquid crystal displays. The research project will employ both laboratory and field studies with technologies from quantitative self-reporting, qualitative ethnographic inquiries, and computer engineering. Its user studies and field trials will involve mobile users from under-served urban communities.<br\/><br\/>Mobile devices, in particular mobile phones, have shown great potential to provide low-income people with usable and affordable access to information technologies. Their limited battery lifetime and limited heat dissipation capability have become a critical challenge to achieving such potential. This research project has the potential to provide enabling technologies and tools that address this challenge thus help bridge the digital divide nationally and globally. It will make fundamental contributions to human-centered design of mobile computing systems as well as provide novel user interfaces, methodologies, algorithms, and their tool implementations for better battery usability and longer battery lifetime. The research endeavor will bring foundational knowledge into both human-centered computing and low-power design as well as bring new opportunities into mobile and ubiquitous computing. It is likely to have a broader impact in the industry through the PI's collaborations with industrial leaders. The research results will be incorporated into undergraduate and graduate courses in mobile computing. The tools, collected data, and educational content will be made open-source and on-line.","title":"HCC: Human Factors in Energy-Efficient Mobile Computing System Design","awardID":"0713249","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["548312"],"PO":["550147"]},"126477":{"abstract":"Abstract <br\/>Proposal #: CNS 07-09140 07-08307 07-08820 <br\/>PI(s): Brockman, Jay B. Bader, David A. Gao, Guang R. <br\/>Barabasi,Albert-Laszlo;Chawla,Nitesh;Kogge,PeterM. Vetter, Jeffrey S. <br\/>Institution: University of Notre Dame Georgia Institute Tech U.Delaware <br\/>Notre Dame, IN 46556-5602 Atlanta, GA 30332-0002 Newark, DE 19716-1551 <br\/>Proposal #: CNS 07-09385 07-09111 07-09254 <br\/>PI(s): Gilbert, John R. Upchurch, Edwin T. Yelick, Katherine A. <br\/>Wolski, Richard. <br\/>Institution: UC-Santa Barbara California Inst Tech UC-Berkeley <br\/>Santa Barbara, CA 93106-2050 Pasadena, CA 91125-0600 Berkeley, CA 94704-5940 <br\/>Title: Colla Rsch:IAD:Dev Rsch Infr. for Multithreaded Computing Community Using Cray Eldorado Platform <br\/><br\/>Project Proposed: <br\/><br\/>This collaborative project, developing a shared infrastructure needed to broaden its impact for developing software to run on the next generation of computer hardware, brings a diverse group of researchers from six universities in a joint effort. The work responds to the trend towards multicore processors where developers envision placing tens to hundreds of cores on a single die, each running multiple threads (in contrast to the currently dominant message-passing architectures resulting from the advent of MPI and Linux clusters). Three objectives are proposed: <br\/>. Acquiring computer hardware as a shared community resource capable of efficiently running, in experimental and production modes, complex programs with thousands of threads in shared memory; <br\/>. Assembling software infrastructure for developing and measuring performance of programs running on the hardware; and <br\/>. Building stronger ties between the people themselves, creating ways for researchers at the partner institutions to collaborate and communicate their findings to the broader community. <br\/>The Cray XMT system, scheduled for delivery in 2007 serves as an ideal platform. The second bullet includes algorithms, data sets, libraries, languages, tools, and simulators to evaluate performance of program running on the hardware focusing on applications that benefit from large numbers of threats, massively data intensive, \"\"sparse-graph\"\" problems that are difficult to parallelize using conventional message-passing on clusters. Each university contributes a piece to the infrastructure, using it for support of projects. Sandia National Laboratories has agreed to host the system and provide supplementary funding. Each university will use the Cray XMT system in courses. <br\/><br\/>Broader Impacts: The infrastructure measures performance providing a basis for the community to improve sharin, and build strong ties for collaboration and communication. Courses will be created and materials will be made available. Workshops for dissemination of the findings are also planned.","title":"Collaborative Research: CRI: IAD: Development of a Research Infrastructure","awardID":"0708307","effectiveDate":"2007-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["558497","406494"],"PO":["557609"]},"125267":{"abstract":"0702743<br\/>Rupak Majumdar<br\/>University of California - SD<br\/><br\/>Collaborative: Software Verification for Hardware Models<br\/><br\/>Modern microprocessors are some of the most complex engineering artifacts ever constructed, and their design complexity has been increasing in every generation. Correctness is a fundamental concern for microprocessors: all software applications implicitly assume correct operation of the processor. As demonstrated by the infamous Pentium division bug, the cost of bugs in the final system is prohibitive. Validating these complex designs is a real challenge. Current practice of extensive simulation for design validation is inadequate as it can only exercise a small portion of the state space, leaving many key properties unchecked.<br\/><br\/>This research applies techniques from formal verification to verifying the correctness of higher-level models of complex processors. Higher level processor models written in programming languages like C, C++, or SystemC, are becoming more and more prevalent as golden reference models for subsequent hardware implementations. While hardware and processor verification have been an active area of research, the novelty of this research is to merge the high-level design structure and powerful automated abstraction techniques developed in software verification (such as Predicate Abstraction, Shape Analysis, and Atomicity) with the insights from hardware verification (such as proof decomposition and memory abstraction). Instead of the usual bit-level models used in hardware verification, the combined techniques are likely to produce more compact models, helping the reasoning to scale to large systems, such as the complete description of a modern microarchitecture.<br\/><br\/>The research will tie in with the investigators' educational objectives of developing graduate level courses that combine the principles of formal verification with the principles of reliable system design.","title":"Collaborative: Software Verification for Hardware Models","awardID":"0702743","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["460594"],"PO":["564388"]},"129634":{"abstract":"Proposal #: CNS 07-22415<br\/>PI(s): Lusk, Mark T. <br\/> Ely, James F.; Ganesh, Mahadevan; Romig, Phillip R.<br\/>Institution: Colorado School of Mines <br\/> Golden, CO 80401<br\/>Title: MRI\/Acq.: High Perfomance Computing Cluster Dedicated to the Energy Science<br\/><br\/>Project Proposed:<br\/>This project, acquiring a high performance computing cluster with the intent of bringing a new dimension of capability to research in energy sciences, enables seven initial projects catalyzing the development of a culture of HPC for this community. The projects include: seismological modeling for fuel deposit identification, biomass energy conversion, hydrogen production photoelectrochemistry, polymer batteries, relating CO2 emission to climate change, with topics such as hydrocarbon deposits, hydrate nucleation and growth, biomass energy conversion, photoelectrical production of hydrogen, etc. Administered by the Golden Energy Computing Organization (GECO), the facility promotes activities which cross disciplinary lines and fosters links between education, scientific inquiry, and industrial pursuits covering a broad spectrum of energy-related research.<br\/><br\/>Broader Impact: The GECO cluster positively impacts national efforts to discover and develop new sources of energy enabling a critical aspect of HPC education, implementation of a training program in HPC maintenance. Furthermore, the institution has established a multi-faceted outreach program involving a college mainly serving Native Americans, Salish Kootenai, on Flathead Indian Reservation. Special training and research opportunities will also be made available to women engineers.","title":"MRI: Acquisition of a High Performance Computing Cluster Dedicated to the Energy Sciences","awardID":"0722415","effectiveDate":"2007-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[343600,343601,343602,"517450"],"PO":["557609"]},"127467":{"abstract":"The goal of this research is to evaluate the privacy risks associated with information sharing in online social networks and to propose efficient mitigation strategies that may enhance privacy while preserving valuable online interaction. Online social networks such as Friendster, MySpace, or the Facebook have experienced exponential growth in membership in recent years. These networks are successful examples of computer-mediated social interaction. However, they also raise novel privacy concerns. This research will quantify the risks associated with information sharing in online social networks, increase awareness about those risks and ways to mitigate them, and therefore help increase the usability and value of those networks.<br\/><br\/>This project will carry out three main activities. First, it will evaluate the risks that information publicly provided on a social networking site may be used to gather additional and potentially more sensitive data about an individual. Specifically, it will evaluate the risks that an individual's social security number may be estimated from ordinary social network data - with the ensuing threat of identity theft. Second, it will evaluate the risks that information publicly provided on a social networking site may be used to re-identify an individual in the context of pseudo-anonymous data. Specifically, it will evaluate the risk that an individual who posts images of him\/herself in otherwise pseudo-anonymous sites may be personally identified using standard face recognition technologies and publicly available social network data. Third, it will design and evaluate appropriate tools to mitigate the level of risk detected through the previous studies, in order to enhance privacy in online social networks without disrupting information sharing. <br\/><br\/>Online social networks are no longer a niche phenomenon; millions use them for communicating, networking, or dating. Security and privacy risks associated with online social networks therefore become significant. Hence, it is crucial to provide tools for privacy-awareness to users and directions for policy to public agencies as well as social network providers. However, the implications of this study are broader. Online social networks are just one way through which individuals today share personal information online. Computer-mediated communication makes it easy to share information and interact, but also to mine, store, and analyze that data. The wider goal of the research is to evaluate and, if necessary, raise awareness about the novel trade-offs associated with information sharing in computer-mediated social systems. The results will provide insight on how computer-mediated communication is creating new opportunities and threats. Such insight will be of use to government agencies for policy making; to individuals for self-awareness and control; and to private sector entities to inform them about potential vulnerabilities in their architectures.","title":"Evaluating and Enhancing Privacy and Information Sharing in Online Social Networks","awardID":"0713361","effectiveDate":"2007-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7486","name":"INFORMATION PRIVACY & SECURITY"}}],"PIcoPI":["553880"],"PO":["564456"]}}