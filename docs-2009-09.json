{"159049":{"abstract":"This CPATH project creates new pathways for undergraduate education majors to become computer science teachers and to obtain sound foundations in computational thinking. It includes a joint effort between faculty in the departments of computer science and education to create a Computer Science (CS) Endorsement program based on the Educational Computing Standards set by the International Society for Technology in Education. The pathways to the endorsement program will be targeted to diverse student groups: all education majors will be exposed to modules focused on computational thinking, science education majors will be able to fulfill general course requirements while taking courses towards the endorsement, and students transferring into education from a STEM discipline will be able to build on their background.<br\/><br\/>The proposed effort builds on existing courses and teacher education. Modules on computational thinking that highlight the pervasiveness of computational metaphors in topics like reasoning, knowledge construction, and problem solving are to be integrated into existing courses. Two new courses are to be developed jointly: a CS Methods course with an associated teaching practicum in computer science and a course in Great Issues in Computer Science. These courses provide students with pedagogical and content knowledge experiences preparing them to effectively teach computer science. The team plans to run a workshop to bring together educators and computer scientists with a focus on incorporating computation in secondary teacher education and exploring the establishment of computer science licensure standards.<br\/><br\/>Intellectual Merit: The design of a CS methods course and the associated collaboration between education and CS faculty should result in a better understanding of how to effectively teach secondary computer science, an urgent need in the nation's high schools. Selected material from the methods course will also benefit computer science faculty teaching introductory courses. Education students satisfying their practical training component in CS introductory courses will increase awareness of good practices and how to effectively teach introductory CS topics. The introduction of a Great Issues course will be of benefit and interest to a broad set of students. Thus the project has the potential to provide a national model for secondary computer science education and contribute to the sparse intellectual core currently existing in this area.<br\/><br\/>Broader Impact: The goal of the project is to increase the number of undergraduate education majors having taken CS courses and obtaining a CS Teaching Endorsement. This increase should translate into an increase in the number of future teachers who are qualified to teach computer science in high schools, are knowledgeable about computer science as a career, and who have an understanding of how the pervasive nature of computation impacts and changes our society. As a multiplier effect, qualified high school teachers teaching computer science should increase the number of high school students receiving a first computer science course. This increased contact is an important part in the ongoing national effort to raise interest in computer science and to educate a more computationally competent and proficient workforce.","title":"CPATH-2: Computer Science Pathways for Educators","awardID":"0938999","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["517654","425107","558286","558287",425106,425107,"425109",425109],"PO":["564181"]},"153780":{"abstract":"Recent technological advances enable collection of massive amounts of<br\/>data in science, commerce, and society. These datasets bring us<br\/>closer than ever before to solving important problems such as decoding<br\/>human genomes and coping with climate changes. Meanwhile, the<br\/>exponential growth in data volume creates an urgent challenge. Many<br\/>existing analysis tools assume datasets fit in memory; when applied to<br\/>massive datasets, they become unacceptably slow because of excessive<br\/>disk input\/output (I\/O) operations.<br\/><br\/>Across application domains, much of advanced data analysis is done<br\/>with custom programming by statisticians. Progress has been hindered<br\/>by the lack of easy-to-use statistical computing environments that<br\/>support I\/O-efficient processing of large datasets. There have been<br\/>many approaches toward I\/O-efficiency, but none has gained traction<br\/>with statisticians because of issues ranging from efficiency to<br\/>usability. Disk-based storage engines and I\/O-efficient function<br\/>libraries are only a partial solution, because many sources of<br\/>I\/O-inefficiency in programs remain at a higher, inter-operation<br\/>level. Database systems seem to be a natural solution, with efficient<br\/>I\/O and a declarative language (SQL) enabling high-level<br\/>optimizations. However, much work in integrating databases and<br\/>statistical computing remains database-centric, forcing statisticians<br\/>to learn unfamiliar languages and deal with their impedance mismatch<br\/>with host languages.<br\/><br\/>To make a practical impact on statistical computing, this project<br\/>postulates that a better approach is to make it transparent to users<br\/>how I\/O-efficiency is achieved. Transparency means no SQL, or any new<br\/>language to learn. Transparency means that existing code should run<br\/>without modification, and automatically gain I\/O-efficiency. The<br\/>project, nicknamed RIOT, aims at extending R---a widely popular<br\/>open-source statistical computing environment---to transparently<br\/>provide efficient I\/O. Achieving transparency is challenging; RIOT<br\/>does so with an end-to-end solution addressing issues on all fronts:<br\/>I\/O-efficient algorithms, pipelined execution, deferred evaluation,<br\/>I\/O-cost-driven expression optimization, smart storage and<br\/>materialization, and seamless integration with an interpreted host<br\/>language.<br\/><br\/>RIOT integrates research and education, and continues the tradition of<br\/>involving undergraduates through REU and independent studies. As a<br\/>database researcher, the PI is committed to learning and drawing from<br\/>work from programming languages and high-performance computing.<br\/>Findings from RIOT help create synergy and seed further collaboration<br\/>with these communities. To ensure practical impact on statistical<br\/>computing, RIOT has enlisted collaboration from statisticians and the<br\/>R core development team on developing, evaluating, and disseminating<br\/>RIOT.<br\/><br\/>Further information can be found at: <br\/>http:\/\/www.cs.duke.edu\/dbgroup\/Main\/RIOT","title":"III: Small: RIOT: Statistical Computing with Efficient, Transparent I\/O","awardID":"0916027","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["508314"],"PO":["565136"]},"153791":{"abstract":"TC: Small: Characterizing and Mitigating Device-Based Attacks in Cellular Telecommunications Networks<br\/><br\/>PI: Patrick Traynor (Traynor@cc.gatech.edu)<br\/>Co-PI: Jonathon Giffin (giffin@cc.gatech.edu)<br\/><br\/><br\/>Mobile phones have traditionally provided a limited set of telephony operations. However, the recent and rapid introduction of complex operating systems, sophisticated user interfaces and connectivity with the Internet has transformed these systems into highly capable general-purpose computing platforms. Unfortunately, the software implementing these systems often lacks even basic security protections. In this project, we will investigate the impact of an immature and vulnerable software infrastructure on both mobile devices and the cellular network core. Characterizing and responding to the threats is critical, especially given that the security models of cellular networks are designed around the assumption of highly limited user devices. We plan first to create Caegis, an in situ set of tools for ARM code analysis and over-the-air cellular phone fuzzing to help manufacturers improve the quality of their software and reduce its susceptibility to malware. We will then focus on basic mechanisms for Remote Repair, which will allow the network to help a device reboot to a known safe state. The development of these two tools, in combination with improved characterizations of the impact of malware, will significantly improve the security provided to this piece of critical infrastructure. Moreover, this project will help students in both independent research and a related class to gain hands-on experience with security research on our Alcatel-Lucent IMS network core.","title":"TC: Small: Characterizing and Mitigating Device-Based Attacks in Cellular Telecommunications Networks","awardID":"0916047","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["549758",409253],"PO":["565239"]},"162382":{"abstract":"Multimedia research, in particular, media understanding research which traditionally largely relies on computer vision research, has been around for many years. However, in general this area still remains open due to the challenging nature in computer vision research. The goal of this project is to attempt to narrow down the whole area to the connected multimedia with the hope to solve for real-world problems in this narrow area that shall lead to the technology development. To achieve this goal, this project is aimed at organizing an international workshop on connected multimedia to specifically address the general media understanding problem under the two constraints -- the social aspect and the cultural aspect. The intellectual merits are manifested through the expected advances in the literature of multimedia, data mining, information retrieval, as well as computer vision after the workshop; it is also expected that organizing this workshop may expedite and catalyze the interdisciplinary development in the areas of multimedia, data mining, information retrieval, and computer vision. The broader impacts of organizing this workshop include the promoted collaborations between computer scientists and social scientists and between academia and industries to work together to solve the problems on the topic of connected multimedia, which may further lead to technological development to provide effective solutions to several important real-world problems. The advanced literature this workshop generates may also serve as the updated materials for the graduate students working in the related areas to broaden and enrich their exposure to their professional training and education.<br\/><br\/>http:\/\/www.fortune.binghamton.edu\/nsf-iis-0956924.htm","title":"International Workshop on Connected Multimedia","awardID":"0956924","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["451438"],"PO":["564316"]},"162393":{"abstract":"Robust and efficient indoor object detection can help people with severe vision impairment to independently access unfamiliar indoor environments. However, most existing object detection methods are developed either for a specific type of object (e.g. face) or for general nature objects (e.g., building, sky, etc) which cannot be directly applied to indoor objects due to following challenges: 1) big inter-class variations of the object model among different indoor environments, 2) small intra-class variations of different object models, 3) less texture compared to objects in natural scene or outdoor environments, 4) only part of the object is captured due to occlusions or blind user, 5) view and scale variations of the objects caused by the position and distance change between the user and the object, and 6) lack of suitable databases.<br\/><br\/>This EAGER project is to explore new methods to detect indoor objects by incorporating the context information from signs (both text and iconic) and other visual clues such as signage of bathrooms and elevator floor numbers. The research enriches the study of object detection by incorporating context information, and leads to significant improvements over existing methods. The methods developed in this project provide new strategies and technologies for the blind and visually impaired to access unfamiliar indoor environments. The research also benefits many important research areas including video surveillance, intelligent conference rooms, video indexing, and human-computer interactions.","title":"Context-based Indoor Object Detection","awardID":"0957016","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560237"],"PO":["564316"]},"153450":{"abstract":"The objective of this proposal is to address various search problems in group theory. <br\/>Decision problems in group theory have been studied for over 100 years now, since Dehn put forward, <br\/>in the beginning of the 20th century, the three famous decision problems now often referred to as <br\/>Dehn's problems: the word problem, the conjugacy problem, and the isomorphism problem. In general, <br\/>decision problems are problems of the following nature: given a property P and an input O, find out <br\/>whether or not the input O has the property P. On the other hand, search problems are of the following <br\/>nature: given a property P and an input O with the property P, find a proof (sometimes called a \"witness\") <br\/>of the fact that O has the property P. This is a substantial shift of paradigm, and in fact, studying <br\/>search problems often gives rise to new research avenues in mathematics or computer science, very different <br\/>from those prompted by addressing the corresponding decision problems.<br\/><br\/>The potential broader impacts of the proposed research are extensive; the impact on the general area <br\/>of information security can be singled out. The difficulty of several well-studied problems, e.g. <br\/>integer factorization and the discrete logarithm problem underlie most current public-key cryptographic <br\/>protocols used in real-life applications. Developing public-key protocols based upon other search problems, <br\/>e.g. the conjugacy search problem whose difficulty has been well studied by group theorists, is prudent from <br\/>the standpoint of robustness, particularly if factorization or related developments threaten the security of <br\/>current protocols. The complexity of non-abelian infinite groups is a promising fertile ground for new <br\/>protocols and there is a great deal of preliminary work required such as that proposed here.","title":"Collaborative research: Theoretical and experimental approaches to search problems in group theory","awardID":"0914773","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550040","550041"],"PO":["565027"]},"151030":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Recent years have witnessed a dramatic change in the goals and modus operandi of malicious hackers. In particular, hackers have realized the potential monetary gains associated with Internet fraud. As a result, there has been an integration of sophisticated computer attacks with well-established fraud mechanisms devised by organized crime, which, in turn, created a vibrant underground economy. This project will develop novel techniques and tools to analyze and understand the underground economy, with the ultimate goal of obtaining a comprehensive picture of the criminal process. More precisely, the underground economy will be analyzed and modeled from three different vantage points: First, the project will identify the actors participating in the underground economy and models their different roles. Second, the project will analyze the processes and interactions between different criminal actors. Third, the project will examine the infrastructure that is used by criminals to carry out their operations.<br\/><br\/>The results of this project are techniques and tools to gather information about the infrastructure of the underground economy, the involved actors, and their interactions. This information can then be used to model the underground economy, improving the understanding of its structure and processes. Such increased understanding can be leveraged to create new techniques and processes for disrupting underground activities. As a result, the broader impact of the research project has the potential to reduce the amount and severity of crime and fraud performed on the Internet, benefiting the community at large. In addition, the tools and techniques will support cyber-crime law enforcement by enabling officers to identify malicious networks and ISPs to predict upcoming, significant attacks.","title":"TC:Medium:Analyzing the Underground Economy","awardID":"0905537","effectiveDate":"2009-09-15","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[402618,402619,"535035","535036"],"PO":["565136"]},"151041":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>This project focuses on understanding the principles and methods for the design of green networks at the edge of the Internet. The total power consumption of edge networks is estimated to be quite significant, so even moderate improvements in energy-usage in an individual device can result in non-trivial savings overall. Obtaining these moderate improvements in the energy-efficiency of edge networks is challenging for two reasons: the diversity of edge networks and the dynamics in their workload. <br\/><br\/>Intellectual Merit. Leveraging the researchers' combined expertise in low-power electronics, link-layer technologies, and energy-efficient network subsystem design and architecture, the project will: a) devise a deep energy-inspection architecture that encompasses a broad range of edge devices and networking technologies, and incorporates innovative hardware designs for subsystem-level monitoring and control of energy usage; b) explore run-time energy adaptation at various levels of the network, enabled by this inspection architecture; c) examine coordination mechanisms for controlling edge network energy usage which will allow coordinated energy management across components and devices, enabling more aggressive energy savings. <br\/><br\/>Broad Impacts. The project can have significant societal benefit, targeted as it is on sustainable technologies. Moreover, the techniques it develops for energy efficiency can be broadly applied to other areas of computing: large server systems, mobile devices, and consumer appliances. Beyond its impact on technology, the project will also contribute to workforce development by training EE and CS students in sustainability.","title":"NetSE: Medium: Collaborative Research: Green Edge Networks","awardID":"0905580","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["539241","515835"],"PO":["565090"]},"155892":{"abstract":"Proposal #: CNS 09-23479 <br\/>PI(s): Sabharwal, Ashutosh; Aazhang, Behnaam; Cavallaro, Joseph R.; <br\/> Knightly, Edward W.; Zhong, Lin<br\/>Institution: Rice University <br\/>Collaborative with<br\/>Proposal #: CNS 09-23484 <br\/>PI(s): Dacso, Clifford<br\/>Institution: Methodist Hospital Rsrch Inst.<br\/><br\/>Title: MRI\/Dev.: Mobile WARP: Platform for Next Generation Wireless Networks & Mobile Applications<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Project Proposed:<br\/>This collaborative project, developing a mobile, open, and all-layers programmable platform for wireless communication systems research, supports the design, development, and dissemination of a community platform instrument, for collaborative architecting next-generation wireless networks and mobile applications, including medical applications. Wireless Open-Access Research Platform (mobileWARP), targets fundamental new research for next generation mobile network clients.<br\/>The work involves the following thrusts:<br\/>- Programmable and Context-Aware Mobile Platform,<br\/>- True Cross-Layer Design Flows, and<br\/>- Open-Access for Research and Education.<br\/>Mobile WARP will be completely reprogrammable at all 7 layers of the networking stack and will support a touch-based user interface to develop state-of-the-art applications. With battery-operated<br\/>portable form factor, it will integrate context measurements from a variety of sensors (location, motion, power consumption, and health) and enable fundamentally new ideas in context-aware networking and applications. Two new design flows will be developed in support of the new hardware, one for the design of energy-efficient networking components on mobile handsets and the other for the design of mobile applications. Each design flow will be architected such that researchers at each layer do not have to learn any programming languages that they traditionally do not use. Lastly, to realize community-powered development, every part of mobileWARP will be open source: hardware designs, sensor subsystems, and all layers of the networking stack. Semester-long courses, laboratory exercises, operational reference designs, and hands-on mobileWARP workshops will also be developed. Reprogrammability at all layers ensures that clean state designs can be verified in a realistic design and testing environment. The platform opens an opportunity to explore merging application domains that could revolutionize the use of wireless. An important category of mobile healthcare for chronic illnesses will serve as a concrete example. Emphasis will be placed on always-available, ultra-low power designs for sensor, processing, and wireless subsystems.<br\/><br\/>Broader Impacts: Embodying a bold convergence concept, and with a potential for transformative change in wireless networking and mobile applications, the project directly impacts diverse research communities, cross-cutting multiple areas and application domains, including mobile healthcare for chronic illnesses. Furthermore, courses developed, as well as laboratory exercises, allow students to explore all layers of wireless radio communication.","title":"Collaborative Research: MRI: Development of mobileWARP - A Platform for Next-Generation Wireless Networks and Mobile Applications","awardID":"0923484","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["533458"],"PO":["557609"]},"151063":{"abstract":"Many services traditionally performed by stand-alone programs running on desktop computers are being migrated to ?Web 2.0? applications, remote services that reside ?in the cloud? and are that accessed through a browser. This migration process offers a unique opportunity to re-engineer the way that software is constructed, adding some extra capabilities that reduce the vulnerability of the global information infrastructure to problems such as viruses, cyber-attacks, loss of privacy, and integrity violations. <br\/><br\/>With this goal in mind, this project designs and implements a next-generation infrastructure for trustworthy web applications. It evolves the existing Web 2.0 technologies into a more trustworthy ?Web 2.Sec? version by introducing information-labeling and strong information-flow controls pervasively at the service provider, at the user?s end, and on all paths in between. <br\/><br\/>A key feature of the new Web 2.Sec architecture is that all application programs are executed on top of a virtual machine (VM) rather than directly on physical hardware. Hence the VM retains full control over the data at all times, allowing it to enforce information-&#64258;ow policies that guarantee con&#64257;dentiality and integrity. Even a malicious or faulty program running on top of the Web 2.Sec VM cannot cause any action that would violate these policies. <br\/><br\/>A strong educational component involving both graduate and undergraduate students rounds off the project.","title":"TC: Medium: Collaborative Research: Next-Generation Infrastructure for Trustworthy Web Applications","awardID":"0905650","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["556722"],"PO":["565327"]},"157740":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is the development of methods for the control of energy flow in buildings, as enabled by cyber infrastructure. The approach is inherently interdisciplinary, bringing together electrical and mechanical engineers alongside computer scientists to advance the state of the art in simulation, design, specification and control of buildings with multiple forms of energy systems, including generation and storage. A significant novelty of this project lies in a fundamental view of a building as a set of overlapping, interacting networks. These networks include the thermal network of the physical building, the energy distribution network, the sensing and control network, as well as the human network, which in the past have been considered only separately. This work thus seeks to develop methods for simulating, optimizing, modeling, and control of complex, heterogeneous networks, with specific application to energy efficient buildings. The advent of maturing distributed and renewable energy sources for on-site cooling, heating, and power production and the concomitant developments in the areas of cyberphysical and microgrid systems present an enormous opportunity to substantially increase energy efficiency and reduce energy-related emissions in the commercial building energy sector. In addition, there is a direct impact of the proposed work in training students with backgrounds in the unique blend of engineering and computer science that is needed for the study of cyber-enabled energy efficient management of structures, as well as planned interactions at the undergraduate and K-12 level.","title":"CPS:Medium:Cyber-Enabled Efficient Energy Management of Structures (CEEMS)","awardID":"0931748","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["552468",420994,420995,420996,420997,"538372"],"PO":["565274"]},"143231":{"abstract":"In computational geometry and numerical analysis, after performing many algebraic operations and root-takings, one often needs to determine whether the result is zero, positive or negative. The zero testing problem and sign determination problem play an essential role in the robust geometric computation. They are also closely related to fundamental questions in computational complexity such as polynomial identity testing. While the zero testing problem can usually be tackled by randomized algorithms, our understanding of the sign determination problem is very limited. The project will study derandomization techniques for zero testing problems, their applications in polynomial identity testing and complexity issues of sign determination problems.<br\/><br\/>Computational number theory and algebraic complexity theory often involve deep and abstract mathematical concepts, which are not covered in traditional computer science courses. However understanding these mathematical concepts is vital to information security workforce. The PI has taught cryptography for many years and he will continue working on issues of introducing number theory topics to computer science students. Many algorithmic problems on high degree algebraic numbers can be reduced to questions on integers represented by straight-line programs. Straight-line programs are procedures to build large integers by additions, subtractions and multiplications from small integers. The problems about straight line programs touch the core issues of complex theory in an intuitive manner. They can serve as an ideal vehicle to attract mathematically talented students to theoretical computer science. The PI will work on introductory materials on straight line programs that are suitable for high school students and undergraduate students.","title":"Zero Testing and Sign Determination of Algebraic Numbers","awardID":"0830524","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["518429"],"PO":["565157"]},"154000":{"abstract":"Today we have organizational and software procedures that facilitate the exchange of interpersonal information in social networking sites, instant messaging, bulletin boards, online role?playing games, computer?supported collaborative work, and online education. All of these applications fit into the larger category of social media that support virtual communities. As we increasingly rely on this cyberspace, the issue of privacy protection in social media is critically important. The objective of this project is to develop an advanced framework called U-Control for Digital Persona and Privacy Management to manage and release personal information considering a notion of digital persona based user privacy preferences and associated risks in disclosing such private information over virtual communities.<br\/><br\/>Successful completion of this project will result in the development of a protection framework and architecture to address the privacy challenges in social media-based virtual communities. This research effort is also expected to set an important direction to the future research in the area of virtual communities and online privacy solutions. This research has the potential for broad societal impact by providing","title":"TC: Small: Collaborative Proposal: User-Controlled Persona in Virtual Community","awardID":"0916875","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[409782],"PO":["564456"]},"158730":{"abstract":"This is a collaborative research effort bringing together expertise of Lise Getoor, University of Maryland College Park (0937094), Alex Pang, University of California-Santa Cruz (0937073) and Lisa Singh, Georgetown University (0937070).<br\/><br\/>In today's linked world, graphs and networks abound. There are communication networks, social networks, financial transaction networks, gene regulatory networks, disease transmission networks, ecological food networks, sensor networks and more. Observational data describing these networks can often times be obtained; unfortunately, this graph data is usually noisy and uncertain. In this research, we propose a formalism which allows us to capture and reason about the inherent uncertainty and imprecision in an underlying graph. We begin by proposing probabilistic similarity logic (PSL), a simple, yet powerful, language for describing problems which require probabilistic reasoning about similarity in networked data. We also introduce the notion of visual comparative analysis of PSL models derived using different evidence and assumptions, and illustrate its utility for the analysis of graphs and networks. <br\/><br\/>Dealing with noise and uncertainty in complex domains, and conducting comparative analytics are core capabilities required for the Foundations on Data Analysis and Visual Analytics (FODAVA) mission. This research focuses on integrating representation, comparative analysis and visualizations methods into an open source toolkit that supports the representation, comparison and visualization of PSL models. In addition to producing the toolkit, the research team is working with researchers in a variety of interdisciplinary domains to validate the utility of our approach, and also developing tutorial and training materials for the tools. <br\/><br\/>The key broader impact of the work is that the methods for reasoning about sources of noise and uncertainty in graphs, and understanding their impact on results are general and fundamental to the intelligent analysis of today's rich information sources. Results, including open source software will be distributed via the project Web site ( http:\/\/www.cs.umd.edu\/projects\/linqs\/fodava\/ ).","title":"FODAVA: Collaborative Research: Foundations of Comparative Analytics for Uncertainty in Graphs","awardID":"0937070","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}}],"PIcoPI":["557843"],"PO":["563751"]},"157520":{"abstract":"CPS: Small: Control of Distributed Cyber-Physical Systems under Partial Information and Limited Communication<br\/><br\/>The objective of this research is the development of novel control architectures and computationally efficient controller design algorithms for distributed cyber-physical systems with decentralized information infrastructures and limited communication capabilities. Active safety in Intelligent Transportation Systems will be the focus cyber-physical application. For the successful development and deployment of cooperative active safety systems, it is critical to develop theory and techniques to design algorithms with guaranteed safety properties and predictable behavior. The approach is to develop a new methodology for the design of communicating distributed hybrid controllers by integrating in a novel manner discrete-event controller design and hybrid controller design and optimization. <br\/><br\/>The methodology to be developed will exploit problem decomposition and will have significant technological impact for a large class of cyber-physical systems that share features of modularity in system representation, partial information, and limited communication. The focus on distributed control strategies with limited communication among agents is addressing an important gap in existing control theories for cyber-physical systems. The approach will mitigate the computational limitations of existing approaches to control design for hybrid systems. <br\/><br\/>Given the focus on cooperative active safety in Intelligent Transportation Systems, the results of this effort will have significant societal impact in terms of increased traffic safety and reduced number and severity of accidents. The broader impacts of this proposal also include involvement of high-school and undergraduate students and curriculum development by incorporating results of research into existing courses on cyber-physical systems.","title":"CPS: Small: Control of Distributed Cyber-Physical Systems under Partial Information and Limited Communication","awardID":"0930081","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["526914","497008"],"PO":["565274"]},"157641":{"abstract":"0930731<br\/>Baru<br\/><br\/>This collaborative grant to the San Diego Supercomputer Center and Arizona State University (PI: Arrowsmith\/EAR-0930643) will support a three year Facility project to further develop and scale up the OpenTopography Portal (http:\/\/www.opentopography.org) for provision of high-performance, internet-based access to large volumes of high-resolution airborne and ground-based LIDAR topographic data sets and generation of derived data products. The proof-of-concept OpenTopography Portal (OpenTopo) was developed through NSF\/Information Technology Research and EAR\/Geoinformatics support to the San Diego Supercomputer Center as part of the GEON Project. That portal currently hosts and distributes a limited number of data sets acquired through the NSF\/EAR supported National Center for Airborne Laser Swath Mapping (NCALM) at the University of Florida and from USGS and NASA-funded research. This support will enable significant upgrades and assimilation of large volumes of extant and future LIDAR data through: 1) provision of internet-based access to LIDAR topography data in multiple formats, including ?raw? point cloud data, standard LIDAR-derived DEMs, and easily accessible Google Earth products; and 2) development of additional collaborations with existing LIDAR topography data providers and hosts (e.g., NCALM, USGS, regional consortia, states, etc.) to link to their data archives and\/or to host and distribute their data and processing software algorithms through a freely accessible web-interface. High-resolution digital elevation models derived from LIDAR (Light Distance And Ranging) methods (both airborne and ground-based) have been revolutionary for Earth science, environmental, and engineering applications. These data are among the most powerful tools available for study of the bare Earth surface, vegetative cover, and civil structures. Capable of generating digital elevation models (DEMs) more than an order of magnitude better resolved than those currently available from digitized USGS topo maps or from Shuttle Radar Topography Mission products, airborne LIDAR (or airborne laser swath mapping - ALSM) provides the ability to acquire meter-scale resolution, decimeter accuracy elevation data sets over large areas at relatively low expense. Ground-based or terrestrial laser scanners (TLS) offers even finer resolution mapping for specific targets. These data enable research on surface processes at fine scales and extents not previously possible yet essential for understanding processes (e.g., erosion, hillslope creep) at the scales at which they operate. OpenTopo will address the challenge of making massive LIDAR data sets and products readily accessible to end users through a freely accessible web-portal.","title":"Facility Support: OpenTopography - A National Hub for High Resolution Topographic Data, Tools, and Knowledge","awardID":"0930731","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"6892","name":"CI REUSE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0600","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"8074","name":"EarthCube"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0603","name":"Division of EARTH SCIENCES","abbr":"EAR"},"pgm":{"id":"1580","name":"INSTRUMENTATION & FACILITIES"}}],"PIcoPI":["559496"],"PO":["563319"]},"154132":{"abstract":"Cognitive femtocells: Breaking the spatial reuse limits of cellular systems<br\/><br\/>Abstract:<br\/><br\/>The next generation of wireless cellular systems will be data traffic driven, providing seamless connectivity to the Internet and its services. In the areas of information and communication technologies, cellular systems and the Internet have proven to be the most transformative technologies for society. This research endeavors to optimally marry these two technologies with the goal of dramatically increasing achievable data rates and coverage. The proposed solution is to deploy very small cellular access points in residential homes and offices. These ``femtocells\" are connected to the network via existing DSL\/Cable and do not require additional deployment of costly wired infrastructure. Several theoretical challenges are posed by the femtocell concept. In particular, due to lack of coordination with the rest of the network, femtocells interfere with the network itself. This research develops novel solutions for femtocell technology by exploiting ideas from cognitive radio, based on intelligent opportunistic usage of the shared radio resource. Femtocell base stations will be deployed without careful frequency planning and will react to the interference environment by adapting their signaling strategy, thus, in the vernacular of cognitive radio, the cellular system plays the role of the ?primary? user. Unlike the classical cognitive radio scenario, the cellular signaling protocols and coding schemes are known. In this research we build on recent results on the Gaussian <br\/>interference channel and exploit the signal strength imbalances due to path-loss typical of cellular networks. Thus, the system is designed so that it operates predominantly in the regime of either weak or strong interference. Advanced signal processing and channel coding are exploited to utilize the fine structure of primary (cellular) signals, to explore the fundamental costs of cognitive radio and to develop coordination strategies to minimize this overhead. The goal of this novel design is to achieve a dramatic improvement in spatial reuse, allowing future cellular systems to achieve data rates comparable to wireless local area network while retaining the seamless connectivity and mobility of cellular networks.","title":"CIF: Small: Cognitive Femtocells: Breaking the Spatial Reuse Limits of Cellular Systems","awardID":"0917343","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["508212","515828"],"PO":["564924"]},"159830":{"abstract":"Positioning techniques for mobile devices play critical roles in many societal, industrial, and military activities. In current Global Positioning System (GPS), the triangulation and\/or trilateration calculation approach dominates, where a system of four or more quadratic equations must be solved, obtained from four or more satellite signals. However, this system does not work in challenging environments such as downtown areas where satellite signals are blocked by skyscrapers. <br\/><br\/>This work is to develop, analyze and evaluate computational methods that can improve the current GPS in terms of positioning accuracy and time efficiency. The proposed linearization approach in this project is unique in that it provides a closed form solution for quadratic equations in the calculation unit of GPS. The sensitivity analysis is derived to identify positioning error sources. The performance of GPS can then be significantly improved. Additionally, since the vulnerabilities in the positioning procedure are identified, this work is also a useful tool for solving security\/privacy related issues. This work is applicable to other wireless environments and can be incorporated with other wireless techniques, such as WiFi and wireless sensor networks (WSNs). Preliminary simulation results show that the performance of the proposed calculation method increases by 30% in terms of accuracy and 50% in terms of execution time complexity. <br\/><br\/>The fundamental framework and robust positioning techniques developed from this project will have broad impacts on high-tech industries. The transformative research will lead to the development and deployment of a new generation of practical positioning systems that can work effectively and efficiently in various challenging environments. The impact of this project also extends to academia and education through publications and dedicated websites.","title":"Collaborative Research: EAGER: Novel Theoretical Foundation for Wireless Positioning in Challenging Environments","awardID":"0943452","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":[427533],"PO":["564924"]},"158862":{"abstract":"This research project aims to understand and develop systems for<br\/>maintaining superlinear indexes for streaming data. A superlinear<br\/>index provides search capability over an abstract space that cannot<br\/>easily be linearized (totally ordered). In contrast, a linear index,<br\/>typified by a B-tree, supports point and range queries on totally<br\/>ordered data.<br\/><br\/>Examples of superlinear indexes include multidimensional indexes,<br\/>which can be over a geometric domain, such as geographic data, or<br\/>which can be over multiple linear indexes; and full text queries,<br\/>which can include searching for a particular word or substring.<br\/><br\/>The superlinear indexes found in today's databases cannot support high<br\/>rates of insertion. On traditional mechanical disk drives, the<br\/>existing superlinear indexes can only support about one hundred<br\/>insertions per second in the worst case. For many important<br\/>applications, that is too slow, and so database users often avoid<br\/>superlinear indexing. Even traditional linear indexes based on<br\/>B-trees cannot support the high insertion rates demanded by many<br\/>databases.<br\/><br\/>This research investigates streaming superlinear indexes, that is,<br\/>indexes that efficiently support full text or multidimensional<br\/>queries, and can be updated at speeds that are related to disk<br\/>bandwidth rather than seeks per second.<br\/><br\/>Among the significant research issues are the following: (1) design<br\/>efficient files structures for streaming superlinear indexes; (2)<br\/>investigate how streaming superlinear indexes might pave the way to<br\/>improved file systems; (3) determine whether cache-oblivious<br\/>algorithms technology can enhance streaming superlinear indexes; and<br\/>(4) program complex data structures for transactions and recovery.<br\/><br\/>If successful, this research will show how to build filesystems that<br\/>achieve dramatically better performance than today's B-tree-based<br\/>filesystems, how to maintain rich geometrical data and<br\/>multidimensional nongeographical databases in real time, and how to<br\/>maintain full-text searchable databases in real time. For example,<br\/>some of today's file systems try to maintain an full-text index to<br\/>find strings in files quickly, but these systems often fall behind at<br\/>high data write rates. A streaming superlinear index would allow such<br\/>a file system to keep up, and would improve the usability of both<br\/>high-end storage systems and relatively small consumer storage systems<br\/>that are nonetheless too large to index with today's indexes.<br\/><br\/>The researchers are developing course materials on streaming indexing<br\/>technology which will be made freely available under the MIT<br\/>OpenCourseWare initiative (http:\/\/ocw.mit.edu).<br\/><br\/>Further information on this project may be found at the project<br\/>web page: http:\/\/supertech.csail.mit.edu\/superlinear-indexes","title":"HECURA: Colaborative: Multidimensional and String Indexes for Streaming Data","awardID":"0937822","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["533341"],"PO":["565136"]},"157773":{"abstract":"CPS: Small: Collaborative Research: Foundations of Cyber-Physical Networks<br\/>The objective of this research is to investigate the foundations,<br\/>methodologies, algorithms and implementations of cyberphysical<br\/>networks in the context of medical applications. The approach is to<br\/>design, implement and study Carenet, a medical care network, by<br\/>investigating three critical issues in the design and construction<br\/>of cyberphysical networks: (1) rare event detection and<br\/>multidimensional analysis in cyberphysical data streams, (2)<br\/>reliable and trusted data analysis with cyberphysical networks,<br\/>including veracity analysis for object consolidation and redundancy<br\/>elimination, entity resolution and information integration, and<br\/>feedback interaction between cyber- and physical- networks, and (3)<br\/>spatiotemporal data analysis including spatiotemporal cluster<br\/>analysis, sequential pattern mining, and evolution of cyberphysical<br\/>networks.<br\/>Intellectual merit: This project focuses on several most pressing<br\/>issues in large-scale cyberphysical networks, and develops<br\/>foundations, principles, methods, and technologies of cyberphysical<br\/>networks. It will deepen our understanding of the foundations,<br\/>develop effective and scalable methods for mining such networks,<br\/>enrich our understanding of cyberphysical systems, and benefit many<br\/>mission-critical applications. The study will enrich the principles<br\/>and technologies of both cyberphysical systems and information<br\/>network mining.<br\/>Broader impacts: The project will integrate multiple disciplines,<br\/>including networked cyberphysical systems, data mining, and<br\/>information network technology, and advance these frontiers. It will<br\/>turn raw data into useful knowledge and facilitate strategically<br\/>important applications, including the analysis of patient networks,<br\/>combat networks, and traffic networks. Moreover, the project<br\/>systematically generates new knowledge and contains a comprehensive<br\/>education and training plan to promote diversity, publicity, and<br\/>outreach.","title":"CPS: Small: Collaborative Research: Foundations of Cyber-Physical Networks","awardID":"0931972","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550342"],"PO":["564778"]},"154143":{"abstract":"Web applications are prevalent and enable much of today's online<br\/>business including banking, shopping, university admissions, and various<br\/>governmental activities. However, the quality of such applications is<br\/>usually low, and they are increasingly popular targets for attack. This<br\/>project aims at developing practical testing and analysis mechanisms and<br\/>tools to secure web applications. In particular, it focuses on<br\/>developing novel, principled techniques to address the following<br\/>research issues: (1) how to formalize security threats in web<br\/>applications; (2) how to provide runtime security for deployed<br\/>applications via dynamic monitoring; and (3) how to provide static<br\/>security enforcement during application development and testing.<br\/><br\/>The project is interdisciplinary, touching upon a number of requisite<br\/>areas including computer security, software engineering, and programming<br\/>languages. It has the potential to advance knowledge in each of these<br\/>disciplines with novel formulations of security requirements, systems<br\/>concepts, and advanced testing and analysis techniques. The project<br\/>also has the potential for significant industrial and societal impact.<br\/>Through the proposed research, education, and outreach activities, the<br\/>project will empower web application developers with the knowledge,<br\/>methodologies, and development tools to build secure web<br\/>applications. Testing and analysis tools developed in the project will<br\/>also be distributed to other institutions and the industry for teaching,<br\/>research, and experimental evaluation.","title":"TC: Small: Runtime and Static Analysis for Web Application Security","awardID":"0917392","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["562712"],"PO":["565327"]},"148951":{"abstract":"The University of New Hampshire (UNH) plans to acquire a high-performance computer from IBM, funded by the National Science Foundation and supplemented by an IBM University Research grant. This machine is powered by 84 PowerXCell 8i processors with a total of 756 computational cores. Beyond substantially increasing UNH's scientific computing capabilities, it provides access to a state-of-the-art accelerator-based architecture, as employed in the world's most advanced supercomputers like Roadrunner at Los Alamos National Laboratory. This research involves grand science challenges in the fields of magnetospheric<br\/>physics (space weather), plasma physics, and computational fluid dynamics, lattice quantum chromodynamics and genomics.<br\/>The investigators on this project conduct research on algorithms and program-<br\/>ming models for modern hardware architectures. Since computational capabilities have advanced from being driven by enhancements in speed to increasing the number of processors and computational cores, efficient exploitation of highly parallel machines challenges conventional programming models and increases the complexity of algorithms. The researchers plan to develop and deploy new computational approaches for describing, at a higher level of abstraction, the equations to be solved and then uses specific computer software,<br\/>including source-to-source translation, to generate highly optimized implementations tailored to the hardware to be used. The program also provides first-hand experience using a cutting-edge supercomputer to students in UNH.","title":"Acquisition of a Cell BE based Cluster for Development and Deployment of Advanced Computational Methods","awardID":"0855145","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["542563","560385","564652","509669","408722"],"PO":["565272"]},"169642":{"abstract":"The research involves the design and analysis of efficient algorithms for fundamental problems that arise in studies of the three-dimensional structures of proteins. Graph-theoretic problems underlie these studies, since protein structures are naturally (and sufficiently) represented by graphs that have vertices for the individual amino acid residues and edges between close pairs. However, graph-theoretic formalisms lead to computationally hard optimization problems, further complicated by extensive amounts of noise in experimental data. Motivated by specific challenges in nuclear magnetic resonance spectroscopy and other protein structure studies, the project addresses two significant algorithmic problems: identifying correspondences between a pair of graphs where one is a significantly corrupted version of the other, and determining three-dimensional coordinates for the vertices of a graph, given approximate, noisy distance measurements for its edges.<br\/><br\/>The first algorithmic problem is a form of graph matching, and the project focuses on developing efficient search algorithms to uncover correspondences, with random graph models to rigorously analyze the algorithms and study threshold phenomena characterizing robustness to noise. In an application to analysis of NMR data, one of the graphs represents the protein and the other the data, a noisy, ambiguous set of atomic interactions; the goal is to match the NMR-identified interactions with specific atomic interactions in the protein. The second algorithmic problem is Euclidean embedding for sparse geometric graphs, and the research involves development of algorithms to render such graphs amenable to low rank distance matrix reconstruction methods, generalizing the reconstruction methods to exploit the underlying geometric structure and account for the confounding noise structure. In the NMR setting, the graph represents NMR-probed through-space atomic interactions, and the goal is to compute structures consistent with the experimental data and biophysical constraints. Both problems are fundamental to numerous other significant applications in protein structure studies.","title":"AF:Small:Collaborative Research: Algorithmic Problems in Protein Structure Studies","awardID":"1023160","effectiveDate":"2009-09-17","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["531610","454047"],"PO":["565223"]},"157784":{"abstract":"Objectives and approaches. The objective of this research is to create a novel Cyber-Physical System, a self-reconfiguring ?second skin orthotic sleeve? consisting of programmable materials. The orthotic sleeve, worn over one or more limbs of brain-injured individuals, may restore brain function by promoting enriched exploration of self-produced limb movements. The approach consists of three steps (1) micro-fabricating sheets with embedded sensors and muscle-like collections of force-producing actuators, (2) conducting longitudinal recordings of kicking by typically developing and preterm brain-injured infants who wear a sensing, but not actuated micro-fabricated second skin, and (3) developing biologically-inspired programming techniques to help determine an algorithm with which the second skin embedded actuators may adaptively assist the ever-changing developmental pattern of infant kicking.<br\/>The technology can be applied to many mobility-impaired populations,including children and adults with brain injury, the ageing population, and injured soldiers. The project will inform basic scientific and engineering research in areas such as formation of architectural structures by large-scale multi-agent robotic systems, and self-organization of swarming small-scale agents that act autonomously in cooperation with biological systems. The multi-institutional effort of this research endeavor will positively impact undergraduate and graduate science education via explorations of the intersection of biology and computation in cyber-physical systems. Innovation, teamwork, and the value of communication are encouraged. These efforts will promote education of an American work force that is technically expert, scientifically comprehensive, and socially aware to sustain national excellence in a future increasingly based on technologically complex systems.","title":"CPS:MEDIUM:Programmable Second Skin to Re-educate Injured Nervous Systems","awardID":"0932015","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["553416"],"PO":["565239"]},"154033":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Cheap commercial off-the-shelf wireless devices are being increasingly deployed for performance-sensitive applications such as patient monitoring with body sensors and home networking for multimedia and gaming. However, wireless communications may interfere with each other when they use the same or adjacent radio frequencies. This becomes a growing issue as the public 2.4GHz spectrum is being populated by a variety of devices, including 802.11b\/g routers, ZigBee sensors, Bluetooth headsets, and cordless phones. Existing interference mitigation schemes are tightly tied with the physical\/MAC layers of particular platforms, and hence often cannot co-exist in the same network without sacrificing the system performance. <br\/><br\/>This project develops a Holistic Transparent Performance Assurance (HTPA) framework to support performance-sensitive applications in the crowded spectrum. HTPA consists of 1) a spectrum profiler that models the spectrum usage and dynamic external, intra- and inter-platform interferences in heterogeneous wireless environments; 2) a virtualized medium access control layer that provides unified interfaces for transparently representing, monitoring, and scheduling the underlying radio resources; and 3) a stream and system performance assurance component that schedules radio resources for each individual data stream, and harnesses network interference based on the system knowledge, MAC abstractions, and dynamic spectrum models.<br\/><br\/>HTPA enables network designers to systematically understand and mitigate the impact of complex interference that exist between heterogeneous wireless devices, and provides reference models for the standardization of future commercial wireless platforms operating in unlicensed spectrums.","title":"NeTS:Small:Collaborative Research:Holistic Transparent Performance Assurance within the Crowded Spectrum","awardID":"0916994","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["545346"],"PO":["564993"]},"157553":{"abstract":"This project, supported by the Ethics Education in Science and Engineering Cross-NSF program, investigates the relationship between engineering and social justice. Given the global challenges of the 21st century, engineering educators are implementing innovative ways to prepare tomorrow's engineers--including programs and courses in community service, sustainable development, and humanitarian engineering. That engineering students might be enacting various forms of social justice in these programs and courses raises important questions. How are engineering students interpreting social justice? How do those interpretations intersect with their education as engineers? What might engineering and social justice have in common? In which ways have these two fields of practice aligned, clashed, or interfaced in recent US history? How and why should relevant dimensions of social justice be effectively taught and disseminated throughout engineering curricula? <br\/><br\/>The main goal of this project is to research these questions and develop educational resources aimed at relevant connections between engineering and social justice, allowing for various interpretations of social justice. To achieve this goal, the project researches historical and ethical connections between engineers and social justice. Furthermore, given the surge in university programs related to community service and humanitarian engineering, the project contributes by developing relevant instructional case studies. The project will also result in a book about Engineering and Social Justice with chapters exploring the social-justice dimensions of engineering during the New Deal, radical and non-radical engineers in the 1960s, engineers of appropriate technology, engineers of sustainable development, and engineering to help. Primary project partners and audiences include engineering faculty and students, engineers in organizations actively pursuing social-justice goals, and a growing network of engineering educators interested in social justice issues. This project stands to have a broad impact by increasing recruitment and retention among US engineering students, particularly women and underrepresented groups, as students become more concerned with the social relevance of their careers.","title":"Engineering and Social Justice: Research and Education of (In)commensurable Fields of Practice","awardID":"0930213","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7915","name":"Ethics & Values of SET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":["563512",420421,"542362"],"PO":["471270"]},"157795":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5)<br\/><br\/>The objective of this research is considering security and timing as primary concerns, re-envisioning computer architecture and network algorithms to provide a robust foundation for CPS. The approach is rethinking the hardware and software divide, providing true process concurrency and isolation. Extending these benefits to the communication network so integral to CPS, multicast and security innovations that consider CPS constraints will be proposed.<br\/><br\/>This project will provide computational and communication foundations for CPS through the following tasks. (1) An open source hardware design will be created. Abandoning the error-prone paradigm of shared memory communication, Precision Timed (PRET) processors for dataflow computations will be extended. (2) The hardware\/software interface will be investigated specifically for PRET architectures. (3) A routing algorithm considering the CPS constraints will be investigated. The constraints include efficiency, adaptability, scalability, simplicity, and security. (4) Distributed Source Coding for CPS applications will be studied with focus on challenges from small packet sizes in these applications. <br\/><br\/>This project will engage the community and students in multiple grades and institutions, through the following undertakings. (1) A package for education and research in CPS will be assembled. This package and the material from this project in the form of tutorials, publications, and curriculum will be available to other institutions. (2) New courses will be created integrating research results into education. (3) A diverse group of students including women and minorities will be recruited. (4) Two applications will be implemented in the fields of medical devices and emergency response.","title":"CPS: Small: RUI: CPS Foundations in Computation and Communication","awardID":"0932113","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[421171,"537446"],"PO":["564778"]},"148973":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project provides infrastructure to the University of Pennsylvania to build from their existing work into the area of mobile manipulation.<br\/><br\/>The GRASP Lab is an internationally recognized robotics research group at the University of Pennsylvania. It hosts 14 faculty members and approximately 60 Ph.D. students from the primary departments of Computer and Information Science (CIS), Electrical and Systems Engineering (ESE), and Mechanical Engineering and Applied Mechanics (MEAM). <br\/><br\/>GRASP recently launched a multidisciplinary Masters program in Robotics and involves these students, as well as many Penn undergrads, in its research endeavors. The research conducted by the members of the GRASP laboratory includes such areas as vision, planning, control, multi-agent systems, locomotion, haptics, medical robotics, machine learning and modular robotics. This proposal requests funding for instruments that would enable us to broaden our research to include the important new area of mobile manipulation. <br\/><br\/>An increasing amount of research in robotics is being devoted to mobile manipulation because it holds great promise in assisting the elderly and the disabled at home, in helping workers with labor intensive tasks at factories, and in lessening the exposure of firemen, policemen and bomb squad members to dangers and hazards. As concluded by the NSF\/NASA sponsored workshop on Autonomous Mobile Manipulation (AMM) in 2005, the technical challenges critically requiring the attention of researchers are:<br\/><br\/>? dexterous manipulation and physical interaction<br\/>? multi-sensor perception in unstructured environments<br\/>? control and safety near human beings<br\/>? technologies for human-robot interaction<br\/>? architectures that support fully integrated AMM systems <br\/><br\/>The researchers at GRASP fully support these recommendations and want to help lead the way in addressing them. Though GRASP conducts a great deal of research on similar challenges in related areas, this group has not worked on the unique and potentially transformative topic of mobile manipulation. The primary inhibitor to pursuing these challenges is that research in mobile manipulation critically depends on the availability of adequate experimental platforms. This group is requesting funding that would allow them to acquire such equipment. <br\/><br\/>In particular, this group is requesting funding for <br\/>(a) one human-scale mobile manipulator consisting of a Segway base, Barrett 7-DOF arm, and 3-fingered BarrettHand equipped with tactile sensors and a visual sensing suite; and <br\/>(b) four small Aldebaran Robotics NAO humanoid robots capable of locomotion and manipulation. <br\/><br\/>These instruments will allow the GRASP community to perform research in such areas as autonomous mobile manipulation, teleoperated mobile manipulation, navigation among people, bipedal locomotion, and coordination of multiple mobile manipulation platforms. Advances in this area are beneficial to society in a variety ways. For example, mobile manipulation is one of the most critical areas of research in household robotics, which aims at helping people (especially the elderly and the disabled) with their chores. Mobile manipulators will also see great use in office and industrial settings, where they can exibly automate a huge variety of manual tasks.","title":"II-EN: Mobile Manipulation","awardID":"0855210","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["549664","426074","553287","505322","562688"],"PO":["564181"]},"159984":{"abstract":"OCI 0944131<br\/>Hans-Werner Braun<br\/>University of California at San Diego<br\/><br\/>Abstract<br\/><br\/>This award supports Hans-Werner Braun's research at the University of California at San Diego through the High Performance Wireless Research and Education Network (HPWREN) which is an NSF funded wireless high bandwidth cyberinfrastructure, which originated in the year 2000 and has been continually evolving to include various research and education applications in difficult to reach areas, as well as first responder and public safety activities. The network operates in predominantly remote and rugged areas of Southern California, spanning from San Clemente Island in the Pacific Ocean, via the California coast, to the inland valleys and on to the high mountains, reaching an altitude of more than 8700 feet. It then extends across the desert, reaching sites close to the Arizona border. Many scientific disciplines and education activities benefit from the network, including a number of NSF-funded projects. Without access to this high-speed data Networking connectivity, many of these project research objectives would be difficult, and several even impossible to achieve.<br\/><br\/>Intellectual Merit<br\/>The collection of real-time data is one of the most valued aspects of the network, such as the deployment of various environmental sensors that enable an understanding of environmental conditions that would be had to obtain otherwise. Real-time data allows for increased knowledge and understanding of an array of scientific concepts such as heavily impact ecological systems on the earth and the tracking of transient events throughout the universe. Examples of significant accomplishments include the research on network workloads with a diverse traffic profile, as well as major discoveries by the Palomar Observatory, providing invaluable assistance during wildland fires, and the social aspects of enlarging Native American contacts with the mainstream populations, with major educational benefits being derived from such contact.<br\/><br\/>The two-year work scope for this renewal proposal is three-fold. (s) maintain and enhance the HPWREN cyberinfrastructure for its many interdisciplinary and multi-institutional research, education, and public safety activities, (2) continue the research on Quality of Service considerations on a highly functional wireless cyberinfrastructure environment, and (3) evaluate transition strategies towards an objective of a more sustainable infrastructure.<br\/><br\/>Broader Impact<br\/>Throughout its existence, the HPWREN project has been successful in its broader impacts, as evidenced by many news updates on the http:\/\/hpwren.ucsd.edu\/web site. This project is centered around network research aspects and also serves as an enabling cyberinfrastructure for various science disciplines and education activities. While partnering with multiple institutions. HPWREN collaborators, alongside this project's NSF support, invested substantially into the overall environment, including by augmenting it with many projects of various scopes and sizes. Specific HPWREN research is ongoing in the areas of workload profiling, performance assessments, as well as backbone and access link Quality of Service and Policy Based Routine implementations and experimentations. Research also continues in the area of network impact-considerate intelligent sensors, forwarding data based on locally determined events, rather than continuously. The current stability and reliability of this network is a direct result of lessons learned in its multi-year development effort. This includes a significant investment in FCC-licensed spectrum radio system and an implementation of backbone link diversity, as well as upgrading of high-traffic links to 155Mbps capacity. Further enhancements are planned, such as a separate 45Mbps path to the Palomar Observatory bringing its aggregate bandwidth to 200Mbps of full-duplex links. Continuation of the HPWREN infrastructure and research environment is an objective of this project.","title":"Integration and Analysis of Reliable Networking for Remote Science, Education, and First Responders","awardID":"0944131","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["554383","533854"],"PO":["564246"]},"148984":{"abstract":"Through Grid and Cloud computing, the importance of distributed computing has risen dramatically in recent years, increasing the computational power available to a widening audience of scientific and commercial users. Gains in computing power have caused a drastic increase in the volume of data produced by users, requiring new research on improved management and access to distributed data. These gains also drive the need for efficient scheduling and leasing of computational resources and for adapting current work in machine virtualization to a distributed context. These research directions require the development and evaluation of new models for computational, communication, and storage costs, but existing infrastructure makes model evaluation difficult or impossible, since they are in constant use by other researchers.<br\/>This project addresses these concerns by providing a diverse group of researchers with a Distributed Research Testbed (DiRT) on which to develop and evaluate new technologies. The clusters making up the testbed are located at the University of Chicago, the University of Florida, the University of Hawai?i, the University of Notre Dame, and the University of Mississippi. Unlike working grid environments, we have complete low-level control of the hardware and complete knowledge of where the data and computation are located. We will use the testbed to address problems faced today by the growing number of users of distributed computing. Because high performance computing is essential to the conduct of modern science, this project will have significant impact on research and education in a a wide variety of scientific disciplines.","title":"Collaborative Research: II-New: Distributed Research Testbed (DiRT)","awardID":"0855246","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["526412"],"PO":["564778"]},"154088":{"abstract":"Approaches to subjectivity and sentiment analysis often rely on<br\/>manually or automatically constructed lexicons. Most such lexicons are<br\/>compiled as lists of words, rather than word meanings (\"senses\").<br\/>However, many words have both subjective and objective senses as well<br\/>as senses of different polarities, which is a major source of<br\/>ambiguity in subjectivity and sentiment analysis. The proposed work<br\/>addresses this gap, by investigating novel methods for subjectivity<br\/>sense labeling, and exploiting the results in sense-aware subjectivity<br\/>and sentiment analysis. To achieve these goals, three research<br\/>objectives are targeted. The first is developing methods for assigning<br\/>subjectivity labels to word senses in a taxonomy. The second is<br\/>developing contextual subjectivity disambiguation techniques to<br\/>effectively make use of the word sense subjectivity annotations. The<br\/>third is applying these techniques to multiple languages, including<br\/>languages with fewer resources than English. The project will have<br\/>broader impacts in both research and education. First, it will make<br\/>subjectivity and sentiment resources and tools more widely available,<br\/>in multiple languages, to the research community, which will help<br\/>advance the state of the art in automatic subjectivity analysis, which<br\/>in turn will benefit end applications. Second, several educational<br\/>goals will be pursued: training graduate and undergraduate students in<br\/>computational linguistics; augmenting artificial intelligence courses<br\/>with projects based on the proposed research, which will offer<br\/>students hands-on experience with natural language processing<br\/>research; and reaching out to women and minorities to increase their<br\/>exposure to text processing technologies and access to research<br\/>opportunities.","title":"RI: Small: Collaborative Research: Word Sense and Multilingual Subjectivity Analysis","awardID":"0917170","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["564432"],"PO":["565215"]},"159302":{"abstract":"The Ana G. M\u00e9ndez University System (AGMUS) and its institutions - Universidad del Este (UNE), Universidad del Turabo (UT), and Universidad Metropolitana (UMET) - in collaboration with universities in Puerto Rico - the University of Puerto Rico, Inter American University (IAU), Universidad Polit\u00e9cnica de Puerto Rico (UPPR), and the University of the Virgin Islands (UVI) - proposes to create an alliance to forming the Caribbean Computing Center for Excellence (CCCE). Additional partners for this project include the Puerto Rico Department of Education, the Institute of Electrical and Electronic Engineers (IEEE) Computer Society Chapters in San Juan and Mayaguez, public and private high schools, INTECO and INTENOR (consortia of municipalities, institutions of higher education and industrial partners from the north and central east of the Island), the industrial and business community of Puerto Rico, and community-based associations in Puerto Rico. Extended partnerships include a number of research institutions on the US mainland and abroad. <br\/><br\/>The CCCE aims to increase the recruitment and retention of students in the computing disciplines, with an emphasis on students from the underrepresented groups. It will recruit high school seniors with hands-on research experiences in university settings, deliver professional development to in-service high school teachers, provide undergraduates with a rich set of research opportunities in Puerto Rico, on the mainland and abroad, and work to prepare undergraduates for graduate school success.","title":"BPC-A: Caribbean Computing Center for Excellence (CCCE)","awardID":"0940522","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["538934"],"PO":["560704"]},"154099":{"abstract":"Computer systems are commonly coupled with human operators who add<br\/>hands, eyes, and judgment to the computer programming and its sensors<br\/>and actuators. The operators can be viewed as programming platforms<br\/>in their own right, where manuals, training, and system feedback<br\/>provide the programming. However, operators have unique platform<br\/>characteristics compared to computers, including, in particular, the<br\/>likelihood of making numerous and diverse errors. Hence systems that<br\/>rely on operators require a protection envelope representing an<br\/>engineered collection of system behaviors that prevent important types<br\/>of operator errors from leading to losses. Having a well chosen<br\/>protection envelope is crucial to the robustness of a system that<br\/>relies on human operators. This project formalizes operator task<br\/>analysis based on models, languages, and techniques created for the<br\/>formal analysis of concurrent processes and use this formalization to<br\/>specify and automatically prove properties of the protection envelopes<br\/>of systems that rely on human operators for their safe and secure<br\/>execution in specified environments. The project uses concurrent game<br\/>structures to provide a technical foundation for reasoning about<br\/>protection envelopes specified using alternating-time temporal logic.<br\/>Progress is validated with case studies for airport screening and<br\/>veterinary tagging protocols. Interest in this type of contribution<br\/>will extend beyond specialized areas like jet pilots and nuclear plant<br\/>operators to roles like: customers in ecommerce transactions or<br\/>automated retail checkouts, drivers in automobiles with new types of<br\/>computer control, managers of smart warehouses, factory floors, and<br\/>office buildings, and first responders in emergencies.","title":"TC: Small: Formalizing Operator Task Analysis","awardID":"0917218","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553855","549775"],"PO":["565264"]},"146245":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).<br\/><br\/>This project will develop the ideas behind, and tools required for, a Rationale Management System that captures design decisions made during software development. The approach utilizes technology developed to support the Semantic Web, using Semantic Annotation to extract information so that it can be structured into an argumentation format for use in development and maintenance. The research and educational activities will impact our ability to leverage knowledge captured during the development of software projects to enhance those software projects. The project will also use rationale to enhance the educational experience of students. The relationship between argumentation-based rationale and student learning will be explored through the Rationale, Critical Thinking, and Creativity Project which evaluates the ability of rationale to assist students in moving to higher levels of cognitive and intellectual development. Partnerships with outreach organizations will provide learning opportunities for underrepresented groups and persons with disabilities.","title":"CAREER: Rationale Capture for High-Assurance Systems","awardID":"0844638","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["425208"],"PO":["564388"]},"146498":{"abstract":"With the continuing proliferation of wireless technology, a wide spectrum of emerging applications using this technology will be tightly interwoven into the fabric of our everyday lives: wireless sensor networks can monitor personal health or critical infrastructures. The viability and success of many of these applications critically hinges on the availability of the underlying wireless communication. As wireless networks become increasingly pervasive, the problem of radio interference and jamming will be inevitable, raising a serious threat to the availability of wireless services. To enable the continuous and highly-available data delivery services over the entire lifetime of wireless networks in support of wireless applications, it is crucial that the wireless networks have built-in strong defense mechanisms against interference and jamming.<br\/> <br\/>This project aims to develop a suite of holistic solutions that monitor the radio environment and provide quick recovery to interrupted services in case of jamming or radio interference. In contrast to traditional techniques, such as spread spectrum which requires costly new hardware, the proposed techniques involve networks to manage their resources collaboratively across all layers to assure the availability of network services, leveraging existing commodity wireless platforms. Through the interaction with industry partners, the project results are expected to provide guidance for coping with jamming in future network architecture. <br\/> The educational component of this project seeks to prepare students to face the challenges of rapidly evolving technologies in wireless networks. The experimental and design components of this project will enhance both the undergraduate and graduate students? education in related areas.","title":"CAREER:THAWS--Towards Highly Available Wireless Services","awardID":"0845671","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["489734"],"PO":["497499"]},"158598":{"abstract":"This grant provides support to graduate students to attend IEEE DySPAN 2010, a premier international venue where technical and policy researchers in the area of dynamic spectrum access gather together in order to examine the state-of-the-art and identify future directions in software defined radio (SDR) and cognitive radio (CR) networking and policy that will lead to creative, original, and transformative concepts. The conference provides not only technical and policy paper presentations but also a wide range of other educational formats, including panels, tutorials, industry presentations, posters and keynote talks. For students who are presenting papers, posters or demos, this gives them the opportunity to present their work to the rest of the dynamic spectrum access research community, which would enable timely feedback to be received that could influence their future activities in this area. Moreover, the attendance of these students at other presentations during this conference would provide them with valuable insights on the current state-of-the-art in cognitive radio, which would help provide a solid foundation for future research efforts. The interactions of the students with other cognitive radio and dynamic spectrum access researchers will help foster new ideas, as well as facilitate the integration of new students into the greater research community. Consequently, this provides students with a wider understanding of the research field and also allows for opportunities to interact with peer graduate students from other institutions, to meet with leading researchers and to grasp the state-of-the-art in dynamic spectrum access. Participation from women and other under-represented groups is particularly sought.","title":"IEEE DySPAN 2010 Student Travel Grant","awardID":"0936334","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["515456"],"PO":["557315"]},"148434":{"abstract":"CBET - 0852948<br\/>Karniadakis<br\/><br\/><br\/><br\/>Many microfluidic, synthetic-materials, and biomedical applications often need to model multiscale flow phenomena across several orders of magnitude in spatio-temporal scales from near-wall subdomains but also the outer flow over long simulation times. The goal of this project is to develop a validated methodology for simulating multiscale flow phenomena over functionalized surfaces with a biomedical focus. To this end, the PIs propose a \"triple-decker\" flow model based on interfacing seamlessly a mesoscopic method (dissipative particle dynamics or DPD) to molecular dynamics (MD) on one side and incompressible Navier-Stokes (NS) equations on the other side. The novelty of the PIs' approach is the use of a mesoscopic layer between NS and MD--unlike previous approaches-- to facilitate a smooth transition from the atomistic to the continuum regime. Their preliminary results for simple fluids show the great potential of this method. Here the PIs propose fundamental new developments to make the method applicable to complex fluids and to flows over functionalized surfaces including polymer brushes, where an assembly of polymer chains tethered by one end to a surface creates a surface with specialized properties. The large theoretical and experimental works on this topic, starting with the work of de Gennes, will act as a testbed to validate the proposed methodology and evaluate its efficiency and then model cytoadhesion over protein-coated surfaces using the polymer brushes as model of cell surface. The objective here is to develop a molecularly based adhesive dynamics model to complement existing mechanistic macromodels for multiparticle adhesive dynamics. Specifically, the PIs will simulate the binding of malaria-infected red blood cells (RBCs) to functionalized walls, as was done in recent microfluidic experiments, in essence mimicking cytoadhesion in arterioles and capillaries. The triple-decker (MD-DPD-NS) approach is general and can be applied to simple and complex fluids in microfluidic or biomedical applications but also in more classical applications, e.g., control of wall shear stress using surfactants or hydrophobic surfaces. DPD, first popularized in Europe, is a very effective method for modelng both complex fluids and soft matter but has not yet been adapted widely in USA, and the proposed work will contribute to its further use and development. More broadly, this work on polymer brushes can be used in a wide range of industrial applications in oil recovery, automotive lubrication, colloid stabilization, and in tailoring surface properties. The PIs will disseminate their models and the triple-decker codes as open source codes via existing external open source websites. They will organize seminar-courses open to all students at Brown University focused on multiscale modeling and applications. In addition, undergraduate students, through Brown's UTRA (Undergraduate Teaching and Research Assistantships) program, will be involved in the research projects, either during the academic year or the summer. The PIs also plan outreach activities for inner-city high school students in a partnership with the MET school, where Brown students will be tutoring MET high school students in physics and mathematics in close collaboration with MET school teachers.<br\/><br\/>This study is cofunded by the CBET, CMMI, and DMS divisions.","title":"Multiscale Modeling of Flow over Functionalized Surfaces: Algorithms and Applications","awardID":"0852948","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1443","name":"FLUID DYNAMICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"5345","name":"BIOMEDICAL ENGINEERING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7479","name":"Biomechanics & Mechanobiology"}}],"PIcoPI":[395651,"517149"],"PO":["525323"]},"159346":{"abstract":"The PIs and Co-PIs of grants supported through the NSF-NIH Collaborative Research in Computational Neuroscience (CRCNS) program meet annually. This will be the fifth meeting of CRCNS investigators. The meeting brings together a broad spectrum of computational neuroscience researchers supported by the program, and includes poster presentations, talks and plenary lectures. The meeting is scheduled for June 7-9, 2009 and will be held at Carnegie Mellon University and the University of Pittsburgh.","title":"Collaborative Research in Computational Neuroscience (CRCNS) PI Meeting 2009","awardID":"0940728","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":[425990],"PO":["564318"]},"159489":{"abstract":"Automatic annotation that uses expert input remains a challenging problem. The teams plans to use a mixture of methods from visual perception research, user-centered design, and image-content based methods. The application field will initially be categorization of biomedical images, which have potential for research and teaching, as well as clinical diagnosis. A closely integrated set of visual data, from users who also provide verbal data for production of annotation should information both image classification schemes and database organization. The project has two major aims: to combined visual perception research and user-centered design to do feature identification and develop appropriate metadata; and to design and build a usable, multimodal, gaze-aware content-based image retrieval system for interactive search and retrieval of multiply-classified images. Evaluation will include both retrieval performance and system usability metrics for both experts and novices. Graduate students will be an ongoing part of the research. Outcomes will be disseminated through journals and conferences, and data will be made available on a shared website.","title":"CDI-Type I: Multi-modal Interface for Retrieval of Perceptually and Semantically Similar Biomedical Images","awardID":"0941452","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7750","name":"CDI TYPE I"}}],"PIcoPI":[426432,"565262","426435",426435],"PO":["565136"]},"159247":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940285","effectiveDate":"2009-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":[425715],"PO":["561855"]},"159269":{"abstract":"The Georgia Institute of Technology in collaboration with Columbus State University proposes an extension to the \"Georgia Computes!\" Alliance. Georgia Computes! has made dramatic strides in improving computing education throughout the state, at all levels of the pipeline. Its efforts start at 4th grade with summer camps, and continue through middle school with camps and outreach with the Girl Scouts, YWCA, and Cool Girls, extend to high school with camps and teacher professional development, and end in undergraduate education with faculty workshops. Georgia Computes! successes include exponential growth in the number of Girl Scouts taking their computing workshops, the creation of eight new regional summer computing camps, a doubling of the number of institutions offering Advanced Placement Computer Science (APCS), a doubling of the number of Hispanic students taking the APCS exam, and change at a quarter of the computing programs in the University System of Georgia. With this Extension, they propose to scale, and broaden their alliance interventions. Georgia Computes! will grow its teacher education efforts to include two regional centers of expertise, at Columbus State and at Armstrong Atlantic State University. In order to offer inservice workshops throughout the state, it will develop on-line materials, including courses that provide on-line access to Georgia's new computer science teaching endorsement. Georgia Computes! will grow its already successful K-12 outreach efforts to help students to develop a broader definition of computing. It will use more diverse student mentors, including high school students and disabled undergraduate students. Most importantly, this Extension will create infrastructure for careful measurement of individual university computing programs in the state and to track individuals from workshops and camps, through high school classes, to university degrees.","title":"BPC-AE: Collaborative Research: Extending \"Georgia Computes!\": A Statewide Vertical Alliance to Broaden Participation through Innovative, Inviting, and Relevant Computing Education","awardID":"0940394","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["517101","521278","521279"],"PO":["560704"]},"153990":{"abstract":"The primary goal of this project is to better understand the cognitive and social factors in a learning paradigm called learning-by-explaining and to build a virtual training partner to promote better learning in this paradigm. Learning-by-explaining is an effective learning technique used by human tutors that has yet to be exploited by the intelligent tutoring system community. In this technique, students are encouraged to explain a concept either to another or themselves. Decades of research shows that generating such explanations can lead to deep understanding of the learning material, and that these learning effects are particularly strong when the explanations are delivered in a social context (i.e., explaining to a peer or tutor), as opposed to explaining to oneself. These effects have even been observed when the \"other\" is a computer generated character. There are competing views on why learning-by-explaining works. Cognitive theories emphasize how the act of generating an explanation helps student recognize gaps and conflicts in their mental models and creates opportunities for mental model revision and that learning partners facilitate this process by identify missing knowledge and prompting for further clarification. In contrast, social theories argue that the presence and behavior of the explainee motivates learners to invest more effort into the learning tasks, resulting in learning gains. This project aims to gain better understanding of the interplay between the cognitive and socio-relational feedback, how they impact the learning-by-explaining process and how to build an explainee agent that facilitates learning-by-explaining. The project seeks to answer two research questions: 1) Will cognitive feedback or socio-relational feedback facilitate learning-by-explaining? 2) How to build an effective virtual training partner \"a virtual explainee\" in the learning-by-explaining context? <br\/><br\/>This project will inform the development of next generation intelligent tutoring systems and has the potential to significantly enhance basic understanding of the design of human centered computing. It explores factors related to effective multi-modal interfaces and helps to identify crucial factors that impact social impressions and effective interaction which may facilitate a new generation of more human-centric approaches to human learning. The project will also support the research activities of underrepresented groups (the senior researcher is a woman and the work will support the training of an intern from a HCBU-MI). It will enhance infrastructure for research and education by making advanced research tools and corpora freely available to the research community. These tools provide a novel method to study and enhance the effectiveness of computer-mediated and human-computer interaction, allowing the experimental manipulation of key mediating factors in such interactions. The work will advance discovery and understanding while promoting teaching and learning as it will be performed within the context of USC's Centers for Creative Technologies, a university-affiliated federal laboratory with a core mission to develop and disseminate advanced virtual reality training technology with an extensive track record in transitioning technology into the classroom.","title":"HCC: Small: Learning-by-Explaining to a Virtual Human","awardID":"0916858","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["514860"],"PO":["565227"]},"153880":{"abstract":"Networks are everywhere. Discovering the underlying principles of the networks has great impact on our understanding of complex systems in many scientific, engineering, and social research areas. Nowadays, the availability of network data, such as online social networks from facebook.com or protein-protein interaction data, give researchers unprecedented opportunities to quantitatively study these complex systems.<br\/><br\/>In this project, the PI brings together problems, ideas and techniques from different areas including machine learning, statistics, biology and social sciences, to develop novel computational tools and statistical models for common problems in network inference and learning. The research activities include i) designing nonparametric Bayesian models to discover latent classes from relational data, ii) developing relational Bayesian models, coupled with efficient deterministic approximate inference methods, to predict missing links and node labels, and iii) examining network dynamics at different substructure levels. <br\/><br\/>The developed models, algorithms, and tools for analyzing network data are available to the public via publication and web distribution, disseminating to other machine learning researchers and helping computational biologists and socials scientists analyze massive network data that are being generated with an unprecedented fast speed. The PI incorporates the research results into the graduate-level interdisciplinary courses he teaches and recruits graduate and undergraduate students to conduct research for this project.","title":"RI:Small: Relational learning and inference for network models","awardID":"0916443","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["547294"],"PO":["562760"]},"153891":{"abstract":"CCF - 0917324 <br\/>SHF: Small: Collaborative Research: Taxonomy for the Automated Tuning of Matrix Algebra Software<br\/>PI Jessup, Elizabeth R. University of Colorado at Boulder<br\/>CCF ? 0916474<br\/>PI Norris, Boyana University of Chicago<br\/>Abstract:<br\/>In response to the need for high-performance scienti&#64257;c software, we propose to study ways to ease the production of optimized matrix algebra software. Each step of the code development process presently involves many choices, most requiring expertise in numerical computation, mathematical software, compilers, or computer architecture. <br\/>The process of converting matrix algebra from abstract algorithms to high-quality implementations is a complex one. When leveraging existing high-performance numerical libraries, the application developer must select the appropriate numerical routines and then devise ways to make these routines run e&#64259;ciently on the architecture at hand. Once the numerical routine has been identi&#64257;ed, the process of including it into a larger application can often be tedious or di&#64259;cult. The tuning of the application itself then presents a myriad of options generally centered around one or more of the following three approaches: manually optimizing code fragments; using tuned libraries <br\/>for key numerical algorithms; and, less frequently, using compiler-based source transformation tools for loop-level optimizations. The goals of the proposed research are three-fold. First, we will construct a taxonomy of available software that can be used to build highly-optimized matrix algebra computations. The taxonomy will provide an organized anthology of software components and programming tools needed for that task. The taxonomy will serve as a guide to practitioners seeking to learn what is available for their programming tasks, how to use it, and how the various parts &#64257;t together. It will build upon and improve existing collections of numerical software, adding tools for the tuning of matrix algebra computations. Second, we will develop an initial set of tools that operate in conjunction with this taxonomy. In particular, we will provide an interface that takes a high-level description of a matrix algebra computation and produces a customizable code template using the software in the taxonomy. The template will aid the developer at all steps of the process from the initial construction of Basic Linear Algebra Subprogram (BLAS)-based codes through the full optimization of that code. Initially, the tools will accept a MATLAB prototype and produce optimized Fortran or C. Finally, we will advance the state-of-the-art in tuning tools by improving <br\/>some of the tools included in the taxonomy, broadening their ranges of functionality in terms of problem domains and languages.","title":"SHF: Small: Collaborative Research: Taxonomy for the Automated Tuning of Matrix Algebra Software","awardID":"0916474","effectiveDate":"2009-09-15","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7934","name":"PARAL\/DISTRIBUTED ALGORITHMS"}}],"PIcoPI":["521548"],"PO":["565157"]},"161151":{"abstract":"Down syndrome is a genetically based impairment that affects an individual's overall development, including the areas of cognition, sensory perception and processing, gross and fine motor skills, and short term memory skills. Estimates are that there are over 450,000 individuals with Down syndrome in the United States. A preliminary survey carried out by the PIs of 561 young adults with Down syndrome established that they do use computers frequently, but that there exist a number of challenges to the human-computer interaction. The PIs' goal in this project is to impact the quality of life for individuals with Down syndrome by laying the groundwork for improving their ability to successfully use computers in the workplace, for socialization, and for activities of daily living. To this end, the PIs will take an in-depth, multi-method approach to understanding how people with Down syndrome interact with computers. They will conduct an ethnographic observation of 10 very successful users with Down syndrome; this will be followed by a study of 10 typical users with Down syndrome in the area of computer security features, and 10 users in the area of social networking. Through these studies the PIs hope to acquire a more detailed understanding of how users with Down syndrome interact with existing computer interfaces, and how modifications to these interfaces might improve their interaction. The research focus will be on web-based security mechanisms and social networking, two critical tools in today's workplace. Over the last decade, research in human computer interaction and assistive technology has expanded from the previous focus on people with motor and perceptual impairments, to include research on people with cognitive impairments. Yet issues relating to computer usage by people with Down syndrome remain relatively unexamined. This is because in the past these individuals have typically been included with other populations (such as those with Autism Spectrum Disorders or Williams syndrome), as part of a general \"users with cognitive disabilities\" category, whereas the specific fine motor, memory, and language challenges faced by users with Down syndrome lead them to experience different problems and have different strengths compared to other labeled groups. The PIs' long-term collaboration and involvement in the Down syndrome community will be an invaluable asset for recruiting participants, for conducting the research, and for disseminating findings.<br\/><br\/>Broader Impacts: The goal of universal usability - to make all user interfaces easy to use for all user populations - continues to elude us. This research will make an impact on both academic research and the practical design and development of applications and interfaces for users with Down syndrome, and will lead to wider employment possibilities and more independent living options related to computer skills.","title":"EAGER: Computer Interface Issues for Young Adults with Down Syndrome to Transition to the Workplace","awardID":"0949963","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[431049,431050,431051],"PO":["565227"]},"162482":{"abstract":"The workshop forum will bring together approximately 25 leading researchers working at the intersections of communications, information theory, signal processing and networking (with emphasis on the lower layers) to explore future directions, potential initiatives and long-term goals of the NSF CISE-CIF program. The workshop will assess the current status of each of the respective disciplines, identify emerging areas of important research, near and long-term goals, future challenges and opportunities, and lay out a five-year vision, in the context of what will it take to get there. The workshop will also produce a report detailing consensus findings and recommendations that will serve as a guide to the research community. <br\/><br\/>The workshop seeks to realize the high synergistic potential for cross-fertilization of ideas among the intersecting fields of communications, information theory, signal processing and physical layer networking. The forum will address the need for dramatic changes in conventional paradigms brought on by the ubiquity of small, mobile, energy-efficient sensing, processing and communicating devices. The forum will also address the need for new theory and technology to harness the tremendous potential of large, decentralized, and complex networked systems. The areas of research fostered by this workshop, as an outgrowth of the findings and recommendations on future directions and challenges, will support the development of enabling technologies critically important to the growth of the technological base of the nation.","title":"Future Directions in Signal Processing, Communications, Information Theory, and Physical Layer Networking","awardID":"0957440","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}}],"PIcoPI":[434205,"518179"],"PO":["564898"]},"153781":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/>This project develops techniques for increasing energy-efficiency of modern data centers with performance constraints. Both computing and cooling energy are considered. According to the U.S. Environmental Protection Agency, data centers in the United States incur an annual energy cost of approximately $4.5 billion, which is comparable to the total consumption of 5.8 million average US households. In the absence of intervention, data center consumption is expected to double in five years. Up to 80% of this projected energy expenditure is avoidable, which constitutes a prospective reduction in nationwide carbon dioxide emissions by up to 47 million metric tons (MMT) per year; an amount comparable to the annual carbon emissions footprint of all fuel combustion in a small nation. The observation motivating the energy-efficiency solutions developed in this project is that the proliferation of individual energy-saving mechanisms in server installations can lead to increasingly suboptimal overall energy management. The problem lies in performance composability or lack thereof; a challenge that arises because individual optimizations generally do not compose well when combined, leading to opportunities for improvement. A theory is developed to define preconditions of composability and a holistic distributed approach is investigated for coordinating energy-saving decisions across multiple components that span both the computing and cooling subsystems. A graduate course on cyber-physical systems is designed to cover the addressed challenges and solutions. Women and minority students are encouraged to benefit from these opportunities.","title":"CSR: Small: Green Farms: Towards a Stable Energy Optimization Architecture for Data Centers","awardID":"0916028","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553633"],"PO":["565255"]},"153792":{"abstract":"Geometric models composed of millions (or more) of facets are common today due to improved technologies for generating high-resolution complex models. The large size makes it infeasible to perform some fundamental geometric operations on these models. For instance, more than 1.4 billion geometric union operations are required to compute the Minkowski sum of the David model. Re-designing existing algorithms for large models would require significant time and effort, and may not always be possible. This project is investigating approximate convex decomposition (ACD), an alternative representation for large geometries that approximately represents the original model using a set of convex objects. By using the much smaller convex approximation in place of the original model, ACD allows existing (inefficient) methods and software to perform efficiently for large geometries without designing and implementing new algorithms. An important goal of this project is to develop simple algorithms that not only allow efficient reconstruction but also allow practical implementation.<br\/><br\/><br\/><br\/>This project will make significant contributions to fundamental problems in geometric computing, such as Minkowski sum, continuous motion collision detection, general penetration depth estimation, and swept volume. Beyond these fundamental geometric operations, this project will provide new ways to handle geometric problems in several areas of robotics (e.g., environment\/map representation, motion planning and grasp planning), in pattern recognition (e.g., structural salient feature recognition, visual-based part decomposition and motif identification in protein structures), and in computer graphics (e.g., data compression, physically-based simulation and skeletonization).<br\/>The software developed by this project will be provided to the public domain.","title":"DC: Small: Collaborative Research: Shape Representation of Large Geometries via Convex Approximation","awardID":"0916053","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["561154"],"PO":["562984"]},"153682":{"abstract":"This project addresses core elements of an information base, key system components of a Knowledge Plane for the future Internet. Today the Internet network management functions are decreasingly available or capable of solving our networking problems. We find a confluence of: current network management being a human based ?cottage industry? limited to individual administrative boundaries; and networks becoming increasingly more pervasive and central in users? lives. In the context of tussles among policies, there is a need for extensibility and distribution, and the necessity for controlled sharing and exchange of information, the Knowledge Plane is a proposal for a new component of the network architecture to provide self-knowledge, self-analysis, self-prediction, and self-repair as much as possible.<br\/>An important component is the substrate in which information is collected, placed, made available under policy control and accessed under that same policy control. This work is taking the first step focusing on features the enable the ability to make information available, a scoping approach to allow for scalability to the size of the Internet, the ability to declare an interest in information (rendezvous), delivery of that information under policy control. There are further central aspects that are left to future work including: efficient rendezvous mechanisms, truly efficient information distribution and delivery, trust expression, and information location management. The contribution of this work is that the information base is critically important to measurement and monitoring required to insure that the future network infrastructure highly available.","title":"NeTS: Small: KPBase: Core of the Knowledge Plane for Network Management","awardID":"0915629","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["125800"],"PO":["564993"]},"156960":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Professor Victor Mbarika of Southern University, Baton Rouge will direct this research and educational program. During the summer and winter breaks of its three year duration; the Dr. Mbarika and Co-PI, Dr. Carlos Thomas, will establish an educational partnership between Southern University, two Universities in Cameroon--The University of Buea and The University of Yaounde Medical School (a teaching hospital). Two undergraduate and two graduate students will be selected from Southern University1 and the same number will be selected from two institutions in Cameroon. These students will collaborate in developing and publishing e-medicine case studies that will be packaged with multimedia features and delivered through the Internet and CDs for teaching Global E-Health issues in US and African classes.<br\/><br\/>Intellectual Merit: In recent years, students have been involved in international research that has led to multiple conference and journal publications based on data collected, but students have never involved in developing case studies on these projects. Based on research and proof of concept from previously funded research, rigorous theory-driven case studies on emedicine implementation in Cameroon will be developed. The proposed project will develop information technology students with a global perspective on how such technologies are implemented in resourcepoor settings of developing nations. These experiences will be used on ongoing projects on emedicine implementation in rural parts of the US, creating a reverse (South to North) knowledge transfer. Further, this will move the researchers from current knowledge on e-medicine transfer in developing nations whereby previously the PI had largely focused on surveying multiple projects from afar. He will now be able to study specific e-medicine projects to gain a more intimate knowledge of the subject domain.<br\/><br\/>Broader Impacts: The proposed project will provide a deeper understanding of e-medicine in resource-poor communities in developing and developed nations. The case studies developed through this collaboration will be packaged in multimedia CDs as well as on the Internet for use in classes anywhere in the world. Publications resulting from this project, including a book on global e-health issues in resourcepoor settings could be used in information technology courses. Local professionals and paraprofessionals will be trained using the teaching materials and tools generated by the case studies to better equip them to maximize their use of technology in e-Medicine. Professionals and para-professionals can will information from the case studies to not only address fears and concerns affecting their support and participation in e-medicine service delivery, but also to refine and improve their approaches to emedicine. Facilitating collaborative cross cultural research to generate solutions to global problems will help create productive world citizens and contributors to a sustainable future. Current multimedia case study collaborations will allow for broader dissemination of these IRES cases at 20 different institutions in the US. Furthermore, the PI?s strong affiliation with Multimedia Educational Resources for Learning and Online Teaching, (MERLOT) an NSF funded project, will provide a platform for even more dissemination opportunities across multiple discipline communities of the organization.","title":"IRES: A US-Cameroon Collaboration for Information Technology in Healthcare (E-Medicine) Research in Resource-Poor Contexts","awardID":"0927688","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7727","name":"IRES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["460924","460923"],"PO":["525681"]},"155871":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Proposal #: CNS 09-23442<br\/>PI(s): Romero, Rodrigo; Gonzalez, Virgilio; Hurtado, Jose M.; Konter, Jasper; Smith-Konter, Bridget R.<br\/>Institution: University of Texas ? El Paso<br\/> El Paso, TX 79968-0587<br\/>Title: MRI\/Acq.: Acq. of the Cyber-ShARE Collaborative Visualization System<br\/><br\/>Project Proposed:<br\/>This project, acquiring a collaborative visualization system referred to as the Cyber-ShARE Collaborative Visualization System (C2ViS) to present high-resolution displays of scientific datasets for exploratory monitoring, supports interdisciplinary research and enables development of new visualization techniques for analyzing and integrating large datasets from the geosciences, environmental sciences, computational sciences, material sciences, biomedical engineering, and other domains. The tile-display 32-monitor system will be driven by 32 workstations interconnected by a high-speed network controlled by a single computer acting as a head node. With an overall 131 megapixels display resolution, images using the full resolution of the tiled-system are physically sent to each machine via open-source software. Supporting a variety of exploratory applications, C2ViS also supports both local and virtual organizations and serves as a resource for city and county government entities, as well as regional school districts.<br\/>Applications include the visualization of tomography models of the subsurface of the Earth, spatial surface datasets from geosciences and environmental science communities, and 3-D solid models for advanced material fabrication, tissue engineering, and biomodeling. In addition, the system will extend Cyber-ShARE?s ability to support interdisciplinary projects, including those related to knowledge representation, trust management, and visualization of scientific data and results, CI-based geological model and data fusion for integration of whole-Earth models, and characterization of ecological and environmental phenomena through sensor network and data stream organization.<br\/><br\/>Broader Impacts: This project contributes to engage young faculty and attract quality researchers to this minority-serving institution. A high-resolution system allows researchers to view data from different perspectives and abstraction levels, enhancing analysis, exploration, and discovery. Furthermore, the system will be used for outreach and education programs to attract students to STEM fields. Middle high schools brought in for summer workshops students will be excited and motivated by interacting with complex graphical models.","title":"MRI: Acquisition of the Cyber-ShARE Collaborative Visualization System","awardID":"0923442","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["565377","565349",415549,415550,415551],"PO":["557609"]},"153451":{"abstract":"The objective of this proposal is to address various search problems in group theory. <br\/>Decision problems in group theory have been studied for over 100 years now, since Dehn put forward, <br\/>in the beginning of the 20th century, the three famous decision problems now often referred to as <br\/>Dehn's problems: the word problem, the conjugacy problem, and the isomorphism problem. In general, <br\/>decision problems are problems of the following nature: given a property P and an input O, find out <br\/>whether or not the input O has the property P. On the other hand, search problems are of the following <br\/>nature: given a property P and an input O with the property P, find a proof (sometimes called a \"witness\") <br\/>of the fact that O has the property P. This is a substantial shift of paradigm, and in fact, studying <br\/>search problems often gives rise to new research avenues in mathematics or computer science, very different <br\/>from those prompted by addressing the corresponding decision problems.<br\/><br\/>The potential broader impacts of the proposed research are extensive; the impact on the general area <br\/>of information security can be singled out. The difficulty of several well-studied problems, e.g. <br\/>integer factorization and the discrete logarithm problem underlie most current public-key cryptographic <br\/>protocols used in real-life applications. Developing public-key protocols based upon other search problems, <br\/>e.g. the conjugacy search problem whose difficulty has been well studied by group theorists, is prudent from <br\/>the standpoint of robustness, particularly if factorization or related developments threaten the security of <br\/>current protocols. The complexity of non-abelian infinite groups is a promising fertile ground for new <br\/>protocols and there is a great deal of preliminary work required such as that proposed here.","title":"Collaborative Research: Theoretical and experimental approaches to search problems in group theory","awardID":"0914778","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["531699"],"PO":["565027"]},"153572":{"abstract":"Most real software systems consist of modules developed in<br\/>multiple programming languages. Different languages differ in their<br\/>security assumptions and guarantees. Consequently, even if single<br\/>modules are secure in some language model and with respect to some<br\/>security policy, there is usually no uniform security guarantee on a<br\/>whole multilingual system. This project focuses on low-overhead<br\/>techniques for providing security guarantees to software systems in<br\/>which type-safe languages such as Java interoperate with native code.<br\/>Native code is developed in low-level languages including C, C++, and<br\/>assembly languages. Although often used in software projects, native<br\/>code is notoriously insecure and is a rich source of security<br\/>vulnerabilities. The PIs are developing a two-layered approach to<br\/>alleviating security threats posed by native code to type-safe<br\/>languages: (1) Binary rewriting tools and their verifiers are being<br\/>incorporated into the Java Virtual Machine (JVM) for rewriting and<br\/>verifying native modules at the machine-instruction level to enforce<br\/>security policies; (2) A safe dialect of C for interoperation with<br\/>Java is being designed; with the help of programmer annotations, the<br\/>safety of programs in this dialect can be statically verified. The<br\/>outcome of this project will enable popular platforms such as the JVM<br\/>and .NET and other major programming languages (e.g., Python, OCaml,<br\/>etc.) to incorporate native modules safely. The developed principles<br\/>will also be applicable to web browsers and operating systems in which<br\/>there is a need of extending them with untrusted low-level modules<br\/>without comprising host security.","title":"TC: Small: Collaborative Research: Securing Multilingual Software Systems","awardID":"0915157","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["517943"],"PO":["564388"]},"162284":{"abstract":"EAGER: Fast and Accurate Nonnegative Tensor Decompositions: <br\/>Algorithms and Software <br\/><br\/>During the past decades, numerous efficient and effective data analysis algorithms have been designed where data sets are represented as two dimensional arrays, i.e., matrices. However, matrix based methods have limitations since modern data sets are multi-scale and multi-dimensional. In numerous applications, data sets are more naturally represented as tensors than matrices including image analysis, climate modeling, chemometrics, genome signal analysis, and biometric recognition. In this project, the mathematical characteristics of tensor decompositions will be studied. Algorithms will be designed for large scale data analysis that can reveal complex relationships among many dimensions which matrix based methods often cannot. Computations on tensors are expected to extend many of the advantages that the matrix based data analysis methods have offered. Tensor-based methods can be utilized for data compression, modeling, regression, and fusing of information obtained from different sources and scales. Tensor based methods are relatively new in many application areas and theoretical and algorithmic developments, especially for large scale problems, have been slow even in the areas where they have been heavily utilized. The key goals of the project include extension of the matrix decomposition techniques such as the SVD to higher order tensors and develop efficient algorithms for large scale analysis of multi-dimensional data and design their higher-order extensions, development of algorithms for the computation of various nonnegative matrix factorizations (NMF) and nonnegative tensor factorizations (NTF) and study of the mathematical properties of the algorithms, such as robustness, efficiency and accuracy, and implement them in publicly available software. This research will substantially improve the possibility of detailed study of larger scale multi dimensional data sets in numerous application areas including text mining, biological network analysis, and medical examination and diagnosis.","title":"EAGER: Fast and Accurate Nonnegative Tensor Decompositions: Algorithms and Software","awardID":"0956517","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["562362",433718],"PO":["565251"]},"153583":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Presence of a well-structured market is necessary for efficient and flexible use of licensed spectrum bands, and for fair pricing of spectrum usage. The goal of this project is to design radio spectrum markets that allow trading of spectral resources - not only of the raw spectrum, but also of a variety of service contracts derived from the use of spectrum. Specific sub-problems that will be addressed in this context include: 1) spectrum-portfolio construction that optimizes risk-versus-return trade-offs, 2) strategy design for optimal cooperation among providers, 3) price-driven dynamic scheduling of subscribers, 4) optimal pricing of spectral contracts, and 5) regulatory mechanisms for effective functioning of the spectrum markets. The solutions to the above problems take advantage of similar formulations in financial engineering, and use tools from optimization, stochastic calculus, and control and game theory.<br\/><br\/>The project is expected to revolutionize spectrum trading by facilitating the design of secondary spectrum markets and spectrum regulation policies. Towards this end, This project aims at establishing a new cross-disciplinary field that is at the interface of wireless networks and financial mathematics. The results will lead to more efficient use of the available spectrum by reducing spectrum wastage and fairness in pricing of wireless subscribers, and also help formulate governmental spectrum management and regulation policies. The results will be disseminated through publications in premier journals and conferences, and interactions with collaborators in the wireless industry.","title":"NetS: SMALL: Collaborative Research: Financial Dynamics of Spectrum Trading","awardID":"0915203","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517945"],"PO":["557315"]},"151042":{"abstract":"The growth of scientific data sets to petabyte sizes offers significant opportunities for important discoveries in fields such as combustion chemistry, nanoscience, astrophysics, climate prediction and biology as well as from data on the internet. However, the realization of new scientific insights from this data is limited by the difficulty of creating scalable applications due to the lack of easy-to-use programming models and tools. To address challenges in creating data intensive applications, the project will build an extensible language framework, backed by an expressive collection of high-performance libraries (I\/O and analytic), to provide a development environment in which multiple domain-specific language extensions allow programmers and scientists to more easily and directly specify solutions to data-intensive problems as programs written in domain-adapted languages. The project will build on recent attribute grammar research to build an extensible specification of C to host domain-specific language extensions which will also address the inadequate performance in storage, I\/O and analysis capabilities in low-level language such as C. <br\/><br\/><br\/><br\/>The proposed extensible language and library framework has the potential to be a transformative problem solving environment for programmers and scientists since it allows scalable and efficient solutions to data-intensive problems to be specified at a high-level of abstraction. The resulting language framework and libraries will be freely available to researchers writing applications for climate and other applications involving spatio-temporal data. This includes many applications in the physical sciences and engineering and thus it is expected that the framework will find use in other scientific domains as well.","title":"DC: Medium: Collaborative Research: ELLF: Extensible Language and Library Frameworks for Scalable and Efficient Data-Intensive Applications","awardID":"0905581","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["563608","544438","563607"],"PO":["560586"]},"155772":{"abstract":"Proposal #: CNS 09-23188<br\/>PI(s): Du, Xiaojiang; Reinholz, Aron J.<br\/>Institution: North Dakota State University - Fargo<br\/>Title: MRI\/Acq.: Dev.of a Hybrid Wireless Network Infrastructure for Integrated Research and Education <br\/>Project Proposed:<br\/>This project, developing a Hybrid Wireless Network (HWN) to be built on top of an existing Heterogeneous Sensor Network (HSN) testbed, supports research in broadband wireless networking and communication enabling high-quality and high-accuracy performance evaluations of protocols and schemes designed for HWNs. Research projects include<br\/>- Efficient Quality of Service (QoS) provisioning and<br\/>- Orthogonal Frequency Division Multiple Access (OFDMA) resource allocation in HWNs.<br\/>These projects are expected to satisfy individual user's QoS requirements while optimizing the performance (e.g., throughput) of the overall system. Although QoS support in traditional wireless networks and OFDMA resource allocation in cellular networks have been well studied, in HWNs QoS routing and OFDMA resource allocation are highly correlated and the problem lends itself to further exploration. The HWN services faculty and students in Computer Science and Electrical Engineering and 65 staff researchers at the Center for Nanoscale Science and Engineering at the institution and nearby universities. The work aims at integrating various aspects of educational and training environment with innovative research into a cohesive package for education in wireless networking and communication.<br\/><br\/>Broader Impacts: Supported education and training activities include <br\/>- Recruiting students of underrepresented groups to participate in the research, as well as mentoring<br\/>- Developing a new course in Wireless Networking and Communications<br\/>- Integrating research and education<br\/>Native American, female, low income, and first generation students will be specifically targeted in this EPSCoR state where 31% of the undergraduate populations falls below the threshold for low-income US citizens.","title":"MRI: Development of a Hybrid Wireless Network Infrastructure for Integrated Research and Education","awardID":"0923188","effectiveDate":"2009-09-01","expirationDate":"2010-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[415078,"563625"],"PO":["557609"]},"153352":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Many information needs can be more easily expressed using longer, sentence-length queries, but the inadequacies of current search engines force people to try to think up the right combination of keywords to find relevant documents. This can be very difficult and often leads to search failures. On the other hand, long queries are handled poorly by current search engines. The focus of this project is on developing retrieval algorithms and query processing techniques that will significantly improve the effectiveness of long queries. A specific emphasis is on techniques for transforming long queries into semantically equivalent queries that produce better search results. In contrast to purely linguistic approaches to paraphrasing, query transformation is done in the context of, and guided by, retrieval models. Query transformation steps such as stemming, segmentation, and expansion have been studied for many years, and we are both extending and integrating this work in a common framework. The new query processing techniques for long queries are being developed and distributed using the NSF-funded Lemur toolkit from UMass\/CMU, and are being evaluated using a variety of document and query collections from sources such as the web, social media sites such as forums, and TREC, with an involvement of graduate and undergraduate students. The project Web site (http:\/\/ciir.cs.umass.edu\/research\/longqueries) will be used to further disseminate results. <br\/><br\/>Given that search is one of the two most common activities on the web and that new modalities for search, such as voice interfaces and collaborative question answering, are increasing the importance of long queries, this research could have a very broad impact, both in the home and the office.","title":"III: Small: Transforming Long Queries","awardID":"0914442","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["507668"],"PO":["563751"]},"151053":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>We increasingly rely on MAD Services, systems that span Multiple Administrative Domains. Examples include cloud computing, peer-to-peer streaming, Internet routing, and wireless mesh routing. Unfortunately, when different parties control a system's nodes, the nodes may undermine the desired service either by malfunctioning or by selfishly maximizing their own benefits to the detriment of the broader system (e.g., a tragedy of the commons.)<br\/><br\/>The central thesis of this research is that any approach to building robust MAD services must account for both selfish behaviors and Byzantine malfunctions.<br\/><br\/>This research therefore brings together ideas from game theory and Byzantine fault tolerance to (1) develop the new theoretical framework for MAD distributed systems; (2) design techniques that rigorously address key practical issues in building MAD systems, such as heterogeneity, locality, and node churn; and (3) construct significant prototypes of dependable MAD systems that tolerate selfish and Byzantine behaviors and whose costs and performance are comparable to less robust systems deployed today.<br\/><br\/>This work seeks to have broader societal impact in at least two dimensions. First, it will develop the theory and practice of MAD systems at a time when crucial personal, business, and societal needs are increasingly met by MAD services. Second, we expect a significant educational impact from this work, as graduate and undergraduate students will participate in a research plan that will enhance skills in both practice and theory.","title":"CSR: Medium: MAD Systems","awardID":"0905625","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["466839","466840"],"PO":["565255"]},"162064":{"abstract":"This award will fund two years of Summer Institutes for young investigators of socio-technical systems. The Summer Institutes are designed to foster intellectual depth and development among the young researchers who attend. These workshops will be managed by the Consortium for the Science of Socio-Technical Systems (CSST). The CSST resulted from recognizing the growing importance of research on the interplay of humans and technology, or socio-technical systems as identified by prior intellectual and community building efforts of the NSF. The CSST involves faculty members in diverse fields, such as social informatics, social computing, CSCW, computational social science, HCI, and information science. The Summer Institute select late stage graduate students and early stage faculty for participation in the program through competitive review of a research based submission. Through an intensive multi-day program the Summer Institute provides an opportunity for research programs to be shaped through intellectual exchange with more experienced researchers as well as enhanced through collaboration with other young researchers.<br\/><br\/>The intellectual experience during the Summer Institute facilitates creation of a social network among the participants and with several senior researchers who serve as instructors for the Institute. This network plays a major role in the professional development of the participants and in the evolution of the field of socio-technical systems research. The diversity of Summer Institute participants (e.g., institutional, disciplinary, geographic, gender, minority group status), serves to broaden participants' perspectives at a critical stage in their careers. In addition, there will be more attention to organizing the CSST and developing more ways to increase the visibility of the CSST activities.","title":"Supporting Young Investigators Summer Research Institutes of the Consortium for the Science of Socio-Technical Systems","awardID":"0955449","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["561666"],"PO":["564456"]},"154100":{"abstract":"Timing errors resulting from process variability, manufacturing defects, and aging effects in scaled CMOS technologies are an important failure mode that impact the reliability of multi-level control logic in commodity mainstream computer systems. This project makes a case for lookahead logic circuits based on the principles of prefix computation to address performance, reliability, and power challenges posed by timing errors in multi-level control logic. Lookahead logic circuits promise low-cost logic-only solutions that can be used to (i) increase performance and\/or yield by reducing logic delay, (ii) improve logic circuit robustness to timing errors by masking them, (ii) lower power consumption by increasing the scope of aggressive dynamic voltage and frequency scaling, and (iv) enable more effective and targeted post-silicon debug and online wearout prediction. The research will formalize the principles of lookahead-based function decomposition and prefix-based computation for multi-level logic circuits, develop logic synthesis and design solutions for lookahead logic, and investigate its applications in the context of superscalar and multi-threaded processor design.<br\/><br\/>A major impact of this research is to enable ubiquitous low-cost highly reliable computing, by expanding its reach to domains, where custom solutions are economically infeasible. An integrated outcome of this project is the development of a testbed and web-based resources to facilitate research in reliable system design. Through course development and collaborations with industrial partners, the research will contribute to education, community resource development and technology transfer to industry.","title":"SHF: Small: Lookahead Logic Circuits for Performance, Power, and Reliability","awardID":"0917226","effectiveDate":"2009-09-15","expirationDate":"2012-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[410022,"517951"],"PO":["559883"]},"154111":{"abstract":"This project designs and implements tools for frictionless information systems that work behind the applications that people use in their work and everyday lives, automatically finding and presenting contextually relevant, useful, and interesting information. To be relevant to a user's information needs in a given context, information must add something new: it must be similar in certain respects to the context, but dissimilar in certain other respects. The technology utilized in this project explicitly and specifically searches or filters for interestingly different information, dissimilar in systematic ways that reflect information attributes relevant to a user's goals.<br\/><br\/>The project develops useful information attributes and dimensions of dissimilarity as well as technologies that can utilize these attributes and dimensions to find useful and relevant information based on the user?s current context. The particular dimensions that matter in a given context will depend upon the user, task, and domain at hand. To address this variability, the project is aimed at a general architecture and a set of tools and libraries that will support the rapid development of frictionless information systems for a wide range of application settings.<br\/><br\/>The results are expected to lead to development of information systems that can provide people with information that is contextually relevant, genuinely interesting, and diverse, resulting in broader and deeper understanding. The results will be disseminated in academic venues as well as through public release of prototype systems via the project Web site (http:\/\/infolab.northwestern.edu\/). The project is well integrated with educational activities. Relevance Engine platform will be utilized in class projects for advanced undergraduates and graduate students, and some of these systems may be aimed at educational settings. Students will be involved in development of corpora for testing prototypes, informal assessment of prototypes using web resources, and gain valuable experience in research, design and implementation, and validation.","title":"III: Small: An Architecture and Platform for Frictionless Information Systems","awardID":"0917261","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[410052,410053],"PO":["563751"]},"157752":{"abstract":"The objective of this research is to develop a theory of ?ActionWebs?, that is, networked embedded sensor-rich systems, which are taskable for coordination of multiple decision-makers. The approach is to first identify models of ActionWebs using stochastic hybrid systems, an interlinking of continuous dynamical physical models with discrete state representations of interconnection and computation. Second, algorithms will be designed for tasking individual sensors, based on information objectives for the entire system. Third, algorithms for ActionWebs will be developed using multi-objective control methods for meeting safety and efficiency objectives. Two grand challenge applications for this research are in Intelligent Buildings for optimal heating, ventilation, air conditioning, and lighting based on occupant behavior and external environment; and Air Traffic Control for mobile vehicle platforms with sensor suites for environmental sensing to enable safe, convenient, and energy efficient routing. <br\/><br\/>The intellectual merit of this research stems from a conceptual shift of ActionWebs away from passive information gathering to an action-orientation. This involves: modeling of ActionWebs using stochastic hybrid systems; taskable, multi-modal, and mobile sensor webs; and multi-scale action-perception hierarchies. <br\/><br\/>The broader impact of the research is in two grand challenge national problems: energy efficient air transportation, and energy efficient, high productivity buildings, and will tackle social, privacy, economic, and usability issues. Integrated with the research is a program of coursework development in networked embedded systems, across stove pipes in EECS, Aero-Astro, Civil, and Mechanical Engineering departments. Outreach objectives include new course design at San Jose State University, and recruiting more women researchers.","title":"CPS: Large: ActionWebs","awardID":"0931843","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"L509","name":"National Security Agency"}}],"PIcoPI":["71498","526900","527079","526901","526840"],"PO":["565274"]},"157873":{"abstract":"The literature is replete with examples of scientists' inattention to ethical issues. Too often scientists and other academicians think of ethics as something outside the realm of their concerns; required courses in higher education frequently do not discuss ethical issues at all. In this project the focus is on facilitating ethics education for scientists by utilizing the heretofore untapped power of interactive technologies such as Second Life. The PI argues that the hands-on and exciting nature of virtual worlds is uniquely suited to maximizing the effectiveness of ethics education, by increasing the ethical engagement of students and faculty. Second Life, the most popular virtual world in the academic arena, hosts hundreds of colleges and universities. Yet none of those member institutions have developed sites committed to ethics education. The PI and her team will develop interactive ethics modules in Second Life, for use in the content of graduate-level science courses. To this end, they will assemble a dedicated group of science faculty who teach graduate-level courses and graduate students in the sciences, who will participate in summer workshops in order to design and implement the online ethics modules. Four main features of ethics training particularly conducive to the virtual world, as confirmed in the research literature, will be addressed: the training will be context- or discipline-specific to increase its effectiveness; the modules will emphasize the ambiguity of the ethical context, helping to free participants of the inevitable bias that comes with the awareness of being studied; the hands-on nature of virtual worlds correlates well with the most successful conditions for increasing ethical awareness; because those in leadership positions (faculty, lead researchers, laboratory supervisors, etc.) have the largest impact on the development of ethical behavior in subordinates, the virtual world modules developed will be able to encourage simulations of those interactions, increasing the likelihood of the success of such training. Data collected during the piloting of the modules will be utilized for improving them. The PI team has been carefully selected to include members with diverse expertise that includes teaching ethics courses, training in ethics, teaching science courses, developing effective curricula, analyzing qualitative and quantitative data, and creating content in virtual worlds. <br\/><br\/>Broader Impacts: This project reaches far beyond the walls of West Chester University students and faculty. The partnering organization for the project is Cheyney University of Pennsylvania, the oldest historically black post-secondary institution in the United States. In addition to the diverse nature of the partnering organizations, the results of research and educational efforts will be disseminated through publications, conferences and web-based activities. Due to the global and self-perpetuating nature of Second Life, the completed modules will be available world-wide, far beyond the time-frame of the life of the grant.","title":"Applying Virtual Worlds to Ethics Education in Science","awardID":"0932712","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":[421414,421415,421416,421417,421418],"PO":["565227"]},"154122":{"abstract":"This research will create a new generation of computational tools, called contextual prediction models, for analyzing and modeling social nonverbal communication in human-centered computing. This computational study of nonverbal communication not only encompass the recent advances in machine learning, pattern analysis and computer vision, but goes further by developing and evaluating new algorithms and probabilistic models specifically designed for the domain of social and nonverbal communication. The ability to collect, analyze and ultimately predict human nonverbal cues will provide new insights into human social processes and new human-centric applications that can understand and respond to this natural human communicative channel. <br\/><br\/>This new endeavor will advance through the development of prediction models and their accompanying selection algorithms and feature representations for predicting human nonverbal behavior given a social context (such as the immediately preceding verbal and nonverbal behaviors of a conversational partner). The investigator's previous work has demonstrated the feasibility of using machine learning approaches to model nonverbal communication. Probabilistic sequential models were shown to improve performance of nonverbal behavior recognition during human-robot interactions and make possible the natural animation of virtual humans. This project addresses three fundamental challenges directly: feature representation (optimal mathematical representation of social context), feature selection (subset of social context relevant to prediction of nonverbal behaviors) and probabilistic modeling (efficiently learning the predictive relationship between social context and nonverbal behaviors). This research will evaluate and test the generalization of the computation tools using a large corpus of natural interactions in different settings (human-human, human-robot and human-computer) and domains (e.g., storytelling, interview, and meetings). <br\/><br\/>These prediction models will have broad applicability, including the improvement of nonverbal behavior recognition, the synthesis of natural animations for robots and virtual humans, the training of cultural-specific nonverbal behaviors, and the diagnoses of social disorders (e.g., autism spectrum disorder). The code resulting from this work will be made available to the research community through an open-source Matlab toolbox. The outcome of this research effort will produce state-of-the-art computational models more accessible to researchers who aim to analyze social nonverbal communication and develop natural and productive human-centered computing technologies.","title":"HCC:Small:Computational Studies of Social Nonverbal Communication","awardID":"0917321","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["486574"],"PO":["564456"]},"148930":{"abstract":"Identical designs of electronic circuits in deep-submicron technology show small parameter variations among different instances implemented on a die or in between dies. The resulting circuit variations have a strong impact on the quality of the design. This project plans to create an infrastructure for characterizing the circuit variability on a large population of Field Programmable Gate Array devices. The proposed infrastructure includes a small population of FPGA kits, as well as a web-based data-collection setup to support variability-experiments on hundreds of FPGAs at the same time, in collaboration with undergraduate students. The project will drive research into innovative applications of circuit variability, in particular into physically unclonable functions (PUF). In addition, a unique education opportunity is created to teach undergraduate students about the impact of variability on their design by making them participate in the experimental data collection. The proposed infrastructure will not only significantly enhance the PI's research in trustworthy circuit design, but also provide valuable variability data for the broader research community.","title":"II-NEW: Infrastructure to Collect and Analyze Circuit Variability in FPGAs","awardID":"0855095","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["548205"],"PO":["565272"]},"158731":{"abstract":"The goal of this research is to combine two areas, Visual Analytics and Bayesian Statistics. Currently, visualizations display inflexible deterministic transformations of data that inherently separate data visualization from visual synthesis. Analysts cannot manipulate displays to inject domain-specific knowledge to formally assess the merger of their expert judgment with the data. However, by changing the nature of the data transformation from deterministic to probabilistic Bayesian methods, manipulations to a display are possible to interpret quantitatively. Thus, a new visualization model is developed which offers editable representations to promote bidirectional flow between analyst and data.<br\/><br\/>This approach enables analysts to quantify data uncertainty, formally include expert judgment into analyses, rapidly generate and test new hypotheses, and allows multi-source and multi-scale data to contribute to one data display. The developed software is applied and evaluated with analysts in multiple fields, including intelligence analysis. <br\/><br\/>While the research immediately impacts how analysts discover new information in large datasets, the methodology also transitions smoothly into the classroom. Bayesian courses are currently limited to advanced graduate students, but learning Bayesian statistics at a more intuitive level can overcome this barrier. The combination of Bayesian methodology and visual analytics enables students to assess the impact of various levels of prior information on probability models through visual representations and the sense-making feedback loop. Students with varying backgrounds, interests, and talents, including undergraduates and underrepresented groups with limited academic history, will now have the opportunity to learn 21st century statistics. The project Web site (http:\/\/infovis.cs.vt.edu\/BAVA) will be used for results dissemination.","title":"FODAVA: Bayesian Analysis in Visual Analytics (BAVA)","awardID":"0937071","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["498312","498313","518252"],"PO":["563751"]},"157763":{"abstract":"CPS:Small:Collaborative Research: Establishing Integrity in Dynamic Networks of Cyber Physical Devices<br\/><br\/><br\/>The objective of this research is to develop energy-efficient integrity<br\/>establishment techniques for dynamic networks of cyber physical devices. <br\/>In such dynamic networks, devices connect opportunistically and perform<br\/>general-purpose computations on behalf of other devices. However, some <br\/>devices may be malicious in intent and affect the integrity of computation. <br\/>The approach is to develop new trust establishment mechanisms for dynamic <br\/>networks. Existing trusted computing mechanisms are not directly applicable <br\/>to cyber physical devices because they are resource-intensive and require <br\/>devices to have special-purpose hardware.<br\/><br\/>This project is addressing these problems along three research prongs. <br\/>The first is a comprehensive study of the resource bottlenecks in current <br\/>trust establishment protocols. Second, the insights from this study are <br\/>being used to develop resource-aware attestation protocols for cyber <br\/>physical devices that are equipped with trusted hardware. Third, the<br\/>project is developing new trust establishment protocols for cyber physical<br\/>devices that may lack trusted hardware. A key outcome of the project is <br\/>an improved understanding of the tradeoffs needed to balance the concerns <br\/>of security and resource-awareness in dynamic networks.<br\/><br\/>Dynamic networks allow cyber physical devices to form a highly-distributed,<br\/>cloud-like infrastructure for computations involving the physical world. The<br\/>trust-establishment mechanisms developed in this project encourage devices to<br\/>participate in dynamic networks, thereby unleashing the full potential of<br\/>dynamic networks. This project includes development of dynamic networking<br\/>applications, such as distributed gaming and social networking, in<br\/>undergraduate curricula and course projects, thereby fostering the<br\/>participation of this key demographic.","title":"CPS:Small:Collaborative Research:Establishing Integrity in Dynamic Networks of Cyber Physical Devices","awardID":"0931914","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["547471"],"PO":["565239"]},"154012":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project focuses on the development of a new binary rewriter that can be use to statically transform binary code that does not have relocation information and to do so without the overhead of dynamic binary rewriting.<br\/><br\/>Binary rewriters are pieces of software that accept a binary executable program as input, and produce an improved executable as output. The output executable usually has the same functionality as the input, but is improved in one or more metrics, such as run-time, energy use, memory use, security, or reliability. Many optimizations for binary rewriting have been proposed to improve all these metrics. However, existing binary rewriters have a severe limitation ? they are unable to rewrite binaries that have no relocation information. Unfortunately, linkers typically discard relocation information, and hence virtually all commercial binaries lack relocation information. Consequently, they cannot be rewritten by existing rewriters. <br\/><br\/>In this project, the PI is building a binary rewriting infrastructure that can rewrite binaries that do not contain relocation information. This will have the following broader impacts: (i) the ability for anyone to rewrite any binary to improve its performance, security, or memory consumption, or to monitor its resource consumption, is a powerful new ability that could unleash innovation and engender a new class of commercial applications; (ii) the resulting new commercial applications will be a net gain for the nation?s economy; (iii) the improvements in those applications will boost the productivity and security of their users; and (iv) a strong educational program with instructional and outreach components.","title":"CSR: Small: Binary rewriting without relocation information","awardID":"0916903","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["540124"],"PO":["565255"]},"146400":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 <br\/>(Public Law 111-5).\"<br\/><br\/>Achieving high quality synchronization with low power dissipation is a major objective in synchronous VLSI circuit design at high frequency regimes. In order to meet this objective, conventional clock design methodologies are constantly being improved. Also, next-generation alternatives to conventional clocking have been emerging. Resonant clocking technologies provide operating frequencies and power dissipation levels that are unprecedented in the state-of-the-art, bulk-CMOS VLSI IC implementations. These technologies must be characterized for on chip variations, have robust simulation models and be supported by specific design flows in order to be viable in high volume production. This project addresses such challenges in the design and design automation of resonant rotary clocking technology for high-volume IC production.<br\/><br\/>With improved nanoscale design characterization and design automation methodologies, rotary clocking technology can be seamlessly integrated within the mainstream VLSI IC design flow. The broader impacts of the proposed research are in revolutionizing the clock synchronization methodology of digital VLSI synchronous circuits for low-power, multi-GHz operation and providing its sustainability over semiconductor technology scaling. Proposed low-power, multi-GHz high-performance clocking operation will have a major impact on all microelectronic systems, from field-deployable low power sensors to the world's fastest supercomputers. The research accomplishments will be disseminated through a wiki site and a book. Another important educational impact is on integrating nano-computing and technology concepts into computer engineering curriculum. A workshop on computing is planned for high school students as an integral part of the ongoing outreach projects in urban Philadelphia.","title":"CAREER: Rotary Clock Technology Integration","awardID":"0845270","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["543565"],"PO":["562984"]},"159831":{"abstract":"Modern scientific research often includes a substantial computational component, which may use a supercomputer and special software to automatically tune (\"optimize\") the application for the computer. A cluster of standard workstations can offer similar net processing power at a fraction of the cost, but automatic optimization of some important numerical applications for these systems remains an elusive challenge.<br\/>The quest for good performance of parallel applications on clusters of workstations has traditionally employed software techniques that are quite different from those applied to the programming of parallel supercomputers. In particular, static automatic parallelization has been employed on supercomputers (especially for dense matrix codes on shared memory systems) but has not been successful on clusters. The lack of success with static parallelization is due in part to the inability of classic parallelization techniques to expose sufficient memory locality.<br\/><br\/>The PI proposes to develop compiler techniques that will allow dense matrix problems to run efficiently on clusters of workstations by dramatically increasing locality while respecting the parallelism constraints of the code. The PI plans to investigate techniques for automatically producing high performance for dense matrix codes executing on clusters of workstations by \"tiling\" time-skewed loop nests such that they can execute efficiently on a cluster of multicore workstations. This research will enable automatic program optimization for numerical applications. The proposed activity could advance the state of performance models for tiling for clusters.","title":"Supercomputing on a Cluster of Workstations via Scalable Locality and Scalable Parallelism","awardID":"0943455","effectiveDate":"2009-09-15","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["518493"],"PO":["565272"]},"154023":{"abstract":"Recent advances in high-throughput sequencing (HTS) technologies provide opportunities to study genome structure, function, and evolution at an unprecedented scale, and are profoundly transforming genomic research. <br\/>However, fully realizing the potential of HTS technologies requires sophisticated data analysis methods. This research project is aimed at developing efficient computational methods for reconstructing the full spectrum of haplotype sequences from HTS data. Working in collaboration with molecular biologists from the University of Connecticut Health Center and the Centers for Disease Control, the investigators will develop methods enabling three novel applications of HTS, namely (a) reconstruction of diploid genome sequences, including complete haplotype sequences of each CNV copy, (b) reconstruction of alternative splicing isoform sequences and their frequencies, and (c) reconstruction of viral quasispecies sequences and their frequencies. Major outcomes of the project will include the development of a comprehensive analytical toolkit for these problems, and high-quality open source software implementations that will be made available free of charge to the research community. The project will provide opportunities for participation of undergraduate and graduate students in bioinformatics research at UCONN and Georgia State University, and will especially encourage participation of women and underrepresented groups.","title":"III: Small: Collaborative Research: Reconstruction of Haplotype Spectra from High-Throughput Sequencing Data","awardID":"0916948","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["525689","485645"],"PO":["565136"]},"154144":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/>As our society stores ever-increasing quantities of digital data and abandons analog storage, we must be able to manage, organize, and preserve digital data for decades or longer. Maintaining access to large-scale digital archives will be critical in enabling future generations to access the medical records, personal information, photographs, and other data that we are generating and storing digitally. However, current approaches to archival storage are ill-suited to long-term preservation because they do not cope well with evolution of device technologies and rely upon centralized search indexes that do not scale well and are prone to failure.<br\/>This project is exploring techniques that allow the management of large-scale archives containing 105?106 intelligent power-managed storage devices connected by a network. These techniques allow seamless evolution of the archival storage system by integrating new devices and removing old, inefficient devices. The research is also developing approaches to index data in the archive, allowing users to quickly find the data they need by maintaining indexes on each device and routing queries to the devices that might contain relevant data. These techniques will allow archives to scale to hundreds of thousands of devices, allowing them to contain the vast digital legacy we are leaving to our descendants.<br\/>This research will guide the design of archives that are power-efficient and can gracefully evolve as storage technology changes. Additionally, the project will train both undergraduates and graduate students in the problems facing digital archiving, an area of critical importance.","title":"CSR: Small: Managing and Indexing Exascale Archival Storage Systems","awardID":"0917396","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["540845"],"PO":["565255"]},"158874":{"abstract":"Extending virtualization technology into high-performance, cluster platforms generates exciting new possibilities. However, I\/O efficiency in virtualized environments, specifically with respect to disk I\/O, remains little understood and hardly tested. The objective of this research is to investigate fundamental techniques for virtual clusters that not only facilitate rigorous performance studies, but also identify places where performance is suffering and then optimize the system to lessen the impact of such bottlenecks. <br\/>This research will greatly contribute to understanding virtualized I\/O, identifying I\/O bottlenecks and optimizing I\/O, and thus facilitate the cluster systems to most effectively utilize virtualization technology. This project will also contribute to the society through promoting research and engaging under-represented groups that leads students to advancing their careers in science and engineering.","title":"RUI: Automatic Identification of I\/O Bottleneck and Run-time Optimization for Cluster Virtualization","awardID":"0937850","effectiveDate":"2009-09-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["424849","550809"],"PO":["565272"]},"157664":{"abstract":"The objective of this research is the transformation from static sensing into mobile, actuated sensing in dynamic environments, with a focus on sensing in tidally forced rivers. The approach is to develop inverse modeling techniques to sense the environment, coordination algorithms to distribute sensors spatially, and software that uses the sensed environmental data to enable these coordination algorithms to adapt to new sensed conditions.<br\/><br\/>This work relies on the concurrent sensing of the environment and actuation of those sensors based on sensed data. Sensing the environment is approached as a two-layer optimization problem. Since mobile sensors in dynamic environments may move even when not actuated, sensor coordination and actuation algorithms must maintain connectivity for the sensors while ensuring those sensors are appropriately located. The algorithms and software developed consider the time scales of the sensed environment, as well as the motion capabilities of the mobile sensors. This closes the loop from sensing of the environment to actuation of the devices that perform that sensing.<br\/><br\/>This work is addresses a challenging problem: the management of clean water resources. Tidally forced rivers are critical elements in the water supply for millions of Californians. By involving students from underrepresented groups, this research provides a valuable opportunity for students to develop an interest in engineering and to learn first hand about the role of science and engineering in addressing environmental issues.","title":"CPS:Medium:Collaborative Research: Physical Modeling and Software Synthesis for Self-Reconfigurable Sensors in River Environments","awardID":"0930919","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["565273"],"PO":["564728"]},"154034":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>The edge of the Internet continues to spread rapidly over the wireless medium. To cope with the escalating demand, every available opportunity in wireless networking will has to be maximally exploited, particularly at the border of physical and higher layers. One such opportunity is the capability of successfully capturing a frame even in the presence of an interfering frame, i.e., message-in-message (MIM). With MIM, two concurrent transmissions may be successful if they are activated in a specific order, but not the reverse. Towards harnessing MIM, this project aims to: i) Understand the intrinsic potential of MIM through theoretical analysis; ii) Draw on this understanding to design efficient higher layer protocols; iii) Develop a prototype testbed to validate\/evaluate the MIM-aware protocols. <br\/><br\/>This project offers obvious benefits to the broader community as it attempts to satiate the growing demand for bandwidth hungry applications over wireless networks by extracting the most from the scant spectral resources. Additionally, this project facilitates: i) Development and strengthening of the laboratory and curriculum for wireless networking at University of South Carolina and Duke University; ii) Involvement and mentoring of undergraduate students in wireless networking research; iii) Deployment of experimental wireless technologies within The Duke SmartHome.","title":"NeTS: Small: Collaborative Research: Transmission Re-Ordering in Wireless Networks: Protocols and Practice","awardID":"0916995","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["462630"],"PO":["557315"]},"148963":{"abstract":"Temporal inference is the task of identifying the location of an event and the ordering of events in a temporal sequence. To perform temporal inference adequately, linguistic information from a variety of sources must be exploited. For example, to determine the temporal location of an event, one needs to look at the time expression (``at ten o'clock\") associated with the event, tense (past, present) and aspect (perfective, progressive) markers, and temporal adverbials (``already\"). To conduct temporal inference automatically, the dominant research paradigm in the Natural Language Processing (NLP) community is to provide a large corpus of human annotated data for supervised machine learning algorithms, which are capable of combining the divergent sources of linguistic information to infer the temporal location and order of events. Under the planning grant, the PIs are funded to work with the research community to define an annotation methodology for a large-scale Chinese corpus that can support research in multilingual temporal inference in conjunction with existing resources for English. This involves gathering input from the research community on (1) the extension of the existing temporal annotation framework for English to Chinese and possibly to other Asian languages, (2) the methods to bootstrap the temporal annotation automatically through existing linguistic resources. A workshop attended by influential researchers in this area is a central part of this planning grant. Chinese is chosen as the primary language for this project because of its distinctive linguistic properties and the lack of necessary linguistic resources to perform temporal inference in this language, although the methodologies developed in this effort are expected to be readily generalizable to other Asian languages. Temporal inference is a fundamental technology that supports many natural language applications, including but not limited to Information Extraction, Question Answering, Text Summarization and Machine Translation. With the rise of China as a global power, advancing temporal inference technology will enable greater information access in a language that has strategic importance.","title":"CRI CI-P: Building a Community Resource for Temporal Inference in Chinese","awardID":"0855184","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["562587","406300"],"PO":["565215"]},"159974":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\" <br\/><br\/>This award funds three collaborating sets of academic \/ industrial teams to integrate, operate, and host experiments on a suite of end-to-end prototype GENI infrastructure built from GENI-enabled commercial hardware across 13 university campuses, linked by compatible build-outs through two US national research backbones (Internet2 and National Lambda Rail) across an aggregate national footprint of 40 gigabits per second. <br\/><br\/>Prototying this meso-scale infrastructure will: <br\/>1. Create a compelling infrastructure for entirely new forms of research experimentation at a much larger scale than has previously been available, which will then provide early forms of meso-scale experimentation that can drive GENI's spiral development; <br\/>2. Stimulate broad community participation and \"opt-in\" by early users across 13 major campuses, which can then grow by a further 21 campuses as the build-out progresses, with a strong partnership between campus researchers and infrastructure operators; and <br\/>3. Forge a strong academic \/industrial base by GENI-enabling commercial equipment from Arista, Cisco, HP, Juniper and NEC, with software from AT&T and Nicira. <br\/><br\/>The scientific, social and economic benefits are many. Meso-scale experiments can begin within the next 12 months. These experiments will operate at an unprecedented scale and can draw on campus student populations as early, opt-in users. Such experimental capabilities will enable whole new classes of network science and engineering research and provide invaluable early feedback that will guide future spiral development. Researchers will work with national infrastructure providers and commercial equipment providers in a collaborative effort in which timely results and progress matter. It is expected that the community will grow in capability and maturity as it strives to create and integrate this highly novel, medium-scale experimental infrastructure. If successful, this could result in GENI-enabled commercial equipment becoming widely available and deployed over the next spirals in GENI's development and prototyping.","title":"GENI D&P Infrastructure","awardID":"0944089","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"6896","name":"ITR COMPUT RESRCH INFRASTRUCT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["521729"],"PO":["564993"]},"158885":{"abstract":"Disk I\/O on high-end computing machines continues to be a significant performance bottleneck. Parallel file systems have been developed to improve parallel I\/O performance. However, most of these methods are application dependent and their performance varies largely from application to application. The performance of parallel I\/O can be improved with better understanding of I\/O access characteristics at both client and file-server side. There is a great need for research into next-generation intelligent and application-specific I\/O architectures to meet the demand of highend computing.<br\/>We propose a dynamic application-specific I\/O architecture that tailors various parallel I\/O optimizations based on I\/O characteristics of applications. This architecture is dynamic in the sense that its underlying optimization strategies are able to adapt to the variations in different applications for best performance. The proposed research is twofold: 1) understanding I\/O behavior, 2) developing application-specific optimizations for data layout, prefetching, and caching to form an integrated application-specific I\/O architecture. Several technical hurdles have been identified, which include I\/O access signature, compiler analysis, global-aware coordinated<br\/>caching, collective prefetching, data layout optimization and distribution strategies. Solutions are proposed and detailed plans are provided to test these newly proposed solutions and techniques under the PVFS2 parallel file system.","title":"HECURA: A Dynamic Application-specific I\/O Architecture for High End Computing","awardID":"0937877","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I159","name":"Defense Advanced Research Proj"}}],"PIcoPI":["557487","557489","521549",424608],"PO":["565272"]},"157796":{"abstract":"Proposal Title: CPS:Medium:Collaborative Research: The Foundations of Implicit<br\/>and Explicit Communication in Cyberphysical Systems<br\/>Institution: University of California-Berkeley<br\/>Abstract Date: 07\/30\/09<br\/>The objective of this research is to develop the theoretical<br\/>foundations for understanding implicit and explicit<br\/>communication within cyber-physical systems. The approach is<br\/>two-fold: (a) developing new information-theoretic tools to<br\/>reveal the essential nature of implicit communication in a<br\/>manner analogous to (and compatible with) classical network<br\/>information theory; (b) viewing the wireless ecosystem itself<br\/>as a cyber-physical system in which spectrum is the physical<br\/>substrate that is manipulated by heterogeneous interacting<br\/>cyber-systems that must be certified to meet safety and<br\/>performance objectives.<br\/>The intellectual merit of this project comes from the<br\/>transformative technical approaches being developed. The key to<br\/>understanding implicit communication is a conceptual<br\/>breakthrough in attacking the unsolved 40-year-old Witsenhausen<br\/>counterexample by using an approximate-optimality paradigm<br\/>combined with new ideas from sphere-packing and cognitive radio<br\/>channels. These techniques open up radically new mathematical<br\/>avenues to attack distributed-control problems that have long<br\/>been considered fundamentally intractable. They guide the<br\/>development of nonlinear control strategies that are provably<br\/>orders-of-magnitude better than the best linear strategies. The<br\/>keys to understanding explicit communication in cyber-physical<br\/>systems are new approaches to active learning, detection, and<br\/>estimation in distributed environments that combine worst-case<br\/>and probabilistic elements.<br\/>Beyond the many diverse applications (the Internet, the smart<br\/>grid, intelligent transportation, etc.) of heterogeneous<br\/>cyber-physical systems themselves, this research reaches out to<br\/>wireless policy: allowing the principled formulation of<br\/>government regulations for next-generation networks. Graduate<br\/>students (including female ones) and postdoctoral scholars will<br\/>be trained and research results incorporated into both the<br\/>undergraduate and graduate curricula.<br\/>NATIONAL SCIENCE FOUNDATION<br\/>Proposal Abstract<br\/>Proposal:0932410 PI Name:Sahai, Anant<br\/>Printed from","title":"CPS: Medium: Collaborative Research: The Foundations of Implicit and Explicit Communication in Cyberphysical Systems","awardID":"0932114","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["553668"],"PO":["562984"]},"154045":{"abstract":"The goal of computational complexity theory is to determine the computational resources needed to carry out various computational tasks. The resources measured may involve hardware (such as gates used to construct a circuit, or area on a chip) or software (such as the time or space used in the execution of a program on a machine), and the tasks considered may range from simple addition of two integers to a large algebraic or geometric computation.<br\/><br\/>This project will deal primarily with \"low level\" complexity theory, in which the resources required grow modestly (at most quadratically) with the size of the task. Examples of such tasks are furnished by the arithmetic operations (addition, subtraction, multiplication, division and square-root extraction) performed by the executions of single instructions in a computer. For these tasks, hardware-oriented resource measures are most appropriate in most cases.<br\/><br\/>The broader impacts of the project lie in the opportunity it will provide to explore a new model for undergraduate research. The most common model for undergraduate research is to give students problems that they may reasonably be expected to solve within the time allowed (typically an academic year for a senior thesis, or ten weeks for a summer assignment). This project will explore a new model, wherein students are assigned the task of working on an authentic research problem (one that has resisted solution for many years, and is unlikely to be resolved with a single new stroke), with the goal of making a contribution (even a small one) that might play a role in an eventual resolution. If explored with imagination, this new model should provide a valuable complement to the established practices for undergraduate research.","title":"AF:Small:RUI:Concrete Computational Complexity","awardID":"0917026","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":[409892],"PO":["565157"]},"158896":{"abstract":"This research focuses on the design and implementation of a lightweight, yet, versatile middleware framework that provides effective and scalable solutions to the problem of interleaving storage workloads with a wide spectrum of demands. The framework uses simple and non-intrusive collection of workload statistics such as workload histograms and measures of temporal dependence to provide accurate forecasting of system workload characteristics and their impact on system metrics. The framework maps accurately and swiftly complex processes that exist and interact in storage clusters into robust allocation decisions. Central to the framework is its ability to estimate beforehand the effect of resource allocation policies on system metrics, which enables navigating through multiple possible allocations of system resources and selecting the on that best meets system targets.<br\/>This research has the potential to revolutionize autonomic resource management in storage systems and provide methodologies to meet conflicting targets such as discovering trade-offs and dependencies between performance and other metrics including cost, energy consumption, reliability, and availability.<br\/>This project enables enhancement of graduate courses on parallel and distributed systems with aspects of emerging paradigms such as data intensive, cloud, and green computing, as well as advances the education of the multiple students directly involved.","title":"Interleaving Workloads with Performance Guarantees on Storage Clusters","awardID":"0937925","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["518455",424644],"PO":["565272"]},"157686":{"abstract":"The objective of this research is to develop the scientific foundation for the quantitative analysis and design of control networks. Control networks are wireless substrates for industrial automation control, such as the WirelessHART and Honeywell's OneWireless, and have fundamental differences over their sensor network counterparts as they also include actuation and the physical dynamics. The approach of the project focuses on understanding cross-cutting interfaces between computing systems, control systems, sensor networks, and wireless communications using time-triggered architectures.<br\/><br\/>The intellectual merit of this research is based on using time-triggered communication and computation as a unifying abstraction for understanding control networks. Time-triggered architectures enable the natural integration of communication, computation, and physical aspects of control networks as switched control systems. The time-triggered abstraction will serve for addressing the following interrelated themes: Optimal Schedules via Quantitative Automata, Quantitative Analysis and Design of Control Networks: Wireless Protocols for Optimal Control: Quantitative Trust Management for Control Networks.<br\/><br\/>Various components of this research will be integrated into the PIs' RAVEN control network which is compatible with both WirelessHART and OneWireless specifications. This provides a direct path for this proposal to have immediate industrial impact. In order to increase the broader impact of this project, this project will launch the creation of a Masters' program in Embedded Systems, one of the first in the nation. The principle that guides the curriculum development of this novel program is a unified systems view of computing, communication, and control systems.","title":"CPS: Medium: Quantitative Analysis and Design of Control Networks","awardID":"0931239","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["497082","526896","553656","534440","541883"],"PO":["565274"]},"156597":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/><br\/>Summary: Formal Analysis of Complex Systems<br\/><br\/>A Collaborative Proposal Involving CMU, CUNY, NYU, Stony Brook, UMD, Cornell, JPL<br\/><br\/><br\/>This Expedition, under the directorship of Lead PI Edmund M. Clarke, will develop new computational tools to help scientists and engineers analyze and understand the behavior of the complex models they develop for application domains ranging from systems biology to embedded control. Building on the success of model checking and abstract interpretation (MCAI), two well-established methods for automatically verifying properties of digital circuit designs and embedded software, this research project will extend the MCAI paradigm to systems with complex continuous dynamics and probabilistic behaviors. Challenge problems providing technology drivers and testbeds for the research include: understanding the precursors and course of pancreatic cancer; predicting the onset of atrial fibrillation; and obtaining deep design-time insights into the behavior of automotive and aerospace control systems. Ultimately, this Expedition is expected to provide vital tools that will enable health-care researchers to discover better treatments for disease and will allow engineers to build safer aircraft and other complex systems.<br\/><br\/>The world-class team of scientists and engineers assembled for this Expedition includes two Turing Award winners, a recipient of the National Medal of Science, and awardees of other prestigious research prizes. Outreach consists of the development of a new, highly ambitious and highly cross-discipline educational program called Complex Systems Science Engineering, an annual Minority-Focused Intersession Workshop for Undergraduates on Understanding and Analyzing Complex Embedded and Biological Systems to be hosted at member institution Lehman College, CUNY; substantial financial support for undergraduate research; student involvement in the NASA JPL Research Affiliates Program; and other research opportunities for undergraduate and graduate students and postdoctoral trainees.<br\/><br\/>More information: http:\/\/www.mcai2.org\/","title":"Collaborative Research: Next-Generation Model Checking and Abstract Interpretation with a Focus on Embedded Control and Systems Biology","awardID":"0926181","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"6894","name":"ITR EXPEDITIONS"}}],"PIcoPI":["499611","553671","469969","460548"],"PO":["565239"]},"154056":{"abstract":"It is often the case that the time and effort required to develop effective and efficient software on high-end computing systems is the bottleneck in many areas of science and engineering. This project is building a novel middleware framework called Global Graphs that targets this bottleneck. Global Graphs takes a data-structure centric view of shared data where graph-based dynamic data structures drive the development of the rest of the system.<br\/><br\/>A key scientific outcome of this proposed framework is to allow the programmer to have multiple views of the shared data as well as multiple views of the control and tasking model. This flexibility can be leveraged along a discrete scale of data and process views depending on whether the goal is to develop a quick prototype for validating ideas on small scale problems, or the goal is efficient realization on large scale problems, or something in between these two extremes. An additional outcome will be the development of a performance feedback engine that will provide the programmer insights into parts of the program to focus on for performance tuning.<br\/><br\/>The proposed work has important implications for a range of domains requiring the processing of large scale datasets, including data mining, scientific computing and XML data management. The broader outcomes of this work will be to train capable undergraduate and graduate students. The PIs are actively encouraging under-represented minorities to participate in this effort.","title":"Global Graphs: A Middleware for Data Intensive Computing","awardID":"0917070","effectiveDate":"2009-09-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["532951","527873"],"PO":["543481"]},"148996":{"abstract":"This project will develop and operate a community infrastructure, CRCNS.ORG, to enable the sharing of data needed by the computational neuroscience community, to enhance and foster collaborations among theoretical and experimental researchers, and to further the development and testing of computational theories of brain function. This infrastructure will widen the spectrum of techniques applied to brain data, enabling discoveries that go beyond the scopes of individual laboratories.<br\/><br\/>The infrastructure targets the communities of neuroscience and related fields such as computer science, physics, mathematics, statistics, and engineering in which investigators seek access to high-quality neurophysiology data, including electrical, magnetic, and optical recordings from single neurons, neural ensembles, and brain regions. Development activities are aimed at lowering the barriers to contributing, accessing, and using neurophysiology data. Standardized methods will be developed for storing and annotating data in a self-describing, hierarchical format, and enabling flexible on-line access. Scalable methods will be developed to enable users to find potentially useful data and to provide means for online visualization and some on-line analysis. Operations activities will support users and data contributors as well as community outreach activities. Three summer training courses will be held to introduce students and researchers to methods and conventions concerning organization, visualization, and analysis of neuroscience data, and how to use the specific resources of the repository.","title":"CI-ADDO-NEW: CRCNS.ORG - online repository for high-quality neuroscience data and resources for computational neuroscience","awardID":"0855272","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["483816","518654"],"PO":["564318"]},"154078":{"abstract":"Detecting and recognizing objects from real world images is a very challenging problem with many practical applications. The past few years have shown growing success for tasks such as detecting faces, text, and for recognizing objects which have limited spatial variability. <br\/><br\/>Broadly speaking, the difficulty of detection and recognition increases with the variability of the objects ? rigid objects being the easiest and deformable articulated objects being the hardest.<br\/>There is, for example, no computer vision system which can detect a highly deformable and articulated object such as a cat in realistic conditions or read text in natural images. This project develops and evaluates computer vision technology for detecting and recognizing deformable articulated objects. <br\/><br\/>The strategy is to represent objects by recursive compositional models (RCMs) which describe objects into compositions of subparts. Preliminary work has shown that these RCMs can be learnt with only limited supervision from natural images. In addition, inference algorithms have been developed which can rapidly detect and describe a limited class of objects. This project starts with<br\/>single objects with fixed pose and viewpoint and proceeds to multiple objects, poses, and viewpoints. Theoretical analysis of these models gives insight and understanding of the performance and computational complexity of RCMs.<br\/><br\/>The expected results are a new technology for detecting and recognizing objects for the applications mentioned above. The results are disseminated by peer reviewed publications, webpage downloads, and by university courses.","title":"RI: Small: Recursive Compositional Models for Vision","awardID":"0917141","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["549461"],"PO":["564316"]},"146466":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>The motivating problem of this research is to determine how to build computational models of expressive human movement for use in character animation applications. Satisfactory solutions to this problem must allow a high degree of control so that character movement can be customized for any context. This work will unify traditionally separate knowledge-driven and data-driven approaches to character animation, building on the control inherent in knowledge-driven techniques and the realism of motion capture data. A feature-based approach will be used to develop generative models. In this approach, a key-feature set will be determined in consultation with movement professionals, and professional performers working in a motion capture studio will provide data sampling the range of these features. Computational models of each feature will be developed from this data using a combination of procedural and learning techniques. The end goal is style-definition, in which explicit aspects of movement style can be represented computationally. This will support both movement analysis and movement generation through a software framework that allows each of these features to be combined and expressed. Key applications include models for conversational agents and a range of animation tools.<br\/><br\/>This work benefits society through the development of new computational models of expressive movement and by providing deeper insights into the nature of human motion. Computational models of movement that offer meaningful, fine-grained control are essential for a range of applications, including virtual worlds like Second Life, conversational agents, remote collaboration systems, training environments, games and other interactive, character based media. These models will be developed by combining two main trends in computer animation research, one that builds models based on explicit representations of existing knowledge and one that mines movement data to create models. The research will integrate computer scientists, digital artists and movement professionals, bringing a broad set of insights to technology development and providing cross-fertilization between these normally disparate groups. Research results will be published broadly and lead to new computational tools that can be used in a range of applications.","title":"CAREER: Generative Models for Character Animation and Gesture in the New Age of Art and Electronic Interaction","awardID":"0845529","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["550684"],"PO":["565227"]},"156146":{"abstract":"With the semiconductor technology entering the nano-scale era, CMOS devices are facing a dramatic increase in vulnerability to transient faults such as soft errors induced by energetic particle strikes. Such soft errors have become a major challenge in designing next generation microprocessors. While techniques for optimizing reliability at low levels can be accurate, they incur significantly high hardware overheads and costly manufacturing processes. The objective of the proposed EAGER proposal is to explore a new flexible processor architecture for highly effective reliable computing by exploiting the semantics of hardware transaction processing. Instead of simply augmenting existing processors for an attainable reliability, the PI proposes to exploit the semantics of transaction processing from database management systems and recent transactional memories for the design and implementation of the transactional processor architecture, where the reliable computing is an inherent property. The transactional processor aims to provide highly effective and flexible transaction-level verification and native supports for recovery from detected errors. The PI will explore the design space of hardware transaction processing and transaction based reliable computing, as well as new programming language constructs to extend current programming languages for writing programs efficiently in transactions. <br\/><br\/>The success of this project may result in design of low-cost reliable computing platforms based on hardware transaction processing. In addition, the proposed activities will provide a unique channel to attract students from under-represented groups and minorities into science and engineering. The PI plans to take advantage of several college and university wide outreach programs to interact with high school students and teachers to motivate them in computer science.","title":"SHF: EAGER: Transactional Processors: Exploiting Hardware Transaction Processing for Reliable Computing","awardID":"0924279","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[416405],"PO":["559883"]},"146598":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Scheduling policies are at the heart of all computer systems and are a key determinant of system performance. The goal of this project is to provide a rigorous foundation for modern scheduling design issues. The project includes two main directions that correspond to two important modern design paradigms. The first direction is understanding the impact of prioritization. Prioritization is now a fundamental part of system design, and it is applied for many reasons, e.g., to provide QoS guarantees, to provide differentiated service, or simply to provide improved performance. The second direction is understanding scheduling in distributed\/parallel architectures.<br\/>Distributed\/parallel designs are now the norm rather than the exception, and they present a wide variety of important scheduling and resource allocation issues.<br\/><br\/>Across these two directions there are two themes that play a prominent role in the research. The first theme is the importance of power management in modern designs. As energy costs soar, power management is increasingly being treated as a first-class design metric, and must be considered when designing scheduling policies. The second theme is the benefit of applying economic tools, such as game theoretic techniques, to approach scheduling questions. Economic tools are increasingly being exploited with great success by computer scientists, and the domain of scheduling is no exception.<br\/><br\/>Because scheduling is important to a wide variety of scientific, engineering, computing, and business applications, this project will have a broad impact beyond computer science. However, because of the interdisciplinary nature of scheduling, there are a wide variety of approaches across very distinct communities. One goal of this project is to provide courses and educational tools that help to bring these communities together.","title":"CAREER: Towards a rigorous foundation for scheduling in modern systems","awardID":"0846025","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550593"],"PO":["561889"]},"159325":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940608","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":[425934,425935,425936],"PO":["560704"]},"169489":{"abstract":"Proposal #: CNS 09-23188<br\/>PI(s): Du, Xiaojiang; Reinholz, Aron J.<br\/>Institution: North Dakota State University - Fargo<br\/>Title: MRI\/Acq.: Dev.of a Hybrid Wireless Network Infrastructure for Integrated Research and Education <br\/>Project Proposed:<br\/>This project, developing a Hybrid Wireless Network (HWN) to be built on top of an existing Heterogeneous Sensor Network (HSN) testbed, supports research in broadband wireless networking and communication enabling high-quality and high-accuracy performance evaluations of protocols and schemes designed for HWNs. Research projects include<br\/>- Efficient Quality of Service (QoS) provisioning and<br\/>- Orthogonal Frequency Division Multiple Access (OFDMA) resource allocation in HWNs.<br\/>These projects are expected to satisfy individual user's QoS requirements while optimizing the performance (e.g., throughput) of the overall system. Although QoS support in traditional wireless networks and OFDMA resource allocation in cellular networks have been well studied, in HWNs QoS routing and OFDMA resource allocation are highly correlated and the problem lends itself to further exploration. The HWN services faculty and students in Computer Science and Electrical Engineering and 65 staff researchers at the Center for Nanoscale Science and Engineering at the institution and nearby universities. The work aims at integrating various aspects of educational and training environment with innovative research into a cohesive package for education in wireless networking and communication.<br\/><br\/>Broader Impacts: Supported education and training activities include <br\/>- Recruiting students of underrepresented groups to participate in the research, as well as mentoring<br\/>- Developing a new course in Wireless Networking and Communications<br\/>- Integrating research and education<br\/>Native American, female, low income, and first generation students will be specifically targeted in this EPSCoR state where 31% of the undergraduate populations falls below the threshold for low-income US citizens.","title":"MRI: Development of a Hybrid Wireless Network Infrastructure for Integrated Research and Education","awardID":"1022552","effectiveDate":"2009-09-23","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["563625"],"PO":["557609"]},"157059":{"abstract":"This project is studying the impact of NSF's Math and Science Partnership (MSP) program on teacher content knowledge, classroom practice, and student achievement. This cross-site study is examining the relationship between the nature of teachers' professional development experiences and both teacher and student outcomes across 10 MSP projects. An advisory board with expertise in research design, data analysis, professional development, and science content is providing feedback throughout the study.<br\/><br\/>What the field knows about professional development strategies to deepen the content knowledge of mathematics and science teachers is surprisingly limited given the extent of efforts in this area. One challenge for moving forward from these findings is that people use the term teacher content knowledge to mean very different things. Another challenge for the field is understanding which strategies or features matter most in professional development programs focused on deepening teacher content knowledge. Finally, substantial constraints in the research design, and\/or instrumentation of many of the studies of professional development in the current literature have limited what has been learned. <br\/><br\/>The study is addressing these challenges by developing a system for capturing equivalent data across MSP projects. The study is documenting details on the professional development offered to teachers (i.e., the interventions), as well as measuring teacher content knowledge and student learning using common instruments across the MSPs. Data are being analyzed using hierarchical linear modeling (HLM). The first phase of the analysis examines the impact of the MSPs on teacher content knowledge and investigates the relative impacts of different approaches to the professional development. The second phase extends the work to explore the relationships among teacher content knowledge, classroom practices, and student achievement. The study is also examining which MSP approaches appear most promising for closing historic achievement gaps.<br\/><br\/>In addition, the study is providing project-specific impact findings for each partner MSP, including results from appropriate statistical tests, and assisting partners with designing and implementing further analyses. Partner MSPs are given feedback on reports\/articles they prepare using the standards of evidence review process developed by the MSP Knowledge Management and Dissemination project.<br\/><br\/>This project is adding to the knowledge base in several important ways. First, findings about the impact of MSPs on K-8 science teacher content knowledge, classroom practice, and student learning can provide guidance in the design of future professional development efforts. Second, the methodology for improving project-specific evaluations and at the same time providing data for more extensive and sophisticated cross-site analyses has the potential to enhance knowledge generation in future programs supported by NSF and other funders.","title":"Assessing the Impact of the MSPs: K-8 Science (AIM: K-8 Science)","awardID":"0928177","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1793","name":"MSP-OTHER AWARDS"}}],"PIcoPI":["469189","469189","561939","446693","446693"],"PO":["565121"]},"153991":{"abstract":"Partial or complete disk failures are becoming so common and frequent in modern-day large-scale data centers that they are now considered the norm rather than the exception. It is thus of paramount importance to develop novel approaches to effectively and significantly supplementing and improving the existing RAID protection mechanisms, with the goal of providing high reliability and availability for RAID-structured storage systems so that they are capable of tolerating partial, complete, and multiple disk faults while delivering acceptable, non-stop services to the users.<br\/>This project seeks to develop a holistic framework, called a RAID protection activator (ProActive), to address the fundamental and ever-increasing availability challenge facing RAID-structured storage systems. ProActive exploits application workload intensity and data\/parity management and intelligently leverages rich available spare storage resources in large-scale data centers to address the efficiency problem of the existing state-of-the-art availability mechanisms for RAID. ProActive will develop solutions to handle the increasingly more frequent partial and complete disk failures in RAID-structured storage systems based on the design goals of significantly supplementing and improving existing fault-detection, fault-tolerance, and fault-recovery mechanisms.<br\/>The broader impact of the project lies in its (1) research development that impacts and enriches fields as diverse as high-performance computing, availability and reliability in high-end computing systems; (2) infrastructure development that enhances research and education at UNL and, through accessibility via public domain, the high performance and data-intensive computing community; and (3) educational development that exposes graduate and undergraduate students to cutting edge research in highly available storage systems.","title":"DC:Small: ProActive: A RAID Protection Activator for High Availability","awardID":"0916859","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["485828","366560"],"PO":["565136"]},"153760":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The problem of automated 3D reconstruction and modeling of urban environments is of great interest and importance in the fields of computer vision and graphics. This is due to the fact that accurate 3D city models are paramount in the further development of a variety of fields. This project acquires vast amounts of data via the latest generation in laser scanning technology and high-resolution cameras in order to achieve the goal of 3D city modeling. That data is registered in a common frame of reference based on current techniques that are improved in order to facilitate voluminous point clouds. One of the major challenges is the complexity of the acquired dataset that needs to be simplified for efficient rendering and higher-level recognition algorithms. Current simplified methods produce reduced sets of triangles that lack higher-order labels. This project segments and classifies the data into coarse and fine urban elements (such as facades, windows, vegetation, etc.), discovers symmetries among the elements, and fills missing data. It also integrates image-based and laser-based models in order to enhance the acquired geometry, and to produce a seamless visualization result. The above will also aid recognition processes, alternative visualizations and truly photorealistic representation of the 3D scene. This work is disseminated through collaborations with the geography and film-and-media departments of Hunter, as well as other agencies (such as museums). It has significant impact for urban planning, architecture, and archeology applications, and in systems such as street map visualization, as well as in film and construction industries.","title":"RI: Small: Modeling Cities by Integrating 3D and 2D Data","awardID":"0915971","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["409474"],"PO":["564316"]},"153771":{"abstract":"NSF Proposal Number: 0915969<br\/>PI: Vosoughi<br\/>Title: CIF: Small: Collaborative Research: Cooperative Sensing and Communications for Cognitive Networks<br\/><br\/>Project Abstract:<br\/><br\/>The emerging cognitive radio network (CRN) paradigm has a great potential to solve what seems to be a spectrum crisis, by allowing the unlicensed or secondary users (SUs) to opportunistically and dynamically utilize the white spaces within the licensed bands, without causing harmful interference to the licensed or primary users (PUs). This research investigates two essential components of CRNs: spectrum sensing and spectrum access and sharing. More specifically, the PIs study: 1) novel integrated signal processing and communication designs for data fusion in cooperative spectrum sensing, and 2) novel cooperative spectrum sharing and communication schemes that benefit both PUs and SUs.<br\/><br\/>In contrast to the existing data fusion rules that assume error-free communication channels with capacity constraints, this research involves novel integrated designs that consider the deteriorating effects of communication channels between the radios and the fusion point and therefore are robust against channel errors and provide higher detection reliability. The robustness can further be improved by employing distributed space-time coding and harvesting diversity gain. Novel cooperative communication schemes are developed based on modern coding and enable SUs to relay PUs? rateless coded data packets in a fashion that is completely seamless to PUs. The schemes have mutual benefits for both PUs and SUs and differ from the existing ones in which SUs are silent during PUs? transmission. Broader impacts include (1) bonding the research groups from OSU and the UR and enhancing research and education through this partnership, (2) making a significant impact on the theory and practice of CRNs, (3) increasing the participation of under-represented students in PIs? research groups and promoting engineering among high school students, and (4) integrating research and education through development of new courses.","title":"CIF: Small: Collaborative Research: Cooperative Sensing and Communications for Cognitive Radio Networks","awardID":"0915994","effectiveDate":"2009-09-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["565204"],"PO":["564924"]},"153892":{"abstract":"Cognitive radios, which have the ability to adjust bandwidth, modulation scheme, transmit power, error coding, and other parameters, provide tremendous flexibility for adaptation to network conditions. While cognitive radios predominantly change spectral allocation or modulation characteristics, this project considers networks of cognitive radios in which the antennas at each node can be electronically reconfigured. Coupling cognitive radios with reconfigurable antennas gives network nodes an additional degree of freedom to increase link robustness, enhance interference suppression, and increase spectral capacity.<br\/><br\/>This project demonstrates how the flexibility in radiation patterns provided by electrically reconfigurable antennas, or ?cognitive antennas?, can enable a greater density of co-channel communication links and thus increase network capacity. Multi-sensor data fusion is being used to incorporate antenna and radio configuration with cognitive radio scene assessment and adaptation techniques, using multiple data sources. Distributed control techniques are being developed to adapt cognitive radio settings with minimum interaction between nodes, and and the stability and convergence of these algorithms (including convergence rate) are analyzed. We are also creating practical networking protocols to include cognitive antenna capabilities in QoS routing, congestion control, path failure mitigation, and resource management. Research results are being demonstrated on a hardware testbed. The main result of this project is a framework for controlling cognitive radios equipped with reconfigurable antennas. <br\/><br\/>The proposal fosters technical innovation and design among undergraduate students, and outreach activities to attract students, especially from under-represented groups, to engineering.","title":"NeTS: Small: Cognitive Antennas for Wireless Ad Hoc Networks","awardID":"0916480","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["497058","520246","563559"],"PO":["557315"]},"152561":{"abstract":"The Internet suffers from insufficient service quality to reliably support many real-time, high bitrate applications. This shortcoming is due in large part to users or providers not considering the effect their choices have on others ? in other words the resulting externalities. For example, users who download movies during the work day reduce the quality of the network for more time-critical applications; in a non-neutral network, individual ISPs may overcharge high-value applications if they do not consider the interactions of such charges across ISPs. Depending on the circumstances, the problem can be due to a combination of the following three effects: i) the technology of the network does not enable the user or provider to make better choices; ii) the network does not give the user or provider the information to make better choices; iii) the user or provider lacks an incentive to make better choices even if he can. This project will investigate how these effects impact service quality in the network. Using this analysis as a basis, remedies for these effects will be investigated. The remedies may include combinations of new protocols and technology, pricing mechanisms, and regulation ? including requirements and\/or mechanisms for information disclosure.<br\/><br\/>Intellectual Merit:<br\/>This project addresses fundamental scientific and engineering questions in networking. The scientific questions include suitable formulation and analysis of the strategic choices that the users, content providers, service providers, and other parties in the network face when they interact. The properties of the resulting equilibrium strategies and their distributed computation raise novel mathematical and algorithmic questions of broad relevance. Other fundamental scientific issues addressed include how to provide incentives for network evolution and for improved reliability. Engineering questions concern the scalability of the proposed algorithms and protocols, their security and robustness, how they can be deployed incrementally, and their extensibility as new technologies, services, and applications get implemented.<br\/><br\/>Broader Impact:<br\/>The investigators expect that the work will contribute to a paradigm shift in the design of the future network. The focus on externalities, which is central to our project, has been largely unexplored and our preliminary investigations demonstrate its substantial importance. The investigations undertaken in the course of this project will suggest how network design should be modified to account for externalities and network informational imperfections. This project, with its focus on the intersection of the engineering and economic issues of network services, will offer ideal research experience to the project?s Ph.D. students. It is expected that the experiences and results from this project will greatly benefit the PI?s courses as well, in particular by making students aware of the inherent tradeoffs in engineering systems that function in a market context.","title":"NetSE: Large: Collaborative Research: Improving Internet Incentives","awardID":"0910702","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":[406461,"560233"],"PO":["564993"]},"161394":{"abstract":"This award supports the first Summer School on Cyber-Physical Systems, held at the Georgia Institute of Technology, Atlanta, Georgia, June 22-25, 2009. NSF funds support outreach and enable the participation of US graduate students and early career faculty in this international event.<br\/><br\/>Cyber Physical Systems (CPS) are systems that rely on a tight integration of computation, communication, and controls, for their operation and interaction with the physical environment in which they are deployed. Such systems must be able to operate safely, dependably, securely, efficiently and in real-time, in potentially highly uncertain or unstructured environments. CPS are expected to have great technical, economic and societal impacts in the near future.<br\/><br\/>The objective of the Georgia Tech Summer School on Cyber-Physical Systems is to establish a forum for intellectual exchange on CPS science and technology for researchers from industry and academia. The format of the Summer School is a five-day meeting, organized around the different aspects of Cyber Physical Systems. The topical areas covered include: formal methods, distributed embedded systems, networked control systems, embedded software, scheduling, platforms, and applications.","title":"Summer School on Cyber-Physical Systems","awardID":"0951657","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"I302","name":"National Security Agency"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":[431683,"553540"],"PO":["561889"]},"153782":{"abstract":"Anonymous communication in computer networks generally relies upon the &#64257;ltering of tra&#64259;c through a cascade of mixes. Clients select a number of proxy nodes that modify and obscure the origin of a message so as to make the detection of a relationship between source and destination extremely di&#64259;cult. While this architecture is known to not be robust against a globally passive adversary, an ever growing body of literature has demonstrated that even moderately capable adversaries can link the communications between two parties using these networks. Accordingly, new techniques ensuring stronger levels of anonymity must be explored. This project will develop a new architecture for anonymity networks o&#64256;ering cryptographic guarantees of anonymity based on a foundation of Secure Function Evaluation. These Provably Anonymous Networks (PANs) protect the participants of communication from tra&#64259;c analysis attacks by remaining unaware that the exchange of messages has occurred. However, realizing a more trustworthy architecture is not simply the result of haphazardly assembling the above components. Rather, this system must be carefully composed so as to avoid the leakage of information useful in the identi&#64257;cation of a communication channel. The results of this project will not only be used to enhance graduate and undergraduate curriculum, but will also be used to develop a tool to assist members of the Carter Center administer observe elections without fear of eavesdropping.","title":"TC: Small: Provably Anonymous Networking Through Secure Function Evaluation","awardID":"0916031","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["549758"],"PO":["565327"]},"152451":{"abstract":"Randomness has emerged as a core concept and tool in computation. From modeling phenomena to efficient algorithms to proof techniques, the applications of randomness are ubiquitous and powerful. Notable examples include: construction of important combinatorial objects such as expanders, rigorously establishing phase transitions in physical models, finding polynomial-time algorithms for fundamental sampling problems and approximating #P-hard counting problems, designing probabilistically checkable proofs (PCP's) and establishing the hardness of approximation, and discovering simpler and often faster algorithms for a variety of computational problems. In the course of these tremendous developments, several general-purpose techniques have emerged, and random sampling has become a fundamental, universal tool across sciences, engineering and computation. <br\/><br\/>This project brings together leading researchers in randomized algorithms to solve hard problems in random sampling, to identify techniques, and to develop new analytical tools. The applications come from a range of fields, including complexity, physics, biology, operations research and mathematics. The most general and widely-studied technique for sampling is simulating a Markov chain by taking a random walk on a suitable state space. The Markov Chain method and its application to sampling, counting and integration, broadly known as the Markov Chain Monte Carlo (MCMC) method, is a central theme of the project. <br\/><br\/>Intellectual Merit. The project focuses on applications of randomized algorithms and random sampling to rigorously address problems across several disciplines. Within computer science these topics include: massive data sets, where sampling is critical both for finding low-dimensional representations and clustering; routing networks, where sampling has many applications from monitoring and path allocation to optimization; machine learning; and property testing. Recent interactions between computer science and other scientic disciplines have led to many new rigorous applications of sampling, as well as new insights in how to design and analyze efficient algorithms with performance guarantees; for instance, phase transitions in the underlying physical models can cause local Markov chains to be inefficient. The project explores deeper connections between physics and random sampling, including conjectured correlations between reconstruction problems and thresholds for the efficiency of local algorithms. Many related problems arise in biology, such as phylogenetic tree reconstruction and analysis of complex biological networks. In nanotechology, models of self-assembly are simple Markov chains. In mathematics, the techniques used in the analysis of sampling algorithms in general and Markov chains in particular have drawn heavily on probability theory, both discrete and continuous. <br\/><br\/>Broader Impact. The college of computing at Georgia Tech is home to the new Algorithms and Randomness Center (ARC) with many faculty and students sharing this expertise. The project's activities include designing a summer school for graduate students in randomized algorithms and designing a course for training students from diverse backgrounds and hosting workshops focusing on both theoretical and applied aspects of randomized algorithms. Participation of women and under-represented groups in all of these activities will be encouraged, and the workshops will include tutorials to increase accessibility. These coordinated efforts in education and research will solidify the impact of ARC and make it a premier center for algorithms, randomness and complexity.","title":"AF: Large: Collaborative Research: Random Processes and Randomized Algorithms","awardID":"0910415","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["549871"],"PO":["565251"]},"153672":{"abstract":"The wireless mesh network technology has recently emerged as a promising solution to building large-scale wireless Internet with quick and easy deployment. It has numerous applications, such as broadband Internet access, building automation, and intelligent transportation systems. The indispensable technology enabling large-area roaming in wireless mesh networks is mobility management. Mobility management has been extensively studied in infrastructure-based single-hop wireless access networks. However, Internet-based hybrid wireless mesh networks involve multihop wireless access from users to the Internet. In such an environment, routing and wireless channel access over multihop wireless links can produce detrimental effects on the performance of mobility management in wireless mesh networks. This research develops scalable and cost-effective mobility management mechanisms for Internet-based hybrid wireless mesh networks. It emphasizes the integrated design of mobility management with efficient medium access control and wireless multihop routing, which was not considered in traditional mobility management design. This research will provide innovative techniques to numerous applications of the wireless mesh network technology. It also provides an excellent opportunity for graduate and undergraduate research students.","title":"NeTS: Small: Cross-layer Design for Seamless Mobility Support in Hybrid Wireless Mesh Networks","awardID":"0915599","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560198"],"PO":["557315"]},"153793":{"abstract":"The proposed research addresses the problem of identifying and providing source code-based understanding of obfuscated malcode plaguing the Internet. Obfuscated malcode presents a clear and present danger to today?s society in terms of individual privacy, security as well as to the Internet?s overall trustworthiness. Attackers continue to use obfuscation to successfully defeat attempts by defenders to prevent infection or spread of the malcode. <br\/>The goal of the research will be to develop dynamic binary analysis processes for Internet worm executables. These processes will be used to create a reverse engineering framework to create assembly code from worm machine code and in turn create associated control and data flow graphs. Generalizations of instruction sequences, known as motifs, are extracted from these graphs using new techniques based in part on program slicing and will be applied against models of worm behavior described in terms of state machine, decision tree or family tree models; partial or complete matching against these models will yield knowledge of worm interactions with its target environment, its obfuscation techniques and its means of command, control and update by the attacker.<br\/>This research will help to assess if control and data flow graphs can represent any obfuscated malcode. In case some malcode cannot be represented using these graphs, other representations will be investigated. The accuracy of the malcode representation will be evaluated since the representation will be based mainly on system call analysis. Finally, several combinations of static and dynamic analyses will be studied to assess the impact on the malcode representation details.","title":"TC: Small: Discovering Designer Intent through Dynamic Analysis of Malware","awardID":"0916061","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["519631"],"PO":["565264"]},"162384":{"abstract":"\"Creating a Research Agenda in Computing at the Margins\" is a workshop designed to help articulate a set of intellectual challenges that should be addressed by CISE researchers as they design and develop information and computing technology that is oriented toward people who are not currently in the set of already well-served technology users. This includes underrepresented populations within the United States, populations who encompass emerging markets in the third world, as well as the economic disadvantaged. The common assumption that increased access resolves the digital divide may actually be false. Indeed, what may be needed are fundamentally different kinds of technologies -- based on new advances in the methods and theories of design and evaluation, along with technological innovation -- grounded in an understanding of the unique constraints and considerations of the communities for which those systems are intended. Evidence already suggests that local differences in infrastructure, literacy, culture, or economic models, can and have fostered scientific innovations in user experience methods and theories, advances in systems and networking technologies and algorithms.<br\/><br\/>The resulting research agenda will stimulate technical innovation that will support the creation, deployment, and assessment of technologies that allow ever more people to enjoy the benefits of the digital society. It will enrich the digital society by diversifying those who participate. New techniques and technology that addresses the wider needs of society is an important educational opportunity. As a research agenda it has the potential to teach the next generation of researchers and engineers a set of skills that help them build technologies that respond to the needs of all sectors of society.","title":"WORKSHOP: Creating a Research Agenda in Computing at the Margins","awardID":"0956948","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["450731"],"PO":["564456"]},"152594":{"abstract":"The cost-effective construction of functionally correct software systems remains an unmet challenge for Computer Science. Although industrial best practices for software construction (such as testing, code reviews, automatic bug finding) have low cost, they cannot provide strong guarantees about correctness. Classical verification methods, on the other hand, are not cost-effective. Recently, the research community has been exploring the idea of dependent types, which extend the expressive power of programming languages to support verification. These rich types allow the programmer to express non-trivial invariant properties of her data and code as a part of her program. That way, verification is incremental, localized and at source-language level.<br\/><br\/>This multi-institution collaborative project is for the design and implementation of a programming language with dependent types, called Trellys. Technically, Trellys is call-by-value functional programming language with full-spectrum dependency. Overall, the project combines numerous fragmented research results into a coherent language design, by building a robust open-source implementation. The design draws on diverse solutions to the technical problems that arise from extending traditional programming languages accommodate dependent types: type and effect inference, language interoperability, compilation, and concurrency.","title":"SHF:Large:Collaborative Research:TRELLYS: Community-Based Design and Implementation of a Dependently Typed Programming Language","awardID":"0910786","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["550615"],"PO":["564388"]},"153694":{"abstract":"The Social Web, or Web 2.0, has changed the way people connect with each other and use information. Sites such as Twitter, Flickr, and Digg allow people to create content, annotate it with descriptive labels, and befriend others to create communities. The collective knowledge and expertise of the community is expressed through the links between people and information. The key to extracting this knowledge is understanding the structure and dynamics of networks.<br\/><br\/>This project will study dynamics of information spread on networks and how it relates to network structure and quality of information. In previous work, investigator has developed a mathematical framework to study the properties of static networks. She showed that a centrality metric based on the number of paths connecting nodes can be used to identify groups and important nodes within them. However, looking at static structure ignores valuable temporal information that can be used to improve the ability to identify influential nodes and hidden groups, as well as quickly and reliably predict important trends and evaluate the quality of information. The investigator will extend these metrics to dynamic networks and model information spread on networks. The investigator will apply these methods to complex networks that link different types of entities, namely, people, content, and groups.<br\/><br\/>Considering network structure in the dynamics of information spread will lead to more effective tools to leverage community's knowledge to address a number of problems, including identifying important trends, assessing information quality, and separating true information from rumors.","title":"NetSE: Small: Structure and Dynamics of Complex Networks","awardID":"0915678","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["517887"],"PO":["564924"]},"161196":{"abstract":"Cognitive radio networks (CRNs) operate on secondary spectrum bands, where they opportunistically access and use under-utilized spectrum bands. Though research on CRNs is gaining momentum, there is still little or no understanding of how these networks will fair in the face of attacks. Moreover, the addition of new architectures and protocols bring more vulnerabilities that have not been seen before.<br\/><br\/>This project will make use of game theoretic techniques to develop pragmatic design methodologies that will lead to more efficient algorithms and protocols for tackling vulnerabilities in cognitive radio networks while maintaining high spectrum usage. The intellectual merit of this project lies in the execution of four tasks. These are 1) devising and solving malicious node detection games where malicious nodes(s) will be detected and isolated by regular nodes, 2) devising mechanisms that will enforce cooperation among cognitive radio nodes such that they use the commonly available spectrum in a co-operative manner, 3) developing rules and policies such that nodes belonging to different networks can co-exist, and 4) studying the performance trade-offs on service guarantees when policies are set in a dynamic manner.<br\/><br\/>Broader impact of this project will include the dissemination of the research results by means of conference and journal publications. Minority and women students will be recruited as research assistants to assist the PI in his efforts. The PI will not only educate the students at UCF about the vulnerabilities in CRNs but will also help the academic and industrial efforts bring the cognitive radio technology to the market place.","title":"EAGER: Tackling Vulnerabilities in Cognitive Radio Networks: A Game Theoretic Approach","awardID":"0950342","effectiveDate":"2009-09-01","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":[431172],"PO":["565157"]},"163044":{"abstract":"Computer-based technologies have become pervasive in our society. Children, and even more so adolescents, have grown to think of the Internet, along with the computers used to surf it and the many platforms meant for game playing, as toys. Supporters of the new technologies point to their potential to educate and to impart skills that will be useful later on in life. Others view the overuse of the Internet and gaming as a harmful addiction. The truth most likely falls in between these two viewpoints. Yet with the exception of investigations into the negative impact of violence (whether on television or in video games), there has been scant research into the positive and negative effects of technology and computers on our nation's youth. In this exploratory project, the PI will seek to determine which factors are responsible for making technology helpful to adolescents and which are detrimental. To this end, adolescents will be asked to participate in a couple of anonymous Internet surveys. One of these surveys will seek to establish the relationship between frequency of use and content of use (gaming, e-mail, educational games, etc.) with a variety of factors such as interest in science, grades, individual psychological characteristics (risk-taking, social influences from friends, psychological well-being, self-control, etc.), engagement in sports or other physical activity, injuries related to computer use, parental monitoring of and limits on computer use, regular bed time and how much sleep per night, cigarette use, alcohol use, height, weight, age, and gender. In a second survey the PI will examine the positive aspects of social networking websites (e.g., Facebook and MySpace) for adolescents with disabilities, who are chronically ill, and who are recovering from major surgery or disabling injury; among other things, participants will be asked what improvements would better serve their needs on social networking sites. The adolescent surveys will be supplemented with parental versions for parents of adolescents.<br\/><br\/>Broader Impacts: This research will provide much needed insight into how computers are affecting our nation's youth. Project outcomes will enable scientists to advise parents and others how to best use technology with adolescents, and will also inform designers how to create better and more inclusive systems in the future.","title":"EAGER: Adolescent Computer and Electronic Game Use","awardID":"0960391","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["485647"],"PO":["565227"]},"158941":{"abstract":"Modern supercomputers are complex, hierarchical systems<br\/>consisting of huge numbers of cores, systems for disk storage,<br\/>and nodes for I\/O forwarding. These numbers continue to grow and<br\/>the need for tools to understand the behavior of the system<br\/>software becomes paramount: without these tools it is impossible<br\/>to effectively tune that software, and high degrees of efficiency<br\/>is unattainable by applications. This project addresses the<br\/>challenge of understanding the behavior of complex system<br\/>software on very large-scale compute platforms, like the current<br\/>petascale computers. In particular, this project is developing<br\/>software infrastructure to provide end-to-end analysis and<br\/>visualization of I\/O system software. Specifically, the<br\/>objectives are to develop, improve, and deploy (1) end-to-end,<br\/>scalable tracing integrated into the I\/O system (MPI-IO, I\/O<br\/>forwarding, and file system); (2) information visualization tools<br\/>for inspecting traces and extracting knowledge; (3) testing<br\/>components that drive this system to generate example patterns,<br\/>including a component to generate anomalies; and (4) tutorials<br\/>and tools for helping other system software developers<br\/>incorporate this analysis and visualization system into their<br\/>production software. The software and techniques developed in<br\/>this project will be directly applicable to and useful in other<br\/>system software libraries which perform complex interactions on<br\/>large systems.<br\/><br\/>For further information see the project web site at the URL:<br\/>http:\/\/vis.cs.ucdavis.edu\/NSF\/Jupiter","title":"Visual Characterization of I\/O System Behavior for High-End Computing","awardID":"0938114","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7476","name":"ETF"}}],"PIcoPI":["552243"],"PO":["560586"]},"154101":{"abstract":"Ad hoc workflows are everywhere in service industry, scientific<br\/>research, as well as daily life, such as workflows of customer<br\/>service, trouble shooting, information search, etc. Optimizing ad<br\/>hoc workflows thus has significant benefits to the society.<br\/>Currently the execution of ad hoc workflows is based on human<br\/>decisions, where misinterpretation, inexperience, and ineffective<br\/>processing are not uncommon, leading to operation inefficiency.<br\/><br\/>The goal of this research project is to design and develop<br\/>fundamental models, concepts, and algorithms to mine and optimize ad<br\/>hoc workflows. The project includes novel research on the following<br\/>key areas: (1) Network Modeling and Structure Mining. A network model<br\/>is built that statistically captures the execution characteristics<br\/>of ad hoc workflows, and is optimized to improve the execution of<br\/>new workflows with respect to different optimization objectives.<br\/>(2) Workflow Artifact Mining. The network model built on workflow<br\/>executions is then extended with workflow artifact mining to realize<br\/>an optimization system that is able to take advantage of both<br\/>executions and text contents. (3) Role Discovery and Relation<br\/>Assessment. A computational framework is built to analyze the roles<br\/>and relationships of agents involved in ad hoc workflow executions<br\/>in order to further optimize workflows.<br\/><br\/>Advances from this project include models to represent ad hoc<br\/>workflows, algorithms for mining hidden collaborative models, and<br\/>techniques that optimize ad hoc workflow processing. The project<br\/>bridges two emerging research areas: service science and network<br\/>science, and enriches the principles and technologies of data mining.<br\/>It also enhances research infrastructure through the collaboration of<br\/>team members from different areas (data mining, database, and<br\/>network). This research is tightly integrated with education through<br\/>student mentoring and curriculum development. <br\/><br\/>Publications, software and course materials that arise<br\/>from this project will be disseminated on the project website:<br\/>URL: http:\/\/www.cs.ucsb.edu\/~xyan\/smartflow.htm","title":"III: Small: Collaborative Research: Mining and Optimizing Ad Hoc Workflows","awardID":"0917228","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["432722"],"PO":["565136"]},"153133":{"abstract":"The most common approach in decision theory involves preferences expressed numerically in terms of utility functions, while optimization over different choices takes into account the probability distribution over possible states of the world. An alternative approach represents preferences in qualitative terms, and is motivated, in part, by difficulties in building good utility functions, ascertaining accurate probability distributions, and related problems.<br\/><br\/>This project is advancing qualitative decision theory by focusing on two promising formalisms for representing and reasoning about qualitative preferences: conditional preference networks (CP-nets) and answer-set optimization (ASO) programs. Both CP-nets and ASO programs offer representations for several classes of preference problems, but each has major limitations. This project addresses these limitations by developing a formalism. ASO(CP) programs, which extend both ASO programs and CP-nets by exploiting key properties of both. The project's major objectives are: to introduce formally ASO(CP) programs by integrating into ASO programs generalized conditional (ceteris paribus) preferences of CP-nets; to establish expressivity of ASO(CP) programs, to study properties of preorders that can be defined by means of ASO(CP) programs, and to address relevant computational issues; to investigate a crucial problem of preference equivalence, essential for automated preference manipulation; to study an extension of ASO(CP) programs to the case of incompletely specified outcomes, essential for practical applications; and, to extend ASO(CP) programs to the first-order language extended with aggregate operators.<br\/><br\/>Representing preferences qualitatively and optimizing over such preferences is a fundamental problem of qualitative decision theory. By integrating and advancing understanding of major types of common preferences that are captured by ASO programs and CP-nets, this project will produce theoretical and practical advances in representation and reasoning about preferences, bringing it to the point where it can be effectively used in practical decision support systems.","title":"RI: Small: Qualitative Preferences: Merging Paradigms, Extending the Language, Reasoning about Incomplete Outcomes","awardID":"0913459","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[407833],"PO":["562760"]},"148920":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The proposed work is focused on gestural human computer interfaces, camera-based interfaces for individuals with severe physical disabilities, communication through sign language and gesture, and\/or motion of the human body and hands. The proposed infrastructure enhancement would make it possible, as well as practical, to conduct video-based research outside the lab. The infrastructure includes a ruggedized mobile system for capture of synchronized, multi-view digital video on site, for instance in schools for the Deaf and in homes for the disabled. Software infrastructure will be enhanced to support the development of the interface for deployment of the systems to be used in the field, and for annotation of video collected in the field. Video data capture from a larger and more diverse pool of subjects will lead to a more diverse collection of videos for study of linguistic variation and for training and testing of computer vision algorithms.<br\/><br\/>The camera-based assistive technology developed as part of this project will have a positive impact on the quality of life of adults and children with severe physical disabilities, as well as their friends, families and caregivers; the software will be disseminated at special care facilities and will also be available on the internet via free download. The automated gesture spotting, indexing, matching, and retrieval methods developed in this project would enable sign-based search of ASL literature, lore, poems, performances, courses, from digital video libraries and DVDs. Such capability could have far-reaching implications for improving education, opportunities, and access for the deaf. The gestural analysis, matching, and retrieval methods developed in this project should also accelerate linguistic and cross-linguistic research on signed languages and the gestural components of spoken languages.","title":"II-EN: Infrastructure for Gesture Interface Research Outside the Lab","awardID":"0855065","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["475203","472054","557296"],"PO":["565227"]},"157511":{"abstract":"This award provides travel funds to assist approximately 20 US-based graduate students to attend the Sixth Symposium on Networked Systems Design and Implementation (NSDI). The goal of the conference is to bring together researchers from across the networking and systems community?including computer networking, distributed systems, and operating systems?to foster cross-disciplinary approaches and to address shared research challenges. This cross-disciplinary emphasis makes it well-suited as a target for student participation.<br\/><br\/>The Sixth Symposium on Networked Systems Design and Implementation (NSDI) will be held in Boston, MA, on April 22-24, 2009. The conference focuses on the design principles of large-scale networks and distributed systems and, in particular, challenges that are shared across systems as diverse as internet routing, peer-to-peer file sharing, sensor nets, scalable web services, and distributed network measurement. <br\/><br\/>Broader Impact. Participation in NSDI and similar conferences is a valuable and important part of the graduate school experience. It provides students with the opportunity to interact with more senior researchers in the field, and exposes students to leading edge work in the field. The award enables the participation of students who would otherwise be unable to attend NSDI.","title":"Student Travel Support for the Sixth Symposium on Networked Systems Design and Implementation (NSDI)","awardID":"0930058","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["463055"],"PO":["565090"]},"154002":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/>Many studies have shown that human mistakes are an important source of system failures. Further, repairing mistakes is often time consuming, leading to high unavailability. In this project, we will explore a novel approach to dealing with human mistakes called operator-proof systems management. In an operator-proof system, an omnipresent management infrastructure will enable the system to defend itself against operator mistakes. The infrastructure will constantly monitor operator actions and the system state to decide when and how the system should defend itself. Possible defensive measures include blocking operator actions that could lead to a mistake and\/or limiting operator access to prevent mistakes from spreading throughout the system. Blocks are later lifted if the system can test the correctness of the operator actions.<br\/>To explore our ideas, we will design and implement two very different prototype operator-proof systems: an Internet service and an enterprise system. We will explore the design space and evaluate the overall approach by running a large set of experiments, where volunteer operators of different levels of experience are asked to perform a variety of tasks on the prototype systems.<br\/>Broader impacts. Our research will provide a concrete step toward the realization of a model where large computer systems can be operated at lower cost by less skilled individuals. Our investigation will also expose a large number of students (acting as volunteer operators) to system management issues and our proposed solutions.","title":"CSR: Small: Operator Proof Systems Management","awardID":"0916878","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["486839","559843"],"PO":["565255"]},"154123":{"abstract":"CCF - 0917324 <br\/>SHF: Small: Collaborative Research: Taxonomy for the Automated Tuning of Matrix Algebra Software<br\/>PI Jessup, Elizabeth R. University of Colorado at Boulder<br\/>CCF ? 0916474<br\/>PI Norris, Boyana University of Chicago<br\/>Abstract:<br\/>In response to the need for high-performance scienti&#64257;c software, we propose to study ways to ease the production of optimized matrix algebra software. Each step of the code development process presently involves many choices, most requiring expertise in numerical computation, mathematical software, compilers, or computer architecture. <br\/>The process of converting matrix algebra from abstract algorithms to high-quality implementations is a complex one. When leveraging existing high-performance numerical libraries, the application developer must select the appropriate numerical routines and then devise ways to make these routines run e&#64259;ciently on the architecture at hand. Once the numerical routine has been identi&#64257;ed, the process of including it into a larger application can often be tedious or di&#64259;cult. The tuning of the application itself then presents a myriad of options generally centered around one or more of the following three approaches: manually optimizing code fragments; using tuned libraries <br\/>for key numerical algorithms; and, less frequently, using compiler-based source transformation tools for loop-level optimizations. The goals of the proposed research are three-fold. First, we will construct a taxonomy of available software that can be used to build highly-optimized matrix algebra computations. The taxonomy will provide an organized anthology of software components and programming tools needed for that task. The taxonomy will serve as a guide to practitioners seeking to learn what is available for their programming tasks, how to use it, and how the various parts &#64257;t together. It will build upon and improve existing collections of numerical software, adding tools for the tuning of matrix algebra computations. Second, we will develop an initial set of tools that operate in conjunction with this taxonomy. In particular, we will provide an interface that takes a high-level description of a matrix algebra computation and produces a customizable code template using the software in the taxonomy. The template will aid the developer at all steps of the process from the initial construction of Basic Linear Algebra Subprogram (BLAS)-based codes through the full optimization of that code. Initially, the tools will accept a MATLAB prototype and produce optimized Fortran or C. Finally, we will advance the state-of-the-art in tuning tools by improving <br\/>some of the tools included in the taxonomy, broadening their ranges of functionality in terms of problem domains and languages.","title":"SHF: Small: Collaborative Research: Taxonomy for the Automated Tuning of Matrix Algebra Software","awardID":"0917324","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7934","name":"PARAL\/DISTRIBUTED ALGORITHMS"}}],"PIcoPI":["518600"],"PO":["565251"]},"154244":{"abstract":"The BitTorrent Ecosystem includes millions of BitTorrent peers, hundreds of active trackers, and dozens of independently-operated torrent discovery sites. The Ecosystem is further fueled with distributed trackers using Distributed Hash Table (DHT) and Peer Exchange (PEX) functionality. The Ecosystem also includes ?interdiction companies,\" which attempt to curtail the distribution of targeted content.<br\/><br\/>Despite its importance, both in terms of its footprint in the Internet and the influence it has on emerging P2P applications, the BitTorrent Ecosystem is only partially understood today. Many communities (including P2P researchers and developers, ISP researchers and engineers, copyright holders, and law enforcement agencies) would like to have a comprehensive and in-depth understanding of the BitTorrent Ecosystem, as well as tools for mapping the Ecosystem in the future.<br\/><br\/>In this context, the PI and his graduate students are exploring two inter-related research directions. First, they are developing tools and methodologies for comprehensive exploration and mapping of the entire BitTorrent Ecosystem. Second, they are examining of how the Ecosystem can be attacked and defended. <br\/><br\/>The expected results for the mapping research include: new public-domain tools and methodologies for mapping and analyzing the Ecosystem; a comprehensive mapping data set, which will be more than an order of magnitude larger than any existing data set and will essentially cover all trackers and peers in the public Ecosystem; novel estimation methodologies based on importance sampling, incorporating measurement samples from both centralized and distributed trackers.<br\/><br\/>The expected results for the BitTorrent attack\/defense research include: measurement and evaluation methodologies of ongoing attacks from ?interdiction companies\"; an in-depth study of the seed attack, whereby the attackers attempt to prevent the initial seed from distributing the file into the Ecosystem; machine learning algorithms for defending against the pollution attack in BitTorrent; and tractable deterministic and stochastic models for the dynamics of BitTorrent attacks, providing critical insight into BitTorrent vulnerabilities.","title":"NeTS:Small: Mapping, Attacking and Defending the BitTorrent Ecosystem","awardID":"0917767","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550020"],"PO":["565303"]},"148931":{"abstract":"Mobile robots are envisioned to play a significant role in a variety of application domains such as collaborative sensing of a target object or environment, assisting homeland security personnel in safe-guarding buildings and detecting intruders or harmful materials, assisting elderly and disabled individuals in daily-life activities, etc. However, several key challenges related to sensing and control algorithms, network protocols, mobility management, localization, and embedded hardware\/software need to be addressed in order to realize the full potential of mobile robots. This project deals with the acquisition and development of an adaptive robotic testbed, consisting of four clusters of heterogeneous mobile robots, to support and expand a wide range of ongoing research and education activities in robotics, embedded sensor systems, wireless sensor networks, distributed computing systems, and power management. The testbed includes four Pioneer 3-DX robots, twenty iRobot Create robots, and several desktop and laptop computers to interact with and control the testbed. The robotic testbed brings together diverse faculty researchers and students to facilitate new advances in each of the above areas and enables the validation of research results that would not have been possible without this infrastructure. In addition to providing state-of-the-art equipment for graduate students to perform their experimental research, the developed infrastructure also provides a flexible and cost-effective testbed for use in undergraduate and graduate courses on robotics, embedded systems, distributed systems, etc. Finally, the testbed also serves as an effective vehicle to recruit high-school and minority students, providing excellent synergy with the highly successful high-school FIRST robotics competition.","title":"CRI: II-NEW: Adaptive Robotic Testbed for Wireless Sensor Networks and Autonomous Systems","awardID":"0855098","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["335186","550994","540778","451692"],"PO":["565303"]},"158732":{"abstract":"This is a collaborative research effort bringing together expertise of Lise Getoor, University of Maryland College Park (0937094), Alex Pang, University of California-Santa Cruz (0937073) and Lisa Singh, Georgetown University (0937070).<br\/><br\/>In today's linked world, graphs and networks abound. There are communication networks, social networks, financial transaction networks, gene regulatory networks, disease transmission networks, ecological food networks, sensor networks and more. Observational data describing these networks can often times be obtained; unfortunately, this graph data is usually noisy and uncertain. In this research, we propose a formalism which allows us to capture and reason about the inherent uncertainty and imprecision in an underlying graph. We begin by proposing probabilistic similarity logic (PSL), a simple, yet powerful, language for describing problems which require probabilistic reasoning about similarity in networked data. We also introduce the notion of visual comparative analysis of PSL models derived using different evidence and assumptions, and illustrate its utility for the analysis of graphs and networks. <br\/><br\/>Dealing with noise and uncertainty in complex domains, and conducting comparative analytics are core capabilities required for the Foundations on Data Analysis and Visual Analytics (FODAVA) mission. This research focuses on integrating representation, comparative analysis and visualizations methods into an open source toolkit that supports the representation, comparison and visualization of PSL models. In addition to producing the toolkit, the research team is working with researchers in a variety of interdisciplinary domains to validate the utility of our approach, and also developing tutorial and training materials for the tools. <br\/><br\/>The key broader impact of the work is that the methods for reasoning about sources of noise and uncertainty in graphs, and understanding their impact on results are general and fundamental to the intelligent analysis of today's rich information sources. Results, including open source software will be distributed via the project Web site ( http:\/\/www.cs.umd.edu\/projects\/linqs\/fodava\/ ).","title":"FODAVA: Collaborative Research: Foundations of Comparative Analytics for Uncertainty in Graphs","awardID":"0937073","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}}],"PIcoPI":[424191],"PO":["563751"]},"157643":{"abstract":"CPS: Small: Design of Networked Control Systems for Chemical Processes<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of the proposed research program is to develop, for the first time, the theory and methods needed for the design of networked control systems for chemical processes and demonstrate their application and effectiveness in the context of process systems of industrial importance.<br\/><br\/>The proposed approach to achieving this objective involves the development of a novel mathematical framework based on nonlinear asynchronous systems to model the sensor and actuator network behavior accounting explicitly for the effect of asynchronous and delayed measurements, network communication and actuation. Within the proposed asynchronous systems framework, novel control methods will be developed for the design of nonlinear networked control systems that improve closed-loop stability, performance and robustness. The controller design methods will be based on nonlinear and predictive control theory and will have provable closed-loop properties.<br\/><br\/>The development and implementation of networked control methods which take advantage of sensor and actuator networks is expected to significantly improve the operation and performance of chemical processes, increase process safety and reliability, and minimize the negative economic impact of process failures, thereby impacting directly the US economy. The integration of the research results into advanced-level classes in process control and the writing of a new book on ``Networked Process Control'' will benefit students and researchers in the field. The development of software, short courses and workshops and the on-going interaction of the PIs with an industrial consortium will be the means for transferring the results of this research into the industrial sector. Furthermore, the involvement of a diverse group of undergraduate and graduate students in the research will be pursued.","title":"CPS: Small: Design of Networked Control Systems for Chemical Processes","awardID":"0930746","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["551341","538807"],"PO":["564728"]},"154013":{"abstract":"The use of virtual machines for Escience has been advocated both within the enterprise to replace aging machines and as the underlying technology of cloud computing whereby scientific researchers can ?rent? servers on demand. However, both scenarios can lead to inadequate performance. Within the enterprise, with incorrect planning or under unexpected heavy or even moderate load, there might not be enough physical capacity for every virtual machine to achieve reasonable performance. In cloud-computing-based scenarios, the ?renters? are largely subject to the informal service promises of the cloud provider based on a granularity that can be too coarse or at the wrong level of abstraction. This project pursues a novel unified framework to ensure predictable Escience based on these two dominant emerging uses of virtualized resources. The foundation of the approach is to wrap an Escience application in a performance container framework and dynamically regulate the application?s performance through the application of formal feedback control theory. The application?s progress is monitored and ensured such that the job meets its performance goals (e.g., deadline) without requiring exclusive access to physical resources even in the presence of a wide class of unexpected disturbances. This project extends this foundation and early results in three important dimensions: creating support for non-specialists to use the framework; implementing these techniques in Eucalyptus, one of the major open-source cloud computing frameworks; and applying the techniques to ?Software-as-a-Service? (SaaS), in which applications in the cloud are regulated to provide predictable performance.","title":"CSR: Small: Feedback-Controlled Management of Virtualized Resources for Predictable Escience","awardID":"0916905","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["466826"],"PO":["565255"]},"144102":{"abstract":"The goal of this project is to design, implement, and research the use of two types of embedded scaffolds, interactive-based scaffolds and resource-based scaffolds, within a video game-based learning environment. A quasi-experimental, pre-post design will be used to examine the impact of these two types of scaffolds, as well a no scaffold treatment group, on middle school students' STEM learning, problem solving, and interest.<br\/><br\/>While a wide range of video games are now being developed for educational purposes, very little is known about how to effectively design and use embedded scaffolds to support learning within these environments. This research will contribute to the field's understanding of how to effectively design and use embedded scaffolds to support middle school students as they learn about STEM and other similarly complex topics. Providing well-designed video games that effectively support learning has the potential to increase the accessibility of high quality STEM materials that support both learning and interest in the content areas.","title":"Examining Embedded Scaffolds in a Video Game to Support STEM Learning and Efficacy for Middle School Students","awardID":"0835450","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}}],"PIcoPI":["466440"],"PO":["564456"]},"157775":{"abstract":"CPS: Small: Collaborative Research: Foundations of Cyber-Physical Networks<br\/><br\/>The objective of this research is to investigate the foundations,<br\/>methodologies, algorithms and implementations of cyberphysical<br\/>networks in the context of medical applications. The approach is to<br\/>design, implement and study Carenet, a medical care network, by<br\/>investigating three critical issues in the design and construction<br\/>of cyberphysical networks: (1) rare event detection and<br\/>multidimensional analysis in cyberphysical data streams, (2)<br\/>reliable and trusted data analysis with cyberphysical networks,<br\/>including veracity analysis for object consolidation and redundancy<br\/>elimination, entity resolution and information integration, and<br\/>feedback interaction between cyber- and physical- networks, and (3)<br\/>spatiotemporal data analysis including spatiotemporal cluster<br\/>analysis, sequential pattern mining, and evolution of cyberphysical<br\/>networks.<br\/><br\/>Intellectual merit: This project focuses on several most pressing<br\/>issues in large-scale cyberphysical networks, and develops<br\/>foundations, principles, methods, and technologies of cyberphysical<br\/>networks. It will deepen our understanding of the foundations,<br\/>develop effective and scalable methods for mining such networks,<br\/>enrich our understanding of cyberphysical systems, and benefit many<br\/>mission-critical applications. The study will enrich the principles<br\/>and technologies of both cyberphysical systems and information<br\/>network mining.<br\/><br\/>Broader impacts: The project will integrate multiple disciplines,<br\/>including networked cyberphysical systems, data mining, and<br\/>information network technology, and advance these frontiers. It will<br\/>turn raw data into useful knowledge and facilitate strategically<br\/>important applications, including the analysis of patient networks,<br\/>combat networks, and traffic networks. Moreover, the project<br\/>systematically generates new knowledge and contains a comprehensive<br\/>education and training plan to promote diversity, publicity, and<br\/>outreach.","title":"CPS: Small: Collaborative Research: Foundations of Cyber-Physical Networks","awardID":"0931975","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["563535"],"PO":["564778"]},"154024":{"abstract":"A surprisingly large number of Americans read below their grade level, either because of limited education or because their native language is not English. Low reading levels impact a child?s progress in school and an adult?s job opportunities as well as limiting information access. <br\/>This project aims to improve access by developing new language processing technology for selecting and transforming text to obtain material at lower reading levels, extending current paraphrasing work that focuses on summarization as compression to include explanatory expansions. In addition, the goal is to develop adaptive models that can be tuned to a specific domain and an individual's needs. The approach involves analyzing corpora of comparable text collected from the web, developing models of paraphrasing aimed at generating simplified English, developing a discourse-sensitive clause selection method for expanding or omitting details, and exploring representations of language that facilitate domain and user adaptation. The language processing contributions of this work include development of text resources to support language technology in education applications, new representations of reading difficulty, and advances in automatic methods of paraphrasing. The broader impact of this project includes making information more accessible to people with limited English reading proficiency. In addition, students working on the project will have the opportunity to interact with teachers from a local school so as to better understand the impact of their work and guide their approach, and their work will be showcased in University of Washington diversity-oriented outreach programs.","title":"RI: Small: Simplifying Text for Individual Reading Needs","awardID":"0916951","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["562965"],"PO":["565215"]},"154145":{"abstract":"Thus far kernel methods have been mainly applied in cases where observations or instances are vectors. We are lifting kernel methods to the matrix domain, where the instances are outer products of two vectors. Matrix parameters can model all interactions between components and therefore take second order information into account. We discovered that in the matrix setting a much larger class of algorithms based on any spectrally invariant regularization can be kernelized. Therefore we believe that the impact of the kernelization method will be even greater in the matrix setting. In particular we will show how to kernelize the matrix versions of the multiplicative updates. This family is motivated by using the quantum relative entropy as a regularization. Most importantly we will use methods from on-line learning to prove generalization bounds for multiplicative updates that grow logarithmic in the feature dimension. This is important because it lets us use high dimensional feature spaces. <br\/><br\/>We will apply our methods to collaborative filtering. In this case an instance is defined by two vectors, one describing a user and another describing an object. The outer products of such pairs of vectors become the input instances to the machine learning algorithms. The multiplicative updates are ideally suited to learn well when there is a low-rank matrix that can accurately explain the preference labels of the instances. The kernel method greatly enhances the applicability of the method because now we can expand the user and object vectors to high-dimensional feature vectors and still obtain efficient algorithms.","title":"RI: Small: Kernelization with Outer Product Instances","awardID":"0917397","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["527386"],"PO":["562760"]},"157544":{"abstract":"CPS: Small: Collaborative Research: Distributed Coordination of Agents For Air Traffic Flow Management<br\/><br\/>This objective of this proposal is to improve the management of the air traffic system, a cyber-physical system where the need for a tight connection between the computational algorithms and the physical system is critical to safe, reliable and efficient performance. <br\/>The approach is based on an adaptive multiagent coordination algorithm with a particular emphasis on the systematic selection of the agents, their actions and the agents' reward functions. <br\/><br\/>The intellectual merit lies in addressing the agent coordination problem in a physical setting by shifting the focus from ``how to learn\" to ``what to learn.\" <br\/>This paradigm shift allows a separation between the learning algorithms used by agents, and the reward functions used to tie those learning systems into system performance. By exploring agent reward functions that implicitly model agent interactions based on feedback from the real world, this work aims to build cyber-physical systems where an agent that learns to optimize its own reward leads to the optimization of the system objective function. <br\/><br\/>The broader impact is in providing new air traffic flow management algorithms that will significantly reduce air traffic congestion. The potential impact cannot only be measured in currency ($41B loss in 2007) but in terms of improved experience by all travelers, providing a significant benefit to society. In addition, the PIs will use this project to train graduate and undergraduate students (i) by developing new courses in multiagent learning for transportation systems; and (ii) by providing summer internship opportunities at NASA Ames Research Center.","title":"CPS:Small: Collaborative Research: Distributed Coordination of Agents for Air Traffic Flow Management","awardID":"0930168","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[420384],"PO":["565274"]},"169644":{"abstract":"The goal of this project is to advance the state of the art in the design and analysis of efficient distribution approximation algorithms for various important network optimization problems. The emerging area of distributed approximation algorithms lies at the intersection of two well-established theoretical computer science areas: distributed computing and approximation algorithms. Distributed approximation algorithms tradeoff optimality of the solution for the amount of resources consumed by the distributed algorithm. Besides a fundamental theoretical interest in understanding the algorithmic complexity of distributed approximation, there is also a practical motivation in studying distributed approximation algorithms. Emerging networking technologies such as ad hoc wireless sensor networks and peer-to-peer networks operate under inherent resource constraints such as energy, bandwidth etc. A distributed algorithm which exchanges a large number of messages and takes a lot of time can consume a relatively large amount of resources, and is not suitable in a resource-constrained network. Also, the topology of these networks can change dynamically. Communication cost and running time is especially crucial in a dynamic setting. Hence it becomes necessary to design efficient distributed algorithms for various network optimization problems that have low communication and time complexity, even possibly at the cost of a reduced quality of solution.<br\/><br\/>The intellectual merit of this project lies in the development and analysis of new efficient distributed approximation algorithms for important network optimization problems including the minimum spanning tree and other spanning substructures, the minimum Steiner tree and related problems, the shortest paths problem etc. These are fundamental problems in distributed computing and are widely used primitives in distributed communication networks.<br\/><br\/>The first part of the project focuses on static networks, i.e., networks whose topology doesn't change with time. The project will design and analyze distributed approximation algorithms that give efficient performance, in terms of both time and message complexity, for a given approximation ratio. An important ingredient of the research is identifying appropriate graph parameters that capture the distributed complexity of the problem at hand. Such parameters serve as natural lower bounds and facilitate the design of optimal algorithms. An overarching goal is to develop uniform approaches to design efficient distributed approximation algorithms for a wide variety of problems.<br\/><br\/>The second part of the project focuses on design and analysis of distributed algorithms for dynamic networks, i.e., networks whose topology changes dynamically. The goal is to study efficient distributed dynamic algorithms to construct and maintain near-optimal solutions for important spanning substructure problems. The algorithms will exploit locality and will be designed to work well on dynamic network models.<br\/><br\/>The broader impact of this project is the potential to impact algorithm design in emerging communication networks, in particular, sensor networks and peer-to-peer networks. The project will yield efficient and scalable distributed algorithms with provable performance guarantees. The PI will collaborate with applied researchers to maximize the impact of the theoretical results to practical applications. The proposed research is a great opportunity for theory to continue to have a practical impact, and a valuable addition to the curricula in both algorithms and networks. The PI will develop a new course on distributed approximation algorithms that is closely related to the research. The course will also aid in disseminating mathematical tools and techniques needed for this research to a wider audience. The PI's research group, Network Algorithms and Analysis Laboratory, will train both graduate and undergraduate students to tackle a variety of algorithmic problems that arise in distributed networks, emphasizing use of randomization in designing efficient distributed algorithms, and probabilistic modeling and analysis of networks.","title":"Efficient Distributed Approximation Algorithms","awardID":"1023166","effectiveDate":"2009-09-24","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["531608",454047],"PO":["565251"]},"156587":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/><br\/>RoboBees: A convergence of body, brain, and colony<br\/><br\/>J. Ayers, G. Barrows, D. Brooks, S. Combes, L. Mahadevan, G. Morrisett, <br\/>R. Nagpal, S. Ramanathan, G.-Y. Wei, M. Welsh, R.J. Wood, T. Zickler<br\/><br\/>This project entails the creation of a coordinated colony of robotic bees, RoboBees. Research topics are split between the ?body?, ?brain?, and ?colony?. Topics within the ?body? include all aspects of the flight apparatus, propulsion, and power systems. The ?brain? involves research on the electronic nervous system equivalent of a bee?s brain including circuits for sensing and decision-making. Finally, research within the ?colony? entails communication and control algorithms that will enable performance well beyond the capabilities of an individual. Each of these research areas is drawn together by the challenges of recreating various functionalities of natural bees. One such example is pollination: Bees coordinate to interact with complex natural systems by using a diversity of sensors, a hierarchy of task delegation, unique communication, and an effective flapping-wing propulsion system. Pollination and other agricultural tasks will serve as challenge thrusts throughout the life of this project. Such tasks require expertise across a broad spectrum of scientific topics. The research team includes experts in biology, computer science, electrical and mechanical engineering, and materials science, assembled to address fundamental challenges in developing RoboBees.<br\/><br\/>Beyond pollination and assisted agriculture, coordinated robotic insects will have substantial impact upon rescue workers for search and rescue and hazardous environment exploration applications. High fidelity environmental monitoring, traffic monitoring, and mobile sensor networks are just a few examples of the future impact of coordinated RoboBees. Since each RoboBee component must be developed from scratch, technological fallout will be prevalent throughout research on the body, brain, and colony. This new technology and the exciting and tangible nature of robotic bees present a tremendous opportunity to catalyze young minds and encourage their participation in science and engineering. An integral part of this program is the development of a museum exhibit, in partnership with the Museum of Science, Boston, which will explore the life of a bee and the technologies required to create RoboBees. <br\/>\u00ac<br\/>For more information, please visit: http:\/\/robobees.seas.harvard.edu","title":"Collaborative Research: RoboBees: A Convergence of Body, Brain and Colony","awardID":"0926148","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6894","name":"ITR EXPEDITIONS"}}],"PIcoPI":["518022","518228","563386","558486"],"PO":["564318"]},"158897":{"abstract":"Abstract <br\/>Modern supercomputers are complex, hierarchical systems <br\/>consisting of huge numbers of cores, systems for disk storage, <br\/>and nodes for I\/O forwarding. These numbers continue to grow and <br\/>the need for tools to understand the behavior of the system <br\/>software becomes paramount: without these tools it is impossible <br\/>to effectively tune that software, and high degrees of efficiency <br\/>is unattainable by applications. This project addresses the <br\/>challenge of understanding the behavior of complex system <br\/>software on very large-scale compute platforms, like the current <br\/>petascale computers. In particular, this project is developing <br\/>software infrastructure to provide end-to-end analysis and <br\/>visualization of I\/O system software. Specifically, the <br\/>objectives are to develop, improve, and deploy (1) end-to-end, <br\/>scalable tracing integrated into the I\/O system (MPI-IO, I\/O <br\/>forwarding, and file system); (2) information visualization tools <br\/>for inspecting traces and extracting knowledge; (3) testing <br\/>components that drive this system to generate example patterns, <br\/>including a component to generate anomalies; and (4) tutorials <br\/>and tools for helping other system software developers <br\/>incorporate this analysis and visualization system into their <br\/>production software. The software and techniques developed in <br\/>this project will be directly applicable to and useful in other <br\/>system software libraries which perform complex interactions on <br\/>large systems. <br\/><br\/>For further information see the project web site at the URL: <br\/>http:\/\/vis.cs.ucdavis.edu\/NSF\/Jupiter","title":"Visual Characterization of I\/O System Behavior for High-End Computing","awardID":"0937928","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7476","name":"ETF"}}],"PIcoPI":["495745","460791"],"PO":["560586"]},"156598":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/><br\/>Summary: Formal Analysis of Complex Systems<br\/><br\/>A Collaborative Proposal Involving CMU, CUNY, NYU, Stony Brook, UMD, Cornell, JPL<br\/><br\/><br\/>This Expedition, under the directorship of Lead PI Edmund M. Clarke, will develop new computational tools to help scientists and engineers analyze and understand the behavior of the complex models they develop for application domains ranging from systems biology to embedded control. Building on the success of model checking and abstract interpretation (MCAI), two well-established methods for automatically verifying properties of digital circuit designs and embedded software, this research project will extend the MCAI paradigm to systems with complex continuous dynamics and probabilistic behaviors. Challenge problems providing technology drivers and testbeds for the research include: understanding the precursors and course of pancreatic cancer; predicting the onset of atrial fibrillation; and obtaining deep design-time insights into the behavior of automotive and aerospace control systems. Ultimately, this Expedition is expected to provide vital tools that will enable health-care researchers to discover better treatments for disease and will allow engineers to build safer aircraft and other complex systems.<br\/><br\/>The world-class team of scientists and engineers assembled for this Expedition includes two Turing Award winners, a recipient of the National Medal of Science, and awardees of other prestigious research prizes. Outreach consists of the development of a new, highly ambitious and highly cross-discipline educational program called Complex Systems Science Engineering, an annual Minority-Focused Intersession Workshop for Undergraduates on Understanding and Analyzing Complex Embedded and Biological Systems to be hosted at member institution Lehman College, CUNY; substantial financial support for undergraduate research; student involvement in the NASA JPL Research Affiliates Program; and other research opportunities for undergraduate and graduate students and postdoctoral trainees.<br\/><br\/>More information: http:\/\/www.mcai2.org\/","title":"Collaborative Research: Next-Generation Model Checking and Abstract Interpretation With a Focus on Embedded Control and Systems Biology","awardID":"0926190","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"6894","name":"ITR EXPEDITIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7723","name":"EXPERIMENTAL EXPEDITIONS"}}],"PIcoPI":["561887",417606,"451745",417608,417609],"PO":["565239"]},"154057":{"abstract":"This research addresses interactivity and scalability in automatically analyzing large collections of video and multiple video streams processed continuously. This work is developing mechanisms to enable real-time interactive video search for user defined concepts using intelligent, active processing clusters and methods for performing high-accuracy semantic video analysis from large amounts of weakly-labeled video over distributed computing resources. The methods leverage modern cluster file systems where data is stored on the local disks of the compute servers, and the location of data is made available to the runtime system to allow co-location of compution and storage.<br\/><br\/>The specific research objectives are to allow co-location of compute and storage through a runtime for parallel stream processing that parallelizes data processing and machine learning tasks across a cluster of multi-core compute nodes. The project also extends distributed versions of graphic model algorithms to speed computation of both the basic low-level signal processing steps and for the semantic analysis based on weakly labeled video data as currently available on the web. The main outcome is to demonstrate vastly accelerated, complete processing of parallel live video streams into a retrieval database with immediate search capabilities and accessing cluster resources during interactive search. The goal of this work is to develop principles for interactive applications driven by real-time processing of high-rate streaming data. The processing architecture and modules developed in this work will enable computer vision and multimedia developers to efficiently apply and test their own methods within this framework.","title":"DC: Small: Semantic Analysis of Large Multimedia Data Sets","awardID":"0917072","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["533348"],"PO":["560586"]},"148986":{"abstract":"This project supports the storage system enhancement to an existing high performance cluster (HPC) already located at PI?s institution to address continuously increasing I\/O and data intensive computing need among the participating institutions and beyond. While sharing physical resources among multiple institutions is clearly cost-effective, protection of data and privacy is an ongoing concern that inhibits large-scale cooperative resource sharing. The multi-terabyte data storage system deployment at a remote institution with multi-gigabit connections achieves fast migration of research data for seamless computing while achieving maximum protection of the data at the remote site. The system allows research collaborators to stream real-time data to the HPC; thereby supporting remote HPC facilities for their computational needs. When successful, time-sensitive applications such as disaster response \/ emergency preparedness systems can be executed in an ad-hoc manner. The networked HPC infrastructure provides optimal access to areas of the state that remain less supported; thereby supporting the needs of the broader science and engineering communities. <br\/><br\/>The acquired system will enable collaborative research including the following:<br\/><br\/>- Data-Mining, Prediction and Data Analysis Frameworks Using Social Network<br\/>Analysis;<br\/><br\/>- Hybrid Monte-Carlo\/Data-Mining Modeling of the Structure-Property Relations of<br\/>Polymeric Materials;<br\/><br\/>- Biomedical Image Processing (Treatment Planning\/Tumor Detection\/Genome wide high throughput SNP analysis of Human Spit);<br\/><br\/>- Detection and Analyses of Electrophysiological Signals from Neurons Interacting<br\/>with Ligands, Neurotransmitters and Nano Materials;<br\/><br\/>- Analysis of Soil conditions and Ground Motions for Earth Quake Related Applications","title":"CRI: II-EN: Stream Computing for Research and Education in Science and Engineering","awardID":"0855248","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[397112,397113,"411431","564180","435908"],"PO":["565272"]},"148997":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project establishes a dedicated computing platform for microsecond simulations to study DNA self-assembly and translocation through solid-state nanopores. The project uses a predictive hierarchical petascale simulation framework to study: Translocation kinetics and dynamics of DNAs through solid state nanopores; electronic properties of translocating DNAs for sequencing nucleotides; ionic screening of surface charges in nanopores; pressure-driven DNA transport in confined silica channels; and shear-induced DNA self-assembly.<br\/><br\/>The computing platform will also support computer science research in techniques for the parallelization of such simulations, and for the integration of multi-scale, multi-phenomena simulation codes for molecular biology and biological materials science.<br\/><br\/>Petascale simulations of DNA translocation through solid-state nanopores and nanofluidic channels underlie \"lab-on-a-chip\" technology and solid-state nanopore \"microscopy\" for molecular structure and high-speed sequencing.<br\/><br\/>The infrastructure will help in training a new generation of graduate students. Students participate in a dual-degree program in which they do a PhD in physical sciences or engineering and a master's degree in computer science. The infrastructure also strengthens the annual computational science workshops for underrepresented groups, in which undergraduate students and faculty mentors from Historically Black Colleges and Universities and Minority Serving Institutions acquire hands-on experience in parallel computing. <br\/><br\/>Further information on the project can be found at the project web page: http:\/\/cacs.usc.edu\/cri\/index.php","title":"II-NEW: A Dedicated Computing Platform for Large Spatiotemporal-scale Atomistic Simulations of DNA Translocation and Self-Assembly","awardID":"0855274","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["490009","490010","490011"],"PO":["560586"]},"154079":{"abstract":"A number of scientific endeavors generate data that can be modeled as graphs: high-throughput biological experiments on protein interactions, high throughput screening of chemical compounds, social networks, ecological networks and food-webs, database schemas and ontologies. Access and analysis of the resulting annotated and probabilistic graphs are crucial for advancing the state of scientific research, accurate modeling and analysis of existing systems, and engineering of new systems. This project aims to develop a set of scalable querying and mining tools for graph databases by integrating techniques from databases and data mining. The proposed research work is theoretical as well as empirical. New theoretical ideas and algorithms are being developed and these are being applied to the domains of Cheminformatics and Bioinformatics.<br\/><br\/>The first research thrust examines primitives for graph data management and graph mining. A declarative query language for graphs is being investigated. This language is based on a formal language for graphs and a graph algebra, and separates the concerns of specification and implementation. Scalability of techniques for similarity search on graphs and mining for significant patterns is being investigated as a part of this thrust.<br\/><br\/>The second research thrust applies the developed techniques to the domain of Cheminformatics. Specific tasks that are being examined are search for similar compounds, mining for significant motifs, diversity analysis, and analysis of macromolecular complexes.<br\/><br\/>The final research thrust applies the developed methods to the domain of Bioinformatics. There has been an explosion of data of widely diverse biological data types, arising from genome-wide characterization of transcriptional profiles, protein-protein interactions, genomic structure, genetic phenotype, gene interactions, gene expression, proteomics, and other techniques. Techniques being developed can integrate and analyze data from multiple sources and models efficiently, while accelerating (interaction and function) prediction, and pathway discovery.<br\/><br\/>Further information about the project can be found at the project web page http:\/\/www.cs.ucsb.edu\/~dbl\/0917149.php.","title":"III: Small: Techniques for Integrated Analysis of Graphs with Applications to Cheminformatics and Bioinformatics","awardID":"0917149","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["536697"],"PO":["565136"]},"159535":{"abstract":"It has long been recognized that while the World Wide Web (WWW) has a wealth of information, there is a severe lack of tools to access and analyze its contents. The tool proposed here, if the effort is fully successful has the potential to radically extend use of WWW contentsThis project will construct a new set of tools that will make World Wide Web archives and present web data available to a wide group of researchers whose efforts depend upon examination of large amounts of data captured in different forms over extensive periods of time. This would include such researchers from the social sciences, health information management research, political science, an environmental sciences, to name a few. The project will comprise two components: a user interface to analysis tools that operate and an architecture for supporting the tools. The analysis tools will provide fundamental data management operations such as formula creation, and data summarization.","title":"EAGER: InfoCalc, a Spreadsheet Interface to Web Archive Analysis","awardID":"0941727","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["447448"],"PO":["543481"]},"159304":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940533","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["542299"],"PO":["560704"]},"159689":{"abstract":"The objective of this project is to understand the role of awareness in the initiation and sustenance of research-oriented virtual organizations. Research-oriented virtual organizations enable: 1) interaction between researchers with diverse perspectives who might not otherwise work together; 2) the sharing of expensive and scarce resources; and 3) novel ways of accomplishing tasks and solving problems. Despite these advantages, one frequent problem encountered by members of research-oriented virtual organizations is persistent difficulty in communicating and coordinating with remote colleagues. One key reason for this is that many research-oriented virtual organizations lack the capacity to support effective awareness and interaction among their members as projects progress.<br\/><br\/>This work builds on theories of social networks and transactive memory as well as theories of interpersonal awareness in focusing on what we call ?awareness networks? ? that is, networks of individuals who, at some level of detail, keep track of each other. The work focuses on 3 key issues: 1) developing a novel two-staged approach to awareness that bridges the current theoretical and practical gap between the initiation of research-oriented virtual organizations and sustained effective work; 2) developing an understanding of the roles of network ties in interpersonal awareness that allow us to apply a network- and relationship-based understanding of individuals to the larger problem of designing tools to provide interpersonal awareness and expertise information in research-oriented virtual organizations and communities; 3) extending transactive memory theory to include multiple dimensions of awareness beyond simple knowledge of expertise distribution. <br\/><br\/>This work will result in new theories and technologies that inform and enhance our ability to support virtual organizations that address key challenges confronting society. Prospective and current ROVO members will be better able to locate each other, coordinate and collaborate toward successful joint outcomes.","title":"VOSS: The Roles of Awareness and Social Networks in the Initiation and Sustenance of Research-Oriented Virtual Organizations","awardID":"0942659","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":["517608","427142",427142,427143,"560930"],"PO":["565342"]},"150790":{"abstract":"The investigators will develop an approximate computational geometry that is algorithm independent, accurate, and fast. Geometric predicate evaluation and element construction will be performed approximately using floating point arithmetic. Degeneracy will be handled transparently. The evaluation and construction techniques will be encapsulated in a software library that will be free for nonprofit use.<br\/><br\/>The research challenge is robustness: the output of an approximate algorithm must be correct for a small perturbation of the given input. This definition extends the numerical analysis definition of a stable algorithm to cover combinatorial error. Robustness is a fundamental computer science problem that is a major challenge in computational geometry. The predominant strategy in computational geometry, exact computation using algebraic geometry, has high computational complexity and contradicts the standard scientific and engineering strategy of approximate computation with error bounds. The investigators will adapt approximate computation to the special needs of computational geometry, which is primarily combinatorial. This task involves core research at the interface between computational geometry and numerical computing.<br\/><br\/>Robust approximate computation will transform how computational geometry is taught, how algorithms are developed and implemented, and how the field interacts with the wider scientific and engineering community. Introductory courses will present a rigorous, practical robustness theory, instead of treating robustness in an ad hoc, incomplete way. Programmers will implement real RAM algorithms as stated, using our library to ensure robustness and to handle degeneracy, instead of addressing these problems anew for every algorithm, which is often a major research challenge. Computational geometry will be available to other disciplines in the form of high-quality software libraries, akin to modern applied mathematics libraries.","title":"AF: Medium: Collaborative Research: Approximate Computational Geometry via Controlled Linear Perturbation","awardID":"0904707","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[401957],"PO":["565157"]},"150691":{"abstract":"This is a collaborative research project combining the expertise of Ashish Goel, Stanford University (IIS-0904325) and Sanjeev Khanna, University of Pennsylvania (IIS-0904314). <br\/><br\/>Traditionally, content has been generated by a limited number of publishers (such as book houses, music companies, and newspapers), and its quality then evaluated by professional editors and reviewers. In recent years, however, individuals have become mass producers of content, generating images, blogs, opinions, and recommendations, in a decentralized manner. This content is then discovered and consumed by other users, and centralized review is rendered infeasible by the sheer magnitude of available content. Consequently, there is a need to utilize user feedback, both explicit and implicit, in order to provide optimum rankings and recommendations to Internet users. The same broad problem occurs in online advertising, automatic moderation of discussion boards, and automated deductions of user preference on social networks. In addition to being very large, user activity data on the Internet is also typically very sparse, since each user only performs a small share of possible actions (e.g., searches for a small fraction of keywords, reviews or purchases a small fraction of products). <br\/><br\/>This project aims to design algorithms and optimization techniques to effectively utilize such data. The sparse data is treated as a \"prior belief\" on user preferences. The project also aims to design economic incentives to obtain useful and corrective data, robust to manipulation. The two parts of this research interact strongly with each other, since the algorithmic component can identify valuable pieces of additional information to acquire. Together, these two parts can help users derive optimum value from Internet data. <br\/><br\/>Results of this project will improve search engine performance and facilitate web applications that employ user feedback. The project Web site (http:\/\/www.stanford.edu\/~ashishg\/sparse_opt.html) will be used to disseminate results.","title":"III: Medium: Collaborative Research: Optimization with Sparse Priors--Algorithms, Indices, and Economic Incentives","awardID":"0904314","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["497006"],"PO":["563751"]},"153860":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>In contrast to software verification, software synthesis \"writes\" programs rather than merely checks them for errors. While verification has recently reached the programmer, the success of synthesis remains in the hands of formally trained experts. To ease the adoption of synthesis, this proposal develops algorithmic synthesis, which is to deductive synthesis what model checking is to deductive verification: Rather than deducing a program with a theorem prover, algorithmic synthesis systematically finds the program in a space of candidate implementations.<br\/><br\/>A key remaining challenge is how to describe this candidate space. Each synthesizer must be \"programmed\" with insights about the domain and its implementation tricks. In deductive synthesis, the insight is conveyed by a domain theory. In algorithmic synthesis, programmers typically communicate their insight by writing a partial program that syntactically defines the candidate space. The partial program is then completed by the synthesizer. Since the program is specified partially, programmers can control the candidate space size, making algorithmic synthesis feasible while leaving tedious program details to the synthesizer.<br\/><br\/>This project investigates linguistic aspects of algorithmic synthesis, addressing three issues: (1) How to debug partial programs? Angelically non-deterministic oracles will be used for gradual development of partial programs. (2) What is domain insight and how to communicate it? Programming abstractions will be developed for defining the candidate space naturally. (3) How to refine the insight with the goal of aiding the synthesizer scalability? An interactive dialogue between the programmer and the synthesizer will help the programmer refine and formalize her insight.","title":"SHF: Small: Programming Abstractions for Algorithmic Software Synthesis","awardID":"0916351","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["556819"],"PO":["565264"]},"153981":{"abstract":"Future multi-core microprocessors will be capable of deconfiguring faulty units in order to permit continued operation in the presence of wear-out failures. However, the unforeseen downside is pipeline imbalance in which other portions of the pipeline are now overprovisioned with respect to the deconfigured functionality. Such an imbalance leads to sub-optimal chip-wide power provisioning, since power is now allocated to pipeline functions that no longer provide the benefit they did with a fully functioning chip.<br\/><br\/>This research proposes to dynamically redistribute the chip power under pipeline imbalances that arise from deconfiguring faulty units. Through rebalancing -- achieved by temporary, symbiotic deconfiguration of additional functionality within the degraded core -- power is harnessed for use elsewhere on the chip. This additional power is dynamically transferred to portions of the multi-core chip that can realize a performance boost from turning on previously dormant microarchitectural features. The technical deliverables of this project will be: (1) a novel resilient multi-core system architecture -- including dynamic power redistribution management algorithms -- that achieves much higher performance than one that is oblivious to pipeline imbalances; and (2) detailed simulations that quantify this performance advantage for various multi-core workloads.<br\/><br\/>The broader impacts of this project relate to integrated research and education, enhanced infrastructure for research, broad dissemination of results, and potential societal impact. Furthermore, the PI will recruit women and underrepresented minority students to work on the project.","title":"SHF: Small: Dynamic Power Redistribution in Failure-Prone CMPs","awardID":"0916821","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["550887"],"PO":["366560"]},"153992":{"abstract":"This project investigates the static and dynamic partitioning of optical networks into domains or clusters and addresses the problem of providing survivable end-to-end service provisioning for unicast and multicast traffic over such multi-domain networks. A large optical network, even if administered by a single operator, needs to maintain its state information in a distributed and multi-domain hierarchy for purposes of scalability and fault-tolerance. Moreover, dynamic reconfiguration is often necessary to respond and adapt to sudden unexpected events or changes in network conditions. Other significant challenges in such a heterogeneous multi-domain environment are to implement end-to-end routing and survivability mechanisms, which are complicated by the limited amount of state information shared across domains due to factors related to business, policy, security, and other issues. This project enables a self-organizing framework for survivable optical networks. The project is addressing new methods for defining and reconfiguring domains based on service and performance requirements, introduces several new mechanisms for providing survivability in multi-domain networks, and is introducing new algorithms and protocols for provisioning survivable end-to-end unicast and multicast services in a scalable and cost-efficient manner. The broader impact of this work is that it can lead to a more robust and dynamic optical control layer that will enable the deployment of a greater range of end-to-end optical services to support emerging applications. It envisions greater intelligence in the control plane of optical transport networks, potentially leading to a network that is more autonomous than networks in existing ASON and GMPLS frameworks.","title":"NeTS:Small:Design and Analysis of Survivable Multi-Domain Optical Networks","awardID":"0916861","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["542048"],"PO":["564993"]},"151330":{"abstract":"This award provides support for a workshop on Mathematical Biology and Numerical Analysis. The objective of this workshop is to give interdisciplinary education, training and research in the mathematical and biological sciences. It will provide the participants with an overview of the necessary mathematical and biological background that are essential for a good number of applications in biological sciences.<br\/><br\/>The workshop is aimed at students and postdocs. It will be interdisciplinary in nature, bringing together students and postdocs from mathematical and biological sciences. The format of the workshop will consist of 12 invited speakers giving a total of 24 lectures in two tracks in two days. There will be ample time for the students to interact with the speakers on a one-on-one basis outside of the formal lectures. The speakers will be asked to present overview lectures at the level of a graduate course to ensure the audience takes away a working knowledge of the material. Then some speakers will lead the hands on use of varied mathematical biology tools in a computer laboratory. The topics to be presented are: a) numerical simulations of ecosystems; b) systems biology of complex traits; c) analysis of compositional heterogeneity among microbial genomes; d) functional connectivity and neuronal network dynamics; e) reconstructing metabolic pathways through network modeling of experimental data. Most of the topics presented at the workshop are not typically covered in standard curricula. Furthermore, the students, postdocs and professors will benefit greatly from interacting with groups from different disciplines and from the research that integrates mathematical and biological sciences.<br\/><br\/>The workshop is expected to have a substantial impact on the training of students and postdocs already in the mathematical and biological sciences, as well as for the recruitment of students from other disciplines into the mathematical and biological sciences. Both groups will benefit from the quality of the teaching in areas of major and active research by leaders in the field. We will be working actively to ensure the participation of minorities, women and students with disabilities at the proposed workshop.","title":"Workshop on Mathematical Biology and Numerical Analysis","awardID":"0906557","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["563571","473784",403326,403327,"457637"],"PO":["230845"]},"153761":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Modern automobiles and flight avionics systems form complex distributed real-time and embedded (DRE) systems. A high-end luxury car can have over 80 Electronic Control Units (ECUs), which are small embedded processors, and multiple networks linking the processors. Furthermore, several hundred software components can be distributed across these multiple networked ECUs. Optimizing the deployment of these software components, by packing the software more tightly onto the processors, can reduce the size of the required underlying infrastructure and have numerous positive side-effects, such as weight and power consumption savings.<br\/><br\/>Determining how to deploy software to hardware in DRE systems is a challenging problem due to the large number of complex constraints that must be dealt with, such as real-time scheduling constraints, component placement restrictions, and fault-tolerance guarantees. This research effort focuses on developing new hybrid heuristic and meta-heuristic techniques for determining how to deploy software to computational nodes. The algorithms and tools will be made available in open source through the Generic Eclipse Modeling System (http:\/\/www.eclipse.org\/gmt\/gems), which is distributed by 45 world-wide mirrors, and the ESCHER tool repository. Opportunities for outreach will be sought through existing mechanisms in place at Vanderbilt University, such as the NSF Science and Technology Center called TRUST and Vanderbilt Center for Science Outreach (CSO) to host summer research students. We will continue to support graduate students belonging to underrepresented groups.","title":"SHF: Small: Automating the Deployment of Distributed Real-time and Embedded System Software using Hybrid Heuristics-based Search Techniques","awardID":"0915976","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["536408","536823"],"PO":["565255"]},"153882":{"abstract":"One of the most important problems in 3D computer vision and graphics is the automatic scene reconstruction from 2D and 3D images. Recently, the reconstruction of complex urban scenes has attracted significant interest. This is because accurate 3D city models are paramount in the further development of a variety of fields such as urban planning, architecture, and archeology. They are also very important for applications commonly used in everyday life such as street map visualization and navigation, as well as in the film and construction industries. Automatic 3D image reconstruction and classification of urban scenes, though, is a problem whose complexity still challenges today?s research community. 3D reconstruction of city models is achieved through data acquisition using a variety of devices such as laser scanners and regular cameras. While laser scanners provide dense, detailed and accurate 3D points, they suffer from slow speed which dramatically increases the cost of acquisition.<br\/><br\/>This project, which is led by a multi-disciplinary team, combines expertise from computer vision, mathematical modeling and statistics to address this limitation. The goal of this work is to develop and implement real-time detection and classification techniques applied to streams of 3D point-cloud data. This allows focused acquisition of objects of interest (e.g. facades, etc.) and thus increases speed and reduces power consumption. It also aids high-level recognition processes in detecting and classifying objects in urban scenes. Reduction of the high-dimensional nature of the data is achieved by the clever innovative selection of a measurement model. A new formulation using hidden Markov models is used to capture the complexity of urban scenes. The real-time algorithms are tested on point-cloud data acquired in a real urban setting by the latest generation of laser range scanning technology.<br\/><br\/>On the education front, this project provides a stimulating research environment for both undergraduate and graduate students on the interdisciplinary frontier of mathematics and computer science. It also provides a framework for innovating the curriculum at both Brooklyn, a minority-serving institution, and Hunter Colleges through the development of interdisciplinary courses.","title":"MSC: Sequential Classification and Detection via Markov Models in Point Clouds of Urban Scenes","awardID":"0916452","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[409474,"519385"],"PO":["565157"]},"152551":{"abstract":"TC:Large: Collaborative Research: AUSTIN An Initiative to Assure Software Radios have Trusted Interactions <br\/><br\/>Software and cognitive radios will greatly improve the capabilities of wireless devices to adapt their protocols and improve communication. Unfortunately, the benefits that such technology will bring are coupled with the ability to easily reprogram the protocol stack. Thus it is possible to bypass protections that have generally been locked within firmware. If security mechanisms are not developed to prevent the abuse of software radios, adversaries may exploit these programmable radios at the expense of the greater good. <br\/>Regulating software radios requires a holistic approach, as addressing threats separately will be ineffective against adversaries that can acquire, and reprogram these devices. The AUSTIN project involves a multidisciplinary team from the Wireless Information Network Laboratory (WINLAB) at Rutgers University, the Wireless@Virginia Tech University group, and the University of Massachusetts. AUSTIN will identify the threats facing software radios, and will address these threats across the various interacting elements related to cognitive radio networks. Specifically, AUSTIN will examine: (1) the theoretical underpinnings related to distributed system regulation for software radios; (2) the development of an architecture that includes trusted components and a security management plane for enhanced regulation; (3) onboard defense mechanisms that involve hardware and software-based security; and (4) a algorithms that conduct policy regulation, anomaly detection\/punishment, and secure accounting of resources. <br\/>Developing solutions that ensure the trustworthy operation of software radios is critical to supporting the next generation of wireless technology. AUSTIN will provide a holistic system view that will result in a deeper understanding of security for highly-programmable wireless devices.","title":"TC: Large:Collaborative Research: AUSTIN-- An Initiative to Assure Software Radios have Trusted Interactions","awardID":"0910671","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["497218","449017"],"PO":["565136"]},"161142":{"abstract":"This NSF EAGER project is to develop novel prototypes for (1) iconic image analysis and recognition for retrieval, classification annotation, and analysis of iconic digital imagery of Cypriot cultural heritage materials, and (2) searching and exploring the Ancient Cypriot Secretariat Corpus. (The corpus contains works from antiquity to early Christian era written in period text and describing scientific, philosophical, social commentary, etc.) The project will involve computer scientists, archeologists and art historians from Penn State and The Cyprus Institute. The systems developed will allow users to search for the iconic images in representative of Cypriot culture at various times of history based on such characteristics as image content, shape sketches, and metadata. From the Secretariat Corpus, end-users will be able to search for items belonging to different categories such as daily life at different periods, mythology, religion, politics, language, landscape, events and other categories. Strong support for this project has been pledged by the Cyprus Institute. The NSF Office of International Science and Engineering will co-sponsor the award.","title":"EAGER: Analysis and Intelligent Search for Cypriot Works of Art and Secretariat Corpus","awardID":"0949891","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[431021,431022,"562561","503706","456076","456076","456076"],"PO":["565227"]},"162473":{"abstract":"IntelliDrive(SM) is a major U.S. Department of Transportation (U.S. DOT)<br\/>initiative of Intelligent Transportation Systems (ITS), aimed at building a<br\/>fully connected surface transportation environment via advanced communication<br\/>and information technologies. The grand vision is \"to provide transformational<br\/>safety, mobility, and environmental improvements in surface transportation\".<br\/><br\/>The IntelliDrive initiative envisions a networked environment among<br\/>vehicles (V2V), between vehicles and infrastructure components (V2I) <br\/>or among vehicles, infrastructure, and wireless hand-held Devices <br\/>(e.g., cell phones and PDAs) (V2D) that enables numerous safety <br\/>and mobility improvement applications. For example,<br\/>in a V2V environment, if the vehicle in front has a malfunctioning<br\/>brake light, the following drivers or travelers will be notified <br\/>in real-time and take precautionary actions (e.g., slow down or <br\/>change lanes); or if roadside sensors detect a patch of ice on the road<br\/>at milepost 305, drivers will be notified immediately through V2I or<br\/>V2D about the situation in terms what, where, and the degree of <br\/>severity, etc. <br\/><br\/>With respect to improving mobility,<br\/>IntelliDrive provides real-time traveler information concerning<br\/>traffic conditions, accidents, transit vehicle on-time performance, <br\/>parking availability, ride share opportunities, etc.<br\/>Thus travelers will be able to make informed decisions about their<br\/>travel so to improve the individual and consequently the overall <br\/>system efficiency and mobility.<br\/><br\/>The main objective of this proposal is to develop the framework of a<br\/>Database Management System (DBMS) in support of IntelliDrive applications. <br\/>This means, among others, a set of services that will answer the questions:<br\/>What data is relevant to answer the query? In what nodes does this <br\/>data reside? How to access the data on these nodes?<br\/><br\/>For further information please see the project web site:<br\/>www.cs.uic.edu\/~wolfson\/html\/IntelliDrive","title":"The IntelliDrive Database Management System","awardID":"0957394","effectiveDate":"2009-09-01","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["516989","557651"],"PO":["469867"]},"161384":{"abstract":"This award supports a doctoral symposium at the 3rd ACM Conference on Recommender Systems (RecSys 2009) to be held in New York, NY October 22-25, 2009. During the last decade the commercial importance of recommender systems has grown, spurring the creation and growth of this conference. RecSys is the leading international forum for the presentation and discussion of research and practice on recommender systems. The doctoral symposium will help students refine their dissertation projects so that they can make stronger contributions to the solution of critical intellectual challenges in recommender systems. The doctoral symposium will help develop a cohort of recommender systems researchers who will contribute to future academic and industrial research. By helping doctoral students to appreciate each other?s different perspectives and form a cohort across those boundaries, we can extend the rich interdisciplinarity of the field and foster commercial and intellectual innovation for the future.","title":"2009 ACM Recommender Systems Conference Doctoral Symposium","awardID":"0951619","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["539967"],"PO":["564456"]},"153772":{"abstract":"Point cloud data (PCD) is pervasive across numerous areas in science and engineering. This project addresses two issues, namely reconstruction in three dimension and inference from PCD in high dimensions. In reconstruction, the problem of approximating a three dimensional shape from its PCD is considered. This problem becomes hopeless from computational view point for shapes sitting in high dimensional spaces. Here, the project focuses on inferring topological and geometric properties of the hidden object from its sampled representation rather than reconstructing it completely.<br\/><br\/>A successful implementation of this project will enable many areas of science and engineering to enhance their scope in modeling, analyzing, prototyping, and visualizing input data with assurance of accuracy. Designing machine parts in automotive industry, creating virtual environments with buildings, simulating cracks and shocks in scientific studies are few examples where new algorithms are needed for reconstructing shapes in presence of non-smoothness. This will be addressed in the reconstruction section of the project. Various scientific and social studies such as the ones in medicine, economics, climate, disease control produce data that presumably sample a hidden parameter space (a manifold). They will benefit from the research on the topology and geometry inference section of the project.","title":"MCS: Reconstructing and Inferring Topology and Geometry from Point Cloud Data","awardID":"0915996","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0507","name":"Division of SCIENCE EDUCATION RESOURCES IM","abbr":"SER"},"pgm":{"id":"1267","name":"TOPOLOGY"}}],"PIcoPI":[409203,"549998"],"PO":["565157"]},"153893":{"abstract":"A computer program consists of many low-level instructions that are executed by a microprocessor. The key to executing a program faster is executing more instructions in parallel. Branch instructions hinder this process since a branch must be executed before subsequent instructions can be executed. A microprocessor attempts to circumvent this constraint by predicting the outcome of the branch, enabling instructions from the predicted target to be executed speculatively and without delay. Because it is so critical to performance, branch prediction has been studied and steadily improved for decades. Microprocessor performance is projected to be flat for the foreseeable future, after decades of exponential growth. A breakthrough in branch predictor design would be transformational. <br\/><br\/>This project provides insight into why conventional branch predictors are limited. A whole new direction in branch predictor design is revealed by this understanding. Two interrelated problems are exposed: 1) conventional predictors often fail to distinguish dynamic branches for which specialized predictions are required, especially memory-dependent branches, and 2) explicitly specializing predictions for these dynamic branches does not fix the problem alone, because stores to their dependent memory addresses change their future outcomes anyway. This project proposes two unprecedented principles for branch predictor design: first, explicitly identifying dynamic branches in order to provide them with specialized predictions and, second, actively updating their predictions when stores occur to their dependent memory addresses. Together, these two principles are called EXACT, stands for EXplicit dynamic-branch prediction with ACTive updates.<br\/><br\/>The goal of the proposed research is to apply these two principles to design predictors that achieve leaps in branch prediction accuracy, halving or more than halving the number of mispredictions with respect to the best known predictor. Results with idealized implementations demonstrate such leaps in accuracy are possible and a first realistic implementation already achieves a significant fraction of this potential. To achieve broader impact, project participants will collaborate closely with industry partners, Intel and IBM, to translate EXACT technology into future microprocessor designs.","title":"SHF:Small: EXACT: Explicit Dynamic-Branch Prediction with Active Updates","awardID":"0916481","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["518384"],"PO":["366560"]},"152562":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Obtaining physiological\/behavioral data from human subjects in their natural environments is essential to conducting ecologically valid social and behavioral research. While several body area wireless sensor network (BAWSN) systems exist today for physiological data collection, their use has been restricted to controlled settings (laboratories, driving\/flying scenarios, etc.); significant noise, motion artifacts, and existence of other uncontrollable confounding factors are the often cited reasons for not using physiological measurements from natural environments. In order to provide scientifically valid data from natural environments, a BAWSN system must meet several unique requirements (1) Stringent data quality without sensing redundancy, (2) Personalization to account for wide between person differences in physiological measurements, and (3) Real-time inferencing to allow for subject confirmation and timely intervention. <br\/><br\/>Intellectual Merit: In this project, a multidisciplinary team of researchers spanning various computing disciplines and behavioral sciences are developing a general purpose framework called FieldStream that will make it possible for BAWSN systems to provide long term unattended collection of objective, continuous, and reliable physiological\/behavioral data from natural environments that can be used for conducting population based scientific studies. FieldStream is being incorporated in two real-life projects ? NIH sponsored AutoSense at Memphis and NSF sponsored Urban Sensing at UCLA, to help validate the assumptions, establish the feasibility of developed solutions, and to uncover new requirements. <br\/><br\/>Broader Impact: By making it possible to obtain scientifically valid objective data from the field, FieldStream promises to help solve several behavioral problems of critical importance to human society that have remained unanswered for lack of such data.","title":"NetSE: Large: Collaborative Research: FieldStream: Network Data Services for Exposure Biology Studies in Natural Environments","awardID":"0910706","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["539242","515835"],"PO":["565090"]},"151000":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Though perhaps unfortunate, as a practical matter software is often<br\/>built with functionality as a primary goal, and security features are<br\/>only added later, often after vulnerabilities have been identified.<br\/>To reduce the cost and increase assurance in the process of security<br\/>retrofitting, the aim to develop a methodology involving automated and<br\/>semi-automated tools and techniques to add authorization policy<br\/>enforcement functionality to legacy software systems.<br\/><br\/>The main insight is that major portions of the tasks involved in<br\/>retrofitting code can be or already have been automated, so the design<br\/>process focuses on enabling further automation and aggregating these<br\/>tasks into a single, coherent approach.<br\/><br\/>More specifically, techniques and tools are being developed to: (1)<br\/>identify and label security-relevant objects and I\/O channels by<br\/>analyzing and instrumenting annotated application source code; (2)<br\/>insert code to mediate access to labeled entities; (3) abstract the<br\/>inserted checks into policy-relevant, security-sensitive operations<br\/>that are authorized (or denied) by the application's security policy;<br\/>(4) integrate the retrofitted legacy code with the site's specific<br\/>policy at deployment time to ensure, through advanced policy analysis,<br\/>that the application enforces that site's policy correctly, and (5)<br\/>verify correct enforcement of OS policy delegation by the retrofitted<br\/>application.<br\/><br\/>The techniques and tools being developed are useful not only<br\/>for retrofitting, but also for augmenting and verifying existing code<br\/>already outfitted with security functionality; hence improving the<br\/>state-of-the-art in creating more secure software.","title":"TC:Medium:Collaborative Research:Techniques to Retrofit Legacy Code with Security","awardID":"0905419","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550282"],"PO":["565264"]},"162253":{"abstract":"NSF Workshop on Distributed Processing over Cognitive Networks<br\/><br\/><br\/><br\/>The emerging interest in cognitive networks, smart grids, and self-organizing networks is motivating heightened research on distributed and collaborative signal processing strategies that enable networks to adapt and respond to information in real-time. Cognitive networks consist of spatially distributed nodes that are linked together through a connection topology. The nodes are generally isotropic without any particular node taking a central control role. The nodes cooperate with each other and adapt their states in response to both local data collected at the nodes and data received from their immediate neighbors. Information arriving at any particular node creates a ripple effect that propagates throughout the network by means of a diffusive process. The diffusion of information results in a form of collective intelligence as evidenced by improved adaptation, learning, tracking, and convergence behavior relative to non-cooperative networks. <br\/><br\/><br\/><br\/>The purpose of the workshop is to bring together research experts from various modalities to brainstorm on the challenges and opportunities of cognitive networks. The workshop recognizes the high potential for cross-fertilization of ideas among different fields involving signal processing, estimation and algorithms, adaptation, system theory, biological and social sciences, computer science, and economic and public policy. The meeting will provide a forum for researchers to discuss the theory, algorithms, and challenges involved in the development of reliable cognitive networks. The workshop will help define a research agenda for the design of adaptive networks for distributed processing and estimation, and will produce a report that can serve as a guide to the research community. Research considered by the workshop will motivate and support development of enabling technologies for various areas including environmental monitoring, distributed event detection, distributed resource monitoring, distributed estimation and target tracking, cooperation among cognitive radios searching for spectral resources, distributed processing and control over smart grids, contributions to swarm theory, animal flocking behavior theory, etc.","title":"NSF Workshop on Distributed Processing over Cognitive Networks","awardID":"0956382","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}}],"PIcoPI":["448637"],"PO":["564898"]},"153552":{"abstract":"This project is developing automated methods of artificial intelligence (AI) for creating generalized plans that include loops and branches, can handle unknown quantities of objects, and work for large classes of problem instances. One of the key challenges is to reason about plans with loops and to do so without using automated theorem proving, which tends to be intractable. In particular, research is accomplishing the following goals: (1) develop new theoretical foundations for generalized planning; (2) develop effective abstraction mechanisms and new plan representations to support these new capabilities; (3) develop effective algorithms for plan synthesis as well as generalization of sample plans; (4) develop analysis tools to reason about the applicability, correctness and efficiency of generalized plans; (5) extend the framework to include sensing actions, conditional plans, and domain-specific knowledge in the form of partially specified plans; (6) create a new set of challenging benchmark problems and perform a rigorous evaluation of the approach; and (7) increase the interaction between the AI community and other communities, particularly model checking, that study the abstraction mechanisms and theoretical foundations necessary for generalized planning. This new framework may significantly improve the scope and applicability of automated planning systems.","title":"RI: Small: Foundations and Applications of Generalized Planning","awardID":"0915071","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["485266","485994"],"PO":["565035"]},"151011":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The goal of the project is to harness the information contained in users' interactions with information systems (e.g., query reformulations, clicks, dwell time) to train those systems to better serve their users' information needs. The key challenge lies in properly interpreting this implicit feedback and collecting it in a way that provides valid training data. Moving beyond existing passive data collection methods, the project draws on multi-armed bandit algorithms, experiment design, and machine learning to actively collect implicit feedback data. Developing these interactive experimentation methods goes hand-in-hand with developing machine learning algorithms that can use the resulting training data, and empirical evaluations that validate the models of user behavior assumed by the algorithms. <br\/><br\/>This research will improve retrieval quality for important applications like intranet search and desktop search. Additionally, the project will provide an operational full-text search engine for the Physics E-Print ArXiv and potentially other digital libraries, thus forming a test-bed for the research while also providing a valuable service and dissemination tool to the academic community beyond computer science. The project provides interesting and motivating research opportunities to undergrads and international exchange students, and the PIs will include relevant material into the undergraduate and graduate curriculum. Finally, following their prior work on the Support Vector Machine, SVM-light (http:\/\/svmlight.joachims.org\/) and an open-source search engine for learning ranked retrieval functions and evaluating the learned rankings, OSMOT (http:\/\/radlinski.org\/osmot\/), the PIs will continue to provide easy-to-use software that enables research and teaching, via the project website (http:\/\/www.cs.cornell.edu\/People\/tj\/implicit\/).","title":"III: Medium: Learning from Implicit Feedback Through Online Experimentation","awardID":"0905467","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["531625","406684"],"PO":["563751"]},"153684":{"abstract":"Abstract <br\/><br\/>The spread of malware has the potential to slow down or cripple wireless services. It poses a particularly inimical threat to a multitude of activities ranging across an entire spectrum from social interaction and gaming, to the flow of commerce and informational services, and, at the largest scale, to national security. Current countermeasures are mostly ad hoc and reactive in that they are used to fend off threats as they arrive or are preemptively discovered. <br\/><br\/>This project aims to develop theoretical foundations for malware control and counter-measure design in wireless networks by drawing from epidemiological analogues in containment or quarantining strategies for limiting the spread of infectious diseases in human society, and game-theoretic models for interactions among opponents. Optimal power control quarantining strategies that curtail and regulate the spread of contagion by exploiting the broadcast property of the wireless medium will be designed, validated analytically and experimentally, and incorporated in networking protocols. <br\/><br\/>This work will facilitate the development of new wireless paradigms where a plethora of devices need to securely communicate with each other and with other entities on the Internet. The research will not only draw from, but also contribute to, disparate disciplines such as epidemiology, game theory, optimal control and communication networks, and may eventually lead to new disciplines at the interfaces of these areas. Graduate and undergraduate students will be trained at the participating universities through supervision of doctoral and masters level dissertations and senior design projects.","title":"TC: Small: Collaborative Research: Mathematics of Infection Diffusion in Wireless Networks","awardID":"0915655","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["519699"],"PO":["497499"]},"151022":{"abstract":"Hybrid multiprocessor architectures present an unprecedented opportunity for high performance computing through the seamless integration of large number of processors and hardware accelerators. This project addresses the research challenges in the design and exploitation of hybrid multiprocessors through innovations that span across the areas of architectures, compilers, and high-performance computing. A hybrid cache coherent non-uniform memory access (CC-NUMA) architecture is designed that clusters CPUs, hardware accelerators, and memories to preserve locality and reduce memory latency. Partitioning models are developed to enable optimal partitioning of data among CPUs and hardware accelerators. Compiler techniques are developed for detection of parallelism, its partitioning, and assignment across CPUs and hardware accelerators. The project enables coexistence of data streaming (push data) and data fetching (pull data) mechanisms. The research benefits from detailed measurements using a 64-processor SGI Altix 4700 CC-NUMA machine with FPGAs, the Intel FSB-FPGA architecture accelerator, and Niveus 4000 workstation with NVIDIA GPUs.<br\/><br\/><br\/><br\/>The research has impact on large-scale scientific computing. The hybrid multiprocessor technology is likely to be transferred to industry while the developed software (compilers, simulators and Hybrid SPLASH-2 benchmarks) will be distributed to researchers. The project also has impact on education and research. The SGI Altix machine is already being used in our graduate classes and further projects on hybrid parallel computing are introduced in architecture, parallel processing, and compiler classes. The project contributes to minority undergraduate education in Computer Science since UCR is recognized for its large undergraduate Hispanic population.","title":"SHF: Medium: Hardware\/Software Partitioning for Hybrid Shared Memory Multiprocessors","awardID":"0905509","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["518640","516924","549718"],"PO":["562984"]},"152485":{"abstract":"The cost-effective construction of functionally correct software systems remains an unmet challenge for Computer Science. Although industrial best practices for software construction (such as testing, code reviews, automatic bug finding) have low cost, they cannot provide strong guarantees about correctness. Classical verification methods, on the other hand, are not cost-effective. Recently, the research community has been exploring the idea of dependent types, which extend the expressive power of programming languages to support verification. These rich types allow the programmer to express non-trivial invariant properties of her data and code as a part of her program. That way, verification is incremental, localized and at source-language level.<br\/><br\/>This multi-institution collaborative project is for the design and implementation of a programming language with dependent types, called Trellys. Technically, Trellys is call-by-value functional programming language with full-spectrum dependency. Overall, the project combines numerous fragmented research results into a coherent language design, by building a robust open-source implementation. The design draws on diverse solutions to the technical problems that arise from extending traditional programming languages accommodate dependent types: type and effect inference, language interoperability, compilation, and concurrency.","title":"SHF:Large:Collaborative Research:TRELLYS: Community-Based Design and Implementation of a","awardID":"0910500","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["551061"],"PO":["564388"]},"157820":{"abstract":"CPS: Small: Collaborative Research: Localization and System Services for SpatioTemporal Actions in Cyber-Physical Systems<br\/><br\/>The objective of this research is to develop models, methods and tools for capturing and processing of events and actions in cyber-physical systems (CPS) in a manner that does not violate the underlying physics or computational logic. The project approach uses a novel notion of cyber-physical objects (CPO) to capture the mobility and localization of computation in cyber-physical systems using recent advances in geolocation and the Internet infrastructure and supports novel methods for spatiotemporal resource discovery.<br\/><br\/>Project innovations include a model for computing spatiotemporal relationships among events of interests in the physical and logical parts of a CPS, and its use in a novel cyberspatial reference model. Using this model the project builds a framework for locating cyber-physical application services and an operating environment for these services. The project plan includes an experimental platform to demonstrate capabilities for building new OS services for CPS applications including collaborative control applications drawn from the intermodal transportation system. <br\/><br\/>The project will enable design and analysis of societal scale applications such as the transportation and electrical power grid that also include a governance structure. It will directly contribute to educating an engineering talent pool by offering curricular training that range from degree programs in embedded systems to seminars and technology transfer opportunities coordinated through the CalIT2 institute at UCSD and the Institute for Sensing Systems (ISS) at OSU. The team will collaborate with the non-profit Milwaukee Institute to explore policies and mechanisms for enterprise governance systems.","title":"CPS:Small:Collaborative Research:Localization and System Services for SpatioTemporal Actions in Cyber-Physical Systems","awardID":"0932360","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["457653"],"PO":["561889"]},"153464":{"abstract":"In this project the PI will address the challenge of empowering people with severe motor and speech impairments (SMSI) to socialize through written and spoken language, by increasing communication rate through a novel and intuitive computer interface. Available augmented communication technologies for the SMSI population typically yield speeds on the order of just one word per minute (based on clinical experience). The PI's objective is to develop an EEG-based brain interface technology based on an intuitive icon-based language generation framework, RSVP iconCHAT, which will achieve increased communication rates for the target population. This technology will exhibit three essential features: rapid serial visual presentation (RSVP) of icons that represent words; a large-vocabulary natural language model with the capability for accurate predictions of intended text in order to control the upcoming sequence of icons to be shown to the subject for confirmation in the RSVP paradigm; and an intent detection mechanism that fuses information from multichannel electroencephalography (EEG) and the generative probabilistic language model. Advanced statistical signal processing, machine learning, and natural language modeling techniques will be employed to achieve communication rates over an order of magnitude higher than the current state-of-the-art. The project will also contribute novel techniques and algorithms for synchronous brain interface design, particularly single-trial ERP detection. Both the brain interface and language model components will learn from previous interactions with the user and exhibit robust cooperative learning behavior in order to maximize language throughput. A Bayesian and information theoretic foundation will support adaptability. The PI notes that his approach is innovative along three dimensions: an intuitive icon-based language representation combined with context-dependent language models will be employed for message construction; a noninvasive brain computer interface that is user-adaptive will be developed and employed to interface with the icon-based platform; and methods for probabilistic information fusion between the brain activity measured by the BCI and the predictive language model will be developed.<br\/><br\/>Broader Impacts: There exists a significant SMSI population due to various reasons such as cerebral palsy (CP), neuromuscular disease (Amyotrophic Lateral Sclerosis, ALS), and severe spinal cord injury leading to locked-in syndrome (LIS). These communities rely on inefficient modes of communication that limit the user's ability to generate acceptable communication rates. Successful achievement of this project's goals will not only provide the target population with an improved face-to-face communication experience with their able-bodied communication partners, but will also enable control of their environment and access to information. In addition, the work will contribute to information fusion from different modalities, optimal data dimensionality reduction, single-trial ERP detection, and human computer communication through a novel interface. Data collected in experiments will be made available to other researchers in order to accelerate verification of outcomes and dissemination of results.","title":"HCC-Small: RSVP IconCHAT - A Brain Computer Interface for Icon-based Communication","awardID":"0914808","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["506513","485923"],"PO":["565227"]},"152496":{"abstract":"TC:Large: Collaborative Research: AUSTIN?An Initiative to Assure Software Radios have Trusted Interactions <br\/><br\/>Software and cognitive radios will greatly improve the capabilities of wireless devices to adapt their protocols and improve communication. Unfortunately, the benefits that such technology will bring are coupled with the ability to easily reprogram the protocol stack. Thus it is possible to bypass protections that have generally been locked within firmware. If security mechanisms are not developed to prevent the abuse of software radios, adversaries may exploit these programmable radios at the expense of the greater good. <br\/>Regulating software radios requires a holistic approach, as addressing threats separately will be ineffective against adversaries that can acquire, and reprogram these devices. The AUSTIN project involves a multidisciplinary team from the Wireless Information Network Laboratory (WINLAB) at Rutgers University, the Wireless@Virginia Tech University group, and the University of Massachusetts. AUSTIN will identify the threats facing software radios, and will address these threats across the various interacting elements related to cognitive radio networks. Specifically, AUSTIN will examine: (1) the theoretical underpinnings related to distributed system regulation for software radios; (2) the development of an architecture that includes trusted components and a security management plane for enhanced regulation; (3) onboard defense mechanisms that involve hardware and software-based security; and (4) a algorithms that conduct policy regulation, anomaly detection\/punishment, and secure accounting of resources. <br\/>Developing solutions that ensure the trustworthy operation of software radios is critical to supporting the next generation of wireless technology. AUSTIN will provide a holistic system view that will result in a deeper understanding of security for highly-programmable wireless devices.","title":"TC: Large: Collaborative Research: AUSTIN - An Initiative to Assure Software Radios have Trusted Interactions","awardID":"0910531","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560140","564848","519433","548204"],"PO":["497499"]},"157710":{"abstract":"CPS: Small: Image Guided Autonomous Optical Manipulation of Cell Groups<br\/><br\/>The objective of this research is to create computational foundation, methods, and tools for efficient and autonomous optical micromanipulation using microsphere ensembles as grippers. The envisioned system will utilize a holographic optical tweezer, which uses multiple focused optical traps to position microspheres in three-dimensional space. The proposed approach will focus on the following areas. First, it will provide an experimentally validated optical-tweezers based workstation for concurrent manipulation of multiple cells. Second, it will provide algorithms for on-line monitoring of workspace to support autonomous manipulation. Finally, it will provide real-time image-guided motion planning strategies for transporting microspheres ensembles. <br\/><br\/>The proposed work will lead to a new way of autonomously manipulating difficult-to-trap or sensitive objects using microspheres ensembles as reconfigurable grippers. The proposed work will also lead to fundamental advances in several cyber physical systems areas by providing new approaches to micromanipulations, fast and accurate algorithms with known uncertainty bounds for on-line monitoring of moving microscale objects, and real-time motion planning algorithms to transport particle ensembles. <br\/><br\/>The ability to quickly and accurately manipulate individual cells with minimal training will enable researchers to conduct basic research at the cellular scale. Control over cell-cell interactions will enable unprecedented insights into cell signaling pathways and open up new avenues for medical diagnosis and treatment. The proposed integration of research with education will train students with a strong background in emerging robotics technologies and the inner workings of cells. These students will be in a unique position to rapidly develop and deploy specialized robotics technologies.","title":"CPS: Small: Image Guided Autonomous Optical Manipulation of Cell Groups","awardID":"0931508","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7751","name":"CDI TYPE II"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["564069","511972",420896],"PO":["564728"]},"153354":{"abstract":"This is a collaborative research project conducted by Robert Kirby, University of Utah (IIS-0914564) and Dongbin Xiu, Purdue University (IIS-0914447). <br\/><br\/>In this age of scientific computing, the simulation science pipeline of mathematical modeling, simulation and evaluation is a commonly employed rendition of the scientific method. In addition to the traditional components of the pipeline, there has been a recent surge of interest in uncertainty quantification (UQ). Visualization is the window through which scientists examine their data for deriving new science, and hence visualization methods which depict underlying uncertainty information are crucial. This research addresses the questions of how does one accurately and efficiently post-process stochastic simulation fields and how does one effectively and succinctly convey the results. This is accomplished by developing strategies and techniques for augmenting current visualization techniques used for visualizing spatio-temporal fields with UQ information in a seamless way. <br\/><br\/>The broader impacts of this work are that (1) proper techniques for UQ will have large impact on many scientific disciplines from medical\/bioengineering to aeronautics, and (2) developed visualization techniques might be put to use when higher dimensional data is available for each point in space. The educational objectives are focused on training a new generation of scientists who are proficient not in both visualization techniques and in UQ. The project will produce a series of methods and algorithms for stochastic visualization. These pioneering results will be disseminated in archival publications as well as via the project website (http:\/\/www.cs.utah.edu\/~kirby\/StochasticVis.html). Workshops on stochastic methods and tutorial sessions in SIAM and IEEE conferences are also planned to raise the visibility and impact of the project.","title":"GV: Small: Collaborative Research: Analysis and Visualization of Stochastic Simulation Solutions","awardID":"0914447","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["456828"],"PO":["563751"]},"157721":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to study active sensing and adaptive fusion using vision and acoustic sensors for continuous, reliable fall detection and assessment of fall risk in dynamic and unstructured home environments. The approach is to incorporate active vision with infrared light sources and camera controls, an acoustic array that identifies the sound characteristics and location, and sensor fusion based on the Choquet integral and hierarchical fuzzy logic systems that supports uncertain heterogeneous sensor data at varying time scales, qualitative data, and risk factors. <br\/>The project will advance the state of the art in (1) active vision sensing for human activity recognition in dynamic and unpredictable environments, (2) acoustic sensing in unstructured environments, (3) adaptive sensor fusion and decision making using heterogeneous sensor data in dynamic and unpredictable environments, (4) automatic fall detection and fall risk assessment using non-wearable sensors, and (5) algorithms for cyber physical systems that address the interplay of anomaly detection (falls) and risk factors affecting the likelihood of an anomaly event. <br\/>The project will impact the health care and quality of life for older adults. New approaches will assist health care providers to identify potential health problems early, offering a model for eldercare technology that keeps seniors independent while reducing health care costs. The project will train the next generation of researchers to handle real, cyber-physical systems. Students will be mentored, and research outcomes will be integrated into the classroom. Novel outreach activities are planned to reach the elderly community and the general public","title":"CPS: Medium: Active Heterogeneous Sensing for Fall Detection and Fall Risk Assessment","awardID":"0931607","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["475599",420930,"537126","561794","485520"],"PO":["564900"]},"154102":{"abstract":"A significant number of attacks on Web browsers and Web applications<br\/>are successful through the use of malicious inputs.<br\/>For instance, attacks on web browser extensions target browsers by<br\/>exploiting vulnerable extensions (add-ons) by supplying malicious input. <br\/>Malicious inputs exercise unintended behaviors leading to attacks that<br\/>compromise confidentiality, integrity and<br\/>availability of web-based systems. This project systematically<br\/>examines the role that user inputs play in web browsers and <br\/>applications, and develops techniques to prevent these attacks by <br\/>confining their influence. The challenge is to develop sound and <br\/>precise automated analysis mechanisms for web based platforms <br\/>such as JavaScript. Research from the areas of static and dynamic analysis, <br\/>information flow tracking and learning program behaviors<br\/>will be used to develop robust, efficient and highly precise techniques.<br\/><br\/>Papers from the project will be distributed in popular online<br\/>resources for Web security for the widest possible dissemination and<br\/>further enhancement. Furthermore, the PIs will transition results from<br\/>this research to Web development and standards communities. <br\/>The results of this project will be integrated into the new and<br\/>existing courses in the undergraduate and graduate curricula at the<br\/>University of Illinois campuses at Chicago and Urbana Champaign. <br\/>These courses will train a growing workforce of software engineers<br\/>who will be more security-aware and apply these principles for<br\/>laying a platform for a more secure Web. This project will also directly<br\/>contribute to the research training of three Ph.D. students<br\/>supervised by the PIs. This project will also support the involvement<br\/>of the PIs in outreach activities aimed at K-12 teacher training and<br\/>minority groups, and contributions by designing programs that create<br\/>awareness and interest in computer science.","title":"TC: Small: Keeping Jack in the Box: Confining the Role of Untrusted Inputs in Web Scenarios","awardID":"0917229","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["497077","532213"],"PO":["497499"]},"153497":{"abstract":"Wireless sensor networks (WSNs) have been mainly used for data collection purposes, and have not been employed in the context of any consistency- or safety-critical applications. As such software development for WSNs has been done mostly on a best-effort basis. However, as WSNs get more integrated with actuation capabilities, the resulting wireless sensor actor networks (WSANs) require more assurance and survivability guarantees. The goal of this project is to design and implement the tool-support necessary for achieving assurance and reliability of WSANs software.<br\/><br\/><br\/>The project will produce a transformation tool that allows programs for WSANs to be written in high-level models traditionally used to describe abstract distributed programs and automatically transforms these abstract programs, while preserving their correctness and reliability properties, into programs deployed in WSANs. The project will also develop a synthesis tool that manipulates the given abstract distributed programs for the automated addition of desired level of fault-tolerance. Finally, the project will design a framework that guards against the corruption of the auxiliary state introduced at the concrete system to ensure that the deployed program is verifiably reliable.<br\/><br\/><br\/>This project will simplify the development of high assurance WSANs software, and has the potential to pave the way to high assurance cyber-physical systems development. The project will integrate research and education through coursework development, building and dissemination of systems software, and outreach to the wider community.","title":"CSR: Small: Collaborative Research: Tool Support for Producing High Assurance and Reliable Software for Wireless Sensor Actor Networks","awardID":"0914913","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553603"],"PO":["565255"]},"163056":{"abstract":"Digital Natives is a term used to describe individuals who were born after 1980 and who have lived their entire life in the presence of easy access to large scale data networks via the Internet, easy access to computing through personal computers, and wide spread communications via cellular phones. These Digital Natives are entering college and rapidly joining the US workforce. Understanding how they view their life goals and objectives will have a profound impact on the way we educate them and how they can be integrated effectively into society. This award provides travel support travel for US participants to a research workshop on Digital Natives. The workshop will take place at KAIST (Korean Advanced Institute for Science and Technology) in Daejeon, South Korea, 4-6 November 2009.<br\/><br\/>The workshop will characterize our current understanding of Digital Natives and their potential impacts on culture, commerce and society at local and global levels. Interactions in the workshop will serve to frame a research agenda that could serve as a basis for future proposals that study the phenomena around Digital Natives in depth. The workshop will foster opportunities to exchange and share knowledge among invited thought leaders and facilitate identification of leading researchable questions to help satisfy knowledge gaps that will be identified through the workshop. The workshop will expose participants to an internationally diverse set of perspectives on intellectual topics around Digital Natives. This diversity will broaden and strengthen the intellectual capabilities of US researchers who attend the workshop.","title":"Etiology and Impact of Digital Natives on Cultures, Commerce and Societies","awardID":"0960483","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[436197,436198],"PO":["564456"]},"154113":{"abstract":"Simulating and controlling communities of characters that can <br\/>interact with each other and their environment, and dynamically <br\/>react to changes, is a challenging problem with many important <br\/>applications ranging from homeland security (e.g., simulation <br\/>of disaster scenarios and responses), to civil crowd control <br\/>(e.g., planning exit strategies for sporting events), to <br\/>education and training (e.g., providing immersive museum exhibits <br\/>and training systems). While there are existing methods that <br\/>attempt to address the simulation aspect, there is a lack of <br\/>methods that support interaction of multiple types\/groups of <br\/>agents and little work has been done on the control or steering <br\/>aspect. <br\/><br\/>This work aims to address these challenges by integrating <br\/>roadmap-based planning with agent-based modeling. This hybrid <br\/>approach enables the development of methodology for modeling group <br\/>interactions which are also influenced by constraints imposed by <br\/>the environment (e.g., wide or narrow corridors) and techniques, <br\/>including interfaces that enable planning and experimentation, that <br\/>can scale to large numbers of agents. The results of this work will <br\/>be shared with the community via publications and open source <br\/>software. An anticipated outcome of this research is a tool for <br\/>simulation and control of large crowds at major events (e.g., <br\/>sporting events, political rallies, emergency evacuations of a <br\/>building, region, or city). This could allow emergency response <br\/>planners to investigate the crowd response when officials are placed <br\/>in particular positions, or architects to study how evacuation times <br\/>are affected by widening or narrowing corridors.","title":"RI: Small: Scalable Roadmap-Based Methods for Simulating and Controlling Behaviors of Interacting Groups: from Robot Swarms to Crowd Control","awardID":"0917266","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["561154","496841"],"PO":["564069"]},"153387":{"abstract":"This is a collaborative research project conducted by Robert Kirby, University of Utah (IIS-0914564) and Dongbin Xiu, Purdue University (IIS-0914447). <br\/><br\/>In this age of scientific computing, the simulation science pipeline of mathematical modeling, simulation and evaluation is a commonly employed rendition of the scientific method. In addition to the traditional components of the pipeline, there has been a recent surge of interest in uncertainty quantification (UQ). Visualization is the window through which scientists examine their data for deriving new science, and hence visualization methods which depict underlying uncertainty information are crucial. This research addresses the questions of how does one accurately and efficiently post-process stochastic simulation fields and how does one effectively and succinctly convey the results. This is accomplished by developing strategies and techniques for augmenting current visualization techniques used for visualizing spatio-temporal fields with UQ information in a seamless way. <br\/><br\/>The broader impacts of this work are that (1) proper techniques for UQ will have large impact on many scientific disciplines from medical\/bioengineering to aeronautics, and (2) developed visualization techniques might be put to use when higher dimensional data is available for each point in space. The educational objectives are focused on training a new generation of scientists who are proficient not in both visualization techniques and in UQ. The project will produce a series of methods and algorithms for stochastic visualization. These pioneering results will be disseminated in archival publications as well as via the project website (http:\/\/www.cs.utah.edu\/~kirby\/StochasticVis.html). Workshops on stochastic methods and tutorial sessions in SIAM and IEEE conferences are also planned to raise the visibility and impact of the project.","title":"GV: Small: Collaborative Research: Analysis and Visualization of Stochastic Simulation Solutions","awardID":"0914564","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["552996"],"PO":["563751"]},"155213":{"abstract":"This Pan-American Advanced Studies Institutes (PASI) on Modeling Computational Science and Engineering is jointly supported by the NSF and the Department of Energy (DOE). The PASI is organized by Dr. Jose Castillo from San Diego State University and it will take place in the Fall of 2009 at the Universidad de Carabobo, Venezuela. The key objective of the proposed PASI is to foster research by disseminating advanced computational science and engineering processes. Topics to be covered will include numerical optimization, exponential data fitting, parallel computing, scientific visualization, wavelets and partial differential equations (PDE?s), and engineering computing. The PASI will introduce students to the realm of current methods of research utilized in the US and other developed countries. It will also include hands-on computer laboratories and one-on-one guidance for beginning researchers. A web site will be created and administered by the Computational Science Research Center (CSRC) at San Diego State University to disseminate the information to be presented at this PASI.","title":"Pan American Advnaced Study Institute on Modeling in Computational Science and Engineering; Carabobo, Venezuela, Fall, 2009","awardID":"0921494","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0300","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7728","name":"PASI"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1260","name":"INFRASTRUCTURE PROGRAM"}}],"PIcoPI":["537485"],"PO":["531406"]},"154124":{"abstract":"This pedagogical qorkflow research project will create a novel hybrid-workflow framework that supports efficient assessment of student learning through interactive generation and execution of various assessment workflows. Unlike in many existing workflow systems, the task of student assessment includes steps that cannot be fully automated, such as obtaining grade, background and student survey information. The system will provide assistance in executing and integrating the results of the manual steps. Research steps will include (a) knowledge-based modeling of computational and non-computational assessment tools as workflow components; (b) interactive generation of assessment workflows while propagating and combining constraints from both computational and non-computational components; and (c) interactive execution of hybrid workflows that incorporates new constraints that are inferred from execution of non-computational components. Evaluations will focus on the effects of Pedagogical Workflow technology on learning assessment performance, especially the assessment of pedagogical discourse in undergraduate engineering courses.<br\/><br\/>Educational technology to support online learning is now centrally supported by many colleges and universities. The perceived mandate to use technology for instruction, in addition to the enormous amount of information available for consumption on the Web, places a considerable burden on instructors who must learn to integrate appropriate student practices and learning assessment via the new media. Pedagogical workflows will allow instructors with little or no training in educational assessment to perform large-scale complex diagnosis and assessment of student learning in ongoing lessons. Facilitating the integration of personal student information into assessment will point to directions to improve STEM participation, learning, and retention. The finding will provide benefits to society by sharing results and technology with instructors and educational experts. The proposed work also has the potential to lead to a new research field on e-Learning workflows, similar to the way in which workflow technology transformed e-Science research with e-Science workflows.","title":"HCC: Small: PedWorkflow: Workflows for Assessing Student Learning","awardID":"0917328","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["446978","563687","519748","507311"],"PO":["565342"]},"148932":{"abstract":"This project focuses on building a test bed that will enable scalable and automated security testing of applications.<br\/><br\/>Software secure design and security testing techniques are fundamental to the development of secure software. Many of the properties, strengths, and limitations of these techniques, however, can be fully understood only through rigorous, controlled experiments. This project addresses these challenges. The overall objective is to help engineers create dependable secure systems. To do this, this project engages in the following research and development activities: <br\/><br\/>-Development of test generation tools that consist of three components: a model-based security test sequence generator that generates tests automatically from a secure design considering two design-level models ? security and threat models; an executable test code generator that converts security tests derived from security and threat models to test code that can be executed together with the implementation under test; a test input generator that generates actual inputs to complete test cases using a syntax-based testing approach. <br\/><br\/>-Development of the testbed that includes various software artifacts and test automation tools to support controlled experiments with security testing.<br\/><br\/>Several tangible results from this work are expected. The success of this project may open a new avenue to automated testing for security, which can improve security assurance while significantly reducing the overall development costs of secure systems. In particular, this work may make it possible to develop many new strategies for generating security test code in terms of a rich variety of coverage criteria for secure design models. This will lay a foundation for evaluating scalability and cost-effectiveness (e.g., in terms of vulnerability detection capability and testing cost) of various security testing strategies. <br\/><br\/>This project has several broad impacts: the proposed work will support several graduate and undergraduate students as they work toward their degree goals and provide them with experience with developing tools and empirical studies. Also, this proposal is focused on making the resulting infrastructure available to researchers and educators, enabling them to use tools and perform controlled experiments as well as train students. <br\/><br\/>North Dakota is an EPSCOR state, thus, support for this project will help meet the goals of the EPSCoR program.","title":"II-NEW: Infrastructure for model-based security testing, controlled experiments, and education","awardID":"0855106","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["564245","502044"],"PO":["565327"]},"158733":{"abstract":"This is a collaborative research effort bringing together expertise of Lise Getoor, University of Maryland College Park (0937094), Alex Pang, University of California-Santa Cruz (0937073) and Lisa Singh, Georgetown University (0937070).<br\/><br\/>In today's linked world, graphs and networks abound. There are communication networks, social networks, financial transaction networks, gene regulatory networks, disease transmission networks, ecological food networks, sensor networks and more. Observational data describing these networks can often times be obtained; unfortunately, this graph data is usually noisy and uncertain. In this research, we propose a formalism which allows us to capture and reason about the inherent uncertainty and imprecision in an underlying graph. We begin by proposing probabilistic similarity logic (PSL), a simple, yet powerful, language for describing problems which require probabilistic reasoning about similarity in networked data. We also introduce the notion of visual comparative analysis of PSL models derived using different evidence and assumptions, and illustrate its utility for the analysis of graphs and networks. <br\/><br\/>Dealing with noise and uncertainty in complex domains, and conducting comparative analytics are core capabilities required for the Foundations on Data Analysis and Visual Analytics (FODAVA) mission. This research focuses on integrating representation, comparative analysis and visualizations methods into an open source toolkit that supports the representation, comparison and visualization of PSL models. In addition to producing the toolkit, the research team is working with researchers in a variety of interdisciplinary domains to validate the utility of our approach, and also developing tutorial and training materials for the tools. <br\/><br\/>The key broader impact of the work is that the methods for reasoning about sources of noise and uncertainty in graphs, and understanding their impact on results are general and fundamental to the intelligent analysis of today's rich information sources. Results, including open source software will be distributed via the project Web site ( http:\/\/www.cs.umd.edu\/projects\/linqs\/fodava\/ ).","title":"FODAVA: Collaborative Research: Foundations of Comparative Analytics for Uncertainty in Graphs","awardID":"0937094","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I114","name":"U.S. Department of Homeland Se"}}],"PIcoPI":["518332"],"PO":["563751"]},"154014":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Heterogeneous architectures with specialized coprocessors are gaining momentum due to compelling performance and energy-efficiency benefits. Heterogeneity introduces two main challenges: how to select the best coprocessor for a particular task, and how to map a task onto a particular accelerator. Programmers should be able to focus on algorithm and software design without worrying about hardware details or sacrificing portability, so rewriting code for every new coprocessor is untenable. While it is possible to schedule and map tasks at compile time, competing tasks and varying workload characteristics mean that effective scheduling must happen at runtime. <br\/><br\/>The solution proposed with this project is to virtualize the underlying system heterogeneity, which frees programmers from the burden of considering this heterogeneity in their implementation. At runtime, the system software layers schedule tasks to the most effective targets and map the programmer's virtualized task description to that target's architecture. The overarching goal of this project is to design an end-to-end solution to the challenge of heterogeneous code generation and optimization. This project develops the required capabilities. The intellectual merit of this research lies in the novel advances required in the compiler, runtime, and operating system. This work in turn provides broad impact by increasing programmer productivity and providing software tools that enable future research and software development. This work will also train graduate and undergraduate students in cutting-edge computer-systems concepts and design skills, and develop new educational and outreach materials. This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).","title":"CSR:Small:Multi-Layer Support for Virtualizing Heterogeneous Architectures","awardID":"0916908","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["438733","489873","489873"],"PO":["565255"]},"158986":{"abstract":"Traditionally, whenever there are significant computational requirements, computer science, computer engineering, or information science programs will adjust their teaching contents to fit the needs from those fields by introducing more background knowledge to the students in these computational programs. However, this solution will not be sustainable when the computational challenges are from all the fields at the same time. One alternative and more sustainable solution is to expand computational thinking centered training into all other fields. This is what this team is proposing. More specifically, this team will integrate computational thinking into health science education in an approach named ?Health Computing?. For students in health sciences and many fields other than computer science, computer engineering, or information science, core computer science courses are difficult. It is also difficult for them to understand the relevance of computer science courses and the core courses in their specific fields. However, the digitalization of all Americans? health records and the progress made in biomedical technologies require health science students to have more advanced training in computing technologies, methods, and tools in order to be globally competitive in their future career. In this proposed project, the team will develop a series of computer and information science courses which are highly relevant to health sciences and arrange a number of activities (such as high school outreach, summer internship, faculty development, multidisciplinary collaboration) to expose the computational thinking centered course materials and teaching strategies to a wider audience.<br\/><br\/>The project plans to provide teaching opportunities to the graduate and undergraduate students as well. In addition, this project will provide summer internship opportunities to the participating students through the business partners of School of Health and Rehabilitation Sciences at University of Pittsburgh. This will allow the students to apply their knowledge and skills beyond the classroom. The high school outreach program proposed in this project will be combined with the one offered by the School of Engineering at University of Pittsburgh, which has a long successful history of recruiting underrepresented students in STEM programs. This project will introduce the proposed teaching strategy and course materials to other health science schools and institutes since they will be applicable and transferable in many other fields.","title":"CPATH-1: Health Computing: Integrating Computational Thinking into Health Science Education","awardID":"0938393","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[424918,"456313",424920,424921,424922],"PO":["565136"]},"158876":{"abstract":"High-End Computing (HEC) systems are designed for performance, not energy efficiency. In recent years, HEC users have found that as energy costs increase, network and disks have become significant bottlenecks; worse, scientific workloads vary wildly, exercising different parts of HEC clusters, making it impossible to understand where the bottlenecks are and where energy is being wasted.<br\/><br\/>This project explores the impact of storage-stack configurations on power and performance, using actual cluster configurations and realistic scientific workloads. The research follows three thrusts: tracing and analysis, adaptive cluster reconfiguration, and new storage software stacks.<br\/>(1) Traces are collected and analyzed which combine both performance and energy data on a large set of scientific workloads: I\/O-, network-, memory-, and CPU-intensive. Three popular scientific cluster configurations are investigated, varying many configuration parameters. (2) Tools are being developed to dynamically adapt a cluster's configurations to a given workload, so as to optimize power and performance prior to running long-term scientific experiments or simulations. (3) New operating systems software is developed specifically to optimize power and performance for scientific workloads: a new lightweight file system and disk I\/O scheduler.<br\/><br\/>The long-term results of this project help society save energy in computing without unduly hurting performance.","title":"Performance- and Energy-Aware HEC Storage Stacks","awardID":"0937854","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I159","name":"Defense Advanced Research Proj"}}],"PIcoPI":["543573","543574"],"PO":["565272"]},"157666":{"abstract":"CPS Small: Control of Surgical Robots: Network Layer to Tissue Contact<br\/><br\/>Research Objectives: This proposed CPS project aims to enable intelligent telesurgery in which a surgeon, or a distributed team of surgeons, can work on tiny regions in the body with minimal access. The University of Washington will expand an existing open surgical robot testbed, and create a robust infrastructure for cyber-physical systems with which to extend traditional real-time control and teleoperation concepts by adding three new interfaces to the system: networking, intelligent robotics, and novel non-linear controllers. <br\/><br\/>Intellectual Merit: This project aims to break new ground beyond teleoperation by adding advanced robotic functions. Equally robust and flexible networking, high-level interfaces, and novel controllers will be added to the existing sytsem. The resulting system will be an open architecture and a substrate upon which many cyber-physical system ideas and algorithms will be tested under realistic conditions. The platforms proven physical robustness will permit rigorous evaluation of results and the open interfaces will encourage collaboration and sharing of results. <br\/><br\/>Broader Impacts: We expect the results to enable new research in multiple ways. First, the collaborators such as Johns Hopkins, U.C. Santa Cruz, and several foreign institutions will be able to remotely connect to new high level interfaces provided by this project. Second, for the first time a robust and completely open surgical telerobot will be available for research so that CPS researchers do not need to be limited to isolated toy problems but instead be able to prototype advanced surgical robotics techniques and evaluate them in realistic contexts including animal procedures.","title":"CPS Small: Control of Surgical Robots: Network Layer to Tissue Contact","awardID":"0930930","effectiveDate":"2009-09-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7680","name":"ENG DIVERSITY ACTIVITIES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7607","name":"ENERGY,POWER,ADAPTIVE SYS"}}],"PIcoPI":["434705","553580"],"PO":["564728"]},"154036":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>A fundamentally different approach for circuit design that has recently gaining popularity is sub-threshold circuits, where the power supply is set below the transistor threshold voltage to obtain energy savings when speed is not the primary constraint. Individual circuits or processing element designed at sub-threshold region operates slowly, but throughput of the circuit can be improved by operating many of them in parallel. Hence, a processing fabric with many sub-threshold cores can be a suitable platform for throughput-oriented parallel applications. This proposal explores the viability of 3D die-stacking of sub-threshold and super-threshold circuits for low power computing. More specifically, our sub-threshold die contains many small sub-threshold cores, whereas our super-threshold die consists of several large super-threshold cores. The sub-threshold cores are used as co-processors to execute massively parallel, high-throughput, low\/mid-performance tasks at ultra low power, while the main super-threshold processors handle high-performance sequential tasks. <br\/><br\/>This new cooperative computing hardware is expected to provide a viable platform for many useful embedded software applications that require both high-performance\/power tasks as well as low-performance\/power tasks. 3D integration will allow each die to utilize the process technology optimized for sub- and super-threshold operation and be seamlessly integrated into a single system. TSV (through silicon via) based 3D communication requires no off-chip access, thereby reducing power consumption further. Sub-threshold circuits are currently used for some low-power applications such as watches, hearing aids, distributed sensor networks, filters, and even pipelined micro-processors. 3D integration is already available in the embedded domain, and the high-performance processor industry is actively evaluating this technology for general purpose computing. This research will fill a critical gap that is needed to make 3D-integrated sub-threshold multi-core co-processors a reality.","title":"SHF: Small: 3D Integration of Sub-Threshold Multi-core Co-processor for Ultra Lower Power Computing","awardID":"0917000","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["422053","518444"],"PO":["562984"]},"157556":{"abstract":"CPS:Small:Collaborative Research: Methods and Tools for the Verification of Cyber-Physical Systems<br\/><br\/>The objective of this research is to investigate and develop methods and tools for the analysis and verification of cyber-physical systems. The approach is to augment the methods and tools that have been developed at the University of Utah and the University of South Florida for modeling and verification of asynchronous and analog\/mixed-signal circuits to address challenges in cyber-physical system verification.<br\/><br\/>This research will develop a unified framework with methods and tools which include an integrated formalism to comprehensively model discrete\/continuous, functional\/timing, synchronous\/asynchronous, and deterministic\/stochastic behavior. These tools will also include algorithms to analyze behavior and verify that it satisfies the correctness requirements on functionality, timing, and robustness. Finally, they will include abstraction and compositional reasoning approaches to enable large systems to be analyzed and verified efficiently.<br\/><br\/>Since cyber-physical systems are becoming ubiquitous, improvements in such systems such as higher reliability, better fault-tolerance, improved performance, and lower design costs will have tremendous positive impact on society. Results from this research will be transferred to the cyber-physical systems community and other application domains by both publishing papers in related conferences and journals as well as by freely distributing tools via the Internet. Both graduate and undergraduate students will be engaged in this multi-institutional research where they will be exposed to the latest research in formal and probabilistic analysis. Early involvement of undergraduate students may help encourage them to attend graduate school. This research project will also recruit underrepresented and female students to allow it to reach broader audiences.","title":"CPS: Small: Collaborative Research: Methods and Tools for the Verification of Cyber-Physical Systems","awardID":"0930225","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["448038"],"PO":["565239"]},"146556":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009(Public Law 111-5).\"<br\/><br\/>The Internet was designed to operate in a trusted and closely knitted academic environment. Today, as the Internet has embraced more than a billion users worldwide, its old design faces significant security and economics challenges. First, it is extremely vulnerable to security attacks such as Denial of Service (DoS) attacks and prefix hijacking attacks. Second, the Internet suffers from the ``tussle of economics,'' in which different participants with competing interests strive to favor their own interests. One aspect of the tussle, the tussle between users and ISPs, has manifested itself in the recent net neutrality debates.<br\/><br\/>The goal of this project is to design, implement, and evaluate a clean-slate network architecture (SureNet) that is resilient to network-layer security attacks and provides control mechanisms for different network participants to express their economic interests. A main design principle behind SureNet is to make identify and trust a first-class network object. A strong notion of identity makes a source (or a network) accountable for its actions, which in turn enables a variety of security and resource management schemes that together make a network trustworthy and a fair playground for participants with conflicting interests. <br\/><br\/>Broader Impact: This project will explore a practical and decentralized approach to establish strong host and network identity, develop mechanisms to isolate and punish misbehaving nodes, and design advanced resource allocation and pricing schemes that enable a network to allocate its resources to users that value them the most. It will foster inter-disciplinary collaboration between computer science and economics, and train both networking and multi-disciplinary graduate students.","title":"CAREER: A Multidisciplinary Approach to Network Architecture Design","awardID":"0845858","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["462629"],"PO":["565090"]},"157688":{"abstract":"Although the benefits of note-taking in the classroom are widely recognized, there has not been enough research focused on alleviating the difficulties encountered by legally blind and low vision students in their attempts to take notes during lecture. The problem is particularly acute in fast-paced STEM courses. Students who are legally blind typically write by placing their head close to the writing surface. They may be able to use a monocular to see what is being written on a board in the front of the classroom. But monoculars with high magnification also have narrow fields of view, which forces the student to \"hunt\" for the target at the front of the classroom each time s\/he looks up from the writing surface. The repeated delay in switching between the writing surface and the board can make it hard for the student to keep up. In this project, the PI will develop and evaluate a portable Note-Taker device that does not require any adaptation of the existing classroom infrastructure, and which allows visually impaired students to shift their attention between the writing surface and the class presentation without inefficient context switching. The device will employ a Tablet PC, a zooming video camera, and an electronic pan\/tilt mechanism, which can all be easily carried in a backpack and set up in a few seconds on any classroom desk. On the Tablet PC's display surface the student will be able both to see a zoomed video of the lecturer's presentation at the front of the classroom in real time, and to take notes with digital ink. The student will be able to adjust the camera's aim at any time by simply tapping on the point of interest in the video window on the display surface of the Tablet PC. The PI's goal is to go beyond mere \"accessibility\" and to create a device that allows legally blind students to take notes as efficiently as fully sighted students. Development and evaluation of the Note-Taker prototype will be done with the full involvement of legally blind and low vision students on the campus of Arizona State University, under the auspices of the Cognitive Ubiquitous Computing Center for Assistive and Rehabilitative Systems (CUbiC CAReS). The PI hypothesizes that his Note-Taking device will improve the learning of students who employ it in their secondary or post-secondary classrooms to take notes during lectures, and that it will also help those students to review their own notes at a later time, in conjunction with cross-referenced audio and video recordings.<br\/><br\/>Broader Impacts: Difficulties in note-taking are not limited to students with low vision. Students with certain learning disabilities, for example, often also have difficulty taking notes at the pace at which material is presented in the classroom. The PI's Note-Taker will reduce irrelevant stimuli, thereby making it easier for such students to successfully absorb, record, and ultimately understand the material presented in the classroom.","title":"HCC: Small: The CUbiC CAReS Note-Taker: Enabling Students who are Legally Blind to Take Notes in Class","awardID":"0931278","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["517575","528940",420831],"PO":["565227"]},"146567":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The World Wide Web is a critical infrastructure that serves our society<br\/>by facilitating information exchange, business and<br\/>education. As it continues to evolve, the number of web-based<br\/>attacks that target innocent web users keeps increasing. <br\/>Examples of such attacks include Cross-site Scripting, SQL Injection<br\/>and Cross-site Request Forgery. Recent attacks on end-users and<br\/>online enterprises through these virulent attacks have resulted in<br\/>widespread damage. Defending these attacks is therefore of very <br\/>important concern to Internet economy and to society-at-large. <br\/>This project develops a comprehensive plan for defending web <br\/>applications from these attacks. <br\/><br\/>The technical contributions of this project are in the development of the<br\/>technologies that elicit the intended behavior of a web application<br\/>and prevent attacks by enforcing these intended behaviors. We build<br\/>a framework in which the intentions of a web application are represented <br\/>using models, which are then enforced to ensure robust prevention of attacks. <br\/>This framework uses novel techniques based on static and dynamic<br\/>analysis, symbolic evaluation, runtime checking and <br\/>isolated execution as foundations. This project also develops<br\/>techniques that enable a web application and a browser to<br\/>collaborate in order to prevent attacks, and apply fine-grained<br\/>restrictions on Web content. The tools being developed in this project <br\/>will have immediate impact on defending legacy web applications <br\/>that are vulnerable to these attacks. <br\/><br\/>The CAREER research project is closely tied with educational<br\/>efforts by integrating topics on web security in the undergraduate <br\/>and graduate computer security classrooms. Finally, a collaborative <br\/>effort with a Chicago inner-city elementary school is also part of this <br\/>project's educational mission.","title":"CAREER: A Framework for Preventing Web-based Attacks","awardID":"0845894","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["532213"],"PO":["564388"]},"157457":{"abstract":"This proposal seeks support for US researchers participation in a workshop\/conference to be held in association with the Third International Conference on Remote Sensing Archaeology (http:\/\/www.spacetimeplace2009.org). The proposed symposium aims to take stock of the emerging trends in Remote Sensing and also explore promising new research pathways as related to multi-diciplinary interaction in emerging topical areas made possible by large scale geospacial and temporal data stores. The agenda is being designed by the The Electronic Cultural Atlas Initiative (ECAI) (www.ecai.org), a research unit of International and Area Studies at the University of California, Berkeley . In the last twelve years, ECAI and other scholarly groups have pursued the capabilities in remote sensing and digital application in archaeology. Concepts like space, place, landscape, time and \"context\" plus technological inputs in mapping and management of heritage are becoming conceptual frameworks in recent trends in the field of archaeology and related areas. The study is inherently international in scope and such conferences as this are integral in moving scholarship forward.","title":"Space Time Place Workshop Proposal","awardID":"0929851","effectiveDate":"2009-09-01","expirationDate":"2011-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["441922"],"PO":["565136"]},"157699":{"abstract":"The objective of this research is to study the formal design and verification of advanced vehicle dynamics control systems. The approach is to consider the vehicle-driver-road system as a cyber-physical system (CPS) by focusing on three critical components: (i) the tire-road interaction; (ii) the driver-vehicle interaction; and (iii) the controller design and validation.<br\/><br\/>Methods for quantifying and estimating the uncertainty of the road friction coefficient by using self-powered wireless sensors embedded in the tire are developed for considering tire-road interaction. Tools for real-time identification of nominal driver behavior and uncertainty bounds by using in-vehicle cameras and body wireless sensors are developed for considering driver-vehicle interaction. A predictive hybrid supervisory control scheme will guarantee that the vehicle performs safely for all possible uncertainty levels. In particular, for controller design and validation, the CPS autonomy level is continuously adapted as a function of human and environment conditions and their uncertainty bounds quantified by considering tire-road and driver-vehicle interaction.<br\/><br\/>High confidence is critical in all human operated and supervised cyber-physical systems. These include environmental monitoring, telesurgery, power networks, and any transportation CPS. When human and environment uncertainty bounds can be predicted, safety can be robustly guaranteed by a proper controller design and validation. This avoids lengthy and expensive trial and error design procedures and drastically increases their confidence level. Graduate, undergraduate and underrepresented engineering students benefit from this project through classroom instruction, involvement in the research and substantial interaction with industrial partners from the fields of tires, vehicle active safety, and wireless sensors.","title":"CPS:Medium: High Confidence Active Safety Control in Automotive Cyber-Physical Systems","awardID":"0931437","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["526982","563532","527080"],"PO":["564728"]},"154069":{"abstract":"This project will provide algorithms and toolkits to empower end users for better application experience when using open-platform smartphones over dynamic wireless access networks. A novel model-based diagnosis engine helps users to understand the access problems as application performance degrades. The cognition-aware feedback completes an execution-evaluation loop for the users to construct correct conceptual perceptions of the troubleshooting process and the root cause. Smartphones with customized software will be distributed to conduct user studies and evaluate the user-interaction effectiveness when dealing with wireless access problems.<br\/><br\/>The combination of formal causality and state models is leveraged to troubleshoot complex wireless access problems. A unique contribution is to integrate application-level user context with network-level diagnostic models, as user mobility and physical environment are important factors of wireless access performance. Machine-learning algorithms are used for robust context inference using noisy data from on-device sensors. Norman's cognition framework is used for iterative presentation and perception of the troubleshooting process on small-screen smartphones with limited input methods.<br\/><br\/>This work fills in the gap of providing diagnostic tools to the mobile users. The success of this project will result in new perception tools, which can be disseminated directly to the public through mobile application stores, to significantly enhance the often-misleading signal indicator on smartphones today. An interactive Web-based education portal will be developed to better involve students and online course modules will be introduced through UMass Lowell's Division of Continuing Studies and Corporate Education to reach IT professionals.","title":"HCC: Small: Integrating User Context and Conceptual Perceptions for Understandable Wireless Access on Open-Platform Smartphones","awardID":"0917112","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["463098"],"PO":["564456"]},"159316":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940573","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["527650","527652"],"PO":["561855"]},"146369":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/><br\/>With recent advances in capacity, bandwidth, and durability, NAND flash memory has been successfully employed in mobile devices like PDAs and laptops and it is starting to replace hard disks in desktop systems. Integrating NAND flash memory into server domain applications, which normally demands a high level of data reliability and exceptional random I\/O performance, however, is much more challenging because NAND flash memory exhibits relatively poor random write performance and insufficient reliability due to limited erasure cycles. To address these problems, an architectural support for flash SSD must be devised in order to fundamentally boost its performance and longevity by a software\/hardware combined effort. In this project, we will develop a novel flash disk storage architecture that exploits the addition of RAM and dedicated software schemes to incorporate flash SSDs into enterprise-class storage systems. We plan to implement a flash disk array prototype and deploy it in real-world data-intensive application. In addition, we will develop new software techniques such as a double-buffer write ordering management scheme and an inter-disk wear-leveling technique. This project will contribute to energy conservation, performance enhancement, data management, and reliability technology for enterprise-class storage systems by developing the flash disk array storage architecture, accompanied by an array of new software schemes. This project will also promote teaching, learning, an training by exposing both undergraduate and underrepresented students to technological and scientific underpinnings in the field of server-class storage systems.","title":"CAREER: Architectural Support for Integrating NAND Flash Solid State Disks into Enterprise-Class Storage Systems","awardID":"0845105","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562727"],"PO":["535244"]},"161560":{"abstract":"Alternate Reality Games (ARGs) are a new genre of interactive experience that requires players to collaborate in order to solve problems using the real world as a narrative platform. The goal of this project is to understand and tailor this new genre for use as (1) an engaging educational activity that provides hands-on experience using a range of collaborate technologies and computational strategies, and (2) a platform on which to co-design and evaluate novel collaborative tools that may be used in unanticipated ways. The proposed work is unconventional and high risk, yet could lead to significant payoffs. Success in the knowledge economy requires that students develop strong instincts and expertise in applying cooperative technologies and tools to effectively collect multimedia data, make sense of it, and use it to solve practical and challenging problems.<br\/><br\/><br\/>The results of this project will produce broader impacts that focus on recruitment and retention of science, technology, engineering, and mathematics (STEM) students. ARGs have the potential to attract a wide variety of students from diverse socio-technical backgrounds, as well as introduce scientific and mathematical problems (e.g., puzzles) in non-traditional ways.","title":"EAGER: Alternate Reality Games (ARGs) in the Service of Education and Design","awardID":"0952567","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["552494","552302","552302"],"PO":["564456"]},"161593":{"abstract":"The Semantic Robot Challenge is a photo treasure hunt for robots. <br\/>Competing mobile robot platforms equipped with multiple cameras and laser range scanners are given a text list of objects dispersed on furniture or on the floor in a conference room. They can learn about what the objects are supposed to look like by connecting to the Internet and finding images of them. Then they have to autonomously search the environment and take snapshots of as many objects as they can, adding bounding boxes around the objects in the pictures and labeling them. The winner is the robot that takes pictures of the largest number of objects, with correct bounding boxes and labels (evaluated by human judges according to well-defined rules). This competition challenges the teams to successfully implement a large number of strategies that humans would use to accomplish the same task. Successful robots are able to perform navigation, exploration, obstacle avoidance and mapping, peripheral vision, foveal vision, observation from multiple viewpoints, bottom-up feature detection and top-down object model verification.<br\/><br\/>The PI is with the organizing committee of the Third Semantic Robot Vision Challenge (SRVC), and this NSF award supports travel scholarships for all participating teams. This challenge is scheduled to take place as a Special Track of the Fifth International Symposium on Visual Computing (ISVC09) in Las Vegas on December 1, 2009. The first SRVC event took place at the AAAI Conference in Vancouver, British Columbia, Canada in 2007. The second SRVC event was organized at CVPR in Anchorage, Alaska in 2008. The practice of providing travel support to participating teams has been shown to provide a great encouragement for teams to attend, and it was implemented for the past two SRVC events.<br\/><br\/>The web site for the Semantic Robot Vision Challenge is http:\/\/www.semantic-robot-vision-challenge.org\/","title":"Travel Scholarships for the Semantic Robot Vision Challenge","awardID":"0952731","effectiveDate":"2009-09-15","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[432192],"PO":["564316"]},"153740":{"abstract":"The staff in trauma centers are faced with complex problems under time pressure.<br\/>Despite the introduction of standard protocols, the diversity of injuries that can occur<br\/>requires a coordinated approach to the evaluation and treatment for each patient.<br\/>Trauma care involves complex teamwork under time pressure, and teamwork errors<br\/>endanger patient care and increase costs. Our proposed ethnographic study will use<br\/>observation and detailed analysis of video recordings of trauma resuscitations to<br\/>determine the nature and extent of teamwork errors in a trauma center. This detailed<br\/>study of complex teamwork will uncover the causes of teamwork errors in collaborative<br\/>high-risk environments. Methods will be developed to understand how teams work and<br\/>where difficulties arise. This work will yield detailed descriptions of errors and their<br\/>causes, a taxonomy of teamwork errors, information on how to improve team<br\/>performance, and guides to the use of technology for teamwork support. It extends the<br\/>level of detail of ethnographic research so that we can achieve precision in the<br\/>understanding of procedures which are difficult to monitor automatically but where<br\/>step-by-step records are essential to detect the causes of errors.<br\/>Understanding and improving the effectiveness of trauma teams has direct benefit to<br\/>society. Further, complex collaborations are ubiquitous in modern enterprises and these<br\/>results could improve collaborations both in terms of quality and productivity across<br\/>organizations. In addition, this work will serve to develop the skills needed by a new<br\/>cadre of researchers with knowledge of computer-supported collaborative work,<br\/>video-content analysis and cooperative research.","title":"HCC-Small: Collaborative Research: Assessing Technology Requirements for Preventing Teamwork Errors in Safety-Critical Settings","awardID":"0915899","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["419981",409129],"PO":["565342"]},"161242":{"abstract":"In 2008, the NSF ADVANCE program awarded a grant (HRD-0819407) to the University of Washington ADVANCE Center for Institutional Change (CIC) to implement the \"On-Ramps into Academia\" workshop series. The series aims to provide Ph.D. level women in industry, consulting, and government research labs with the information and resources necessary to make a successful transition back to academia as faculty.<br\/><br\/>The next workshop will be held October 18-20, 2009 in Seattle, WA. Of the fifteen applicants to date, eight have Ph.D.s in Computer Science and an additional woman has a Ph.D. in Technical Communication with a focus on Human-Computer Interaction (HCI). This supplement requests travel support for the these women in Computer Science to attend the On-Ramps workshop.","title":"Funding Computer Scientists to Attend the On-Ramps into Academia Workshop","awardID":"0950585","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["549399","545988"],"PO":["561855"]},"153872":{"abstract":"This project seeks to improve the quality and reliability of Analog\/Radio-Frequency (RF) integrated electronic circuits (ICs) by developing an intelligent system for systematically exploring the wealth of information generated throughout their production lifetime and applying it towards improving the effectiveness of their design, manufacturing, and testing. While a large amount of data is made available through extensive design simulations and measurements on actual fabricated circuits, there currently exists a striking lack of formal methods to efficiently extract meaningful information from this data. The research activities that will be carried out through this project aim to fill this void by developing correlation mining methods based on the most recent developments in the fields of machine learning and data mining. Ultimately, using data from actual IC productions provided by industrial partners (i.e. IBM and Texas Instruments), the objective of this project is to demonstrate the impact that such correlations can have on reducing the cost of testing, enhancing the yield of the production and enabling post-manufacturing calibration of analog\/RF circuits. <br\/><br\/>This project will facilitate the cost-effective realization of robust electronic circuits and systems, thus enabling more reliable computing and promoting technology trustworthiness. The proposed research is complemented by educational and outreach activities, including the development of a new graduate-level course on applications of Machine-Learning in Computer Aided Design and Test and the involvement of graduate, undergraduate and high-school students in research with the groups of the Principal Investigators, the industrial partners, and the research laboratory of the international collaborator.","title":"SHF: Small: Collaborative Research: Correlation Mining and its Applications in Test Cost Reduction, Yield Enhancement, and Performance Calibration in Analog\/RF Circuits","awardID":"0916415","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["565034","550329"],"PO":["562984"]},"153993":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The major objective of this project is to develop the fundamental theoretical framework and algorithms that realize human context awareness in an infrastructure-free fashion and validate them through physical experiments using a body sensor network. This new human context-awareness approach will open up many new research opportunities in pervasive computing, as well as human-computer interaction and human-robot interaction. This project will have many societal impacts. First, the research results can be applied to track and monitor emergency responders, therefore significantly improving the operation efficiency and personnel safety. Second, this project will benefit health research and health care practices. Being able to monitor human's activity and location in a daily setting will enable researchers to study many health problems related to human behaviors. When used by physicians to monitor their patients or elderly people, it can greatly improve the accuracy of disease diagnosis and human health assessment. The proposed research and education integration activities will help boost the enrollment and retention rate in the ECEN program at Oklahoma State University. The proposed outreach activities will stimulate prospective and current college students, especially Native American, female students, to pursue degrees or careers in science and engineering.","title":"CSR: Small: Infrastructure-free Human Context Awareness with a Wearable Sensing and Computing System","awardID":"0916864","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["523489"],"PO":["565255"]},"153641":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Multicore processors have become main-stream. At the same time, CPU clock rates are no longer increasing. Operating within this environment, application developers are under competitive pressure to parallelize software in order to achieve an aceptable performance level for computationally intensive features. Unfortunately, fully automated parallelization is constrained by sequential semantics and by limits of a compiler?s analytical abilities. Consequently, designing parallel programming languages for developing efficient yet reliable main-stream applications continues to be a challenge. Rewriting software completely by hand is undesireable, because this kind of activity may waste years of investment in large scale software. Therefore, ideally, existing software should be automatically converted to new parallel forms.<br\/><br\/>To address this problem, new program slicing techniques are investigated in this project to enable programmers to convert existing sequential programs, with minimum hand-made changes, into forms which can be safely parallelized by automatic tools. This research will result in a set of novel program analysis and transformation techniques to support the new slicing methods. <br\/><br\/>The project will have a broad impact on the US software industry?s ability to compete globally in its endeavor to retrofit existing software for the emerging hardware platforms. The tool and techniques developed in the project will be used in compiler and architecture courses offered at both graduate and undergraduate levels. The project also engages both graduate and undergraduate students in the key research activities, providing advanced technical training which will be critical to future success of a new generation of computer scientists and software engineers.","title":"CSR:Small:New Slicing Techniques for Program Parallelization","awardID":"0915414","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[408878],"PO":["565255"]},"153762":{"abstract":"This project is to develop new, effective distance metrics for comparing two images. These metrics account for two effects. First, pixels can change their position, deforming from one image to another. Second, pixels may change their intensity. In many vision problems, intensity changes are primarily due to lighting variation. The research team first addresses the effect of illumination changes, which enables to develop a new, powerful, robust distance for measuring the effects of lighting variation in an image. The research team combines this with both existing and new methods to develop a robust distance that accounts simultaneously for image deformations and intensity variations. Computing this distance separates these two effects, providing a correspondence between images. This can be used to track objects moving relative to a light, to match images taken at different times of day, or to recognize objects seen under different lighting, from different viewpoints, with variations in their shape.<br\/><br\/>This new metric provides a theory of computation for deformation and lighting that encodes our notion of image similarity. However, it is still a considerable challenge to find ways to effectively compute with such an image metric. Therefore, the research team also develops computationally effective algorithms based on this new metric. These algorithms improve performance in numerous applications such as face recognition, autonomous navigation, and optical flow and tracking, in which variations in lighting and shape cause significant challenges for existing methods.","title":"RI:Small:Robust Image Matching with Deformations and Lighting Variation","awardID":"0915977","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["541955"],"PO":["564316"]},"153894":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Increasingly, the Internet is used to distribute content on massive scale. Massive content distribution causes shortage of network capacity, increases costs of service providers, and impairs quality of user experience. This project develops advanced content-distribution techniques for achieving complex cost-performance objectives. An interesting class of existing content-distribution techniques, known as ?swarming?, use ad-hoc methods designed to help file receivers exchange pieces of the file they have already received. However, little is known about how to develop suitable swarming techniques for infrastructure networks under complex objectives.<br\/><br\/>This project is unleashing the potential of swarming as the most advanced content-distribution technique. Unlike existing ad-hoc approaches, the new approach uses general optimization theory in developing swarming algorithms. The novelty is to conceptualize swarming as a technique for distributing content over multiple multicast trees (MMT). Under the new approach, content distribution is formulated as a problem of optimal swarming over MMT. The solution algorithms become the best way of conducting swarming under each performance objective. Even heuristic solutions have performance guarantees. <br\/><br\/>The project will contribute a family of optimized and robust swarming techniques, suitable for future networks and applications. These techniques can mitigate network congestion or increase distribution speed, leading to eventual outcomes in increasing economic value, accelerating the rate of innovation, and improving productivity. The algorithms can be applied generally to other content-intensive applications, including IPTV, or to scientific networks that routinely transfer massive data.","title":"NeTS:Small:Fundamental Methods and Heuristics for Advanced, Network-Centric Content Distribution","awardID":"0916486","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["267015"],"PO":["564993"]},"153663":{"abstract":"Operators of large-scale enterprises and ISPs need to understand the type of traffic that their networks handle, and emergent applications and traffic behavior, in order to better service them and detect anomalies. Also, better assessment of the carried traffic will inform network planning and security. Particularly for private enterprise networks, monitoring methods can be used to detect inappropriate traffic classes indicating unprofessional (or at least unauthorized) activity. This work will adapt and innovate methods of unsupervised machine learning to classify traffic flows to ascertain the types of end-user applications which are active in an enterprise network. <br\/><br\/>The broader impact of the project will include explaining networking concepts to a wider audience of machine learning researchers, and vice versa so that the newly developed techniques will have wide dissemination to the networking community, as well as to other domains in science and engineering. Also, cross-disciplinary graduate-level courseware on applications of machine learning to network flow data and related concepts will be developed and disseminated. More practical developments will be achieved through collaboration with industrial partners. Finally, the project will aim to support graduate students from under-represented groups in computer science and engineering, particularly women.<br\/><br\/>The primary technical merit of the research to be conducted will pertain to the high-volume and considerably complex network data under consideration, including prevalent short flows, given limited computing and communication resources to do so.","title":"NetSE Small: Unsupervised flow-based clustering","awardID":"0915552","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["556038","562302"],"PO":["564993"]},"153784":{"abstract":"This project will advance the understanding of swarms of simple vehicles that can collectively accomplish complex tasks. Prof. Rossi and Shen take their inspiration from social animals such as flocks of birds and schools of fish that communicate using simple rules to coordinate motion and make decisions for the entire group. There can be significant differences between rules found in biology and technological applications. For instance, birds coordinate motion with visual cues whereas networked robots coordinate activities using wireless communication. These two types of communication provide different kinds of information and have different limitations. Profs. Shen and Rossi are particularly interested in autonomous underwater vehicles because they face the challenge of low or irregular communication quality and poor position information.<br\/><br\/>Profs. Shen and Rossi will combine mathematical modeling and analysis with engineering applications to study specific problems. First, they will explore leadership within swarms to understand how small numbers of individuals within a swarm can shape decision making for the entire group. Second, they will study swarm behavior in the presence of background flows to understand how currents can distort or disassemble swarms that would be effective in calm conditions. Third, they will study threat avoidance strategies to understand how complex motion can protect a swarm when individual evasion is impossible. Finally, they will study coordinated detection of a scalar field such as nutrients or contaminants in the ocean. Profs. Shen and Rossi will create an interdisciplinary research team around these problems involving students from both mathematics and computer science.","title":"NetSE: Small:Autonomous Wireless Swarms: Integrating Science and Engineering","awardID":"0916035","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["538152","528443"],"PO":["564924"]},"150275":{"abstract":"Postdoctoral Research Fellowship.","title":"PostDoctoral Research Fellowship","awardID":"0902914","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7335","name":"WORKFORCE IN THE MATHEMAT SCI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[400479],"PO":["565231"]},"153795":{"abstract":"The cost-effective construction of software is increasingly important to businesses and consumers. Given software's ever-increasing size and complexity, modern software construction employs significant tool support. Recent tools complement traditional static analysis tools by exploiting the natural language found within a program's text through the use of Information Retrieval (IR). Best known for its use by search engines on the Internet, IR encompasses a growing collection of techniques that apply to large repositories of natural language. New tools using IR have tackled problems previously requiring considerable human effort. However, to reap the full benefit of IR techniques, the language across all software artifacts (e.g., requirement and design documents, test plans, as well as source code) must be normalized. Normalization align the vocabulary found in source code with that of other software artifacts. In addition to improving existing tools, normalization will also encourage the development of new techniques and methodologies useful in future tools. Empirical study of successful tool improvements will aid technology transfer of the tools expected to improve programmer productivity. Beyond its technical goals, this research promotes discovery in Loyola's undergraduate curriculum through the direct involvement of undergraduate students in scientific research and by integrating research results into classroom learning.","title":"SHF: Small: RUI: Making Sense of Source Code: Improving Software through Information Retrieval","awardID":"0916081","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[409261,409262],"PO":["564388"]},"152585":{"abstract":"This research program will develop and demonstrate theory and techniques for efficient collection, transmission and processing of information in wirelessly-connected sensor networks. This fundamental research is aimed towards development of a revolutionary wireless sensor node, optimized for infrastructure monitoring, and characterized by ultra-low power consumption. Power consumption, installation complexity and installation cost are significant bottlenecks to the widespread deployment of wireless infrastructure monitoring that will be addressed by this research. This research program improves energy efficiency and battery lifetime through the use of compressed sampling in sensing, physical communication and network communication and through the co-design of hardware and algorithms.<br\/><br\/>A theme of the research is the development of compressive sampling techniques. Compressive sampling techniques will be developed to reduce the number of samples that need to taken by sensors, to optimize the placement of sensing nodes, and to minimize the amount of data transmitted by the sensing nodes. This research will develop new theoretical approaches to signal sampling, to ultra-wideband (UWB) wireless communication of acquired information, and to sensor network architecture and protocols. Development of new theory and algorithms will go hand-in-hand with the development of new circuit techniques. New integrated circuit techniques for analog-to-digital conversion and wireless communication will be developed.<br\/><br\/>A Center for Structural Health Monitoring through Compressed Sensing will be formed to broaden the impact of this research. The scope of the education component of this program targets grade-school, undergraduate and graduate students. An interdisciplinary curriculum of courses in Math, Civil Engineering and Electrical Engineering will be created. The center will also develop an extensive outreach education program.","title":"CIF: Large: Sensing Sensors: Compressed sampling with Co-design of Hardware and Algorithms Across Multiple Layers in Wireless Sensor Networks","awardID":"0910765","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":[406523,"550475","507958","564507","534190"],"PO":["564898"]},"151023":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>There is a growing need for wireless networks that can sustain high data rates, are robust to interference, make efficient use of battery resources, and offer secure communications. This project introduces cooperative beamforming (CB), a novel technique that enables high throughput and power efficient communications in a secure manner. CB consists of two stages. In the first stage, the sources share their data with neighboring nodes via low-power communications. Various approaches for such information sharing are considered, with a goal to minimize queuing delays, conserve energy, and achieve high throughput. In the second stage, the cooperative nodes apply a weight to the signal received during first stage, and transmit. The weights are such that a specific objective criterion (e.g., signal to interference at the destination) is maximized. In CB, although each node uses low power, all nodes together can deliver high power to a faraway destination. This increase in power offsets power reduction due to propagation attenuation. CB can be viewed as an alternative to multihop transmission and, unlike multihop transmission, does not deplete the power resources of other nodes. Since CB can achieve long distance communication, new paths can be found to improve the overall network performance. Also, CB improves network security by avoiding eavesdroppers; unlike traditional cryptographic-based protocols that operate at higher layers and are sensitive to the broadcast nature of the transmission medium, CB improves security at the physical layer. CB will be implemented on a hardware network testbed to demonstrate how the developed techniques can revolutionize wireless communications.","title":"NeTS: Medium: Collaborative Research: Cooperative Beamforming for Efficient and Secure Wireless Communication","awardID":"0905513","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["546219"],"PO":["557315"]},"156600":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/><br\/>Summary: Formal Analysis of Complex Systems<br\/><br\/>A Collaborative Proposal Involving CMU, CUNY, NYU, Stony Brook, UMD, Cornell, JPL<br\/><br\/><br\/>This Expedition, under the directorship of Lead PI Edmund M. Clarke, will develop new computational tools to help scientists and engineers analyze and understand the behavior of the complex models they develop for application domains ranging from systems biology to embedded control. Building on the success of model checking and abstract interpretation (MCAI), two well-established methods for automatically verifying properties of digital circuit designs and embedded software, this research project will extend the MCAI paradigm to systems with complex continuous dynamics and probabilistic behaviors. Challenge problems providing technology drivers and testbeds for the research include: understanding the precursors and course of pancreatic cancer; predicting the onset of atrial fibrillation; and obtaining deep design-time insights into the behavior of automotive and aerospace control systems. Ultimately, this Expedition is expected to provide vital tools that will enable health-care researchers to discover better treatments for disease and will allow engineers to build safer aircraft and other complex systems.<br\/><br\/>The world-class team of scientists and engineers assembled for this Expedition includes two Turing Award winners, a recipient of the National Medal of Science, and awardees of other prestigious research prizes. Outreach consists of the development of a new, highly ambitious and highly cross-discipline educational program called Complex Systems Science Engineering, an annual Minority-Focused Intersession Workshop for Undergraduates on Understanding and Analyzing Complex Embedded and Biological Systems to be hosted at member institution Lehman College, CUNY; substantial financial support for undergraduate research; student involvement in the NASA JPL Research Affiliates Program; and other research opportunities for undergraduate and graduate students and postdoctoral trainees.<br\/><br\/>More information: http:\/\/www.mcai2.org\/","title":"Collaborative Research: Next-Generation Model Checking and Abstract Interpretation with a Focus on Embedded Control and Systems Biology","awardID":"0926194","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"6894","name":"ITR EXPEDITIONS"}}],"PIcoPI":[417615,417616,"511008"],"PO":["565239"]},"153454":{"abstract":"Humans possess the ability to learn increasingly sophisticated representations of the world in which they live. In the visual domain, it is estimated that we are able to identify in the order of 30,000 object categories at multiple levels of granularity (e.g. toe-nail, toe, leg, human body, population). Moreover, humans continuously adapt their models of the world in response to data. Can we replicate this life-long-learning capacity in machines?<br\/><br\/>In this project, the PIs build hierarchical representations of data streams. The model complexity adapts to new structure in data by following a nonparametric Bayesian modeling paradigm. In particular, the depth and width of our hierarchical models grow over time. Deeper layers in this hierarchy represent more abstract concepts, such as ?a beach scene? or ?chair?, while lower levels correspond to parts, such as a ?patch of sand? or ?body part?. The formation of this hierarchy is guided by fast hierarchical bottom up segmentation of the images.<br\/><br\/>To process large amounts of information, the PIs distribute computation across many CPUs \/GPUs. They develop novel fast inference techniques based on variational inference, memory bounded online inference, parallel sampling, and efficient data-structures.<br\/><br\/>The technology under development has a large number of potential applications ranging from organizing digital libraries and the worldwide web, building visual object recognition systems, successfully employing autonomous robots and training a ?virtual doctor? by processing worldwide information from hospitals about diseases, diagnosis and treatments.<br\/><br\/>Results are disseminated through scientific publications and publicly available software.","title":"RI:Small:Collaborative Research: Infinite Bayesian Networks for Hierarchical Visual Categorization","awardID":"0914783","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["516952"],"PO":["562760"]},"153696":{"abstract":"Abstract<br\/><br\/>The spread of malware has the potential to slow down or cripple wireless services. It poses a particularly inimical threat to a multitude of activities ranging across an entire spectrum from social interaction and gaming, to the flow of commerce and informational services, and, at the largest scale, to national security. Current countermeasures are mostly ad hoc and reactive in that they are used to fend off threats as they arrive or are preemptively discovered. <br\/><br\/>This project aims to develop theoretical foundations for malware control and counter-measure design in wireless networks by drawing from epidemiological analogues in containment or quarantining strategies for limiting the spread of infectious diseases in human society, and game-theoretic models for interactions among opponents. Optimal power control quarantining strategies that curtail and regulate the spread of contagion by exploiting the broadcast property of the wireless medium will be designed, validated analytically and experimentally, and incorporated in networking protocols. <br\/><br\/>This work will facilitate the development of new wireless paradigms where a plethora of devices need to securely communicate with each other and with other entities on the Internet. The research will not only draw from, but also contribute to, disparate disciplines such as epidemiology, game theory, optimal control and communication networks, and may eventually lead to new disciplines at the interfaces of these areas. Graduate and undergraduate students will be trained at the participating universities through supervision of doctoral and masters level dissertations and senior design projects.","title":"TC: SMALL: COLLABORATIVE RESEARCH: Mathematics of Infection Diffusion in Wireless Networks","awardID":"0915697","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["496297","517945"],"PO":["565136"]},"151034":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>There is a growing need for wireless networks that can sustain high data rates, are robust to interference, make efficient use of battery resources, and offer secure communications. This project introduces cooperative beamforming (CB), a novel technique that enables high throughput and power efficient communications in a secure manner. CB consists of two stages. In the first stage, the sources share their data with neighboring nodes via low-power communications. Various approaches for such information sharing are considered, with a goal to minimize queuing delays, conserve energy, and achieve high throughput. In the second stage, the cooperative nodes apply a weight to the signal received during first stage, and transmit. The weights are such that a specific objective criterion (e.g., signal to interference at the destination) is maximized. In CB, although each node uses low power, all nodes together can deliver high power to a faraway destination. This increase in power offsets power reduction due to propagation attenuation. CB can be viewed as an alternative to multihop transmission and, unlike multihop transmission, does not deplete the power resources of other nodes. Since CB can achieve long distance communication, new paths can be found to improve the overall network performance. Also, CB improves network security by avoiding eavesdroppers; unlike traditional cryptographic-based protocols that operate at higher layers and are sensitive to the broadcast nature of the transmission medium, CB improves security at the physical layer. CB will be implemented on a hardware network testbed to demonstrate how the developed techniques can revolutionize wireless communications.","title":"NeTS: Medium: Collaborative Research: Cooperative Beamforming for Efficient and Secure Wireless Communication","awardID":"0905556","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["540080"],"PO":["557315"]},"157700":{"abstract":"The objective of this research is to enable operation of synthetic and<br\/>cyborg insects in complicated environments, such as outdoors or in a<br\/>collapsed building. As the mobile platforms and environment have<br\/>significant uncertainty, learning and adaptation capabilities are<br\/>critical. The approach consists of three main thrusts to enable the<br\/>desired learning and adaptation: (i) Development of algorithms to<br\/>efficiently learn optimal control policies and dynamics models through<br\/>sharing the learning and adaptation between various instantiations of<br\/>platforms and environments. (ii) Creation of control learning<br\/>algorithms which can be run on low-cost, low-power mobile platforms.<br\/>(iii) Development of algorithms for online improvement of policy<br\/>performance in a minimal number of real-world trials.<br\/><br\/>The proposed research will advance learning and adaptation<br\/>capabilities of practical cyberphysical systems. The proposed<br\/>approach will be generally applicable and lead to a new class of<br\/>learning and adapting systems that are able to leverage shared<br\/>properties between multiple tasks to significantly speed up<br\/>learning and adaptation.<br\/><br\/>Success in this research project will bring society closer to solving<br\/>the grand challenge of teams of mobile, disposable, search and rescue<br\/>robots which can robustly locomote through uncertain and novel<br\/>environments, finding survivors in disaster situations, while removing<br\/>risk from rescuers. This project will provide interdisciplinary<br\/>training through research and classwork for undergraduate and graduate<br\/>students in creating systems which intimately couple the cyber and<br\/>physical aspects in robotic and living mobile platforms. Through the<br\/>SUPERB summer program, under-represented students in engineering will<br\/>experience research in learning and robotics.","title":"CPS: Medium: Learning for Control of Synthetic and Cyborg Insects in Uncertain Dynamic Environments","awardID":"0931463","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["520938","301575",420868],"PO":["565136"]},"152497":{"abstract":"Research in machine translation of human languages has made substantial progress recently, and surface patterns gleaned automatically from online bilingual texts work remarkably well for some language pairs. However, for many language pairs, the output of even the best systems is garbled, ungrammatical, and difficult to interpret. Chinese-to-English systems need particular improvement, despite the importance of this language pair, while English-to-Chinese translation, equally important for communication between individuals, is rarely studied. This project develops methods for automatically learning correspondences between Chinese and English at a semantic rather than surface level, allowing machine translation to benefit from recent work in semantic analysis of text and natural language <br\/>generation. One part of this work determines what types of semantic <br\/>analysis of source language sentences can best inform a translation system, focusing on analyzing dropped arguments, co-reference links, and discourse relations between clauses. These linguistic phenomena must generally be made more explicit when translating from Chinese to English. A second part of the work integrates natural language generation into statistical machine translation, leveraging generation technology to determine sentence boundaries, ordering of constituents, and production of function words that translation systems tend to get wrong. A third part develops and compares algorithms for training and decoding machine translation models defined on semantic representations. All of this research exploits newly-developed linguistic resources for semantic analysis of both Chinese and English. <br\/><br\/>The ultimate benefits of improved machine translation technology are easier access to information and easier communication between individuals. This in turn leads to increased opportunities for trade, as well as better understanding between cultures. This project's systems for both Chinese-to-English and English-to-Chinese are developed with the expectation that the approaches will be applied to other language pairs in the future.","title":"RI: Large: Collaborative Research: Richer Representations for Machine Translation","awardID":"0910532","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[406300],"PO":["565215"]},"157832":{"abstract":"CPS:Small: Real-time, Simulation-based Planning and Asynchronous Coordination for Cyber-Physical Systems<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to investigate how to replace human decision-making with computational intelligence at a scale not possible before and in applications such as manufacturing, transportation, power-systems and bio-sensors. The approach is to build upon recent contributions in algorithmic motion planning, sensor networks and other fields so as to identify general solutions for planning and coordination in networks of cyber-physical systems.<br\/><br\/>The intellectual merit of the project lies in defining a planning framework, which integrates simulation to utilize its predictive capabilities, and focuses on safety issues in real-time planning problems. The framework is extended to asynchronous coordination by utilizing distributed constraint optimization protocols and dealing with inconsistent state estimates among networked agents. Thus, the project addresses the frequent lack of well-behaved mathematical models for complex systems, the challenges of dynamic and partially-observable environments, and the difficulties in synchronizing and maintaining a unified, global world state estimate for multiple devices over a large-scale network.<br\/><br\/>The broader impact involves the development and dissemination of new algorithms and open-source software. Research outcomes will be integrated to teaching efforts and undergraduate students will be involved in research. Underrepresented groups will be encouraged to participate, along with students from the Davidson Academy of Nevada, a free public high school for gifted students. At a societal level, this project will contribute towards achieving flexible manufacturing floors, automating the transportation infrastructure, autonomously delivering drugs to patients and mitigating cascading failures of the power network. Collaboration with domain experts will assist in realizing this impact.","title":"CPS: Small: Real-time, Simulation-based Planning and Asynchronous Coordination for Cyber-Physical Systems","awardID":"0932423","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["553948",421302],"PO":["565274"]},"155775":{"abstract":"Proposal #: CNS 09-23203 <br\/>PI(s): Murphy, Robin R.; Ames, Aaron D.; Gutierrez-Osuna, Ricardo; Song, Dezhen; Stoleru, Radu<br\/>Institution: Texas A & M<br\/> College Station, TX 77843-3000<br\/>Title: MRI\/Acq.: Mobile, Distributed Instrumentation for Response Research (RESPOND-R)<br\/><br\/>Project Proposed:<br\/>This project, acquiring equipment to create a mobile, modular, distributed instrument called RESPOND-R, aims to develop an integrated, interoperable research instrument suitable for a comprehensive use of Cyber-Physical Systems (CPS) technologies for various types of incidents: urban building and bridge collapse (earthquakes, hurricanes, explosives), radiological or chemical spills, and terrorism. CPS explores new technologies such as robots, wireless networks, miniature sensors, sensor networks, and other types for emergency preparedness, prevention, response, and recovery. The instrument services projects in multidisciplinary research in Emergency Informatics for disaster response. Emergency Informatics consists of a real-time collection, processing, distribution, and visualization of information for emergency preservation, preparedness, response, and recovery. RESPOND-R addresses the lack of an Integrated Emergency Informatics Instrument that can be configured to support scenario-based experimentation and transported to exercises and responses. To capture the interaction of devices, the physical worlds, and human decision making, the project will use the Disaster City facility at the institution. CPS components in core areas (unmanned systems, imaging\/chemical and radiological sensors, wireless communication networks, nodes and motes, and human performance) will be acquired. Addressing testing within real-world conditions and scenarios, RESPOND-R is expected to advance knowledge in the emerging, multidisciplinary fields of Emergency Informatics and CPS by providing access to a complete, large scale system that is located in a fidelity disaster testbed or can be transported to homeland security exercises or actual incidents. RESPOND-R will be open to researchers outside the institution, with a projection that 22 universities will participate over 3 years.<br\/><br\/>Broader Impacts: Used by 18 faculty in 8 departments and 2 colleges (Engineering and Architecture), the instrument contributes to educate 10-20 graduate students each year through field components of courses and dissertation work. Leveraging initiatives for underrepresented group, RESPOND-R will also be utilized for the training of 1000 responders and policy makers. In keeping with instruments used by ?storm chasers,? the instrument will be deployable for exercises and disasters where CPS components can reduce negative outcomes of events while gathering extremely valuable data and\/or save lives.","title":"MRI: Acquisition of Mobile, Distributed Instrumentation for Response Research (RESPOND-R)","awardID":"0923203","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["467563","550010","561708","565226","526843"],"PO":["557609"]},"158932":{"abstract":"I\/O performance is often an issue for high-end computing (HEC) codes, due to their increasingly data-intensive nature and the ever-growing CPU-I\/O performance gap. Portable parallel I\/O benchmarks can help <br\/>(1) application developers to improve their codes' performance, <br\/>(2) HEC storage systems architects to improve their designs, and <br\/>(3) future and current owners of HEC platforms to reduce hardware cost and improve application performance through better system provisioning and configuration. <br\/><br\/>To keep up with the growing scale and complexity of HEC applications, this project develops automated generation of parallel I\/O benchmarks, analogous to the SPEC and NAS benchmarks for computation. Our approach will be embedded in BenchMaker, a prototype tool that takes a real-world, large-scale parallel application and automatically distills it into a compact, human-intelligible, I\/O-intensive, and parameterized benchmark. Such a benchmark accurately reflects the original application's I\/O characteristics and I\/O performance, yet with shorter execution time, reduced need for libraries, better portability, and easy scalability. <br\/><br\/>Benchmarks and tools that benefit the computational science community at large will be produced by this research. These benchmark prototypes will be used for parallel computing course projects and student research contests.","title":"Collaborative Research: Automatic Extraction of Parallel I\/O Benchmarks from HEC Applications","awardID":"0938064","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["438346"],"PO":["565272"]},"158701":{"abstract":"This research project will extend the theoretical foundations of mixture modeling for statistical learning by novel mathematical tools that can probe into the precise geometry of mixture models. Based on the theoretical results, the investigators will develop new approaches to clustering, dimension reduction, variable selection, and temporal analysis. These methods will open promising paths for interactively visualizing complex data and for data summarization. A suite of statistical tools will be integrated as the technical backbone into a new visualization system. Applications to very large-scale, high dimensional, and temporally evolving data will be explored. The principal investigators, with complementary backgrounds in theoretical statistics, computational statistics, and information visualization, will also work with colleagues across multiple departments at Penn State University to test their methods and prototype systems using real-world data sets.<br\/><br\/>In a plethora of scientific and engineering areas with direct and tremendous impacts on our everyday life, such as extreme weather prediction and manufacturing engineering design, researchers are facing gigantic amount of data with great complexity in terms of dimensionality, data types, statistical dependence, and temporal variations. Visualization has played important roles in support of analyzing complex data. Visualization systems help users increase available spatial and cognitive resources, improve searching, enhance pattern recognition, and ultimately make sense of abstract phenomena. This research project aims at fundamentally advancing the mathematical core of visualization systems. The investigators take a probabilistic framework to model data, specifically the mixture model. Mixture modeling provides a highly flexible and theoretically solid basis for summarizing data and automatically extracting patterns from data. This project will develop theories and algorithms for mixture modeling and exploit them to construct new statistical learning and data mining techniques. These statistical methods will thoroughly change the ways visualization systems are designed, offering more functions as well as better functions. Software packages for advanced methods of statistical learning and interactive visualization will be developed and distributed for public use. The proposed research on data visualization and modeling techniques are expected to affect a wide range of fields in science, engineering, and commerce. The applications to hurricane forecast and engineering design can deeply influence our daily life.","title":"New Geometric Methods of Mixture Models for Interactive Visualization","awardID":"0936948","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}}],"PIcoPI":[424112,"554666","430272","430272"],"PO":["565157"]},"157733":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to develop truly intelligent, automated driving through a new paradigm that tightly integrates probabilistic perception and deterministic planning in a formal, verifiable framework. The interdisciplinary approach utilizes three interlinked tasks. Representations develops new techniques for constructing and maintaining representations of a dynamic environment to facilitate higher-level planning. Anticipation and Motion Planning develops methods to anticipate changes in the environment and use them as part of the planning process. Verifiable Task Planning develops theory and techniques for providing probabilistic guarantees for high-level behaviors. Ingrained in the approach is the synergy between theory and experiment using an in house, fully equipped vehicle.<br\/>The recent Urban Challenge showed the current brittleness of autonomous driving, where small perception mistakes would propagate into planners, causing near misses and small accidents; Fundamentally, there is a mismatch between probabilistic perception and deterministic planning, leading to \"reactive\" rather than \"intelligent\" behaviors. The proposed research directly addresses this by developing a single, unified theory of perception and planning for intelligent cyber-physical systems.<br\/>Near term, this research could be used to develop advanced safety systems in cars. The elderly and physically impaired would benefit from inexpensive, advanced automation in cars. Far term, the advanced intelligence could lead to automated vehicles for applications such as cooperative search and rescue. The research program will educate students through interdisciplinary courses in computer science and mechanical engineering, and experiential learning projects. Results will be disseminated to the community including under-represented colleges and universities.","title":"CPS:Medium: Tightly Integrated Perception and Planning in Intelligent Robotics","awardID":"0931686","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["502048","553705",420975,"553547"],"PO":["565136"]},"155687":{"abstract":"Proposal #: CNS 09-23003 <br\/>PI(s): Dandekar, Kapil R. <br\/>Fontecchio, Adam K.; Johnson, Jeremy R.; Kim, Youngmoo E.; Kurzweg, Timothy P.<br\/>Institution: Drexel University <br\/>Title: MRI\/Dev.: Software Defined Communications Testbed for Radio and Optical Wireless Networking<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Project Proposed:<br\/>This project, developing a multi-purpose Software Defined Communications (SDC) testbed to be used for rapid design and prototyping of the next generation wireless communication networks making use of radio, optical, or ultrasonic modalities, responds to the impending need for new high-bandwidth, inexpensive, flexible, and upgradable wireless communication technologies to meet the growing demands of future applications. Among others, the SDC testbed aims to enable many projects including high-speed secure data transmission, thru-metal relay and control networks, localization and tracking, real-time wireless video transmission, and enhanced home entertainment systems. The integrated plan challenges the existing radio frequency centric view of software defined radio by addressing the requirements of high-bandwidth, robustness, and easy configurability for future telecom applications. Supporting multiple signal propagation media within a single framework, the project aims to<br\/>- Develop a modular hardware and software platform which can be used to prototype technology and algorithms for macro- and micro-scale communications, local area networking, and localization applications.<br\/>- Provide software reconfigurability at all layers of the protocol stack (in contrast to conventional SDR which only provides physical layer flexibility) so that cross layer UWB and optical communications techniques can be developed and field-tested.<br\/>- Disseminate transceiver hardware block diagrams and FPGA\/DSP software modules to allow the SDR community to prototype high performance radio, optical, and ultrasonic communications systems.<br\/>- Build propagation channel data repositories for high data rate UWB, optical, and ultrasonic wireless systems which can be used by industry and academia to design and evaluate new algorithms.<br\/>- Demonstrate, experimentally for the first time, the augmentation of UltraWideBand (UWB) multicarrier, UWB impulse radio, diffuse free space optical, line-of-sight optical communications with spectrum-efficient MIMO space-time coding techniques.<br\/><br\/>Broader Impacts: This project offers educational opportunities for graduate and undergraduate students, as well as for K-12 students and teachers. It catalyzes advanced telecommunications development, but also trains and excites future engineers and general public. The project creates an Entrepreneur Development program in ECE; it will be used as a model for undergraduate senior design students in the context of starting a small business; facilitates independent study and cooperative work, and conducts outreach programs with local students and teachers.","title":"MRI: Development of Software Defined Communications Testbed for Radio and Optical Wireless Networking","awardID":"0923003","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["503250","555302","429743","543563","563559"],"PO":["557609"]},"148922":{"abstract":"This proposed project will design, develop, deploy, and operate a virtual Emergency Operations Center (vEOC) for (1) primary use as a research instrument, but with (2) secondary use for training and education. The vEOC, named Ensayo, will enable research on dynamic decision-making, individual and group problem solving, organizational learning, communication, coordination, and knowledge management in the context of roles and organizational structures to enable cross-institutional management of disasters. The vEOC will be web-based implemented using open source and open standards software and tools. Little substantive research has been conducted on large scale, emergent management structures. The size and complexity of these emergent structures affords a unique insight into studying the mechanisms (both successful and less successful) of operation, providing a valid substrate to formulate the components of the vEOC. Our initial research has yielded insights into the role that a vEOC could play in this, and other EOC contexts <br\/><br\/>The fundamental goal of Ensayo is to craft a research instrument that, although based on the elements of a local EOC, can be adapted to reflect a wide variety of EOC forms in order to support research, training and education. One of the collaborating institutions is minority serving, and located where the primary context for this work is important for the well-being of society ? hurricanes and emergency preparedness. Ensayo affords not only a research tool for academics, but also a resource for education, training and policy analysis for communities of practice who engage in any emergency operations event.","title":"Collaborative Research: II-NEW: Ensayo - A Virtual Emergency Operations Center (vEOC)","awardID":"0855078","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[396906,396907],"PO":["564456"]},"157755":{"abstract":"CPS:Small:Mathematical, Computational, and Perceptual Foundations for Interactive Cyber-Physical Systems<br\/><br\/>The objective of this research is to create interfaces that enable people with impaired sensory-motor function to control interactive cyber-physical systems such as artificial limbs, wheelchairs, automobiles, and aircraft. The approach is based on the premise that performance can be significantly enhanced merely by warping the perceptual feedback provided to the human user. A systematic way to design this feedback will be developed by addressing a number of underlying mathematical and computational challenges.<br\/><br\/>The intellectual merit lies in the way that perceptual feedback is constructed. Local performance criteria like stability and collision avoidance are encoded by potential functions, and gradients of these functions are used to warp the display. Global performance criteria like optimal navigation are encoded by conditional probabilities on a language of motion primitives, and metric embeddings of these probabilities are used to warp the display. Together, these two types of feedback facilitate improved safety and performance while still allowing the user to retain full control over the system.<br\/><br\/>If successful, this research could improve the lives of people suffering from debilitating physical conditions such as amputation or stroke and also could protect people like drivers or pilots that are impaired by transient conditions such as fatigue, boredom, or substance abuse. Undergraduate and graduate engineering students will benefit through involvement in research projects, and K-12 students and teachers will benefit through participation in exhibits presented at the Engineering Open House, an event hosted annually by the College of Engineering at the University of Illinois.","title":"CPS: Small: Mathematical, Computational, and Perceptual Foundations for Interactive Cyber-Physical Systems","awardID":"0931871","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550866",421048],"PO":["565227"]},"154004":{"abstract":"This project will integrate new cognitive models of behavioral data based on queueing theory with new machine learning techniques for analyzing neurophysiological data, specifically electroencephalogram (EEG), in order to provide a deeper and more complete understanding of mental states as well as more accurate prediction of human performance. In cognitive modeling, a new brain network architecture for human performance and mental workload, called Queuing Network-Model Human Processor (QN-MHP), will be further improved. QN-MHP with a new human-like small-scale knowledge system will be used to model the increase of myelination in the brain in cognitive development and predict human performance, in terms of subjective risk perception and confidence. In machine learning, new spatio-temporal (pattern-based) classification techniques will be developed for multidimensional time series data and used to identify human mental states (e.g., fully awake, fatigue, distracted, anger) from EEG data. The integrated framework will result in a robust intelligent system that uses machine learning to identify mental states and the queueing model of that mental state to predict the human performance as well as provide a human operator with feedback. A mind-driven intelligent transportation system will be developed as a case study in this project, where a certain type of feedback will be designed to help drivers avoid accidents and to improve system safety. This system can also be applied to other human-machine systems that require full or partial attention of human operators (e.g., in aviation, military, or manufacturing settings).","title":"RI:Small:Collaborative Proposal: Computational Framework of Robust Intelligent System for Mental State Identification and Human Performance Prediction with Biofeedback","awardID":"0916883","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["460530"],"PO":["564318"]},"165499":{"abstract":"Proposal #: CNS 07-09268<br\/>PI(s): Du, Xiaojiang<br\/>Institution: North Dakota State University <br\/> Fargo, ND 58105-5756<br\/>Title: A Heterogeneous Sensor Network Laboratory for Integrated Research and Education<br\/><br\/>Project Proposed:<br\/>This project, building a Heterogeneous Sensor Network (HSN) testbed consisting of 100 low-end and 20 high-end sensors, and 4 workstations, studies the capacity (throughput) and lifetime limits of HSNs. The testbed aims to support the following projects regarding HSNs: <br\/>. Determining Fundamental Performance Limits;<br\/>. Investigating Innovative Network Architectures; and<br\/>. Designing Secure and Efficient Time Synchronization Schemes.<br\/>The former studies capacity (throughput) and lifetime limits to provide insight to the design of better protocols and algorithms. The second project investigates architectures that support reliable and efficient clustering and communications. The latter concentrates on the design of secure and efficient time synchronization schemes. Performance evaluation includes energy consumption, signal strength, communication overhead, computation overhead, storage requirement, data delivery rate (throughput), end-to-end delay, security, etc.<br\/><br\/>Broader Impacts: The infrastructure contributes to attract underrepresented groups (including Native Americans, female, low income, and first generation students) in an EPSCoR state. Is also contributes to military, homeland security, health care, environment, agriculture, manufacturing, and other areas where sensor networks have applications.","title":"CRI: A Heterogeneous Sensor Network Laboratory for Integrated Research and Education","awardID":"1002974","effectiveDate":"2009-09-23","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["563625"],"PO":["564778"]},"158855":{"abstract":"The objective of this research is to develop techniques that utilize solid-state memory technologies from device, circuit, architecture, and system perspectives across I\/O hierarchy in order to exploit their true potential for improving I\/O stack performance in high-performance computing systems. <br\/>I\/O friendly memory system architectures will be developed to enable hybrid processor-memory 3D integrations with largely reduced off-chip I\/O traffic. Adaptive cache management and hotspot prediction methods will be developed to address the low random write performance of solid-state drives, and data processing techniques will be developed to enable run-time configurable trade-offs among solid-state drive performance characteristics. A comprehensive full-system simulation infrastructure will be developed to evaluate and demonstrate the research under diverse high-performance computing workloads.<br\/>The research will facilitate the high-performance computing systems to most effectively utilize existing\/emerging memory and processing technologies to tackle the grand I\/O stack design challenge. It can greatly contribute to enabling high-performance computing systems to stay on track of their historic scaling, and hence benefit numerous real-life applications such as biology, chemistry, earth science, health care, etc. This project will also contribute to the society through engaging under-represented groups, research infrastructure dissemination for education and training, and outreach to high school students.","title":"Collaborative Research: Cross-Layer Exploration of Non-Volatile Solid-State Memories to Achieve Effective I\/O Stack for High-Performance Computing Systems","awardID":"0937794","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["360575"],"PO":["565272"]},"154015":{"abstract":"Speech processing systems, including automatic speech recognition and speaker identification, are the key enabling technologies that permit natural interaction between humans and intelligent machines such as humanoid robots, automated information providers, and similar devices. For example, it is now commonplace to encounter speech-based intelligent agents handle at least the initial part of a query in many types of call center applications. While we have made great progress over the past two decades in overcoming the effects of additive noise in many practical environments, the failure to develop techniques that overcome the effects of reverberation in homes, classrooms, and public spaces is the major reason why automated speech technology remains unavailable for general use in these venues. Reverberation remains one the most difficult unsolved problems in speech recognition in open acoustical environments.<br\/><br\/>This project develops novel approaches that combat the effects of reverberation through two complementary perspectives: contemporary knowledge of human auditory processing and state-of-the art application of statistical source separation techniques that build on techniques in image and music processing. The synergistic development of these approaches is expected to provide substantially improved speech recognition and speaker identification accuracy in reverberant acoustical environments, along with a principled structure that enables us to understand on a much deeper level why the solutions to these problems are effective. This work is expected to have an enormous impact in extending the applicability of automatic recognition of natural and casual speech to highly reverberant environments.","title":"RI: Small: Robust Automatic Speech Recognition in Highly Reverberant Environments","awardID":"0916918","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[409820,409821],"PO":["565215"]},"148944":{"abstract":"Through Grid and Cloud computing, the importance of distributed computing has risen dramatically in recent years, increasing the computational power available to a widening audience of scientific and commercial users. Gains in computing power have caused a drastic increase in the volume of data produced by users, requiring new research on improved management and access to distributed data. These gains also drive the need for efficient scheduling and leasing of computational resources and for adapting current work in machine virtualization to a distributed context. These research directions require the development and evaluation of new models for computational, communication, and storage costs, but existing infrastructure makes model evaluation difficult or impossible, since they are in constant use by other researchers.<br\/>This project addresses these concerns by providing a diverse group of researchers with a Distributed Research Testbed (DiRT) on which to develop and evaluate new technologies. The clusters making up the testbed are located at the University of Chicago, the University of Florida, the University of Hawai?i, the University of Notre Dame, and the University of Mississippi. Unlike working grid environments, we have complete low-level control of the hardware and complete knowledge of where the data and computation are located. We will use the testbed to address problems faced today by the growing number of users of distributed computing. Because high performance computing is essential to the conduct of modern science, this project will have significant impact on research and education in a a wide variety of scientific disciplines.","title":"Collaborative Research: II-New: Distributed Research Testbed (DiRT)","awardID":"0855136","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[396976,396977],"PO":["564778"]},"158866":{"abstract":"This research project aims to understand and develop systems for<br\/>maintaining superlinear indexes for streaming data. A superlinear<br\/>index provides search capability over an abstract space that cannot<br\/>easily be linearized (totally ordered). In contrast, a linear index,<br\/>typified by a B-tree, supports point and range queries on totally<br\/>ordered data.<br\/><br\/>Examples of superlinear indexes include multidimensional indexes,<br\/>which can be over a geometric domain, such as geographic data, or<br\/>which can be over multiple linear indexes; and full text queries,<br\/>which can include searching for a particular word or substring.<br\/><br\/>The superlinear indexes found in today's databases cannot support high<br\/>rates of insertion. On traditional mechanical disk drives, the<br\/>existing superlinear indexes can only support about one hundred<br\/>insertions per second in the worst case. For many important<br\/>applications, that is too slow, and so database users often avoid<br\/>superlinear indexing. Even traditional linear indexes based on<br\/>B-trees cannot support the high insertion rates demanded by many<br\/>databases.<br\/><br\/>This research investigates streaming superlinear indexes, that is,<br\/>indexes that efficiently support full text or multidimensional<br\/>queries, and can be updated at speeds that are related to disk<br\/>bandwidth rather than seeks per second.<br\/><br\/>Among the significant research issues are the following: (1) design<br\/>efficient files structures for streaming superlinear indexes; (2)<br\/>investigate how streaming superlinear indexes might pave the way to<br\/>improved file systems; (3) determine whether cache-oblivious<br\/>algorithms technology can enhance streaming superlinear indexes; and<br\/>(4) program complex data structures for transactions and recovery.<br\/><br\/>If successful, this research will show how to build filesystems that<br\/>achieve dramatically better performance than today's B-tree-based<br\/>filesystems, how to maintain rich geometrical data and<br\/>multidimensional nongeographical databases in real time, and how to<br\/>maintain full-text searchable databases in real time. For example,<br\/>some of today's file systems try to maintain an full-text index to<br\/>find strings in files quickly, but these systems often fall behind at<br\/>high data write rates. A streaming superlinear index would allow such<br\/>a file system to keep up, and would improve the usability of both<br\/>high-end storage systems and relatively small consumer storage systems<br\/>that are nonetheless too large to index with today's indexes.<br\/><br\/>The researchers are developing course materials on streaming indexing<br\/>technology which will be made freely available under the MIT<br\/>OpenCourseWare initiative (http:\/\/ocw.mit.edu).<br\/><br\/>Further information on this project may be found at the project<br\/>web page: http:\/\/supertech.csail.mit.edu\/superlinear-indexes","title":"HECURA: Colaborative: Multidimensional and String Indexes for Streaming Data","awardID":"0937829","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["531670"],"PO":["565136"]},"154147":{"abstract":"The United States is a multi-cultural society, where uses of communication technology have become ubiquitous and routine. Although there has been a substantial amount of research on computer-mediated communication, very little has been said on the issue of cultural differences in assessing the uses and interpretations of current technologies. The very ubiquity of social computing applications makes the study of cultural differences in their use for relational maintenance difficult. Focusing on environments where social relationships are paramount for survival and where computer-mediated communication applications are relatively limited in number can help us examine how cultural preferences, social needs and constraints of available infrastructure shape the use of computer-mediated communication for relational maintenance. The goal of this research is to make empirical and theoretical contributions to ongoing research on cultural differences in the use of computer-mediated communication through the investigations of the role of social media in transnational contexts. This research will also contribute to the development of theory of the basic processes underlying social relationships through empirical investigations of non-western relational maintenance practices.<br\/><br\/>The results of this research will address how cultural differences can shape future development and design of human-centered computing applications and will enhance ongoing efforts to promote design and deployment of computer-mediated communication technologies in digitally nascent societies. By turning attention to the cultural contexts of technology use for relational maintenance, we also seek to engage with people whose perspectives are often unheard, including transnational migrants. Contextual study of Internet and social network site use is especially valuable in a culture that differs from the predominantly Western perspective that developed or provided templates for the development of the majority of current social computing applications.","title":"HCC: Small: From Local Ties to Transnational Connections: The Role of Computer-mediated Communication in Relational Maintenance","awardID":"0917401","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[410143,"464219"],"PO":["564456"]},"154037":{"abstract":"Automating debugging has been a long standing grand challenge.<br\/>Central to automated debugging is the capability of identifying failure causal paths, which are paths leading from the root cause to the failure with each step causally connected. It is key to understanding and fixing a software fault. The project develops a novel scalable debugging technique. Given a failure and the desired output, the technique produces the failure causal path.<br\/><br\/>The following enabling techniques are devised. Given a failure and the desired output, the first technique is to search for a dynamic patch to the failure such that the patched execution generates the desired output. Sample patches include negating the branch outcome of a predicate execution. The second technique is to align the failing and the patched executions to facilitate later comparison. It consists of control flow alignment and memory alignment. Two runs may differ in control flow so that correspondence between execution points need to be established. A data structure may be allocated to different memory locations so that memories also need to be aligned. The third technique is to efficiently compare the program states of the two runs at the aligned places to generate the causal path. The ramifications include reducing resource consumption of debugging and improving software productivity and dependability.","title":"CSR: Small: Automated Software Failure Causal Path Computation","awardID":"0917007","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["550848"],"PO":["564388"]},"165048":{"abstract":"The ability to make meaning out of a visual world, such as recognizing objects, scenes and semantically meaningful activities and events, is a cornerstone of artificial intelligence. In computer vision, very important progress has been made recently in object and scene level recognition. But such tasks are often performed without an integrated and coherent description of the scene. Moreover, very few current algorithms are capable of further interpreting higher level semantic meanings of an image such as an event or activity. The goal of this project is to achieve event classification via an integrated image understanding given a single unknown image.<br\/>This project aims to push the frontier of integrated and descriptive understanding of images through the development of sophisticated learning frameworks suitable for training algorithms by using a large amount of real-world data such as the ones from the Internet. High accuracy performance, minimal human supervision, flexibility and scalable learning will be the focus of this endeavor. This project?s theoretical framework ties together several areas of computer vision, offers interesting model representations for the machine learning field, and connects more semantically driven visual recognition problem with the natural language processing field. <br\/>The results are vital for image understanding technology for the visually- impaired; automatic annotation of images for large digital library as well as the next generation of image retrieval engines; and translation, education and rehabilitation technology for language students and medical patients (such as aphasia, stroke, etc.). <br\/>The project?s long-term educational plan focuses on bringing the latest visual computation and cognition research directly into the classroom and the community at large, with an emphasis on reaching the underrepresented groups of students.","title":"CAREER: Telling the Story of a Visual World: Event Classification and Integrated Image Understanding","awardID":"1000845","effectiveDate":"2009-09-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["485283"],"PO":["564316"]},"148966":{"abstract":"This proposed project will design, develop, deploy, and operate a virtual Emergency Operations Center (vEOC) for (1) primary use as a research instrument, but with (2) secondary use for training and education. The vEOC, named Ensayo, will enable research on dynamic decision-making, individual and group problem solving, organizational learning, communication, coordination, and knowledge management in the context of roles and organizational structures to enable cross-institutional management of disasters. The vEOC will be web-based implemented using open source and open standards software and tools. Little substantive research has been conducted on large scale, emergent management structures. The size and complexity of these emergent structures affords a unique insight into studying the mechanisms (both successful and less successful) of operation, providing a valid substrate to formulate the components of the vEOC. Our initial research has yielded insights into the role that a vEOC could play in this, and other EOC contexts <br\/><br\/>The fundamental goal of Ensayo is to craft a research instrument that, although based on the elements of a local EOC, can be adapted to reflect a wide variety of EOC forms in order to support research, training and education. One of the collaborating institutions is minority serving, and located where the primary context for this work is important for the well-being of society - hurricanes and emergency preparedness. Ensayo affords not only a research tool for academics, but also a resource for education, training and policy analysis for communities of practice who engage in any emergency operations event.","title":"Collaborative Research:II-NEW: Ensayo - A Virtual Emergency Operations Center (vEOC)","awardID":"0855193","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[397037],"PO":["550147"]},"154048":{"abstract":"Access control is one of the key aspects of information security. In<br\/>the past decade and a half, significant progress has been made in<br\/>increasing the assurance and expressiveness offered by access-control<br\/>systems, in large part through the use of formal logics to model or<br\/>implement these systems.<br\/><br\/>A particular challenge in building access-control systems is to allow<br\/>delegation between domains that use different authorization logics.<br\/>This project focuses on developing a framework for interfacing<br\/>different, mutually incompatible authorization logics. The framework<br\/>provides an interface for communication between logics via a very<br\/>small set of primitives that imposes no fundamental constraints on the<br\/>design of the logics that use it. Part of this framework will be an<br\/>architecture to facilitate the automated construction of proofs of<br\/>access.<br\/><br\/>Another barrier to implementing logic-based access-control systems is<br\/>that substantial effort is typically required to retrofit existing<br\/>systems to support the use of theorem provers, proof checkers, and<br\/>associated infrastructure. This project will investigate several<br\/>approaches to solving this problem, including automated program<br\/>rewriting and automated construction of lightweight theorem provers<br\/>and proof checkers.","title":"Enabling Practical Cross-domain Logic-based Access Control","awardID":"0917047","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["563508"],"PO":["565264"]},"148977":{"abstract":"The goal of this project is to acquire and integrate Biomedical Computing Infrastructure (BCI) capable of processing the increasingly high-resolution, large-volume, and high-frequency digital content generated within biomedical applications. The BCI will comprise: a large NVIDIA processor-based Tesla cluster with double precision Graphics Processing Units (GPUs) along with a multi-node NEC Nehalem-based cluster to drive the Tesla cluster via Infiniband; large shared memory multi-core computer nodes; and a large parallel high-performance solid-state disk farm. <br\/><br\/>Intellectual Merit: While parallel- and grid-computing is relatively well understood, effective use of a cluster of massively multi-core GPUs with large memory, and fast disk access has as yet been minimally explored. Thus, the BCI seeks to facilitate deployment of this transformational computational paradigm in ongoing biomedical research projects between the University at Buffalo, SUNY and the Roswell Park Cancer Institute. These projects encompass the gamut of biomedical computing from: virtual surgery and intervention; image segmentation and labeling; computer tomography and reconstruction; imaging biomarkers and computer-aided diagnosis; to nuclear molecular imaging.<br\/><br\/>Broader Impact: This BCI empowers a large group of multidisciplinary researchers to unlock the full potential of the digital content in the biomedical enterprise as well as attain faster and more reliable transfer of science from the lab to the clinic. In addition, a vibrant dissemination and outreach effort has been planned around the BCI, involving classes, tutorials and workshops, to engage students and researchers of all ages. Many of these activities forming the foundation of the team?s outreach efforts, ranging from the high-school summer institutes to conference workshops, have already been initiated and the web-portal documents these efforts (http:\/\/www.cse.buffalo.edu\/~vipin\/nsf\/cri2009\/).","title":"II-NEW: Acquisition of BCI - A Biomedical Computing Infrastructure","awardID":"0855220","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["510422","558152","550248",397081,397082],"PO":["563751"]},"158899":{"abstract":"Abstract <br\/>Emerging high-end computing platforms, such as leadership-class machines at the petascale, provide new horizons for complex modeling and large-scale simulations. These machines are used to execute data intensive applications of national interest such as climate modeling, cosmic microwave background radiation, and astrophysical thermonuclear flashes. While these systems have unprecedented levels of peak computational power and storage capacity, a critical challenge concerns the design and implementation of scalable I\/O (input-output) system software (also called I\/O stack) that makes it possible to harness the power of these systems for scientific discovery and engineering design. Unfortunately, currently, there are no available mechanisms that accommodate I\/O stack-wide, application-level QoS (quality-of-service)specification, monitoring, and management. <br\/><br\/>This project investigates a revolutionary approach to the QoS-aware management of the I\/O stack using feedback control theory, machine learning, and optimization. The goal is to maximize I\/O performance and thus improve overall performance of large scale applications of national interest. The project uses (1) machine learning and optimization to determine the best decomposition of application-level QoS to sub-QoSs targeting individual resources, and (2) feedback control theory to allocate shared resources managed by the I\/O stack such that the specified QoSs are satisfied throughout the execution. The project tests the developed I\/O stack enhancements using the workloads at NCAR, LBNL and ANL systems. It also involves two efforts in broadening participation: CISE Visit in Engineering Weekends (VIEW) and NASA-Aerospace Education Services Project (NASA-AESP) at the Center for Science and the Schools (CSATS).","title":"Collaborative Research: Adaptive Techniques for Achieving End-to-End QoS in the I\/O Stack on Petascale Multiprocessors","awardID":"0937939","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["562541"],"PO":["565272"]},"146568":{"abstract":"Proposal Number: 0845896<br\/><br\/>PI: Marco Gruteser<br\/>Institution: Rutgers University<br\/>Title: CAREER: User-Controlled Wireless Privacy via Client-Oriented De-Identification<br\/><br\/><br\/>Abstract<br\/><br\/>This project addresses the challenge of strengthening control over location privacy for users of wireless devices such as smartphones. As these devices and their network services continuously monitor our environment, they enable many novel applications with tremendous societal benefits. However, they also raise significant privacy challenges by making it difficult for users to control when information about their whereabouts can be sensed or revealed. <br\/>To address this challenge, this project studies the hitherto relatively unexplored concept of incorporating a comprehensive set of de-identification techniques into clients, which limit device-specific information that could allow extended tracking and eventually identification of the device?s user. <br\/><br\/>Project results are expected to lead to novel models that relate parameters such as spatio-temporal precision and accuracy, sampling frequency, and the presence of pseudo-identifiers to tracking and identification risks. These models complement existing models for transactional database records and can be used to inform users about their current level of privacy or guide system designers. In addition, the project is expected to provide fundamental insights on physical layer techniques that limit the accuracy with which infrastructure location sensors can locate a transmitting client, and techniques that can automatically detect candidate pseudoidentifiers in transmitted messages. The project also strengthens Rutgers University?s electrical and computer engineering curriculum by incorporating privacy and wireless mobile system topics. It further includes industry collaboration and an outreach plan in collaboration with New Jersey's Liberty Science Center to attract high school students from underrepresented groups to the computer engineering profession.","title":"CAREER: User-Controlled Wireless Privacy via Client-Oriented De-Identification","awardID":"0845896","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553648"],"PO":["565327"]},"146337":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>A storage-centric heterogeneous sensor network (SC-HSN) consists of a large number of resource-poor sensor nodes at the lower tier and relatively fewer powerful master nodes at an upper tier. Sensor nodes produce and submit data to nearby master nodes which then answer the queries from the network owner on behalf of sensor nodes. SC-HSHs are ideal data sensing solutions in remote and extreme environments such as oceans, volcano, animal habitats, and battlefields. In such adverse environments, it is often impossible or prohibitive to maintain a stable always-on communication connection from the sensor network to the external network owner, and thus in-network data storage is a must such that data continuously produced by sensor nodes are stored inside the network and await ad-hoc queries via an on-demand communication connection.<br\/><br\/>This project studies some fundamental open challenges associated with dependable data management in SC-HSNs. Specifically, there are three main thrusts in this project: (1) Distributed Fault-Tolerant Data Storage; (2) Privacy-Preserving Data Access Control; and (3) Verifiable Queries over Encrypted Data. The outcome of this research will advance the state of the art in data management in WSNs and provide an integrated solution to reliable, secure, efficient data storage and retrieval in SC-HSNs. The results of this project will also provide great insights for dependable data management in other types of emerging wireless networks such as mobile ad hoc networks, wireless mesh networks, and vehicular networks. The results of the project will be disseminated widely through publications and talks, and the proposed research will also be integrated with the education curricula.","title":"CAREER: Dependable Data Management in Heterogeneous Sensor Networks","awardID":"0844972","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550852","551041"],"PO":["565303"]},"148999":{"abstract":"The activity of visualizing and exploring complex multi-dimensional data provides insight that is essential for progress in several areas of science and engineering, where the amount and complexity of the data overwhelms traditional computing environments. This project will develop the first complete version of the Allosphere, an infrastructure that will provide powerful methods for detailed analysis, synthesis, and manipulation of such data by integrating multimodal representations of large-scale data with human-scale visualization and interaction techniques in a novel immersive environment.<br\/><br\/>Intellectual Merit: The Allosphere comprises a 10m diameter spherical display surface in a three-story near-anechoic building space, with a bridge running through the center that holds up to 25 participants. When fully equipped, the Allosphere will include high-resolution stereo video projectors to illuminate the complete spherical display surface, a large array of speakers distributed outside the surface to provide high quality spatial sound, a suite of sensors and interaction devices to enable rich user interaction with the data and simulations, and the computing infrastructure to enable the high-volume computations necessary to provide a rich visual, aural, and interactive experience for the users. The Allosphere will be one of the largest visualization\/exploration instruments in the world, and it will serve as an ongoing research testbed for several important areas of computing. In addition, the Allosphere will serve as an environment for experimental media creation and performance, as a tool for scientific discovery in areas such as nanosystems, neuroscience, quantum computing, and biochemistry, and as an instrument for education and outreach.<br\/><br\/>Broader Impacts: This infrastructure project will complete the audio, interaction, and computational infrastructure of the Allosphere. This first version will serve as a computing research infrastructure in two primary ways: (1) as a platform for driving computing research needed to create future immersive multimodal, multimedia visualization environments, raising challenging problems in storage, networking, rendering, software virtualization, real-time simulation, and human-computer interaction; and (2) as an immersive visualization environment for research in computing areas such as scientific and information visualization, knowledge discovery, visual analytics, complex design, large-scale performance debugging, data mining, and cloud computing. As infrastructure for both computing and scientific exploration, the Allosphere will benefit a number of important fields that have wide impact on society. The facility will be made available to researchers and partners (in academia, industry, and government) beyond UCSB. The project will also leverage local outreach programs to attract K-12 students, underrepresented groups, and undergraduate students, and involve them in scientific projects and explorations that utilize this unique immersive environment. The facility will be integrated into courses and research projects in several departments at UCSB. Results will be disseminated via the project Web site (http:\/\/allosphere.ucsb.edu).","title":"II-NEW: Equipping the Allosphere, an Environment for Immersive Data Exploration","awardID":"0855279","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["402357","466630","558448","561463","518684"],"PO":["563751"]},"159306":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940537","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":[425868],"PO":["561855"]},"150891":{"abstract":"The design of computational systems that support group decisions, allocate resources to distributed tasks, or mediate social interactions is fundamentally different from the corresponding design problem serving individual or centralized users. When multiple parties, or agents, are involved, the designer's objectives are complicated by the fact that the interests of these parties are rarely, if ever, perfectly aligned. The field of mechanism design offers a theoretical framework that directly addresses the issue of incentives as it relates to the design of multiagent systems. However, this purely analytical approach carries with it inherent practical limitations. The investigators introduce a new approach, empirical mechanism design (EMD), whose premise is to extend the basic foundation of mechanism design with empirical methods such as simulation and statistical analysis. These extensions promise to dramatically expand the scope of mechanism design beyond the small-scale, stylized, or idealized domains to which it has been predominantly limited to date.<br\/><br\/>The project will investigate several concrete EMD problems, within the general theme of market design. Improved market design has significant implications for the public and private sectors. In public policy, market-based approaches are likely to play a major role in, for example, instituting measures to cope with climate change, banking reform and regulation, and adoption of new energy sources. In the commercial domain, new markets for advertising placement, computational services, and other goods will also entail significant mechanism design efforts. Regardless of the sector, design outcomes bear on important social objectives including efficiency, transparency, and stability (e.g., of financial relationships). An empirical basis for evaluating candidate mechanisms will complement existing theoretical perspectives, enriching the tools available to designers and other stakeholders.","title":"RI: Medium: Collaborative Research: Methods for Empirical Mechanism Design","awardID":"0905139","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["563733"],"PO":["565251"]},"153960":{"abstract":"This project is an investigation into algorithms and mechanisms that will allow sophisticated staging of input and output data in desktop grids. Data staging allows the system to store data semi-permanently in the underlying peer-to-peer structure, and to run multi-node jobs (applications) whether they be tightly-coupled parallel applications, arbitrary work-flows, or anything between.<br\/>We are building support for these application types by extending our current desktop grid infrastructure in three distinct areas. We are developing cluster identification techniques that can define arbitrarily-sized virtual clusters through both passive and active network measurement. We are incorporating virtual cluster descriptions into the underlying peer-to-peer infrastructure to allow the scheduling algorithms to map multi-node jobs to the clusters. Finally, we are incorporating data placement into the underlying infrastructure; data is placed according to use and process binding.<br\/>This work will impact several research areas, including that of distributed and decentralized scheduling, application description, network characterization, and storage networks. In all of these areas our work will explore the tension between local autonomy and global, aggregate objectives.<br\/>The algorithms and techniques will have broad applicability across a wide range of emerging distributed and collaborative applications. However, the work described here will also explicitly and immediately impact the quality of research conducted by our collaborators in astronomy and elsewhere. The ability to run parallel applications, and those with more complicated inter-relationships, will enable whole new classes of scientific applications to be run on top of ad-hoc grid-like systems.","title":"CSR: Small:Data Staging and Parallel Applications in Robust Desktop Grids","awardID":"0916742","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559445","485350",409678],"PO":["565255"]},"150451":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to address the computational challenges in multi-core power distribution design by leveraging recent advances in single-instruction multiple-data (SIMD) graphics processing units (GPUs). The approach is to develop a massively parallel GPU-accelerated design engine to facilitate the analysis, design and verification of power-gated multi-core on-chip power delivery networks encompassing both electrical and thermal integrity issues. <br\/><br\/>Intellectual Merit: Aggressive fine-grained power gating is essential to pushing the performance vs. power envelope of current and future multi-core chip designs. This need introduces significant challenges in the design and verification of power delivery networks under complex power gating scenarios. While the recent GPU advances provide a potentially promising computing solution, the effective use of such SIMD compute power requires rethinking computed-aided design. In this work, GPU-specific computing paradigms, algorithms and implementations will be developed to address multi-core power distribution design and associated full-chip thermal challenges via efficient parallel computing on low-cost SIMD graphics processors. <br\/><br\/>Broader Impacts: This work exploits recent SIMD GPU based massively parallel platforms for addressing CAD challenges. The acquired experience is likely to contribute to computing advances in other science and engineering fields. The PI will promote the research participation from undergraduate students and students from underrepresented groups. The outcomes of this work will be integrated into the PI's graduate-level VLSI courses to provide educational and research experiences to students. The developed algorithms and methodologies will be disseminated in the research community at large and major semiconductor and EDA companies for potential industrial application.","title":"Thermal-Aware GPU-Based Design Engine for On-Chip Power Delivery in Power-Efficient Multi-Core Chips","awardID":"0903485","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["486370"],"PO":["565185"]},"153850":{"abstract":"The emergence of affordable, high performance networking technology like InfiniBand is fueling the growth of high-end computing (HEC) systems. However, there are no schemes in these systems to provide a minimal Quality of Service (QoS) for the execution of parallel jobs by taking network-level contention into account. InfiniBand provides feature-rich QoS mechanisms. The research focuses on the following novel research directions: 1) How to take advantage of InfiniBand QoS mechanisms to design a QoS-aware MPI library? 2) How to take advantage of these mechanisms to design a QoS-aware parallel file system? 3) How to dynamically provide QoS by monitoring network traffic and making adjustments to virtual lane arbitration at InfiniBand's switch and adapter hardware? 4) How to design and establish job priority guidelines with the proposed QoS framework? and 5) What kind of performance, scalability, efficiency and productivity benefits can be achieved by this proposed QoS framework with petascale applications? The transformative impact of the research enables next generation InfiniBand clusters and applications to be QoS-aware and highly efficient in addition to delivering performance and scalability. The research has significant impact on the design, deployment, and utilization of next generation ultra-scale systems with QoS support.","title":"SHF: Small: Designing QoS-Aware MPI and File Systems Protocols for Emerging InfiniBand Clusters","awardID":"0916302","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["561947"],"PO":["565272"]},"153971":{"abstract":"Increasingly, automated economic transaction systems in eBay, Google and other institutions negotiate, buy and sell goods, services, advertisements etc. They use auctions to make decisions including pricing, allocation and optimization. As a result, we now have auctions systems far greater in scale than the traditional \"human scale\" of negotiations and specialized auctions, and they impact our lives in sophisticated ways. These systems face many algorithmic challenges in the interface of Economics, Learning Theory, and Optimization, which is the focus of this project.<br\/><br\/>In this project researchers will (a) design and analyze models for the various parties (users, auctioneer, buyer and seller) and their impact on the auctions; (b) design and analyze mechanisms in the presence of parties with mixed utilities that go beyond the traditional linear profit; (c) quantify impacts of budgets in mechanisms on truthfulness, equilibria and utilities, which has been traditionally underemphasized; (d) study the effect of bounded computational power and rationality on mechanisms; (e) design richer mechanisms for futures, combinatorial goods as well as dynamic settings; (f) study privacy, security and verifiability of auction mechanisms; (g) study the various learning and optimization problems that are fundamental to the tasks above.<br\/><br\/>This project ultimately addresses the questions of how various parties with natural knobs (budget, utility) interact with automated economic transaction systems, how information is learned, used and controlled in such systems, and how these systems will evolve over the long term. The project explores these questions via the specific research tasks above, as well as via training undergraduate and graduate students to work in the interface of Economics, Optimization and other areas.","title":"AF: Small: Computer Science and Decision Making","awardID":"0916782","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7948","name":"QUANTUM COMMUNICATION"}}],"PIcoPI":["540234","264120","507886"],"PO":["565251"]},"153862":{"abstract":"The trend towards multi-\/many- core design has made network-on-chip (NoC) a crucial hardware component of future microprocessors. With the continuous down-scaling of CMOS processing technologies, reliability is becoming a primary target in NoC design. Negative Bias Temperature Instability (NBTI) is a critical reliability threat for deep sub-micrometer CMOS technologies. NBTI increases the PMOS transistor threshold voltage and reduces the drive current, causing failures in logic circuits and storage structures due to timing violations or minimum voltage limitations. Meanwhile, process variation (PV) - the divergence of transistor process parameters from their design specifications - caused by the difficulty in controlling sub-wavelength lithography and channel doping as CMOS manufacturing technology scales, results in variability in circuit performance\/power and has become a major challenge in the design and fabrication of future microprocessors and NoCs. Since NBTI and PV affect both NoC delay and power, it is imperative to address these challenges at the NoC architecture design stage to ensure its efficiency as the underlying CMOS fabrication technologies continue to scale. <br\/><br\/>The goal of this project is to develop techniques for designing novel, cost-effective router microarchitectures and adaptive routing schemes that mitigate NBTI and PV impact on NoCs by leveraging the interplay between the two. The scalability and sustainability of future many-core processors crucially depend on the dependability of NoCs. Mechanisms that can simultaneously tolerate PV and NBTI will be investigated for enhancing the reliability of NoCs fabricated using nanoscale transistor technologies. The educational and outearch activities include recruiting graduate and undergraduate students from under-represented groups for this project and integration of research and education.","title":"SHF: Small: Leveraging the Interplay between Process Variation and NBTI in Nanoscale Reliable NoC Architecture Design","awardID":"0916384","effectiveDate":"2009-09-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["540130","550720"],"PO":["565157"]},"153983":{"abstract":"The goal of this project is to design a scalable and robust system for modeling and representing the spatiotemporal and semantic structure of large collections of partially geo-referenced imagery. Specifically, the project is aimed at Internet photo collections of images of famous landmarks and cities. The functionalities of the system include 3D reconstruction, browsing, summarization, location recognition, and scene segmentation. In addition, the system incorporates human-created annotations such as text and geo-tags, models scene illumination conditions, and supports incremental model updating using an incoming stream of images. This system is designed to take advantage of the redundancy inherent in community photo collections to achieve levels of robustness and scalability not attainable by existing geometric modeling approaches. The key technical innovation of the project is a novel data structure, the iconic scene graph that efficiently and compactly captures the perceptual, geometric, and semantic relationships between images in the collection.<br\/><br\/>The key methodological insight of this project is that successful representation and recognition of landmarks requires the integration of statistical recognition and geometric reconstruction approaches. The project incorporates statistical inference into all components of the landmark modeling system, and includes a significant layer of high-level semantic functionality that is implemented using recognition techniques.<br\/><br\/>Potential applications with societal impact include virtual tourism and navigation, security and surveillance, cultural heritage preservation, immersive environments and computer games, and movie special effects. Datasets and code produced in the course of the project will be made publicly available. The project includes a significant education component through undergraduate and graduate course development.","title":"RI: Small: Modeling and Recognition of Landmarks and Urban Environments","awardID":"0916829","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"K576","name":"National Security Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"L582","name":"National Security Agency"}}],"PIcoPI":["541984","562635"],"PO":["564316"]},"153752":{"abstract":"The rapidly increasing number of individuals suffering from chronic diseases is placing an unprecedented demand on the traditional healthcare. The medical care costs of people with chronic diseases account for more than 75% of the estimated $1.4 trillion for medical care costs in the United States. Yet, there are significant challenges in creating technologies that enable individuals to proactively manage their health and that enable physicians, therapists and educators to effectively and efficiently treat people with chronic, long-term health challenges. This research examines the role of personal health technologies for individuals and health care practitioners engaged in chronic disease management and disease prevention and wellness. Building on our initial research in technologies for diabetes management, we propose four threads of inquiry that are integrated into our research activities: (1) Mobile Technologies for Personalized Health, (2) Automated Techniques for In-The-Moment Health Advice, (3) Tools for Experimentation, and (4) Measurement Techniques to Assess Personal Health Care Technologies. <br\/><br\/>The broad goal is to design technologies that help people take ownership of their own health and wellness. Advancing the use of information technologies outside of the scope of traditional critical care is of paramount importance for making progress in this thorny area. Research results will begin to push the influence of health technologies ?up the chain? from disease management to disease prevention and wellness.","title":"HCC: SMALL: Technologies for Nutrition and Diabetes Management","awardID":"0915934","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["506686",409156],"PO":["564456"]},"153873":{"abstract":"This proposed project will develop a framework for organizing images that allows the specific types of relationships between those images to be represented, manipulated, highlighted, enhanced, and studied. The technical challenges involve building new representational and algorithmic systems to capture the major \"longitudinal categories\" that relate heterogeneous images to each other within collections. The problem of relationship between images is normally posed through registration, which is most often highly contextualized. This work will capture the steps necessary to specify registration as a metadata construction that enables a range of granularities in mapping images to each other, and heterogeneous relationship across organizational categories such as time (diachronic), multi-modal, and instances related by a semantic object. The work is highly interdisciplinary and results can be generalized to other problem sets.","title":"III: Small: FoLIO - Framework for Longitudinal Image-based Organization","awardID":"0916421","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["494196"],"PO":["563751"]},"152542":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Proposal#: 0910767 <br\/>Collaborative Proposal #s: 0909980, 0910483, 0910653 <br\/>Title: TC: Large: Collaborative Research: Trustworthy Virtual <br\/>Cloud Computing <br\/>PIs: Peng Ning, Xuxian Jiang, and Mladen Vouk <br\/>Abstract: <br\/><br\/>Virtual cloud computing is emerging as a promising solution to IT <br\/>management to both ease the provisioning and administration of complex <br\/>hardware and software systems and reduce the operational costs. With the industry?s continuous investment (e.g., Amazon Elastic Cloud Computing, IBM Blue Cloud), virtual cloud computing is likely to be a major component of the future IT solution, which will have significant impact on almost all sectors of society. The trustworthiness of virtual cloud computing is thus critical to the well-being of all organizations or individuals that will rely on virtual cloud computing for their IT solutions. <br\/><br\/>This project envisions trustworthy virtual cloud computing and investigates fundamental research issues leading to this vision. Central to this vision is a new security architecture, which harnesses new opportunities and capabilities such as built-in out-of-band system <br\/>access, processor and hardware support for trusted computing, and out-of-box examination by hypervisors. This project focuses on key research issues following this security architecture, including new security services that enhance the trustworthiness of virtual cloud computing, protection of management infrastructure against malicious workloads, and protection of hosted workloads from potentially malicious management infrastructure. The research will enable the adoption of virtual cloud computing for critical IT management in industry and government organizations. This project will involve both graduate and undergraduate students, and will produce open source software and tools, which will be made available to the public.","title":"TC: Large: Collaborative Research: Trustworthy Virtual Cloud Computing","awardID":"0910653","effectiveDate":"2009-09-15","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553906"],"PO":["565327"]},"153994":{"abstract":"Parallel corpora, i.e. texts that are translations of each other, are an important resource for many natural language processing tasks, and especially for building data-driven machine translation systems. Unfortunately, for the majority of languages, parallel corpora are virtually non-existent. To be able to develop machine translation systems for those languages, we need to be able to learn from non-parallel corpora. Comparable corpora ? i.e. documents covering at least partially the same content ? are available in far larger quantities and can be easily collected on the Web. Examples include news published in many languages by Voice of America or BBC, and the multi-lingual Wikipedia.<br\/>To make best use of comparable corpora it is not sufficient to extract sentence pairs, which are sufficiently parallel, thereby building a parallel corpus and then using proven training procedures. Rather, new techniques are required to find sub-sentential translation equivalences in non-parallel sentences. To extract phrase pairs from comparable corpora requires a cascaded approach:<br\/>- find comparable documents using, for example, cross-lingual information retrieval techniques;<br\/>- detect promising sentence pairs, i.e. those, which may contain translational equivalences; <br\/>- apply robust phrase alignment techniques to detect phrase translation pairs within non-parallel sentence pairs;<br\/>The main focus of the project lies on this third step: developing novel alignment algorithms, which do not rely on aligning all words within the sentences, as traditional word alignment algorithms do, but can separate parallel from non-parallel regions.<br\/>The long term benefit of this work will be that machine translation technology can be applied to those languages, for which so far no translation systems are available, due to the lack of the language resources required by current technology. This will enable communication across language barriers, esp. in critical situations like medical assistance or disaster relieve.","title":"RI-Small: Exploiting Comparable Corpora for Machine Translation (CC4MT)","awardID":"0916866","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["467050"],"PO":["565215"]},"153763":{"abstract":"The proposed work explores techniques for making static analysis tools<br\/>more effective in the hands of users. This will lead to the<br\/>development of new static analysis algorithms, techniques, and<br\/>interfaces that provide the information users need to find, verify,<br\/>and fix defects.<br\/><br\/>The core of the proposed work will be a framework for static analysis<br\/>visualization and interaction, with several components. First, the<br\/>framework will include checklists to help users triage defect reports,<br\/>i.e., decide whether they are true or false positives. The aim is to<br\/>develop ways to instrument static analyses to automatically generate<br\/>checklists based on imprecision introduced during the analysis.<br\/>Second, the framework will include lightweight query and search<br\/>facilities to help users work with static analysis tool results. Users<br\/>need effective ways to query the knowledge-base generated by a tool<br\/>when trying to understand an error report; current static error<br\/>reports tend to provide too little or too much information. Third, the<br\/>framework will include a generic visualization for program paths, a<br\/>core part of many static analysis tools' defect reports. While some<br\/>tools include simple path visualization, our framework will aim for<br\/>far more effective interfaces by applying information visualization<br\/>principles.","title":"SHF: Small: User-Centered Software Analysis Tools","awardID":"0915978","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["550282","556281","410225"],"PO":["565264"]},"153884":{"abstract":"This proposal explores how individuals decide what online information to trust given the uncertain information they often encounter. In today's society, life experiences are often processed in an online world. Online resources provide information and support for parenting, health, hobbies, news, and more. However, online resources are often incomplete, may include a diversity of opinions, and may be inaccurate. In a connected series of research studies exploring general theoretical questions, this project focuses on a compelling and common example of uncertainty online - the uncertainty about treatments for a chronic health condition. Chronic disease is a leading cause of ill health world wide, and one in ten Americans lives with a life-altering chronic condition. Unlike acute conditions (such as a high fever), chronic conditions, such as HIV, diabetes, arthritis, and Lyme disease, are prolonged and rarely cured completely. For this reason, management of chronic conditions lies much more in the hands of the patient.<br\/><br\/>This research will study online health resources and individuals' use of these online resources using interview data, survey data, and text analysis of thousands of pages and posts available in online content. First, it will characterize the uncertainty of different types of online resources. Second, it will focus on how uncertainty impacts a specific community characterized by highly uncertain and even controversial information about the disease process and treatment (the Lyme disease community). And third, the research will test the generalizability of results in a complementary setting (such as individuals with chronic arthritis). The empirical work will answer the following questions: 1) How does the existence of incomplete, divergent and\/or conflicting information affect the health choices made by individuals with chronic illness? 2) What factors (community, time, exposure to information) are critical to an individual with chronic illness deciding whether to believe in a specific viewpoint?<br\/><br\/>The results will drive the design of two technological interventions that can improve people's ability to understand and decide among online resources: (1) A tool to extract and highlight key parameters of decision making derived from the research, that will crawl relevant sources and extract information such as patient consensus, medical research timeline, and risks. (2) A tool to classify online resources in terms of viewpoint, leveraging machine-learning techniques such as co-training to learn classifications on the fly. The second tool will inform the first, but also provide an interface for sorting and filtering online information and compare the information cloud associated with different viewpoints. The results of this research will add to existing knowledge about how the Internet can support individuals with chronic conditions, and contribute to the development of curriculum for courses on human-computer interaction in the medical area.","title":"HCC: Small: Helping People Negoiate Uncertain Information Online","awardID":"0916459","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["518044"],"PO":["564456"]},"153532":{"abstract":"Computational mechanism design has been highly successful in providing a theoretical and practical framework for coordinated decision making in systems with multiple, self-interested agents. A key property introduced within mechanism design theory is that of \"incentive-compatibility,\" namely that it is an agent's best interest to truthfully reveal private information about its preferences for different outcomes even in settings of strategic interdependence. However, there has been relatively little attention given to the use of incentive mechanisms for the purpose of coordinating computational processes, where the inputs to the computation are distributed across agents. The focus of this project is on the problem of incentive-compatible learning, where the private information of agents represents \"training data\" and the design goal is to allow the system to collectively learn from the distributed experience that this information represents.<br\/><br\/>The research seeks mechanisms that promote learning with self-interested agents that is just as effective as it would be with cooperative agents, and to otherwise understand when this is not possible. It will provide a new bridge between mechanism design theory and computer science. The research is centered around three themes: (1) incentive-compatible reinforcement learning, where the design goal is to quickly learn an optimal policy for the entire state space when each agent has private information about the rewards for some subset of the state space and may misreport them; (2) incentive-compatible supervised learning, where each agent has private knowledge of a set of labeled training examples and the design goal is to learn a hypothesis that minimizes global error despite agents' ability to misreport training data; (3) incentive-compatible information aggregation, where each agent has a subjective belief about the probability of some uncertain events and participates in a mechanism to capitalize on its information, and the design goal is to achieve online aggregation of information despite the intrinsic self-interest of agents. This project has the potential for broad spillover benefits to societal, engineering, and business settings where learning is performed with self-interested agents.","title":"HCC: Small: Incentive-Compatible Machine Learning","awardID":"0915016","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["541779","541778"],"PO":["565251"]},"153653":{"abstract":"Abstract <br\/>With the advances of modern computer architectures, interconnects are playing an ever increasingly important role for providing an effective communication medium. Advanced optical switching technologies, such as optical packet switching and wavelength-division-multiplexing, provide a platform to exploit the huge capacity of optical fiber to meet the increasing needs. This research proposes a new switching paradigm - optical cut-through with electronic packet buffering, and systematically investigates the fundamental and challenging issues in the optical interconnect under this switching scheme, with the objective of designing cost-effective, ultra-low latency and pragmatic interconnects for future high-performance computing and communications systems. <br\/><br\/>A unique feature of the proposed interconnect is that those packets that do not cause contention can pass the interconnect directly in optical form and experience minimum delay, while only those that cause contention are buffered. This research proposes to combine optical packet switching with electronic buffering, such that the interconnect will enjoy both fast switching and large buffering capacity. This research will (1) design the switching fabric and packet scheduling algorithms, (2) design practical Forward Error Control (FEC) for the interconnect, and (3) conduct extensive performance evaluations by means of simulation and emulation tools and analytical models. The outcome of this project will have a significant impact on fundamental design principles and infrastructures for the development of future high-performance computing and communications systems. The PIs will integrate graduate and undergraduate students into the project and promote the participation of female and minority students. The findings will be disseminated to the research community by way of conferences, journals, and web site access.","title":"SHF: Small: Collaborative Research: Ultra Low Latency Optical Packet Switched Interconnects with Novel Switching Paradigm","awardID":"0915495","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["537230"],"PO":["366560"]},"153774":{"abstract":"The goal of this research is the investigation of a computational framework that allows for group-wise joint segmentation, smoothing and registration of images and shapes. With recent advances in sensor technology, images (shapes and other types of data) are being generated in abundance, and there is now a need for algorithms that operate and process images in collections instead of individually. In particular, this requires segmentation, smoothing and registration, three most important image processing operations, to be formulated in new ways that emphasize the relational aspects of their inputs. In addition, image data in computer vision applications are usually sampled from low-dimensional manifolds embedded in high-dimensional features spaces, and an important problem is to construct versatile and expressive computational models that exploit their geometries for solutions. The proposed computational framework addresses these two issues by formulating a variational framework that unifies smoothing, segmentation and registration. Specifically, it uses hypergraphs to model the multiple geometric relations among the inputs, and the three operations are integrated in one single discrete variational framework defined over a hypergraph. The proposed framework provides a foundation for several principled joint segmentation and registration algorithms for images and shapes that can guarantee crucial properties such as compatibility, consistency, unbiasedness and symmetry. Furthermore, it also provides a new and more discriminative numerical signature for 2D and 3D shapes that can be important for many shape-related vision applications such as shape recognition, shape retrieval and image-based medical diagnosis.","title":"RI-small: Simultaneous Groupwise Nonrigid Registration, Segmentation and Smoothing of 3D Shapes and Images","awardID":"0916001","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["412202",409210],"PO":["564316"]},"162244":{"abstract":"Both the need and the opportunities for governments to understand and respond to citizens expectations have grown enormously. Technical innovation and social forces are creating a kind of perfect storm of new data for government agencies to cope with, coming from a convergence of rapidly expanding web-based service delivery, exploding capability of social media and mobile devices for network-based citizen feedback, and policy initiatives promoting greater use of network-based applications and infrastructure to promote transparency and citizen engagement. Government agencies are thus challenged with gathering, integrating, and interpreting rapidly growing, diverse data flows both to and from citizens across the knowledge life cycle, and using the results to improve performance.<br\/><br\/>It is not clear what computational, analytical, and organizational capabilities agencies will need to cope with this expanding scale of citizen engagement, or what theory and research methods are most appropriate to understand the information received. The complexity of shifting interactions among technical and social developments requires understanding and strategies somewhat beyond our existing knowledge base. Service providers will need improved computational and analytical skills, strategies, and assessment methods, in short a new set of integrated computational and organizational capabilities. Researchers will need new frameworks to guide inquiry.<br\/><br\/>The purpose of this project is therefore to build out the knowledge base available to government agencies and researchers. This will be done by assembling and reviewing existing research and best practices, building a research agenda for future work, and developing methods to enhance agency capabilities to conduct citizen research programs. The research team will collaborate with a Federal agency (General Services Administration - Office of Citizen Services) to identify the goals and capability issues from the agency perspective, and to develop the research agenda for building agency capabilities. This includes conducting pilot-type scale research with OSC to build capacity and test methods.<br\/><br\/>Intellectual Merit <br\/>This research addresses a critical problem that extend across information systems and organizational studies: How to gather, integrate, and interpret complex, dynamic data flows in ways that lead to enhanced organizational capabilities and improved performance. Theory that treats organizational capability and performance improvement recognizes the importance of information, but does not deal adequately with the capability or design of systems supplying the information. The wide range of technical challenges to integrating information across diverse sources are well recognized but the path to interoperable and adaptive systems remains largely unmapped. The research in these areas crosses organizational studies, computer and information science, and public administration.<br\/><br\/>Broader Impact<br\/>Government agencies face an information environment that is vital to the success of their programs and at the same time challenges their capacity to cope with the volume and diversity of flows. They are expected to provide ever greater information to the public and at the same time seek and respond to ever greater levels of public engagement and feedback. There is a real prospect of rapidly growing public demand for both engagement and access, spurred by improved communication capability and stimulated by more responsive agency behavior. New information system strategies are needed to cope with such increases in scale and complexity. This research will respond to this need by treating the information systems themselves as integrated organizational and computational entities. This approach will provide an enhanced knowledge base for developing these improved systems as well as the capabilities for information gathering and integration strategies in the organizations themselves.","title":"CISE-IIS: Creating a Knowledge Foundation for Citizen Services Research Programs in Government","awardID":"0956356","effectiveDate":"2009-09-15","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["551444",433610],"PO":["565136"]},"153543":{"abstract":"In many scientific disciplines today, a community of users is working<br\/>together to assemble, revise, and curate a shared data repository. As<br\/>the community accumulates knowledge and the database content evolves<br\/>over time, it may contain conflicting information and members can<br\/>disagree on the information it should store. Relational database<br\/>management systems (RDBMS) today can help these communities manage<br\/>their shared data, but provide limited support for managing<br\/>conflicting facts and conflicting opinions about the correctness of<br\/>the stored data.<br\/><br\/>This project develops a Belief Database System (BeliefDB) that allows<br\/>users to express belief annotations. These annotations can be positive<br\/>(agreement) or negative (disagreement), and can be of higher order<br\/>(belief annotations about other belief annotations). The approach<br\/>allows users to have a structured discussion about the database<br\/>content and annotations. A BeliefDB gives annotations a clearly<br\/>defined semantics that lets a relational database understand and<br\/>manage them efficiently.<br\/><br\/>Intellectual merits: (i) Definition of a Belief Database Model: The<br\/>project develops a formalism that extends a relational database with<br\/>belief annotations on data and on previously inserted annotations.<br\/><br\/>(ii) Design of a Belief Query Language: The project complements the<br\/>data model with a new query language that extends SQL. (iii)<br\/>Development of a canonical Belief Database Representation: The<br\/>projects develops approaches to store and manipulate belief databases<br\/>on top of a conventional RDBMS.<br\/><br\/>Broader impact: Curated databases and shared data repositories are<br\/>becoming widespread in the scientific communities. A BeliefDB<br\/>provides a new data management system that addresses the need of these<br\/>communities to manage conflicting data. If successful, the project<br\/>will be one of the pieces that will help data management technology<br\/>undergo a new paradigm shift, from managing data as content, to<br\/>supporting a community of users in collaboratively creating partly<br\/>conflicting database contents.<br\/><br\/>For further information on the project see the project web page::<br\/>http:\/\/db.cs.washington.edu\/beliefDB\/","title":"III: Small: BeliefDB - Adding Belief Annotations to Databases","awardID":"0915054","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[408636,"531543","536677"],"PO":["563727"]},"153664":{"abstract":"During software maintenance, 50% to 90% of developer effort is spent on program comprehension activities, which are performed by developers to better understand source code. Reducing the effort spent by developers on these activities can reduce software maintenance costs. Researchers have developed techniques and tools to detect code clones (similar or identical segments of source code), because their presence can diminish program comprehensibility. However, knowledge only of the presence of clones does not allow a developer to perform maintenance tasks correctly and completely; proper performance of these tasks requires a thorough understanding of the relationships among the detected clones. Existing approaches for investigating these relationships are limited in their applicability and effectiveness.<br\/><br\/>The goal of this collaborative project is to develop an automated and rigorous analysis process for identifying and codifying the relationships among clones using their structural and semantic properties. To maximize the impact of the techniques and tools on the effectiveness and efficiency of performing maintenance tasks when clones are present, the investigators will perform a domain analysis. After initial development, the team will validate and refine the techniques and tools. The research will help developers to maintain software, reducing total software cost and improving overall software quality.","title":"SHF:Small:Collaborative Research: Improved Code Clone Categorization","awardID":"0915559","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["551799","543615"],"PO":["564388"]},"151002":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>There is a growing need for wireless networks that can sustain high data rates, are robust to interference, make efficient use of battery resources, and offer secure communications. This project introduces cooperative beamforming (CB), a novel technique that enables high throughput and power efficient communications in a secure manner. CB consists of two stages. In the first stage, the sources share their data with neighboring nodes via low-power communications. Various approaches for such information sharing are considered, with a goal to minimize queuing delays, conserve energy, and achieve high throughput. In the second stage, the cooperative nodes apply a weight to the signal received during first stage, and transmit. The weights are such that a specific objective criterion (e.g., signal to interference at the destination) is maximized. In CB, although each node uses low power, all nodes together can deliver high power to a faraway destination. This increase in power offsets power reduction due to propagation attenuation. CB can be viewed as an alternative to multihop transmission and, unlike multihop transmission, does not deplete the power resources of other nodes. Since CB can achieve long distance communication, new paths can be found to improve the overall network performance. Also, CB improves network security by avoiding eavesdroppers; unlike traditional cryptographic-based protocols that operate at higher layers and are sensitive to the broadcast nature of the transmission medium, CB improves security at the physical layer. CB will be implemented on a hardware network testbed to demonstrate how the developed techniques can revolutionize wireless communications.","title":"NeTS: Medium: Collaborative Research: Cooperative beamforming for efficient and secure wireless communication","awardID":"0905425","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["526916","563559","563559"],"PO":["557315"]},"153785":{"abstract":"This project develops semi-supervised machine learning algorithms that are practical, and at the same time guided by rigorous theory. In particular, the project is developing learning theory that quantifies when and to what extent the combination of labeled and unlabeled data is provably beneficial. Based on the theory, novel algorithms are being developed to address issues that currently hinder the wide adoption of semi-supervised learning. The new algorithms will be able to guarantee that using unlabeled data is at least no worse, and often better, than supervised learning. The new algorithms will also be able to learn from unlimited amounts of supervised and unsupervised data as they arrive in real-time, something humans can do but computers cannot so far. <br\/><br\/>This project has a number of broader impacts: (1) An open-source software will be an enabling tool for new discoveries in science and technology, by making machine learning possible or better in situations where labeled data is scarce. Since the software specifically targets non-machine-learning-experts, the impact is expected to be across the whole spectrum of science and technology that utilizes machine learning. (2) It advances our understanding of the learning process via new machine learning theory, which can be applied to both computers and humans. (3) The proposal contains projects ideally suited to engage students in computer science education and research.","title":"RI: Small: Semi-Supervised Learning for Non-Experts","awardID":"0916038","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560208"],"PO":["562760"]},"153675":{"abstract":"Scientists have discovered that individuals are often unable to make optimal decisions when problems are complex due to limitations on cognitive abilities. This interdisciplinary project employs visual analytics as a transformational analytical tool in economics. The investigators use visual analytics to improve decision making and identify key motivations in knowledge creation in various economic problems. The project?s suite of tools allows users to interactively explore datasets and decision spaces as well as compare alternate hypothesis and develop new hypothesis. Further, keystrokes and information pertinent to understanding decision-making and knowledge generation are recorded, allowing the investigators to make predictions about the decision-making process on a broad scale and providing guidance for theoretical models of decision-making. This is the first thorough investigation of the value of visual analytics for economic decision-making.<br\/><br\/>Intellectual Merit<br\/>This project brings together a team of scientists from economics, electrical and computer engineering and cognitive science, fields that are rarely linked. The fundamental objective of this three-year project is to improve individual and group economic decision making through the introduction of visual analytics as a necessary tool for dealing with complex information sets. The project?s second objective is to quantify the effectiveness of visual analytics for decision making. Visual analytics has emerged as an important approach to data analysis in many fields such as medicine, business, and the physical sciences, and the investigators are the first to quantify its value for decision-making using rigorous experimental methods. The final objective is to develop a unique suite of visual analytics tools to help economists and policy-makers analyze large datasets. <br\/><br\/>Broader Impact: The use of visual analytics for economic decision-making is extremely beneficial to policy makers. Use of these tools should have an immediate and positive impact on the capacity to analyze complex economic datasets. These tools can also be used in many fields with problems in analytical reasoning. The visual analytics tools that result at the completion of the project will be made available online for classroom use, which will have a broad impact on education. Visual analytics tools are unique in that they are both simple enough and captivating for K-12 students, while also being helpful to students at the undergraduate and graduate levels. The project will use over 650 undergraduate student subjects drawn from a large and diversified student population and will provide these students with important exposure to modern research methods. The VSEEL laboratory at Purdue has an excellent record of involving members of underrepresented minority groups at both the undergraduate and graduate levels and this project is expected to continue this tradition. Over 40 percent of these student subjects will be women and about one-third will be underrepresented minorities. Based on past experience, we expect that at least one-half of the Ph.D. student researchers will be women and\/or minorities.","title":"TLS - Applied Visual Analytics for Economic Decision-Making","awardID":"0915605","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0400","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7626","name":"SCIENCE OF SCIENCE POLICY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["488997","499748",408959,408960],"PO":["565013"]},"153796":{"abstract":"Mobile devices supporting a wide variety of multimedia applications under a very stringent energy budget are a key driver of electronic systems in future. The objective of the proposed research is to explore a generic, programmable, reconfigurable, and energy-efficient architectural platform for future mobile devices for real-time multimedia processing. The aim is to exploit the inherent error tolerance in multimedia applications for run-time energy-accuracy trade-off. The proposed research will analyze the interaction of ultra-low-power computing and error characteristics of real-time multimedia processing. This research will pursue a circuit-architecture-algorithm co-design approach to model, analyze, and demonstrate a reconfigurable hardware platform for memories, datapath, and buses to exploit the error characteristics of real-time multimedia processing algorithms for ultra-low power. <br\/><br\/>This generic architecture for energy-efficient multimedia systems can lay the foundation of future mobile supercomputers performing wide array of applications with minimal energy. The PIs will disseminate the research results through project website, conference and journal publications. The existing interactions with leading microprocessor and mobile handset manufacturers will provide opportunities for technology transfer. The educational goal is to create next generation engineers who understand the effects of energy and accuracy on computations. The PIs will engage in recruiting students from underrepresented groups and mentor students under the Summer Undergraduate Research Experience for minorities (SURE) program at Georgia Tech.","title":"SHF: Small: A Generic Micro-Architecture for Accuracy-Aware Ultra Low Power Multimedia Processing","awardID":"0916083","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["431683","518444"],"PO":["366560"]},"162266":{"abstract":"Intellectual Merits: The objective of this project is to develop information theory and signal processing-based algorithms for Heterogeneous Sensor Networks (HSN) that jointly addresses sensor adaptation and data fusion in the presence of a combination of stationary or non-stationary heterogeneous sensors in constrained environments. Two research thrusts will be investigated: 1) information theory for HSN design; 2) signal processing for HSN information integration. Current research on the theory and algorithms of HSN is very limited. There exist a number of fundamental problems that have never been addressed, yet they are critical to the HSN. To tackle these problems, novel approaches and methodologies that will incorporate techniques such as information theory, network science, collaborative signal processing, estimation theory, statistical approach, and optimization will be studied and therefore has the potential to inspire transformative methodologies that could be applied to many domains. The proposed theories will lead to practical methodologies, algorithms and design tools with performance robust to uncertainty and adaptive to variations in dynamic operating conditions.<br\/><br\/>Broader Impacts: This project will make a significant contribution to the applications of HSN and will have a broad and deep social impact. Because of the vast amounts of real-time information coming from many widely distributed sources in homeland security and defense, HSN is needed to collect and process threat-related information to insure that it is not overlooked. A carefully developed, research-centric education plan is also proposed. Under-represented and female students will be recruited from different societies for this project.","title":"EAGER: Heterogeneous Sensor Network Design and Information Integration","awardID":"0956438","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["531713"],"PO":["564924"]},"153213":{"abstract":"The project?s goal is to create a science for embedding information in physical objects whose manufacturing process is inherently imprecise. The team will reach their objective through the investigation of a specific problem of significant economic importance: thwarting counterfeiting, and the related problem of physical tamper-detection. Counterfeiting is a growing economic problem that has been called the ?crime of the century? by a recent manufacturing industry report, and its cost is rapidly escalating (its yearly cost to the automotive industry alone is in the tens of billions of dollars and the loss of about 250,000 U.S. jobs for the legitimate manufacturers). In terms of scientific impact, the project has excellent potential for launching a significant new field. While the marking of digital objects is a well-explored area, the creation of algorithms for placing marks in physical objects is mostly unexplored territory. In terms of industrial impact, the project also has excellent potential for profoundly improving the current ?state of the practice?, which is all too easily defeated by sophisticated counterfeiters. This is because the project?s framework assumes an adversary with powerful capabilities, such as greater manufacturing prowess than the legitimate manufacturer, and full knowledge of the algorithms used to embed marks and to read marks (i.e., no ?security through obscurity?). The project?s only assumption is that the adversary does not know a secret key used to embed the mark. The work focuses on the development of the computational algorithms necessary to resolve several difficult issues and tradeoffs about what information to embed in the object, and where\/how to embed it. A solution must not increase manufacturing cost and must be usable with the current manufacturing pipeline. The approach is inherently multidisciplinary, combining information hiding, computer vision\/graphics, and robust algorithms. Hence, students in the project will acquire a unique combination of skills.","title":"RI: Small: A Computational Framework for Marking Physical Objects against Counterfeiting and Tampering","awardID":"0913875","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["541856","553652"],"PO":["565136"]},"163135":{"abstract":"The life science research community generates an abundance of data on genes, proteins, sequences, etc. These are captured in publicly available resources such as Entrez Gene, PDB and PubMed and in focused collections such as TAIR and OMIM. A number of ontologies such as GO, PO and UMLS are in use to increase interoperability. Records in these resources are typically annotated with controlled vocabulary (CV) terms from one or more ontologies. Records are often hyperlinked to those in other repositories, creating a richly curated biological Web of semantic knowledge. <br\/><br\/>The objective of this project is to develop tools to explore and mine this rich Web of annotated and hyperlinked entries so as to discover meaningful patterns.<br\/>The approach builds upon finding potentially meaningful and novel associations between pairs of CV terms cross multiple ontologies. The bridge of associations across ontologies reflects annotation practices across repositories. A variety of graph data mining and network analysis techniques are being explored to find complex patterns of groups of CV terms cross multiple ontologies. The intent is to identify biologically meaningful associations that yield nuggets of actionable knowledge to be made available to the scientist together with a set of golden publications that support the identified patterns.<br\/><br\/>The intellectual merit of the project is that it is unique in comparison to other bioinformatics data integration and analysis projects. Data is integrated from across numerous sources including genes, gene annotations, ontologies, and the literature. The exploratory nature (EAGER) of this research is both with respect to the biological and the computer science disciplines. From the biological viewpoint, a high level of speculation is associated with any discovered biological patterns. Discovered patterns night not necessarily meet criteria for experimental validation. The research methodology combines algorithmic and analytical techniques from multiple computer science sub-disciplines. While specific technical innovations are expected, an inter-related set of computer science challenges needs to be defined.<br\/>This research has the potential for broader impact since the methodology can be applied to any type of interlinked resources on the biological semantic Web as well as to any collection of hyperlinked resources. This research is a collaboration between the University of Maryland and the University of Iowa. For further information see the project web pages at the following URL:<br\/>http:\/\/www.umiacs.umd.edu\/research\/CLIP\/RSEAGER2009\/","title":"III EAGER Collaborative Research: Exploratory Research on the Annotated Biological Web","awardID":"0960963","effectiveDate":"2009-09-15","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543580"],"PO":["560586"]},"157822":{"abstract":"CPS: Small: Cyber-physical system challenges in man-machine interfaces: context-dependent control of smart artificial hands through enhanced touch perception and mechatronic reflexes<br\/><br\/>The objective of this research is to integrate user control with automated reflexes in the human-machine interface. The approach, taking inspiration from biology, analyzes control-switching issues in brain-computer interfaces. A nonhuman primate will perform a manual task while movement- and touch-related brain signals are recorded. While a robotic hand replays the movements, electronic signals will be recorded from touch sensors on the robot?s fingers, then mapped to touch-based brain signals, and used to give the subject tactile sensation via direct cortical stimulation. Context-dependent transfers of authority between the subject and reflex-like controls will be developed based on relationships between sensor signals and command signals.<br\/><br\/>Issues of mixed authority and context awareness have general applicability in human-machine systems. This research advances methods for providing tactile feedback from a remote manipulator, dividing control appropriate to human and machine capabilities, and transferring authority in a smooth, context-dependent manner. These principles are essential to any cyber-physical system requiring robustness in the face of uncertainty, control delays, or limited information flow.<br\/><br\/>The resulting transformative methods of human-machine communication and control will have applications for robotics (space, underwater, military, rescue, surgery, assistive, prosthetic), haptics, biomechanics, and neuroscience. Underrepresented undergraduates will be recruited from competitive university programs at Arizona State University and Mexico?s Tec de Monterrey University. Outreach projects will engage the public and underrepresented school-aged children through interactive lab tours, instructional modules, and public lectures on robotics, human-machine systems, and social and ethical implications of neuroprostheses.","title":"CPS:Small:Cyber-physical system challenges in man-machine interfaces: context-dependent control of smart artificial hands through enhanced touch perception and mechatronic reflexes","awardID":"0932389","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7751","name":"CDI TYPE II"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[421263,"539697"],"PO":["565227"]},"151046":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project focuses on understanding the principles and methods for the design of green networks at the edge of the Internet. The total power consumption of edge networks is estimated to be quite significant, so even moderate improvements in energy-usage in an individual device can result in non-trivial savings overall. Obtaining these moderate improvements in the energy-efficiency of edge networks is challenging for two reasons: the diversity of edge networks and the dynamics in their workload.<br\/><br\/>Intellectual Merit. Leveraging the researchers' combined expertise in low-power electronics, link-layer technologies, and energy-efficient network subsystem design and architecture, the project will: a) devise a deep energy-inspection architecture that encompasses a broad range of edge devices and networking technologies, and incorporates innovative hardware designs for subsystem-level monitoring and control of energy usage; b) explore run-time energy adaptation at various levels of the network, enabled by this inspection architecture; c) examine coordination mechanisms for controlling edge network energy usage which will allow coordinated energy management across components and devices, enabling more aggressive energy savings.<br\/><br\/>Broad Impacts. The project can have significant societal benefit, targeted as it is on sustainable technologies. Moreover, the techniques it develops for energy efficiency can be broadly applied to other areas of computing: large server systems, mobile devices, and consumer appliances. Beyond its impact on technology, the project will also contribute to workforce development by training EE and CS students in sustainability.","title":"NetSE: Medium: Collaborative Research: Green Edge Networks","awardID":"0905596","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["553707",402668],"PO":["565090"]},"151057":{"abstract":"Scientific network research relies heavily on sound, empirical analysis of real-world network traffic. It is often not possible to robustly validate a proposed mechanism, enhancement, or new service without understanding how it will interact with real networks and real users. Yet obtaining the necessary raw measurement data?in particular packet traces including payload?can prove exceedingly difficult. Simply put, the lack of public access to current, representative datasets significantly hinders the progress of our scientific field. Not having appropriate traces for a study can stall the most promising research. There have been extensive efforts by the community at large to change the status quo by providing collections of public network traces. However, the community?s major push to encourage institutions to release anonymized data has achieved only very limited successes. The risks involved with any release still outweigh the potential benefits in almost all environments. The lack of significant progress in this direction?despite extensive efforts?is an undeniable indication that the community needs a new approach. Towards this end, the PIs are developing in a systematic fashion a scheme that has been used informally numerous times over two decades of network research: rather than bringing the data to the experimenter, bring the experiment to the data. Past studie have packaged up an analysis for execution by somebody external who had the privileges to access network traffic out of our reach. These people crunched the traffic with our scripts and then manually verified that the output did not leak any sensitive information before passing it on to us. The PIs are establishing such mediated trace analysis as a standard approach to empirical network research. The aim is to formalize the process sufficiently to facilitate researchers tapping into a potentially broad pool of providers willing to mediate access to traces for research studies. Several large-scale network environments have already confirmed to us that they consider this model a feasible approach, and are willing to participate. The main challenge to overcome is the burden the process imposes on trace providers and on the research ?development cycle?. The basic tenet is that it possible to greatly improve many of the tedious mediation steps by devising a systematic framework that accounts for the legitimate concerns of providers while reducing their effort to such a degree that it becomes practical for them to provide mediated trace analysis on a routine basis. <br\/><br\/>The key challenge is to automate the common steps of the mediation process without compromising the core requirement of the trace provider maintaining thorough control over the process. Starting with carefully examining the threats that arise, the PIs are devising a formal framework for trace mediations that will include a computational model specifically tailored to the process? unique requirements, along with a powerful suite of tools to provide extensive support for the different elements of the undertaking.<br\/><br\/>The mediation approach has the potential to broadly improve how scientists tackle network measurement studies?both opening up access to a far greater range of empirical data than is currently viable, and instilling a greater degree of scientific rigor into the process of conducting such research. By making empirical data available to many more teams of researchers than occurs today, this work will significantly broaden efforts within the field.","title":"NeTS:Medium:Invigorating Empirical Network Research via Mediated Trace Analysis","awardID":"0905631","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["562327","563433","562329"],"PO":["557315"]},"151068":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Accurate wireless measurements are critical to the sustained growth of deployed wireless networks, as well as the successful development of wireless innovations. Because of the significant effort required to deploy wireless networks and obtain reliable measurements, current wireless traces are lacking both in breadth of environments and consistency of methodology. The AirLab project seeks to facilitate meaningful analysis of wireless networks by deploying a distributed wireless measurement infrastructure that produces consistent and comparable wireless traces over different deployment environments. AirLab provides core periodic measurements as well as user-driven experiments, and a centralized repository for storing, accessing, and statistically analyzing wireless traces. The richness of these measurement datasets allows researchers to detect and confirm hidden trends, and derive statistically meaningful conclusions based on real-world observations. All AirLab measurements are public and accessible by the research community, thereby lowering the barrier to entry for research and enabling researchers to innovate without the upfront expenses of deploying local wireless testbeds. The project integrates its research outcomes into the undergraduate and graduate education programs. It also proactively seeks to increase the number of women and underrepresented groups in the field.","title":"NeTS: Medium: AirLab: Distributed Infrastructure for Wireless Measurements","awardID":"0905667","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560388","551126","560332","552796"],"PO":["565303"]},"154104":{"abstract":"New immersive display systems are emerging as platforms for presenting three dimensional data and virtual worlds. However, little effort has been spent on evaluating these systems or providing guiding design principles from a human factors point of view. The PIs argue that interconnected tiled screens have the potential to be as effective as more costly continuous image systems. Demonstrating this potential would in effect significantly drive down the cost of 3D immersive visualization, paving the way for much broader application areas than are now possible (imagine, for example, a science teacher able to show her students a 3D visualization of DNA and to have them interact with the model on a low cost immersive display). To this end, in this project the PIs will compare performance and user interaction on a low-cost, multi-screen spatially immersive visualization system against a more expensive continuous image platform. Their hypothesis is that the low-cost system will present a perceptually equivalent visual experience, despite image seams introduced by the connecting display screens. Psychophysical experimentation will compare the two systems through human judgments based on performance. Project outcomes will also provide insights into optimal hardware and software display configuration when building large multi-screen displays. The PI has an extensive background in conducting experiments involving human subjects, while the Co-PI brings expertise on building and configuring next generation immersive displays, including one of those to be used in this work, which was developed under a prior NSF award. The team has access at Texas A&M to two complementary immersive systems, putting them in a unique position to conduct this research.<br\/><br\/>Broader Impacts: The knowledge and insights gained from this work should help make immersive visualization systems available in areas currently unable to afford such systems or to justify the expense, and thus advance discovery and understanding by enhancing the infrastructure for research, while also promoting teaching, training and learning by engaging more (and more diverse) students in science and technology.","title":"HCC: The Effect of Tiled Display on Performance in Multi-Screen Immersive Virtual Environments","awardID":"0917232","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["534310",410034],"PO":["565227"]},"145766":{"abstract":"This proposal is to organize a national workshop to bring together research and development communities of nanotechnology and high performance computing to discuss challenge problems in multi-scale modeling and large-scale simulations for nanotechnology.<br\/>The proposed education components influence the public education systems in science and technology through Virtual School of Science and Engineering by NSF-OCI sponsored Great Lakes Consortium Project and HPC University project initiated by NSF TeraGrid.","title":"NSF-CCF-EMT Workshop on Cyberinfrastructure (CI)-based Emerging Models and Petascale Computing for Nanoscience and Nanotechnology","awardID":"0842323","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["554242","467389","558550"],"PO":["565272"]},"154115":{"abstract":"High-end systems and general-purpose computers alike are increasingly being configured with hardware accelerators. A typical system, or node of a large-scale platform, contains a few multicore processors that share memory, together with one or more coprocessors, such as a high-end accelerator board, an inexpensive programmable graphics card (GPGPU), or an FPGA (Field Programmable Gate Array). The coprocessors will typically have a different instruction set, distinct memory, a different operating environment and markedly different execution characteristics than the multicore component of the system. As a result, these heterogeneous platforms pose tough challenges with regard to their programmability. <br\/><br\/><br\/> The goal of this research is to significantly simplify the process of developing code for heterogeneous platforms by providing a single, high-level programming interface that may be used across, and within, multicore processors and a broad variety of accelerators. Language features will be designed, in the form of an extension to the industry standard OpenMP API, that will enable the application developer to specify code regions for acceleration, along with the necessary synchronization and data motion. The implementation will translate the resulting enhanced OpenMP for a variety of heterogeneous platforms.","title":"SHF:Small: Portable High-Level Programming Model for Heterogeneous Computing Based on OpenMP","awardID":"0917285","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["506602"],"PO":["564588"]},"154005":{"abstract":"Field Programmable Gate Arrays (FPGAs) are used in a variety of embedded applications in communication, space, automotive, medical devices and industrial control. Due to the safety-critical nature of many of these applications, the trustworthiness of the underlying hardware platform is imperative. FPGA-based embedded systems offer lower cost and reduced power consumption by aggressively embracing newer deep sub-micron technology process, which brings lifetime reliability concerns of the systems to the forefront. The impact of performance degradation is more significant in new technologies, resulting in accelerated aging and premature failures. Further, the reconfigurable nature of FPGAs and the heterogeneous components embedded in a FPGA make the reliability degradation and possible solutions to mitigate them different from those employed for application specific integrated circuits and microprocessors. Consequently, techniques to mitigate the impact of aging mechanisms are vital to ensure the trustworthiness of reconfigurable embedded systems, and are the focus of this research. The tools and techniques developed as part of this research will serve as a foundation for designing life-time aware reliable embedded systems and for catalyzing further research in this area. Due to the pervasiveness of embedded systems, providing solutions to improve lifetime reliability is anticipated to have a broad impact on the society. The project will involve both undergraduate and graduate students in all aspects of this research. The PIs will actively promote the projects to under-represented communities to improve student diversity. In addition, the PIs will integrate the research results in existing courses on VLSI design and reconfigurable systems.","title":"TC:Small:Improving Lifetime Reliability for Reconfigurable Embedded Systems","awardID":"0916887","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518504","549542"],"PO":["565255"]},"154126":{"abstract":"The significant progress made by database research on <br\/>schema mapping (e.g., omposition, invertibility), data exchange, <br\/>and query rewriting, can provide breakthrough solutions for the Database <br\/>Schema Evolution problem. But as of today, information systems are <br\/>sorely lacking the methods and tools needed to cope with the<br\/>problem, and to reduce the cost of data migration, rework of queries, <br\/>application rewriting, and downtime created by schema changes. <br\/>In fact, this old problem has been made worse by the success of <br\/>scientific databases (e.g., Ensembl) and web information<br\/>systems (e.g., Wikipedia)---where the fast evolution of applications <br\/>and requirements characterizing the web and the scientific discovery <br\/>process is exacerbated by the number and diversity of users and <br\/>organizations cooperating on these endeavors.. Fortunately, the openness of<br\/>these public-domain information systems (vs. corporate ones), and the <br\/>abundance of their interesting evolution histories make it possible to<br\/>built a comprehensive testbed to determine the strengths, limitations, <br\/>and potentials of candidate methods and tools proposed for the problem.<br\/><br\/>Thus, this project is building: (i) an open-source curated repository <br\/>containing evolution histories from key information systems, <br\/>(ii) benchmarks for a comprehensive set of tools tested therein, <br\/>and (iii) instruments to collect and analyze evolution histories.<br\/>These are then used to (a) compare and evaluate existing approaches, <br\/>methods and tools, and (b) entice researchers to evaluate and improve <br\/>their techniques and add their test cases to the benchmark.<br\/>A transformative impact can be expected upon schema mapping<br\/>research and applications, inasmuch as theoretical solutions <br\/>are now validated and improved on real-life case-studies. <br\/>These in turn are expected to transform and improve significantly <br\/>scientific databases and web information systems. For further<br\/>information see the project web page:<br\/>http:\/\/www.cs.ucla.edu\/~zaniolo\/nsf0917333.html","title":"III: Small: Information Systems Under Schema Evolution: Analyzing Change Histories and Management Tools","awardID":"0917333","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["542091"],"PO":["563727"]},"148934":{"abstract":"As the computing industry accelerates into the many core era, it is confronted with the need for reliable and accurate simulation, modeling and performance prediction tools for future systems comprised of tens to hundreds of cores per die. Due to different intellectual histories and goals, the integration of mature existing point tools into accurate models of even small 4-8 core systems has proven to be time consuming, error prone, and brittle, with the models themselves taking hours to days for a single simulation run on state-of-the art workstations. Concurrently, these effects make re-use across groups and institutions difficult and have begun to severely inhibit research and teaching progress in many core architectures. <br\/><br\/>The proposed program of work will create an open source many core simulation and modeling infrastructure. This infrastructure, Manifold, will adapt techniques for concurrent simulation to enable existing highly parallel architectures to be harnessed to model future designs. Manifold will enable users to incorporate existing simulation tools when they exist, as well as provide models for key many core components and phenomena, for example interconnection networks. The goal is a software infrastructure that is i) easily accessible to all academic and research communities, ii) runs on commodity clusters, iii) runs on many core laptops for classroom use, and iv) reduces barriers to entry in catalyzing new efforts. Central to Manifolds mission is the development of curricular material for computer architecture modeling and simulation including new courses, course modules, training materials, and significant evangelization.","title":"CI-ADDO-NEW: Manifold - A Scalable Simulation Infrastructure for Future Many Core Systems","awardID":"0855110","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["517778","434457","556660"],"PO":["565272"]},"158735":{"abstract":"Title: Scalable Visualization and Model Building<br\/>PI: Cleveland, William S. [Purdue University]<br\/><br\/>Developing new algorithms, visualization tools, and mathematical models that can predict and explain patterns in data is fundamental to machine learning and statistics. They enable a predictive modeling that is fundamental to science and engineering. Visualization is critical in all phases of data analysis, from the moment the data are collected when data checking and cleaning are needed, to the final presentation of results. Visualization facilitates model building by allowing the analyst to critically assess the predictive power of a model, and to diagnose problems in fitting the patterns in the data. The investigators are carrying out research in approaches, methods, and models for describing patterns in data with a strong emphasis on visualization and on comprehensive analysis of massive datasets.<br\/><br\/>The research is addressing two broad topics. One is a framework for the integration of visual analysis and statistical modeling. We envision a system that facilities an iterative modeling process. The modeling cycle includes multiple stages, starting with descriptive visualization, then model selection, model fitting, diagnosis and evaluation, and finally iterative model refinement. The second topic is a general approach to visualization and modeling that scales from small to massive datasets, and the development of new methods specifically for the scaling of data visualization. We approach scaling by partitioning the data into subsets, sampling the subsets, and applying modeling and visualization to each subset. The investigators are carrying out the research in the context of two challenging data analysis projects in homeland security: (1) Daily counts of chief complaints from 76 emergency departments of the Indiana Public Health Emergency Surveillance System; and (2) Internet packet traces for network security that we collect on the campuses of Purdue University and Stanford University.","title":"Scalable Visualization and Model Building","awardID":"0937123","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}}],"PIcoPI":["521276"],"PO":["562984"]},"154137":{"abstract":"This project will examine two issues related to end-user debugging of computer programs. First, what strategies do male and female end-user programmers try to use for debugging, and with which do they succeed? Second, how should end-user programming environments go about supporting and guiding these debugging strategies? Most of what is programmed must eventually be debugged. The support of problem-solving tasks such as debugging must extend all the way to the heart of problem solving, to strategy.<br\/><br\/>Although once only professional programmers developed software, today it is common for end users to create some of their own software. Common examples are spreadsheet systems, in which end users program by creating and changing formulas, and web application builders, in which end users program by demonstrating the desired behavior and\/or making dataflow connections among computation tools dragged in from a palette. Numerous other examples exist. In fact, in the U.S. alone, there are millions of end users doing such forms of programming every day - many more than professional programmers. <br\/><br\/>Unfortunately, however, evidence is beginning to accumulate that some females are not benefiting as much as males from these empowering devices. There have been recent reports of gender differences in end users' willingness to approach and adopt new software features related to debugging, differences in attitudes toward software features, and differences in end-user programmers' playful tinkering with features. Other results of gender differences in software-based problem solving are also emerging. These findings suggest that there are factors within the software itself that may be subtly undermining females' effectiveness in many software-based problem-solving tasks.<br\/><br\/>This project contributes to the effective use of information technology in evolving, heterogeneous socio-technical systems, enabling more people to take full advantage of the power of computing. It will accomplish this by investigating the underlying strategies males and females use successfully to solve problems with software, and then investigating how to support these strategies. This work will also produce new advances in how to guide and encourage computational thinking to help males and females solve everyday problems that arise in computing, combining empirical methods with proof-of-concept prototypes. In addition, it will contribute to education programs, and in particular will involve talented female high-school students as research interns, to encourage them in the direction of computer science.","title":"HCC: Small: Supporting Males' and Females' Problem-Solving Strategies in End-User Debugging","awardID":"0917366","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["548135"],"PO":["564456"]},"159835":{"abstract":"Positioning techniques for mobile devices play critical roles in many societal, industrial, and military activities. In current Global Positioning System (GPS), the triangulation and\/or trilateration calculation approach dominates, where a system of four or more quadratic equations must be solved, obtained from four or more satellite signals. However, this system does not work in challenging environments such as downtown areas where satellite signals are blocked by skyscrapers. <br\/><br\/>This work is to develop, analyze and evaluate computational methods that can improve the current GPS in terms of positioning accuracy and time efficiency. The proposed linearization approach in this project is unique in that it provides a closed form solution for quadratic equations in the calculation unit of GPS. The sensitivity analysis is derived to identify positioning error sources. The performance of GPS can then be significantly improved. Additionally, since the vulnerabilities in the positioning procedure are identified, this work is also a useful tool for solving security\/privacy related issues. This work is applicable to other wireless environments and can be incorporated with other wireless techniques, such as WiFi and wireless sensor networks (WSNs). Preliminary simulation results show that the performance of the proposed calculation method increases by 30% in terms of accuracy and 50% in terms of execution time complexity. <br\/><br\/>The fundamental framework and robust positioning techniques developed from this project will have broad impacts on high-tech industries. The transformative research will lead to the development and deployment of a new generation of practical positioning systems that can work effectively and efficiently in various challenging environments. The impact of this project also extends to academia and education through publications and dedicated websites.","title":"Collaborative Research: EAGER: Novel Theoretical Foundation for Wireless Positioning in Challenging Environments","awardID":"0943479","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["539562"],"PO":["564924"]},"158867":{"abstract":"Abstract<br\/>A major challenge for future High End Computing (HEC) systems built using many-core chips is the storage system since the available memory and bandwidth per processor core is starting to decline at an alarming rate, with the rapid increase in the number of cores per chip. Data-intensive applications that require large data sets and\/or high input-output bandwidth will be especially vulnerable to these trends. Historically, the storage architecture of an HEC system has been constrained to a large degree by the filesystem interfaces in the underlying Operating System (OS). The specific focus of this research is on exploring a new storage model based on write-once tree structures. This research will explore three programming models for users of the storage system, all of which can inter-operate through shared persistent data: 1) a declarative programming model in which any data structure can be directly made persistent in the storage system, with no programmer intervention, 2) a strongly-typed imperative programming model in which a type system extension will be used to enforce a separation between data structures that can be directly made persistent and those that cannot, and 3) a weakly-typed runtime interface that enables low-level C programs to access the storage system.","title":"Collaborative Research: Programming Models and Storage System for High Performance Computation with Many-Core Processors","awardID":"0937832","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["517820"],"PO":["565272"]},"157778":{"abstract":"CPS: Small: Compositionality and Reconfiguration for Distributed Hybrid Systems<br\/><br\/>The objective of this research is to address fundamental challenges in the verification and analysis of reconfigurable distributed hybrid control systems. These occur frequently whenever control decisions for a continuous plant depend on the actions and state of other participants. They are not supported by verification technology today. The approach advocated here is to develop strictly compositional proof-based verification techniques to close this analytic gap in cyber-physical system design and to overcome scalability issues. This project develops techniques using symbolic invariants for differential equations to address the analytic gap between nonlinear applications and present verification techniques for linear dynamics.<br\/><br\/>This project aims at transformative research changing the scope of systems that can be analyzed. The proposed research develops a compositional proof-based approach to hybrid systems verification in contrast to the dominant automata-based verification approaches. It represents a major improvement addressing the challenges of composition, reconfiguration, and nonlinearity in system models. <br\/><br\/>The proposed research has significant applications in the verification of safety-critical properties in next generation cyber-physical systems. This includes distributed car control, robotic swarms, and unmanned aerial vehicle cooperation schemes to full collision avoidance protocols for multiple aircraft. Analysis tools for distributed hybrid systems have a broad range of applications of varying degrees of safety-criticality, validation cost, and operative risk. Analytic techniques that find bugs or ensure correct functioning can save lives and money, and therefore are likely to have substantial economic and societal impact.","title":"CPS: Small: Compositionality and Reconfiguration for Distributed Hybrid Systems","awardID":"0931985","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["553671","469969"],"PO":["565274"]},"154027":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Presence of a well-structured market is necessary for efficient and flexible use of licensed spectrum bands, and for fair pricing of spectrum usage. The goal of this project is to design radio spectrum markets that allow trading of spectral resources - not only of the raw spectrum, but also of a variety of service contracts derived from the use of spectrum. Specific sub-problems that will be addressed in this context include: 1) spectrum-portfolio construction that optimizes risk-versus-return trade-offs, 2) strategy design for optimal cooperation among providers, 3) price-driven dynamic scheduling of subscribers, 4) optimal pricing of spectral contracts, and 5) regulatory mechanisms for effective functioning of the spectrum markets. The solutions to the above problems take advantage of similar formulations in financial engineering, and use tools from optimization, stochastic calculus, and control and game theory.<br\/><br\/>The project is expected to revolutionize spectrum trading by facilitating the design of secondary spectrum markets and spectrum regulation policies. Towards this end, This project aims at establishing a new cross-disciplinary field that is at the interface of wireless networks and financial mathematics. The results will lead to more efficient use of the available spectrum by reducing spectrum wastage and fairness in pricing of wireless subscribers, and also help formulate governmental spectrum management and regulation policies. The results will be disseminated through publications in premier journals and conferences, and interactions with collaborators in the wireless industry.","title":"NeTS: Small: Collaborative Research: Financial Dynamics of Spectrum Trading","awardID":"0916958","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["531798","531799"],"PO":["564993"]},"154148":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/>The Health Guardian project provides medical care through Wireless Health: remote monitoring, wearable body area sensors and wireless communications. The goal is to promote independent living by improving home patient care quality (and reduce costs) while enabling the care of mobile individuals. Today, doctors and nurses manually record and track patients? status. This manual process cannot guarantee accuracy and efficiency in the face of increasing complexity of sensed data and measurement procedures. However, remote, automated monitoring has become technically feasible. This program introduces a BodyLAN interconnecting body sensors to a data collection gateway, the ?Health Guardian?. In turn, the Health Guardian connects to external networks to propagate the data for further processing. Leveraging the growing popularity of P2P personal networks, this project enables new patient care models based on P2P networking among patients and care providers. <br\/>Broader Impact: Wireless health will reach into homes, workplace environments and rural communities. The foundation for emerging new applications and business opportunities that range from networking of individuals interacting in health, wellness and safety to rehabilitation and disease management of clinical patients. On the education front, creation of cross cutting project-oriented undergraduate and graduate courses.<br\/>Intellectual merits: Innovative research in delay tolerant, reliable networking between Body LAN, Guardian and Internet overcoming intermittent wireless connectivity; cooperation among peers to share critical resources and discover ?useful? neighbors with the help of Social Network techniques; concept validation via clinical trials.","title":"NetSE: Small: Collaborative Research: The Health Guardian- A Gateway to Networked Wellness","awardID":"0917408","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["558959","547185"],"PO":["565090"]},"148956":{"abstract":"This proposed project will design, develop, deploy, and operate a virtual Emergency Operations Center (vEOC) for (1) primary use as a research instrument, but with (2) secondary use for training and education. The vEOC, named Ensayo, will enable research on dynamic decision-making, individual and group problem solving, organizational learning, communication, coordination, and knowledge management in the context of roles and organizational structures to enable cross-institutional management of disasters. The vEOC will be web-based implemented using open source and open standards software and tools. Little substantive research has been conducted on large scale, emergent management structures. The size and complexity of these emergent structures affords a unique insight into studying the mechanisms (both successful and less successful) of operation, providing a valid substrate to formulate the components of the vEOC. Our initial research has yielded insights into the role that a vEOC could play in this, and other EOC contexts<br\/><br\/>The fundamental goal of Ensayo is to craft a research instrument that, although based on the elements of a local EOC, can be adapted to reflect a wide variety of EOC forms in order to support research, training and education. One of the collaborating institutions is minority serving, and located where the primary context for this work is important for the well-being of society ? hurricanes and emergency preparedness. Ensayo affords not only a research tool for academics, but also a resource for education, training and policy analysis for communities of practice who engage in any emergency operations event.","title":"Collaborative Research:II-NEW: Ensayo - A Virtual Emergency Operations Center (vEOC)","awardID":"0855164","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["426517"],"PO":["564456"]},"158878":{"abstract":"This research project aims to understand and develop systems for<br\/>maintaining superlinear indexes for streaming data. A superlinear<br\/>index provides search capability over an abstract space that cannot<br\/>easily be linearized (totally ordered). In contrast, a linear index,<br\/>typified by a B-tree, supports point and range queries on totally<br\/>ordered data.<br\/><br\/>Examples of superlinear indexes include multidimensional indexes,<br\/>which can be over a geometric domain, such as geographic data, or<br\/>which can be over multiple linear indexes; and full text queries,<br\/>which can include searching for a particular word or substring.<br\/><br\/>The superlinear indexes found in today's databases cannot support high<br\/>rates of insertion. On traditional mechanical disk drives, the<br\/>existing superlinear indexes can only support about one hundred<br\/>insertions per second in the worst case. For many important<br\/>applications, that is too slow, and so database users often avoid<br\/>superlinear indexing. Even traditional linear indexes based on<br\/>B-trees cannot support the high insertion rates demanded by many<br\/>databases.<br\/><br\/>This research investigates streaming superlinear indexes, that is,<br\/>indexes that efficiently support full text or multidimensional<br\/>queries, and can be updated at speeds that are related to disk<br\/>bandwidth rather than seeks per second.<br\/><br\/>Among the significant research issues are the following: (1) design<br\/>efficient files structures for streaming superlinear indexes; (2)<br\/>investigate how streaming superlinear indexes might pave the way to<br\/>improved file systems; (3) determine whether cache-oblivious<br\/>algorithms technology can enhance streaming superlinear indexes; and<br\/>(4) program complex data structures for transactions and recovery.<br\/><br\/>If successful, this research will show how to build filesystems that<br\/>achieve dramatically better performance than today's B-tree-based<br\/>filesystems, how to maintain rich geometrical data and<br\/>multidimensional nongeographical databases in real time, and how to<br\/>maintain full-text searchable databases in real time. For example,<br\/>some of today's file systems try to maintain an full-text index to<br\/>find strings in files quickly, but these systems often fall behind at<br\/>high data write rates. A streaming superlinear index would allow such<br\/>a file system to keep up, and would improve the usability of both<br\/>high-end storage systems and relatively small consumer storage systems<br\/>that are nonetheless too large to index with today's indexes.<br\/><br\/>The researchers are developing course materials on streaming indexing<br\/>technology which will be made freely available under the MIT<br\/>OpenCourseWare initiative (http:\/\/ocw.mit.edu).<br\/><br\/>Further information on this project may be found at the project<br\/>web page: http:\/\/supertech.csail.mit.edu\/superlinear-indexes","title":"HECURA: Colaborative: Multidimensional and String Indexes for Streaming Data","awardID":"0937860","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["548187","471720"],"PO":["565136"]},"157668":{"abstract":"The objective of this research is the transformation from static sensing into mobile, actuated sensing in dynamic environments, with a focus on sensing in tidally forced rivers. The approach is to develop inverse modeling techniques to sense the environment, coordination algorithms to distribute sensors spatially, and software that uses the sensed environmental data to enable these coordination algorithms to adapt to new sensed conditions. <br\/><br\/>This work relies on the concurrent sensing of the environment and actuation of those sensors based on sensed data. Sensing the environment is approached as a two-layer optimization problem. Since mobile sensors in dynamic environments may move even when not actuated, sensor coordination and actuation algorithms must maintain connectivity for the sensors while ensuring those sensors are appropriately located. The algorithms and software developed consider the time scales of the sensed environment, as well as the motion capabilities of the mobile sensors. This closes the loop from sensing of the environment to actuation of the devices that perform that sensing. <br\/><br\/>This work is addresses a challenging problem: the management of clean water resources. Tidally forced rivers are critical elements in the water supply for millions of Californians. By involving students from underrepresented groups, this research provides a valuable opportunity for students to develop an interest in engineering and to learn first hand about the role of science and engineering in addressing environmental issues.","title":"CPS:Medium:Collaborative Research:Physical modeling and software","awardID":"0930946","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["523704"],"PO":["564728"]},"154038":{"abstract":"Abstract: 0917008: TC: Small: Denial-of-Service Attacks and Counter Measures in Dynamic Spectrum Access Networks<br\/><br\/>This project studies denial-of-service (DoS) attacks that are unique to dynamic spectrum access (DSA) networks: (a) DoS attacks by incumbent user emulation; (b) DoS attacks by protocol manipulation. In the first case, one or more malicious nodes pretend to be the primary by mimicking the power and\/or signal characteristics to deceive legitimate secondary nodes into vacating the white space unnecessarily. In the second case, the malicious users either modify spectrum sensing related information or falsify their own sensing data thereby affecting the final decision. A number of mathematical models for the DoS attacks and several counter measures based on game theory, decision theory, stochastic learning, cryptography and Byzantine fault tolerance are developed in this project. Some defense mechanisms and protocols developed through this project will be tested on SpiderRadio (a cognitive radio test-bed being developed in the PIs? laboratory).<br\/><br\/>Broader Impact: Since DSA networks are expected to play an important role in first responder networks, the solutions proposed here are expected to impact design of such networks. Since research in DSA network protocols and architectures are still in the formative stages, the proposed security solutions can be incorporated into the design phase of the system rather than being added on as an after thought.<br\/><br\/>Graduate and undergraduate level courses and Technogenesis&#61651; scholarships will be used to disseminate the finding of this project. Special efforts will be taken to mentor women and minority students via established connections.","title":"TC: Small: Denial-of-Service Attacks and Counter Measures in Dynamic Sepctrum Access Networks","awardID":"0917008","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["515465",409877],"PO":["565327"]},"148967":{"abstract":"Body sensor networks (BSNs) represent an emerging area of research with significant scientific and technical challenges but with tremendous potential to impact a variety of application domains--most notably healthcare and medical research. While significant advancements are being made in this area, most efforts are isolated and independent, limiting the collective progress and making it difficult for new researchers to enter the field. This planning project establishes a foundation for the development of community research, education, and support infrastructure to help advance the field of BSNs. The project activities include 1) soliciting input from a broad community of researchers, educators, and domain experts to establish the consensus needs of the BSN community; 2) developing initial models for BSN hardware, software, and support infrastructure; and 3) developing a business model to ensure that cost is not a barrier to BSN research, education, or application. The ultimate goals of this project are to 1) increase the relevance and practicality of BSN research and development by enabling engineers to experiment with standardized physical systems and achieve more practical results; 2) empower new researchers and educators to enter the field with an inexpensive, substantial, and ultimately self-sustaining support infrastructure; and 3) provide teachers at all levels of education the infrastructure and educational modules to incorporate BSNs into their classrooms and laboratories, providing hands-on experiences through which students can see how computer science and engineering can have a direct impact on human health and quality of life.","title":"CI-P: Development of Community Infrastructure for Body Sensor Network Research, Education, and Support","awardID":"0855197","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["527785","485695"],"PO":["564778"]},"146426":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>While mobile applications offer users an opportunity for on-the-go Internet connectivity, deploying, monitoring, and maintaining distributed mobile applications introduces new challenges for software developers. Seemingly trivial tasks--such as configuring devices, starting executions, and tracking errors--are complicated by the unique characteristics of mobile environments. Historically, application management frameworks have helped developers cope with the complexities of managing applications; however, no existing frameworks address the challenges presented by mobile networks. To this end, this proposal has the following goals: 1) investigate mechanisms for the delay tolerant control of mobile applications that enable distributed application management despite network disruptions; 2) develop and evaluate algorithms for partially predictable resource scheduling that leverage the predictable patterns of human interaction to fairly arbitrate access to mobile devices in shared testbeds; 3) develop a software toolkit for mobile application management that simplifies application deployment and visualization. The framework will implement a set of unified abstractions that shield developers from the complexities of managing applications on mobile computing devices. The results of the work will benefit a range of students, researchers, and developers by advancing the state-of-the-art for mobile application management and enabling easier access to experimentation on mobile testbeds. By integrating the framework with shared mobile testbeds, undergraduates at small colleges with little prior exposure to systems development, including women and underrepresented groups, will experience the technological richness of large research institutions and gain hands-on experience with developing real distributed systems.","title":"CAREER: Mobile Application Management","awardID":"0845349","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["523270"],"PO":["535244"]},"154049":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The performance of wireless networks critically depends upon the careful design of networking protocols. Networking protocols are traditionally designed based only on intuition, and through a complex design process that is particular to the network at hand. The disadvantage of the traditional approach is that protocol design cycles are long, costly, and prone to human error. The lack of a general methodology also means that either the protocols are general-purpose and hence low-performance, or are specialized and hence inflexible and require complete re-design when the application specifications change. The major research contribution of this project is the establishment of a general methodology for the automation of networking protocols, taking the Medium Access Control (MAC) protocols as a first prototype. The MAC protocol performance is critical in high-performance wireless networks. The following design process chain is created to generate a MAC protocol based on resource constraints and application-specific goals: (1) Optimization Program: Formulation of the network protocol problem that models the effects of control information exchanges, (2) Solvers: Optimal waveform generation, which specifies the optimal exchange of both control information and data, (3) Protocol Extraction: The extraction of the optimal protocol as a minimal description of the optimal waveforms. This technology opens the way to the design of networking protocols that will be based on automation design tools in the future. This project also integrates the development of prototype tools into graduate-level coursework.","title":"NeTS: Small: Automated Design of Medium Access Control Protocols","awardID":"0917052","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[409902],"PO":["557315"]},"148978":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project involves the building of a high-performance computing and data storage infrastructure at Southern Illinois University Carbondale (SIHPSI - Southern Illinois HPC Infrastructure), a facility first-of-its-kind not only within the campus but in the greater Southern Illinois region also. Intellectual Merit: Research activities using SIHCPI encompass two broad areas - (1) Computational Nanoscience and Engineering (CNE): Examples include multimillion atom simulations of nanodevices, design of molecular catalysts, studies of polymer morphology at interfaces, fundamental studies of the driving mechanisms in non-equilibrium states of matter, and quantum information processing exploring new properties of atomic nuclei; and (2) Geographic Information Science (GIS): Involves strategic research to investigate new algorithms for representation and transformation of massive dynamic data allowing a cognitive and visual interpretation for analysts by exploiting invariant geometric properties. SIHPSI serves as a nucleation center for further addition of HPC resources and offers SIUC?s faculty members a much quicker time frame (1-2 weeks) to start computing as compared to a custom cluster configuration which usually takes about 6 months from start to production. Broader Impact: Research in the CNE area is expected to have significant impact in a wide range of technological applications including low-power and fast transistors, coatings, lithography, adhesives to light emitting diodes and sensors, various smart and functionalized materials, and quantum computation. The GIS research facilitates efficient data streaming, crime and health studies, medical imaging, and genome mapping. SIHPSI has an educational interface that supports ? (1) revamping several courses in the area of scientific modeling and numerical analysis; (2) developing a new course on computational nanoelectronics; and (3) training (through summer workshops) a diverse community of college teachers as well as K-12 students in the field of scientific computing and data analysis. Materials\/modules developed in the teaching\/training activities will be posted on NSF?s nanoHUB.org for use by the broader community.","title":"II-NEW: Southern Illinois HPC Infrastructure (SIHPCI)","awardID":"0855221","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[397084,"518429","564177","518496",397088],"PO":["565272"]},"159747":{"abstract":"When people play games for entertainment, they are free to choose whether to play at all and which games to play. So-called 'serious games' employ a media form players are accustomed to enjoying as entertainment for serious goals such as learning, health, and persuasion. Rather than voluntary and for fun, a serious game may in fact be a mandatory class assignment, a required part of corporate training, or a prescribed activity to improve brain health. Serious games may not be fun. Even games which are fun for many people (e.g., the Civilization series of games are some of the best selling games ever and are widely used as educational games), may not be \"fun,\" \"engaging,\" \"motivating,\" or whatever other words may be used to describe the rationale for using games by academics or designers for a distinct subset of the target audience. Motivation is known to be important for school learning yet motivation for serious games has not been studied. In the same way that learners hold different underlying affinities for intrinsic and extrinsic rewards associated with learning, it is posited in this project that gamers develop unique gaming motivation affinities and mindsets throughout their lifetime of gaming experiences. Player typologies classify players as achievers, explorers, socializers, or killers, but these typologies only consider voluntary play of a particular game or game genre. It is not yet known whether players easily and enthusiastically embrace games which do not fit their preferred gaming motivations, or if such mismatches interfere with engagement and learning. By definition, serious games piggyback on players' entertainment gaming experiences, yet they do so with no consideration of why and how different people play entertainment games, nor what the implications of those individual lifetime gaming motivation and experience differences are for how a serious game will be received. This project will develop and test drive the idea of a Gaming Motivation Profile (GMP), parallel to motivation and mindset theories. The project is risky, because GMP may turn out not to exist, or to be unimportant. The project is worthwhile because if indeed GMP mediates the impact of serious games, there are myriad implications for game design and for how serious games are introduced to improve their effectiveness. The proposed Phase 1 exploratory research seeks 1.) to articulate, explore, and collect normative data about the construct of gaming motivation profile (GMP) as an individual trait, 2.) to discover whether the way individuals play particular games is consistent with their GMP, 3.) to study what happens as far enacted play style and enjoyment when GMP is not available within a game. The proposed Phase 2 rresearch be a first step in examining the \"so what\" of GMP and serious gaming. Researchers will study how a learning game's and a brain game's intended outcomes (e.g., learning and brain training) are impacted when players' GMP (and therefore, their preferred play patterns) are or are not available in the game. The Phase 2 experiment will test the efficacy of manipulating regulatory fit (introducing task goals which are or are not consistent with the game) for improving the intended outcomes of a brain game and a learning game. <br\/><br\/>Understanding the impact of GMP on serious gaming intended outcomes holds promise to inform serious game design and to better serve diverse audiences for serious games. It is reasonable to expect, based on large gender differences in the quantity and quality of gaming, that GMP will vary by gender, age, and other demographics, with implications for more universal serious game design.","title":"EAGER: Collaborative Research: Motivation and Serious Gaming","awardID":"0943057","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["550870"],"PO":["564456"]},"160891":{"abstract":"Spatial awareness is the key to successful orientation and wayfinding. While navigation through familiar terrain allows us the luxury of reaching our destination without guidance, unfamiliar or only partially familiar environments require the use of external spatial information, which is most often presented verbally or in the form of maps. If we were to ask a knowledgeable local person for directions the information imparted to us might point out some landmarks along the way or inform us about a structuring present in the street names (e.g., that they are alphabetically ordered). People have long exploited the capability to recognize salient objects, and to use those objects to understand a space and guide their actions. But mobile GPS-based navigation systems typically overlook our abilities in spatial knowledge construction and application. The growing popularity of such devices has resulted in an increasing dependence on individual location-action pairs (e.g., turn left here) to guide us step by step; this has the drawback of not affording an overall understanding of the spatial environment, which in emergency situations, for example, may prove harmful. With spatial information now available in a much wider array of formats, with better currency and increased fidelity, it is time to rethink how to provide spatial information for orientation and wayfinding from the perspective of creating spatial awareness, via what the PI refers to as sapient interfaces. In this project the PI will explore first steps toward this goal, by drawing on theories from different fields that contribute to our understanding of the cognition of spaces. The central research question to be addressed is: How can spatial awareness be supported by a mapping system that focuses on the cognitively ergonomic organization and presentation of spatial information? The PI will seek a systematic understanding of the factors contributing to the development of spatial awareness (e.g., object saliency), and to identify principles and derive design guidelines for mobile navigation mapping systems that focus on the cognitively ergonomic organization and presentation of spatial information. A critical part of the research will be the cross-validation of formal approaches to spatial analysis; project outcomes will include a theoretical foundation of spatial awareness that is grounded in formal spatial analysis measures.<br\/><br\/>Broader Impacts: The growing dependence on GPS-based navigation systems has negative impacts on our ability to think spatially, because current devices provide information in a manner that fails to build an understanding of spatial relations. This project will rethink the way in which spatial information is provided by such systems, so as to foster rather than impede spatial thinking and to thereby avoid spatial illiteracy in coming generations.","title":"EAGER: Spatial Awareness Through Sapient Interfaces","awardID":"0948601","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[430271,430272],"PO":["565227"]},"150980":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Despite large acoustic differences in the speech of various talkers, humans are generally able to understand each other quickly and easily. The mechanisms by which humans map such variability onto a set of phonemes has been the subject of research for more than 50 years. This \"speaker normalization\" problem has generally been thought of in terms of normalizing the formant frequencies of a particular speaker with a reference set of formants. In this project, a novel approach to speaker normalization is explored, in which not formants but subglottal resonances<br\/>(SGRs) are normalized. SGRs have previously been shown to define a set of frequency bands within which formants may vary, yet retaining the same phonemic vowel quality. Normalizing SGRs (and associated frequency bands) therefore reduces formant variability in an effective way. In this project, effects of SGR normalization on automatic speech recognition<br\/>(ASR) performance are evaluated for both adult and child speakers of English and Spanish. In parallel, effects on human speech perception in multi-talker conditions are explored. Results are expected to improve ASR performance and shed light on human speech production and perception. The project will result in speech databases (including direct recordings of SGR acoustics) and ASR tools, which are critically useful for research in speech production, perception, speaker identification, and speech processing algorithms for cochlear implants and multi-lingual ASR. The collaboration in Engineering, Linguistics, Speech & Hearing, and Psychology facilitates a multidisciplinary learning environment.<br\/>Publications, results, databases, and tools will be disseminated to the research community.","title":"RI: Medium: Collaborative Research: The Effect of Subglottal Resonances on Machine and Human Speaker Normalization","awardID":"0905381","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["558131"],"PO":["565215"]},"161661":{"abstract":"This project is focused on a potentially transformational research study involving the simultaneous investigation of usability and security\/privacy technologies for location-based geo-social applications, with the objective of studying the usability, feasibility, and scalability of privacy-preserving and secure location-aware geo-social networking platforms for mobile devices. The approach is based on a belief that usability and security\/privacy are addressed properly and most effectively from the start. In particular, the project will study the usability of privacy-agile secure location-based communication and associated supporting protocols that scale to large numbers of users and accommodate various privacy levels suitable for different application domains. By studying the usability of location-aware protocols, the investigators propose methods that provide seamless connectivity and functionality over different networking technologies, without sacrificing the user experience. The investigators also plan to address other security issues in privacy-preserving operation, including authentication, access control and accountability. This project envisions a wide range of future applications with three unifying factors: (1) a geo-social undertone, i.e., applications that combine social groups and locality, (2) lack of, or desire to avoid using, fixed infrastructure facilities, and (3) need for both security and privacy. Although progress is starting on technologies for supporting such applications, there has been precious little work done on the study of usability factors with respect to the privacy and security users expect with their small-device location-based applications. The proposed project therefore has an ambitious goal: to study the usability of privacy-preserving geo-social technologies, including the user models, perceptions, interfaces, and feasible communication\/computation technologies for supporting futuristic geo-social applications on portable mobile devices in the aforementioned setting. Methods employed may include interviews, focus groups, and cognitive walkthroughs. One key feature of the approach is to study methods that shield location from identity, thereby allowing for location-based services and geo-social applications while also protecting user privacy, and, most importantly, to do so in a way that is most usable and effective from the user?s point of view.<br\/><br\/>Technologies using location and small devices are growing at a rapid rate, while techniques considering security and location and identity privacy are only now being addressed. Thus, usable systems that protect location-sensitive privacy concerns could have a major impact on society. The tools developed in this project will enable important and economically beneficial technologies to be developed for location-aware geo-social networks preserving privacy rights for the individuals using such services. In addition, a vital part of this project involves graduate-student participation in research. Thus, this project has the potential of bringing expanded research opportunities for developing the next generation of information technology researchers. Likewise, it also includes an important educational component.","title":"EAGER: Usable Location Privacy in Geo-Social Networks","awardID":"0953071","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521484","515757",432332],"PO":["565136"]},"150771":{"abstract":"This project will develop and validate a novel approach to modeling fMRI activations in rich experiments with multiple stimuli or tasks. Rather than rely on a spatial correspondence across subjects to identify robust activations, the proposed methods will employ a notion of functional consistency, removing the need to assume spatial alignment among functional areas in different subjects. The resulting models of fMRI activation will also naturally enable studies of anatomical variability in homologous functional regions across subjects. The motivation for this work comes from visual fMRI studies that present subjects with several categories of visual stimuli. As fMRI studies move towards more complex experiments that include more stimuli, the space of possible brain responses grows exponentially, presenting a serious challenge for analysis methods. Explicit representations of fMRI activation patterns that enable exploratory search in the space of possible brain responses are at the core of this project. Computational models of brain activity based on such representations will significantly enrich the utility of fMRI for investigating the functional organization of the brain.<br\/><br\/>The research team will develop computational methods for fMRI analysis naturally suited for experiments with a multitude of stimuli. The approach is to model the space of all possible activation profiles, to search for stable clusters of activation profiles, and to characterize functionally homogeneous sets of brain locations associated with these clusters. A natural extension of the model will not only identify stable activation profiles but also group stimuli based on the similarity of the evoked activation profiles in the brain. Furthermore, this approach will yield a model of spatial variability of the detected functional areas, leading to better functionally-guided registration algorithms. The methods will be validated in a set of empirical experiments with a large number of visual stimuli in object perception and recognition tasks. The fMRI studies in this project will produce new insights into the functional organization of the ventral pathway of the visual system.","title":"Finding Structure in the Space of Activation Profiles in fMRI","awardID":"0904625","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":[401912,401913],"PO":["564318"]},"153950":{"abstract":"Communication across networks with feedback and relays is an important, challenging, and largely open problem in information and communication theory. Systematic and scalable communication algorithms will enhance reliability, decrease coding complexity or delay, impart robustness to communication schemes by exploiting diversity, and in some cases increase the achievable communication rates. Since all modern communication systems employ multiple feedback mechanisms, a better understanding of communication feedback is imperative.<br\/><br\/>This research focuses on a deeper study of this topic by viewing it through the lenses of consensus algorithms and more general stochastic approximation algorithms. This approach yields scalable and robust algorithms for cases of extreme relevance to modern communication systems, e.g., network scenarios with noisy feedback. A confluence of problems, techniques and tools from information theory and distributed dynamic systems are utilized, with a potential transformative impact on both fields. In addition to analytical techniques and simulations, the team also utilizes facilities and experience realizing novel communication algorithms in a wireless network testbed based upon software-defined radios.<br\/><br\/>Any impact on the problem of communication across networks with noisy feedback will have immediate applications to most modern communication systems. Moreover, this research furthers the unification of the two aspects and research communities relevant to a more general information theory - one that considers both the transmission of data (classical information theory), as well as its utilization (classical dynamical systems). An emphasis on organizing special sessions in conferences, offering new graduate courses, including undergraduates in the experimental research, mentoring minority students, and furthering outreach to high school students interested in engineering is an integral part of the project.","title":"CIF: Small: A Stochastic Approximation Approach to Network Communications with Feedback","awardID":"0916716","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["540625","526930"],"PO":["564924"]},"153840":{"abstract":"The proliferation of camera-enabled consumer items, like cellular phones, wearable computers, and domestic robots, has introduced moving cameras, in staggering numbers, into everyday life. These cameras record our social environment, where people engage in different activities and objects like vehicles or bicycles are in motion. State-of-the-art structure from motion algorithms cannot reliably reconstruct these types of scenes. The overarching focus of this work is to develop the theory and practice required to robustly reconstruct a dynamic scene from one moving camera or simultaneously from several moving cameras.<br\/><br\/>To achieve this, the PI is developing a theory of imaging in dynamic scenes. A useful ?device? for analyzing dynamic scenes is to visualize them as constructs in spacetime, analogous to static structures in space. Much of the progress in multi-view geometry in static scenes has centered on the development of tensors that embody the relative positions of cameras in space. The dimensional analogue is being used to define corresponding analogues for multi-view geometry in dynamic scenes. A goal in this work is to derive geometric relationships within a system of independently moving cameras. To reconstruct unconstrained dynamic scenes, factorization approaches are being extended to spacetime to simultaneously reconstruct nonrigid structure from multiple moving cameras. <br\/><br\/>The algorithms that result from this research create the space for a host of new technologies in several industries such as autonomous vehicle navigation, distributed visual surveillance, aerial video monitoring and indexing, cellphone interface, urban navigation, coordination and planning for autonomous robots, and human-computer interface.","title":"RI: Small: Spacetime Reconstruction of Dynamic Scenes from Moving Cameras","awardID":"0916272","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["563366"],"PO":["564318"]},"164730":{"abstract":"Texas A&M University, in collaboration with Rensselaer Polytechnic Institute and Auburn University, proposes to use culturally responsive approaches to attract and retain high school students to computer science. They will expand two frameworks that have been developed for math education into computing education. The AADMLSS City Stroll (African American Distributed Multiple Learning Styles System) and CSDT (Culturally Situated Design Tools) are interactive environments that use culturally relevant cues to teach math. AADMLSS City Stroll system is a game-like environment that includes instruction, practice, and assessment. CSDTs are web-based applets, based on ethnomathematics, that is, the mathematical knowledge embedded in cultural designs such as cornrow hairstyles, Native American beadwork, Latino percussion rhythms, etc. The essential idea of CSDTs is one of translating knowledge from informal to formal systems. The goals of the proposed project are: (1) to assist the efforts to extend the work on these math educational tools to include computing; (2) to develop a institutional \"pipeline\" such that K-12 students successfully participating in these activities can maximize their odds of entering undergraduate programs in computing; and (3) extend the current work with CSDTs and AADMLSS, from the local or regional scale to the national scale, by incorporating it into the Boys and Girls Clubs of America (BGCA).","title":"Collaborative Proposal: BPC-DP: Incorporating Cultural Tools for Math and Computing Concepts into the Boys and Girls Clubs of America","awardID":"0969240","effectiveDate":"2009-09-09","expirationDate":"2013-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["542299"],"PO":["561855"]},"153730":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The TEAMS project applies digital evolution to the design of robust communication services for cooperating groups of robots. Example applications include teams of robots for disaster relief operations, assisting humans in dangerous occupations, and monitoring of critical infrastructure and public service facilities such as drinking water reservoirs. In digital evolution, a population of self-replicating computer programs exists in a user-defined computational environment and is subject to mutations and natural selection. Evolved algorithms <br\/>(sequences of instructions comprising the genomes of digital organisms) can be recompiled to execute directly on hardware platforms. The project explores three overlapping classes of behavior: distributed self-organization of nodes; collective communication operations that tolerate adverse conditions; and mobility-aided communication methods, where nodes change their locations in order to improve communication performance. Evolved behaviors are evaluated on an NSF-sponsored digital evolution testbed containing a heterogeneous collection of microrobots. The ability to observe the evolutionary process in digital organisms provides a powerful method to investigate the driving forces in complex systems. The TEAMS project exploits this open-ended method of exploration to find better ways to construct software for mobile robotic systems that need to interact with the physical world, and each other, in order to solve problems. On a broader scale, the project includes several innovative educational and outreach components, such as an after-school program to provide economically disadvantaged K-12 students with exciting hands-on experiences involving evolutionary computation, adaptive software, and robotics.","title":"CSR:Small: TEAMS -- Transplanting Artificial Life Behaviors to Mobile Robots","awardID":"0915855","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["472159"],"PO":["565255"]},"153984":{"abstract":"PROPOSAL NO: 0916837 <br\/>INSTITUTION: University of Texas at Austin <br\/>PRINCIPAL INVESTIGATOR: Touba, Nur<br\/>TITLE: Next Generation Test Compression Technology<br\/><br\/><br\/>Abstract<br\/><br\/> Testing integrated circuits (ICs) requires storing large amounts of test data on a tester and transferring it to\/from the chip-under-test. The bandwidth between the tester and chip is very limited due to limited pins and tester channels. Test data volume continues to grow dramatically with increasingly dense system-on-chips (SOCs) and three-dimensional ICs as well as the need for additional tests to target defects in nanometer designs. A major development in the field over the past decade has been the emergence of test compression technology which stores test data on the tester in compressed form and decompresses it on-chip. The commercialization of this technology has helped immensely in keeping up with rising test data volume. However, going forward, there is a need for a next generation of test compression technology that can provide significantly greater compression to handle the larger designs of the future. This research will develop new theory, concepts, and architectures that are fundamentally different from existing commercial technology and have the potential for providing an order of magnitude or more improvement for test stimulus compression as well as output response compaction.<br\/><br\/> Society increasingly relies on correct and dependable operation of electronic devices. The impact of this research will be to develop new technology to keep test costs down and make it economical to fit in more tests to improve product quality. This will be critical as the manufacturing process becomes increasingly difficult to control at smaller geometries. Participation of undergraduates, women, and minorities will be actively encouraged.","title":"SHF:Small: Next Generation Test Compression Technology","awardID":"0916837","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["517957"],"PO":["562984"]},"153632":{"abstract":"The research involves the design and analysis of efficient algorithms for fundamental problems that arise in studies of the three-dimensional structures of proteins. Graph-theoretic problems underlie these studies, since protein structures are naturally (and sufficiently) represented by graphs that have vertices for the individual amino acid residues and edges between close pairs. However, graph-theoretic formalisms lead to computationally hard optimization problems, further complicated by extensive amounts of noise in experimental data. Motivated by specific challenges in nuclear magnetic resonance spectroscopy and other protein structure studies, the project addresses two significant algorithmic problems: identifying correspondences between a pair of graphs where one is a significantly corrupted version of the other, and determining three-dimensional coordinates for the vertices of a graph, given approximate, noisy distance measurements for its edges. <br\/><br\/>The first algorithmic problem is a form of graph matching, and the project focuses on developing efficient search algorithms to uncover correspondences, with random graph models to rigorously analyze the algorithms and study threshold phenomena characterizing robustness to noise. In an application to analysis of NMR data, one of the graphs represents the protein and the other the data, a noisy, ambiguous set of atomic interactions; the goal is to match the NMR-identified interactions with specific atomic interactions in the protein. The second algorithmic problem is Euclidean embedding for sparse geometric graphs, and the research involves development of algorithms to render such graphs amenable to low rank distance matrix reconstruction methods, generalizing the reconstruction methods to exploit the underlying geometric structure and account for the confounding noise structure. In the NMR setting, the graph represents NMR-probed through-space atomic interactions, and the goal is to compute structures consistent with the experimental data and biophysical constraints. Both problems are fundamental to numerous other significant applications in protein structure studies.","title":"AF:Small:Collaborative Research: Algorithmic Problems in Protein Structure Studies","awardID":"0915388","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["511584"],"PO":["565223"]},"153753":{"abstract":"Abstract: Critical infrastructures are complex physical and cyber-based systems that form the lifeline of modern society, and their reliable and secure operation is of paramount importance to national security and economic vitality. In particular, the cyber system forms the backbone of a nation?s critical infrastructures, thus a major cybersecurity incident could have significant negative impacts on the reliable, efficient, and safe operations of the physical systems that rely upon it. Recent findings, as documented in government reports and literature, indicate the growing threat of cyber-based attacks on our nation?s power grid and other critical infrastructures. The goal of this project is to develop a comprehensive cybersecurity framework and algorithms for securing the electric energy infrastructure, and implement a novel curriculum, which include: (i) developing an integrated risk modeling methodology that models both cyber attacks on the Supervisory Control and Data Acquisition (SCADA) system and the resulting impacts on the performance and stability of the power grid; (ii) developing risk mitigation algorithms, both in cyber and power system domains, to prevent and mitigate cyber attacks on the power grid; (iii) evaluating the risk models and algorithms through a combination of model, simulation, and testbed-based evaluations using realistic system topologies and attack scenarios; (iv) implementing a novel curriculum on cybersecurity of critical infrastructure systems through graduate courses and undergraduate projects. This project?s outcome will have broader impacts in securing our nation?s power grid and other critical infrastructures against cyber attacks, and creating a skilled workforce in this critical area of national need.","title":"TC: Small: Cyber Security of Electric Power Infrastructure: Risk Modeling and Mitigation","awardID":"0915945","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553535","553643"],"PO":["564223"]},"153874":{"abstract":"A large class of distributed data-rich applications, including distributed data mining, distributed workflows, and Web 2.0 Mashups, are increasingly relying on cloud services to meet their data storage and computing demands. However, today, these applications are responsible for combining data and results from different specialized cloud services individually, which can lead to significant performance and reliability bottlenecks, due to the lack of appropriate resources connecting the applications to multiple clouds, resulting in a significant impediment to their successful deployment. This project proposes a cloud proxy network that allows optimized and reliable data-centric operations to be performed at strategic network locations. In this model, proxies may take on several data-centric roles: interacting with cloud services, routing data to each other, caching data for later use, and invoking compute-intensive data operators for intermediate processing. The proposed solution will enable an efficient coupling of cloud services to yield improved end-to-end performance and reliability for newly emerging data-intensive applications. This project will explore the potential of the proxy network architecture by evaluating its merits using a volunteer approach, focusing on four main research challenges: Proxy Performance, Proxy Reliability, Proxy Information Sparsity, and Proxy Selection.<br\/><br\/>The broader impact of this project is to amplify the effectiveness and productivity of diverse scientific, social, and engineering communities for enabling data-driven scientific inquiry in a performance-efficient and reliable manner. Proxy middleware will be released to the wider community towards this end. Educating a new generation of students in data-centric computing through major curriculum innovation is also proposed.","title":"DC: Small: One Thousand Points of Light: Accelerating Data-Intensive Applications By Proxy","awardID":"0916425","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["543508","543510"],"PO":["560586"]},"153995":{"abstract":"CIF: Small: Collaborative Research: Wireless Networks: Fundamental Limits via Extremal Entropy Properties<br\/><br\/>Using extremal entropy properties to characterize the fundamental performance limits of network communication is a tradition of information theory. Most historical successes, however, relied on one particular extremal entropy inequality: the entropy-power inequality of Shannon and Stam, which, though powerful, applies mainly to networks with certain degradedness structure. Moreover, wireless features such as multiple-input multiple-output (MIMO) communications, channel uncertainty incurred by fading, and secrecy constraints due to the broadcast nature of radio communication bring new challenges that cannot be overcome by the entropy-power inequality of Shannon and Stam alone. This situation calls for in-depth investigations of the interaction between converse problems in network information theory and extremal entropy properties in statistics, resorting to powerful statistical tools to solve important communication engineering problems.<br\/><br\/>The specific goals of this research are: 1) to examine systematic ways of establishing extremal entropy properties through links between information theory and statistics; 2) to establish channel-enhancement as a general framework for solving the converse problems for MIMO downlink communication; and 3) to identify general frameworks for solving the converse problems for collaborative communication in cognitive wireless networks. <br\/><br\/>Recent years have seen substantial efforts in designing new coding schemes to achieve better performance for wireless networks. Fundamental understanding of the limits of these coding schemes is thus extremely important from the engineering viewpoint to direct future research and to prevent over-engineering and bolster confidence for simple and structured coding schemes. Intellectual results obtained from this research will also be disseminated via course developments on network information theory and wireless communications at Texas A&M and the University of Hawaii.","title":"CIF: Small: Collaborative Research: Wireless Networks: Fundamental Limits via Extremal Entropy Properties","awardID":"0916867","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["297790"],"PO":["564924"]},"153522":{"abstract":"Design of today's electronic systems would not be possible without the tools that automate the process of integrating billions of nano-scale components--e.g. into the \"brain\" of an iPhone. As technology advances towards mobile devices that are smaller yet more powerful, these tools need to evolve as fast as the systems that they help design--in fact faster, because the nano-scale components not only grow in numbers but also shrink in size, bringing along with them new challenges.<br\/><br\/>To improve existing design-aid tools, a new window of opportunity has arisen due to the emergence of a more powerful yet affordable computational platform: a network of multi-core computers working together as if it were one enormous machine. By leveraging this platform the proposed research investigates alternative design automation strategies which traditionally were deemed to be too time-consuming. <br\/><br\/>The focus of the research is to improve an important step of the design process known as global routing, the step in which designers plan how the billions of nano-scale components will be interconnected on the chip. This planning can significantly impact the severity of many issues in subsequent stages of the design cycle, yet it has to be done quickly. With the aid of large-scale parallelism provided by grids, the research aims to demonstrate that the use of a computational technique called integer programming, which was previously viewed as too time-consuming for global routing, can help generate significantly higher quality solutions while meeting practical runtime requirements.<br\/><br\/>Successful completion of the research contributes to faster delivery of electronic products to market with lower design cost, resulting in stronger businesses that can initiate new projects in the technology sector, and hence in the creation of more jobs.","title":"SHF:Small:Parallel ILP-Based Global Routing on A Grid of Multi-Cores","awardID":"0914981","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["469654"],"PO":["562984"]},"161145":{"abstract":"Computer graphics has been successfully used in a wide range of cultural heritage applications.<br\/>It has been proven both in the context of study by subject specialists and in the preparation of exhibits for education of the general public. Each year hundreds more computer graphics based cultural heritage projects are initiated around he world. However, the use of digital material remains demanding and requires technologists as well as subject specialists. This research project will impact the development of exhibitions used to communicate historical and cultural information to the general public. Preparing such exhibits will be easier for subject specialists, and it will be possible to create more engaging interactive displays of information<br\/><br\/>The goal of this research is to change the methods for both authoring and using digital objects in communication. The research addresses the problem of generating compelling 3D displays of heritage sites, where large archival photographic documentation is available. Recent innovations in sketch-based modeling, in particular the ?Mental Canvas? framework that relies only on 3D strokes rather than full solids, will be exploited along with computer vision techniques. The Mental Canvas framework will allow user annotation in order to facilitate the application of recent improvements in image feature detection and bundle estimation to compute 3D points from archival images. Annotation is required since current methods often fail when all camera characteristics are unknown and photographs were not taken from views designed to facilitate 3D reconstruction. The output of the proposed system will be a 3D model that can be easily navigated by a casual user. The system will then be able to naturally navigate through space and browse solid models, archival imagery and textual data. An exhibit of artifacts and imagery from the Dura Europos site that is being prepared by the Yale Art Gallery is serving as the testbed for the research.","title":"EAGER: Combining Sketching and Computer Vision Techniques in Cultural Heritage Applications","awardID":"0949911","effectiveDate":"2009-09-01","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["541919"],"PO":["532791"]},"153654":{"abstract":"Computer systems are increasingly located in places, where they can be physically accessed by people who are not authorized to have unrestricted control of and access to these systems. Examples of this include company laptops carried by employees, robotic vehicles, gaming consoles with copyright protection mechanisms, and remote users of servers in data-centers. An emerging threat in such scenarios are hardware attacks, where snooping devices are attached to the system to directly read and\/or modify data within the system. These attacks can circumvent all traditional security protections in the system, such as password checks, access permissions for data files, etc.<br\/>To address these threats, researchers and processor makers have proposed or developed various types of secure processor architectures, which encrypt and continuously verify data in the system?s memory. However, these secure processors are far from being ready for widespread use, primarily because they focus on a single-processor, non-mobile system that is already up and running and executing a single application. <br\/><br\/>This research project will investigate how to overcome these limitations, focusing on mechanisms for secure boot-up and system configuration, secure communication between and migration of applications, secure access to peripheral devices (including the network). In essence, this project will build the intellectual framework that will be needed to make computers secure regardless of their physical location, preventing unauthorized access even if the system is captured, stolen, or actually owned by a potentially malicious entity. Other broader impacts of this project include improvements in education and workforce, by making computer hardware designers more aware of physical security and by making computer security experts more aware of implications of physical (hardware) attacks.","title":"SHF: Small: Collaborative Research: Beyond Secure Processors - Securing Systems Against Hardware","awardID":"0915501","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["485790"],"PO":["366560"]},"153775":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The problems of indoor location computing are not yet fully solved. They still present serious challenges and involve phenomena not yet fully understood. There is indeed a considerable distance toward a fully scalable and affordable system that is readily deployable using existing technologies (such as IEEE 802.11), and is able to provide accurate location information for indoor mobile computing. This project is developing realistic radio propagation models and adaptive signal-location maps particularly adapted to different building environments leading to robust and competitive techniques for location determination. The research team is investigating an innovative direction to develop a benchmark standard in order to capture and classify critical environmental and system factors and to provide performance bounds as well as reproducible test-beds for indoor research. The key of the research is to quantify radio signal measurement inaccuracy under various environments. This is achieved by measuring packets during the remodeling process of the second floor of the Science and Technology building, the new construction of the Student Campus Center at USCB, and by simulating various partitions between the transmitter and the receiver. This project transforms indoor location determination systems from high cost, labor intensive, imprecise, and static technologies to an affordable, automated, accurate, and dynamic system. This project attacks theoretical and systems challenges and will enable practical deployment of the ARIADNE indoor system. Moreover, this exciting project will help attract, educate and retain talented undergraduate students and also motivate them for higher studies.","title":"NeTS: Small: RUI: Dynamic Indoor Location Computing and Benchmarking","awardID":"0916012","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["537119"],"PO":["565303"]},"153896":{"abstract":"One way to form a model of massive data sets is to use clustering techniques that summarize the data by several cluster representatives. However, clustering huge data sets is a very challenging problem whose difficulty increases further when the data is dynamic. We are developing scalable and robust stream summarization methods to provide a concise summary of huge multi-dimensional data streams that keep track of each discovered cluster or component of the summary through time, and that store only milestones corresponding to the occurrence of significant changes in these cluster representatives. Moreover to handle possibly diverse data formats and different sources of data, we are using a semi-supervised framework for (i) combining diverse representations of the data, in particular where data comes from different sources, some of which may be unreliable or uncertain; and (ii) exploiting optional external concept set labels to guide the clustering of the main data set in its original domain.<br\/><br\/>Our methods have tremendous impact on applications that deal with streaming data in general, and more specifically on monitoring data streams in real-life dynamic settings. For example, as more and more everyday activities move online, network and Web data has been increasing at a rapid pace that precludes standard and classical data analysis methods, and call instead for real time analysis. The same can be said about the deluge of data that is being or about to be generated by new and future sensor networks, astronomical observatories, and missions in space. Thus, new research efforts and paradigms are needed and will have a strong impact on our ability to digest and make sense of this data.","title":"DC: Small: Stream Clustering Algorithms in Mixed Domains with Soft Two-way Semi-Supervision","awardID":"0916489","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":[409510],"PO":["560586"]},"152565":{"abstract":"Humans, rats and other vertebrates, relying on their advanced nervous systems, are far superior at dealing with the uncertainties of the world than are artificial systems. Thus, a machine, whose behavior is guided by a neurobiologically inspired system, might demonstrate the flexible, autonomous behavior normally attributed to biological organisms. Biological organisms have the ability to respond quickly to an ever-changing world. Because this adaptability is so critical for survival, all vertebrates have sub-cortical structures, which comprise the neuromodulatory systems, to handle uncertainty and change in the environment. Attention, which is influenced by neuromodulation, plays a significant role in animal's ability to respond to such changes. Different neuromodulatory systems are thought to play important and distinct roles in attention. A collaborative approach, which compares rodent experiments with robots having simulated nervous systems, will examine these attentional systems. These experiments will lead to a better understanding of how animals cope with uncertainty in the environment, and will lead to the design of a robot capable of flexible and complex behavior. This work has the potential of being paradigm-shifting technology that could find its way in many practical applications.<br\/><br\/>In an interdisciplinary approach, a robotic system, whose design is based on the vertebrate neuromodulatory system and its effect on attention, will be constructed and tested under similar experimental conditions to the rat, and then in a more practical application. This approach, which combines computational modeling and robotics with rodent behavioral and electrophysiological experiments, will lead to a better understanding of how areas of the brain allocate attentional resources and cause the organism to respond rapidly to essential events and objects. Two of these neuromodulatory systems, the cholinergic and noradrenergic, are thought to play important and distinct roles in attention. Expected uncertainty, the known degree of unreliability of predictive relationships in the environment, drives activity within the cholinergic system. Unexpected uncertainty, large changes in the environment that violate prior expectations, drives activity within the noradrenergic system. These systems modulate activity in brain areas to properly allocate the attention to stimuli in the environment necessary for adequate learning to occur and fluid behavior to be maintained. This knowledge will be used to construct a robust, intelligent robotic system whose capability to adapt to change, and behave effectively in a noisy, complex environment will rival that of a biological system.","title":"RI: Large: Collaborative Research: Understanding Uncertainty in Rats and Robots","awardID":"0910710","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["541837"],"PO":["564318"]},"155843":{"abstract":"Proposal #: CNS 09-23386<br\/>PI(s): Siegel, Howard Jay <br\/> Burns, Patrick J.<br\/>Institution: Colorado State University <br\/>Title: MRI\/Acq.: ISTeC High Performance Computing Infrastructure for Science and Eng Research<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Project Proposed:<br\/>This project, acquiring High Performance Computing (HPC) instrumentation, aims to support much larger and more complex problems in science and engineering (especially for data intensive applications), add greater physical fidelity to existing models, facilitate application of HPC to new areas of research and discovery, and support training to attract new researchers. Filling the current void in cyberinfrastructure (CI) resources, the project is expected to change the culture of discovery at the institution, elevating HPC to the level of central infrastructure. Advanced networking will facilitate the interaction of Tier-3 system with other systems, and enhance researchers? abilities to utilize Tiers 1 and 2 systems worldwide. The principal focus of the system will be data- (and often compute-) intensive applications in NSF funded research areas, such as design of extreme ultraviolet lasers, weather forecasting, computational physics, climate change, atmospheric modeling, bioinformatics, network traffic analysis, robotics, computational electromagnetics, remote sensing, robust resource allocation, and magnetic materials. Tier -3 system will expand the domain and range of computations, allowing problems of greater fidelity including multi-physics algorithms and much finer spatial and temporal resolutions. The work is carried out with CSU-Pueblo, a Hispanic-serving institution, as full partner.<br\/>Broader Impacts: <br\/>The existing Tier-3 will share cycles of different architectures for educational purposes: workshops, seminars, expertise via affinity groups, instructors, courses, and students. The institution, a large producer of STEM graduates, will integrate HPC into the STEM curricula and K-12 teacher training programs with emphasis on inclusion of women and minorities. Member companies of the ISTeC Industrial Advisory Council have expressed interest in participating in the activities. Existing courses support the activity through teams consisting of application experts from diverse disciplines (breadth), and mathematicians (algorithms) and computists (mapping applications and algorithms to parallel architectures) (depth).","title":"MRI: Acquisition of the ISTeC High Performance Computing Infrastructure for Science and Engineering Research Projects","awardID":"0923386","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["542085","542086"],"PO":["557609"]},"151003":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The nature of telecommunications networks is rapidly changing.<br\/>Commodity smart<br\/>mobile phone frameworks such as Android and Openmoko invite developers and end users to build applications, modify the behavior of the phone, and use network services in novel ways. However, while simultaneously spurring incredible innovation, the move to open systems alters the underlying performance and security assumptions upon which the network was designed. Such changes invite vulnerabilities ranging from merely vexing phone glitches to catastrophic network failures. The current infrastructure lacks the basic protections needed to protect an increasingly open network, and it is unclear what new stresses and threats open systems and services will introduce.<br\/><br\/>This research analytically and experimentally investigates defensive infrastructure addressing vulnerabilities in open cellular operating systems and telecommunications networks. In this, we are exploring the requirements and design of such defenses in three coordinated efforts; a) extending and applying formal policy models for telecommunication systems, and provide tools for phone manufacturer, provider, developer, and end-user policy compliance verification, b) building a security-conscious distribution of the open-source Android operating system, and c) explore the needs and designs of overload controls in telecommunications networks needed to absorb changes in mobile phone behavior, traffic models, and the diversity of communication end- points.<br\/><br\/>This research symbiotically supports educational goals at the constituent institutions by supporting graduate and undergraduate student research, and is integral to the security and network curricula.","title":"TC: Medium: Collaborative Research: Security Services in Open Telecommunications Networks","awardID":"0905434","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[402531],"PO":["565327"]},"153786":{"abstract":"Geometric models composed of millions (or more) of facets are common today due to improved technologies for generating high-resolution complex models. The large size makes it infeasible to perform some fundamental geometric operations on these models. For instance, more than 1.4 billion geometric union operations are required to compute the Minkowski sum of the David model. Re-designing existing algorithms for large models would require significant time and effort, and may not always be possible. This project is investigating approximate convex decomposition (ACD), an alternative representation for large geometries that approximately represents the original model using a set of convex objects. By using the much smaller convex approximation in place of the original model, ACD allows existing (inefficient) methods and software to perform efficiently for large geometries without designing and implementing new algorithms. An important goal of this project is to develop simple algorithms that not only allow efficient reconstruction but also allow practical implementation. <br\/><br\/>This project will make significant contributions to fundamental problems in geometric computing, such as Minkowski sum, continuous motion collision detection, general penetration depth estimation, and swept volume. Beyond these fundamental geometric operations, this project will provide new ways to handle geometric problems in several areas of robotics (e.g., environment\/map representation, motion planning and grasp planning), in pattern recognition (e.g., structural salient feature recognition, visual-based part decomposition and motif identification in protein structures), and in computer graphics (e.g., data compression, physically-based simulation and skeletonization). <br\/>The software developed by this project will be provided to the public domain.","title":"DC: Small: Collaborative Research: Shape Representation of Large Geometries via Convex Approximation","awardID":"0916040","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["511370"],"PO":["562984"]},"151014":{"abstract":"Contemporary Internet malware is constantly evolving and making antivirus and intrusion detection systems increasingly obsolete. It is no longer acceptable to simply rely on binary signatures for malware identification. Both current and future generations of malware will require entirely new detection strategies that can tolerate the rapid perturbations in binary structure and payload delivery mechanisms. A promising direction to this end is the use of multi-perspective, behavioral-oriented paradigms for malware identification. In this project, we propose a new approach to 1) automatically extract infection knowledge, based on a multi-perspective, behavior-oriented view, and 2) rapidly apply this gained knowledge to diagnose the presence of malware in host computer systems. For each malware family, a probabilistic profile will be automatically extracted, which captures the invariant behavioral features of its members. This envisioned knowledge-extraction process should provide sufficient abstraction in its invariant behavior characterization such that future malware variants can be recognized. We also propose a Bayesian framework for diagnosing live malware infections on fielded computer systems. If successful, this research will introduce a new complementary strategy for diagnosing malware infections in ways that cannot be defeated through the current suite of antivirus countermeasures.","title":"TC: Medium: Collaborative Research: Multi-Perspective Bayesian Learning for Automated Diagnosis of Advanced Malware","awardID":"0905478","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["416053","451649"],"PO":["565136"]},"153797":{"abstract":"The goal of this project is to incorporate key elements of telecommunication policy and economics into Internet architecture. As a result of technical, economic and public policy forces, the Internet's original design principles -- layering and end-to-end -- are increasingly violated. Internet Service Providers are deploying quality of service mechanisms, but only allowing their use for certain applications sold to their own subscribers. Some Internet Service Providers have used deep packet inspection techniques to implement traffic management practices that throttle or block peer-to-peer applications. <br\/><br\/>To counteract this deterioration, this project will propose an interdisciplinary approach to update the Internet architectural principles to account for telecommunications policy and economics. The project will identify the flaws of the end-to-end and layering models that are not withstanding the technical, economic, and legal forces upon networking; modify these models so that they promote good technical design, respond appropriately to economic pressures, and encourage beneficial outcomes that benefit society; and validate these new models and illustrate their potential use by applying them to three case studies -- net neutrality, traffic management, and Quality of Service.<br\/><br\/>This research will have a broad impact. The P.I. is developing an undergraduate course on ?The Internet and Public Policy?. This research will help bridge the gulf that exists between communication lawmakers and networking researchers by informing staff members in the United States Congress about the technical aspects of telecommunication issues, and by developing an architectural framework for the networking research community to help them consider impacts of network economics and law.","title":"NetSE: Small: Incorporating Telecommunications Policy and Economics into Internet Architecture","awardID":"0916085","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["516930"],"PO":["564993"]},"152587":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Proposal#: 0910767<br\/>Collaborative Proposal #s: 0909980, 0910483, 0910653<br\/>Title: TC: Large: Collaborative Research: Trustworthy Virtual<br\/>Cloud Computing<br\/>PIs: Peng Ning, Xuxian Jiang, and Mladen Vouk<br\/>Abstract:<br\/><br\/>Virtual cloud computing is emerging as a promising solution to IT<br\/>management to both ease the provisioning and administration of complex<br\/>hardware and software systems and reduce the operational costs. With the industry?s continuous investment (e.g., Amazon Elastic Cloud Computing, IBM Blue Cloud), virtual cloud computing is likely to be a major component of the future IT solution, which will have significant impact on almost all sectors of society. The trustworthiness of virtual cloud computing is thus critical to the well-being of all organizations or individuals that will rely on virtual cloud computing for their IT solutions. <br\/><br\/>This project envisions trustworthy virtual cloud<br\/>computing and investigates fundamental research issues leading to this vision. Central to<br\/>this vision is a new security architecture, which harnesses new<br\/>opportunities and capabilities such as built-in out-of-band system<br\/>access, processor and hardware support for trusted computing, and<br\/>out-of-box examination by hypervisors. This project focuses<br\/>on key research issues following this security architecture, including new<br\/>security services that enhance the trustworthiness of virtual cloud<br\/>computing, protection of management infrastructure against malicious<br\/>workloads, and protection of hosted workloads from potentially<br\/>malicious management infrastructure.<br\/> The research will enable the adoption of virtual cloud computing for critical IT management in industry and government organizations. This project will involve both graduate and undergraduate students, and will produce open source software and tools, which will be made available to the public.","title":"TC: Large: Collaborative Research: Trustworthy Virtual Cloud Computing","awardID":"0910767","effectiveDate":"2009-09-15","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553865","553866","434616"],"PO":["565327"]},"153324":{"abstract":"URL: A Unified Reinforcement Learning Approach for Auto-configuration of<br\/>Virtualized Resources and Appliances<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Cloud computing, unlocked by virtualization, is emerging as an increasingly important service-oriented computing paradigm. The goal of this project is to develop a unified learning approach, namely URL, to automate the configuration processes of virtualized machines and applications running on the virtual machines and adapt the systems configuration to the dynamics of cloud. The URL approach features three innovations: First is a reinforcement learning (RL) methodology for auto-configuration of virtual machines (VMs) on distributed computing resources in a real-time manner. Second is a unified RL approach for auto-configuration of both VMs and multi-tier web appliances. It is able to adapt the VM resource budget and appliance parameter settings in a coordinated way to the cloud dynamics and the changing workload for the objective of service quality assurance. Third is a distributed, cooperative RL approach that allows the RL-based learning and optimization agents running on different servers and with independent action choices to make an optimal joint configuration policy in large-scale systems. <br\/><br\/>Deliverables that emerge from this project will advance discovery and understanding of autonomic management of large-scale complex systems with profound technical, economic, and societal impact. In addition, this project has an integral educational component. It will raise the level of awareness of system management issues and the power of machine learning technology, and prepare the students to enter the industry with adequate understanding of the challenges and opportunities in cloud computing.","title":"CSR: Small: A Unified Reinforcement Learning Approach for Autoconfiguration of Virtualized Resources and Appliances","awardID":"0914330","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["451038"],"PO":["565255"]},"151025":{"abstract":"Contemporary Internet malware is constantly evolving and making antivirus and intrusion detection systems increasingly obsolete. It is no longer acceptable to simply rely on binary signatures for malware identification. Both current and future generations of malware will require entirely new detection strategies that can tolerate the rapid perturbations in binary structure and payload delivery mechanisms. A promising direction to this end is the use of multi-perspective, behavioral-oriented paradigms for malware identification. In this project, we propose a new approach to 1) automatically extract infection knowledge, based on a multi-perspective, behavior-oriented view, and 2) rapidly apply this gained knowledge to diagnose the presence of malware in host computer systems. For each malware family, a probabilistic profile will be automatically extracted, which captures the invariant behavioral features of its members. This envisioned knowledge-extraction process should provide sufficient abstraction in its invariant behavior characterization such that future malware variants can be recognized. We also propose a Bayesian framework for diagnosing live malware infections on fielded computer systems. If successful, this research will introduce a new complementary strategy for diagnosing malware infections in ways that cannot be defeated through the current suite of antivirus countermeasures.","title":"TC: Medium: Collaborative Research: Multi-Perspective Bayesian Learning for Automated Diagnosis of Advanced Malware","awardID":"0905518","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[402605,"548389"],"PO":["565136"]},"163125":{"abstract":"The scale, resolution and fidelity of scientific simulations are limited by the size and balance of the next-generation high performance computing systems. Because of this critical dependency between computing resources and new scientific capability, it is crucial to engage the scientific and HPC community to develop an understanding of the requirements for new computing environments. <br\/><br\/>We will hold a series of quarterly workshops over the next year to bring the community together to discuss these important issues and build a pathway for the future of computational science.<br\/><br\/>A core group of 30 leading scientists, vendors and resource providers will be selected to convene for a series of three one-day meetings. We will focus on user requirements and lessons learned from the current programs including the benefits and challenges of the current architectures and deployments. The final workshop will engage 75 members of the community for one and a half days.<br\/><br\/>We will produce a concise summary of the state of the computing environments in the US and around the world today, a set of quantitative descriptions of current application requirements and how well those requirements match the computing environment that is being provided through federal, state and other funding. Included will be a projection of the future requirements for scientific and engineering applications and a corresponding description of what the future computing environment should be to meet these needs. The workshops reports will also consider and comment on mechanisms by which the computing environment might be provided over the next 5-10 years.<br\/><br\/>Broader Impact<br\/>Continuing and developing the US supercomputing program will complement existing and upcoming education, outreach and training efforts. These efforts are geared to reach a wide range of people: from K-12 to post college, under-represented groups and women and teachers and scientists.<br\/><br\/>Soliciting input from the entire community via a website will also allow everyone to participate in this series of workshops, which is appropriate since the entire community will benefit from the continuation of the supercomputing program.","title":"Community Input on the Future of High-Performance Computing","awardID":"0960905","effectiveDate":"2009-09-15","expirationDate":"2011-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7476","name":"ETF"}}],"PIcoPI":["463616"],"PO":[436368]},"158901":{"abstract":"Data provenance documents the inputs, entities, systems, and processes that influence data of interest---in effect providing a historical record of the data and its origins. The generated evidence supports essential forensic activities such as data-dependency analysis, error\/ compromise detection and recovery, and auditing and compliance analysis.<br\/><br\/>This collaborative project is focused on theory and systems supporting practical end-to-end provenance in high-end computing systems. Here, systems are investigated where provenance authorities accept host- level provenance data from validated provenance monitors, to assemble a trustworthy provenance record. Provenance monitors externally observe systems or applications and securely record the evolution of data they manipulate. The provenance record is shared across the distributed environment.<br\/><br\/>In support of this vision, tools and systems are explored that identify policy (what provenance data to record), trusted authorities (which entities may assert provenance information), and infrastructure (where to record provenance data). Moreover, the provenance has the potential to hurt system performance: collecting too much provenance information or doing so in an inefficient or invasive way can introduce unacceptable overheads. In response, the project is further focused on ways to understand and reduce the costs of provenance collection.","title":"Collaborative Research: Secure Provenance in High-End Computing Systems","awardID":"0937944","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["521556"],"PO":["565272"]},"157812":{"abstract":"The goal of this project is to develop a novel cyber-physical system (CPS) for performing multimodal image-guided robot-assisted minimally invasive surgeries (MIS). The approach is based on: (1) novel quantitative analysis of multi-contrast data, (2) control that uses this information to maneuver conformable robotic manipulators, while adjusting on-the-fly scanning parameters to acquire additional information, and (3) human-information\/machine-interfacing for comprehensive appreciation of the physical environment. <br\/><br\/>The intellectual merit arises from the development of: (1) a CPS that relies on \"real\" and \"real-time\" data, minimizing parametric and abstracted assumptions, extracts and matures information from a dynamic physical system (patient and robot) by combining management of data collection (at the physical sensor site) and data analysis (at the cyber site), (2) \"smart sensing\", to control data acquisition based on disruptive or situation altering events, (3) control coordination by interlacing sensing, control and perception, and the incorporation of steerable tools.<br\/><br\/>The societal impact arises from contributions to a leap in MIS: from \"keyhole\" visualization (i.e., laparoscopy) to in-situ real-time image guidance, thereby enabling a wider range of MIS. This will directly benefit patients and their families (faster recovery\/reduced trauma). Economic impact arises from the cost-effectiveness of MIS to the health care system, faster patient return to the workplace, and technology commercialization. The project will integrate research and education, diversity and outreach, by enhancing current and introducing new research-intensive courses in Cyber-physical Systems, Medical Imaging and Medical Robotics, and dissemination via trans-institutional collaborations, a comprehensive web site, multimedia web-seminars, and distribution to high schools.","title":"CPS: Medium: Image Guided Robot-Assisted Medical Interventions","awardID":"0932272","effectiveDate":"2009-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["525000","554348",421224,421225,421226],"PO":["565274"]},"153456":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Software security attack prevention, which addresses threats posed by software vulnerabilities and malicious software, is important for modern computing, especially for embedded systems. Despite widespread research efforts, the increasing complexity of software and sophistication and ingenuity of software attacks have led to a constant need for innovation. Some of the shortcomings of conventional techniques are insufficient detection accuracy (false positives\/negatives) and high performance penalties.<br\/><br\/>In this project, a new methodology will be investigated for detecting and preventing malicious code execution and software vulnerability exploits, with the potential to significantly improve the accuracy and efficiency beyond current techniques. It will leverage recent advances in related areas, such as virtualization and dynamic binary instrumentation, which enable efficient creation of isolated execution environments and dynamic monitoring and analysis of program execution. The key aspects of the project are safe post-execution analysis to detect violation of specific security policies, derivation of a hybrid model that represents a dynamic control of the program\/data flow in terms of regular expressions and data invariants, run-time prevention of malicious behavior, and several software\/hardware enhancements for efficiently deploying the defense framework on embedded systems.<br\/><br\/>The methodologies will be disseminated through research articles, and software tools developed will be placed on the world-wide web. Undergraduates will be encouraged to carry out independent research projects on this topic. Princeton encourages applications from female and minority students through special fellowships, which will be leveraged. Several other outreach activities are also planned for promoting education among underrepresented high school students.","title":"CSR:Small:Preventing the Exploitation of Software Vulnerabilities and Execution of Malicious Software on Embedded Systems","awardID":"0914787","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550002"],"PO":["565255"]},"153698":{"abstract":"Distributed applications that require enforcement of fundamental authorization policies play an increasingly important role in internet and telecommunications infrastructure. Traditionally, controls are imposed before shared resources are accessed to ensure that authorization policies are respected. Recently, there has been great interest in the exploration of accountability mechanisms that rely on after-the-fact verification. In this approach, audit logs record vital systems information and an auditor uses these logs to identify dishonest principals and assign blame when there has been a violation of security policy. Accountability is an important tool to achieve practical security that should be viewed as a first-class design goal of services in federated distributed systems.<br\/><br\/>The goals of this project are to provide a theoretical basis for the design and analysis of accountability mechanisms and to use the theory to develop language based techniques for statically validating auditors and accountability appliances. This proposal investigates operational (via game-based models) and logical (via game logics) foundations for accountability to provide the theoretical basis for the design and analysis of accountability mechanisms.<br\/><br\/>The project will bring our understanding of accountability closer to the level of before-the-fact access-control mechanisms, which benefit from well understood operational models and logics and therefore support language-based methods that statically validate implementations against interfaces which specify security guarantees.<br\/><br\/>Accountability supplements purely technology-based approaches to security with insights derived from the interplay between people and technology. This project aims to develop new models, logics, algorithms, and theories for analyzing and reasoning about accountability-based approaches to trustworthiness.","title":"TC: SMALL: Language Based Accountability","awardID":"0915704","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["409674","409672","409673"],"PO":["565264"]},"152488":{"abstract":"The cost-effective construction of functionally correct software systems remains an unmet challenge for Computer Science. Although industrial best practices for software construction (such as testing, code reviews, automatic bug finding) have low cost, they cannot provide strong guarantees about correctness. Classical verification methods, on the other hand, are not cost-effective. Recently, the research community has been exploring the idea of dependent types, which extend the expressive power of programming languages to support verification. These rich types allow the programmer to express non-trivial invariant properties of her data and code as a part of her program. That way, verification is incremental, localized and at source-language level.<br\/><br\/>This multi-institution collaborative project is for the design and implementation of a programming language with dependent types, called Trellys. Technically, Trellys is call-by-value functional programming language with full-spectrum dependency. Overall, the project combines numerous fragmented research results into a coherent language design, by building a robust open-source implementation. The design draws on diverse solutions to the technical problems that arise from extending traditional programming languages accommodate dependent types: type and effect inference, language interoperability, compilation, and concurrency.","title":"SHF:Large:Collaborative Research: TRELLYS: Community-Based Design and Implementation of a Dependently Typed Programming Language","awardID":"0910510","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["532995"],"PO":["565264"]},"151047":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Concurrency-related vulnerabilities are pervasive in modern computing<br\/>systems. Concurrency exploits include time-of-check-to-time-of-use<br\/>(TOCTTOU) race conditions in file systems, attacks on signal handlers,<br\/>and evasive malware that uses concurrency to escape sandboxing<br\/>mechanisms. As processors feature ever more parallelism, and<br\/>computers process more of our sensitive data, defending against<br\/>concurrency attacks is a key challenge for the coming decade.<br\/><br\/>The first goal is to protect legitimate applications from concurrency<br\/>attacks when they access system resources (e.g., prevent TOCTTOU<br\/>attacks on file accesses and exploitable race conditions in signal<br\/>handlers). The objective is to provide application programmers with<br\/>mechanisms and policies for synchronizing access to system resources<br\/>so they can avoid unintentional vulnerabilities.<br\/><br\/>The second goal is to provide strong confinement of untrusted code in<br\/>the presence of concurrency, i.e., blocking intentionally malicious<br\/>behavior. Today's malware abuses concurrency mechanisms to bypass and<br\/>circumvent containment mechanisms like reference monitors and system<br\/>call wrappers. Providing robust system support for containing<br\/>malicious code is a critical challenge in intrusion detection and<br\/>prevention.<br\/><br\/>Modern computing systems fundamentally depend on concurrency for their<br\/>performance and functionality. Making sure that concurrency is used<br\/>securely is essential for building a trusted cyber infrastructure.<br\/>This research will have a significant impact on the practical<br\/>development of secure software, and enable security-critical<br\/>applications to realize the performance benefits of today's highly<br\/>parallel systems.","title":"TC: Medium: Collaborative Research: Securing Concurrency in Modern Systems","awardID":"0905602","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["519592","555324"],"PO":["565264"]},"155535":{"abstract":"Proposal #: CNS 09-22644<br\/>PI(s): Robila, Stefan A.<br\/>Institution: Montclair State University <br\/>Title: MRI\/Acq.: High Performance Computer Cluster Supporting Computational Science Research and Learning<br\/><br\/>Project Proposed:<br\/>This project, acquiring a high performance computer cluster, aims to expand interdisciplinary projects in three departments (CS, Math Science, and Linguistics) and enable collaboration with a research intensive university (Syracuse). These projects require significant computation power and describe problems where the size of the data sets continues to grow. The work involves novel approaches for parallel image and signal processing, and in particular spectral imaging. The approach includes design of parallel algorithms and the development of theories on how to parallelize the general data processing steps. Other projects use parallel processing for phylogenetic modeling, use dynamic systems for disease modeling, parallelization techniques for the use of scattering theory, and the cross-lingual morphosyntactic tagging.<br\/><br\/>Broader Impacts: This project helps to attract more students to hands-on multidisciplinary research and to establish and strengthen a cross-institutional research partnership between an undergraduate-serving teaching institution and a research university. The research on spectral imaging parallel applications allows for the use of spectral sensors in new applications improving the timeliness and accuracy of results. In terms of dynamic systems, computer modeling and computational analysis of disease dynamics might contribute to determine the best policy for a given epidemic situation. Applications and contributions of scattering theory to science include deep earth seismology, exploration of underground resources, engineering, mine detection, and other military applications. In phylogeny, the ability to reconstruct optimal evolutionary trees based on objective criteria impacts directly the understanding of the relationships among organisms, human evolution, and spread of infectious disease.","title":"MRI: Acquisition of a High Performance Computer Cluster Supporting Computational Science Research and Learning","awardID":"0922644","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["444454"],"PO":["557609"]},"153478":{"abstract":"Software failures in server applications are a significant problem for preserving system availability. In the absence of perfect software, this research focuses on tolerating and recovering from errors by exploiting software elasticity: the ability of regular code to recover from certain failures when low-level faults are masked by the operating system or appropriate instrumentation. Software elasticity is exploited by introducing rescue points, locations in application code for handling programmer-anticipated failures, which are automatically repurposed and tested for safely enabling fault recovery from a larger class of unanticipated faults. Rescue points recover software from unknown faults while maintaining system integrity and availability by mimicking system behavior under known error conditions. They are identified using fuzzing, created using a checkpoint-restart mechanism, and tested then injected into production code using binary patching. This approach masks failures to permit continued program execution while minimizing undesirable side-effects, enabling application recovery and software self-healing.","title":"TC: Small: Exploiting Software Elasticity for Automatic Software Self-Healing","awardID":"0914845","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["508477","564223"],"PO":["366560"]},"153599":{"abstract":"This project represents a broad investigation into algorithmic algebraic geometry, traversing complexity theory, Diophantine approximation, real and p-adic geometry, numerical algorithms, and the nascent field of statistical algebraic geometry. The main focus is systems of sparse polynomial equations --- a family of computational problems central in many applications. The proposed algorithms have immediate impact in certain areas of engineering where the PI and co-PIs have close connections with industry and faculty outside of mathematics. Intellectual merits include (1) an approach to a deterministic solution of Smale's 17th Problem, (2) optimal stochastic root counts for sparse polynomial systems, and (3) new algebraic examples of problems on the border between P and NP. <br\/><br\/>Broader impacts include novel approaches to problems from engineering and computer science, the training of postdoctoral researchers, and the education of graduate students. In particular, PI Rojas and graduate student Rusek have an ongoing collaboration with Sandia National Laboratories (including publically-available software) on rigorously quantifying uncertainties in the failure of physical structures, e.g., the storage of nuclear waste. Co-PI Avendano and PI Rojas also have ongoing work with Prof. Daniele Mortari (of the Texas A and M Aerospace Engineering Department) on satellite orbit design, with applications to surveillance and astronomical observation.","title":"MCS: Randomization in Algorithmic Fewnomial Theory Over Complete Fields","awardID":"0915245","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["510113",408779,408780],"PO":["565027"]},"157603":{"abstract":"CPS:Small:Collaborative Research: Methods and Tools for the Verification of Cyber-Physical Systems<br\/><br\/>The objective of this research is to investigate and develop methods and tools for the analysis and verification of cyber-physical systems. The approach is to augment the methods and tools that have been developed at the University of Utah and the University of South Florida for modeling and verification of asynchronous and analog\/mixed-signal circuits to address challenges in cyber-physical system verification.<br\/><br\/>This research will develop a unified framework with methods and tools which include an integrated formalism to comprehensively model discrete\/continuous, functional\/timing, synchronous\/asynchronous, and deterministic\/stochastic behavior. These tools will also include algorithms to analyze behavior and verify that it satisfies the correctness requirements on functionality, timing, and robustness. Finally, they will include abstraction and compositional reasoning approaches to enable large systems to be analyzed and verified efficiently.<br\/><br\/>Since cyber-physical systems are becoming ubiquitous, improvements in such systems such as higher reliability, better fault-tolerance, improved performance, and lower design costs will have tremendous positive impact on society. Results from this research will be transferred to the cyber-physical systems community and other application domains by both publishing papers in related conferences and journals as well as by freely distributing tools via the Internet. Both graduate and undergraduate students will be engaged in this multi-institutional research where they will be exposed to the latest research in formal and probabilistic analysis. Early involvement of undergraduate students may help encourage them to attend graduate school. This research project will also recruit underrepresented and female students to allow it to reach broader audiences.","title":"CPS: Small: Collaborative Research: Methods and Tools for the Verification of Cyber-Physical Systems","awardID":"0930510","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[420575],"PO":["565239"]},"158934":{"abstract":"Data provenance documents the inputs, entities, systems, and processes that influence data of interest---in effect providing a historical record of the data and its origins. The generated evidence supports essential forensic activities such as data-dependency analysis, error\/ compromise detection and recovery, and auditing and compliance analysis. <br\/><br\/>This collaborative project is focused on theory and systems supporting practical end-to-end provenance in high-end computing systems. Here, systems are investigated where provenance authorities accept host- level provenance data from validated provenance monitors, to assemble a trustworthy provenance record. Provenance monitors externally observe systems or applications and securely record the evolution of data they manipulate. The provenance record is shared across the distributed environment. <br\/><br\/>In support of this vision, tools and systems are explored that identify policy (what provenance data to record), trusted authorities (which entities may assert provenance information), and infrastructure (where to record provenance data). Moreover, the provenance has the potential to hurt system performance: collecting too much provenance information or doing so in an inefficient or invasive way can introduce unacceptable overheads. In response, the project is further focused on ways to understand and reduce the costs of provenance collection.","title":"Collaborative Research: Secure Provenance in High-End Computing Systems","awardID":"0938071","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["438346"],"PO":["565272"]},"157724":{"abstract":"CPS: Small: Control Subject to Human Behavioral Disturbances<br\/><br\/>The objective of this research is to develop an integrated methodology for control system design in situations where disturbances primarily result from routine human behavior, as, for example, in future artificial pancreas systems where meals and exercise are the main disturbances affecting blood glucose concentration. The approach is to recognize that human behavioral disturbances (i) are generally random but cannot be treated as zero-mean white noise processes and (ii) occur with statistical regularity but cannot be treated as periodic due to natural variation in human behavior. This emerging class of problems requires (i) the derivation of new mathematical representations of disturbances for specific applications and (ii) the formulation of new stochastic control models and algorithms that exploit statistical regularity in the disturbance process.<br\/><br\/>The intellectual merit of the proposed research stems from the fact that it explicitly recognizes a new class of disturbances, human behavioral disturbances, seeking to develop an integrated approach to statistically characterizing and responding to future perturbations, adapting gracefully to uncertainty about the future. The anticipated research outcomes will be relevant in diverse fields, including stochastic hybrid control and human automation interaction.<br\/><br\/>As a broader implication, the proposed research will enable the design of future field deployable artificial pancreas systems, potentially improving the lives of 1.5 million Americans suffering from Type 1 diabetes. With help from the two graduate students funded by the project, the principle investigator will supervise a ?Capstone? design course, exposing undergraduates to various aspects of control under human behavioral disturbances.","title":"CPS: Small: Control Subject to Human Behavioral Disturbances","awardID":"0931633","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["540768"],"PO":["565227"]},"154116":{"abstract":"Abstract ? Keyser (0917286)<br\/>Simulations play an important role in many graphical applications, ranging from entertainment to virtual environments used for training. These applications demand greater and greater realism, and this in turn creates a need for more believable and more efficient simulations. While there have been major improvements in simulation technology, many of these techniques can be quite slow, and simply applying greater computing power is not sufficient to meet the demands of real-time systems. The focus of this research is on finding ways to create real-time simulations by taking different approaches to the simulation framework used in computer graphics. The researchers explore ways to replace simulation by statistical data, simplify the theory of effects-based simulations, and incorporate these approaches into a system that trades off accuracy and speed to meet the requirements of a given problem. This work can change the manner in which simulation is performed in graphics and other applications.<br\/>This research deals with developing methods for real-time simulation by taking fundamentally different approaches to the simulation problem. First, the researchers investigate ways of replacing full physics-based simulations with statistically-based capture of simulation effects. Rather than simulating at run-time, statistics are gathered regarding simulation behavior across several samples, from either full simulations or other sources. At run-time, the simulation is replaced by a result generated according to the statistical distribution. Second, the researchers develop ways of simplifying the theory of certain simulation systems to allow simplified simulations that still capture the important effects, while leaving the less important details to be handled by other (less computationally-involved) means. Third, the researchers investigate ways to develop level-of-detail simulations that allow a tradeoff between fidelity and efficiency, supporting both a highly accurate simulation and a faster simulation with guaranteed performance. The statistical and simplified approaches are incorporated into this level-of-detail simulation.","title":"HCC: Small: Rethinking Simulation in Computer Graphics","awardID":"0917286","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["535314"],"PO":["565227"]},"158736":{"abstract":"Modern direct manipulation and visualization systems have made key strides in bringing powerful data transformations and algorithms to the analyst's desktop. But to further promote the vision of powerful visual analytics, wherein automated algorithms and visual representations complement each other to yield new insight, we must continually increase the expressiveness with which analysts interact with data. This project focuses on the task of storytelling, that is to say the stringing together of seemingly unconnected pieces of data into a coherent thread or argument. To support storytelling, which requires both human judgment and algorithmic assistance, the PIs will first develop a new theory of relational redescriptions that provides a uniform way to describe data and to compose data transformation algorithms across a multitude of domains. Using this theory, the PIs will be able to define stories formally as compositions of relational redescriptions. They will develop scalable and steerable algorithms for storytelling that will respond to dynamic user input, such as preferences and constraints, and they will contextualize their use in interactive visualizations that harness the power of spatial layout. Finally, they will investigate how analysts engage in sense-making using the new storytelling algorithms and visualizations, in the hope of finding answers to questions such as: How do analysts achieve insight and advance their conceptualization of patterns derived from datasets? Project outcomes will include the formal conceptualization of storytelling as well as the compositional approach to building complex chains of inference.<br\/><br\/>Broader Impacts: This research will make it easier for analysts to interactively explore connections in large-scale heterogeneous datasets. The PIs will work with the FODAVA-lead team at Georgia Tech and PNNL's NVAC to investigate applications of relational redescriptions and storytelling to domains of interest to NSF and DHS, and will develop in consultation with real users across these groups a layered software framework for storytelling (both analysis and visualization) capabilities; the framework will be released into the public domain under the GNU GPL\/Lesser GNU GPL license, and APIs will be provided that allow analysts to tailor it to suit their needs. Although this project will focus on cyber-analytics scenarios such as those motivated by the VAST 2009 challenge, project outcomes will generalize across other domains such as bioinformatics, systems biology, electronic commerce, and social networks. The unified notion of redescriptions will help integrate multiple data sources (numeric, symbolic, textual, and categorical), and situate them on a common footing for visual analytics; it will also enable visual analysts from different application domains to use a common vocabulary while interacting with one other.","title":"Formal Models, Algorithms, and Visualizations for Storytelling Analytics","awardID":"0937133","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"KX06","name":"U.S. Department of Homeland Se"}}],"PIcoPI":["486496","498314","518252"],"PO":["565227"]},"155106":{"abstract":"The goal of this project is to develop a morphological analyzer for Old Icelandic using an extension of the functional programming language FM\/Haskell. Old Icelandic, one of the most complex of the early Germanic languages, is closely related to Old English. Old Icelandic is also interesting as it is the language of the sagas, Nordic mythology and early Germanic law. One of the main features of FM\/Haskell is code that is easily interpreted, even for non-programmers; this allows the investigators to use students as part of the research team, and to solicit feedback from the user community. <br\/><br\/>An important feature of the morphological analyzer system is the inclusion of an English language look-up tool. Because of the highly inflected nature of Old Icelandic, it is often difficult for students and non-experts to find appropriate English definitions without considerable effort. The system also incorporates a clear method for debugging and error correction. The research team will develop simple user interfaces for adding inflectional prototypes and sub-prototypes, and for adding and editing lexical resources. When fully developed, the system will offer far greater accuracy than earlier morphological analyzers for Old Icelandic. <br\/><br\/>Given the architecture of the system, the approach can be easily extended to other languages; this will be demonstrated by developing a proof-of-concept analyzer for Old English. This extensibility is important for international collaborative efforts that focus on the development of these systems. The research community will be provided with a fast and highly accurate method for adding morphosyntactic detail to the rapidly increasing digital corpus of Old Icelandic documents; with this added detail, the speed and sophistication of searches on the corpus will increase dramatically. All code and instructions will be freely distributed, along with the library of language functions, allowing others to build systems for other morphologically complex languages.","title":"A Morphological Analyzer for Old Icelandic in FM\/Haskell","awardID":"0921123","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[412844],"PO":["564500"]},"154138":{"abstract":"Many complex software-based systems must be certified in order<br\/>to be deployed in safety-critical environments. Modern software<br\/>certification processes require trustworthy evidence supporting the<br\/>verification claims. While verification tools have made tremendous<br\/>gains in power, they lack the ability to generate concise and<br\/>independently checkable evidence. The V Kernel project develops a<br\/>practical approach to reconciling trust and automation. The claims<br\/>generated by the fast but untrusted front-line verification tools are<br\/>certified offline by slower but verified back-end checkers. The<br\/>front-line analyzers can provide hints and certificates that assist the<br\/>back-end tools. The verification of the checkers can be carried out by<br\/>untrusted tools as long as the end result can be independently<br\/>certified. Our approach does not constrain front-line tools by<br\/>requiring them to produce proof objects. A wide variety of verification<br\/>tools including SAT solvers, decision procedures, model checkers, static<br\/>analyzers, and theorem provers can be validated using this approach.","title":"TC: Small: Anchoring Trust with a Verified Reference Kernel","awardID":"0917375","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["555363"],"PO":["565136"]},"158868":{"abstract":"Data provenance documents the inputs, entities, systems, and processes that influence data of interest---in effect providing a historical record of the data and its origins. The generated evidence supports essential forensic activities such as data-dependency analysis, error\/ compromise detection and recovery, and auditing and compliance analysis. <br\/><br\/>This collaborative project is focused on theory and systems supporting practical end-to-end provenance in high-end computing systems. Here, systems are investigated where provenance authorities accept host- level provenance data from validated provenance monitors, to assemble a trustworthy provenance record. Provenance monitors externally observe systems or applications and securely record the evolution of data they manipulate. The provenance record is shared across the distributed environment. <br\/><br\/>In support of this vision, tools and systems are explored that identify policy (what provenance data to record), trusted authorities (which entities may assert provenance information), and infrastructure (where to record provenance data). Moreover, the provenance has the potential to hurt system performance: collecting too much provenance information or doing so in an inefficient or invasive way can introduce unacceptable overheads. In response, the project is further focused on ways to understand and reduce the costs of provenance collection.","title":"Collaborative Research: Secure Provenance in High-End Computing Systems","awardID":"0937833","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543574","553485"],"PO":["565272"]},"154028":{"abstract":"High performance computing is used to run models of the real world. This is true in both ultra high performance simulations used in scientific computing to study Physics, Biology etc. as well in designing approximations of real world involving applications such as gaming, social networks etc. Maximizing realism of the world being modeled and mimicked is the key to get this right. This work attacks the problem of realism on two fronts : first a framework is developed to speed up sequential parts of the computation using a large number of available cores based on a new concept of probabilistic speed-up. Secondly a runtime solution is devised to maximize realism in immersive applications such as gaming under the constraint of responsiveness. The frameworks involve development of programming models, interfaces, APIs and run-time system to solve the above problems by managing the underlying parallelism and computation. Apart from research this effort involves developing a cross-cutting graduate level course that spans between simulations, algorithms and programming languages.","title":"SHF: Software Tools and Techniques for Maximizing Realism on Multi-core Processors","awardID":"0916962","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["550988"],"PO":["565272"]},"154149":{"abstract":"A vision of the next-generation wireless networks includes deployment of highly capable intelligent devices that connect to form high-quality high-speed wide-area wireless networks. This necessitates advances on several fronts: more efficient spectrum use by sharing among cognitive devices, more sophisticated communication schemes and new \"socially-aware\" network architectures. In this project, we seek to increase wireless network capacity and capabilities by a factor of 10 or more by developing mechanisms and algorithms for enhancing cooperation among users in networks by using ideas from mathematical game theory and taking advantage of social aspects of networks.<br\/><br\/>This project will solve well-known hard problems in communication networks from a novel perspective, combining ideas from mathematical economics, game theory and information theory to propose incentive-informed schemes that will enable user cooperation in networks thereby paving the way for ubiquitous wireless connectivity. The project will solve long-standing unsolved problems in information theory and develop a mathematical theory of social communication networks. The project will potentially transform existing wireless and communication networks by laying foundations for a systematic study of incentives and cooperation in networks.<br\/><br\/>The project will have substantial broader impact on the development of science, education, and technology: It will contribute to a novel synthesis of ideas from various disciplines. Conducted research shall be incorporated into undergraduate and graduate classroom teaching to better prepare the next generation of engineers. In the long run, the project will enable substantial increase in network capacity and technological development of \"socially\" smart network architectures.","title":"NetSE: Small: Cooperation and Incentives in Communication and Social Networks","awardID":"0917410","effectiveDate":"2009-09-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["432720"],"PO":["565342"]},"159847":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The PIs from University of California Los Angeles (UCLA) propose a project: Teachers are Key to address a central aspect of the crisis in secondary school computer science (CS) education: the need for quality high school CS teachers. Teachers are Key builds upon a long-time collaboration between UCLA researchers and the Los Angeles Unified School District (LAUSD). This collaboration has resulted in the development of a comprehensive introductory computer science curriculum and a summer professional development program to instruct teachers on the curriculum concepts and content. <br\/><br\/>For this project the PIs will build effective supports and a professional development system at a local and national level for computer science teachers. Many of these teachers are new to computer science and are the lone teacher at their schools making professional development and support networks a necessity. This comprehensive support network will offer 1) continuous in-classroom teacher professional development supported by a district-wide CS coaching \/ peer-to-peer mentoring system, 2) on-going professional development workshops throughout the school year and 3) an on-line learning community. The programs designed and corresponding lessons learned will be disseminated nationwide as a guide and assistance for other school districts and universities.<br\/><br\/>Teachers are Key's initiatives will build upon the expertise of the PIs (university faculty\/researchers and K-12 leaders with an established partnership around these issues) and their partners: 1) UCLA Center X, a leading urban teacher professional development center with a long history of reform efforts and working with teachers within LAUSD and the 2) Computer Science Teachers Association, the national professional organization of computer science teachers. The PIs of this grant are university researchers and K-12 District leaders who are uniquely positioned to leverage and scale up successful programs and to create a model for institutional change.<br\/><br\/>Intellectual Merit:<br\/>Improving STEM education and guaranteeing equal access to quality education for all students is one of our country?s most pressing challenges. Teachers are Key sits at the crux of this national challenge. This project will provide essential knowledge about two important subjects: 1) increasing rigorous learning of computer science opportunities in schools, especially in schools with high numbers of minority students, and 2) effective methods of professional development for computer science teachers. This knowledge has the potential to shed light on similar challenges in other STEM disciplines.<br\/><br\/>Broader Impacts:<br\/>Teachers are Key will provide a model of what has to be done at the school, district, state, and national levels to improve quality computer science education for all students. The models of professional development that will be designed and implemented in the second largest and one of the most diverse school districts in the country will contribute to local and national efforts underway to broaden participation in computing. This project will provide insight on three important things 1) Recruiting and training a very large number of new high school teachers who can impart to students the magic and \"computational thinking\" of computer science, 2) re-positioning CS at the high school level as an academic subject, and 3) redesigning the high school curriculum so that it is rigorous and engaging for a broad segment of our student population. In order to develop a 21st Century economy, we must train students in 21st century skills including making rigorous computational training available to all students.","title":"Teachers Are Key: Partnering With and Supporting Quality Computer Science Teachers Within the Second Largest School Districts in the Country","awardID":"0943507","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7967","name":"EDUCATION AND WORKFORCE"}}],"PIcoPI":["528136","528138","528135",427576],"PO":["564181"]},"158637":{"abstract":"Advances in computing technology from the past few decades have opened the possibility of a cyberinfrastructure for linguistics that will advance the field by allowing linguists to analyze and test hypotheses against much larger data sets, collaborate with more people across greater distances, and as a result find solutions to questions not previously answerable. However, in order to realize the promise of a well-engineered cyberinfrastructure, the field needs to solve three problems: (1) establishing a culture of publishing and sharing data and annotations, and of expecting hypotheses to be tested against available data sets; (2) identifying existing standards and software that can contribute to a general cyberinfrastructure and plan how to build from them; and (3) developing a funding model which will sustain not only research contributions by linguists and computational linguists, but also software development (including user interface work) by software engineers.<br\/><br\/>These problems can not be solved by isolated research projects, but rather require wide-spread communication, participation and buy-in from the field. The goal of this workshop, Cyberling 2009: Towards a Cyberinfrastructure for Linguistics, is to bring together linguists representing a wide range of subfields (as well as outside specialists) who are interested in the potential of cyberinfrastructure for linguistics and who have experience in working with related projects to create a roadmap for solving the problems noted. The workshop is being collocated with the Linguistic Society of America's 2009 Linguistic Institute at the University of California, Berkeley, and includes open panel discussions to engage the general audience of the Linguistic Institute and thereby promote wider interest in cyberinfrastructure development within the field.","title":"Cyberling 2009 Workshop: Towards a Cyberinfrastructure for Linguistics","awardID":"0936577","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["507285"],"PO":["564500"]},"154039":{"abstract":"CMU is working toward a new approach to providing storage quality-of-service (QoS) in distributed environments supporting multiple services with time-varying workloads. Today's shared storage, whether implementing QoS or not, allows different services' workloads to mix without consideration of the large efficiency swings caused by unpredictable interference. Ideally, however, each service would see full efficiency within the fraction of the I\/O system's time allocated to it, which would increase effective utilization and enable practical storage QoS control. We are formulating and beginning exploration of a resource management architecture in which QoS control is layered atop robust performance insulation and equipped with algorithms for dataset assignment and slack exploitation. The eventual outcomes seeded by this project will include enabling the storage QoS critically needed for emerging virtualized and cloud computing environments, enhancing education at CMU and elsewhere by providing insights taught in our storage systems and distributed systems classes, and being integrated into a deployed instance used by scientists sharing a cluster for their work.","title":"CSR: An initial study of the potential of a new approach to storage QoS for dynamic, multi-service infrastrctures","awardID":"0917012","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["486330","486331"],"PO":["493916"]},"166018":{"abstract":"Abstract: Side-Channel-Proof Embedded Processors with Integrated Multi-Layer Protection<br\/>Embedded digital systems are ubiquitous and may contain sensitive information that could be used for malicious purposes if fallen into the wrong hands. Therefore, strong cryptographic algorithms have been incorporated inside these devices. However, attackers have switched their targets from the cryptographic algorithms themselves to the hardware\/software implementations of these algorithms, through ?side-channel? chip measurements. From a hardware perspective, such side-channel attacks can be implemented at both the circuit-level and architecture-level. Although much research has been performed in mitigating side-channel attacks, these solutions are inflexible, unsystematic, and have high overhead. The goal of this research is to develop a universal solution that synergistically combines both architecture-level and circuit-level countermeasures for mitigating all major categories of side-channel attacks, to yield an extremely secure, highly flexible, low overhead digital system design methodology. In this proof-of-concept project, preliminary research will be carried out at both levels. At the architecture-level, novel architectural support to mitigate architecture-level timing and access-driven attacks will be developed. At the circuit-level, Delay-Insensitive Ternary Logic will be utilized to design the new architectural support as well as other key components of a MIPS32 4K-compatible embedded microprocessor. The effectiveness and efficiency of side-channel attack resistance at both architecture-level and circuit-level will be evaluated. Educational modules of circuit-level and architecture-level attack mitigation will be developed. Graduate and undergraduate students, especially from underrepresented groups, will be involved in this project. The research outcome will be disseminated to the academic and industrial communities through journal articles, conference presentations, and appropriate websites.","title":"TC: Medium: Collaborative Research: Side-Channel-Proof Embedded Processors with Integrated Multi-Layer Protection","awardID":"1004945","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["517241"],"PO":["543481"]},"159748":{"abstract":"When people play games for entertainment, they are free to choose whether to play at all and which games to play. So-called 'serious games' employ a media form players are accustomed to enjoying as entertainment for serious goals such as learning, health, and persuasion. Rather than voluntary and for fun, a serious game may in fact be a mandatory class assignment, a required part of corporate training, or a prescribed activity to improve brain health. Serious games may not be fun. Even games which are fun for many people (e.g., the Civilization series of games are some of the best selling games ever and are widely used as educational games), may not be \"fun,\" \"engaging,\" \"motivating,\" or whatever other words may be used to describe the rationale for using games by academics or designers for a distinct subset of the target audience. Motivation is known to be important for school learning yet motivation for serious games has not been studied. In the same way that learners hold different underlying affinities for intrinsic and extrinsic rewards associated with learning, it is posited in this project that gamers develop unique gaming motivation affinities and mindsets throughout their lifetime of gaming experiences. Player typologies classify players as achievers, explorers, socializers, or killers, but these typologies only consider voluntary play of a particular game or game genre. It is not yet known whether players easily and enthusiastically embrace games which do not fit their preferred gaming motivations, or if such mismatches interfere with engagement and learning. By definition, serious games piggyback on players' entertainment gaming experiences, yet they do so with no consideration of why and how different people play entertainment games, nor what the implications of those individual lifetime gaming motivation and experience differences are for how a serious game will be received. This project will develop and test drive the idea of a Gaming Motivation Profile (GMP), parallel to motivation and mindset theories. The project is risky, because GMP may turn out not to exist, or to be unimportant. The project is worthwhile because if indeed GMP mediates the impact of serious games, there are myriad implications for game design and for how serious games are introduced to improve their effectiveness. The proposed Phase 1 exploratory research seeks 1.) to articulate, explore, and collect normative data about the construct of gaming motivation profile (GMP) as an individual trait, 2.) to discover whether the way individuals play particular games is consistent with their GMP, 3.) to study what happens as far enacted play style and enjoyment when GMP is not available within a game. The proposed Phase 2 rresearch be a first step in examining the \"so what\" of GMP and serious gaming. Researchers will study how a learning game's and a brain game's intended outcomes (e.g., learning and brain training) are impacted when players' GMP (and therefore, their preferred play patterns) are or are not available in the game. The Phase 2 experiment will test the efficacy of manipulating regulatory fit (introducing task goals which are or are not consistent with the game) for improving the intended outcomes of a brain game and a learning game. <br\/><br\/>Understanding the impact of GMP on serious gaming intended outcomes holds promise to inform serious game design and to better serve diverse audiences for serious games. It is reasonable to expect, based on large gender differences in the quantity and quality of gaming, that GMP will vary by gender, age, and other demographics, with implications for more universal serious game design.","title":"EAGER: Collaborative Research: Motivation and Serious Gaming","awardID":"0943064","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[427323],"PO":["564456"]},"159528":{"abstract":"Scientists and engineers stand on the brink of new opportunities to enable and accelerate scientific discoveries by exploiting access to an unprecedented scale and diversity of high-end digital resources and services. To better facilitate the use of such resources for transformational science and engineering discoveries, the PIs have proposed the design for a world-class, comprehensive cyberinfrastructure (CI) of advanced digital services: the eXtreme Science and Engineering Discovery Environment (XSEDE). XSEDE will enable researchers to use XSEDE resources and services directly, from their personal and campus resources, from other high-end centers and cyberinfrastructure resources, and via science gateways and discovery environments. The XSEDE Partnership will be led by NCSA, TACC, NICS and PSC, and includes partners who complement their strengths with expertise in CI architecture, systems engineering, and program management. Driven by a comprehensive set of community science requirements, the team will design a plan for the full XSEDE architecture of diverse digital services for enabling end-to-end research. It will also plan a highly coordinated user support program, including advanced user support and a multi-pronged training, education and outreach program, offering an array of services from technology experts to assist all levels of users and to recruit and prepare future users. XSEDE will be designed to interface with other CI projects and resources, and to evolve to meet emerging requirements and technology opportunities. The resulting plan will enable the deployment and operation of XSEDE to transform the conduct of computational science from use of individual resources for discrete tasks to enabling end-to-end science in a complete, comprehensive, integrated environment of extraordinary capability that enables transformative scientific breakthroughs in the next five years. The XSEDE plan will be shared with science and technology researchers and educators via workshops and direct communications. This will enable integration of research and education with leading applications teams and tool developers by increasing their awareness of current technologies and best practices through communication and curriculum content, while stimulating development of needed capabilities and technologies for addressing science community needs. The XSEDE plan will explore ways to increase and broaden participation by working with under-represented faculty and students among the current community of high-end practitioners as well as recruiting and engaging even larger numbers of under-represented individuals.","title":"Planning for XSEDE: the eXtreme Science and Engineering Discovery Environment","awardID":"0941686","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7476","name":"ETF"}}],"PIcoPI":["538215","469704","494781","469708"],"PO":["525727"]},"146339":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Due to the dynamic nature and unprecedented scale of the Internet, Internet services pose challenges including scalability, reliability, and availability to underlying networked systems. This CAREER project concentrates on building Internet services that are resilient to those challenges with machine learning and control techniques. Internet services build upon cluster-based computer systems that keep growing in scale and complexity. Such systems become so complicated that it is even a big challenge to get a good understanding of the entire system dynamic behaviors. The investigators take an analytical and organized approach to design an autonomous software infrastructure on networked systems for building resilient Internet services. The project builds empirical models using statistical learning to help overcome the challenges of scale and complexity in networked systems. It designs coordinated admission control and capacity planning algorithms with end-to-end quality-of-service on multi-tier clusters. Model-independent control techniques are used with empirical models to allocate resources and to dynamically reconfigure the system for performance optimization needs. It develops performance differentiation, isolation, and self-adaptive reconfiguration capabilities for enhancing system reliability and availability. It broadens the research impact by developing a testbed in a data center lab to demonstrate the orchestration of designed techniques for automated arrangement, coordination, and management of complex computer systems, middleware, and services. The research results will be disseminated to the public as technical reports. This project also supports a new inter-disciplinary Ph.D. of Engineering in security program.","title":"CAREER: Building Resilient Internet Services with Learning and Control","awardID":"0844983","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550728"],"PO":["535244"]},"160760":{"abstract":"EAGER: A New Algorithmic and Graph Model for Networking in Challenged Environments<br\/><br\/><br\/>This EAGER proposal presents a generalized graph model that can capture mobility in Networking in Challenged Environments (NICE). This model is called a weighted evolving graph which captures time-space dynamics while remaining simple enough to maintain most of the elegant structure of the traditional graph model. We &#64257;rst present several path optimization problems based on different metrics, including earliest completion, minimum hop, fastest, and maximum reliability. We then extend several graph concepts in this new model.<br\/><br\/>The proposal addresses one fundamental issue: can we develop a localized solution in which the graph is \"trimmed\" (by removing nodes\/links across time and space) using only local information at each node? The merit of a trimmed graph is the reduction of searching complexity for routing and broadcasting.<br\/>We plan to apply the proposed model to three different applications: (a) dynamic sensor networks with frequently switched on\/off sensors, (b) mobile networks with cyclic movement trajectories (such as vehicular networks), and (c) people networks in which college students carrying iMotes\/smart phones maintain contact records during periodic meetings and classes.<br\/><br\/>The proposed graph theoretic model to capture NICE is a simple one. The proposal presents a promising and unique way of applying this graph model to address a new set of path optimization problems and other graph concepts. The proposed model can be applied to three important applications in dynamic sensor networks, DTNs, and people networks. We envision that insights and results from this research will provide guidelines for modeling and analyzing NICE. This research will also exploit and contribute to fundamental theories on dynamic and challenged networks under the generalized graph abstraction.","title":"EAGER: A New Algorithmic and Graph Model for Networking in Challenged Environments","awardID":"0948184","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["7594"],"PO":["557315"]},"161871":{"abstract":"Although an overnight shipping company allows one to track the shipment of a package from coast to coast and a credit card company can track your purchases throughout the world, integrating, cleaning and using the various kinds of data available for engineering and planning studies in health, transportation and public infrastructure systems is extremely difficult. Such \"retrospective\" studies require intense scrutiny of the data and involve a myriad of decisions concerning the data and the definitions of the concepts involved to properly \"clean\" or prepare the data for the study. These decisions are typically written in English, if at all, and thus not automatically processable by any future user of the data. In a similar way, integrating data from multiple sources is difficult because of the details of the technology used to capture the data. The critical problems are that data from multiple sources can be hard to integrate and studies are almost never able to use data (that was carefully cleaned and scrutinized for one study) in another study. This seriously limits the opportunity to conduct larger or broader scale studies or to \"re- run\" studies on new data. One can envision a world where retrospective studies can be easily described, decisions about data use, data cleaning, and data integration can be precisely recorded, and operations, management, engineering, and planning activities can be informed by the results from studies as easily as we can currently track our packages as they wend their way across the country. This project envisions one solution to these problems; to devise methods and tools that will declaratively (i.e., at a high level, described in a formal language) document data manipulation activities in retrospective studies. Analysts will then be able to use this declarative specification to greatly facilitate the specification and conduct of new studies, making their jobs much easier. For example, if an analyst wants to repeat a study with new data, or with different parameters, the analyst will be able to use the declarative specifications saved from the original study, instead of having to decipher the low-level notes which may or may not have been saved from the original study. The declarative specifications will also be useful for combining the results of previous studies to create new studies. This project will focus three kinds of retrospective research studies: 1) studies from the Clinical Outcomes Research Institute (CORI), based on data concerning patient endoscopic procedures, 2) studies based on the Portland Oregon Regional Transportation Archive Listing (PORTAL), data containing years of highway loop-detector data as they conduct a study to determine the factors that correlate with certain kinds of congestion, and 3) studies based on data from the Portland, Oregon Water Bureau containing 8 years of water consumption data reported every 15 minutes from households across the city. <br\/><br\/>Intellectual Merit<br\/>By attempting to bring the capability of state-of-the-art schema and data integration and data cleaning systems into a set of tools that can be used easily by analysts and can be interfaced seamlessly with existing analysis tools, the research team will make contributions to the database field by identifying separable concerns (within integration and cleaning) and by generalizing functions that are currently available in more complex, all encompassing tools. <br\/><br\/>Broader Impacts <br\/>The results of this project will have broad impact because they are advancing the science of retrospective studies significantly. The results will be applicable beyond the three areas being studied and will enable researchers and analysts to perform their studies more efficiently and to perform more studies. Results will be disseminated broadly, not only by the PI and co-PI through the usual publication venues, but by researchers in the three areas being studied. <br\/><br\/>Major Themes\/Keywords: Computer Science\/Information Technology. Engineering. Social Science. Intelligent Transportation Systems. Health Systems. Water Consumption.","title":"EAGER: Full Disclosure of Data Preparation and Use in Retrospective Studies","awardID":"0954268","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["432768",432768,"533018","533018"],"PO":["543481"]},"160782":{"abstract":"The increasing use of geospatial information (that is to say, data connected to a location on Earth) in applications such as Google Maps and Google Earth underscores its growing importance to mainstream computing. However, nearly all such geospatial applications use a highly visual interface and are therefore largely inaccessible to visually-impaired users. Although today's most widely used solutions for touch interfaces (point haptic devices) are rudimentary when compared to the richness and complexity of human touch, ongoing developments suggest that it will eventually become technically possible to design and implement a system that uses touch and sound to convey many different forms of geospatial data. The PI's ultimate goal is to create such a system that will allow visually-impaired users to effectively access and interact with geospatial information. In this exploratory project, he will conduct research on how to design such touch\/sound based systems. The work will cut across disciplines and actively involve visually-impaired persons as users and designers, in order to leverage the unique perspective on the use and design of non-visual interfaces that visually-impaired users have; a significant part of the research will be carried out by a visually-impaired graduate research assistant. The expected outcomes of the PI's four step research plan will include an analysis of the goals and needs of visually-impaired users and their support personnel regarding geospatial information, a list of potential tasks for this context, a catalog of how different touch\/sound methods could be used for these tasks, and an evaluation of some of these methods with visually-impaired users.<br\/><br\/>Broader Impacts: The interdisciplinary human-computer interaction program at the PI's institution has recently admitted its first visually-impaired graduate student, who will contribute his technical skills and his connections to the visually-impaired community to this project. The results of this work will impact the quality of touch\/sound user interfaces by providing designers with a broader overview, by helping them consider multiple alternatives, and by enabling them to make more informed and inclusive design decisions. While these new user interfaces will initially benefit primarily persons with visual impairments in accessing and interacting with geospatial data, it is likely that some of the tasks and methods explored in this research will have relevance for enhancing future interfaces to geospatial data for sighted users as well.","title":"EAGER: Designing Touch-Sound Interfaces to Geospatial Information for Visually-Impaired Users","awardID":"0948260","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[430000],"PO":["565227"]},"160672":{"abstract":"This travel award supports participation in the 3rd IEEE Workshop on Enabling the Future Service-Oriented Internet (EFSOI): Towards Socially-Aware Networks take place in conjunction with IEEE Globecom 2009, in Honolulu, HI. December 4, 2009. <br\/><br\/>This technical workshop is a relative new venue for presenting new research results in the fast emerging area in networking, namely that of service-oriented and socially-aware networks. The workshop recognizes the convergence of various communications technologies and the emergence of a number of socio-technical applications leading to a crucial national need to engage and educate the next generation of researchers and educators in the modeling and understanding of service oriented infrastructures, networks and virtual collaboration systems. Thus attendance at EFSOI provides a valuable a research and career development experience for graduate students and post-doctoral researchers from United States academic institutions. Participants will have the opportunity to present their work, attend panel and keynote speech sessions, and interact with peers engaged in state-of-the-art research in the field. <br\/><br\/>Approximately 10-15 US-based graduate students and post-doctoral researchers are provided the opportunity to attend EFSOI. The travel awards will target graduate students, in particular female and under-represented minority students, since they often have limited travel funds to attend workshops; attendance at such events is an important part of their educational experience.","title":"Third IEEE Workshop on Enabling the Future Service-Oriented Internet: Towards Socially-Aware Networks","awardID":"0947805","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["521130"],"PO":["557315"]},"161552":{"abstract":"The Second Annual School of Information Theory to be held on August 9-13 at Northwestern University. Information theory provides the theoretical foundations for modern communication systems. This rich foundation has enabled dramatic performance improvements in both wire-line and wireless communication systems. In recent years, there has been much interest in building on these successes and extending information theoretic ideas to provide fundamental insight into the design of increasingly complex networks that are of critical importance both for military and civilian uses. Examples include communication systems such as Mobile Ad hoc Networks (MANETs), wireless mesh networks and sensor networks as well as biological and social systems. With the goal of developing the next generation of information theorists, the first Annual School of information theory was held on June 2-5, 2008 at Penn State University. <br\/>The school was very successful and provided nearly 100 graduate and postdoctoral students with an excellent platform where they were exposed to the state of the art in information theory. The Second Annual School of Information Theory will build on this success by exposing students to leading research in information theory through lectures by four leading figures in information theory and also by providing students the opportunity to discuss their own work and interact. This grant is providing travel support to make attending the school an affordable opportunity for graduate students and post docs from across the US.","title":"Supporting Students Attending the Second Annual North American School of Information Theory","awardID":"0952529","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}}],"PIcoPI":["560218","523548"],"PO":[432103]},"153940":{"abstract":"Today we have organizational and software procedures that facilitate the exchange of interpersonal information in social networking sites, instant messaging, bulletin boards, online role?playing games, computer?supported collaborative work, and online education. All of these applications fit into the larger category of social media that support virtual communities. As we increasingly rely on this cyberspace, the issue of privacy protection in social media is critically important. The objective of this project is to develop an advanced framework called U-Control for Digital Persona and Privacy Management to manage and release personal information considering a notion of digital persona based user privacy preferences and associated risks in disclosing such private information over virtual communities. <br\/><br\/>Successful completion of this project will result in the development of a protection framework and architecture to address the privacy challenges in social media-based virtual communities. This research effort is also expected to set an important direction to the future research in the area of virtual communities and online privacy solutions. This research has the potential for broad societal impact by providing user-controlled sharing of personal attributes and the efficiency of existing business models and operations of such.","title":"TC: Small: Collaborative Proposal: User-Controlled Persona in Virtual Community","awardID":"0916688","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["492724"],"PO":["565342"]},"161200":{"abstract":"Abstract<br\/><br\/>This project provides travel funds to fifteen graduate students attending US institutions who have authored accepted papers at ICIP 2009. Awardees will receive $1,000 each to help defray their travel expenses. The 2009 IEEE International Conference on Image Processing (ICIP) will take place in Cairo, Egypt, from November 7 to 11, 2009. The conference is sponsored by the IEEE Signal Processing Society and is the premier forum for the presentation of technological advances and research results in the fields of theoretical, experimental, and applied image and video processing. ICIP 2009, the sixteenth in the series that has been held annually since 1994, will bring together leading engineers and scientists in image processing from around the world. Research frontiers in fields ranging from traditional image processing applications to evolving multimedia and video technologies are regularly advanced by results first reported in ICIP technical sessions. <br\/>The project will lead to enhancements in all fields of image and video processing by enabling a number of young and promising researchers to participate in the discussion and presentation of the latest advances and in theoretical, experimental, and applied image and video processing. Recipients of the travel awards will be selected using the following criteria: (i) Full-time enrollment in a higher education US institution, (ii) Accepted paper of superior quality as evidenced by the reviews that the submission of the applicant received during the review process, and (iii) Letters of recommendation from academic advisors commenting about their overall achievements. No student of any of the selection committee members will receive a travel grant to attend ICIP 2009.","title":"Funding for Graduate Student Travel to International Conference on Image Processing 2009, November 7-11, 2009","awardID":"0950350","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}}],"PIcoPI":["515560"],"PO":["564898"]},"153830":{"abstract":"Looking back at Weiser's 1991 vision of ubiquitous computing, many of his predictions have been surpassed, often by several orders of magnitude: information appliances sport ever more powerful processors, store in excess of 64 GB of data onto solid state chips, and have constant high-bandwidth access to the network. Yet one prediction that has not been realized, as anybody who uses mobile computers today can attest, is the ability to use information appliances for several days before recharging them. While battery life is the cornerstone (without sufficient battery life the burden of maintaining multiple mobile devices outweighs the advantages), three emerging technologies may significantly alter the energy footprint of information appliances: bi-stable displays which only consume energy when they are refreshed; Magnetic RAM (MRAM) which combines the speed of SRAM, the density of DRAM, and the non-volatility of FLASH memory; and a new generation of powerful embedded processors that support aggressive power saving strategies, and which offer a preview of the potential of energy efficient asynchronous processors. Combined, these technologies will make it possible to create systems where power consumption is near zero while quiescent, a significant departure from the behavior of current devices. The PI's goal in this project is to investigate how the various interaction techniques we know of today might benefit a low energy architecture enabled by the aforementioned emerging technologies. The team has extensive experience with hardware design, hardware simulation, and empirical evaluation. Project outcomes will contribute to a better understanding of the parameters influencing the design of very low power interfaces, and will include: an openly available hardware test bed for evaluating interaction technique energy signatures; the first systematic evaluation of the energy footprint of command selection and navigation techniques to complement the extensive performance data already gathered; an evaluation of the potential of sensor-assisted techniques to reduce the energy consumption of information appliances; and the first evaluations of the potential of asynchronous design to enable very low power information appliances. Evaluations will be performed in the lab and through longitudinal deployments, considering a variety of tasks, to further increase the external validity of the results.<br\/><br\/>Broader Impacts: Project outcomes will establish the empirical foundations for very low energy interface designs that will help researchers and designers better understand the energy implications of various interaction techniques. They will offer researchers and practitioners the tools and toolkits they need to quickly implement and evaluate the overall energy footprint of a design, and thus will significantly lower the barrier to entry into this research area. Furthermore, they will support new curricula that focus on energy consumption. Given that information appliance use is accelerating, and since the distinction between information appliances and personal computers is blurring, this work will have a great impact on reducing the overall energy consumed for our everyday information needs.","title":"HCC: Small: Energy Signature of Interaction Techniques for Low Power Bi-Stable Displays Information Appliances","awardID":"0916217","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["475376","475375"],"PO":["565227"]},"153951":{"abstract":"CSR:Small:Collaborative Research: Hybrid Opportunistic Computing for Green Clouds<br\/><br\/>Xiaosong Ma (PI) and Xiaohui Helen Gu (co-PI), NCSU (lead institute)<br\/>Wuchun Feng (PI), Virginia Tech<br\/><br\/>Abstract<br\/><br\/>On-demand, service-oriented cloud computing infrastructures continue to increase in popularity with organizations. Three observations motivate us to investigate running high-throughput, data-intensive tasks as background workloads on these cloud infrastructures. First, the rapid growth in hardware parallelism leaves more residue resources to be exploited. Second, the ``incremental power usage'' of piggybacking a secondary background workload onto the foreground workload to utilize those residue resources is relatively low. Third, the advances in GPGPU (General-Purpose GPU) processing enable a novel coupling of concurrent workloads.<br\/><br\/>This project will explore a new computing model of offering cloud services on active nodes that are serving on-demand utility computing users. We plan to (1) assess the efficacy of resource sharing between foreground and background workloads and investigate the relationship between their resource usage patterns and the benefit and cost of their mixed execution; (2) develop scheduling and load management middleware that performs dynamic background workload distribution considering the energy-performance tradeoff; and (3) exploit the use of GPGPUs for cloud services on active nodes that are running foreground workloads mainly on the CPUs.<br\/><br\/>Our research will explore a revolutionary change in the use of cloud computing and may influence their hosting organizations' future resource configuration and planning to create greener clouds. The research will be closely integrated with education-oriented cloud platforms at NCSU. The PIs will also leverage their established services and connections to increase the participation of women and minority students and to promote students' interactions with industry partners.","title":"CSR: Small: Collaborative Research: Hybrid Opportunistic Computing for Green Clouds","awardID":"0916719","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563449"],"PO":["565255"]},"162300":{"abstract":"Technology mediated social participation is now a way of life for millions of people as they text family and friends via cell phones, track leaders and celebrities on Twitter, update their Facebook page to tell others about their activities, and interact with numerous web portals. Use of these technologies spans a broad range of users, from kids under ten years old to retirees.<br\/><br\/>This proposal will develop an intellectual framework and research agenda for studying and facilitating social participation for national priorities, such as health care, education, energy, disaster response, community safety, and environmental protection. Two workshops will cover six topics that will spur research challenges: (a) theoretical integration (b) social capital, social intelligence, and effective action, (c) sharable infrastructure, ethics, and protections, (d) design to motivate, (e) graduate training and (f) the unique challenges for government use of social media. The primary output of the workshops will be a report that specifies challenges and outcomes for each of the topic areas.","title":"Proposal for Two NSF Workshops: Technology-Mediated Social Participation","awardID":"0956571","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["561428","527291","527292"],"PO":["565342"]},"160496":{"abstract":"Visualization tools are an essential part of how many users work with complex data. However, many of the tasks in a broad range of domains require comparing complex objects (graphs, volumes, time series, molecular motions, etc.), and while there exist a wealth of tools for visualizing individual objects there is little support at present for comparing two or more of them. The PI argues that the visual comparison of complex objects is best handled with visualization tools and techniques specifically designed for that purpose, but the design of such tools is challenging as it adds new issues to the more general visualization problems, and the challenges increase as the visualization tasks scale to larger or more complex objects, or to comparisons among larger numbers of objects. While there are examples of comparative visualization tools, existing solutions are highly specialized; they provide only limited help in developing new tools, or in understanding the more general problem of comparative visualization.<br\/><br\/>In this exploratory project, the PI will take the first steps toward development of a science of comparative visualization. He will develop comparative visualization systems as case studies, providing insights into the more general problem as well as testbeds for new techniques and evaluation. He will develop a concept framework of visual comparison to codify ideas and principles, and he will develop new techniques that address issues common in comparative visualizations. Specific techniques the PI intends to develop include cartographic principles for informative display in 3D, mechanisms for the static depiction of complex motions, generalized applications of registration, interactive and automated view controls for juxtaposed displays, and generalized methods for data abstraction. These techniques are all motivated by general needs in comparative visualizations, and build upon prior technical developments and visual principles.<br\/><br\/>Broader Impacts: By providing a general analysis of the issues involved, along with principles and guidelines for the design of visualization tools, a taxonomy and catalog of known solutions, and new techniques to address common problems, a science of comparative visualization will allow developers to create better, and possibly more general, tools, which will impact a wide range of disciplines in science, engineering, and medicine.","title":"EAGER: Comparative Visualization","awardID":"0946598","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["531411"],"PO":["565227"]},"153720":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 <br\/>(Public Law 111-5). <br\/><br\/>Large scale software is difficult to maintain, modify and keep up to date. There is a dire need for automated support for software system navigation, search, and comprehension activities to assist software developers and maintainers. This project addresses this issue by tackling some foundational issues and providing innovative methods for useful automated support for software system navigation, search, and comprehension activities. The research will lead to automatic analyses of the programmer's words and their relationships, through their usage in code, which will elucidate the concepts and actions encoded in the program. By building the conceptual models from the ``sound bites'' using context and program structure, a more complete picture is recovered enabling transformative improvements in automated support for software maintenance and program comprehension.<br\/><br\/>The analyses are heavily driven by natural language processing, information retrieval, and machine learning. The research will advance the theory and development of software maintenance tools, which will improve the effectiveness of software maintainers, decreasing software maintenance costs and raising software quality as software evolves. In developing a new required course on software engineering-in-the-small, the PIs will incorporate learning how to use and evaluate software maintenance tools, including those developed in this project.","title":"SHF: Small: Analyzing and Modeling Natural Language Usage in Software to Improve Software Maintenance Tools","awardID":"0915803","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["527984","511464"],"PO":["564388"]},"153841":{"abstract":"This proposal will be awarded using funds made available by the American Recovery and Reinvestment Act of 2009 (Public Law 111-5), and meets the requirements established in Section 2 of the White House Memorandum entitled, Ensuring Responsible Spending of Recovery Act Funds, dated March 20, 2009. I also affirm, as the cognizant Program Officer, that the proposal does not support projects described in Section 1604 of Division A of the Recovery Act.<br\/><br\/>This collaborative research will create techniques that improve the reliability of software product lines. A software product line is a family of software systems that share certain common features and differ according to a set of specified variations. Use of software product lines has grown rapidly in industry because such reuse reduces the cost of building new systems. <br\/>Reliability is important to product-line developers since many product lines, such as mobile phones, industrial robots, and surgical imaging systems, require reliable operation. This project focuses on development of a rigorous framework for incremental assessment and prediction of software product line reliability (SPL-iRAP). The research has three major thrusts: (1) developing reliability modeling techniques for software product lines to handle the effects of variations and ongoing changes, (2) investigating the use of reliability models for prediction across the product line based on empirical data, and (3) quantifying the benefit of the reuse on software quality. The researchers will train students, particularly women and underrepresented groups, in software reliability techniques, create new curriculum units for teaching, and partner with industrial developers of product lines to demonstrate the new techniques.","title":"SHF: Small: Collaborative Research: Evidence-based Reliability Assessment of Software Product Lines","awardID":"0916275","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["531356"],"PO":["564388"]},"152631":{"abstract":"Trustworthy Reactive Routing Systems<br\/><br\/> Warren A. Hunt, Jr. and Sandip Ray<br\/> Department of Computer Sciences<br\/> University of Texas at Austin<br\/><br\/> {hunt,sandip}@cs.utexas.edu<br\/><br\/>Reactive concurrent systems, such as routers, consist of a number of<br\/>interacting processes that perform non-terminating computations<br\/>while receiving and transmitting messages. The design of such<br\/>routing systems is error-prone, and non-determinism inherent in<br\/>concurrent communications makes it hard to detect or diagnose such<br\/>errors. Our effort will develop ACL2-based tools for ensuring<br\/>trustworthy execution of large-scale reactive routing systems.<br\/><br\/>We aim to develop a scalable, mechanized infrastructure for<br\/>certifying correct and secure execution of reactive routing system<br\/>implementations through: a generic framework for modeling and<br\/>specifying systems at a number of abstraction layers; a<br\/>compositional methodology for mathematically analyzing such models;<br\/>and developing a suite of tools and techniques to mechanize and<br\/>automate such analysis within a unified logical foundation. Our<br\/>research exploits ACL2's general-purpose reasoning engine while<br\/>augmenting the tool suite with a streamlined modeling and<br\/>specification methodology. We will develop a collection of targeted<br\/>tools for verifying safety, liveness, and security properties of<br\/>such systems while staying within a single logic and proof system.<br\/><br\/>To facilitate verification of correspondence between protocol<br\/>layers, we propose to enhance ACL2's reasoning engine with automated<br\/>verification tools based on advances in BDD- and SAT-based<br\/>techniques. The invention and proof of inductive invariants is one<br\/>of the most time-consuming activities in reactive system<br\/>verification, and we will integrate into ACL2 a general-purpose<br\/>symbolic simulation capability; this technique can symbolically<br\/>simulate system models over a large number of computation steps,<br\/>thereby often obviating the construction of single-step inductive<br\/>invariants. The expected results will help automate the mechanical<br\/>verification of reactive systems such as routers and CPSs.","title":"TC: Large: A Formal Platform for Analyzing Internet Routing","awardID":"0910913","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["503869","503869","266247","409703"],"PO":["497499"]},"150695":{"abstract":"This is a collaborative research project combining the expertise of Ashish Goel, Stanford University (IIS-0904325) and Sanjeev Khanna, University of Pennsylvania (IIS-0904314).<br\/><br\/>Traditionally, content has been generated by a limited number of publishers (such as book houses, music companies, and newspapers), and its quality then evaluated by professional editors and reviewers. In recent years, however, individuals have become mass producers of content, generating images, blogs, opinions, and recommendations, in a decentralized manner. This content is then discovered and consumed by other users, and centralized review is rendered infeasible by the sheer magnitude of available content. Consequently, there is a need to utilize user feedback, both explicit and implicit, in order to provide optimum rankings and recommendations to Internet users. The same broad problem occurs in online advertising, automatic moderation of discussion boards, and automated deductions of user preference on social networks. In addition to being very large, user activity data on the Internet is also typically very sparse, since each user only performs a small share of possible actions (e.g., searches for a small fraction of keywords, reviews or purchases a small fraction of products).<br\/><br\/>This project aims to design algorithms and optimization techniques to effectively utilize such data. The sparse data is treated as a \"prior belief\" on user preferences. The project also aims to design economic incentives to obtain useful and corrective data, robust to manipulation. The two parts of this research interact strongly with each other, since the algorithmic component can identify valuable pieces of additional information to acquire. Together, these two parts can help users derive optimum value from Internet data. <br\/><br\/>Results of this project will improve search engine performance and facilitate web applications that employ user feedback. The project Web site (http:\/\/www.stanford.edu\/~ashishg\/sparse_opt.html) will be used to disseminate results.","title":"III: Medium: Collaborative Research: Optimization with Sparse Priors -- Algorithms, Indices, and Economic Incentives","awardID":"0904325","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["429621"],"PO":["563751"]},"153731":{"abstract":"CSR:Small:Collaborative Research: Hybrid Opportunistic Computing for Green Clouds<br\/><br\/>Xiaosong Ma (PI) and Xiaohui Helen Gu (co-PI), NCSU (lead institute)<br\/>Wuchun Feng (PI), Virginia Tech<br\/><br\/>Abstract<br\/><br\/>On-demand, service-oriented cloud computing infrastructures continue to increase in popularity with organizations. Three observations motivate us to investigate running high-throughput, data-intensive tasks as background workloads on these cloud infrastructures. First, the rapid growth in hardware parallelism leaves more residue resources to be exploited. Second, the ``incremental power usage'' of piggybacking a secondary background workload onto the foreground workload to utilize those residue resources is relatively low. Third, the advances in GPGPU (General-Purpose GPU) processing enable a novel coupling of concurrent workloads.<br\/><br\/>This project will explore a new computing model of offering cloud services on active nodes that are serving on-demand utility computing users. We plan to (1) assess the efficacy of resource sharing between foreground and background workloads and investigate the relationship between their resource usage patterns and the benefit and cost of their mixed execution; (2) develop scheduling and load management middleware that performs dynamic background workload distribution considering the energy-performance tradeoff; and (3) exploit the use of GPGPUs for cloud services on active nodes that are running foreground workloads mainly on the CPUs.<br\/><br\/>Our research will explore a revolutionary change in the use of cloud computing and may influence their hosting organizations' future resource configuration and planning to create greener clouds. The research will be closely integrated with education-oriented cloud platforms at NCSU. The PIs will also leverage their established services and connections to increase the participation of women and minority students and to promote students' interactions with industry partners.","title":"CSR: Small: Collaborative Research: Hybrid Opportunistic Computing for Green Clouds","awardID":"0915861","effectiveDate":"2009-09-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["502081","549981","502081","549981"],"PO":["565255"]},"153852":{"abstract":"For millions of Internet users today, controlling information access on Online Social Networks (OSNs) such as Facebook and LinkedIn is a difficult challenge. Privacy controls in current systems do not provide the necessary level of flexibility and usability to their users. Some systems like MySpace and LinkedIn allow users to grant all-or-nothing access control to their profiles. While simple to use, these controls are imprecise and can easily leak data to unintended recipients or prevent the legitimate sharing of data. In contrast, OSNs like Facebook provide extremely powerful controls that are unfortunately too complex for most users to configure. This proposal addresses the need for privacy control policies that are both powerful and simple to use. The proposed work provides simple and powerful privacy policies by using machine learning techniques to automatically infer user preferences from observed user behavior. The work also proposes \"privacy lenses,\" a generalized mechanism to debug privacy policies by viewing user information through the access controls of any specified user. These technical solutions will be implemented on the Facebook social network as a third-party application. In addition, the data gathered from the deployed application will provide evidence to either validate or refute the perplexing phenomenon known as the \"privacy paradox,\" where users take little action to protect their privacy despite expressing strong concerns about online privacy.<br\/><br\/>The proposed project addresses a significant problem fundamental to protecting online information. By allowing the social network to \"learn\" what users want based on their actions, the PIs remove the complexity of managing privacy policies, thereby giving non-technical Internet users a simple and intuitive way to customize their preferences. The work is novel in its use of machine learning techniques to infer user preferences, and can change the way privacy policies are constructed for a wide variety of Internet applications. By gathering user data from a large-scale social network, the project will also provide significant support to improve understanding of the motivations behind users actions concerning online privacy. Finally, the proposed work will integrate sophisticated experimental networking research techniques with detailed human studies, adding an additional dimension to traditional experiments performed by social scientists.","title":"TC: Small: Towards Automating Privacy Controls for Online Social Networks","awardID":"0916307","effectiveDate":"2009-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560388",409400],"PO":["543481"]},"152521":{"abstract":"Randomness has emerged as a core concept and tool in computation. From modeling phenomena to efficient algorithms to proof techniques, the applications of randomness are ubiquitous and powerful. Notable examples include: construction of important combinatorial objects such as expanders, rigorously establishing phase transitions in physical models, finding polynomial-time algorithms for fundamental sampling problems and approximating #P-hard counting problems, designing probabilistically checkable proofs (PCP's) and establishing the hardness of approximation, and discovering simpler and often faster algorithms for a variety of computational problems. In the course of these tremendous developments, several general-purpose techniques have emerged, and random sampling has become a fundamental, universal tool across sciences, engineering and computation.<br\/><br\/>This project brings together leading researchers in randomized algorithms to solve hard problems in random sampling, to identify techniques, and to develop new analytical tools. The applications come from a range of fields, including complexity, physics, biology, operations research and mathematics. The most general and widely-studied technique for sampling is simulating a Markov chain by taking a random walk on a suitable state space. The Markov Chain method and its application to sampling, counting and integration, broadly known as the Markov Chain Monte Carlo (MCMC) method, is a central theme of the project.<br\/><br\/>Intellectual Merit. The project focuses on applications of randomized algorithms and random sampling to rigorously address problems across several disciplines. Within computer science these topics include: massive data sets, where sampling is critical both for finding low-dimensional representations and clustering; routing networks, where sampling has many applications from monitoring and path allocation to optimization; machine learning; and property testing. Recent interactions between computer science and other scientic disciplines have led to many new rigorous applications of sampling, as well as new insights in how to design and analyze efficient algorithms with performance guarantees; for instance, phase transitions in the underlying physical models can cause local Markov chains to be inefficient. The project explores deeper connections between physics and random sampling, including conjectured correlations between reconstruction problems and thresholds for the efficiency of local algorithms. Many related problems arise in biology, such as phylogenetic tree reconstruction and analysis of complex biological networks. In nanotechology, models of self-assembly are simple Markov chains. In mathematics, the techniques used in the analysis of sampling algorithms in general and Markov chains in particular have drawn heavily on probability theory, both discrete and continuous.<br\/><br\/>Broader Impact. The college of computing at Georgia Tech is home to the new Algorithms and Randomness Center (ARC) with many faculty and students sharing this expertise. The project's activities include designing a summer school for graduate students in randomized algorithms and designing a course for training students from diverse backgrounds and hosting workshops focusing on both theoretical and applied aspects of randomized algorithms. Participation of women and under-represented groups in all of these activities will be encouraged, and the workshops will include tutorials to increase accessibility. These coordinated efforts in education and research will solidify the impact of ARC and make it a premier center for algorithms, randomness and complexity.","title":"AF: Large: Collaborative Research: Random Processes and Randomized Algorithms","awardID":"0910584","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["518569","565106","565103","517800"],"PO":["565251"]},"153985":{"abstract":"Abstract<br\/><br\/>0916845 <br\/>Nealen, Andrew <br\/>HCC: Small: Dynamic Skeletal Part Hierarchies for Sketching 3D Shapes and Their Animations<br\/>Rutgers University New Brunswick<br\/><br\/>Software for creating, modifying and animating digital 3D shapes is a key component in many computer applications: computer aided design, engineering, computer animation and digital games to name a few. This proposal addresses research into dynamic hierarchical part hierarchies, which combine the interrelated topics of modeling and animating digital shapes into a coherent whole, as well as simple and effective sketch-based computer tools, with the ultimate goal of making these tasks more accessible to amateurs and professionals alike. Advances in consumer computer graphics, as well as the current in\u00feux of user generated digital content, both in virtual 3D worlds as well as on the Internet, illustrate the demand for easy-to-use 3D content creation software. Recent research in shape modeling and animation, as well as sketch-based interfaces, has led to the development of experimental techniques, which clearly demonstrate their viability. Yet, most of these are highly specialized and domain specific, and they do not deal with these problems as a whole. The proposed research will build upon this previous work, but put an emphasis on developing new sketch-based interfaces, algorithms and shape representations that allow combining previously disjoint, yet intrinsically connected tasks of shape modeling and animation.","title":"HCC: Small: Dynamic Skeletal Part Hierarchies for Sketching 3D Shapes and Their Animations","awardID":"0916845","effectiveDate":"2009-09-01","expirationDate":"2013-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["554082"],"PO":["565227"]},"155932":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project, building and testing an Affordable System for Solar Irradiance Sensing and Tracking (ASSIST), proposes a tiered-architecture where a small number of expensive and highly calibrated observatories get complimented by a larger number of inexpensive, but uncalibrated, ASSIST nodes. <br\/>Integrating economic stand alone wireless global irradiance sensors with a new dome sensor that avoids having costly moving parts and automatic solar trackers (ASTs), ASSIST nodes should adapt to the vagaries of wireless communication channel, as well as possible failures of many nodes in the ensemble. The work responds to a major obstacle in developing policies that promote and take advantage of existing solar technologies, that of lack of reliable data for ground solar irradiance (direct normal and global irradiance). Despite well-defined and easily calculated radiation reaching outer layers of the atmosphere, solar irradiance reaching ground level (where thermal and photovoltaic solar collectors operate) depends strongly on localized and complex atmospheric conditions. Hence, distributed, embedded environmental sensor systems now enable scientists and engineers to observe environmental systems with previously unattainable spatio-temporal resolution. The vision of sensor systems coupled with 'smart' networking, integrated with visualization tools by an overarching cyberinfrastructure is shared by disciplines actively engaged in solar irradiance monitoring all over the world, and is likely to be realized when such systems are developed ahead of the observatory efforts. The system, developed and tested in the heart of California's Central Valley, is coupled with well-characterized infrastructure-rich solar observatories already deployed. ASSIST aims to serve as a model sensor and information technology system for directly and quantitatively observing the effects of cloud cover, aerosol content, and the presence of participating gases in the lower atmosphere (water vapor, carbon dioxide) and in the stratosphere (ozone), all of which can reduce the availability of direct isolation at ground level to a small fraction of the solar irradiance that reaches the upper atmosphere. From the operational standpoint, the balancing of supply and demand peaks in the electrical grid requires detailed consideration of the availability of solar power as US embraces a more renewable profile of energy utilization. Thus, forecasting the available insolation enables information technology for the success of any policy to include power to the power grid. Engaging students and researchers, this end-to-end sensor system supporting the observatory scale science in solar systems science provides a well-characterized, science-driven design test-bed in a minority-serving university<br\/><br\/>Broader Impacts: This project enables engineers and scientists to quantify DNI data at spatial and temporal scales currently unavailable. The work develops distributed instruments that are self-configurable, without the need of expensive and difficult-to-maintain mobile parts, and significantly less expensive than current instruments in solar observation technology. The system will be utilized for student experiences; it provides access to important data; and its findings may be adopted by other observatories. In addition to an expected major impact on environmental, CS, electrical, and mechanical research and education directives, the project services student in a minority-serving institution.","title":"MRI: Development of ASSIST: Affordable System for Solar Irrdiance and Tracking","awardID":"0923586","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["511033","534560","509403"],"PO":["557609"]},"153875":{"abstract":"In future high-performance microprocessors, memory system organization and management is perhaps the most critical looming issue. Accesses to memory will incur long delays and energy overheads in various queuing structures and in long wires. Each access will experience non-uniform delay and energy overheads based on the location of the stored data. Efficient layout of data within the memory hierarchy is therefore essential for high performance and low power. In this proposal, the PIs put forth a comprehensive hardware\/software strategy for data placement in cache\/memory structures with non-uniform delay and power. Novel mechanisms are proposed to cost-effectively migrate pages within the memory hierarchy. These mechanisms will attempt to leverage hardware structures, OS support, compiler hints, and compiler transformations. The PIs also plan to engage in broader impact activities that encourage minority participation and augment research infrastructure.","title":"SHF: Small: Hardware\/Software Management of Large Multi-Core Memory Hierarchies","awardID":"0916436","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["542054","556789"],"PO":["366560"]},"153644":{"abstract":"The goal of this project is to make possible database searching in a privacy-constrained manner: A private database provider allows only properly authorized searches by clients, in a manner that does not reveal the search criteria yet enforces the requirement that the client learns only what is authorized by the search. The initial focus will be on techniques for the case of exact matches, later extended to the much more difficult case of approximate matching. If multiple matches are found, either all of them are returned, or a subset of the \"best\" of them, under appropriately defined notions of quality, is returned; in approximate matching there is a natural notion of quality, namely, having smaller distance to the target of the search as specified by the query. The technical challenges include verification of the validity of a search request, and then carrying out the search, in manner that enforces the search's authorized criteria without revealing them. The project holds the promise of leading to substantial improvements in the highly unsatisfactory current \"state of the practice\" for searches carried out on private and sensitive databases, that unnecessarily reveal too much information and prevent useful collaborations from taking place due to concerns over the leakage of sensitive information. The minimal-disclosure feature of the protocols will also make possible a de facto \"defense in depth\", in that a compromised server will no longer automatically imply the compromise of all the clients' interactions with that server.","title":"TC: Small: Collaborative Research: Privacy-Constrained Searching","awardID":"0915436","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553652"],"PO":["565136"]},"153765":{"abstract":"Computational geometry is the branch of theoretical computer science devoted to the design, analysis, and implementation of geometric algorithms and data structures. Computational geometry has deep roots in reality: Geometric problems arise naturally in any computational field that simulates or interacts with the physical world---computer graphics, robotics, geographic information systems, computer aided-design, and molecular modeling, to name a few---as well as in more abstract domains such as combinatorial geometry and algebraic topology. <br\/><br\/>This research focuses on fundamental problems in computational geometry. These problems include set-cover, hitting set, independent set, and other related problems. These problems have numerous applications from wireless networking to optimization.<br\/><br\/>The main theme of this research is to combine ``classical'' Computational Geometry techniques (like cuttings, epsilon-nets, etc) together with techniques used in Operation Research (Linear Programming, rounding techniques, etc).<br\/><br\/>This research aims to greatly improve our understanding of the structure of these fundamental problems. The research may lead to improved approximation algorithms for these problems. <br\/><br\/>The algorithms and insights obtained from the technical work will benefit computer science and related disciplines where geometric algorithms are widely used. This research has potential to broaden the scope of Computational Geometry by introducing new techniques into the field. <br\/><br\/>A book partially based on the research in this award will be published in the near future. This will make the developed techniques available to wide audience consisting of students and researchers from several disciplines include engineering, mathematics, and the natural and social sciences.","title":"AF: Small: Approximation, Covering and Clustering in Computational Geometry","awardID":"0915984","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":["517802"],"PO":["565157"]},"153886":{"abstract":"The field of bioinformatics and computational biology is experiencing a data revolution unlike any other scientific computing field. Experimental techniques to procure data have increased in throughput, improved in accuracy, and reduced in costs. The preponderance of data has limited the scalability of existing software tools. In a pursuit to understand the complexities and challenges that stem from designing algorithms for data-intensive biocomputing, this project is developing new approaches for two major problems in protein bioinformatics: i) identification of protein families and homology clusters; and ii) peptide identification from large-scale mass spectrometry data. The former requires large-scale graph analysis and the latter requires large-scale database search. The project is investigating a multi-faceted approach which involves designing space-efficient algorithms for massively parallel machines, developing algorithmic heuristics for reducing the time to solution, evaluating the MapReduce paradigm as an alternate computing model, and deploying multicore architectures for fine-grain parallelism. Project outcomes will include new algorithms and open-source software libraries for large-scale protein bioinformatics, including a more generic library for data-intensive biocomputing. The project is addressing a critical need for scalable methods in protein bioinformatics and in doing so will usher in state-of-the-art computing models and concepts from both software and hardware into mainstream biocomputing. Broader impacts include creating interdisciplinary research opportunities for undergraduate and graduate students, and new interdisciplinary curricula at high school, undergraduate and graduate levels. Education materials will be disseminated through a partnership program with Shodor Education Foundation, Inc.<br\/><br\/>Project homepage: http:\/\/www.eecs.wsu.edu\/~ananth\/DataIntensive-Biocomputing\/","title":"DC: Small: Efficient Algorithms for Data-intensive Bio-computing","awardID":"0916463","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["523585",409487,"538714"],"PO":["560586"]},"153655":{"abstract":"0915503<br\/>CSR:Small:Efficient and Predictable Memory Hierarchies for High-Performance Embedded Systems<br\/><br\/>Abstract<br\/><br\/><br\/>High-end embedded systems are increasingly used for complex computation, such as advanced image processing and speech processing. Such complex tasks often involve irregular data structures such as linked data structures, or exhibit irregular access patterns even with regular data structures. Managing scratchpad memory for such tasks becomes increasingly challenging due to the difficulty of determining addresses that will be accessed in the future. For such complex applications, hardware-managed storage (caches) can perform relatively well without much programming effort. However,caches do not offer predictability required to derive a tight worst case execution time (WCET) bound in real-time systems, due to their dynamic behavior that is difficult to predict at compile time. <br\/><br\/>The goal of the project is to explore a new intelligent real-time cache, which offers ease of storage management as well as allows programs to control caching behavior with low overheads, providing predictability that supports real time analysis. The work consists of: (1) Instruction and architecture support that provides primitives to control cache behavior with low overheads, (2)Development compile-time analysis and run-time support to support the new cache, and (3)Proof-of-concept of the proposed system. <br\/><br\/>Improved memory performance and predictability will be to make computer systems more efficient, enable more challenging problems to be solved, and improve energy-efficiency of existing applications. This project will also extend outreach to undergraduate and high-school students about the value of engineering to society and attract more students into the field. It will also benefit the public by disseminating research results through publications and tool releases.","title":"CSR:Small:Efficient and Predictable Memory Hierarchies for High-Performance Embedded Systems","awardID":"0915503","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"J138","name":"National Security Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"K555","name":"National Security Agency"}}],"PIcoPI":["485952","485790"],"PO":["565255"]},"152324":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Proposal#: 0910767 <br\/>Collaborative Proposal #s: 0909980, 0910483, 0910653 <br\/>Title: TC: Large: Collaborative Research: Trustworthy Virtual <br\/>Cloud Computing <br\/>PIs: Peng Ning, Xuxian Jiang, and Mladen Vouk <br\/>Abstract: <br\/><br\/>Virtual cloud computing is emerging as a promising solution to IT <br\/>management to both ease the provisioning and administration of complex <br\/>hardware and software systems and reduce the operational costs. With the industry?s continuous investment (e.g., Amazon Elastic Cloud Computing, IBM Blue Cloud), virtual cloud computing is likely to be a major component of the future IT solution, which will have significant impact on almost all sectors of society. The trustworthiness of virtual cloud computing is thus critical to the well-being of all organizations or individuals that will rely on virtual cloud computing for their IT solutions. <br\/><br\/>This project envisions trustworthy virtual cloud computing and investigates fundamental research issues leading to this vision. Central to this vision is a new security architecture, which harnesses new opportunities and capabilities such as built-in out-of-band system <br\/>access, processor and hardware support for trusted computing, and out-of-box examination by hypervisors. This project focuses on key research issues following this security architecture, including new security services that enhance the trustworthiness of virtual cloud computing, protection of management infrastructure against malicious workloads, and protection of hosted workloads from potentially malicious management infrastructure. The research will enable the adoption of virtual cloud computing for critical IT management in industry and government organizations. This project will involve both graduate and undergraduate students, and will produce open source software and tools, which will be made available to the public.","title":"TC:Large: Collaborative Research: Trustworthy Virtual Cloud Computing","awardID":"0909980","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["492625"],"PO":["565327"]},"153776":{"abstract":"The research objective is to investigate methods to recover geometry and perform spatial reasoning in rooms. This project aims to recover the room space, illumination, and object layout from an image. Together, these elements capture the layout of the room walls, the location of objects in the image and the 3D space, and a lighting representation that allows illumination artifacts to be explained and rooms to be relit with inserted objects. The work takes an integrated approach, exploiting constraints within and between spatial representations. The project also aims to leverage knowledge of room geometry to better reason about surface utility, enabling advanced spatial analysis of indoor scenes. <br\/><br\/>This research unifies ideas from geometry, multiple view computer vision, shading, and statistics to recover complex spatial representations from single views. The work further aims to create tools for object insertion and removal and scene completion, allowing the average person to more easily create the photograph that she wants or an interior designer to quickly sketch a photorealistic prototype of a new concept. The recovered spatial information also enables mobile robots to find walkable paths through cluttered rooms and to understand how objects can be physically manipulated and placed, which is essential for assistive household robotics. Other anticipated applications include surveillance, security, and transportation safety. The project contributes to education through student projects, course development, and workshops and tutorials involving a broader audience.","title":"RI: Small: Exploiting Geometric and Illumination Context in Indoor Scenes","awardID":"0916014","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["457204","469791"],"PO":["564316"]},"152566":{"abstract":"The Internet suffers from insufficient service quality to reliably support many real-time, high bitrate applications. This shortcoming is due in large part to users or providers not considering the effect their choices have on others ? in other words the resulting externalities. For example, users who download movies during the work day reduce the quality of the network for more time-critical applications; in a non-neutral network, individual ISPs may overcharge high-value applications if they do not consider the interactions of such charges across ISPs. Depending on the circumstances, the problem can be due to a combination of the following three effects: i) the technology of the network does not enable the user or provider to make better choices; ii) the network does not give the user or provider the information to make better choices; iii) the user or provider lacks an incentive to make better choices even if he can. This project will investigate how these effects impact service quality in the network. Using this analysis as a basis, remedies for these effects will be investigated. The remedies may include combinations of new protocols and technology, pricing mechanisms, and regulation ? including requirements and\/or mechanisms for information disclosure. <br\/><br\/>Intellectual Merit: <br\/>This project addresses fundamental scientific and engineering questions in networking. The scientific questions include suitable formulation and analysis of the strategic choices that the users, content providers, service providers, and other parties in the network face when they interact. The properties of the resulting equilibrium strategies and their distributed computation raise novel mathematical and algorithmic questions of broad relevance. Other fundamental scientific issues addressed include how to provide incentives for network evolution and for improved reliability. Engineering questions concern the scalability of the proposed algorithms and protocols, their security and robustness, how they can be deployed incrementally, and their extensibility as new technologies, services, and applications get implemented. <br\/><br\/>Broader Impact: <br\/>The investigators expect that the work will contribute to a paradigm shift in the design of the future network. The focus on externalities, which is central to our project, has been largely unexplored and our preliminary investigations demonstrate its substantial importance. The investigations undertaken in the course of this project will suggest how network design should be modified to account for externalities and network informational imperfections. This project, with its focus on the intersection of the engineering and economic issues of network services, will offer ideal research experience to the project?s Ph.D. students. It is expected that the experiences and results from this project will greatly benefit the PI?s courses as well, in particular by making students aware of the inherent tradeoffs in engineering systems that function in a market context.","title":"NetSE: Large:Collaborative Research: Improving Internet Incentives","awardID":"0910711","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["432638"],"PO":["564993"]},"153545":{"abstract":"Testing is essential for database applications to function correctly and with acceptable performance when deployed. In practice, it is often necessary for vendors of database application software to test their software adequately before selling or integrating their software to the database owner. However, testing database applications is very costly. In particular, it is time-consuming and challenging to generate desirable database states, an important portion of test inputs for testing database applications. However, little research has been conducted to provide scalable, effective tool support for generating database states to achieve various testing objectives.<br\/><br\/>This research aims to adequately generate database states for database applications by developing novel techniques for (1) generating desirable database states to satisfy the given constraints on result sets from the given query, (2) applying this preceding technique on a variety of testing tasks, and (3) exploring more complicated situations such as constraints in multiple interacting queries. The research advances understanding of fundamental issues related to testing database applications and the design and implementation of practical techniques to carry out such testing. Among the broader impacts of the project includes integration of the research into education programs and enhancement of teaching and research infrastructure.","title":"SHF: Small: Collaborative Research: Constraint-Based Generation of Database States for Testing Database Applications","awardID":"0915059","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["492490"],"PO":["564388"]},"151004":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Though perhaps unfortunate, as a practical matter software is often<br\/>built with functionality as a primary goal, and security features are<br\/>only added later, often after vulnerabilities have been identified.<br\/>To reduce the cost and increase assurance in the process of security<br\/>retrofitting, the aim to develop a methodology involving automated and<br\/>semi-automated tools and techniques to add authorization policy<br\/>enforcement functionality to legacy software systems.<br\/><br\/>The main insight is that major portions of the tasks involved in<br\/>retrofitting code can be or already have been automated, so the design<br\/>process focuses on enabling further automation and aggregating these<br\/>tasks into a single, coherent approach.<br\/><br\/>More specifically, techniques and tools are being developed to: (1)<br\/>identify and label security-relevant objects and I\/O channels by<br\/>analyzing and instrumenting annotated application source code; (2)<br\/>insert code to mediate access to labeled entities; (3) abstract the<br\/>inserted checks into policy-relevant, security-sensitive operations<br\/>that are authorized (or denied) by the application's security policy;<br\/>(4) integrate the retrofitted legacy code with the site's specific<br\/>policy at deployment time to ensure, through advanced policy analysis,<br\/>that the application enforces that site's policy correctly, and (5)<br\/>verify correct enforcement of OS policy delegation by the retrofitted<br\/>application.<br\/><br\/>The techniques and tools being developed are useful not only<br\/>for retrofitting, but also for augmenting and verifying existing code<br\/>already outfitted with security functionality; hence improving the<br\/>state-of-the-art in creating more secure software.","title":"TC:Medium:Collaborative Research:Techniques to Retrofit Legacy Code","awardID":"0905442","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548254"],"PO":["565264"]},"153688":{"abstract":"Network intrusion detection systems (NIDS) need to balance between a set of challenges difficult to simultaneously address to their full extent: the complexity of network communication; the need to operate extremely efficiently to achieve line-rate performance; and dealing securely with untrusted input. Our project aims to build an efficient and secure bridge between dealing effectively with these challenges, and offering the high-level abstractions required for describing a security policy. Observing that NIDS implementations share a large degree of functionality, we introduce a new middle-layer into NIDS processing, consisting of two main pieces: first, an abstract machine model that is specifically tailored to the network intrusion detection domain and directly supports the field's common abstractions and idioms in its instruction set; and second, a compilation strategy for turning programs written for the abstract machine into highly optimized, natively executable code for a given target platform, with performance comparable to manually written C code. As a broader goal, our undertaking provides the security community with a novel architecture that facilitates development and reuse of building blocks commonly required for network traffic analysis. While the focus of our effort is the design and implementation of the abstract machine environment itself, we envision enabling the community to unleash its full potential by building analysis functionality on top of the platform we develop.","title":"TC: Small: A High-Performance Abstract Machine for Network Intrusion Detection","awardID":"0915667","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["562329","525668"],"PO":["564223"]},"165788":{"abstract":"Georgetown University proposes a project aimed at attracting underrepresented students to computing. Traditional approaches target individuals those, for example, with an interest in math and\/or science or those who have already taken a computer science course who have a good likelihood of pursuing computing. This project targets an untapped, but potentially higher impact, target audience: students who are not already attracted to science. Students will be recruited from the general population using mainstream sources as well as science-based venues. The effort will investigate whether untapped mainstream venues can be used to recruit new computing professionals. In particular, can sports and computer games attract unrepresented students? Can marketing techniques, perhaps from sports, gaming, and television sitcom venues, be exploited to broaden participation in computing? This project will develop marketing techniques and recruitment approaches, with corresponding dissemination methods, to popularize the idea of computing across a variety of demographics, targeting women and minorities in K-12. It will also develop methods for introducing and training students in computing by transforming low-level technical concepts into high-level modules appealing to mainstream populations using storyboards where students will act as private investigators, solving mysteries in which the more exciting computing technologies such as robotics, augmented reality techniques, intelligent software agents, and avatars are used as tools to find each clue. The major outcomes of this project will be: <br\/><br\/> Reusable storyboard modules and tools that leverage visual technologies in computing and embeds them into investigative scenarios, and teaming approaches similar to popular sports activities. <br\/> Curriculum and materials for one-week summer institutes piloted at Georgetown and Georgia Tech exploiting\/experimenting\/evaluating modules that build upon the PIs current research programs. <br\/> Teacher training kits\/documentation for integrating the modules into the classroom. <br\/> Slogan\/marketing plan to advertise computing (and the modules) to the target populace.","title":"BPC-DP: Popularizing Computing to the Mainstream","awardID":"1004014","effectiveDate":"2009-09-14","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":[444191],"PO":["564181"]},"152478":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Proposal#: 0910767 <br\/>Collaborative Proposal #s: 0909980, 0910483, 0910653 <br\/>Title: TC: Large: Collaborative Research: Trustworthy Virtual <br\/>Cloud Computing <br\/>PIs: Peng Ning, Xuxian Jiang, and Mladen Vouk <br\/>Abstract: <br\/><br\/>Virtual cloud computing is emerging as a promising solution to IT <br\/>management to both ease the provisioning and administration of complex <br\/>hardware and software systems and reduce the operational costs. With the industry?s continuous investment (e.g., Amazon Elastic Cloud Computing, IBM Blue Cloud), virtual cloud computing is likely to be a major component of the future IT solution, which will have significant impact on almost all sectors of society. The trustworthiness of virtual cloud computing is thus critical to the well-being of all organizations or individuals that will rely on virtual cloud computing for their IT solutions. <br\/><br\/>This project envisions trustworthy virtual cloud computing and investigates fundamental research issues leading to this vision. Central to this vision is a new security architecture, which harnesses new opportunities and capabilities such as built-in out-of-band system <br\/>access, processor and hardware support for trusted computing, and out-of-box examination by hypervisors. This project focuses on key research issues following this security architecture, including new security services that enhance the trustworthiness of virtual cloud computing, protection of management infrastructure against malicious workloads, and protection of hosted workloads from potentially malicious management infrastructure. The research will enable the adoption of virtual cloud computing for critical IT management in industry and government organizations. This project will involve both graduate and undergraduate students, and will produce open source software and tools, which will be made available to the public.","title":"TC: Large: Collaborative Research: Trustworthy Virtual Cloud Computing","awardID":"0910483","effectiveDate":"2009-09-15","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553884"],"PO":["565327"]},"152599":{"abstract":"Pollution sensing and diagnosis have long been separated from the people most impacted by them. It was conducted by specialists with expensive and scarce equipment. As a result, testing was infrequent and decisions on mitigation were made by central planners with limited access to data. Worse yet, individuals with the ability to dramatically limit dangerous exposure via minor changes in behavior have been left blind to the relationship between their daily actions and exposure to pollution. Advances in computing, sensing, and wireless communication technologies have the potential to allow those most affected by pollution to participate in pollution sensing, rational cost assessment, and mitigation.<br\/><br\/>This project focuses on developing a distributed mobile system for socially-collaborative environmental monitoring, which greatly reduces the problem of environmental sensing data scarcity, supports richer environmental sensing data analysis, and enables better environment awareness and protection via social collaboration. This project will develop a system composed of inexpensive sensing and computation devices purchased by individuals for their own edification and protection. These embedded systems will communicate with each other and aggregate data, enabling multi-sensor localization of pollution<br\/>sources and quantification of the potential damage by each polluter. By measuring pollution and modeling its impact, it will be possible to associate pollution sources with the costs they impose. Furthermore distributed networking will allow individuals to actively participate in and socially collaborate on environmental monitoring and protection.","title":"CSR: Large: Collaborative Research: CommonSense--A Distributed Mobile System for Socially-Collaborative Environmental Monitoring","awardID":"0910816","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550572"],"PO":["565274"]},"157813":{"abstract":"The objective of this research is to develop a real-time operating system for a virtual humanoid avatar that will model human behaviors such as visual tracking and other sensori-motor tasks in natural environments. This approach has become possible to test because of the development of theoretical tools in inverse reinforcement learning (IRL) that allow the acquisition of reward functions from detailed measurements of human behavior, together with technical developments in virtual environments and behavioral monitoring that allow such measurements to be obtained.<br\/><br\/>The central idea is that complex behaviors can be decomposed into sub-tasks that can be considered more or less independently. An embodied agent learns a policy for actions required by each sub-task, given the state information from sensori-motor measurements, in order to maximize total reward. The reward functions implied by human data can be computed and compared to those of an avatar model using the newly-developed IRL technique, constituting an exacting test of the system. <br\/><br\/>The broadest impact of the project would provide a formal template for further investigations of human mental function. Modular RL models of human behavior would allow realistic humanoid avatars to be used in training for emergency situations, conversation, computer games, and classroom tutoring. Monitoring behavior in patients with diseases that exhibit unusual eye movements (e.g., Tourettes, Schizophrenia, ADHD) and unusual body movement patterns (e.g., Parkinsons), should lead to new diagnostic methods. In addition the regular use of the laboratory in undergraduate courses and outreach programs promotes diversity.","title":"CPS: Small: A Real-Time Cognitive Operating System","awardID":"0932277","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[421228],"PO":["565035"]},"151037":{"abstract":"TC: Medium: Collaborative Research: Wide-Aperture Traffic Analysis for Internet Security<br\/><br\/>Among emerging network threats, some of the most pernicious and elusive are stealthy attacks that take place at very low rates and in a targeted fashion. This project is developing methods for identifying malicious and unwanted activity in the Internet -- specifically, traffic that is low-volume and well \"hidden'' among normal traffic. The approach being taken is to develop new methods for direct analysis of Internet traffic of unprecedented scope and scale. In particular, the project is designing and implementing a system that leverages high-performance cluster computing to allow application of sophisticated pattern analysis and machine learning algorithms to network traffic at the packet and flow level.<br\/><br\/>An organizing principle of the system is its decomposition into data-parallel \"lenses'' and more computationally challenging \"pattern analysis'' components. The project is investigating the application of this architecture to dark address monitoring in traffic from core networks -- a capability that has not been possible to date.<br\/>The end result of this project will be a set of tools and a running system that may be used by researchers to enable new investigations into traffic analysis, and may be used by network operators on an ongoing basis to help protect their networks.","title":"TC: Medium: Collaborative Research: Wide-Aperture Traffic Analysis for Internet Security","awardID":"0905565","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["486062","564449"],"PO":["564223"]},"157824":{"abstract":"CPS: Small: Community-based Sense & Respond -- Theory and Applications<br\/><br\/>The objective of this research is to address a fundamental question in cyber-physical systems: What is the ideal structure of systems that detect critical events ? such as earthquakes ? by using data from large numbers of sensors held and managed by ordinary people in the community? The approach is to develop theory about widely-distributed sense and respond systems, using dynamic ? and possibly unreliable ? networks using sensors and responders installed and managed by ordinary citizens, and to apply the theory to problems important to society, such as responding to earthquakes.<br\/><br\/>Intellectual Merit: This research develops theory and prototype implementations of community-based sense-and-respond systems that enable people help one another in societal crises. The number of participants in such systems may change rapidly; some participants may be unreliable and some may even deliberately attack systems; and the structures of networks change as crises unfold. Such systems must function in rare critical situations; so designs, analyses and tests of these systems must give confidence that they will function when the crisis hits. The proposed research will show how to design systems with organic growth, unreliable components and connections, security against rogue components, and methods of demonstrating reliability.<br\/><br\/>Broader Impact: People want to help one another in a crisis. Cheap sensors, mobile phones, and laptops enable people to use information technology to help. This research empowers ordinary citizens collaborate to overcome crises. The researchers collaborate with the US Geological Service, Southern California Edison, and Microsoft, and will host 3,000 students at a seismic facility","title":"CPS: Small: Community-based Sense & Respond -- Theory and Applications","awardID":"0932392","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["432447","499268","456621","499268","548354"],"PO":["564778"]},"154447":{"abstract":"This proposal requests funding to support a doctoral consortium for Ph. D. students to be held just prior to the Joint Conference for Digital Libraries (JCDL) held this year in Austin, Texas. The doctoral consortium is a workshop for Ph.D. students who are in the early phases of their dissertation work. It is international in scope. The primary goal is to help students develop their thesis proposal and a plan for subsequent research by providing constructive and thoughtful feedback on their work to date and ideas for future work. Students provide formal written papers for critical review, and then present their research at the workshop, which takes place the day before the conference begins. The consortium is led by prominent professors and experienced practitioners in the field of digital library research and development. Leaders come from all over the world, and work at universities, research foundations, and in industry. The JCDL doctoral consortium provides students with an opportunity to meet and interact intellectually with people who would be otherwise difficult to meet, as well as to discuss their ideas with a broad and diverse set of people.","title":"Doctoral Consortium Support - JCDL 2009","awardID":"0918459","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[411072],"PO":["433760"]},"176117":{"abstract":"The CrystalGrid Framework (CGF) project will research the acquisition, transport, and curation of data over the entire data space of the field of X-ray crystallography, addressing methods for managing wide heterogeneity in data representations, formats, data containers, administrative domains and diverse instruments and equipment. Until recently, individual labs have simply imposed local homogeneity of format and procedure, and not stored lab-dependent metadata. This ad hoc system is limited, however, as crystallographers begin to cross between labs to accomplish their research objectives, and as increasing numbers and sizes of output data streams leave less time for each investigation. Local workflow must be made explicit, procedures must be formally described, and the history and assemblages of data expressed in an open, shareable way. Creation and management of complete, accessible records for each experiment is critical, as well as heterogeneity in data acquisition and management across the field. <br\/><br\/>To meet that need, this project will develop a framework of web service interfaces and data and metadata systems addressing the whole spectrum of crystallography. Project participants and collaborators will leverage existing projects, such as Reciprocal Net and Common Instrument Middleware Architecture, that address narrower issues in the problem domain. The CGF will also draw on collaborating projects with overlapping areas of interest, such as the UK-based Comb-e-Chem project. The resulting framework will be a useful environment for crystallographic investigations and an extensible platform on which new web-based applications can be built.<br\/><br\/>The CGF project involves the classic problem of dealing with heterogeneity in data, procedures, and instruments in the crystallography application space, and another classic problem in integrating the entire data collection, transport, and curation requirements of the domain into a seamless beginning to end system. The challenge is to create a virtualization system that manages heterogeneity in more than a single aspect and to provide vertical integration using only open, extensible, and interoperable standards and methodologies.<br\/><br\/>While the project constitutes research into pertinent computer science problems, the plan for performing the research is centered on producing a product (the CGF) that will immediately be useful in addressing emerging technical problems in the field of X-ray crystallography. Within crystallography, one of the specific goals is to make structural results accessible that might otherwise never be seen, and so the CGF will help increase the body of scientific knowledge and improve the return on federal investment in the large numbers of x-ray diffractometers and associated instruments nationwide. Although the project targets specifically a few hundreds of crystallography labs worldwide, the software and methods created in it are intended to be reusable for any science moving from individual lab practices to a shared, global collaboratory system. In sciences such as high-energy physics and astronomy, the scientists have long shared single, unique, large instruments and had to create shared data management and instrument metadata. CGF is likely to be useful in other scientific disciplines which still use widely-distributed lab-based instruments that now need to be linked in data grids.","title":"Collaborative Research: The CrystalGrid Framework","awardID":"1059061","effectiveDate":"2009-09-01","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":[471971],"PO":["565136"]},"146604":{"abstract":"Proposal ID: 0846053 <br\/>Title: CAREER: An Effective Integration of Research and Education on High-Speed and Energy-Efficient Interconnects for Multi-Core and Multi-Thread Systems<br\/>PI name: Jiangjiang Liu <br\/><br\/><br\/>Abstract: <br\/>The goal of this CAREER project is to improve the speed and energy efficiency of computers that use multi-core systems. There is enormous demand for these multi-core systems in high-performance and data-intensive applications. When information is sent from one core to another, the interconnect devices create a bottleneck. Compressing the information to reduce its size speeds up the transfer over the interconnects and reduces energy consumption. This project will conduct the first comprehensive compressibility analysis of information on all important interconnect components for multi-core systems in the context of real-world application programs. This will help guide the proposed design of compression techniques for interconnects and provide a deeper understanding of how compression should be applied to help interconnect performance and alleviate energy bottlenecks in multi-core systems. Three novel information compression techniques are proposed. The proposed methods can be adapted and applied to address high-speed I\/O channel performance and energy bottlenecks.<br\/><br\/><br\/>The CAREER project effectively integrates research and education; promotes undergraduate and graduate research; stimulates and equips aspiring computer science undergraduates who are underrepresented or economically challenged in advanced study; triggers initial interest of K-12 students in computing with strong outreach efforts; enhances Lamar?s infrastructure by providing high-performance computing equipment; enhances scientific and technological understanding by disseminating the results of the program to a broad audience through international publications and a dedicated website; and advances and accelerates expansion of high performance computing applications as well as commercial business applications by improving the interconnect speed and overall performance of multi-core systems.","title":"CAREER: An Effective Integration of Research and Education on High-Speed and Energy-Efficient Interconnects for Multi-Core and Multi-Thread Systems","awardID":"0846053","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[390833],"PO":["562984"]},"154106":{"abstract":"Technology limitations, emerging applications, and changing usability trends are ushering in a new era in multi-core computer systems. A key problem for both application and microprocessor design is that applications are largely evolving independently from the architectural development of microprocessors. This is a problem for architectural research because developing efficient architectural solutions requires realistic characterization of the next generation applications. From a system design perspective, understanding application behavior is crucial for building an efficient system, since they must be optimized to exploit mechanisms provided in the architecture. This proposal seeks to re-think next generation multi-core systems - both software<br\/>and hardware architectures using state-of-the-art quantitative design<br\/>tools.<br\/><br\/>The two key ideas explored in this research are the following. First, is a hybrid task-level\/data-level parallelism execution model for emerging applications that have abundant but not synchronization-free parallelism. Second, is the development of new highly accurate and efficient quantitative models to evaluate architecture and application design alternatives, at scale and over a wide range of application workloads. The project seeks to provide a suite of quantitative tools to close the development loop of design, evaluation and analysis of software's behavior on hardware, allowing the tuning of both software and hardware. This project takes real-time graphics as a challenge application and derives a full system, called Copernicus, for future real-time graphics that can provide significantly higher image<br\/>qualities. The project will also integrate these quantitative models in the curriculum and disseminate to the research community.<br\/><br\/>The innovations proposed in this research have the potential for significantly aiding microprocessor and application development for future systems. The development of a full system specification for ray-tracing can trigger an inflection in the evolution of both programmable processors and<br\/>specialized graphics processors.","title":"SHF: Small: Multi-Core Architecture, Applications, and Tools Co-Design","awardID":"0917238","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["521594",410040],"PO":["366560"]},"148914":{"abstract":"Through Grid and Cloud computing, the importance of distributed computing has risen dramatically in recent years, increasing the computational power available to a widening audience of scientific and commercial users. Gains in computing power have caused a drastic increase in the volume of data produced by users, requiring new research on improved management and access to distributed data. These gains also drive the need for efficient scheduling and leasing of computational resources and for adapting current work in machine virtualization to a distributed context. These research directions require the development and evaluation of new models for computational, communication, and storage costs, but existing infrastructure makes model evaluation difficult or impossible, since they are in constant use by other researchers.<br\/>This project addresses these concerns by providing a diverse group of researchers with a Distributed Research Testbed (DiRT) on which to develop and evaluate new technologies. The clusters making up the testbed are located at the University of Chicago, the University of Florida, the University of Hawai?i, the University of Notre Dame, and the University of Mississippi. Unlike working grid environments, we have complete low-level control of the hardware and complete knowledge of where the data and computation are located. We will use the testbed to address problems faced today by the growing number of users of distributed computing. Because high performance computing is essential to the conduct of modern science, this project will have significant impact on research and education in a a wide variety of scientific disciplines.","title":"Collaborative Research: II-New: Distributed Research Testbed (DiRT)","awardID":"0855047","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["565244"],"PO":["564778"]},"157626":{"abstract":"0930643<br\/>Arrowsmith<br\/><br\/>This collaborative grant to the Arizona State University and San Diego Supercomputer Center (PI: Baru\/EAR-0930731) will support a three year Facility project to further develop and scale up the OpenTopography Portal (http:\/\/www.opentopography.org) for provision of high-performance, internet-based access to large volumes of high-resolution airborne and ground-based LIDAR topographic data sets and generation of derived data products. The proof-of-concept OpenTopography Portal (OpenTopo) was developed through NSF\/Information Technology Research and EAR\/Geoinformatics support to the San Diego Supercomputer Center as part of the GEON Project. That portal currently hosts and distributes a limited number of data sets acquired through the NSF\/EAR supported National Center for Airborne Laser Swath Mapping (NCALM) at the University of Florida and from USGS and NASA-funded research. This support will enable significant upgrades and assimilation of large volumes of extant and future LIDAR data through: 1) provision of internet-based access to LIDAR topography data in multiple formats, including ?raw? point cloud data, standard LIDAR-derived DEMs, and easily accessible Google Earth products; and 2) development of additional collaborations with existing LIDAR topography data providers and hosts (e.g., NCALM, USGS, regional consortia, states, etc.) to link to their data archives and\/or to host and distribute their data and processing software algorithms through a freely accessible web-interface. High-resolution digital elevation models derived from LIDAR (Light Distance And Ranging) methods (both airborne and ground-based) have been revolutionary for Earth science, environmental, and engineering applications. These data are among the most powerful tools available for study of the bare Earth surface, vegetative cover, and civil structures. Capable of generating digital elevation models (DEMs) more than an order of magnitude better resolved than those currently available from digitized USGS topo maps or from Shuttle Radar Topography Mission products, airborne LIDAR (or airborne laser swath mapping - ALSM) provides the ability to acquire meter-scale resolution, decimeter accuracy elevation data sets over large areas at relatively low expense. Ground-based or terrestrial laser scanners (TLS) offers even finer resolution mapping for specific targets. These data enable research on surface processes at fine scales and extents not previously possible yet essential for understanding processes (e.g., erosion, hillslope creep) at the scales at which they operate. OpenTopo will address the challenge of making massive LIDAR data sets and products readily accessible to end users through a freely accessible web-portal.","title":"Facility Support: OpenTopography - A National Hub for High Resolution Topographic Data, Tools, and Knowledge","awardID":"0930643","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0603","name":"Division of EARTH SCIENCES","abbr":"EAR"},"pgm":{"id":"1580","name":"INSTRUMENTATION & FACILITIES"}}],"PIcoPI":["528336"],"PO":["563319"]},"154117":{"abstract":"Recent research in computer graphics has shown that the classical topological graph theory provides a solid mathematical foundation and powerful tool for the development of 3D modeling systems. Despite its initial success, there is still a significant gap between the theoretical research in topological graph theory and its direct applications in computer graphics. In particular, the research in classical topological graph theory has largely neglected geometric issues. Moreover, very recent research has shown exciting connections between graph embeddings on non-orientable surfaces and surface weaving, and demonstrated a need for a refined and extended study in this direction. <br\/>This proposed research, guided by its applications in computer graphics, will refine and extend the classical topological graph theory in the following two directions: <br\/>1. Graph embeddings on orientable surfaces with geometric constraints: This project will re-examine the fundamental issues studied in graph embeddings on orientable surfaces that are related to topologically robust 3D modeling, by considering geometric constraints such as symmetry, planarity and conical properties. Applications of this research include development of topologically robust and highly interactive graphics modeling systems.<br\/>2. Graph embeddings on non-orientable surfaces and their applications in modeling surface weaving: This project will refine and extend the study on graph embeddings on non-orientable surfaces and the corresponding graph surgery operations, study their relations to 3D modeling, and build a new paradigm of modeling surface weaving. Applications of this research include creating beautiful shapes such as woven basket and topological sculptures.","title":"AF: Small: Topological Graph Theory Revisited: With Applications in Computer Graphics","awardID":"0917288","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":[410068,"527807"],"PO":["565157"]},"154007":{"abstract":"The dramatic increase in throughput demands on transport systems has propelled the development of all-optical networks. These networks can provide tremendous capacity when they are designed with their own limitations in mind, such as coarse wavelength granularity and physical impairments. In this research we consider the holistic design of optical networks that include the interdependence of three network layers: the traffic grooming layer, the lightpath management layer, and the physical fiber layer.<br\/><br\/>The network is first viewed from the top-down, where sub-wavelength circuit requests arrive with specific quality of service requirements. Current traffic grooming approaches are altered to incorporate their dependence on the lightpath management and physical layer constraints.<br\/>The system is then examined from the bottom-up, so that the quality of transmission and efficiency of resource utilization can be optimized as the higher layer protocols evolve. Total capacity is measured from an information theoretic view point and system optimization uses ideas from game theory. <br\/><br\/>The results of the research will be practical algorithms for improved capacity and survivability of future optical networks as well as providing a quantitative proof of their superiority. The enhancement of network capability will help satisfy our society?s ever-increasing need for information. It encourages the development of applications that require significant bandwidth. It also stimulates cross-fertilization of ideas from the two fields of networking and communications. The algorithms and software will be made publicly available via a web-site. The research enhances the education of the diverse group of graduate and undergraduate students participating in it.","title":"NeTS: Small: Collaborative Research: Holistic and Integrated Design of Layered Optical Networks","awardID":"0916890","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["523508"],"PO":["564993"]},"154128":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project addresses the complex networking challenge presented by the emerging cloud computing model. Cloud providers must run a diverse set of client applications, each with potentially different networking demands, on shared data-center facilities. Traditionally, a datacenter network is configured to use the same routing process to choose the \"best\" route for each flow in a datacenter, regardless of the application. For example, Ethernet frequently performs shortest-path routing along a single spanning tree. Yet data center networks typically exhibit significant redundancy; routing along a single tree leaves many paths unused, sacrificing potential gains in reliability, isolation and performance.<br\/><br\/><br\/>Topology switching moves beyond this one-size-fits-all approach providing an architecture for fine-grained multi-topology networking. It allows applications to create custom routing systems within a data center; they can configure multiple logical topologies that, together, are tailored to their reliability and performance requirements. From a cloud provider's perspective, a topology-switched network increases efficiency by multiplexing potentially hundreds of topologies across the same shared physical network. The PIs are designing a scalable topology-switched routing platform that facilitates the exploration of application interfaces, management challenges, novel routing strategies, and performance benefits of this approach.<br\/><br\/><br\/>Ultimately, the project aims to develop a flexible topology management primitive that improves administrators' ability to effectively manage extremely large datacenter deployments. The research is also analyzing the benefits and costs of multi-topology networking. Additional outcomes of this proposal include a public release of the topology switching platform, enabling academic and industrial feedback and adoption.","title":"NeTS: Small: Topology Switching for Data Centers and the Clouds Above","awardID":"0917339","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548363","518658"],"PO":["565303"]},"158737":{"abstract":"Finding and labeling semantic patterns in large, spatial data sets is one of the most important problems facing computer scientists today. Massive spatial data sets are being acquired in almost every scientific discipline, such as medicine, geology, biology, astrophysics, and others. Finding meaningful patterns in those data is often the bottleneck to scientific discovery. The proposed research is to develop a transformative machine learning methodology, where the process of discovering semantic patterns in large spatial data sets is interactive and semi-autonomous. With the proposed tools and algorithms, the user is provided with an interactive system that shows the most likely segmentations and labelings given the information provided so far, but allows the user to provide additional information as he\/she sees fit. The user might adjust a segmentation, provide a label, or specify an expected pattern. The system will adapt in real time to each of these inputs, thus adjusting its predictions throughout the data. <br\/><br\/><br\/><br\/>The broad impact of the proposed plan will be enhanced through an integrated educational and outreach plan. Besides the published results of research results, the field will benefit from free distribution of research and education resources, including web pages, bibliographies, software, and data sets, including augmentations to WordNet. Further broad impacts include focused workshops and courses on shape analysis, machine learning, and visualization at both the university and professional levels. Finally, diversity enhancement programs will promote the opportunities for disadvantaged groups in research.","title":"Interactive Discovery and Semantic Labeling of Patterns in Spatial Data","awardID":"0937139","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}}],"PIcoPI":["531640","533355",424207,"511536"],"PO":["562984"]},"158979":{"abstract":"The College Board proposes to create a new Advanced Placement (AP) course - AP Computer Science: Principles - that will focus on the principles and practices of computing, preparing more students for a competitive 21st century workforce. The new course will be consistent with the 2002 National Research Council recommendation that AP courses \"reflect what we know about how students learn; build students' transferable, conceptual understanding and inquiry skills; and convey the content and unifying concepts of a discipline.\" The course will be engaging, accessible, inspiring, and rigorous. It is intended to foster a wider appeal for the CS discipline and better prepare STEM majors. The College Board's meticulous AP course development process, already proven and thoroughly vetted in the NSF-funded redesign of several other AP science courses, will provide the framework for developing the new course's curriculum. Specific deliverables of the proposal will be: 1) the AP CS Principles course; 2) the design of course pilots in both secondary and post-secondary settings; 3) implementation of the pilots and curriculum evaluations; and 4) a suite of computer-based, prototype assessment items.","title":"Using Computational Thinking to Model a New Course: Advanced Placement Computer Science: Principles","awardID":"0938336","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["531300","531309","531302"],"PO":["561855"]},"148947":{"abstract":"In response to a strong demand from its users, the PLT infrastructure project aims to equip the PLT Scheme software infrastructure with four key components. Objective one is to reduce the running time of PLT Scheme object code; the PIs intend to accomplish this with the addition of a just- in-time compiler. The second objective calls for an enhanced ability to embed foreign code into PLT Scheme and vice versa; the plan calls for the implementation of a dynamic foreign function interface that allows programmers to develop and embed C code in an incremental manner. The project's third objective is to integrate a web repository for software libraries directly into the programming language. Objective four is to assist educational users (middle schools, high schools, colleges, and some graduate courses) with additional teaching libraries; to this end, the PIs are designing a framework for plugging special-purpose functional languages into the PLT Scheme framework.","title":"CI-ADDO-EN: Infrastructure for the Production of Languages","awardID":"0855140","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["475166"],"PO":["564388"]},"154029":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Computer systems such as personal computers and embedded systems are increasingly pervasive. People's everyday lives depend on these systems. Therefore, they must be high-confidence. To boost system performance, hardware and software are often closely coupled for optimizations. As a result, separate verification of software and hardware cannot guarantee the correctness of the entire system; thus hardware\/software (HW\/SW) co-verification, verifying the hardware and software together, is highly desired. There are four major benefits from co-verification: (1) advocating design-level HW\/SW interface specifications, (2) facilitating early hardware and software verification in the system context, (3) reducing verification complexity by properly leveraging HW\/SW couplings, and (4) broadening property coverage to the entire system. <br\/><br\/>This project develops an automata-theoretic approach to HW\/SW co-verification. Major research tasks include: (1) developing a co-specification scheme for hardware and software, (2) developing an automata-theoretic model for co-verification and its model checking algorithms, (3) developing abstraction\/refinement algorithms for co-verification, (4) developing a co-verification toolkit supporting this approach, and (5) evaluating this approach and the toolkit on device-driver co-verification. <br\/><br\/>Education and outreach efforts include (1) collaborating with industrial partners on device-driver co-verification, (2) creating video demonstration of this research and make it available online for education and research purposes, (3) integrating research activities and results of this project into a three course software engineering sequence, (4) advising and mentor undergraduate and graduate students to conduct research in this project, and (5) broadening participation through outreach efforts.","title":"CSR: SHF: Small: Automata-Theorectic Approach to Hardware\/Software Co-Verification","awardID":"0916968","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559275"],"PO":["565255"]},"146417":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Internet-connected computer systems face ongoing software attacks. Existing defensive solutions, such as intrusion detection systems, rely on the ability to identify malicious software (malware) in order to prevent its installation. This approach remains imperfect, resulting in widespread, persistent malware infections, malicious execution, and transmission of undesirable Internet traffic. This project develops solutions that help computer systems automatically recover from unknown malicious software infections by identifying and disabling the software. It departs from previous malware analysis because it employs strict post-infection analysis matching real-world environments: it assumes that security monitoring does not exist during the critical malware installation time and develops hypotheses of the malware's design and system alterations given only observations of the infected system's execution. It designs on-line forensic analysis techniques that hoist an infected system into a virtual machine for runtime execution monitoring. <br\/><br\/>This project investigates three primary areas: (1) Analysis and interpretation of unknown malicious software behavior when no clean reference system is available for comparison. (2) Correlation of undesirable network activity with malicious software components responsible for that activity. Attack recovery, or remediation, reclaims the infected system for legitimate use by disabling these components. (3) Inference of unobserved malicious software installation steps, enabling protection against reinfection. This project offers hands-on student training in binary code analysis, appropriate responses to successful attack, and the role of virtual machines in secure system design. By helping users and organizations recover from widespread infections, it offers practical value to system and network operators.","title":"CAREER: Local Remediation of Global Internet Epidemics","awardID":"0845309","effectiveDate":"2009-09-01","expirationDate":"2012-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["409253"],"PO":["497499"]},"146109":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>CAREER: Securing Channel Access in Multi-Channel Ad Hoc Networks<br\/>Proposal ID: 0844111<br\/>PI?s Name: Loukas Lazos<br\/>University of Arizona<br\/>Award Abstract<br\/><br\/>An increasing number of mobile users rely on wireless technologies to gain secure and uninterrupted access to network services. As the volume of data disseminated via the wireless medium rapidly expands, provision of performance, reliability, and security become challenging problems. These problems can be alleviated by the use of multiple orthogonal frequency bands (channels) that has been demonstrated to substantially reduce contention and interference. However, for systems with poor physical security and lack of centralized resource allocation such as ad hoc, sensor, and cognitive radio networks, a multitude of internal and external attacks against the medium channel access mechanisms can negate any gains due to channelization. <br\/>Most previous adversary models and protection methods are limited to single-channel networks thus ignoring the additional vulnerabilities and complexities of channelization. This project aims to advance our understanding regarding the feasible space of attacks against channel access. We design secure multi-channel access techniques, focusing on the protection of control traffic, collaborative attack detection, and uncoordinated medium sharing. Moreover, for networks with dynamic spectrum such as cognitive radio networks, we develop verifiable channel sensing methods. Central to this effort is our definition of quantitative security metrics under well defined adversarial models. Conducted research is expected to enforce wireless networks with the very much needed guarantees in security and performance.<br\/>In the educational domain, this project seeks to expose undergraduate and graduate students to fundamental problems from interdisciplinary fields in computer engineering, information science, and mathematics.","title":"CAREER: Securing Channel Access in Multi-Channel Ad Hoc Networks","awardID":"0844111","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["561905"],"PO":["497499"]},"150971":{"abstract":"TC: Medium: Collaborative Research: Novel Forensic Analysis for Crimes Involving Mobile Systems<br\/><br\/>Abstract:<br\/><br\/>Our project will significantly advance forensic methods of investigating mobile devices used for trafficking in digital contraband. While current methods and legislation focus heavily on logical identifiers, we will design, evaluate, and deploy new forensic techniques that focus on consistent and trackable characteristics of mobile computing. Additionally, our work will play an important role in understanding the limits of personal privacy in these settings. <br\/><br\/>We will develop new radio fingerprinting techniques that detect identifying information present in a radio's low-level components. We seek the comprehensive understanding available from an accurate model of these processes so that we can both determine the key causes of anonymity loss and investigate new countermeasures. <br\/><br\/>We will develop novel techniques of traffic analysis that determine the source of encrypted Web traffic. Our focus will be on real-world traffic scenarios, where background traffic is present and the entire Internet is a potential source.<br\/><br\/>We will empirically evaluate our methods in a real-world setting by using two large, outdoor and indoor wireless testbeds that we have deployed. <br\/><br\/>Our research will directly assist law enforcement that investigate network trafficking of images of child sexual exploitation, demonstrating the usability of trustworthy computing. We will disseminate our results to the Internet Crimes Against Children Task Force and the Massachusetts State Police. Additionally, this project will define research pathways to allow students who complete their BS and MS degrees at John Jay (a minority-serving institution) to continue their PhD work at UMass Amherst.","title":"TC: Medium: Collaborative Research: Novel Forensic Analysis for Crimes Involving Mobile Systems","awardID":"0905349","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["451830","545656"],"PO":["565136"]},"160651":{"abstract":"This project will combine design principles and technology advancements to enable the deployment and evaluation of new interface paradigms for managing continuities between hyperlinked 3D virtual workspaces and for managing user orientation with respect to 2D and 3D information resources within virtual workspaces. <br\/><br\/>Having built the open source 3D collaboration system (Open Cobalt) as a means of enabling the deployment of hyperlinked virtual workspaces, the research group will leverage the modularity and flexibility of Open Cobalt's graphical user interface (GUI) framework to explore optimal user interface approaches for: (1) defining optimal affordances for virtual workspace authors and end-users to manage the configuration and functionality of 3D portals (links) within hypermedia-enabled virtual workspaces, and (2) managing the perceptual relationships among 2D and 3D components displayed within virtual workspaces, which include multiple interacting avatars and aggregated 2D and 3D content. The research will assess the effectiveness of multiple GUI approaches in each of these areas in the context of two exemplar implementations involving scientific collaboration and education. <br\/><br\/>This work will provide key insights into optimal GUI approaches for managing content and connectivity within virtual workspaces. It will also: (1) further advance usability within a software infrastructure designed to support the cost-effective, large-scale deployment of interconnected and deeply capable virtual workspaces, (2) advance a common and extensible software framework supporting synchronized communication and collaboration among large numbers of people across distributed and hyperlinked virtual workspace contexts, and (3) provide open source software products that can serve as the basis for future research experimentation. <br\/><br\/>This project has great potential in advancing an effective 3D GUI for managing virtual place and space so that people are better able to manage access to social and informational resources within hyperlinked virtual workspaces. This will have direct impact on the efficacy of using virtual workspaces in support of education, research, business, social interaction, and entertainment. The resulting functionality of Open Cobalt will; (1) provide a highly capable open source platform in support of further research on virtual worlds; (2) further advance a powerful medium for enabling scientific outreach and education; and (3) serve as a powerful 'force multiplier' that by supporting an interlinked network of multi-user virtual world spaces, can leverage individual and recombined intellectual communities across the nation and beyond.","title":"EAGER: Intelligent Interfaces for Managing User Experience in Hypermedia-Enabled Virtual Workspaces","awardID":"0947483","effectiveDate":"2009-09-01","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[429609],"PO":["564456"]},"150993":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>The nature of telecommunications networks is rapidly changing. Commodity smart mobile phone frameworks such as Android and Openmoko invite developers and end users to build applications, modify the behavior of the phone, and use network services in novel ways. However, while simultaneously spurring incredible innovation, the move to open systems alters the underlying performance and security assumptions upon which the network was designed. Such changes invite vulnerabilities ranging from merely vexing phone glitches to catastrophic network failures. The current infrastructure lacks the basic protections needed to protect an increasingly open network, and it is unclear what new stresses and threats open systems and services will introduce.<br\/><br\/>This research analytically and experimentally investigates defensive infrastructure addressing vulnerabilities in open cellular operating systems and telecommunications networks. In this, we are exploring the requirements and design of such defenses in three coordinated efforts; a) extending and applying formal policy models for telecommunication systems, and provide tools for phone manufacturer, provider, developer, and end-user policy compliance verification, b) building a security-conscious distribution of the open-source Android operating system, and c) explore the needs and designs of overload controls in telecommunications networks needed to absorb changes in mobile phone behavior, traffic models, and the diversity of communication end- points.<br\/><br\/>This research symbiotically supports educational goals at the constituent institutions by supporting graduate and undergraduate student research, and is integral to the security and network curricula. This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).","title":"Collaborative Proposal: Security Services in Open Telecommunications Networks","awardID":"0905406","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["518545"],"PO":["565327"]},"150762":{"abstract":"Computing substrates such as multi-core processors or Field Programmable Gate Arrays (FPGAs) share the characteristic of having two-dimensional arrays of processing elements interconnected by a routing fabric. At one end of the spectrum, FPGAs have single-output programmable logic functions, and at the other end, multi-core chips have complex 32\/64-bit processing cores. For different applications, different programmable substrates produce the best area-power-performance tradeoffs. This project is developing a large-scale multi-core substrate that has hundreds or thousands of simple processing cores along with a compilation system that maps computations onto this fabric. This many-core architecture, named Diastolic Array, is coarser-grained than FPGAs but &#64257;ner-grained than conventional multi-cores. To efficiently exploit such a large number of processing cores, the architecture needs spatially mapping a computation to processing cores and communication to the point-to-point interconnect network. To be practically viable, this mapping process must be automated and effective. The project addresses this challenge by simultaneously developing hardware architecture and a compilation system.<br\/><br\/><br\/>A diastolic array chip is expected to outperform FPGAs or general-purpose processors on an interesting class of applications, enabling more efficient prototyping and low-volume production. The outcomes of this project such as statically-con&#64257;gured interconnection architecture with associated algorithms for routing and resource allocation will also be applicable to other multi-core designs. Finally, the project is developing a new parallel processing module for an undergraduate computer architecture class to give sophomores early exposure to parallel hardware, experience with writing parallel programs and using compilers that exploit parallelism.","title":"SHF: Medium: Collaborative Research: Throughput-Driven Multi-Core Architecture and a Compilation System","awardID":"0904598","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["561979"],"PO":["562984"]},"160453":{"abstract":"As more compute, memory, and storage resources continue to be integrated within multicore chips and multiprocessor systems built from multicores, significant advancements in the interconnect architecture that enable efficient connectivity and sharing among multiple heterogeneous system resources (including caches) across multiple hierarchy levels are needed. Escalating energy and reliability problems with nanometer technology scaling are making over-provisioning and static allocation of resources less viable for meeting increasing performance demands. This exploratory research investigates new and innovative on-chip network designs and network-driven shared resource management techniques that have the broader impact of laying important groundwork for realizing adaptive, fault-resilient, low-cost, energy- and performance-efficient multicore parallel computing systems with hundreds to thousnads of nodes.","title":"EAGER: Network-Driven Shared Resource Design and Management in Multicores","awardID":"0946388","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["325495"],"PO":["366560"]},"153930":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Online social networks (OSNs) have become central to the lives of millions of people worldwide. Unfortunately, existing OSNs cede responsibility for user data to a single administrative entity, and are inherently prone to violations of users&#700; privacy. This sensitive user data creates an attractive target for hackers and can be abused by internal administrators. This work argues that more decentralized alternatives to the dominant OSN architecture can provide a better balance between features and privacy. By endowing OSN participants with full ownership and control of their personal data, including control over which machines are allowed to store information and who is allowed to access it, decentralized OSN architectures have the potential to reduce the risk of a large-scale privacy breach while providing OSN features, efficiency, and availability that are competitive with more centralized schemes. <br\/><br\/><br\/>The work will provide insights into the fundamental tension between privacy and features in OSN-service architectures. Implementation and evaluation of methods based on these insights will lead to greater understanding of the features, efficiency, and availability that decentralized OSN architectures can support. The work will enable scientific inquiry into a wide range of social phenomena through the development of privacy-preserving methods and infrastructure for collecting location data. The work will also strengthen ties between computer science and on-campus initiatives for integrating undergraduate education and research through the Duke SmartHome.","title":"NetSE: Small: Privacy-preserving Architectures for Social Networking Services","awardID":"0916649","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["451799"],"PO":["564456"]},"162400":{"abstract":"Recent developments in augmenting appearance-based approaches to object recognition with shape have used local shape features in analogy to appearance features. However, past work on shape has shown that shape is much richer than a conglomerate of local features. Rather, shape is very high-dimensional and defies global embedding in a reasonably-dimensioned Euclidean space. Thus, Euclidean space concepts used in appearance-based recognition, such as formation of visual words from k-means, vocabulary trees, etc.<br\/>are no longer applicable. This project is developing analogous concepts for efficient indexing with a large number of categories in the context of a metric space for shape.<br\/><br\/>These concepts are being investigated in the context of an integrated bottom-up and top-down object recognition and segmentation framework. First, a top-down approach using a novel language for shape has already exceeded the state of the art in the ETHZ dataset. However, the prototypical shapes are manually selected. <br\/><br\/>The project aims to use the concept of structural averaging to automatically form prototypical shapes. Second, a fragment-based bottom-up approach has shown state of the art performance for a one-category Weizmann Horse database. An extension to the use of more categories requires an organization of the object space and the space of object fragments. The project aims to capture the metric structure of both spaces using a proximity graph, which is then used for efficient indexing. These two developments will together enable an integrated approach where bottom-up methods narrow a selection of categories which are then examined by the top-down approach.<br\/><br\/>Broader impacts include aerial tracking and recognition of vehicles for defense applications, segmentation of X-ray fluoroscopic images of the spine, and indexing into databases, e.g., trademarks.","title":"EAGER: A Metric Space Embedding of Object Fragments and Object Categories for Object Recognition and Segmentation","awardID":"0957045","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550631"],"PO":["564316"]},"153820":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Wireless sensor networks have been applied to many military and commercial applications. However, the sensor network envisioned so far is targeted for a single mission and often designed for some particular application. As sensors become widely deployed, multiple missions, each with different requirements, may share common sensors to achieve their goals. Each mission may have its own requirements for the type of data being reported, the sampling rate, accuracy, and location of the sampling. From resource management point of view, it will be cost effective for sensor networks to support multiple missions instead of a single mission. The specific goal of this project is to support multi-missions in wireless sensor networks. <br\/><br\/>The project addresses four intertwined issues: (i) various mission-driven scheduling protocols which can optimize the sensor coverage will be designed, implemented, and evaluated; (ii) novel techniques will be developed to disseminate the mission switch code\/command to the affected sensor nodes quickly and efficiently; (iii) mission-driven sensor assignment schemes will be designed to maximize the network utility; (iv) mission-specific network configurations will be investigated to meet the real-time requirements of data transfer for dynamic and competing missions. This project will make significant theoretical advances in understanding and designing multi-mission oriented sensor networks, and will develop comprehensive protocols to support multi-missions in sensor networks. The success of this project is likely to have a broader impact on making wireless sensor networks more affordable and amenable to commercial, civilian, and military applications. The results of the project will be disseminated widely through high quality publications and presentations. The proposed research will also be integrated with the education curricula at Penn State University.","title":"NeTS:Small:Supporting Multi-Missions in Wireless Sensor Networks","awardID":"0916171","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518380","550785"],"PO":["565303"]},"153941":{"abstract":"As semiconductor technologies scale continues to shrink, building fault-tolerant, defect-free microprocessors becomes increasingly difficult. Tighter design constraints, lower operating voltages, and increasing power densities have lead to circuits that are more susceptible to manufacturing defects, transient faults, and wearout-related failures. It is anticipated that future designs will consist of 100 billion transistors, many of which will be unusable due to manufacturing defects and many will fail over time due to wearout and other errors. Traditional mainframes and mission-critical systems rely on redundancy to overcome such failures. Reliability is essentially viewed as a tax that is levied in the form of additional silicon area devoted to constant double and triple checking of results that end-users must pay to ensure correct operation. As reliability concerns invade the desktop and cellphone environments, large scale redundancy is impractical due to the high cost and energy overheads. <br\/><br\/>This research proposes StageNet, a new style of microprocessor architecture in which reliability is not a tax, but rather built in to the natural operation of the system. StageNet is both introspective to enable continuous monitoring and adaptation to reliability hazards and reconfigurable at a fine-grain level to minimize the lifetime performance impact that individual failures have on the system. StageNet consists of three major components: an adaptive computing substrate that enables dynamic reorganization of individual microprocessors, armored cache designs to provide high defect tolerance with low area overhead for on-chip caches, and a dynamic adaptation system to manage the execution of applications and organization of the hardware over its lifetime. The broader impact of this research is that it creates cost-effective ways of dealing with faulty transistors that will enable the proliferation of embedded computers into more aspects of life, where robustness and reliability are current barriers.","title":"SHF: Small: An Adaptive Architecture Fabric for Constructing Resilient Multicore Systems","awardID":"0916689","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["518034"],"PO":["366560"]},"153710":{"abstract":"Given the diverse and complex nature of computer security, a natural response of the academic and industrial community has been to study how one can create technical solutions to the problem. Although the technical solutions to various problems can be quite effective, the underlying premise of many of the solutions is predicated upon an informed awareness of the user of the importance of avoiding risky behavior. While there has been considerable rigor undertaken with regards to the evaluation of the efficacy of the various technical approaches, the human aspect of computer security has received relatively minor attention with largely cursory \/ anecdotal evaluation. <br\/>The unfortunate result of this lack of rigorous scientific data is the use of under-funded and ad hoc awareness security awareness initiatives that offer limited benefit to the security of the enterprise. This work will leverage the unique aspects of the university-environment to conduct a multi-scale (time, observation group, data granularity) formal set of experiments regarding the efficacy of security awareness techniques. Moreover, the inter-disciplinary effort will bring to bear the application of formal experiments to explore the usage of negative, positive, and targeted communication interventions drawn from theoretical considerations of existing criminology, psychology, and information system literature.<br\/><br\/>Stated in an alternative manner, organizations dedicate significant financial and human resources to information security awareness programs designed to raise user knowledge about safe computing practices and information security risks. Unfortunately, despite the fact that many organizations are expending significant resources on awareness, organizations have little if any guidance or scientific evidence to construct effective strategies. Should strategies focus on positive or negative strategies? Are post cards or hallway posters or training classes more effective? Are awareness campaign effects temporary or long term? The focus of this work will be to provide that rigorous scientific basis by exploring how effective awareness techniques are in the ?wild? <br\/>of the university environment, unimpeded by normal network security controls. A key broader impact of the work will be the creation of basic guidelines for the construction of security awareness programs. The net result will be dramatically improved cost efficiency of security awareness techniques and hence, significant improvement in the national cyber-security infrastructure.","title":"TC:Small: A Formal Inter-Disciplinary Study of the Impact of Security Awareness Efforts on User Behavior","awardID":"0915775","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486414","540626",409053],"PO":["564456"]},"153952":{"abstract":"The goal of the AquaSWARM project is to design and develop small, energy-efficient, autonomous underwater robots as sensor-rich platforms for dynamic, long-duration monitoring of aquatic environments. A novel concept of gliding robotic fish is investigated, which merges the energy-efficient design of underwater glider with the high maneuverability of robotic fish. Gliding motion, enabled by pitch and buoyancy control, is exploited to realize dive\/ascent and large-distance horizontal travel. Soft actuation materials-based flexible tail fins are used to achieve maneuvers with high hydrodynamic efficiency. The research is focused on understanding gliding design for small robotic fish, and addressing the energy efficiency issue from a systems perspective. Schools of such autonomous robots are deployed in lakes at the Michigan State University Kellogg Biological Station to detect harmful algal blooms (HABs) and validate models for HAB dynamics. <br\/><br\/>The project is expected to result in cost-effective, underwater robots that can perform uninterrupted, long-duration (several months), long-travel (hundreds of miles) operation in aquatic environments. This will provide a novel, viable, versatile, cyber-physical infrastructure for aquatic environmental monitoring, with applications ranging from understanding the impact of global warming, to environmental protection, drinking water reservoir safety, and seaport security. The project also offers an interdisciplinary training environment for graduate and undergraduate students, and provides outreach opportunities to inspire pre-college students and train highly qualified teachers. Robotic fish-based HAB detection will also be used as a tool to engage communities at local lakes and stimulate their interest in novel technology and environmental issues.","title":"RI: Small: AquaSWARM: Small Wireless Autonomous Robots for Monitoring of Aquatic Environments","awardID":"0916720","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["554510","560245"],"PO":["564069"]},"162301":{"abstract":"This proposal requests funds for a \"Million Book Project\" partners research and coordination meeting to be held on November 6-9, 2009, at Carnegie Mellon University in Pittsburgh, Pennsylvania.. The Million Book Project was begun in 2000, aiming to be the most ambitious mass digitization project ever undertaken. The initial goal was to digitize and provide free-to-read access to one million books by 2007. Today the Million Book Project, the Google Book Search Project and others continue to bring new materials to the web. It is estimated that about 10 million books are now available on the web through these different projects. Vast and increasing amounts of physical textual content previously constrained in use due to location and access issues is now available to all via the internet worldwide. To date the Project has scanned over 1.5 million books in China, India and Egypt. In the process it continues add knowledge, stimulate new research in areas of large-scale, multi-lingual database storage, retrieval and presentation of results. This meeting will continue and renew the those processes of communication, planning, interaction and coordination necessary to ensure international collaborationKey topics to be explored include machine translation and summarization, intellectual property and rights management issues, improving and providing centralized access to the metadata, usability issues, growing the collection, diversity, dissemination, education and others.","title":"Million Book Project Partners Meeting: Supplemental Grant","awardID":"0956574","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["461693"],"PO":[433760]},"150443":{"abstract":"The objective of this research is to develop a new class of on-chip power electronics circuits that will enable highly granular, active power management for future multicore processors, allowing energy-delay trade-offs to be performed in the presence of workload variability. The approach is based on the introduction of magnetic materials as a \"post-process\" on a standard CMOS run. <br\/><br\/>Intellectual Merit. Current implementations employ off-chip, board-level voltage regulation and bring in independent supply voltages from off-chip. Such approaches are not scalable and require that power be delivered to the chip at highly scaled voltage levels, leading to unsustainable current demands. We specifically address how passive magnetic devices can dramatically improve the design of on-chip power management and delivery circuits by providing for high density energy storage on-chip. We will innovate new magnetic devices (inductors and GMR sensors) that can be implemented on a conventional CMOS process. <br\/><br\/>Broader Impacts. This project will allow the PIs to train graduate and undergraduate students in a truly cross-disciplinary research environment combining physics, nanoscale materials, circuit design, and power electronics applications. This research effort will also feed a new course at Columbia on power electronics, with a special emphasis on integrated approaches, bridging the disconnect between the power electronics community and the traditional integrated circuit design community. Significant effort will be made for K-12 outreach by systematically training highly motivated high school students within the program and also enhancing the interaction with the local K-12 educators.","title":"On-chip magnetics for power management and delivery in multicore processors","awardID":"0903466","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["529662","541360"],"PO":["565185"]},"150685":{"abstract":"Last Modified Date: 05\/15\/09 Last Modified By: Tatiana D. Korelsky <br\/><br\/>Abstract <br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>The researchers are developing new theoretical models and technology to automatically convert descriptive text into 3D scenes representing the text?s meaning. They do this via the Scenario-Based Lexical Knowledge Resource (SBLR), a resource they are creating from existing sources (PropBank, WordNet, FrameNet) and from automated mining of Wikipedia and other un-annotated text. In addition to predicate-argument structure and semantic roles, the SBLR includes necessary roles, typical role fillers, contextual elements, and activity poses which enables analysis of input sentences at a deep level and assembly of appropriate elements from libraries of 3D objects to depict the fuller scene implied by a sentence. For example, ?Terry ate breakfast? does not tell us where (kitchen, dining room, restaurant) or what he ate (cereal, doughnut, or rice, umeboshi, and natto). These elements must be supplied from knowledge about typical role fillers appropriate for the information that is specified in the input. Note that the SBLR has a component that varies by cultural context. <br\/><br\/>Textually-generated 3D scenes will have a profound, paradigm-shifting effect in human computer interaction, giving people unskilled in graphical design the ability to directly express intentions and constraints in natural language -- bypassing standard low-level direct-manipulation techniques. This research will open up the world of 3D scene creation to a much larger group of people and a much wider set of applications. In particular, the research will target middle-school age students who need to improve their communicative skills, including those whose first language is not English or who have learning difficulties: a field study in a New York after-school program will test whether use of the system can improve literacy skills. The technology also has the potential for interesting a more diverse population in computer science at an early age, as interactions with K-12 teachers have indicated.","title":"RI: Medium: Collaborative Research:From Text to Pictures","awardID":"0904289","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["467639"],"PO":["565215"]},"153963":{"abstract":"Environment Protection Agency estimates that by 2011 data centers nationwide would consume electricity amounting to the equivalent output of about 30 power plants. Clearly, improving the power and thermal behavior of these systems has a direct impact on their energy efficiency and reliable operation. DRAM memories constitute a significant fraction of the power consumed in computers. In addition, in the dawning era of multi-\/many-core processors, the performance of a system is largely dependant on its main memory efficiency. This project investigates ways to operate DRAMs at full bandwidth utilization while spending the minimum power per unit of data communicated and maintaining lower operating temperatures. Specifically, this work aims at answering three fundamental questions: a) how can we enhance processor architectures to balance the activity on different DRAM chips to protect chips under thermal stress, b) how can we enhance the DRAM systems to reduce their power consumption and peak operating temperatures, and c) how can we enhance the operating systems to improve the thermal behavior of DRAM systems? <br\/><br\/><br\/>Techniques developed in this project will improve the thermal behavior of DRAM systems and hence will reduce the cost of thermal management and decrease the system energy consumption. Furthermore, these improvements will enable new generations of high-performance processors. This, in turn, will enhance the computational capabilities of future computing systems and enable progress in various fields. Finally, projects derived from this work will be integrated into courses contributing to the training of an engineering workforce for an energy-efficient and sustainable society.","title":"SHF: Small: Thermal-Aware High-Performance DRAM Architectures in Multicore Technologies","awardID":"0916746","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["518459",409687],"PO":["562984"]},"161223":{"abstract":"Computing has many potential 'green' applications including improving energy conservation, enhancing energy management, reducing carbon emissions, and improving environmental protection. The Computer Science and Telecommunications Board of the National Research Council will appoint an ad hoc study committee to plan and conduct a workshop involving approximately 40 experts that will explore research themes and specific research opportunities that could advance these energy and environmental objectives and also result in advances in computer science and consider research modalities, with a focus on applicable computational techniques and long-term research opportunities. In phase 2, a consensus report will be prepared that identifies promising research opportunities, catalogs applicable computational techniques, lays out an overall framework for 'green' computing research, and recommends long-term research objectives and directions.","title":"Computing Researech for Environmental and Societal Sustainability","awardID":"0950451","effectiveDate":"2009-09-15","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560890"],"PO":["565136"]},"171398":{"abstract":"Spectral Graph Theory or Algebraic Graph Theory, as it is also known,<br\/>is the study of the relationship between the eigenvalues and<br\/>eigenvectors of graphs and their combinatorial properties. Random<br\/>walks on graphs, expander graphs, clustering, and several other<br\/>combinatorial aspects of graphs are intimately connected to their<br\/>spectral properties. Recent approaches to the analysis of<br\/>high-dimensional data have exploited the fundamental eigenvectors of<br\/>the data. These data sets are large and ever increasing requiring<br\/>``real-time\" accurate responses to the given queries. This creates the<br\/>need for very fast algorithms, that also provide strict theoretical<br\/>guarantees on their output. Spectral techniques have been applied to image<br\/>processing, both by computers and in the primary visual cortex of<br\/>monkeys. Critical component to all these application is algorithms<br\/>with efficiency and accuracy guarantees for solving these linear system<br\/>and finding their fundamental eigenvectors.<br\/><br\/><br\/>A multidisciplinary team consisting of Theoretical Computer<br\/>Scientists, Machine Learning Scientist, and Neuroscientist will<br\/>develop and apply spectral graph theory to applications from data<br\/>mining to clustering, and image processing. Enabling technology<br\/>develop will include: 1) linear-work or O(m log m)-work algorithms<br\/>that run in poly-logarithmic parallel time for computing extreme<br\/>eigenvalues and generalized eigenvalues of diagonally-dominant<br\/>matrices, including Laplacian matrices, as well as algorithms of<br\/>similar complexity for solving the related linear systems. 2) Better<br\/>estimates for Fiedler values and generalized Fiedler values.<br\/>Application development: 1) Improvements in spectral image<br\/>segmentation. 2) The use of generalized eigenvalues in data mining and<br\/>image segmentation to combine multiple sources of information. 3) The<br\/>use of preconditioners for approximate inference in graphical models.<br\/>and 4) Combine insights into the problem of image segmentation gained<br\/>from spectral algorithms with knowledge gained from recent experiments in visual system<br\/>of monkeys to better understand how the primary visual cortex functions.","title":"Collaborative Research: Spectral Graph Theory and Its Applications","awardID":"1032367","effectiveDate":"2009-09-01","expirationDate":"2010-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":["483541"],"PO":["550329"]},"153732":{"abstract":"Although high-cost, data-intensive multi-camera systems have been widely used for mobile human tracking and recognition, the pyroelectric infrared (PIR) sensor has a variety of advantages including dramatically low costs, chemical stability, high sensitivity to human body thermal variation, and extremely low sensory data throughput.<br\/><br\/>This project implements an Intelligent Compressive Multi-Walker Recognition and Tracking (iSMART) testbed based on PIR Sensor Networks (PSN). The novelties of iSMART include three aspects: (1) Context-aware region-of-interest (RoI) exploration to achieve an inherent tradeoff between area of sensor coverage and degree of information acquisition resolution. This research uses strict mathematical models to measure RoI context. (2) Decentralized inference \/ learning for in-network intelligence. This project develops a belief-propagation-based distributed inference scheme with data-to-object association for continuous tracking and recognition of multiple walkers. It uses orthogonal-projection-based distributed learning for sensor calibration and feature model training. (3) Networked, compressive sampling structures and sensing protocols. This project extends the latest progress in compressive and multiplex sensing theories to guide the design of novel networked sensor receiver pattern geometries and decentralized sensing protocols.<br\/><br\/>The above research efforts will lead to a novel low-cost, high fidelity wireless distributed sensing system for multiple walker recognition and tracking. As an alternative to video camera systems, iSMART systems can be widely deployed to automatically monitor airports, customs \/ harbors, and other critical national infrastructures. This project will also generate interesting hands-on labs on intelligent sensor \/ sensor networks and class projects for both undergraduate and graduate students.","title":"RI: Small: Intelligent Compressive Multi-Walker Recognition and Tracking (iSMART) through Pyroelectric Sensor Networks","awardID":"0915862","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["513708","472051"],"PO":["564069"]},"153853":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Network matrices, such as traffic matrices, delay matrices, adjacency matrices, and social proximity matrices, are essential inputs to a wide range of network applications. Network matrices and the underlying network often exhibit a multi-faceted scaling behavior. To capture such multi-scale behavior, a particularly promising approach is Multi-Resolution Analysis (MRA), which creates multiple approximate representations of network matrix at different resolutions. This project will (i) develop a novel framework to enable network-centric MRA of network matrices, and (ii) use the framework to develop novel solutions to several network management tasks: missing value inference, design of experiments, traffic synthesis, and anomaly detection.<br\/><br\/>Intellectual Merit: The project is multi-disciplinary by nature and will foster effective synergy between networking, statistics, data mining, and scientific computing. The MRA framework and its applications will deepen the understanding of the spatial and temporal characteristics of network matrices at different scales, and advance the state of art in several significant network management tasks.<br\/><br\/>Broader Impact: The MRA framework is valuable to multiple scientific fields. The project is expected to produce publications in leading conferences and journals, and software that will be publicly available online. Through technology transfer, the network management solutions can potentially improve the operations of real ISP networks. The project will provide several graduate students' thesis research and honors undergraduate research projects. The research results will also be integrated into undergraduate and graduate curricula as well as outreach activities.","title":"NetSE: Small: Multi-Resolution Analysis of Network Matrices","awardID":"0916309","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["550986","266247","560223"],"PO":["564924"]},"153623":{"abstract":"Proposal Title: CSR:Small:Collaborative Research: Combining Static Analysis and<br\/>Dynamic Run-time Optimization for Parallel Discrete Event<br\/>Simulation in Many-Core Environments<br\/>Institution: SUNY at Binghamton<br\/>Abstract Date: 07\/06\/09<br\/>This project investigates how a new processor paradigm (multi-core architectures)<br\/>changes the way Parallel Discrete Event Simulation (PDES) is done. This topic is<br\/>important given the wide use of simulation and the emergence of multi-core<br\/>architectures. PDES is likely to play an increasingly important role in discrete event<br\/>simulation as Moore?s Law is sharply curtailed and explicit parallelism becomes the<br\/>major avenue for improving performance of sequential applications. Improving PDES<br\/>performance translates to improved.<br\/>Discrete Event Simulation (DES) is widely used for performance evaluation in many<br\/>application domains. The fine grained nature of PDES causes its performance and<br\/>scalability to be limited by communication latency. The emergence of multi-core<br\/>architectures and their expected evolution into manycore systems offers potential relief<br\/>to PDES and other fine grained parallel applications because the cost of communication<br\/>within a chip is dramatically lower than conventional networked communication. Absent<br\/>this dominant effect, PDES performance will be determined by issues such as load<br\/>balancing, synchronization and optimism control, and the choice and configuration of<br\/>various other algorithms and data structures of the simulator. Operation in a manycore<br\/>environment introduces new system tradeoffs that must be effectively balanced by the<br\/>system software. Primarily, the pressure on the memory system and resilience to load<br\/>fluctuations will emerge as critical issues that we address in the proposed research.<br\/>Finally, the more predictable nature of communication cost in this environment (due in<br\/>part to the more frequent synchronization possible between nearby cores) can be<br\/>exploited, especially by static analysis, for effective simulation.<br\/>As multi-cores become the default microprocessor architecture, applications that are<br\/>performance constrained must evolve to use parallelism to take advantage of the<br\/>resources available on the cores. This project?s new PDES can have a significant<br\/>impact on a number of applications that rely on discrete event simulations. The PIs plan<br\/>to incorporate the research results into a graduate level course on parallel simulation<br\/>techniques and to involve undergraduate students in the project.","title":"CSR: Small: Collaborative Research: Combining Static Analysis and Dynamic Run-time Optimization for Parallel Discrete Event Simulation in Many-Core Environments","awardID":"0915337","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[408839],"PO":["565255"]},"153744":{"abstract":"The research objective is the design and implementation of a new formal data model and type system called Spatial Algebra 3D (SPAL3D) for three-dimensional (3D) spatial data in database systems and geographical information systems. While these systems so far focus on two-dimensional spatial entities only, despite many potential geoscience applications, three-dimensional (3D) data modeling and data management have so far been rather neglected. This research and education project explores the fundamental properties and the structure of complex 3D spatial data from a data management and database perspective, identifies their most important operations and predicates, and supports their treatment in data modeling, representation, storing, manipulation, and querying. SPAL3D is extensible, makes it possible to add new types and operations, and can be plugged into different DBMS. The solution approach is based on three three fundamental pillars: (i) an abstract data model<br\/>(SPAL3D-A) for the rigorous, mathematical definition of a comprehensive type system (algebra) for 3D spatial data including volumes, surfaces, and 3D lines, (ii) a discrete data model (SPAL3D-D) for the design of effective geometric data structures for the 3D spatial data types of SPAL3D-A and on efficient geometric algorithms on these data structures for the 3D operations and predicates of SPAL3D-A, and (iii) the implementation and database integration (SPAL3D-I) of the data structures and algorithms of SPAL3D-D as abstract data types into several extensible DBMS data models and query languages.<br\/><br\/>The results of this research are expected to have broad impact on applications in areas where the third dimension of spatial data plays an important role. Examples are geographical information systems, meteorology, hurricane research, environmental monitoring, pollution control, soil science, water supply and distribution, fishery monitoring and simulating, geology, soil engineering and mining, earthquake modeling and simulation, to name only a few. The educational component of this project includes specialized classes that focus on important aspects of this project, the creation and use of new GIS educational materials, and the involvement of students in interdisciplinary research. The project Website<br\/>(http:\/\/www.cise.ufl.edu\/~mschneid\/Research\/FundedResearchProjects\/NSF-IIS-0915914\/spal3d)<br\/>is used for the dissemination of research results, educational material, publications, generated data sets, produced software, and other information of interest.","title":"III: Small: SPAL3D -- Design and Implementation of a Type System for Three-Dimensional Spatial Data in Databases","awardID":"0915914","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[409138],"PO":["563751"]},"153865":{"abstract":"Modern mobile platforms, such as the Google Android and Apple iPhone, are reinventing the mobile landscape by opening up third-party development and by providing sophisticated productivity, communication, and application suites. In addition, mobile devices are increasingly used to store sensitive personal information such as financial and medical data. Mobile environments face a wide range of unique security challenges. First, emerging mobile platforms have vastly different security and trust models. Second, techniques that worked for securing desktops do not transition well to mobile environments because mobile devices are highly resource constrained. Finally, mobile devices have inherently different usability patterns than traditional desktops that impact security.<br\/><br\/>This project explores a new model for mobile security based on moving the complexity of malware detection to an in-cloud security service rather than performing analysis locally on each mobile device. We will investigate in-cloud security services for mobile devices based on an architecture that consists of a lightweight agent that runs on mobile devices interposing on access of applications and data, and a network service that identifies malicious applications using parallel signature, behavioral, and reputation-based detection engines. Our approach is structured around three objectives: (1) functionality across a wide variety of mobile platforms and security models, (2) minimal on-device CPU, memory, and power resources, and (3) security that adapts to mobile usability patterns. We will work with our industry partners to facilitate the deployment of the techniques and methods developed through this effort on live operational networks.","title":"TC: Small: In-Cloud Security Services for Mobile Devices","awardID":"0916390","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553725","553725","464147"],"PO":["565327"]},"153986":{"abstract":"Problems related to requirements definitions account for numerous project failures and translate into significant amounts of wasted funds. In many cases, these problems originate from inadequacies in the human-intensive task of eliciting stakeholders' needs, and the subsequent problems of transforming them into a set of clearly articulated and prioritized requirements. These problems are particularly evident in very large projects such as the FBI Virtual Case File or NASA's Space Station, in which knowledge is dispersed across thousands of different stakeholders. On one hand, it is desirable to include as many people as possible in the elicitation and prioritization process, but on the other hand this can quickly lead to a rather chaotic overload of information and opinions. The work proposed under this grant will develop a new framework that utilizes data mining and recommender systems techniques to process and analyze high volumes of unstructured data in order to facilitate large-scale and broadly inclusive requirements processes. The proposal is based on the observation that the requirements elicitation process of many large-scaled industrial and governmental projects is inherently data-driven, and could therefore benefit from computer-supported tools based on data mining and user modeling techniques. <br\/><br\/>INTELLECTUAL MERIT <br\/>The proposed research will lead to a robust requirements elicitation framework and an associated library of tools which can be used to augment the functionality of wikis, forums, and specialized management tools used in the requirements domain. Specifically, this research will enhance requirements clustering techniques by incorporating prior knowledge and user-derived constraints. A contextualized recommender system will be designed to facilitate appropriate placement of stakeholders into requirements discussion forums generated in the clustering phase. <br\/><br\/>BROADER IMPACT <br\/>The proposed work has potential for broad impact across organizations that develop stakeholder-intensive systems. Technology transfer can be expected due to collaborations with organizations such as Siemens and Google planned as an integral part of this research. Educational materials will be developed specifically for requirements engineering and recommender systems courses, and will be broadly disseminated. <br\/><br\/>Key Words: Recommender systems; Data mining; Clustering; Requirements engineering; Requirements elicitation.","title":"III: Small:Using Data Mining and Recommender Systems to Facilitate Large-Scale Requirements Processes","awardID":"0916852","effectiveDate":"2009-09-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["525682","550521"],"PO":["565136"]},"152655":{"abstract":"Wireless sensor networks (WSNs) composed of smart sensors interconnected over wireless links are quickly becoming the technology of choice for monitoring and measuring geographically distributed physical, chemical, or biological phenomena in real time. Dynamic WSN environments encountered in environmental monitoring, surveillance, pollution control, and reconnaissance applications, require responsive management of WSN resources and their adaptive allocation to sensing, networking support, localization, and planning tasks, based on user requests and changes in the environment. A specified quality of service should however be ensured for criteria such as resolution of the raw-data, latency, network reconfiguration delay, and resource utilization in the steady-state. This project develops an integrated cross-layered approach to networking, databases, control, mobility management, and information processing in WSNs. In particular, context-aware and energy-efficient solutions are pursued that are based on opportunistic sensing and processing techniques, dynamic indexing structures, novel query language constructs, reactive mobility control algorithms, and distributed compression based routing algorithms.<br\/><br\/>The technological advances from this research will significantly simplify the deployment of WSNs and lead to novel context-aware applications. The advances will directly benefit domains such as emergency-response management, environmental threat remediation, and biological habitat monitoring. Apart from developing the required algorithms, the project will implement simulation platforms and a monitoring environment using physical devices. The platforms will provide students with new educational opportunities to actively explore information acquisition and resource management in resource-constrained environments. All project resources will be shared with the public through a project webpage.","title":"NeTS: Large:Collaborative Research: Context-Driven Management of Heterogeneous Sensor Networks","awardID":"0910988","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["532978",406717,406718,"460591",406720],"PO":["565303"]},"153997":{"abstract":"Cooperative coevolution is a potent approach to doing large-scale stochastic optimization. The unsolved game-theoretic challenges inherent in this computational method are complex and of significant interest to the evolutionary computation community. This project is advancing the state of the art in coevolution and is applying it to significantly larger problems than commonly found in the literature. These challenges, and their solution, have potentially transformative impact on other co-adaptive environments such as multiagent reinforcement learning, estimation of distribution algorithms, agent modeling, and swarm robotics. Coevolution has strong applicability to fields that use multiagent system models, including multirobotics, biology, economics, land use, and political science. Better models in these fields can positively affect society, policy, homeland security, and the environment.","title":"RI: Small: Cooperative Coevolutionary Design and Multiagent Systems","awardID":"0916870","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["549627"],"PO":["562760"]},"155702":{"abstract":"Proposal #: CNS 09-23031 <br\/>PI(s): An, Edgar Beaujean, Pierre-Philippe J.; Xiros, Nikolaos I.<br\/>Institution: Florida Atlantic University <br\/>Title: MRI\/Acq.: Two REMUS Autonomous Underwater Vehicles for Multiple Cooperative Marine Vehicle Research<br\/>Project Proposed:<br\/>This project, acquiring two REMUS 100 autonomous underwater vehicles (AUVs), addresses the research challenge of multiple cooperating vehicles systems (MCVS), which involves a fleet of AUVs and autonomous safety vehicles (ASVs). Since successful operation of any MCVD often rests upon efficient communication among the vehicles, the dynamic mission planning problem (including search and classify and mapping capabilities) is studied utilizing a fleet of heterogeneous AUVs and ASVs. This challenging problem, considering underwater acoustic communication, navigation, and sensing constraints, differs from those usually studied and reported in the underwater literature. The work is contrasted to unmanned aerial or ground vehicles in which communication and navigation capabilities are generally NOT considered significant bottlenecks. The project capitalizes on two previous NSF achievements:<br\/>- An underwater vehicle network simulatorsand<br\/>- A location aware source routing (LASR) protocol developed for multiple communicating AUVs subject<br\/> to realistic underwater communication constraints.<br\/>Nonlinear and stochastic variations with the environmental conditions and sensor characteristics are expected. Because a closed form solution for an optimal controller design is not anticipated, given that control performance tends to be cost-prohibitive, when completely via experimentation. Hence, given the wide range of mission and environmental scenarios and controller objectives, the problem will be studied combining modeling, simulation, and experimentation. Some of the simulated results will be validated by carrying out targeted at-sea field experiments using the instrumentation. Local cost definitions will be explored as a means to constrain individual vehicle?s maneuvering and cooperation. Attention is paid to maximizing the overall mission efficiency while minimizing the impact of uncertainty. Expectations include development of:<br\/>- An advanced event-base planning and control algorithms to improve robustness of communication and <br\/>navigation uncertainty, throughput, and bandwidth efficiency,<br\/>- An advanced multiple cooperating vehicle modeling software to support mission performance analysis, and <br\/>- A science base for multiple AUVs and undersea acoustic networks.<br\/><br\/>Broader Impacts: <br\/>The research problems constitute ideal topics for theses and dissertations. This multidisciplinary field will be integrated into the existing course curriculum, providing valuable theoretical and simulation knowledge to the students, as well as hands-on experiences. Using underwater robotics as a primary domain application, the existing effort, sustaining the teachers and students with interest in math and science, will be continued giving special consideration to female and underrepresented groups. Workshops, competitions, and summer classes are also planned to expose students the logistics of marine vehicles. The understanding gain is likely to provide insights to the U.S. Navy for missions using a fleet of autonomous underwater vehicles to better search and classify in homeland security missions.","title":"MRI: Acquisition of Two REMUS Autonomous Underwater Vehicles for Multiple Cooperative Marine Vehicle Research","awardID":"0923031","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["558924",414766,414767,"544956"],"PO":["557609"]},"153766":{"abstract":"Broadcast media underlying wireless networks enable diverse devices to communicate using shared channels, but also leave them severely exposed to adversaries. Our increased reliance on wireless networks for connectivity to the cyber-infrastructure, and for monitoring our physical infrastructure, has opened the door for sophisticated denial-of-service attacks with potentially devastating effects on our economy and homeland security.<br\/><br\/>This project pursues a new game-theoretic framework for agile and resilient wireless systems. The framework models the interaction between communicating nodes and adversaries as two-player games, with strategies defined by various protocol choices and cross-layer attacks. A central thesis of this game-theoretic paradigm is that resilient wireless systems need to be highly agile, rapidly mixing strategies to thwart adaptive attackers.<br\/><br\/>The research methodology underlying this project is threefold. The first component formulates games capturing complex interactions between communicating nodes and adversaries across basic building blocks of wireless systems. The second component concerns optimization problems and equilibria associated with these games. The final component realizes the architecture and solutions in two<br\/>real-world prototypes: a Linux-based platform for 802.11 networks, and a Software-Defined Radio platform for studying more sophisticated mechanisms.<br\/><br\/>This project addresses the critical need of protecting our wireless infrastructure from DoS attacks. The research conducted will lead to (a) new game-theoretic analysis of wireless systems quantifying vulnerabilities and worst-case scenarios, and identifying promising methods to thwart such attacks; (b) highly agile cross-layer protocols that are resilient to the most adaptive adversaries; (c) new tools for implementing and evaluating these protocols in real-world systems.","title":"NeTS: Small: A Game-Theoretic Framework for Agile and Resilient Wireless Systems","awardID":"0915985","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["518182","518070"],"PO":["557315"]},"153887":{"abstract":"Computer systems are increasingly located in places, where they can be physically accessed by people who are not authorized to have unrestricted control of and access to these systems. Examples of this include company laptops carried by employees, robotic vehicles, gaming consoles with copyright protection mechanisms, and remote users of servers in data-centers. An emerging threat in such scenarios are hardware attacks, where snooping devices are attached to the system to directly read and\/or modify data within the system. These attacks can circumvent all traditional security protections in the system, such as password checks, access permissions for data files, etc.<br\/>To address these threats, researchers and processor makers have proposed or developed various types of secure processor architectures, which encrypt and continuously verify data in the system?s memory. However, these secure processors are far from being ready for widespread use, primarily because they focus on a single-processor, non-mobile system that is already up and running and executing a single application. <br\/><br\/>This research project will investigate how to overcome these limitations, focusing on mechanisms for secure boot-up and system configuration, secure communication between and migration of applications, secure access to peripheral devices (including the network). In essence, this project will build the intellectual framework that will be needed to make computers secure regardless of their physical location, preventing unauthorized access even if the system is captured, stolen, or actually owned by a potentially malicious entity. Other broader impacts of this project include improvements in education and workforce, by making computer hardware designers more aware of physical security and by making computer security experts more aware of implications of physical (hardware) attacks.","title":"SHF: Small: Collaborative Research: Beyond Secure Processors - Securing Systems Against Hardware Attacks","awardID":"0916464","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["550974"],"PO":["366560"]},"153777":{"abstract":"People rely on two types of trust when making everyday decisions:<br\/>vertical and horizontal trust. Vertical trust captures trust<br\/>relationships between individuals and institutions, while horizontal<br\/>trust represents the trust inferred from the observations and opinions<br\/>of other peers. Although significant benefit could be realized by<br\/>combining horizontal and vertical trust mechanisms, they have evolved<br\/>independently in computing systems.<br\/><br\/>This project focuses on developing a composable trust model capable of<br\/>tightly coupling vertical and horizontal trust in a manner that is<br\/>both amenable to formal analysis and efficiently deployable. This<br\/>research advances the state of the art in trust management through a<br\/>series of innovative results, including the design of a unified<br\/>framework for specifying composite trust policies and the design and<br\/>analysis of efficient algorithms for policy evaluation. The composite<br\/>trust management approach championed by this project also enables<br\/>policy authors to move beyond simple proof of compliance to identify<br\/>the \"top-k\" preferred users satisfying security policies including<br\/>subjective assessments. The beneficiaries of this research range from<br\/>administrators of traditional computing systems who can better<br\/>incorporate previous history into their decision-making processes, to<br\/>users in social networks who can more carefully manage the exposure of<br\/>their personal data.","title":"TC: Small: Collaborative Research: Towards a Dynamic and Composable Model of Trust","awardID":"0916015","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["534206"],"PO":["564388"]},"153667":{"abstract":"Large-scale hosting infrastructures have become important platforms for many real-world systems such as cloud computing, enterprise data centers, massive data analytics, and web hosting services. Unfortunately, today's large-scale hosting infrastructures are still vulnerable to various system anomalies such as performance bottlenecks, resource hotspots, service level objective (SLO) violations, and various software\/hardware failures. <br\/><br\/>The goal of this project is to assess the viability of an online predictive anomaly management solution for large-scale hosting infrastructures. We will develop novel techniques for 1) performing light-weight online system anomaly prediction; 2) providing self-evolving anomaly prediction models to achieve high-quality prediction for real-world dynamic systems; and 3) performing speculative, ``hot\" system anomaly diagnosis that search possible anomaly causes and suggest corrective actions while the system approaches the anomaly state. Our research will carry out evaluation by conducting experiments and case studies with our industrial partners on realistic platforms. <br\/><br\/>Students supported by this project will gain experience with development and testing of robust real-world hosting infrastructures through interactions with our industrial partners, through internships and onsite experimentation. This work will advance diversity by involving students from under-represented groups. Particularly, the prototype developed in this project will be applied to the Virtual Computing Lab (VCL) at NCSU, a platform for providing a better educational experience for K-12, community colleges, and universities. <br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).","title":"CSR:Small: Online System Anomaly Prediction and Diagnosis for Large-Scale Hosting Infrastructures","awardID":"0915567","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["502081"],"PO":["565255"]},"151005":{"abstract":"Cooperative networking exploits the broadcast nature of the wireless channel by effectively pooling the overheard information, which is traditionally treated as harmful interference. While there is a mature suite of tools at the physical (PHY) layer to harvest cooperative gains, it is still unclear how these tools can be employed to deliver significant network capacity gains. The goal of this project is to design and implement cross-layer mechanisms for cooperative networking. By integrating PHY layer cooperation with Medium Access Control (MAC) and application layers, the project will provide higher network capacity and improved multimedia quality.<br\/><br\/>The project has two interrelated components investigating basic architectures for next generation cooperative networks: (i) Cooperative data transmission, which focuses on a robust cooperative MAC-PHY incorporating multiple relays under mobility and loose requirements on synchronization and network topology. (ii) Cooperative video transmission, which exploits the synergy between cooperation and layered compression in providing unequal error protection, as well as differential quality in multicast. <br\/><br\/>Apart from potential impacts on the theory and practice of new wireless technologies, this project will train undergraduate and graduate students in all aspects of wireless communications. The impact on industry will be facilitated by the close relationship of NYU-Poly with WICAT member companies.<br\/><br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).","title":"NeTS: Medium: Collaborative Research: Unlocking Capacity for Wireless Access Networks through Robust Cooperative Cross-Layer Design","awardID":"0905446","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["491898","559524","525973"],"PO":["565303"]},"153678":{"abstract":"This project addresses critical questions relevant to the successful realization of nanoelectronics based computing platforms. The promised higher density, lower power, and faster operation of nanoelectronics devices is attracting increasing interest. Two of the remaining major roadblocks to the creation of nanoscale computational structures, however, are very high levels of defects and process variations. While the small size of nanostructures and their self-assembly based manufacturing provide great advantages, they also cause them to be very vulnerable to defects and parameter variations---much more so than conventional CMOS. The high defect rates require a layered approach for fault tolerance and typically involve incorporating carefully targeted redundancy at multiple system levels. In addition to defects, even tiny variations in the manufacturing process can lead to very substantial variations in the actual values of key parameters, such as circuit delay. The purpose of this award is to develop a comprehensive methodology to efficiently use redundancy in nanofabrics to ameliorate the effects of both high defect levels and circuit delay variations. The methodology that will be developed will assist designers with a set of well-tested approaches to provide resilience in the face of manufacturing defects and process variations. In educational terms, this project will contribute to the training of undergraduate and graduate students in the art of physical nanofabrics, nanoscale computer architecture, and circuit design for the future nano-technologies.","title":"SHF: Small: Exploiting Redundancy for Process-Variation Resilience in Nano-scale Fabrics","awardID":"0915612","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["553614","553615",408968],"PO":["565157"]},"151016":{"abstract":"Stochastically Robust Resource Allocation for Computing<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Parallel, distributed, and Internet-based computing, communication, and information systems are heterogeneous mixtures of machines and networks. They frequently experience degraded performance due to uncertainties, such as unexpected machine failures, changes in system workload, or inaccurate estimates of system parameters. It is important for system performance to be robust against uncertainties.<br\/>What does it mean for a computer system to be ?robust?? How can robustness be described? How does one determine if a claim of robustness is true, or if a system will fail? How can one decide which of two systems is more robust? These are the types of issues we address in this project, with our team of faculty, graduate students, and undergraduate students from Colorado State University and the University of Colorado, and colleagues in industry (DigitalGlobe) and a national laboratory (NCAR, National Center for Atmospheric Research).<br\/>We are designing models, metrics, mathematical and algorithmic tools, and strategies for (1) deriving system resource management schemes that are robust, and (2) quantifying the probability of meeting performance requirements given uncertainties. We are validating our research by working with DigitalGlobe, which supplies images to Google Maps and Microsoft Virtual Earth, and NCAR, whose research activities include the prediction of severe and catastrophic weather. The robustness concepts being developed have broad applicability, and will significantly contribute to meeting national needs to build and maintain robust information technology infrastructures.","title":"CSR:Medium:Collaborative Research: Stochastically Robust Resource Allocation for Computing","awardID":"0905487","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[402572],"PO":["565255"]},"153799":{"abstract":"Observers have raised alarms about increasing political polarization of our society, with opposing groups unable to engage in civil dialogue to find common ground or solutions. Aggregators such as Digg, Reddit, and Google News rely on ratings and links to select and present subsets of the large quantity of news and opinion items generated each day. If a majority of the raters or linkers share a political viewpoint, minority viewpoints may get little representation in the results, creating an echo chamber for the majority. Even if a site selects items based on votes or links from people with diverse views, algorithms based solely on popularity may lead to a tyranny of the majority that effectively suppresses minority viewpoints. This work is the first attempt to formalize several different instances of the general concept of diversity of viewpoints and to devise algorithms that optimize for these measures. The techniques are likely to be applicable to other domains where selecting a diverse set of items is valuable, such as search engine results and audience voting on questions to ask of a conference speaker or public official. The goals of this research are to: 1) form alternative measures of diversity for result sets; 2) develop algorithms for selecting result sets that jointly optimize for diversity and popularity; 3) assess the impacts of alternative selection and presentation methods on people's willingness to use an aggregation service, their exposure to diverse opinions, and the size of their argument repertoires.<br\/><br\/>The results of the project will provide a better understanding of alternative notions of what it means for a set of items to be diverse or balanced, and the range of reactions that different people have to varying levels and presentations of diversity. Insight into people's preferences for acceptable support and challenge may also allow for the creation of news and opinion aggregators that cause people to choose to expose themselves to greater diversity, thus reducing polarization and enhancing democracy. Results, including open source software, will be distributed via the project web site: (http:\/\/si.umich.edu\/balance\/).","title":"III: Small: Optimizing News and Opinion Aggregators for Diversity","awardID":"0916099","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["539967"],"PO":["563751"]},"157803":{"abstract":"The objective of this research is to understand mechanisms for generating natural movements of skeletal mechanisms driven by stochastically-controlled, biologically-inspired actuators. The approach is to verify the hypothesis that the variability associated with high redundancy and the stochastic nature of the actuation is key to generating natural movements. This project seeks to: (i) develop a method to model and characterize actuator array topologies; (ii) develop a method to analyze the force variability of stochastic actuator arrays; (iii) develop an analytical method to generate movements for a robot with multiple degrees of freedom by minimizing the effect of variability; and (iv) demonstrate the validity of the approach through the development of a robotic arm driven by multiple stochastic array actuators.<br\/><br\/>With respect to intellectual merit, the study of inhomogeneous stochastic actuator network topologies inspired by neuromuscular systems could find the \"missing links\" that bridge the gap between biological natural movements and the ones in artificial systems. Potential results could impact other research areas, including robust computer networks, robust immune systems, and redundant muscle coordination.<br\/><br\/>With respect to broader impacts, a new graduate-level course provides students in engineering and science with a comprehensive and multidisciplinary education in the underlying principles, cutting-edge applications, and societal impacts of biologically-inspired robotics. Outreach activities include an interactive educational program for K-12 students and a workshop for high-school students and their mentors on robot development. International collaboration with Tokyo University of Science, Japan, will be initiated.","title":"CPS: Small: Generation of natural movement for a multiple degrees-of-freedom robot driven by stochastic cellular actuators","awardID":"0932208","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["549592"],"PO":["564728"]},"152479":{"abstract":"Abstract <br\/>Humans, rats and other vertebrates, relying on their advanced nervous systems, are far superior at dealing with the uncertainties of the world than are artificial systems. Thus, a machine, whose behavior is guided by a neurobiologically inspired system, might demonstrate the flexible, autonomous behavior normally attributed to biological organisms. Biological organisms have the ability to respond quickly to an ever-changing world. Because this adaptability is so critical for survival, all vertebrates have sub-cortical structures, which comprise the neuromodulatory systems, to handle uncertainty and change in the environment. Attention, which is influenced by neuromodulation, plays a significant role in animal's ability to respond to such changes. Different neuromodulatory systems are thought to play important and distinct roles in attention. A collaborative approach, which compares rodent experiments with robots having simulated nervous systems, will examine these attentional systems. These experiments will lead to a better understanding of how animals cope with uncertainty in the environment, and will lead to the design of a robot capable of flexible and complex behavior. This work has the potential of being paradigm-shifting technology that could find its way in many practical applications. <br\/><br\/>In an interdisciplinary approach, a robotic system, whose design is based on the vertebrate neuromodulatory system and its effect on attention, will be constructed and tested under similar experimental conditions to the rat, and then in a more practical application. This approach, which combines computational modeling and robotics with rodent behavioral and electrophysiological experiments, will lead to a better understanding of how areas of the brain allocate attentional resources and cause the organism to respond rapidly to essential events and objects. Two of these neuromodulatory systems, the cholinergic and noradrenergic, are thought to play important and distinct roles in attention. Expected uncertainty, the known degree of unreliability of predictive relationships in the environment, drives activity within the cholinergic system. Unexpected uncertainty, large changes in the environment that violate prior expectations, drives activity within the noradrenergic system. These systems modulate activity in brain areas to properly allocate the attention to stimuli in the environment necessary for adequate learning to occur and fluid behavior to be maintained. This knowledge will be used to construct a robust, intelligent robotic system whose capability to adapt to change, and behave effectively in a noisy, complex environment will rival that of a biological system.","title":"RI: Large: Collaborative Research: Understanding Uncertainty in Rats and Robots","awardID":"0910485","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["502207","498816"],"PO":["564318"]},"158903":{"abstract":"Emerging high-end computing platforms, such as leadership-class machines at the petascale, provide new horizons for complex modeling and large-scale simulations. These machines are used to execute data intensive applications of national interest such as climate modeling, cosmic microwave background radiation, and astrophysical thermonuclear flashes. While these systems have unprecedented levels of peak computational power and storage capacity, a critical challenge concerns the design and implementation of scalable I\/O (input-output) system software (also called I\/O stack) that makes it possible to harness the power of these systems for scientific discovery and engineering design. Unfortunately, currently, there are no available mechanisms that accommodate I\/O stack-wide, application-level QoS (quality-of-service)specification, monitoring, and management.<br\/><br\/>This project investigates a revolutionary approach to the QoS-aware management of the I\/O stack using feedback control theory, machine learning, and optimization. The goal is to maximize I\/O performance and thus improve overall performance of large scale applications of national interest. The project uses (1) machine learning and optimization to determine the best decomposition of application-level QoS to sub-QoSs targeting individual resources, and (2) feedback control theory to allocate shared resources managed by the I\/O stack such that the specified QoSs are satisfied throughout the execution. The project tests the developed I\/O stack enhancements using the workloads at NCAR, LBNL and ANL systems. It also involves two efforts in broadening participation: CISE Visit in Engineering Weekends (VIEW) and NASA-Aerospace Education Services Project (NASA-AESP) at the Center for Science and the Schools (CSATS).","title":"Collaborative Research: Adaptive Techniques for Achieving End-to-End QoS in the I\/O Stack on Petascale Multiprocessors","awardID":"0937949","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["396478","550407","542016"],"PO":["565272"]},"157814":{"abstract":"The objective of this research is to develop a framework for the development<br\/>and deployment of next-generation medical systems consisting of integrated and<br\/>cooperating medical devices. The approach is to design and implement an<br\/>open-source medical device coordination framework and a model-based component<br\/>oriented programming methodology for the device coordination, supported by a<br\/>formal framework for reasoning about device behaviors and clinical workflows.<br\/><br\/>The intellectual merit of the project lies in the formal foundations of the<br\/>framework that will enable rapid development, verification, and certification<br\/>of medical systems and their device components, as well as the clinical<br\/>scenarios they implement. The model-based approach will supply evidence for<br\/>the regulatory approval process, while run-time monitoring components embedded<br\/>into the system will enable \"black box\" recording capabilities for the forensic<br\/>analysis of system failures. The open-source distribution of tools supporting<br\/>the framework will enhance its adoption and technology transfer.<br\/><br\/>A rigorous framework for integrating and coordinating multiple medical devices<br\/>will enhance the implementation of complicated clinical scenarios and reduce<br\/>medical errors in the cases that involve such scenarios. Furthermore, it will<br\/>speed up and simplify the process of regulatory approval for coordination-enabled medical devices, while the formal reasoning framework will improve the confidence in the design process and in the approval decisions.<br\/><br\/>Overall, the framework will help reduce costs and improve the quality of the<br\/>health care.","title":"CPS:Medium:Collaborative Research:Infrastructure and Technology Innovations for Medical Device Coordination","awardID":"0932289","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563764",421231,"559268","563763"],"PO":["565274"]},"155757":{"abstract":"Proposal #: CNS 09-23152<br\/>PI(s): Arce-Nazario, Rafael; Orozco, Edusmildo<br\/>Institution: University of Puerto Rico ? Rio Piedras<br\/><br\/>Title: MRI\/Acq.: Acq.of Equipment for the Establishment of a Reconfigurable Computing Center at UPR-RP <br\/><br\/>This project, acquiring a shared computational resource instrument with multiple high-end general purpose processors and Field Programmable Gate Arrays (FPGA) co-processors that form flagship platforms for Reconfigurable Computing (RC), supports interdisciplinary collaboration with research groups in Finite Field Applications, Computational Discrete Mathematics, Electronics Design Automation, and Developmental Biology. Focusing on research tools for assisting automatic partitioning of applications to multicore architectures and configurable platforms, the project services eight application fields, including hardware\/software (HW\/SW) co-design tools, power optimization tools for embedded systems, Latin square orthogonality- and hypercube cut number-related problems, reconfigurable radar waveforms, and bioinformatics. The DMAGIC (DST Mapping using Algorithmic and Graph Interaction and Computation) methodology generates a high-level efficient partition for a given pair of problem descriptions in Discrete Signal Transform (DST) and architectural descriptions. Hence, algorithms will be designed mapping the different research areas into the platform. Education and research training are given a high priority.<br\/><br\/>Broader Impacts: The instrument expedites scientific results, impacts the education and training of all users, and contributes to workforce training. Collaborations open new opportunities for undergraduate research, contributing not only to retain students, but also to direct them to graduate studies. This university, residing in an EPSCoR jurisdiction, services a large number of underrepresented minority students.","title":"MRI Acquisition of Equipment for the Establishment of a Reconfigurable Computing Center at the University of Puerto Rico","awardID":"0923152","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["559151","425100"],"PO":["557609"]},"153458":{"abstract":"Humans possess the ability to learn increasingly sophisticated representations of the world in which they live. In the visual domain, it is estimated that we are able to identify in the order of 30,000 object categories at multiple levels of granularity (e.g. toe-nail, toe, leg, human body, population). Moreover, humans continuously adapt their models of the world in response to data. Can we replicate this life-long-learning capacity in machines? <br\/><br\/>In this project, the PIs build hierarchical representations of data streams. The model complexity adapts to new structure in data by following a nonparametric Bayesian modeling paradigm. In particular, the depth and width of our hierarchical models grow over time. Deeper layers in this hierarchy represent more abstract concepts, such as ?a beach scene? or ?chair?, while lower levels correspond to parts, such as a ?patch of sand? or ?body part?. The formation of this hierarchy is guided by fast hierarchical bottom up segmentation of the images. <br\/><br\/>To process large amounts of information, the PIs distribute computation across many CPUs \/GPUs. They develop novel fast inference techniques based on variational inference, memory bounded online inference, parallel sampling, and efficient data-structures. <br\/><br\/>The technology under development has a large number of potential applications ranging from organizing digital libraries and the worldwide web, building visual object recognition systems, successfully employing autonomous robots and training a ?virtual doctor? by processing worldwide information from hospitals about diseases, diagnosis and treatments. <br\/><br\/>Results are disseminated through scientific publications and publicly available software.","title":"RI: Small: Collaborative Research: Infinite Bayesian Networks for Hierarchical Visual Categorization","awardID":"0914789","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["517415"],"PO":["562760"]},"153579":{"abstract":"This project advances learning methods for obtaining linguistic knowledge from raw or nearly raw text; such knowledge constitutes a core component of natural language processing technology but is difficult to obtain, usually relying on expensive manual annotation of text data. Specifically, this project aims to automate some of the mechanical aspects of developing learning algorithms for linguistic structure (in part by using a empirical Bayesian framework to unify considerable past work by the PI and others), to enrich models with richer linguistic bias (particularly through lexicalization and integration of morphology and syntax), and to apply these techniques to new natural language processing problems (identifying boilerplate and quotation extraction). Another exciting dimension is learning from text collections in multiple languages (not necessarily including translations), which past work has shown can lead to better unsupervised learning. The project will lead to working systems, including generic tools applicable to many problems in natural language processing and machine learning. These tools will provide infrastructure for the PI's courses and will be publicly available to the research community. Research results will be published in leading journals and at major conferences. The project supports one primary graduate student and a post-doctoral researcher. Major impacts of this project will be improvements in the quality of rapidly ported natural language processing tools for new languages and text domains, as well as a deeper scientific understanding of natural language learning by machines.","title":"RI-Small: Probabilistic Models for Structure Discovery in Text","awardID":"0915187","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["563246"],"PO":["565215"]},"151038":{"abstract":"Despite years of effort, the underlying structure of the Internet is still largely opaque to networking researchers. This opaque structure is also a barrier to ISP administrators trying to diagnose connectivity problems - when a problem occurs, it can be difficult to identify the root cause if it is not in the ISP's own network. In our view, the opaque structure is primarily due to the lack of vantage points from which to measure the Internet: there are more than 100,000 uniquely routed prefixes, yet there are only a few hundred locations from which one can launch probes. This project addresses this lack of<br\/>vantage points by developing techniques, using special types of measurement packets, to simulate having a very much larger number of vantage points. <br\/><br\/>Specifically, the PI proposes to build these techniques into a measurement tool, work with several ISPs to have them adopt and deploy the tool, and also deploy it on an NSF and ISP supported testbed called PlanetLab. Using the tool, a number of fundamental questions about the Internet will be studied: How is the Internet evolving? Is the Internet structure self-similar? What is the prevalence of asymmetric routing? Answers to these questions are needed to understand the impact of proposed changes to the Internet. The PI will also make the measurements publicly available. <br\/><br\/><br\/>This award is funded under the American Recovery and Reconstruction Act of 2009 (Public Law 111-5).","title":"NeTS:Medium:Internet Measurement in the Large","awardID":"0905568","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["463055"],"PO":["564993"]},"163138":{"abstract":"The life science research community generates an abundance of data on genes, proteins, sequences, etc. These are captured in publicly available resources such as Entrez Gene, PDB and PubMed and in focused collections such as TAIR and OMIM. A number of ontologies such as GO, PO and UMLS are in use to increase interoperability. Records in these resources are typically annotated with controlled vocabulary (CV) terms from one or more ontologies. Records are often hyperlinked to those in other repositories, creating a richly curated biological Web of semantic knowledge. <br\/><br\/>The objective of this project is to develop tools to explore and mine this rich Web of annotated and hyperlinked entries so as to discover meaningful patterns.<br\/>The approach builds upon finding potentially meaningful and novel associations between pairs of CV terms cross multiple ontologies. The bridge of associations across ontologies reflects annotation practices across repositories. A variety of graph data mining and network analysis techniques are being explored to find complex patterns of groups of CV terms cross multiple ontologies. The intent is to identify biologically meaningful associations that yield nuggets of actionable knowledge to be made available to the scientist together with a set of golden publications that support the identified patterns.<br\/><br\/>The intellectual merit of the project is that it is unique in comparison to other bioinformatics data integration and analysis projects. Data is integrated from across numerous sources including genes, gene annotations, ontologies, and the literature. The exploratory nature (EAGER) of this research is both with respect to the biological and the computer science disciplines. From the biological viewpoint, a high level of speculation is associated with any discovered biological patterns. Discovered patterns night not necessarily meet criteria for experimental validation. The research methodology combines algorithmic and analytical techniques from multiple computer science sub-disciplines. While specific technical innovations are expected, an inter-related set of computer science challenges needs to be defined.<br\/>This research has the potential for broader impact since the methodology can be applied to any type of interlinked resources on the biological semantic Web as well as to any collection of hyperlinked resources. This research is a collaboration between the University of Maryland and the University of Iowa. For further information see the project web pages at the following URL:<br\/>http:\/\/www.umiacs.umd.edu\/research\/CLIP\/RSEAGER2009\/","title":"III EAGER Collaborative Research: Exploratory Research on the Annotated Biological Web","awardID":"0960984","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["500661"],"PO":["560586"]},"157704":{"abstract":"The physical environment of a cyber-physical system is unboundedly complex, changing continuously in time and space. An embodied cyber-physical system, embedded in the physical world, will receive a high bandwidth stream of sensory information, and may have multiple effectors with continuous control signals. In addition to dynamic change in the world, the properties of the cyber-physical system itself ? its sensors and effectors ? change over time. How can it cope with this complexity? The hypothesis behind this proposal is that a successful cyber-physical system will need to be a learning agent, learning the properties of its sensors, effectors, and environment from its own experience, and adapting over time. Inspired by human developmental learning, the assertion is that foundational concepts such as Space, Object, Action, etc., are essential for such a learning agent to abstract and control the complexity of its world. To bridge the gap between continuous interaction with the physical environment, and discrete symbolic descriptions that support effective planning, the agent will need multiple representations for these foundational domains, linked by abstraction relations. To achieve this, the team is developing the Object Semantic Hierarchy (OSH), which shows how a learning agent can create a hierarchy of representations for objects it interacts with. The OSH shows how the ?object abstraction? factors the uncertainty in the sensor stream into object models and object trajectories. These object models then support the creation of action models, abstracting from low-level motor signals. To ensure generality across cyber-physical systems, these methods make only very generic assumptions about the nature of the sensors, effectors, and environment. However, to provide a physical test bed for rapid evaluation and refinement of our methods, the team has designed a model laboratory robotic system to be built from off-the-shelf components, including a stereo camera, a pan-tilt-translate base, and a manipulator arm. For dissemination and replication of research results, the core system will be affordable and easily duplicated at other labs. There are plans to distribute the plans, the control software, and the software for experiments, to encourage other labs to replicate and extend the work. The same system will serve as a platform for an open-ended set of undergraduate laboratory tasks, ranging from classroom exercises, to term projects, to independent study projects. There is a preliminary design for a very inexpensive version of the model cyberphysical system that can be constructed from servo motors and pan-tilt webcams, for use in collaborating high schools and middle schools, to communicate the breadth and excitement of STEM research.","title":"CPS: Medium: Learning to Sense Robustly and Act Effectively","awardID":"0931474","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["534124","507875"],"PO":["565136"]},"157825":{"abstract":"A Logical Framework for Self-Optimizing Networked Cyber-Physical Systems<br\/><br\/>The objective of this research is to develop foundations for the newly emerging<br\/>generation of networked cyber-physical systems. The approach is based on a<br\/>distributed logic of cyber-physical systems together with distributed<br\/>cross-layer control and optimization strategies to enabled local actions to<br\/>maintain or improve the satisfaction of system goals. The framework will be<br\/>implemented first in simulation, then on one of SRI's robot platforms, and<br\/>demonstrated in the context of networked mobile robotic teams, a particularly<br\/>challenging application.<br\/><br\/>Networked cyber-physical systems present many intellectual challenges<br\/>not suitably addressed by existing computing paradigms. They must<br\/>achieve system-wide objectives through local, asynchronous actions,<br\/>using distributed control loops through the environment. A key<br\/>challenge is to develop a robust computational foundation that<br\/>supports a wide spectrum of system operation between autonomy and<br\/>cooperation to adapt to uncertainties, changes, failures, and resource <br\/>constraints, in particular to limitations of computational, energy, <br\/>and networking resources.<br\/><br\/>The results will have a variety of applications including distributed<br\/>surveillance, instrumented pervasive spaces, crisis response, medical<br\/>systems, green buildings, self-assembling structures, networked<br\/>space\/satellite missions, and distributed critical infrastructure<br\/>monitoring and control. There is also potential for integration<br\/>into SRI's commercial robotic platform. Results will be publicly<br\/>available from a project web site, and tutorial material will be<br\/>developed for students and researchers. A multi-disciplinary research<br\/>seminar will be sponsored by SRI. The coPI is female with a strong<br\/>record of mentoring female students and young researchers, including<br\/>the project's female postdoc.","title":"CPS: Medium: A Logical Framework for Self-Optimizing Networked Cyber-Physical Systems","awardID":"0932397","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["550115","474613"],"PO":["565239"]},"155889":{"abstract":"Proposal #: CNS 09-23479 <br\/>PI(s): Sabharwal, Ashutosh; Aazhang, Behnaam; Cavallaro, Joseph R.; <br\/> Knightly, Edward W.; Zhong, Lin<br\/>Institution: Rice University <br\/>Collaborative with<br\/>Proposal #: CNS 09-23484 <br\/>PI(s): Dacso, Clifford<br\/>Institution: Methodist Hospital Rsrch Inst.<br\/><br\/>Title: MRI\/Dev.: Mobile WARP: Platform for Next Generation Wireless Networks & Mobile Applications<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Project Proposed:<br\/>This collaborative project, developing a mobile, open, and all-layers programmable platform for wireless communication systems research, supports the design, development, and dissemination of a community platform instrument, for collaborative architecting next-generation wireless networks and mobile applications, including medical applications. Wireless Open-Access Research Platform (mobileWARP), targets fundamental new research for next generation mobile network clients.<br\/>The work involves the following thrusts:<br\/>- Programmable and Context-Aware Mobile Platform,<br\/>- True Cross-Layer Design Flows, and<br\/>- Open-Access for Research and Education.<br\/>Mobile WARP will be completely reprogrammable at all 7 layers of the networking stack and will support a touch-based user interface to develop state-of-the-art applications. With battery-operated<br\/>portable form factor, it will integrate context measurements from a variety of sensors (location, motion, power consumption, and health) and enable fundamentally new ideas in context-aware networking and applications. Two new design flows will be developed in support of the new hardware, one for the design of energy-efficient networking components on mobile handsets and the other for the design of mobile applications. Each design flow will be architected such that researchers at each layer do not have to learn any programming languages that they traditionally do not use. Lastly, to realize community-powered development, every part of mobileWARP will be open source: hardware designs, sensor subsystems, and all layers of the networking stack. Semester-long courses, laboratory exercises, operational reference designs, and hands-on mobileWARP workshops will also be developed. Reprogrammability at all layers ensures that clean state designs can be verified in a realistic design and testing environment. The platform opens an opportunity to explore merging application domains that could revolutionize the use of wireless. An important category of mobile healthcare for chronic illnesses will serve as a concrete example. Emphasis will be placed on always-available, ultra-low power designs for sensor, processing, and wireless subsystems.<br\/><br\/>Broader Impacts: Embodying a bold convergence concept, and with a potential for transformative change in wireless networking and mobile applications, the project directly impacts diverse research communities, cross-cutting multiple areas and application domains, including mobile healthcare for chronic illnesses. Furthermore, courses developed, as well as laboratory exercises, allow students to explore all layers of wireless radio communication.","title":"Collaborative Research: MRI: Development of mobileWARP - A Platform for Next-Generation Wireless Networks and Mobile Applications","awardID":"0923479","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["542042","50058","548310","548311","548312"],"PO":["557609"]},"148904":{"abstract":"This project will support a four-day workshop focused on issues in high-fidelity simulation in support of robotics research and education. Approximately 20 of the world?s foremost experts in the development and use of simulation tools for the analysis, design, and control of robotic manipulation systems will be invited. The main goals will be to assess the state of the art in robot simulation tools and to produce a plan of action for the deployment of a broadly accessible simulation tool. The workshop will culminate in the development of a CRI:ADDO proposal to NSF to support the deployment and initial development of the tool, after which, support and development would continue in a self-sustaining mode.","title":"CRI: CI-P: SPADE: A High-Performance Computing Platform for Support of Robotics Research and Education","awardID":"0855024","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["534411","541895"],"PO":["565136"]},"157858":{"abstract":"This proposal supports student involvement and attendance at the 2009 SIAM\/ACM Joint Conference on Geometric and Physical Modeling. This four day event draws between 200?300 attendees across a broad set of interdisciplinary academic areas including mathematics (geometry, topology, numerical methods, optimization), engineering (design, modeling, simulation) and computer science (graphics, computational geometry). The meeting is a unique, multi-disciplinary event. Whereas most scientific meetings in the above areas are ?stove-piped? by the individual disciplines, the SIAM Activity Group on Geometric Design and the ACM Symposium on Solid and Physical Modeling have an over 30 year history of spanning disciplines. The above event is bringing together scientists and engineers, both from academia and industry, around the themes of geometry and topology and their role in product design, manufacturing, simulation and other applications.<br\/><br\/>The intellectual merit of the proposed activity lies in the educational opportunities and the shared research objectives of the community. By providing travel grants for students studying in these areas, the NSF encourages the students to pursue interdisciplinary work and enhance their academic experiences. Secondarily, the academic subjects covered by this meeting are of vital importance in many areas of critical national need. Work presented at this meeting covers diverse topics ranging from biomedical CAD and biomanufacturing to sustainable design and optimization of next generation materials. The broader impact is found in developing the careers of the student supported by these travel grants and their work in these areas of critical national need. Given the central role geometry and topology play in everything from product design to virtual training systems to advanced manufacturing technology, the proper nurturing of these activities?especially those of an interdisciplinary nature?is vital to producing scientists and engineers who can meet the nation?s needs.","title":"G&V: Request for Student Travel Support for 2009 SIAM\/ACM Joint Conference on Geometric and Physical Modeling","awardID":"0932602","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["560676"],"PO":["532791"]},"154107":{"abstract":"The use of wireless networks is expanding, including mesh networks that increase the geographic coverage of an access point, and ad hoc networks that provide instantaneous and self-configuring communications when wired infrastructure is not available. The viability of these networks is hampered, however, by the poor performance of TCP when it operates over multiple wireless hops. Many alternative transport protocols are being designed, but the lack of<br\/>experiments on deployed networks severely limits the impact and relevance of current research in the area.<br\/><br\/>This project designs a software toolkit that simplifies the process of developing wireless transport protocols. Protocols can be written in user space, enabling researchers to avoid the complexities of kernel development and focus their efforts on experimental evaluation. The project uses the toolkit to implement a number of leading wireless transport protocols, comparing their performance, examining the decomposition of functionality between end hosts and routers, and evaluating TCP compatibility. The end result will be a comprehensive study of wireless transport protocols in an experimental setting,<br\/>demonstrating how to obtain high throughput while working seamlessly with existing TCP stacks.<br\/><br\/>The toolkit will be developed as an open source project, so that it can be used by the research community to develop new transport protocols or to examine the interaction of wireless transport protocols with new MAC designs, network coding, or routing protocols. The project will also develop curriculum for incorporating a mesh testbed into a senior-level course in networking, with accompanying labs and instructional materials.","title":"NeTS:Small: Wifu: A Software Toolkit for Wireless Transport Protocols","awardID":"0917240","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[410042],"PO":["557315"]},"157627":{"abstract":"The objective of this research is to develop a framework for the development<br\/>and deployment of next-generation medical systems consisting of integrated and<br\/>cooperating medical devices. The approach is to design and implement an<br\/>open-source medical device coordination framework and a model-based component<br\/>oriented programming methodology for the device coordination, supported by a<br\/>formal framework for reasoning about device behaviors and clinical workflows.<br\/><br\/>The intellectual merit of the project lies in the formal foundations of the<br\/>framework that will enable rapid development, verification, and certification<br\/>of medical systems and their device components, as well as the clinical<br\/>scenarios they implement. The model-based approach will supply evidence for the regulatory approval process, while run-time monitoring components embedded<br\/>into the system will enable \"black box\" recording capabilities for the forensic<br\/>analysis of system failures. The open-source distribution of tools supporting<br\/>the framework will enhance its adoption and technology transfer.<br\/><br\/>A rigorous framework for integrating and coordinating multiple medical devices<br\/>will enhance the implementation of complicated clinical scenarios and reduce<br\/>medical errors in the cases that involve such scenarios. <br\/><br\/>Furthermore, it will speed up and simplify the process of regulatory approval for coordination-enabled medical devices, while the formal reasoning framework will improve the confidence in the design process and in the approval decisions.<br\/><br\/>Overall, the framework will help reduce costs and improve the quality of the<br\/>health care.","title":"CPS:Medium:Collaborative Research: Infrastructure and Technology Innovations for Medical Device Coordination","awardID":"0930647","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553656","553657"],"PO":["561889"]},"157748":{"abstract":"The objective of this research is to develop new principles for<br\/>creating and comparing models of skilled human activities, and to<br\/>apply those models to systems for teaching, training and assistance of<br\/>humans performing these activities. The models investigated will<br\/>include both hybrid systems and language-based models. The research<br\/>will focus on modeling surgical manipulations during robotic minimally<br\/>invasive surgery. Models for expert performance of surgical tasks will<br\/>be derived from recorded motion and video data. Student data will be<br\/>compared with these expert models, and both physical guidance and<br\/>information display methods will be developed to provide feedback to<br\/>the student based on the expert model.<br\/><br\/>The intellectual merit of this work lies in the development of a new<br\/>set of mathematical tools for modeling human skilled activity. These<br\/>tools will provide new insights into the relationship between skill,<br\/>style, and content in human motion. Additional intellectual merit lies<br\/>in the connection of hybrid systems modeling to language models, the<br\/>creation of techniques for automated training, and in the assessment<br\/>of new training methods.<br\/><br\/>The broader impact of this research will be the creation of automated<br\/>methods for modeling and teaching skilled human motion. These methods<br\/>will have enormous implications for the training and re-training of<br\/>the US workforce. This project will also impact many diversity and<br\/>outreach activities, including REU programs and summer camps for K-12<br\/>outreach. The senior personnel of this project also participate in the<br\/>Robotic Systems Challenge and the Women in Science and Engineering<br\/>program.","title":"CPS:Medium:Hybrid Systems for Modeling and Teaching the Language of Surgery","awardID":"0931805","effectiveDate":"2009-09-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["531055","426359","555788","445173"],"PO":["565239"]},"145538":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of<br\/>2009 (Public Law 111-5).<br\/><br\/>Large-scale spatial temporal systems such as wildfire are inherently difficult to study due to their complex and dynamical behavior. Computer modeling and simulation provide an important tool for understanding and predicting the dynamic behavior of these systems. While sophisticated simulation models have been developed, traditional simulations are largely decoupled from real systems by making little usage of real time data from the systems under study. With recent advances in sensor and network technologies, the availability and fidelity of such real time data have greatly increased. A new paradigm of dynamic data-driven simulation is emerging where a simulation system is continually influenced by the real time data for better analysis and prediction of a system under study. This project investigates tractable approaches for dynamic data driven simulation of large-scale spatial temporal systems based on state-of-the-art probabilistic techniques using Sequential Monte Carlo (SMC) methods. New algorithms and methods are developed to enhance the effectiveness and efficiency of data driven simulation of large-scale spatial temporal systems. The project builds upon the application context of wildfire that the PI has experience with.<br\/><br\/>This project will have a strong impact on both theory and practice aspects of simulation-based study of large-scale complex systems in general, and wildfire in particular. The project will result in major advances to the new paradigm of dynamic data-driven simulation, and can potentially benefit many other fields where sophisticated simulation models are used, such as manufacturing, transportation, geo-ecological science, and national security. The project also has a comprehensive education component, including course development, involving undergraduates and under-represented students in research, and international student exchange. Dissemination will include demonstrations, a shared simulation environment, and workshops\/tutorials.","title":"CAREER: Large-scale Spatial Temporal Data Driven Simulation with Sequential Monte Carlo Methods","awardID":"0841170","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["426827"],"PO":["535244"]},"154008":{"abstract":"Many successful large-scale software systems share a fundamental characteristic: their modular structures enable system-wide advances though distributed and parallelized improvement of modules. However, merely breaking software into modules, without assessing the interplay between a design and the organization that must instantiate it, does not always ensure that parallelized, module-wise evolution is effective. In particular, mismatches between design and organizational structures can result in expensive inter-team communication costs, exacerbated by barriers such as differing time zones, languages and cultures. This research aims to formally express and quantitatively assess the key characteristics of software structures that allow for system-wide evolution through distributed module-wise contributions, and to account for the relationship between design structure and organizational structure, as it impacts software quality, productivity, and survival. The work will explore a computable socio-technical model, associated metrics and automated analysis techniques to improve the conduct of software development. The approach will allow designers to assess and manipulate software designs at early development stages so that modules can be defined and implemented by independent teams, shortening development time, facilitating changes, and minimizing coordination costs. The results will be demonstrated on large software systems, working with industrial partners who wish to understand the impact of these techniques.","title":"SHF:Small:Exploring the Synergy between Software Design and Organizational Structure","awardID":"0916891","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["498101","519253"],"PO":["564388"]},"154129":{"abstract":"The scale and complexity of highly distributed data intensive systems is approaching a point where traditional performance evaluation techniques are becoming difficult to apply. Specifically, use of traditional stochastic performance evaluation methods encounters difficulties in (1) complexity (i.e., scale of the models and intractability of corresponding solution techniques) and (2) parameter estimation (i.e., needed by the models).<br\/><br\/>In this project we seek to address these two challenges through the use of machine learning techniques. Such techniques have not been traditionally employed in this area, but have emerged recently as a possible direction. We envision that this will lead us not only to better machine learning approaches but will also facilitate merging of machine learning-based techniques with more traditional approaches to performance evaluation, where we anticipate obtaining better results than can be obtained through either approach alone.<br\/><br\/>The broader impacts of this work will be to enable a deeper understanding of the role, advantages, and limitations of machine learning approaches in performance evaluation of large-scale systems as well as their relationship with more traditional approaches. Broader impact also includes improved interdisciplinary education at the graduate and undergraduate levels and diversity efforts.","title":"DC:Small: \"Synergizing statistical machine learning and stochastic system modeling with application to real systems\".","awardID":"0917340","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":[410098,"497149"],"PO":["543481"]},"148948":{"abstract":"This project develops the OpenVMI, an open-source, software-based research instrument for virtual machine introspection (VMI). VMI is important to certain research areas such as distributed computing, automated system management and configuration, and computer security.<br\/><br\/>Virtualization technologies have created new momentumfor a number of research areas such as distributed computing, automated system management and configuration, and computer security. One basic yet powerful instrumentation function in virtualization-based research is virtual machine introspection (VMI): observing a VM?s semantic states and events from outside the VM. VMI is hard to implement, mainly because of the semantic gap between the external and internal observations of the VM. Thus a generic VMI software instrument becomes highly desirable to virtualization researchers. <br\/><br\/>This project develops and deploys OpenVMI, an open-source, software-based research instrument for VMI at Purdue University and North Carolina State University. OpenVMI can be thought of as a ?fluoroscopic? instrument for VMs. Through the OpenVMI API, a user will be able to obtain the VM?s semantic states and events in both kernel and user spaces without modifying or instrumenting the VM. <br\/><br\/>Three research areas are identified at the PIs? institutions that will benefit from the development and deployment of OpenVMI:<br\/><br\/>-Management of hosted virtual environments: This research involves monitoring, provisioning and regulating autonomous virtual environments running in a shared distributed hosting infrastructure. Open- VMI will enable non-intrusive, semantic monitoring of VMs, which will trigger VM management operations at runtime such as VM migration, resource adaptation and access control. <br\/>-Monitoring, detection and investigation of user-level malware: This research is concerned with OSlevel policies and mechanisms for malware detection and investigation. By using OpenVMI, these policies and mechanisms can be moved out of the target VM, achieving stronger tamper-resistance without losing VM observability. <br\/>-Monitoring of OS integrity: This research addresses the integrity of the guest OS against kernel-level attacks. It also involves detailed profiling of kernel-level attacks for future detection and recovery. OpenVMI will provide a unique vintage point to observe runtime state changes of kernel objects, which will help reveal details of an OS integrity violation. <br\/><br\/>Six research projects in the above areas are designated for OpenVMI deployment.","title":"Collaborative Research: II-New: OpenVMI: A Software Instrument for Virtual Machine Introspection","awardID":"0855141","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["518557"],"PO":["564181"]},"160740":{"abstract":"This is a study of how people make decisions in dynamic, social environments, achieving a methodological innovation by using online real-time strategy (RTS) games as laboratories for studying human behavior. Investigation into social interactions has been discussed in the context of virtual worlds and online role-playing games, but not in RTS games, nor have researchers yet developed the data-collection techniques or theoretical principles for doing research in this important sector of human-centered computing. In addition to their entertainment value, RTS games have emerged to become virtual platforms that simulate real-world, real-time physics, scenarios, characters, and strategies. Particularly, multi-player online RTS games are providing a new model of human interaction that is in line with decision theory, game theory, planning, learning, and other concepts from research fields such as Computer Science, Artificial Intelligence, Economics, and Behavioral Sciences.<br\/><br\/>This research will study users' social strategies in RTS games in three major ways: developing a gaming environment, a user study with experiments, and an automated learning approach. The game will present users with a series of missions to be accomplished, and users will receive points for successful completion. In early stages these missions can be accomplished alone and with little effort, but as the player progresses they will require alliances with others. The first phase of user studies will involve a qualitative analysis of user behaviors, identifying specific points in the game when users must make decisions where the social relationships will be important factors. This qualitative analysis will be followed by a quantitative analysis of the players' performance, developing techniques for measuring the payoffs from each action. Once players begin developing strong alliances, a set of experiments will analyze their reasoning when making strategic decisions. This will include measurements of social tie strength, structural social network features, the past history of interactions, and evolutionary simulations of strategies. The final phase of research will involve controlled experiments with users, presenting them with situations where they have to make a decision that requires consideration of the social structure.<br\/><br\/>This project will make software, test suites, documentation, and teaching materials freely available on the Internet. Decision making is an important problem in artificial intelligence, and effective decision-making is important in all kinds of organizations and real-world applications. This research could provide the theoretical and experimental basis for developing practical algorithms and applications for social decision making, to make it easier for the organizations and the users of such applications in their decision-making process.","title":"EAGER: Understanding Social Behavior in Real-Time Strategy Games","awardID":"0948123","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["531452",429897],"PO":["564456"]},"150840":{"abstract":"A central task in understanding how neurons collectively process information is to map how neurons influence each other in local cortical networks. As defined here, local cortical networks will consist of tens to hundreds of neurons. Influence will be defined as how well knowledge of activity in one neuron will allow the activity in another neuron to be predicted. Three methods for measuring influence between neurons will be explored. To assess these methods, they will be used on data from simple, and then realistic, models of cortical networks where the underlying connectivity structure is known. After refinement, the methods will be applied to recordings from hundreds of cortical neurons in small slice cultures of brain tissue. Over 100 cortical neurons at a time will be recorded through the use of an advanced, 512 electrode array. In addition, measures of influence will be applied to data taken from 16 wire electrodes placed in behaving rats. These in vivo recordings will serve as a first step toward linking influence maps in cortical networks to behavior. This research is expected to provide new knowledge that could aid the design of brain-like computing devices. In addition, it could ultimately be used as a tool to identify differences in influence patterns between healthy and pathological brains. <br\/><br\/>The three methods for measuring influence will include directed information, transfer entropy, and Granger causality. Special care will be taken to identify situations where these measurements may produce false positive connections. These include cases where two neurons are driven by a common source at different delays, and cases where one neuron influences another neuron indirectly through an intercalated neuron. Such false positive connections will be identified and corrected, to the extent possible, by comparing raw pairwise measures of influence with conditional measures of influence. Simulations will also provide an estimate of how often neurons outside the recorded population can contribute to false positive connections. These estimates will be used to place confidence limits on the influence maps extracted from actual data. In neurons where influences converge, synergistic interactions between influences will be measured. The map of influence will serve to identify locations within the network where synergistic transformations of information, or computations, occur.","title":"Collaborative Research: Causal Connectivity and Computations in Hundreds of Neurons in Cortex","awardID":"0904912","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[402087,"562709","471524"],"PO":["564318"]},"150972":{"abstract":"Assuring deadlines of embedded tasks for contemporary multicore architectures is becoming increasingly difficult. Real-time scheduling relies on task migration to exploit multicores, yet migration actually reduces timing predictability due to cache warm-up overheads and increased interconnect traffic.<br\/><br\/>This work promotes a fundamentally new approach to increase the timing predictability of multicore architectures aimed at task migration in embedded environments making three major contributions:<br\/><br\/>1. The development of novel strategies to guide migration based on cost\/benefit tradeoffs exploiting both static and dynamic analyses.<br\/><br\/>2. The devising of mechanisms to increase timing predictability under task migration providing explicit support for proactive and reactive real-time data movement across cores and their caches.<br\/><br\/>3. The promotion of rate- and bandwidth-adaptive mechanisms as well as monitoring capabilities to increase predictability under task migration.<br\/><br\/>The work aims at initiating a novel research direction investigating the benefits of interactions between hardware and software for embedded multicores with respect to timing predictability. This project fundamentally contributes to the research and educational infrastructure for the design and development of safety- and mission-critical embedded systems.","title":"CSR: Medium: Collaborative Research: Providing Predictable Timing for Task Migration in Embedded Multi-Core Environments (TiME-ME)","awardID":"0905365","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518504","528208"],"PO":["565255"]},"161994":{"abstract":"The governments of the world are evolving toward a more complex global network of political, societal, and economic dependencies, driven in large part by the expanding capabilities of information and communication technologies (ICT). ICT has become so ubiquitous and integrated with social behavior that the distinction between social and technical interactions becomes arbitrary at best. A street protester who snaps a camera phone picture and emails it instantly across the world may not be thinking about computers, but is using an enormous computing system nonetheless. The potential of these social and technical interactions and relationships has the potential to transform political (witness Iran), economic (witness eBay) and organizational behavior (witness AirNow). These new capabilities support highly computing-based social systems that must work within the evolving global network of dependencies. Governments strive to combat terrorism, manage air quality, and promote international commerce by jointly constructing new knowledge sharing systems. The transnational effects of these new forms of computing based social systems remain poorly understood, as do the related threats and opportunities. The US and others must produce scholars trained in methodological tools to work effectively on research questions associated directly with international computing-based social systems. International engagement demands deep understanding of how these new systems affect the way nations and cultures respond to public needs and engage one another in response to transnational problems, like air pollution. This grant will begin to develop new social ICT models and tools for computing-based knowledge sharing across geographic and political boundaries focused on air pollution. This will be based on study of current and proposed international efforts at collaboration on air quality monitoring and reporting systems. It encompasses both comparative and transnational work in the domain of air quality monitoring and reporting systems in the US, Mexico, and China.<br\/><br\/>The following research questions will guide the work:<br\/>o How do participants in different countries perceive the dimensions, stakeholders, benefits, and risks of engaging in intergovernmental systems for information and knowledge sharing?<br\/>o What are the similarities and differences in these perceptions? What cultural, political, economic, and social factors might account for them?<br\/>o How do the participants attempt to create shared understanding of technologies, context, terms, processes, and contingencies that generate capabilities for effective action?<br\/>o Which strategies, tools, and behaviors are more likely to lead to successful international knowledge networks that benefit individuals, organizations, and communities?<br\/>o What preparation, methods and tools are best suited for research on these questions?<br\/><br\/>Intellectual merit<br\/>This proposal begins to build a knowledge base of cross-cultural investigations and empirical case studies of how new social ICT systems can be used on information-intensive international problems. The case studies and cross-case analyses will provide new comparative material and contribute to improved methodologies for cross-cultural research. The case analyses will lead to new testable models of information flow that accompany interactions and dependencies that cross national boundaries and cultures, as well as a future research agenda to refine both models and the methodologies.<br\/><br\/>Broader Impacts<br\/>This work extends information sharing and integration research to cross-national settings in which two or more countries share responsibility for a common problem, need, or initiative. In addition, the program will enlarge a collegial network and equip faculty and students to conduct research on problems of international or global import with deeper understanding of cultural factors and with the application of rigorous methodologies. This capacity-building feature will have long-lasting effects in the form of international science partnerships. Links to government officials as research hosts and advisors will provide not only research context and venues, but also opportunities to share findings that inform more culturally-aware public policies and government practices. The project will also lay the groundwork for teaching cases, course modules, and other curricular material.","title":"Understanding Cross-Boundary Knowledge Networks in the Context of Information-Intensive Transnational Problems","awardID":"0955057","effectiveDate":"2009-09-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[433032,"551444","433610"],"PO":["565136"]},"150862":{"abstract":"Transformative research is conducted via computational analyses of large data sets in the terabyte and petabyte range. These analyses are often enabled by scientific workflows, which provide automation and efficient and reliable execution on campus and national cyberinfrastructure resources. Workflows face many issues related to data management such as locating input data, finding necessary storage co-located with computing capabilities, and efficiently staging data so that the computation progresses but storage resources do not fill up. Such data placement decisions need to be made within the context of individual workflows and across multiple concurrent workflows. Scientific collaborations also need to perform data placement operations to disseminate and replicate key data sets. Additional challenges arise when multiple scientific collaborations share cyberinfrastructure and compete for limited storage and compute resources. This project will explore the interplay between data management and computation management for these scenarios. The project will include the design of algorithms and methodologies that support large-scale data management for efficient workflow-based computations composed of individual analyses and workflow ensembles while preserving policies governing data storage and access. The algorithms will be evaluated regarding their impact on performance of synthetic and real-world workflows running in simulated and physical cyberinfrastructures. New approaches to data and computation management can potentially transform how scientific analyses are conducted at the petascale. Besides advancing computer science, this work will have direct impact on data and computation management for a range of scientific disciplines that manage large data sets and use them in complex analyses running on cyberinfrastructure.","title":"DC: Medium: Intelligent Data Placement in Support of Scientific Workflows","awardID":"0905032","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["535329","491371"],"PO":["493916"]},"161411":{"abstract":"Numerous images on the internet call for efficient and effective image search algorithms to help users to find images that contain the object of interest. The current state-of-the-art image-search methods usually represent an object of interest as a set of features and localize the object by searching for a rectangular window that covers the desirable features. Without considering spatial relations among the features, these methods usually suffer from a low discriminative power and a high false positive rate. Instead, this EAGER project formulates object localization as a global feature grouping problem, where detected features are grouped according to some general spatial relations, such as group convexity, the separation of boundary and internal features, and feature affinities. The optimal feature grouping is achieved by using new graph models and approaches. Within this formulation, the search window is a tighter bounding polygon rather than a rectangle.<br\/><br\/>By considering spatial relations and tighter bounding polygons, the feature-grouping approach developed in this project is expected to produce a significant improvement over existing image-search methods, which can be verified by testing on a standard data set. The source code developed in this project is planned to be made publicly accessible upon completion of this project. This research is focused on object localization, which can also benefit many other computer-vision applications, such as scene matching and reconstruction, object detection and recognition, content-based video retrieval, and video surveillance.","title":"EAGER: Grouping Features for Object Localization and Image Search","awardID":"0951754","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["451161"],"PO":["564316"]},"150884":{"abstract":"The recent development of various government and University funded screening centers has provided the academic research community with access to state-of-the-art high-throughput and high-content screening facilities. As a result, chemical genetics, which uses small organic molecules to alter the function of proteins, has emerged as an important experimental technique for studying and understanding complex biological systems. However, the methods used to develop small-molecule modulators (chemical probes) of specific protein functions and analyze the phenotypes induced by them have not kept pace with advances in the experimental screening technologies. Developing probes for novel protein targets remains a laborious process, whereas experimental approaches to identify the proteins that are responsible for the phenotypes induced by small molecules require a large amount of time and capital expenditure. There is a critical need to develop new methods for probe development and target identification and make them publicly available to the research community. Lack of such tools represents an important problem as it impedes the identification of chemical probes for various proteins and reduces our ability to effectively analyze the experimental results in order to elucidate the molecular mechanisms underlying biological processes. <br\/><br\/>Intellectual Merit <br\/>This project will develop novel algorithms in the areas of cheminformatics, bioinformatics, and machine learning to analyze the publicly available information associated with proteins and the molecules that modulate their functions (target-ligand activity matrix). These algorithms will be used to develop new classes of computational methods and tools to aid in the development of chemical probes and the analysis of the phenotypes elicited by small molecules. The key hypothesis underlying this research is that the target-ligand activity matrix contains a wealth of information that if properly analyzed can provide insights connecting the structure of the chemical compounds (chemical space) to the structure of the proteins and their functions (biological space). Novel methods will be developed to: (i) better analyze the screening results and identify high affinity and selective hits, (ii) build models that can predict the compounds that are active against a novel protein target and select a set of compounds to be included in a high-throughput screen that will be enriched in actives, (iii) virtually generate a set of core molecules (scaffolds) for a given protein target that can be significantly different from those currently available in the various libraries and have a high probability of being active against the target, and (iv) identify the proteins being targeted by compounds in phenotypic assays. In addition, the research will be facilitated by creating a database to integrate a large portion of the publicly-available target-ligand binding data along with information about the targets and the compounds involved. The successful completion of this research will transform the &#64257;eld of chemical genetics by establishing a new methodology by which the increasing amount of target-ligand activity information is used in a systematic way to explicitly guide the discovery of new probes and the analysis of phenotypic assays. <br\/><br\/>Broader Impact <br\/>The ability to discover chemical probes for a wide range of novel protein targets will make it possible to identify drugs for pharmaceutically relevant proteins, positively impacting the rate of drug discovery. In addition, it will greatly increase the set of proteins that can be selectively modulated via small organic molecules, expand the various biological processes that can be investigated via chemical genetics approaches, and allow researchers to use chemical genetics techniques to gain insights on the mechanisms of action associated with certain phenotypes. This will provide a better understanding of the dynamics of these processes and will supplement existing approaches based on molecular genetics. To further aid in the broad dissemination of the results and enhance scientific understanding, the computational methods developed will be made freely available via stand-alone or web-based services to aid researchers working in the area of chemical genomics. Finally, the project integrates the research with an educational plan that focuses on interdisciplinary undergraduate, graduate, and post-graduate education in the areas of Computer Science, Medicinal Chemistry, and Chemical Genetics. <br\/><br\/>Key Words: supervised learning; semi-supervised learning; cheminformatics; structural bioinformatics; data mining; graph algorithms","title":"III: Medium: Collaborative Research: Computational Methods to Advance Chemical Genetics by Bridging Chemical and Biological Spaces","awardID":"0905117","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["565089"],"PO":["565136"]},"150895":{"abstract":"It is often assumed that the use of robots to help people execute tasks will result in better performance than if the person or robot were operating alone. However, research in automated systems suggests that the performance of a human-machine system depends on the extent to which the person trusts the machine and the extent to which this trust (or distrust) is justified. As robots are being developed to aid people with complex tasks, it is critical not only that we build systems which people can trust, but that these systems also foster an appropriate level of trust based on the capabilities of the systems. A user who does not have an appropriate level of trust in the robot may misuse or abuse the robot's autonomous capabilities or expose people to danger. This project proposes to develop quantitative metrics to measure a user's trust in a robot as well as a model to estimate the user's level of trust in real time. Using this information, the robot will be able to adjust its interaction accordingly. <br\/><br\/>Promoting appropriate levels of trust will be particularly beneficial in safety-critical domains such as urban search and rescue and assistive robotics, in which users risk harm to themselves, the robot, or the environment if users do not trust the robot enough to rely on its autonomous capabilities. The research has the potential for a large impact on the field of human-robot interaction as few studies have explicitly examined issues involving trust of robots. Being able to model trust and foster appropriate levels of trust will result in more effective use of robotic automation, safer interactions, and better task performance.","title":"HCC: Medium: Collaborative Research: Development of Trust Models and Metrics for Human-Robot Interaction","awardID":"0905148","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["549680"],"PO":["565227"]},"160597":{"abstract":"The International Workshop on Cyber-Physical Systems: Closing the Loop is to be held in conjunction with Embedded Systems Week (ESWEEK) in Grenoble, France, October 11-16, 2009. The objectives of the Cyber-Physical Systems (CPS) workshop are to: (i) provide a forum for investigation of major challenges in addressing next-generation physical and engineered systems; (ii) promote collaboration and cooperation between CPS researchers in the United States and Europe; and (iii) stimulate discussions on research in CPS through panels, poster and break-out sessions.<br\/><br\/>With respect to intellectual merit, the emerging field of CPS requires close interaction and collaboration between experts from a variety of fields. CPS is of global importance and there are significant CPS research activities in the U.S., Europe and elsewhere. This workshop contributes to the planning and coordination of CPS research that plays a critical role in identifying new crosscutting scientific foundations for building high-confidence cyber-physical systems and bringing together stakeholders from academia, industry and government agencies with a global perspective.<br\/><br\/>With respect to broader impacts, this workshop can lead to advances in CPS with the potential for technological impact on a number of important application domains including energy, transportation, and healthcare. The workshop will facilitate diverse participation of U.S. researchers in the international ESWEEK event, including Ph.D. students and junior faculty. Efforts are made to towards broadening the participation of researchers from women and other underrepresented groups. The workshop, thus, has the potential to contribute to training the next generation of scientists, engineers, and designers for cyber-physical systems.","title":"International Workshop on Cyber-Physical Systems (WCPS'09): Closing the Loop -- To be held in conjunction with ESWEEK 2009. To Be Held in Grenoble, France, October, 11-16, 2009","awardID":"0946918","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["541836"],"PO":["565205"]},"153700":{"abstract":"Proposal Number: 0915718<br\/>Title: AF:Small:Coarse-Grained Algorithms for Soft Matter<br\/>Principal Investigator: N. R. Aluru <br\/>Institution: University of Illinois at Urbana-Champaign<br\/><br\/>Abstract<br\/><br\/>Soft matter (e.g. liquids, polymers, biopolymers, etc.) plays an important role in many emerging technologies in engineering and science. The physics of soft matter at macroscopic scales has been investigated for many decades. There is now a good understanding of how to manipulate soft matter at macroscopic scales. The physics of soft matter in confined environments (referring to the behavior of soft matter in constrained spaces) can be quite different from its macroscopic counterpart and many fundamental issues still remain. Soft matter in confined environments can find applications in important technological areas such as energy, health, sensing, sequencing, separation, etc. As a result, soft matter in confined environments has now gained significant interest from the scientific community. Various computational techniques can be used to understand physical, chemical and biological properties of soft matter. However, many of the existing techniques are either too expensive or not accurate enough to perform detailed studies. The objective of this research is to develop advanced computational algorithms to enable a detailed understanding of soft matter in confined environments. <br\/><br\/>Even though quantum-mechanical and atomistic molecular dynamics simulations can be used to understand soft matter in confined spaces, they are limited to small length and short time scales. Mesoscopic methods, such as Brownian dynamics, Monte Carlo, lattice Boltzmann, dissipative particle dynamics, etc., can be used to overcome the limitations of quantum and atomistic molecular dynamics simulations, but, structural accuracy is a key issue in these methods. The objective of this research is to develop novel coarse-grained algorithms where inter-atomic potentials, widely used in atomistic simulation of soft matter, are directly incorporated into advanced physical theories. The inter-atomic potentials will be coarse-grained to ensure structural consistency. The inter-atomic potential based coarse-grained algorithms will be applied for several challenging examples of soft matter. The accuracy of the structural prediction from coarse-grained algorithms will be compared with that from atomistic simulations. It is anticipated that inter-atomic potential based coarse-grained algorithms will be many orders of magnitude faster than purely atomistic simulations and the development of such algorithms will not only elucidate the fundamental aspects of soft matter in confined spaces, but will also lead to rapid computational prototyping of various applications of soft matter.<br\/><br\/>The proposed research is at the cross-roads of several engineering and science disciplines. As a result, the development of inter-atomic potential based coarse-grained algorithms for soft matter will impact several disciplines and application areas. Some of the application areas that could benefit from this fundamental research are energy, sensing, health, sequencing, separation, etc. The main efforts of this project will result in the education of students and postdoctoral associates in the highly interdisciplinary area of soft matter. The research results from this project will be broadly disseminated via journal and conference publications, presentations at meetings and workshops, software, courses taught by the PI in the Department of Mechanical Science and Engineering and summer schools offered at University of Illinois.","title":"AF:Small:Coarse-Grained Algorithms for Soft Matter","awardID":"0915718","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":["539633"],"PO":["565223"]},"153821":{"abstract":"0915928 - NeTS: Small: Collaborative Research: Supporting unstructured peer-to-peer social networking<br\/><br\/>09\/01\/09-08\/31\/12<br\/><br\/>G. de Veciana, PI, U.T. Austin, and G. Kesidis, PI, Penn State<br\/><br\/>Award Abstract:<br\/><br\/>Peer-to-peer systems have seen continued growth, in terms of traffic volume, and as the architecture of choice to build new applications and network services ? notable benefits lie in their distributed design leading to higher reliability and flexibility. However as users\/peers increasingly become content providers, and generally conduct more of their business on the network, privacy is a critical concern.<br\/><br\/>By leveraging peers? trust relationships through referral mechanisms based on underlying reputation systems, applications that deliver a new standard of privacy are being devised. Peer-to-peer systems that dynamically adapt, in a distributed and scalable manner, based on the outcomes of peer transactions, are being modeled and analyzed. The focus is on unstructured networks where peer-membership correlations among communities of interest can be learned to improve the search performance of reputation-biased random walks and limited-scope flooding. Content-sharing applications are being designed based that leverage this framework to incentivize cooperative behavior while enabling collaborative filtering and content pushing.<br\/><br\/>Expected results include the development analysis and testing of a new framework for privacy-preserving search for large-scale, unstructured, on-line, peer-to-peer networks. Complementary incentive mechanisms resulting in improve file sharing and promoting honest referrals will be devised. The results will be disseminated through peer-reviewed venues and, where possible, industry concerns, while data and simulation tools are made available on the web.<br\/><br\/>The efforts impact will lie in contributing new ways to improve privacy and promote more honest and efficient cooperation in large-scale on-line peer-to-peer systems, for content sharing, as well as a broader set of social networking applications.","title":"NeTS: Small: Collaborative Research: Supporting unstructured peer-to-peer social networking","awardID":"0916179","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["562302"],"PO":["565303"]},"153942":{"abstract":"Detection and analysis of branching structures and\/or texture is very challenging; it arises in many areas of science and engineering (e.g., medical images, chemical compounds, etc). The objective of this proposal is to develop novel approaches to model, detect, and analyze branching structures obtained from multimodality data. Such representation and analysis tools are expected to make many complex problems more tractable. Examples include identifying and recognizing a large number of structure classes; discovering new relationships among structure, texture, and function or pathology; evaluating hypotheses; developing modeling tools; assisting with surgical design; and managing medical image data efficiently. <br\/>Specifically, the investigators plan to explore three research topics under this project: (1) To develop descriptors of branching structures and texture, and knowledge discovery tools that will enable hypotheses generation and evaluation and improve modeling of branching structures; (2) To design automated algorithms and a flexible framework to detect branching structures. The investigators are especially interested in addressing challenges of occlusion and topology change; (3) To demonstrate the applicability of the proposed tools to breast imaging by building a prototype database of images from various modalities and associated clinical data that will provide advanced analysis and visualization capabilities. <br\/>Though the investigators use breast imaging as the driving application, the proposed project is expected to provide software and data resources that can assist clinical tasks and scientific discoveries in general. Developing automated tools to effectively characterize, detect, and classify tree-like structures in images would provide great insight into the relationship between the branching topology and function or pathology. The investigators plan to further contribute to the medical\/scientific community by disseminating the related software and annotated data sets. <br\/>The educational goals include incorporating research findings to graduate courses at Temple (data mining course and medical image analysis seminar) and at the University of Pennsylvania (medical image analysis course).","title":"III: Small: Collaborative Research: Modeling, Detection, and Analysis of Branching Structures in Medical Imaging","awardID":"0916690","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[409627],"PO":["565136"]},"152611":{"abstract":"This project develops a high-level notion of context that exploits the capabilities of next generation networks to enable applications that deliver better user experiences. In particular, it exploits mobile devices -- always with a user -- to capture key elements of context: the user's location and, through localization, characteristics of the user's environment. What matters for the user experience is the user's place: a location in conceptual terms such as \"at home,\" \"jogging,\" or \"grocery shopping\" -- descriptions that combine positions with activities, environmental properties, and the activities of other nearby people. Realizing this notion of place requires that information from devices and infrastructure flow in ways unanticipated in current network architectures. It presumes enabling opportunistic interactions while preserving the users' privacy and designing incentive mechanisms to promote cooperation without exploitation of any. The above architectural concerns lie far beyond traditional network topics such as routing.<br\/><br\/>This project will develop, demonstrate, and evaluate a novel network architecture that gives primacy to user experience. It will lead to theoretical advances in semantic context modeling, mobility tracking at multiple levels of abstraction, collaborative localization, and incentive mechanisms. Networked applications offering enhanced user experience will have significant payoffs for industry and the productivity and quality of life of citizens. A prototype system will implement and evaluate context-aware services in university settings with prospects of expansion to K-12 schools and public facilities.","title":"NetSE: Large: Collaborative Research: Platys: From Position to Place in Next Generation Networks","awardID":"0910846","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["462630"],"PO":["565342"]},"153832":{"abstract":"The goal of this research project is to provide a framework model that integrates existing models of indoor and outdoor space, and to use this model to develop an interactive platform for navigation in mixed indoor and outdoor spaces. The user should feel the transition between inside and outside to be seamless, in terms of the navigational support provided. The approach consists of integration of indoors and outdoors on several levels: conceptual models (ontologies), formal system designs, data models, and human interaction. At the conceptual level, the project draws on existing ontologies as well as examining the \"affordances\" that the space provides. For example, an outside pedestrian walkway affords the same function as an inside corridor. <br\/><br\/>Formal models of place and connection are also used to precisely specify the design of the navigational support system. Behavioral experiments with human participants assess the validity of our framework for supporting human spatial learning and navigation in integrated indoor and outdoor environments. These experiments also enable the identification and extraction of the salient features of indoor and outdoor spaces for incorporation into the framework. Findings from the human studies will help validate the efficacy of our formal framework for supporting human spatial learning and navigation in such integrated environments. <br\/><br\/>Results will be distributed using the project Web site (www.spatial.maine.edu\/IOspace) and will be incorporated into graduate level courses on human interaction with mobile devices, shared with public school teachers participating in the University of Maine?s NSF-funded RET (Research Experiences for Teachers). The research teams are working with two companies and one research center on technology transfer for building indoor-outdoor navigation tools with a wide range of applications, including those for the persons with disabilities.","title":"III:Small: Information Integration and Human Interaction for Indoor and Outdoor Spaces","awardID":"0916219","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[409353,"561515"],"PO":["563751"]},"161213":{"abstract":"This is an EAGER project that addresses a highly exploratory investigation into key elements needed to specify the characteristics of an operating system (OS) in a way that permits an architectural model to be created that interacts fully with a suite of simulation tools.<br\/><br\/>The suite of tools, CoGenT (CoGeneration of Tools), include specification languages to allow researchers to express novel instruction sets and micro-architectures and the infrastructure for automatic generation of corresponding functional and timing co-simulators, compilers, linkers, loaders, debuggers, assemblers, disassemblers, and a fully integrated instrumentation facility to enable meaningful experimentation within this new design space. CoGenT?s ability to automatically generate a functional simulator from a specification, and other related elements, will be released this year.<br\/><br\/>This EAGER addresses the problem that, in simulating complex architectures, it is important to be able to specify OS support, not just as a set of external calls, but as a specific model that integrates with the rest of the architecture. Current architectures rely on the services and policies of the operating system, and the operating system itself needs to evolve with the radical shifts in architecture and applications that are anticipated in the next decade.<br\/><br\/>With this project, this team develops an approach that enables simultaneous research into novel hardware and software paradigms, with great flexibility, and without the heretofore prohibitive cost of manually building a complete hardware and software simulation infrastructure with a tailored OS implementation. Traditional system simulation approaches either ignored OS impact on performance or resorted to costly and inflexible full system simulation where an actual OS implementation is executed directly. The former provides unrealistic results, and the latter does not admit the kind of exploration needed for transformative paradigm shifts.<br\/><br\/>The goal of this project is to extend the relatively recent approach of functional and timing co-simulation for hardware architectures into \"pseudo-full system simulation\", where the OS becomes a first-class element in the simulation modeling and instrumentation framework. Simulating an OS model derived from a specification will also enable sensitivity and significance analyses, often neglected in current simulation-based research even though they are essential to understanding the real impact of new approaches.","title":"Describing the Operating System for Accurate User-mode Simulation","awardID":"0950410","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["517880","550864"],"PO":["535244"]},"153722":{"abstract":"The staff in trauma centers are faced with complex problems under time pressure.<br\/>Despite the introduction of standard protocols, the diversity of injuries that can occur<br\/>requires a coordinated approach to the evaluation and treatment for each patient.<br\/>Trauma care involves complex teamwork under time pressure, and teamwork errors<br\/>endanger patient care and increase costs. Our proposed ethnographic study will use<br\/>observation and detailed analysis of video recordings of trauma resuscitations to<br\/>determine the nature and extent of teamwork errors in a trauma center. This detailed<br\/>study of complex teamwork will uncover the causes of teamwork errors in collaborative<br\/>high-risk environments. Methods will be developed to understand how teams work and<br\/>where difficulties arise. This work will yield detailed descriptions of errors and their<br\/>causes, a taxonomy of teamwork errors, information on how to improve team<br\/>performance, and guides to the use of technology for teamwork support. It extends the<br\/>level of detail of ethnographic research so that we can achieve precision in the<br\/>understanding of procedures which are difficult to monitor automatically but where<br\/>step-by-step records are essential to detect the causes of errors.<br\/>Understanding and improving the effectiveness of trauma teams has direct benefit to<br\/>society. Further, complex collaborations are ubiquitous in modern enterprises and these<br\/>results could improve collaborations both in terms of quality and productivity across<br\/>organizations. In addition, this work will serve to develop the skills needed by a new<br\/>cadre of researchers with knowledge of computer-supported collaborative work,<br\/>video-content analysis and cooperative research.","title":"HCC-Small: Collaborative Research: Assessing Technology Requirements for Preventing Teamwork Errors in Safety-Critical Settings","awardID":"0915812","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[409084],"PO":["564456"]},"153843":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).<br\/><br\/>The main goal of this project is to develop a tagging method which neither relies on target-language training data nor requires bilingual dictionaries and parallel corpora. The main assumption is that a model for the target language can be approximated by language models from one or more related source languages.<br\/><br\/>Exploiting cross-lingual correspondence leads to a better understanding of 1) what linguistic properties are crucial for morphosyntactic transfer; 2) how to measure language similarity at different levels: syntax, lexicon, morphology; 3) how this method applies to pairs that do not belong to the same family; 4) what determines the success of the model, and 5) how to quantify its potential for a given language pair. By exploiting cross-language relationships, the size, and hence cost, of the training data are significantly reduced. <br\/><br\/>This project is a new cross-fertilization between theoretical linguistics (especially typology and diachronic linguistics) and natural language processing. The practical contribution is a robust and portable system for tagging resource-poor languages. With this new approach, it is be possible to rapidly deploy tools to analyze a suddenly critical language. This approach can also enhance NSF's initiatives in documenting endangered low density languages as it leverages exactly the type of knowledge that a field linguist and a native speaker could provide. Additional benefits include high quality annotated data, automatically derived multilingual lexicons, annotation schemes for new languages, new typological generalizations, and graduate and undergraduate researchers with significant experience of highly practical work on difficult and underrepresented languages.","title":"RI: Small: RUI: Resource-light Morphosyntactic Tagging of Morphologically Complex Languages","awardID":"0916280","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550607"],"PO":["565215"]},"153964":{"abstract":"The long-term practical objective of this research project is to develop simulated training environments that mesh with the constraints of perceiving and enacting actions in the real world. Simulated environments differ from real environments in a number of aspects. In particular, there are significant differences in perceptual and motor features between these environments. Advances in embodied cognitive science have consistently demonstrated how the body, and the environment which it inhabits, are tightly coupled with the mind, and together they form a complex system for perception and action. The central questions being investigated in this research involve identifying the conditions that promote perceiving and enacting actions in simulated training environments, and include questions such as: (a) whether high fidelity simulation environments and perceptual motor cues signaling risk are necessary ingredients to enhance training effectiveness; (b) whether performance pressure is a necessary component in training paradigms; (c) the extent to which bodily interactivity with the training environment is necessary; and (d) the extent to which individual differences in perception and action contribute to training effectiveness of simulated environments. This research project also begins to investigate whether encoding events in language that selectively focus on particular conceptual components can be used as an effective mechanism to guide visual attention. Simulation environments will be modeled after real world events, and will vary the degree of user control and level of immersion. Research participants will have their eye movements recorded, mark off when a meaningful event ends and another begins, perform perceptual mental simulation tasks by identifying the correct bodily movements, or manipulate user controlled simulation environments. <br\/><br\/>This research project investigates how people spontaneously engage in riskier behaviors due to differences between simulated environments and the real world, whether putting people under some pressure is critical for successful training in simulated environments, and what type of physical interactivity with simulated environments is essential for optimal performance. This research also investigates whether differences in cognitive abilities and personality types have effects on performance in simulated environments. This project uses multiple methods in an attempt to understand along which dimensions training in simulated environments can effectively transfer to real world practice. This research pushes forward the frontiers of perceiving and enacting actions in psychology, computer science, robotics, and human computer interactions. The results will form an empirical basis promoting the development of improved methods for training in simulated worlds. Improved designs of simulated worlds for training and modeling are increasingly important in many areas of our society including: impacts in education, military, law enforcement and emergency response organization training; smart environments for the better treatment of disabled or special needs populations; and entertainment industries and the arts.","title":"HCC: Small: Perceiving and Enacting Actions in Simulated Environments: The Role of Perceptual Motor Features and Individual Differences","awardID":"0916749","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[409689,409690,409691],"PO":["565227"]},"160256":{"abstract":"The ACL2 theorem prover has an established user community in industry,<br\/>government, and academia. ACL2 supports industrial-scale verification<br\/>projects by combining automation and controllability, but its<br\/>extensibility is limited: its large (10 MB), complex code base<br\/>requires, for soundness, that it be entrusted solely to its two<br\/>authors. The PIs propose to modify ACL2 radically, opening up the<br\/>system by making it more modular, thus enabling trusted development by<br\/>untrusted users while maintaining proof security. Key challenges are<br\/>to expose the functionality of system components, and to separate out<br\/>a trusted core from code that need not be trusted for correct<br\/>functionality, such as code implementing heuristics, I\/O, theory<br\/>management, and interactive proof development and debugging. Code<br\/>refactoring is already a hard problem, especially for a system with<br\/>the complexity of ACL2, but in this project there is also the<br\/>challenge of making the resulting system modifiable in a way that does<br\/>not compromise logical soundness.<br\/><br\/>Expected results include an ACL2 system that can be modified soundly<br\/>by users according to specific needs. In particular, research on<br\/>teasing apart inherently sequential output from reasoning code should<br\/>support research on parallel reasoning algorithms taking advantage of<br\/>modern multi-core machines, leading to formally verified parallel<br\/>implementations. More generally, the system will provide a platform<br\/>that promotes research in heuristics for automating reasoning. It<br\/>will also facilitate the customization of ACL2 for use in the<br\/>undergraduate classroom. The resulting system will be freely<br\/>distributed on the Internet.","title":"TC: EAGER: Modularization Supporting Extensibility for an Industrial-strength Theorem Prover","awardID":"0945316","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[428590,"503869",428592],"PO":["565264"]},"153612":{"abstract":"As the web continues to play an increasing role in information<br\/>exchange, so too is it becoming the prevailing platform for infecting<br\/>vulnerable hosts. One commonly deployed strategy for delivering<br\/>web-malware involves the underhanded tactic of targeting browser<br\/>vulnerabilities to automatically download and run malicious software<br\/>upon visiting a website. When popular websites are exploited, the<br\/>victim base from these so-called drive-by downloads can be far greater<br\/>than other forms of exploitation because traditional defenses (e.g.,<br\/>firewalls) pose no barrier to infection. Unfortunately, with the<br\/>plethora of (insecure) web applications being deployed today, it is<br\/>likely that web servers will continue to be popular targets for<br\/>exploitation for the foreseeable future.<br\/><br\/>One of our primary goals is to take an in-depth look at the malware<br\/>serving network on the Web by building a scalable malware execution<br\/>and analysis infrastructure. Specifically, we plan to build a<br\/>resource-efficient host architecture that permits lightweight process<br\/>monitoring via tracking of interactions with the OS. An important<br\/>facet of our research direction is to explore a transactional<br\/>framework that unifies virtualization and logging to allow efficient<br\/>analysis. In this framework, the granularity of recorded transactions<br\/>is dynamically adjusted based on execution contexts, aggregating<br\/>multiple transactions to a single, summarized, transaction whenever<br\/>possible. Broader impats of this project will result from the<br\/>comprehensive analysis of the different aspects of the problem posed<br\/>by web-based malware, and the tools, methods, and analytical<br\/>techniques that will ultimately allow for large-scale malware analysis<br\/>by the security community at large.","title":"TC: Small: Collaborative Research: Scalable Malware Analysis Using Lightweight Virtualization","awardID":"0915291","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["542388"],"PO":["565327"]},"153733":{"abstract":"The proposal is to support multi-stage queries by integrating knowledge from across different queries, creating a \"knowledge mosaic.\" This approach, if successful could radically improve and extend web search from one of primarily fact-finding to one of fact-finding and problem solving using a set of related queries which find pieces of information which are then \"stitched together\" such that relationships and links between the information can be better revealed. The approach to problem-solving becomes one of using a set of related queries which find out portions of information on graph models, building the knowledge mosaic using RDF and other graph-based Semantic Web technologies and extending a proposed new query language SPARQ2L The resultant view keeps track of what knowledge has been found, and attempts tto combine it in useful ways to provide a more complex knowledge view for the information the user seeks to discover. The research could have pronounced impact on how search and discovery is performed on the web.","title":"III:Small : MOSAIC - Advanced Querying Paradigms For Supporting Discovery Oriented Tasks on the Semantic Web","awardID":"0915865","effectiveDate":"2009-09-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["518218"],"PO":["563727"]},"152523":{"abstract":"Information and communication technology (ICT) promises to help reduce impacts of large-scale disruptions from natural hazards, pandemics, and terrorist threat. This research focuses on a critical aspect of large-scale emergency response -- the needs and roles of members of the public. By viewing the citizenry as a powerful, self-organizing, and collectively intelligent force, ICT can play a transformational role in crisis situations. This view of a civil society augmented by ICT is based on socio-behavioral knowledge about how people behave in crisis, rather than on simplified and mythical portrayals. With a critical reframing of emergency response as a socially-distributed information system, the project aims to leverage the knowledge of members of the public through reuse of publicly available computer mediated communications (CMCs) (e.g., community, mapping, and social networking sites; blogs; Twitter). The project will study and integrate that heterogeneous information and -- with techniques of information extraction through natural language processing as well as trust and reputation modeling -- add meta-information to help users assess context, validity, source, credibility, and timeliness to make the best decisions for their highly localized, changing conditions.<br\/><br\/><br\/>The results of this research addresses matters of policy, practice and technological innovation, responding directly to needs identified in national policy statements, including Grand Challenge #1 of the National Science and Technology Council's Subcommittee on Disaster Reduction, which calls for the provision of \"hazard and disaster information where and when it is needed\" (SDR, 2005). At-risk populations are disproportionately affected by crises; the results of this research could mitigate the impacts on these communities. The research is also inclusive of people across different cultures\/ethnic groups within the U.S. and from different countries. The project broadens the future STEM workforce, since socio-technical and practical orientations to computational research attract women to study STEM disciplines. The research contributions include cyberinfrastructure-aware applications, techniques, and services built from empirical knowledge of the social structures that produce crisis data.","title":"HCC: Large: Collaborative Research: Widescale Computer-Mediated Communication in Crisis Response: Roles, Trust & Accuracy in the Social Distribution of Information","awardID":"0910586","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["24532","530768","489545","543626"],"PO":["565227"]},"153503":{"abstract":"When humans speak to each other and want the dialogue to go well, they adapt to each other?s manner of speaking, using the same words, grammatical constructions and expressions. In order to make fundamental improvements in the performance of spoken dialogue systems, LexE is using subtle techniques to model this adaptation, which is called lexical entrainment. LexE is getting users to adapt their speech to the system, as well as getting the system?s speech to adapt to what the user says. To do this, LexE studies human-human dialogues to find the words and constructions (the ?primes?) that are often adopted by dialogue participants. The spoken dialogue system then uses these primes in its output. The system also detects the expressions that its user employs to refer to objects uses them in its synthetic speech. <br\/>Two real-user spoken dialogue systems are being used as test platforms for LexE. The first is a bus information system for the Port Authority of Allegheny County; the second is the City of Pittsburgh 311 non-emergency service. By making these publicly-available spoken dialogue systems easier to use, LexE makes them (and other spoken dialogue systems) more accessible to a large part of our population, many of whom, the elderly, for example, get much of their information over the telephone. The techniques developed in this project also provide insights for the education of non-native speakers and for speech therapy, where tutoring systems can imitate the way humans implicitly correct errors in what their interlocutors say.","title":"RI: SMALL: LexE: Using Two-part Lexical Entrainment for More Efficient and Reliable Spoken Dialogue Systems","awardID":"0914927","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["561898"],"PO":["565215"]},"153745":{"abstract":"The research involves the design and analysis of efficient algorithms for fundamental problems that arise in studies of the three-dimensional structures of proteins. Graph-theoretic problems underlie these studies, since protein structures are naturally (and sufficiently) represented by graphs that have vertices for the individual amino acid residues and edges between close pairs. However, graph-theoretic formalisms lead to computationally hard optimization problems, further complicated by extensive amounts of noise in experimental data. Motivated by specific challenges in nuclear magnetic resonance spectroscopy and other protein structure studies, the project addresses two significant algorithmic problems: identifying correspondences between a pair of graphs where one is a significantly corrupted version of the other, and determining three-dimensional coordinates for the vertices of a graph, given approximate, noisy distance measurements for its edges.<br\/><br\/>The first algorithmic problem is a form of graph matching, and the project focuses on developing efficient search algorithms to uncover correspondences, with random graph models to rigorously analyze the algorithms and study threshold phenomena characterizing robustness to noise. In an application to analysis of NMR data, one of the graphs represents the protein and the other the data, a noisy, ambiguous set of atomic interactions; the goal is to match the NMR-identified interactions with specific atomic interactions in the protein. The second algorithmic problem is Euclidean embedding for sparse geometric graphs, and the research involves development of algorithms to render such graphs amenable to low rank distance matrix reconstruction methods, generalizing the reconstruction methods to exploit the underlying geometric structure and account for the confounding noise structure. In the NMR setting, the graph represents NMR-probed through-space atomic interactions, and the goal is to compute structures consistent with the experimental data and biophysical constraints. Both problems are fundamental to numerous other significant applications in protein structure studies.","title":"AF:Small:Collaborative Research: Algorithmic Problems in Protein Structure Studies","awardID":"0915916","effectiveDate":"2009-09-01","expirationDate":"2010-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["454047"],"PO":["565223"]},"153866":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Securing cyberspace is one of the top priorities in protecting our national infrastructure. As wireless ad hoc networks (WANETs) have been built to access or been parts of the Internet, they become the weakest links which should be secured and protected. This project investigates security issues in WANETs, such as trust establishment and management, secure connectivity, efficient secure routing and their performance, by utilizing the social network theory (including tools such as graph theory, percolation theory and hyperbolic geometry). First, the results in empirical social network studies are utilized to improve our understanding of the properties of the trust and physical network graphs, the existence and distribution of secure paths, and secure connectivity in WANETs. Second, by mimicking the social behavior of individuals, new methodologies are established to design efficient and scalable multi-hop communication schemes in WANETs. Finally, the project investigates the secure efficiency of a WANET as the end-to-end secure throughput and delay and conduct formal analysis of secure network performance and trade-off between security and throughput\/delay. This project opens a new research direction in wireless networks and invents novel network design methodologies.<br\/><br\/>The proposed research has broad impacts in many aspects including securing national cyberspace, creating multidisciplinary research themes mixing sociology, mathematics and wireless networks, disseminating the research findings to multiple communities of interest through publications in journals and conferences, and training the future multidisciplinary work force for telecommunications and information industries.","title":"NeTS:Small: How to Exploit Social Network Theory in Designing Secure Wireless Networks","awardID":"0916391","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560200"],"PO":["557315"]},"153987":{"abstract":"In order to provide system security, hardware modules which function as trust anchors are used in an ever increasing number of devices. The majority of laptops and PCs are now equipped with Trusted Platform Modules (TPMs), and a large number of pervasive computing systems such as smart cards, electronic passports or high-speed routers make use of hardware for cryptographic algorithms and key storage. In almost all such applications the security of the entire system hinges on the assumption that the hardware modules are trustworthy. Recently, due to the increasing use of potentially untrusted semiconductor foundries, the threat of maliciously manipulated hardware has been raised, Since hardware manipulations, including hardware Trojans, are difficult to detect and, perhaps more importantly, even harder to repair, they form a very serious threat to system security for today's and future applications.<br\/><br\/>The standard approach to Trojan hardware consists in adding extra logic to a given IC design which weakens the system. The main drawback of this approach, from an attacker's perspective, is that extra function blocks can potentially be detected through a host of techniques, including, e.g., optical inspections at different layers of the design, or power and EM fingerprinting. Our malicious circuit manipulations are orders of magnitude more subtle than previously known Trojans, but can nevertheless totally compromise secure hardware blocks by leaking cryptographic keys. The core idea is to create malicious side-channels, in particular power supply channels, through small modifications of circuit elements, e.g., at the transistor level. We will refer to these covert channels as Trojan side channels (TSC). The core parts of the research are modeling of the assumptions, development of channels and modulations schemes, their realization on the circuit level, and proof-of-concept implementations.<br\/><br\/>In addition to posing a threat to system security, Trojan side-channels can also be used constructively. For instance, they have applications in anti-counterfeiting: illegal copies of ICs with the same functional behavior will not leak the same side-channel ID and can thus easily be detected. Also, TSC could be used for conveying internal status information about a circuit, increasing the testability of a circuits. Moreover, because TSC can be viewed as a form of physically encryption one can imagine other cryptographic protocols and applications using TSC as primitives.","title":"TC: Small: Minimalist Hardware Trojans through Malicious Side-Channels","awardID":"0916854","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["549951","438750"],"PO":["564388"]},"153635":{"abstract":"Device drivers constitute a large fraction of the code in commodity operating systems. Over 35,000 drivers with over 112,000 versions exist for Windows XP, while over 3.1 million lines out of 5.4 million lines of the Linux kernel is device driver code. As several recent exploits against device drivers show, drivers are rife with bugs that compromise system security.<br\/><br\/>Exploits against device drivers are dangerous because commodity operating systems execute drivers in kernel address space. A compromised driver can modify kernel data structures or execute arbitrary code with kernel privilege. Prior techniques that protect commodity OS kernels from device drivers either suffer from low performance or are limited to specific classes of vulnerabilities, such as memory errors.<br\/>Inspired by user-mode driver frameworks, this project applies a three-pronged approach to the problem of protecting kernel data from vulnerabilities in device drivers. First, this project will develop techniques to monitor kernel data structure updates initiated by device drivers and ensure that they do not compromise the integrity of these data structures. Second, it will develop techniques to limit driver access to kernel memory via DMA without requiring hardware support yet taking advantage of it if available. Third, it will develop new techniques for recovering from compromised drivers.<br\/><br\/>These techniques are applicable to legacy device drivers on standalone commodity operating systems and require minimal changes to the operating system. In addition, they impose negligible overheads on common-case performance of device drivers and are thus practical for use even with high-throughput devices.","title":"TC: Small: Collaborative Research: Protecting Commodity Operating Systems from Vulnerable Device Drivers","awardID":"0915394","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486426"],"PO":["565327"]},"153756":{"abstract":"To take full advantage of the parallelism offered by a multicore<br\/>machine, one must write parallel code. Writing parallel code is<br\/>difficult. Even when one writes correct code, there are numerous<br\/>performance pitfalls. For example, an unrecognized data hotspot could<br\/>mean that all threads effectively serialize their access to the<br\/>hotspot, and throughput is dramatically reduced.<br\/><br\/>This project aims to provide a generic framework for performing<br\/>certain kinds of concurrent operations in parallel. Infrastructure is<br\/>provided to perform those operations in a scalable way over the<br\/>available threads in a multicore machine, automatically responding to<br\/>hotspots and other performance hazards. The goal is not to squeeze<br\/>the last drop of performance out of a particular platform. Rather,<br\/>with the planned system a programmer can, without detailed knowledge<br\/>of concurrent and parallel programming, develop code that efficiently<br\/>utilizes a multicore machine.<br\/><br\/>The project involves the development of algorithms and data structures<br\/>designed for the efficient parallel execution of generic code<br\/>fragments. The primary focus is on data intensive operations as would<br\/>typically be found in an in-memory database engine. Critical research<br\/>questions include how to design generic multi-threaded operators that<br\/>can be applied to a range of computations, how to avoid cache<br\/>thrashing, and how to implement the framework in a way that works on a<br\/>variety of hardware platforms. Performance improvements in throughput<br\/>of an order of magnitude are expected relative to naive solutions that<br\/>suffer from contention. The project aims to achieve performance close<br\/>to that of hand-tailored expert-written parallel code, with far less<br\/>coding effort.<br\/><br\/>This project has immediate applications in both commercial and<br\/>public-domain database systems where performance improvements would<br\/>enhance the experience of database system users, and reduce hardware<br\/>and energy requirements for a given level of performance.<br\/><br\/>Programmability improvements would allow programmers without expertise<br\/>in parallel programming to effectively use multicore machines. The<br\/>project also provides the focus for an advanced-level course on<br\/>database system implementation for multicore machines. The software<br\/>infrastructure will be made available for research use by others.","title":"III: Small: Avoiding Contention on Multicore Machines","awardID":"0915956","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["531167"],"PO":["563727"]},"153525":{"abstract":"This project investigates hierarchical machine intelligence for modeling and composing complex soundscapes. We adapt methods for extracting time-dependent information from text documents to the problem of extracting spectral (graphical) patterns and the probabilities that they occur or co-occur in soundscapes. We are analyzing the spectral patterns that emerge from sound files of many types, including recordings of building interiors with regular foot traffic, musical files, and synthesized sound. A significant part of the research is in devising spectral features that are important for this kind of mapping\/identification. <br\/><br\/>Research under this award is also investigating the use of reinforcement learning (RL) to identify time-dependent 'landmarks' from soundscape models, and we employ RL agents to compose large soundscapes from thousands of millisecond length grains of sound in a process called granular synthesis. Systems of RL agents enable us to study distributed time-dependent RL agents in a complex environment, with the ability to produce aural demonstrations of the agents' learning. We also expect the system to produce some compositions that are pleasing in the electronic music sense.<br\/><br\/>This research will have an impact on curricular efforts in Arts and Technology at Smith College, supporting the Computer Science Department's efforts to attract more students, especially to research.","title":"RI:Small:RUI:Intelligent Soundscape Analysis and Generation","awardID":"0914988","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[408593],"PO":["565035"]},"153888":{"abstract":"This project considers the physical limits of communication in a wireless network and how these limits can be achieved by communication protocols in an effective way. Specifically, it aims at determining the fundamental limits of the capacity of the network using an innovative approach based on physics, rather than postulating random propagation channel models. The project focuses on the characterization of the amount of spatial diversity that a wireless networks can provide, which is shown to be one of the central issues to determine its capacity. The spatial diversity is quantified in terms of the dimensionality of the propagating field, which is what carries the information through the network. Hence, drawing connections between information theory, functional analysis of continuous vector spaces, electromagnetic theory, and networks, the project aims at developing an information theory for wireless networks. The project considers different geometric configurations of wireless network, and determines their corresponding number of spatial degrees of freedom. It then considers both the effects of narrow-band and wide-band frequency transmission. Results are in terms of scaling laws, as well as capacity laws that are not asymptotic in the number of nodes in the network.","title":"CIF: Small: A Space Dimension Approach for Wireless Netowrk Information Theory","awardID":"0916465","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["409707"],"PO":["564924"]},"153899":{"abstract":"Wireless sensor networks (WSNs) have been mainly used for data collection purposes, and have not been employed in the context of any consistency- or safety-critical applications. As such software development for WSNs has been done mostly on a best-effort basis. However, as WSNs get more integrated with actuation capabilities, the resulting wireless sensor actor networks (WSANs) require more assurance and survivability guarantees. The goal of this project is to design and implement the tool-support necessary for achieving assurance and reliability of WSANs software.<br\/><br\/><br\/>The project will produce a transformation tool that allows programs for WSANs to be written in high-level models traditionally used to describe abstract distributed programs and automatically transforms these abstract programs, while preserving their correctness and reliability properties, into programs deployed in WSANs. The project will also develop a synthesis tool that manipulates the given abstract distributed programs for the automated addition of desired level of fault-tolerance. Finally, the project will design a framework that guards against the corruption of the auxiliary state introduced at the concrete system to ensure that the deployed program is verifiably reliable.<br\/><br\/><br\/>This project will simplify the development of high assurance WSANs software, and has the potential to pave the way to high assurance cyber-physical systems development. The project will integrate research and education through coursework development, building and dissemination of systems software, and outreach to the wider community.","title":"CSR: Small: Collaborative Research: Tool Support for Producing High Assurance and Reliable Software for Wireless Sensor Actor Networks","awardID":"0916504","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["511692"],"PO":["565255"]},"153668":{"abstract":"Emerging applications using wireless sensor networks for critical areas such as environmental monitoring and emergency response highlight the urgent need for more powerful algorithms for tracking amorphous events or phenomena with dynamic identities. Several such events may combine into a large whole or one event may disintegrate into several smaller ones. Current efforts in event detection and tracking have mostly assumed that either events remain distinct, never crossing or passing too close together to become indistinguishable, or if they do cross that they were identified prior and nothing new has formed. This project addresses the research challenges in designing and implementing a system that is capable of tracking events with or without well-defined shapes and identities in the presence of stringent energy constraints and unpredictable network failures posed by wireless sensor networks. Specific research objectives include: design and evaluation of algorithms that detect and track any types of events including amorphous phenomena with dynamic signatures and events that possess a static shape with a crisp boundary; design and evaluation of algorithms that form and reform communication structures around events of interest; and development of an integrated system that provides interfaces to high level application tasks to execute on each identified event. Successful completion of this project will result in a rich set of tools that can be used by applications monitoring all different types of events. The tools will be made publicly available via the Internet. This project provides opportunities for recruitment of female students and undergraduate students.","title":"NeTS: Small: Algorithms and System Support for Monitoring of Amorphous Phenomena with Dynamic Signatures in Wireless Sensor Networks","awardID":"0915574","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["172368"],"PO":["565303"]},"151006":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The nature of telecommunications networks is rapidly changing. <br\/>Commodity smart<br\/>mobile phone frameworks such as Android and Openmoko invite developers and end users to build applications, modify the behavior of the phone, and use network services in novel ways. However, while simultaneously spurring incredible innovation, the move to open systems alters the underlying performance and security assumptions upon which the network was designed. Such changes invite vulnerabilities ranging from merely vexing phone glitches to catastrophic network failures. The current infrastructure lacks the basic protections needed to protect an increasingly open network, and it is unclear what new stresses and threats open systems and services will introduce.<br\/><br\/>This research analytically and experimentally investigates defensive infrastructure addressing vulnerabilities in open cellular operating systems and telecommunications networks. In this, we are exploring the requirements and design of such defenses in three coordinated efforts; a) extending and applying formal policy models for telecommunication systems, and provide tools for phone manufacturer, provider, developer, and end-user policy compliance verification, b) building a security-conscious distribution of the open-source Android operating system, and c) explore the needs and designs of overload controls in telecommunications networks needed to absorb changes in mobile phone behavior, traffic models, and the diversity of communication end- points.<br\/><br\/>This research symbiotically supports educational goals at the constituent institutions by supporting graduate and undergraduate student research, and is integral to the security and network curricula.","title":"TC: Medium: Collaborative Research: Security Services in Open Telecommunications Networks","awardID":"0905447","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["518380","521556"],"PO":["565327"]},"152579":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Obtaining physiological\/behavioral data from human subjects in their natural environments is essential to conducting ecologically valid social and behavioral research. While several body area wireless sensor network (BAWSN) systems exist today for physiological data collection, their use has been restricted to controlled settings (laboratories, driving\/flying scenarios, etc.); significant noise, motion artifacts, and existence of other uncontrollable confounding factors are the often cited reasons for not using physiological measurements from natural environments. In order to provide scientifically valid data from natural environments, a BAWSN system must meet several unique requirements (1) Stringent data quality without sensing redundancy, (2) Personalization to account for wide between person differences in physiological measurements, and (3) Real-time inferencing to allow for subject confirmation and timely intervention. <br\/><br\/>Intellectual Merit: In this project, a multidisciplinary team of researchers spanning various computing disciplines and behavioral sciences are developing a general purpose framework called FieldStream that will make it possible for BAWSN systems to provide long term unattended collection of objective, continuous, and reliable physiological\/behavioral data from natural environments that can be used for conducting population based scientific studies. FieldStream is being incorporated in two real-life projects ? NIH sponsored AutoSense at Memphis and NSF sponsored Urban Sensing at UCLA, to help validate the assumptions, establish the feasibility of developed solutions, and to uncover new requirements. <br\/><br\/>Broader Impact: By making it possible to obtain scientifically valid objective data from the field, FieldStream promises to help solve several behavioral problems of critical importance to human society that have remained unanswered for lack of such data.","title":"NetSE: Large: Collaborative Research: FieldStream: Network Data Services for Exposure Biology Studies in Natural Environments","awardID":"0910754","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["532662"],"PO":["565090"]},"153316":{"abstract":"Personally identifiable or sensitive information (PII) has become a target of attackers seeking financial gain through its misuse. With the trend toward storing and processing PII on complex and insecure systems, the need for improved protection has become a goal of enterprise policy and legislative efforts. In this project, we investigate Concatenated Dynamic Information Flow Tracking (CDIFT), an architecture for performing dynamic information &#64258;ow analysis at various system levels and across multiple processes in a distributed enterprise. CDIFT will allow administrators to ?map? the enterprise business logic (applications, network, storage) and determine where information of interest is stored or transmitted. The same mechanism can also be used to enforce an information &#64258;ow policy, restricting where and by whom such information can be viewed. CDIFT will complement and enhance current compliance and auditing efforts, which require considerable recurrent effort and a large number of man-hours spent by administrators and auditors on understanding existing systems.<br\/><br\/>We will develop and experimentally evaluate novel techniques for conducting fine-grained tracking of information of interest (as de&#64257;ned by the system operator or, in the future, by end-users, in a flexible, context-sensitive manner) toward mapping the paths that such information takes through the enterprise and providing a means for enforcing information &#64258;ow and access control policies. Our hypothesis is that it is possible to create efficient fine-grained information tracking and access control mechanisms that operate throughout an enterprise legacy computing infrastructure through appropriate use of hypervisors and distributed tag propagation protocols.","title":"CSR: Small: An Information Accountability Architecture for Distributed Enterprise Systems","awardID":"0914312","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["549898","564223"],"PO":["366560"]},"151017":{"abstract":"This research explores challenges in developing privacy-preserving information networks and services (PPNs). Next generation healthcare information systems and applications, such as personalized and predictive medicine, need PPNs for privacy-preserving information sharing and dissemination among independent healthcare providers, enabling information access over distributed access controlled content, while safeguarding personal health information and medical privacy of individuals from unauthorized disclosures.<br\/><br\/>The intellectual merits of this research include the development of: (1) privacy-preserving search capabilities over distributed access controlled content, a critical functionality for PPNs; (2) a suite of utility-aware data anonymization services, preserving the privacy of personal medical information against unauthorized disclosure, at the same time maximizing the data utility for medical service providers; and (3) the PPN architecture and middleware optimized for high availability, scalability and failure recovery.<br\/><br\/>The broad impact is two-fold. First, this research will create better and broader understanding of the challenges and functional requirements for building the next generation of privacy preserving networked information systems over distributed access controlled content. A domain-specific proof-of-concept prototype on top of the PPN core will be developed for discovering and analyzing risk factors for resistant bacterial infections. These real-world studies will be conducted in collaboration with Morehouse School of Medicine and Children's Healthcare of Atlanta, and be use as both a driver and a testbed for this research. Second, this research will demonstrate that the PPN is an enabling infrastructure for real-time, continuous and on demand data analysis over massively-distributed and privately-shared data repositories.","title":"NetSE: Medium: Privacy-Preserving Information Network and Services for Healthcare Applications","awardID":"0905493","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["549757","532971","521101",402577],"PO":["564456"]},"164569":{"abstract":"Among the activities in CISE\/CNS related to security are Trustworthy Computing (TC) , and Future Internet Design (FIND). For the former, one of the five emphasis areas declared in the TC solicitation is Security Architecture. For the latter, one of the objectives of the NSF activity towards a future Internet is security. GA Tech. proposes to run two related workshops: the first on Security-Driven Architecture (SDA) and the second an information meeting in connection with future directions for FIND towards research on architectures wherein one of the design objectives is security. <br\/><br\/>This award, co-funded by NSF and DARPA, is providing travel expenses attendant to two workshops, which took place July 28-29, 2009 in Arlington, VA. <br\/><br\/>The first workshop, called Secure-Driven Architecture (SDA) is driven by the possibility of redesigning systems (hosts, networks, applications) to be secure from the start; this is in contrast with the current industry practice of patching systems when vulnerabilities are discovered (mostly by attackers) and with the current research practice of studying ?point? solutions that address particular security issues. The premise of the workshop is that by starting from scratch it could be possible to design a system far more secure than is promised by the current research. <br\/><br\/>The workshop is organized into the following six sessions: <br\/><br\/>1. Multi-faceted architecture, which considers new design paradigms <br\/>2. Cryptography as an enabler of security through a system <br\/>3. Network security, where the intention is to secure the network and for the network to help mitigate attacks on end-points. <br\/>4. Host security <br\/>5. Formal methods and other mostly theoretical concepts in support of security <br\/>6. Wrap-up and next steps. <br\/><br\/>The second workshop, concerned with New Directions in Networking, had as its purpose informing the community of new opportunities for the funding of substantial projects to design new network architectures where security is one of several objectives. The opportunities would be an expansion of NSF?s current FIND (Future Internet Design) activity towards actual architectures. Through the discussions of the workshop, a follow-on meeting, called a Summit, is planned wherein actual architectures would be presented and evaluated.","title":"Clean-Slate Security-Driven Architecture Workshop and Information Session","awardID":"0968749","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I330","name":"Defense Advanced Research Proj"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["561756"],"PO":["565327"]},"157804":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/><br\/>The objective of this research is to understand how pervasive information changes energy production, distribution and use. The design of a more scalable and flexible electric infrastructure, encouraging efficient use, integrating local generation, and managing demand through awareness of energy availability and use over time, is investigated. The approach is to develop a cyber overlay on the energy distribution system in its physical manifestations: machine rooms, buildings, neighborhoods, isolated generation islands and regional grids. A scaled series of experimental energy networks will be constructed, to demonstrate monitoring, negotiation protocols, control algorithms and Intelligent Power Switches integrating information and energy flows in a datacenter, building, renewable energy: farm\", and off-grid village. These will be generalized and validated through larger scale simulations. The proposal?s intellectual merit is in understanding broadly how information enables energy efficiencies: through intelligent matching of loads to sources, via various levels of aggregation, and by managing how and when energy is delivered to demand, adapted in time and form to available supply. Bi-directional information exchange is integrated everywhere that power is transferred. Broader impacts include training diverse students, such as undergraduates and underrepresented groups, in a new interdisciplinary curriculum in information and energy technologies. Societal impact is achieved by demonstrating dramatic reductions in the carbon footprint of energy and its overall usage, greater penetration of renewables while avoiding additional fossil fuel plants, and shaping a new culture of energy awareness and management. The evolution of Computer Science will be accelerated to meet the challenges of cyber-physical information processing.","title":"CPS:Medium: LoCal - A Network Architecture for Localized Electrical Energy Reduction, Generation and Sharing","awardID":"0932209","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["550677",421195,"527078","527079"],"PO":["564728"]},"151028":{"abstract":"This project is developing and evaluating the application of iterative process improvement technology to assure the privacy, security, reliability, and trustworthiness of elections, which are the very cornerstone of democracy. The focus of the project is to locate mismatches between existing voting systems and the processes that are currently using them in the conduct of elections. These mismatches can result in vulnerabilities or inaccuracy in elections. This project demonstrates how to remediate such vulnerabilities through the use of iterative process improvement. The methodology uncovers vulnerabilities by modeling processes and examining how discrepancies between the characteristics of these processes and the behaviors of voting systems that are used by the processes can lead to such vulnerabilities. In this way, this project is making a novel and important contribution to defending one of the most critical processes of democracy. <br\/><br\/>The project tests the results on the election processes and systems of Yolo County. Part of the research is to model that county's processes using the process definition language, and examining what these processes require and expect from the voting systems they use. The existing voting systems can then be examined to determine whether they meet the requirements and expectations of the processes using them. Where mismatches occur, the vulnerabilities created by such mismatches can be assessed, improvements suggested, and the methodology can show how the suggested improvements address the mismatches and remove the vulnerabilities.","title":"TC:Medium:Collaborative Research: Technological Support for Improving Election Processes","awardID":"0905530","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["536735","536737"],"PO":["565264"]},"158904":{"abstract":"The Wisconsin Hierarchically-Redundant, Decoupled storage project (HaRD)<br\/>investigates the next generation of storage software for hybrid Flash\/disk<br\/>storage clusters. The main objective of the project is to improve the<br\/>performance of storage in a variety of diverse scenarios, including new<br\/>application environments such as photo storage as found in Facebook and<br\/>Flickr, high-end scientific processing as found in government labs, and<br\/>large-scale data processing such as that found in Google and Microsoft. The<br\/>HaRD project focuses on three key issues in order to improve performance of<br\/>these important applications: client-side Flash-based RAID and file-system<br\/>integration, server-side memory reduction and multicore scheduling of<br\/>file-system tasks, and scheduled network transfers. HaRD pulls together these<br\/>technologies into a synthesized whole through three targeted storage systems:<br\/>a scalable photo server, a high-performance checkpoint subsystem, and an<br\/>improved file system for MapReduce workloads. The impact of this project is<br\/>significant, as HaRD helps to shape the storage software architecture of the<br\/>next generation of cloud computing services, which are of increasing relevance<br\/>to both industry and society at large.","title":"HaRD: The Wisconsin Hierarchically-Redundant, Decoupled Storage Project","awardID":"0937959","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7476","name":"ETF"}}],"PIcoPI":["550389","550390"],"PO":["565272"]},"157815":{"abstract":"CPS: CPS:Small: A Unified Distributed Spatiotemporal Signal Processing Framework for Structural Health Monitoring<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to meet the urgent global need for improved safety and reduced maintenance costs of important infrastructures by developing a unified signal processing framework coupling spatiotemporal sensing data with physics-based and data-driven models. The approach is structured along the following thrusts: investigating the feasibility of statistical modeling of dynamic structures to address the spatiotemporal correlation of sensing data; developing efficient distributed damage detection and localization algorithms; investigating network enhancement through strategic sensor placement; addressing optimal sensor collaboration for recursive localized structural state estimation and prediction.<br\/><br\/>Intellectual merit: This innovative unified framework approach has the potential of being more reliable and efficient with better scalability compared to the current state-of-the-art in structural health monitoring. The proposed research is also practical as it allows analysis of real-world data that accounts for structural properties, environmental noise, and loss of integrity over sensors. Probabilistic representation of significant damages allows more informative risk assessment. <br\/><br\/>Broader impacts: The outcome of this project will provide an important step toward safety and reliability albeit increasing complexity in dynamic systems. New models and algorithms developed in this project are generic and can contribute in many other areas and applications that involve distributed recursive state estimation, distributed change detection and data fusion. This project will serve as an excellent educational platform to educate and train the next generation CPS researchers and engineers. Under-represented groups such as female students and Native American students will be supported in this project, at both the graduate and undergraduate levels.","title":"CPS:Small: A Unified Distributed Spatiotemporal Signal Processing Framework for Structural Health Monitoring","awardID":"0932297","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["518429"],"PO":["565136"]},"156605":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/><br\/>Summary: Formal Analysis of Complex Systems<br\/><br\/>A Collaborative Proposal Involving CMU, CUNY, NYU, Stony Brook, UMD, Cornell, JPL<br\/><br\/><br\/>This Expedition, under the directorship of Lead PI Edmund M. Clarke, will develop new computational tools to help scientists and engineers analyze and understand the behavior of the complex models they develop for application domains ranging from systems biology to embedded control. Building on the success of model checking and abstract interpretation (MCAI), two well-established methods for automatically verifying properties of digital circuit designs and embedded software, this research project will extend the MCAI paradigm to systems with complex continuous dynamics and probabilistic behaviors. Challenge problems providing technology drivers and testbeds for the research include: understanding the precursors and course of pancreatic cancer; predicting the onset of atrial fibrillation; and obtaining deep design-time insights into the behavior of automotive and aerospace control systems. Ultimately, this Expedition is expected to provide vital tools that will enable health-care researchers to discover better treatments for disease and will allow engineers to build safer aircraft and other complex systems.<br\/><br\/>The world-class team of scientists and engineers assembled for this Expedition includes two Turing Award winners, a recipient of the National Medal of Science, and awardees of other prestigious research prizes. Outreach consists of the development of a new, highly ambitious and highly cross-discipline educational program called Complex Systems Science Engineering, an annual Minority-Focused Intersession Workshop for Undergraduates on Understanding and Analyzing Complex Embedded and Biological Systems to be hosted at member institution Lehman College, CUNY; substantial financial support for undergraduate research; student involvement in the NASA JPL Research Affiliates Program; and other research opportunities for undergraduate and graduate students and postdoctoral trainees.<br\/><br\/>More information: http:\/\/www.mcai2.org\/","title":"Collaborative Research: Next-Generation Model Checking and Abstract Interpretation with a Focus on Embedded Control and Systems Biology","awardID":"0926200","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"6894","name":"ITR EXPEDITIONS"}}],"PIcoPI":["472891"],"PO":["565239"]},"155879":{"abstract":"Proposal #: MRI 09-23456<br\/>PI(s): Lei, Hansheng; Benacquista, Matthew J.; Figueroa, Andres; Iglesias, Juan R.; Mukherjee, Soma<br\/>Institution: University of Texas - Brownsville<br\/>Title: MRI\/Acq.: FUTURO: A Data Intensive and High Performance Computing Cluster for Integrated R & E <br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Project Proposed:<br\/>This project, acquiring Futuro, a computer cluster for interdisciplinary research projects and Computer Science education programs, enables research activities in data mining, pattern discovery, genetic data analysis, experimental astronomical physical, collaborative filtering, theory of computation, high dimensional visualization, and other computational areas. Seeking to lay the foundation for a strong research and education integration centered on CS in two minority-serving universities, UT-Brownsville and UT-Pan American, it enables the following potential transformative goals:<br\/>- Terabyte scale data mining and pattern discovery in time series datasets obtained from heterogeneous sensor networks (addresses data analysis problems in Laser Interferometer Gravitational Wave Observatory (LIGO))<br\/>- Genetic data analysis in complex human diseases to identify susceptibility factors enabling understanding of genetic causes of complex diseases such as schizophrenia (potential to lead to new therapeutic strategies)<br\/>- Studying the dynamical systems and Stellar populations to model the behavior of black hole binaries in globular cluster and galactic nuclei (creates models of formation of stellar systems via intensive computation that can provide information for interpretation of results from operating gravitational wave detectors)<br\/>- Exploring and creating computing-effective, scalable, robust and intelligent learning algorithms for large recommender systems based on collaborative filtering by incorporating multispectral information (may lead to next generation recommender systems)<br\/>- Visualizing high dimensional streaming data from heterogeneous sensors (potential to contribute in developing new data reduction methodologies that incorporate intelligent computation such as data mining and thus more advanced visualization systems with cross-disciplinary utility)<br\/>- Benchmarking and developing algorithms for approximating NP-hard subgraph isomorphism problem with best possible practical performance (benefits applications such as image recognition and bioinformatics)<br\/>Futuro will serve as laboratory in which core research can be conducted in a collaborative fashion at a high level providing real-world test applications while training students.<br\/><br\/>Broader Impacts: This project benefits many users from physics, bioinformatics, computational engineering, and environmental engineering in two minority-serving universities. Futuro forms the nucleus for collaboration between computer scientists and researchers from other departments. The project will train students at the Rio Grande Valley, a historically underrepresented region with more than 90% Hispanics, in areas that are expected to have great national impact. The work provides experience in parallel programming and scientific computing, the CS curriculum will be enriched by the lab modules enabled by the cluster facility.","title":"MRI: Acquisition of Futuro: A Data Intensive and High Performance Computing Cluster for Integrated Research and Education","awardID":"0923456","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["425909",415590,"511634",415592,"528704"],"PO":["557609"]},"151039":{"abstract":"To survive and flourish, people must interact with their environment in an organized fashion. To do so, they need to learn, imagine, and perform an assortment of transformations on and in the world. Primary among these are manipulation of objects and navigation in space. This project integrates research in computer science and cognitive science to develop and evaluate augmented reality tools to create effective dynamic explanations that enhance manipulation and navigation, in conjunction with identification and visualization. Augmented reality refers to user interfaces in which virtual material is integrated with and overlaid on the user?s experience of the real world; for example, by using tracked head-worn and hand-held displays. Dynamic explanations are task-appropriate sequences of actions, presented interactively, with appropriate added information. The tools will be created in collaboration with subject matter experts for exploratory use in indoor and outdoor real world domains: navigating and identifying landmarks in a wooded park area, assembling a piece of furniture, and navigating and visualizing for planning the site of a new urban campus. Cognitive science research will determine the best ways to convey explanations and information to people. Computer science research will address the design and implementation of systems that embody the best candidate approaches for identifying objects and locations, specifying actions, and adding non-visible information. In situ experiments will be used to assess and refine the systems. <br\/><br\/>Manipulation, navigation, identification, and visualization are representative of important things that people do every day, ranging from fixing broken equipment to reaching a desired destination in an unfamiliar environment. The ways in which we perform these tasks could potentially be improved significantly through augmented reality systems designed using the principles to be developed by this project. Both the cognitive principles and the augmented reality tools will have broad applicability. The systems developed will inform the design of future systems that can aid the general public, for educational and recreational ends, as well as systems that can assist people with auditory, visual, or physical impairments.","title":"HCC: Medium: Collaborative Research: Generating Effective Dynamic Explanations in Augmented Reality","awardID":"0905569","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["530199"],"PO":["564456"]},"157826":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research project is to achieve fundamental advances in software technology that will enable building cyber-physical systems to allow citizens to see the environmental and health impacts of their daily activities through a citizen-driven body-worn mobile-phone-based commodity sensing platform. The approach is to create aspect-oriented extensions to a publish-subscribe architecture, called Open Rich Services (ORS), to provide a highly extensible and adaptive infrastructure. As one example, ORS will enable highly adaptive power management that not only adapts to current device conditions, but also the nature of the data, the data?s application, and the presence and status of other sensors in the area. In this way, ORS will enable additional research advances in power management, algorithms, security and privacy during the project. A test-bed called CitiSense will be built, enabling in-the-world user and system studies for evaluating the approach and providing a glimpse of a future enhanced by cyber-physical systems.<br\/><br\/>The research in this proposal will lead to fundamental advances in modularity techniques for composable adaptive systems, adaptive power management, cryptographic methods for open systems, interaction design for the mobile context, and statistical inference under multiple sources of noise.<br\/><br\/>The scientific and engineering advances achieved through this proposal will advance our national capability to develop cyber-physical systems operating under decentralized control and severe resource constraints. The students trained under this project will become part of a new generation of researchers and practitioners prepared to advance the state of cyber-physical systems for the coming decades.","title":"CPS:Medium: CitiSense - Adaptive Services for Community-Driven Behavioral and Environmental Monitoring to Induce Change","awardID":"0932403","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["521727","560640","525613","438188","564209"],"PO":["565274"]},"158805":{"abstract":"This proposal requests funding to assist approximately 15 US-based graduate <br\/>students to attend the Fourth Workshop on Hot Topics in Security (HotSec). <br\/>Participation in HotSec and similar conferences is a valuable and important part of the <br\/>graduate school experience. It provides students with the opportunity to interact with <br\/>more senior researchers in the field, and exposes students to leading edge work in the <br\/>field. The support requested in this proposal will enable the participation of students who <br\/>would otherwise be unable to attend HotSec.","title":"Student Travel Support for the Fourth Workshop on Hot Topics in Security (HotSec '09)","awardID":"0937497","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["559051"],"PO":["565264"]},"157716":{"abstract":"CPS: Small: MPSoC based Control and Scheduling Co-design for Battery Powered Cyber-Physical Systems<br\/><br\/>The objective of this research is to develop new scientific and engineering principles, algorithms and models for the design of battery powered cyber-physical systems whose computational substrates include high-performance multiprocessor systems-on-chip. The approach is to design control tasks that guarantee performance and meet criteria for battery operation time. Task schedulers are co-designed to balance the computing load across the multiple processors, and to control the physical plant together with the control tasks. The controller and scheduler will be integrated with battery management algorithms through a systems theory approach so that the methods are provably correct with justfiable performance. <br\/><br\/>Intellectual Merit: The program will create progress in digital and hybrid control theory that keeps up with the recent trend of using multiprocessor systems-on-chips for control and robotic applications. The mechanism for the migration of control tasks between multiple processors will respect physical and thermal performance. A novel battery dynamic discharge model is developed, which may be applied to context when the discharge current of batteries cannot be predicted by existing static battery models.<br\/><br\/>Broader Impacts: Collaborations with industrial partners have been set up. The program offers multidisciplinary training in cyber-physical systems. A teaching and outreach lab is in place to host K-12 student teams that participate in robot competitions, and has become an Explorer Post for Boy Scout of America.","title":"CPS: Small: MPSoC based Control and Scheduling Co-design for Battery Powered Cyber-Physical Systems","awardID":"0931576","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["431683","550613"],"PO":["564778"]},"158816":{"abstract":"I\/O performance is often an issue for high-end computing (HEC) codes, due to their increasingly data-intensive nature and the ever-growing CPU-I\/O performance gap. Portable parallel I\/O benchmarks can help <br\/>(1) application developers to improve their codes' performance, <br\/>(2) HEC storage systems architects to improve their designs, and <br\/>(3) future and current owners of HEC platforms to reduce hardware cost and improve application performance through better system provisioning and configuration. <br\/><br\/>To keep up with the growing scale and complexity of HEC applications, this project develops automated generation of parallel I\/O benchmarks, analogous to the SPEC and NAS benchmarks for computation. Our approach will be embedded in BenchMaker, a prototype tool that takes a real-world, large-scale parallel application and automatically distills it into a compact, human-intelligible, I\/O-intensive, and parameterized benchmark. Such a benchmark accurately reflects the original application's I\/O characteristics and I\/O performance, yet with shorter execution time, reduced need for libraries, better portability, and easy scalability. <br\/><br\/>Benchmarks and tools that benefit the computational science community at large will be produced by this research. These benchmark prototypes will be used for parallel computing course projects and student research contests.","title":"Collaborative Research: Automatic Extraction of Parallel I\/O Benchmarks from HEC Applications","awardID":"0937571","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["550397"],"PO":["565272"]},"156517":{"abstract":"The NSF and other Federal agencies will require further understanding of concepts, methods, and means for Exascale computing systems before formulation of future programs in enabling technologies, architectures, and methodologies. NSF supports a targeted two-year program of investigation, The Exascale Point-design Study, to provide sufficient depth and detail of understanding of the interrelationships among possible enabling technologies, implementation architectures and operating system software, and programming interfaces and methodologies.<br\/><br\/>Working in consultation with LSU, USC, UIUC, and Sandia National Laboratory (under DOE sponsorship), UD team devises an Exascale compilation technology and strategy derived from prior research conducted under NSF, DOE, and DARPA sponsorship, reflecting some of the best-known principles and practices envisioned for hardware and software at the Exaflops scale. This collaborative research will be performed in collaboration with our partners who will contribute architecture (LSU), application drivers and programming models (UIUC), enabling technology and hardware system design (USC), and systems integration and deployment (SNL). The team plans to provide a final report of its evaluations and analysis.","title":"Advanced Software Technology for an Exascale Point Design Study","awardID":"0925863","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7684","name":"STRATEGIC TECHNOLOGIES FOR CI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["475422","525208","558848"],"PO":["565272"]},"159806":{"abstract":"The study of gene regulation is central to modern biology. A significant portion of the nascent field of synthetic biology has revolved around building synthetic gene networks to recapitulate regulatory mechanisms found in nature or to engineer novel biological functions. However, artificial gene networks have not approached the sophistication of their natural counterparts in either design or performance. There are several technical and scientific challenges that currently limit the engineering of large-scale integrated synthetic genetic networks. This research centers on developing a framework for automating the process of gene network design by a) obtaining various working \"parts\" of gene regulatory mechanisms from nature and b) by applying engineering sciences to learn how to compose them reliably into novel systems which have predictable behaviors. The value of this project will be demonstrated through the development of the ?Programmable Rhizosphere?, which is a framework for engineering mutualism between model plant and soil microbe species. The Programmable Rhizosphere will allow control of interactions between disparate organisms, and represents a significant step towards our ability to manipulate complex ecosystems.<br\/><br\/>Broader impact: This project brings together researchers from top US institutions as well as establishes a collaboration with major universities in the UK. Graduate students and postdoctoral researchers associated with this project will get an opportunity to participate in a multi-institution, multidisciplinary research project. They will have the opportunity to train on a wide variety of techniques in computational and molecular biology. The results of the project will be disseminated to the broader public including middle and high school students through the development of informational materials and hands-on demonstrations designed for educating the public on the technologies and potential impact of synthetic biology. In addition to the advances in the understanding of engineering synthetic regulatory systems, the Programmable Rhizosphere technology has broad implications for sustainability in agriculture. In particular, these technologies could be used to engineer beneficial phenomena such as nitrogen fixation in agricultural crops, which would displace petroleum-based fertilizers currently used in agricultural production.","title":"COLLABORATIVE RESEARCH: Programming the rhizosphere through highly integrated genetic, spatio-temporal control systems","awardID":"0943385","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7552","name":"COFFES"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7954","name":"SANDPIT"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1112","name":"Genetic Mechanisms"}}],"PIcoPI":["539225","559397"],"PO":["565223"]},"154119":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). The bottleneck for the transferring data at very high speeds often turns out to be the end-system performance. In the absence of definitive knowledge about the workload at the receiving end-system, the sender's transmission rate often overshoots the critical bottleneck rate of the receiver. This typically results in oscillations between the extremes and poor performance. To optimize the performance of the transport protocols and achieve the important flow control functionality, it is important to estimate the receiving end-system effective bottleneck rate. In this project we will use modeling and active analysis of the end-system to estimate this rate. We will develop queueing network models for representing the different multicore and multiprocessor end-systems running different types of workloads. We will develop a software tool to be integrated with existing transport protocols. We will carry out experimental analysis for different types of end-systems with different configurations and workloads. We will apply and extend methods that have been proposed to address the limitations of queueing network models for performance analysis of computer systems with bursty workloads and correlated service times. The software tool will be made available to the research community to analyze and optimize distributed applications and systems. The research project will provide a framework to train graduate and undergraduate students in both analytical and experimental methods, and develop knowledge and intuition about next generation computer systems and distributed applications.","title":"CSR:Small:Estimating the End-system Network I\/O Bottleneck Rate to Optimize Transport Layer Performance","awardID":"0917315","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["541428","485983"],"PO":["565255"]},"154009":{"abstract":"Commercial providers are increasingly permitting third-party developers to write and implement their own software applications on wireless devices, ranging from sensors to 3G cellular phones. As the number of applications and users grow, reliable software dissemination is quickly emerging as a key enabling technology, providing fundamental reprogramming services, such as software download, updates and security patching.<br\/><br\/><br\/>Intellectual Merit<br\/>This project aims to develop analytical foundations for efficient software dissemination in loss-prone wireless networks, measured in terms of delay and communication\/computational speed. Planned research will proceed along four thrusts: 1) PERFORMANCE LIMITS: mathematically formalizing the problem of software dissemination in multi-hop wireless networks using stochastic shortest path optimization based on the theory of Markov Decision Processes; 2) LARGE-SCALE ASYMPTOTICS: analyzing performance at high node densities using extreme-value theory and comparing state-of-the-art technologies, including rateless coding, packet-level channel hopping, and physical-layer cooperation; 3) ACK-LESS PROTOCOLS: eliminating control traffic (e.g., ACKnowledgments), with high probability, using a combination of extreme-value theory and shifted rateless codes; 4) IMPLEMENTATION: implementing theoretically-based software dissemination protocols on sensor motes and, subsequently, on Android-capable smartphones.<br\/><br\/><br\/><br\/>Broader Impact<br\/><br\/>This work promises a broad impact to various societal needs. On an education level, open cell phone programming expertise will be incorporated into innovative class assignments and labs taught by the PIs, including Software Engineering, Algorithms, and Networking. On a commercial side, the research identifies and provides directions for fundamental issues that will face private enterprises attempting to capitalize on emerging smartphone capabilities. The PIs will also expedite research transfer through liaisons with local and international industrial partners. Finally, the project will establish theoretical connections between disconnected fields, most notably bringing tools primarily used in civil and financial engineering into computing and communication.","title":"CIF: Small: Large-Scale Software Dissemination in Stochastic Wireless Networks","awardID":"0916892","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["486132","449083"],"PO":["564924"]},"150940":{"abstract":"Software reliability affects virtually everyone. Thorough software checking is unquestionably crucial to improve software reliability, but the checking coverage of most existing techniques is severely hampered by where they are applied: a software product is typically checked only at the site where it is developed, thus the number of different states checked is throttled by those sites' resources (e.g., machines, testers\/users, software\/hardware configurations).<br\/>To address this fundamental problem, we will investigate mechanisms that will enable software vendors to continue checking for bugs after a product is deployed, thus checking a drastically more diverse set of states. Our research contributions will include the investigation, development, and deployment of: (1) a wide-area autonomic software checking infrastructure to support continuous checking of deployed software in a transparent, efficient, and scalable manner; (2) a simple yet general and powerful checking interface to facilitate creation of new checking techniques and combination of existing techniques into more powerful means to find subtle bugs that are often not found during conventional pre-deployment testing; (3) lightweight isolation, checkpoint, migration, and deterministic replay mechanisms that enable replication of application processes as checking launch points, isolation of replicas from users, migration of replicas across hosts, and replay of identified bugs without need for the original execution environment; and (4) distributed computing mechanisms for efficiently and scalably leveraging geographically dispersed idle resources to determine where and when replicas should be executed to improve the speed and coverage of software checking, thereby converting available hardware cycles into improved software reliability.","title":"CSR: Medium: Guanyin: a Thousand hands with a Thousand eyes for Distributed Software Checking","awardID":"0905246","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["541922","508477","508314"],"PO":["565255"]},"150951":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The project develops cryptographic protocol reasoning techniques<br\/>that take into account algebraic properties of cryptosystems.<br\/>Traditionally, formal methods for cryptographic protocol<br\/>verification view cryptographic operations as a black box,<br\/>ignoring the properties of cryptographic algorithms that can be<br\/>exploited to design attacks. The proposed research uses a novel<br\/>approach based on equational unification to build new more<br\/>expressive and efficient search algorithms for algebraic theories<br\/>relevant to cryptographic protocols. Equational unification gives<br\/>a compact representation of all circumstances under which two<br\/>different terms correspond to the same behavior. The algorithms<br\/>are implemented and integrated into Maude-NPA, a system that has<br\/>been successful in symbolic protocol analysis. It is demonstrated<br\/>that Maude-NPA when enriched with such powerful unification<br\/>algorithms can analyze protocols and ensure their reliability,<br\/>which could not be done otherwise.<br\/><br\/>Improved techniques for analyzing security are helpful both in<br\/>assuring that systems are free of bugs, and in speeding up the<br\/>acceptance of new systems based on the confidence gained by a<br\/>formal analysis. This research will lead to the design and<br\/>implementation of next generation tools for protocol analysis.<br\/>Algorithms developed will be made available to researchers as a<br\/>library suitable for use with protocol analysis tools. Tools from<br\/>the project will help students understand concepts relevant to<br\/>protocol design and get hands-on experience. Equational<br\/>unification for algebraic theories is not only useful for<br\/>protocol analysis, but also for program analysis in general, thus<br\/>making the results of this project to be widely relevant.","title":"TC: Medium: Collaborative Research: Unification Laboratory: Increasing the Power of Cryptographic Protocol Analysis Tools","awardID":"0905286","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[402395],"PO":["565264"]},"150962":{"abstract":"Wireless mesh networks promise a flexible and cost-effective solution for bringing high-bandwidth low-latency applications to the home. Two orthogonal but immensely attractive approaches for designing high-performance mesh networks are network coding and cross-layer optimization. The former exploits the interfering wireless media as a broadcast channel by ingenious information processing, while the latter intelligently allocates and shares network resources across the layers. This project investigates the long-overdue and highly challenging synergistic union of network coding and cross-layer optimization. <br\/><br\/>The characterization of intersession network coding (INC), coding across different network flows, is NP-hard. Nonetheless, the problem can be made tractable under important practical settings. Based on new path-based characterizations, this project rigorously quantifies the network capacity in presence of different practical INC schemes. A new network-coding based cross-layer paradigm is developed for controlling mesh networks that takes into account practical considerations such as robustness, scalability, and time-varying wireless broadcast environment. New distributed, low-overhead protocols are constructed and validated over a mesh testbed on the Purdue University campus. Undergraduates and under-represented students are actively recruited for the project. Research results are disseminated via the web and through publications in conferences and journals. The results of the project, spanning from theoretic exploration to protocol deployment on a practical testbed lead to the significant performance gains necessary to realize the full capability of mesh networks, which in turn has the potential to revolutionize the telecommunications industry. <br\/><br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).","title":"NeTS: Medium: Collaborative Research: Unifying Network Coding and Cross-Layer Optimization for Wireless Mesh Networks: From Theory to Distributed Algorithms to Implementation","awardID":"0905331","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550994",402421],"PO":["557315"]},"150973":{"abstract":"Architecturally Diverse Systems for Streaming Applications <br\/>Abstract (0905368)<br\/>Many important scientific computing problems, called ?streaming applications,? have high input data rates derived from real-time sensor data or directly from data streaming from disk arrays. Real-time sensor based data (e.g., telescopic astrophysical data obtained in the search for new planets) is frequently sourced from analog devices and requires filtering and various data cleaning prior to performing a host of complex computations. Large disk based data sets (e.g., genome and protein sets used in understanding disease factors) are often passed at high data rates from disk storage.<br\/> Choices for dealing with such applications include a multiplicity of computing devices (e.g., general purpose processors, chip-multiprocessors, graphics processors, field programmable gate arrays, etc.). While each individually is well matched to certain types of computations, often more effective solutions are found by integrating multiple computer types into a single system. <br\/>The central research issue is determining how to effectively integrate diverse computing resources for solution of complex streaming applications. The research includes further development of the AutoPipe design environment. AutoPipe provides tools for algorithm specification, and for design, simulation and deployment of diverse integrated computing architectures. Techniques for inclusion of analog devices in mixed analog-digital systems is being undertaken so that Auto-Pipe can handle mixed signal, analog\/digital algorithmic functional and resource components in a single system. The research activity is driven by two important applications taken from the astro-physics and computational biology domains. There will be heavy involvement of graduate and undergraduate students in the research.","title":"CSR:Medium: Architecturally Diverse Systems for Streaming Applications","awardID":"0905368","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[402452,"511557","511555","511556","493325"],"PO":["565255"]},"162974":{"abstract":"The goal of this research aims to produce a general-purpose but domain-customizable collaborative scientific workflow tool for accelerating scientific discovery, particularly facilitating large-scale and cross-disciplinary research projects that are collaborative in nature and require intensive user interaction from multiple distributed domain scientists. As a natural extension to the existing single user-oriented scientific workflow management tools by providing direct system support for scientific collaboration, this project seeks to pave a way toward a next-generation tool supporting scientific collaboration over the Internet. The expected tool can be easily expanded to support data-centric collaborative information management in any intelligence community.<br\/><br\/>To achieve this broader impact, this research seeks to establish a set of foundational models and techniques supporting collaborative scientific workflow composition and management; and based on them, construct an Internet-based collaborative scientific workflow tool framed with an open-source initiative. The initial focus of the Early Concept Grants Exploratory Research (EAGER) project is on rapidly creating a prototype tool as a proof of concept, equipped with basic dataflow-oriented scientific workflow models and collaboration patterns integrated in an agile service-oriented architecture. To avoid reinventing the wheel, the efforts will be concentrated on transforming and extending Taverna, a known open-source scientific workflow management tool, into a collaborative version. Evaluations and validations will be conducted through partnerships with multiple collaborative scientific communities. <br\/><br\/>For further information, see the project website at <br\/>http:\/\/www.CollaborativeScientificWorkflows.org\/","title":"III:EAGER:Collaborative Research: A Collaborative Scientific Workflow Composition Tool Supporting Scientific Collaboration","awardID":"0960014","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["496337"],"PO":["543481"]},"150995":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Wireless mesh networks promise a flexible and cost-effective solution for bringing high-bandwidth low-latency applications to the home. Two orthogonal but immensely attractive approaches for designing high-performance mesh networks are network coding and cross-layer optimization. The former exploits the interfering wireless media as a broadcast channel by ingenious information processing, while the latter intelligently allocates and shares network resources across the layers. This project investigates the long-overdue and highly challenging synergistic union of network coding and cross-layer optimization. <br\/><br\/>The characterization of intersession network coding (INC), coding across different network flows, is NP-hard. Nonetheless, the problem can be made tractable under important practical settings. Based on new path-based characterizations, this project rigorously quantifies the network capacity in presence of different practical INC schemes. A new network-coding based cross-layer paradigm is developed for controlling mesh networks that takes into account practical considerations such as robustness, scalability, and time-varying wireless broadcast environment. New distributed, low-overhead protocols are constructed and validated over a mesh testbed on the Purdue University campus. Undergraduates and under-represented students are actively recruited for the project. Research results are disseminated via the web and through publications in conferences and journals. The results of the project, spanning from theoretic exploration to protocol deployment on a practical testbed lead to the significant performance gains necessary to realize the full capability of mesh networks, which in turn has the potential to revolutionize the telecommunications industry.","title":"NeTS-Medium: Collaborative Research: Unifying Network Coding and Cross-Layer Optimization for Wireless Mesh Networks: From Theory to Distributed Algorithms to Implementation","awardID":"0905408","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548182"],"PO":["557315"]},"153910":{"abstract":"The modern, highly digitized world is replete with human activities that generate copious streams of data on a seemingly-continuous basis. There is knowledge to be gained by suitably analyzing, mining and monitoring the wealth of information in these data streams. However, due to the sheer scale of the data involved, traditional algorithmic thinking is inadequate and one needs data streaming algorithms that can process inputs memory-efficiently in one, or a few, scanning passes, ideally operating in sync with data generation.<br\/><br\/>The area of data streaming algorithms, though dating back to about 1980, has truly come alive only in the last decade or so, with a wealth of algorithms having been developed for, e.g., various statistical analyses, geometric problems and graph-theoretic problems. An area rich with algorithmic ideas deserves sound theoretical underpinnings. Accordingly, this project shall investigate a number of fundamental questions in this area, focusing on the delineation of what can and cannot be achieved in this important computational model. By investigating foundational questions, rather than focusing too much on particular applications, the project's approach shall be that of algorithms-and-complexity theory.<br\/><br\/>Some representative research goals of this project are as follows. (1) Refining our understanding of the space complexity of various statistical measures, especially in the multi-pass setting. (2) Understanding the power of randomness in order-dependent streaming problems. (3) Proving lower bounds in stronger variants (extensions) of the basic stream model. (4) Attacking fundamental questions in communication complexity that lie at the heart of current open questions in data stream complexity.<br\/><br\/>Results obtained in the course of the project will be disseminated at international conferences, workshops and seminars at various institutions. The project's educational component shall consist of the development of a graduate-level course on data stream algorithms, covering the basics of the field and leading up to the most significant recent discoveries.","title":"DC: Small: Data Streaming through a Complexity-Theoretic Lens","awardID":"0916565","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["538173"],"PO":["563727"]},"153800":{"abstract":"It was recently discovered that copy number variations (CNVs) in human genome are quite common, and have important implications on phenotype. Currently, the primary platforms for large-scale detection and characterization of CNVs are SNP (single nucleotide polymorphism) microarrays. The current state-of-the-art in computational identification of CNVs from microarray data relies mostly on model-based approaches (e.g., Hidden Markov Models). However, such methods <br\/>require extensive training data, which may not be always available. Furthermore, since these methods use common CNVs to train their models, they are not as successful in identifying rare CNVs, which are believed to make up a substantial proportion of all CNVs in the human population. The objective <br\/>of this project is to develop optimization based algorithms and software for the identification and genotyping of CNVs, with a view to enabling fast and accurate identification of different types of CNVs (rare and common), without the requirement of training data.<br\/><br\/>The proposed framework develops a novel computational approach by explicitly formulating CNV identification as a series of optimization problems that incorporate multiple factors, including sensitivity to noise, rarity\/commonality of CNVs, genotypic specificity, and parsimony. <br\/>This formulation enables development of efficient algorithms that treat identification of rare and common CNVs as different problems with different objective functions. Availability of the resulting software to the community will enable more efficient and accurate identification of CNVs in large <br\/>samples, facilitating advances in understanding the role of CNVs in a range of complex phenotypes, including HIV, autism, schizophrenia, mental retardation, and many others. Furthermore, the computational innovations introduced by this project are likely to find applications in next generation sequencing.","title":"III: Small: Computational Infrastructure for the Identification of Copy Number Variations from SNP Microarrays","awardID":"0916102","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["432373",409276],"PO":["565136"]},"150896":{"abstract":"Society depends heavily on computers functioning correctly and securely. Unfortunately, software continues to be plagued by bugs and security vulnerabilities, and these problems are likely to get worse as multicore processors become ubiquitous and more programs become multithreaded. Yet multicore technology also provides the opportunity to use parallelism on commodity computers to improve software robustness.<br\/>This research seeks to improve the reliability and security of software by using multicore processors to enable new types of powerful, run-time checks. The project will make it possible to run checks in parallel on multicore systems, while preserving the same strong safety guarantees and simple programming model of running checks sequentially. The project will also study how to enable online data race detection and deterministic replay for multithreaded programs running on multiprocessors by offloading the work of data race detection onto other cores. Finally, the project will study powerful, new classes of run-time checks that are enabled by speculative parallel checks, multicore processors, and deterministic replay.<br\/>This research will benefit society by developing techniques to make software systems more reliable and secure and by producing open-source software artifacts that can be used by other groups. The project will also contribute material for courses that teach how to program multicore computers.","title":"CSR:Medium:Improving Software Reliability and Security Through Multicore Technology","awardID":"0905149","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["556912","521047","502231"],"PO":["565255"]},"153932":{"abstract":"As the computing capacity increases rapidly in large-scale cluster computing platforms, power management becomes an increasingly important concern. This project focuses on the research of reducing disk and memory power consumption through energy-aware cooperative caching in cluster-based storage systems. The project leverages I\/O characteristics of scientific applications and dynamic power management features of disk drives and memory chips to reduce I\/O energy consumption. This project involves three components: (1) investigate program context based pattern detection to predict I\/O activities in the operating systems, (2) investigate disk energy aware cooperative cache management schemes, and (3) prototype the management schemes and incorporate into cluster-based file systems. This project has broader impact through its contributions to the energy-aware computing, graduate education, and undergraduate education via an existing NSF-REU site award.","title":"DC:Small: Energy-aware Coordinated Caching in Cluster-based Storage Systems","awardID":"0916663","effectiveDate":"2009-09-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["486060"],"PO":["563727"]},"153822":{"abstract":"Cognitive radios enabling dynamic spectrum access are envisioned to sense the environment and self-learn to maximize an individual or group utility function. This results in cheating, irrational behavior, inequality aversion, altruism, learning from past memory, etc. These traits are strikingly similar to human behavior and social interactions. Therefore, this project explores this parallelism going beyond traditional game theoretic analysis. <br\/><br\/>What are the implications if communication protocols in a cognitive radio network resemble human behavioral and psychological interactions? Will the network develop its own psychology with random perturbations, similar to human evolution?<br\/>These are the fundamental questions addressed in this project using tools from social science and behavioral games. Some of the main theoretical ideas will be implemented in SpiderRadio, a cognitive radio network prototype developed in the PIs? laboratory at Stevens. <br\/><br\/>Intellectual Merit: The intellectual merit of this project is an inter-disciplinary effort that<br\/>overlaps human behavioral models, cognitive psychology, economic models, decision theory and dynamic spectrum access. Emerging social science concepts such as evolutionary and cognitive psychology, behavioral economics, drama theory, personal and social dilemmas are used to model various types of interactions among cognitive radio nodes in a network. <br\/><br\/>Broader Impact: The outcomes of this project will have a broader impact on wireless networking research and spectrum policy making communities. This project also gives a unique opportunity for students in engineering and psychology to collaborate. Finally, some of the ideas presented here will impact the next generation standards in cognitive radio networking.","title":"NetSE:Small: Human Behavior Inspired Cognitive Radio Network Design","awardID":"0916180","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["515465","409877"],"PO":["564924"]},"153943":{"abstract":"Data management systems are undergoing a sea change. Specialized<br\/>engines with specialized physical storage structures are emerging to<br\/>address the extreme data volume and performance requirements of modern<br\/>applications. At the same time, the complexity of these systems, the<br\/>applications in which they are used and the platforms on which they<br\/>are built is increasing. Thus, there is a growing need for automatic<br\/>database design for these emerging database systems. Unfortunately,<br\/>previous work in automatic design cannot be used directly. While the<br\/>conceptual framework of previous research is useful, the specifics<br\/>must be reworked in order to adequately take advantage of the<br\/>opportunities and address the challenges that these new structures<br\/>present. Furthermore, most design tools only create complete designs.<br\/>There is also a need for automatic designers that can produce a new<br\/>design that is sensitive to the cost of migrating an old design to a<br\/>new one. Such an incremental designer would often generate a<br\/>sub-optimal design if that design will produce 80% of the benefit with<br\/>20% of the work.<br\/><br\/>The PIs propose to investigate this incremental automatic design<br\/>paradigm for newly emerging database systems. Specifically, the<br\/>project addresses three data management platforms: column stores for<br\/>OLAP, main memory, cluster-based systems for OLTP, and an extension to<br\/>row stores for exploiting correlations in data attributes.<br\/><br\/>The PIs expect to extend the work on current design tools by<br\/>demonstrating workable incremental designers as described above. There<br\/>is a strong need for such tools, and if this research is successful,<br\/>it should enable successful deployment of many new-style data<br\/>managers. Moreover, incremental design ideas based on sound<br\/>cost-benefit analysis are applicable to other data-intensive computing<br\/>environments and constitute an important direction towards truly<br\/>autonomic computing. Further information on the project can be found<br\/>on the project web page: http:\/\/database.cs.brown.edu\/projects\/auto\/","title":"III: Small: Automatic Incremental Design for Next-Generation Database Systems","awardID":"0916691","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["483626","483625"],"PO":["563727"]},"150797":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Traffic measurement is central to network operation, management, and security. Yet, support for measurement was not an integral part of the original Internet architecture. This project aims to develop a programmable measurement architecture that is versatile enough to support current and future measurement needs, adaptable to dynamic network conditions, modular\/lightweight, and scalable to high link speeds. <br\/><br\/>This project proposes a new flow abstraction module and query language that can specify arbitrary traffic sub-populations for statistics collection. Efficient data structures to encode these queries will be developed. The team also strives to identify a core set of data streaming and sampling primitives that can be composed together to satisfy most of the queries. Efficient hardware implementation for these core set of primitives will constitute the basic measurement modules that can be easily reconfigured to measure traffic at different desired granularity. Measurement application case studies will be carried out to evaluate and showcase the capabilities of the proposed approach. <br\/><br\/>This project has great potential in guiding the design of a clean-slate measurement instrumentation for future Internet. It will provide both graduate and undergraduate students with training that span multiple disciplines, from fundamental statistical theory, algorithm design, to hardware implementation. The results (including the query language and underlying data structures, sampling\/streaming algorithms, and hardware building blocks) will be broadly disseminated through publications, invited talks\/tutorials, and open-sourcing software distribution.","title":"NeTS: Medium: Collaborative Research: Towards Versatile and Programmable Measurement Architecture for Future Networks","awardID":"0904743","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["531923"],"PO":["565303"]},"153833":{"abstract":"Intrusion monitoring using networked sensors has a broad range of applications, including border security, surveillance, and monitoring of critical infrastructure such as nuclear power plants. In these hostile environments, the sensor network will itself be an attractive target that well-funded attackers will attempt to undermine. The sensor network has to be protected so that no intruders can evade monitoring, a challenging issue with many aspects not adequately addressed by existing research.<br\/><br\/>This project investigates novel techniques for location privacy and jamming-resistant tracking to defeat smart and resourceful attackers in intrusion monitoring applications. Location privacy techniques hide the locations of critical infrastructure such as base stations to make it hard for an adversary to locate and attack them. Jamming-resistant tracking allows the system to detect and track intruders in the presence of jamming attacks. However, existing location privacy techniques do not work effectively against resourceful adversaries who can monitor all traffic at a large area, and existing jamming-resistant algorithms do not scale well to large networks. These problems will be addressed in this project.<br\/><br\/>Through this project, we expect to uncover insights and develop algorithms that will apply to intrusion monitoring systems. By providing a layered, comprehensive defense system, the success of this project will have substantial impacts on both civilian and military operations where security is a major concern. This project will also help develop course materials on sensor network security and privacy. New course materials will enhance the information assurance curricula at UTA and other institutions.","title":"TC:Small: Towards Trustworthy Intrusion Monitoring Using Wireless Sensor Networks","awardID":"0916221","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["561003","561002"],"PO":["564223"]},"153954":{"abstract":"With the continuous growth of data production and the ever expanding computing infrastructure, future extreme-scale data intensive computing systems are facing unprecedented design and control challenges to meet the continuous and increasing demand for information processing. <br\/>Scalability, robustness, continuous availability, and service quality are the key attributes desired to ensure that the system designed today is capable of operating with the same efficiency on the extreme scale of the future. <br\/>The goal of the research described in this proposal is to develop theoretical foundations and practical control algorithms that enable the scalable design and efficient management of future extreme-scale data-intensive computing. Specifically, the researchers will <br\/>1) identify fundamental design principles needed to achieve scalability when developing network infrastructure and software systems in large scale. Here the concerns are to understand the performance degradation limited by various factors, including network structure, processor speeds, buffering\/storage capacities, etc. <br\/>2) develop distributed control strategies on operator placement, data storage, load shedding, and resource allocation so as to enable efficient in-network information processing. <br\/>The project will produce a deeper and quantitative understanding on the fundamental design principles and control strategies needed to achieve scalability, robustness and quality of service for future data-intensive information service systems. These advances will occur through a collaborative effort spanning multiple disciplines ranging from performance modeling, networking, queueing, to optimization.","title":"DC: Small:Collaborative Research: Managing Extreme-Scale Data Intensive Computing: Fundamental Design and Control Strategies","awardID":"0916726","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["545655"],"PO":["543481"]},"153723":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5.)<br\/><br\/>It is commonly understood that to achieve a desired level of security in wireless networks is a bigger challenge than in wired networks. The denial of service (DoS) attack is a prominent threat in wired networks, and is a more potent threat in the wireless domain. This project aims to explore enabling approaches for a novel beamforming framework with cross-layer interactions, referred to as xBeam, as a defense against DoS attacks in wireless networks. This project examines various DoS attacks, develops xBeam algorithms, evaluates the effectiveness of xBeam in deterring DoS attacks, and validates the algorithms using a wireless test bed.<br\/><br\/>Intellectual merit: This project develops a novel defense approach against DoS attacks in wireless networks, which is based on adaptive beamforming with cross-layer interactions. The approach can deter DoS attacks across different networking layers, multiple DoS attacks mounting from different spatial directions, and attacks mounted by malicious attackers who are mobile.<br\/><br\/>Broader impact: This research contributes to a substantial improvement in wireless network security and contributes to the advance of a networked mobile wireless information society. The project supports research oriented education, by providing opportunities for advanced study of wireless network security through coursework and hands-on experimentation. This research also provides quality research experiences for undergraduate students in the summer, particularly students from underrepresented groups.","title":"NeTS: Small: xBeam: Cross-Layer Beamforming Against Denial of Service Attacks in Wireless Networks","awardID":"0915813","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[409086,409087],"PO":["557315"]},"153844":{"abstract":"Modern networks invalidate many of the assumptions of traditional networking. For example, mobile ad hoc networks (MANETs) invalidate the assumption that there will be stable routes in the network, throwing traditional routing techniques into disarray. Handheld computing devices further challenge assumptions about platform mobility. While the need for cross-layer design to meet these new challenges has become well known, no replacement for the traditional network stack has emerged yet. Implementing experimental cross-layer approaches on commodity hardware and software remains challenging. <br\/><br\/>In this project we are building a framework for modular, extensible, experimental, network stack implementation, called the FINS (Flexible Internetwork Stack) Framework. The framework allows users to leverage existing protocols (such as TCP and IP) where needed, providing implementations that provide more real-time control and transparency than is available in existing implementations, while allowing users to replace or modify components as desired. Thus, the FINS Framework allows researchers ready access to the network stack in a manner previously possible only in simulation or by making painstaking operating system modifications. <br\/><br\/>The FINS Framework facilitates ready implementation of new network technologies and context-aware applications thereby lowering the bar for participation in experimental networking research. The initial implementation of the framework is on handheld devices. The framework is being released via open source license, making it broadly available to the research community. A set of hands-on networking course modules utilizing the FINS Framework and handheld devices is being developed, and utilized for undergraduate research at a predominantly undergraduate institution.","title":"NeTS: Small: Collaborative Research: The Flexible Internetwork Stack (FINS) Framework","awardID":"0916283","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["552282"],"PO":["565090"]},"153965":{"abstract":"Suitable models for dynamic covariance matrices can be extremely useful in several application domains, such as in text mining and topic modeling, where one can study the evolving correlation between topics; in financial data ranging from stock\/bond returns to interest rates and currencies, where the paramount importance of tracking evolving covariances has been widely acknowledged; in environmental informatics to study trends in dynamic covariance among disparate variables from the atmosphere as well as the biosphere. In such domains, it is not sufficient to simply compute the sample covariance at each time step; the goal is to discover any trends there may be in the evolution of the covariance structure.<br\/><br\/>This project introduces and investigates a novel family of Dynamic Wishart Models (DWMs), which has the same graphical model structure as the Kalman filter, but tracks evolution of covariance matrices rather than state vectors. Similar to the use of multivariate Gaussians in Kalman filters, the models use the Wishart and inverse Wishart family of distributions on covariance matrices. Unlike Kalman filters, an analytic closed form filtering may not be possible in DWMs, but the models still have enough structure to allow efficient approximate inference algorithms. The project focuses on approximate inference for filtering, smoothing, and related problems in the context of DWMs; develop suitable numerically stable recursive updates in order to prevent numerical loss in positive definiteness; and investigate generalizations of DWMs including mixture models for tracking complex covariance dynamics. <br\/><br\/>The development of effective tracking algorithms for covariances will permit the modeling of dynamic systems where the states really represent the varying relationships between multiple entities. The key contribution of the research is in leveraging the existing literature of dynamic latent state vectors to create equally powerful methods for dynamic latent covariance matrices. Such a transformation will have direct impact on applications in text analysis and topic modeling, financial data analysis, social network analysis, environmental informatics, and several other domains, and will spawn new opportunities for bringing together researchers and students across these disciplines, thereby broadening participation in computer sciences.","title":"RI: Small: Statistical Modeling of Dynamic Covariance Matrices","awardID":"0916750","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550553","557452"],"PO":["562760"]},"153734":{"abstract":"The staff in trauma centers are faced with complex problems under time pressure. Despite the introduction of standard protocols, the diversity of injuries that can occur requires a coordinated approach to the evaluation and treatment for each patient. Trauma care involves complex teamwork under time pressure, and teamwork errors endanger patient care and increase costs. Our proposed ethnographic study will use observation and detailed analysis of video recordings of trauma resuscitations to determine the nature and extent of teamwork errors in a trauma center. This detailed study of complex teamwork will uncover the causes of teamwork errors in collaborative high-risk environments. Methods will be developed to understand how teams work and where difficulties arise. This work will yield detailed descriptions of errors and their causes, a taxonomy of teamwork errors, information on how to improve team performance, and guides to the use of technology for teamwork support. It extends the level of detail of ethnographic research so that we can achieve precision in the understanding of procedures which are difficult to monitor automatically but where step-by-step records are essential to detect the causes of errors. <br\/><br\/>Understanding and improving the effectiveness of trauma teams has direct benefit to society. Further, complex collaborations are ubiquitous in modern enterprises and these results could improve collaborations both in terms of quality and productivity across organizations. In addition, this work will serve to develop the skills needed by a new cadre of researchers with knowledge of computer-supported collaborative work, video-content analysis and cooperative research.","title":"HCC: Small: Collaborative Research: Assessing Technology Requirements For Preventing Teamwork Errors in Safety-Critical Settings","awardID":"0915871","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["121525",409115,"534247"],"PO":["565342"]},"152524":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Obtaining physiological\/behavioral data from human subjects in their natural environments is essential to conducting ecologically valid social and behavioral research. While several body area wireless sensor network (BAWSN) systems exist today for physiological data collection, their use has been restricted to controlled settings (laboratories, driving\/flying scenarios, etc.); significant noise, motion artifacts, and existence of other uncontrollable confounding factors are the often cited reasons for not using physiological measurements from natural environments. In order to provide scientifically valid data from natural environments, a BAWSN system must meet several unique requirements (1) Stringent data quality without sensing redundancy, (2) Personalization to account for wide between person differences in physiological measurements, and (3) Real-time inferencing to allow for subject confirmation and timely intervention. <br\/><br\/>Intellectual Merit: In this project, a multidisciplinary team of researchers spanning various computing disciplines and behavioral sciences are developing a general purpose framework called FieldStream that will make it possible for BAWSN systems to provide long term unattended collection of objective, continuous, and reliable physiological\/behavioral data from natural environments that can be used for conducting population based scientific studies. FieldStream is being incorporated in two real-life projects ? NIH sponsored AutoSense at Memphis and NSF sponsored Urban Sensing at UCLA, to help validate the assumptions, establish the feasibility of developed solutions, and to uncover new requirements. <br\/><br\/>Broader Impact: By making it possible to obtain scientifically valid objective data from the field, FieldStream promises to help solve several behavioral problems of critical importance to human society that have remained unanswered for lack of such data.","title":"NetSE: Large: Collaborative Research: FieldStream: Network Data Services for Exposure Biology Studies in Natural Environments","awardID":"0910592","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["349186","565105"],"PO":["565090"]},"155803":{"abstract":"Proposal #: MRI 09-23282<br\/>PI(s): Flurchick, Kenneth<br\/> Li, Yaohang; Mohan, Ram; Tang, Guoqing<br\/>Institution: North Carolina Agricultural & Technical State University <br\/>Title: MRI\/Acq.: Support for Consortium for Research Computing for Sciences, Engineering, and Technology - CRCSET<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Project Proposed:<br\/>This project, acquiring, deploying, and maintaining a distributed High Performance Computing (HPC) system, aims to provide appropriate processing speed and power to pursue the needs required by various departments, programs, and research groups that have joined the institutional Consortium for Research Computing for the Sciences, Engineering, and Technology (CRCSET). These groups try to advance their respective research via the computational study of physical chemical properties and simulation of chemical\/physical processes in molecules, nano-materials and broad based bulk materials, physics based modeling in engineering disciplines, and other areas such as computational biology, finance, business, etc. Combined with advanced research training in computational science and engineering, the acquisition supports core projects and ancillary research projects, including:<br\/>- Computational Science and Engineering Program (core program recently approved for a PhD)<br\/>- All Electron Studies of Organic Molecular Crystals (OMCs) under Pressure<br\/>- Polymer Composite Fabrication Process Modeling and Simulations<br\/>- Ancillary Research Projects and Tools:<br\/> .Modeling C60 Reorientation of Various Solvents<br\/> .Modeling Material Deformation at Nano-Length Scales<br\/> .Computational Modeling and Simulation of Bio-Inspired Adaptive and Reconfigurable Systems<br\/> .New Research Tools for Collaborative Grid Computing and Visualization<br\/>- Research and Education Support<br\/>Broader Impacts: <br\/>This work fosters research and research and education training for underrepresented groups at a historically black college and\/or university (HBCU) and additionally provides computational resources to other HBCUs. Moreover, it aims to gain a better description at the atomic scale of the OMCs and to improve the understanding of the manufacturing processes for advanced composites.","title":"MRI\/Acq: Proposal for support for the Consortium for Research Computing for the Sciences, Engineering and Technology - CRCSET","awardID":"0923282","effectiveDate":"2009-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["537459","482837","521896",415230],"PO":["557609"]},"153504":{"abstract":"Group based anonymization is the most widely studied approach for privacy preserving data publishing. This includes k-anonymity, l-diversity, and t-closeness, to name a few. The goal of this proposal is to raise a fundamental issue on the privacy exposure of this approach which has been overlooked in the past and come out with a computationally efficient solution. The group based anonymization approach basically hides each individual record behind a group to preserve data privacy. However, patterns may still be derived or mined from the published anonymized data and be used by the adversary to breach individual privacy. The objective of this research is therefore to develop novel group-based anonymization methods that can defend against such an attack. The first part of the project is to define the attack problem, i.e., the published anonymized data can in fact be mined for privacy attacks. It identifies and formulates the privacy exposure to such an attack. The second part is to conduct a systematic study on the exposure of existing privacy techniques to the attack. The third part is to derive the condition that is able to resist such an attack and develop efficient data publishing algorithms to prevent it from occurring.","title":"III:Small:Privacy Preserving Data Publishing: A Second Look on Group based Anonymization","awardID":"0914934","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["492421"],"PO":["565136"]},"153988":{"abstract":"Many large-scale networked systems such as Online Social Networks (OSNs)are often represented as annotated graphs with various node or link attributes. Such a representation is usually derived from a snapshot that is obtained through measurements. These graph representations enable researchers to characterize the connectivity of these systems using graph analysis. However, captured snapshots of large networked systems are likely to be distorted. Furthermore, commonly-used graph analysis characterizes the connectivity of a graph in an indirect fashion and generally ignores graph dynamics. <br\/><br\/>This multi-disciplinary research program designs, develops and rigorously evaluates theoretically grounded techniques to accurately measure and properly characterize the connectivity structure of large-scale and dynamic networked systems. More specifically, the project examines various graph sampling techniques for collecting representative samples from large and evolving graphs. It also investigates how multiscale analysis can be used as a powerful technique to characterize the key features of the connectivity structure of large dynamic networked systems at different scales in space and time. The developed techniques will be used to characterize fundamental properties of the friendship and various interaction connectivity structures in different OSNs. <br\/><br\/>This project promises to identify the underlying technical and social factors that primarily drive the structural properties and dynamic nature of OSN-specific connectivity structures. It will produce new models for friendship and interactions in OSNs, a large archive of anonymized datasets and new tools for OSN measurement, simulation and analysis. The latter will be incorporated into newly-developed courses in Computer Science and Sociology, and will be freely distributed.","title":"NetSE: Small: Collaborative Research: Multi-Resolution Analysis & Measurement of Large-scale, Dynamic Networked Systems with Applications to Online Social Networks","awardID":"0916855","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["550949"],"PO":["565342"]},"152657":{"abstract":"Research in machine translation of human languages has made substantial progress recently, and surface patterns gleaned automatically from online bilingual texts work remarkably well for some language pairs. However, for many language pairs, the output of even the best systems is garbled, ungrammatical, and difficult to interpret. Chinese-to-English systems need particular improvement, despite the importance of this language pair, while English-to-Chinese translation, equally important for communication between individuals, is rarely studied. This project develops methods for automatically learning correspondences between Chinese and English at a semantic rather than surface level, allowing machine translation to benefit from recent work in semantic analysis of text and natural language <br\/>generation. One part of this work determines what types of semantic <br\/>analysis of source language sentences can best inform a translation system, focusing on analyzing dropped arguments, co-reference links, and discourse relations between clauses. These linguistic phenomena must generally be made more explicit when translating from Chinese to English. A second part of the work integrates natural language generation into statistical machine translation, leveraging generation technology to determine sentence boundaries, ordering of constituents, and production of function words that translation systems tend to get wrong. A third part develops and compares algorithms for training and decoding machine translation models defined on semantic representations. All of this research exploits newly-developed linguistic resources for semantic analysis of both Chinese and English.<br\/><br\/>The ultimate benefits of improved machine translation technology are easier access to information and easier communication between individuals. This in turn leads to increased opportunities for trade, as well as better understanding between cultures. This project's systems for both Chinese-to-English and English-to-Chinese are developed with the expectation that the approaches will be applied to other language pairs in the future.","title":"RI: Large: Collaborative Research: Richer Representations for Machine Translation","awardID":"0910992","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["24532","511542"],"PO":["565215"]},"153636":{"abstract":"CSR:Small:Failure-Aware Monitoring and Management of Online Availability and Performance for Dependable Computing Clusters<br\/><br\/>Abstract:<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Computational clusters and clusters coalitions continue to grow in scale and in the complexity of their components and interactions. In these systems, component failures become norms instead of exceptions. Failure occurrence as well as its impact on system performance and operation costs is becoming an increasingly important concern to system designers and administrators. The success of petascale computing will depend on the ability to provide dependability at scale. Failure management and failure-aware resource management are crucial techniques for understanding emergent, system-wide phenomena and self-managing resource burdens.<br\/><br\/>This project investigates a set of innovative techniques on failure-aware monitoring and management for system-level availability assurance. In this project, we will develop a framework along with mechanisms for failure-aware autonomic resource management in large clusters, quantify the temporal and spatial correlations among failure occurrences for proactive failure management, and devise resource allocation and reconfiguration approaches to deal with the system availability and productivity issues caused by component failures that occur frequently in modern large and complex clusters. <br\/><br\/>Broader impacts of the project include the publication and dissemination of research results and developed software artifacts. The research enables collaborative research opportunities for students and faculty in the program, as well as undergraduate science and engineering students in New Mexico. Research-based materials about dependable high-performance computing will also be instilled into the undergraduate and graduate computer science and engineering curriculum.","title":"CSR:Small:Failure-Aware Monitoring and Management of Online Availability and Performance for Dependable Computing Clusters","awardID":"0915396","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[408866],"PO":["535244"]},"153757":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>High-performance real-time embedded systems have stringent requirements for key performance properties, such as end-to-end timeliness and reliability, in order to operate properly. In recent years, with the continuously decreasing feature size and increasing demand for computational capabilities, today's high-performance embedded systems face an increasing probability of overheating and even thermal failures. As a result, their power consumption and temperature must be explicitly controlled for improved reliability. On the other hand, multi-core processors have recently become the main trend in the current processor development, due to some well-known technological barriers. Consequently, future high-performance embedded systems can be expected to be equipped with multi-core or even many-core processors. Therefore, new control algorithms need to be developed to simultaneously meet the timing and power\/thermal constraints for multi-core embedded systems.<br\/><br\/>This project aims to develop a holistic framework, based on recent advances in feedback control theory, to meet both timing and power\/thermal constraints for high-performance embedded systems with multi-core processors. Our framework can make three major contributions. First, our solution can coordinate different control strategies to meet both constraints with guaranteed system stability. Second, we propose novel power\/thermal control (capping) algorithms for multi-core processors to achieve improved control accuracy and system performance. Third, we propose new feedback scheduling algorithms to utilize the new features available in multi-core processors, such as shared L2 caches and per-core dynamic voltage frequency scaling (DVFS), for improved real-time performance. We also plan to investigate heterogeneous cores, memory power management, and system controllability for better power\/thermal control and timeliness guarantees.","title":"CSR:Small: A Control-Theoretic Approach to Simultaneously Meeting Timing and Power\/Thermal Constraints for Multi-Core Embedded Systems","awardID":"0915959","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554423"],"PO":["565255"]},"153878":{"abstract":"With the continuous growth of data production and the ever expanding computing infrastructure, future extreme-scale data intensive computing systems are facing unprecedented design and control challenges to meet the continuous and increasing demand for information processing.<br\/>Scalability, robustness, continuous availability, and service quality are the key attributes desired to ensure that the system designed today is capable of operating with the same efficiency on the extreme scale of the future.<br\/>The goal of the research described in this proposal is to develop theoretical foundations and practical control algorithms that enable the scalable design and efficient management of future extreme-scale data-intensive computing. Specifically, the researchers will<br\/>1) identify fundamental design principles needed to achieve scalability when developing network infrastructure and software systems in large scale. Here the concerns are to understand the performance degradation limited by various factors, including network structure, processor speeds, buffering\/storage capacities, etc.<br\/>2) develop distributed control strategies on operator placement, data storage, load shedding, and resource allocation so as to enable efficient in-network information processing.<br\/>The project will produce a deeper and quantitative understanding on the fundamental design principles and control strategies needed to achieve scalability, robustness and quality of service for future data-intensive information service systems. These advances will occur through a collaborative effort spanning multiple disciplines ranging from performance modeling, networking, queueing, to optimization.","title":"DC: Small: Collaborative Research: Managing Extreme-Scale Data Intensive Computing: Fundamental Design and Control Strategies","awardID":"0916440","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["523640"],"PO":["560586"]},"151216":{"abstract":"This project has two major components. The first is an investigation of visualization and analysis methods for data sets in high dimensions, with a focus on categorical variables whose number of unique levels is comparable to the total sample size. Examples of such variables include search query strings, ISBNs, song titles, author names, URLs, genotypes, environments, and customer ID numbers. The visualization methods are designed to show broad trends and to highlight anomalies. The inferential methods are of the sample reuse type: the bootstrap and cross-validation. New methods are necessary here because the data sets have complicated interlocking patterns that invalidate any IID sampling assumptions. The second component is better statistical inference by improving on their numerical methods. This includes calibration of empirical likelihood methods to get better coverage and to extend confidence regions for the mean beyond the convex hull of the data points. It also includes the embedding of quasi-Monte Carlo sampling methods into Markov chain Monte Carlo algorithms to combine the accuracy of the former and the wide applicability of the latter.<br\/><br\/><br\/>Exploratory data analysis of categorical variables is useful to see broad patterns including small groups of customers that have similar tastes for a small list of songs or books or movies. It is also useful to identify anomalies that may indicate abusive behavior, including cyber-attack, and what is commonly called spam in the online context. One of the original motivations for the sample reuse methods is in crop science. In some of those problems, a large number of plant varieties (genotypes) are grown under many different environmental conditions. A statistical model is used to determine which varieties to use in each environment. Earlier statistical methods were based on assumptions that don't fit this setting and they often did not select the best model. New methods from this project may therefore be used to select better models which then result in increased production of food and fiber. The empirical likelihood work is basic research aimed at removing unnecessary mathematical assumptions from statistical models in order to widen their applicability. The Monte Carlo sampling component of the project is basic research on a computational technique used extensively in physics as well Bayesian statistical inference.","title":"Monte Carlo and Quasi-Monte Carlo Methods for Statistics","awardID":"0906056","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["564007"],"PO":["565309"]},"153999":{"abstract":"Due to the importance of uncertain data for a large number of applications,<br\/>there has been significant recent interest in database support for uncertain<br\/>data. Existing work in this area includes new models for uncertain data,<br\/>prototype implementations, and efficient query processing algorithms for<br\/>specific types of queries. Despite the recent efforts, several important aspects<br\/>of uncertain data management remain unexplored. This project addresses two<br\/>of these areas: Query Optimization and Support for Non-Relational Operators.<br\/><br\/>The first goal is about efficient execution of uncertain data queries. As with<br\/>traditional data, efficient execution is necessary for ensuring the viability of<br\/>uncertain data management systems. However, due to the complications of<br\/>ensuring correct results, and the need for CPU-intensive operations over<br\/>probability distributions, the goal is critical and challenging. In this project,<br\/>automatic query optimizations are developed, through query rewriting rules<br\/>that involve probability threshold operators, corresponding access methods,<br\/>and cost estimation functions.<br\/><br\/>The difficulty of handling uncertainty when dealing with non-relational<br\/>operators has been expressed in many domains. The project aims to<br\/>advance the capability of tracking the exact impact of uncertain inputs as<br\/>data is processed by arbitrary programs, leveraging advanced techniques<br\/>from the area of program analysis. A key problem with traditional Monte<br\/>Carlo based solutions lies in correctly identifying independence in the output<br\/>of Monte Carlo simulations. Data lineage tracing, which identifies the set of<br\/>inputs used to compute an output value, is used to address the challenge.<br\/>Furthermore, a program dependence tracing based approach is devised to<br\/>trace the propagation of uncertainty during execution of arbitrary binary<br\/>code. The technique does not rely on Monte Carlo simulations, and does<br\/>not require access to source code or domain knowledge.<br\/><br\/>For further information see the project web page:<br\/>http:\/\/www.cs.purdue.edu\/homes\/sunil\/uncertainty","title":"III: Small: Towards Scalable and Comprehensive Uncertain Data Management","awardID":"0916874","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["470080","550848"],"PO":["563727"]},"152668":{"abstract":"Many of the most interesting and valuable discoveries that can be made from data arise not from the evaluation of single records, but from identifying a set of records that are anomalous in some interesting way. Together they may indicate for example the emergence of a disease outbreak or new patterns of criminal activity. One can view pattern discovery as an interactive process between data analysis algorithms and human users who have expertise in the domain. This research will develop an integrated framework of probabilistic methods to interact with the user in detecting, characterizing, explaining, and learning anomalous patterns over groups of records. The focus is on the many situations where the data (and the probabilistic patterns to be discovered) are not appropriate for using other existing techniques, such as graph mining or frequent sets. The proposed methods will search over arbitrary subsets of records and evaluate their correspondence to known, potentially very complex, probabilistic patterns, or their failure to match baseline data under various learned statistical models. These methods will assist the user in understanding and modeling the discovered, previously unknown anomalies to be identi&#64257;able as a known pattern when encountered in the future. <br\/><br\/>Intellectual Merit<br\/>This collaborative team of researchers will develop, implement, and evaluate a general, comprehensive, and widely applicable probabilistic framework for pattern discovery. The proposed work will address these challenging and important research questions: <br\/> - How can machine learning concepts such as classi&#64257;cation and anomaly detection be generalized to consider groups of records rather than single records?<br\/> - How can a detection algorithm simultaneously detect and differentiate between known and currently unknown pattern types?<br\/> - How can an algorithm explain clearly to a user what pattern was found and why?<br\/> - How can an algorithm learn new pattern types through feedback from a user?<br\/><br\/>The ability to detect, characterize, explain, and learn patterns from groups of records in massive datasets will provide a qualitatively new approach for advancing discovery of knowledge from data. <br\/><br\/>Broader Impact<br\/>Although the applications for these algorithms are innumerable, development and testing will be prioritized in the areas of patient care in the intensive care unit (ICU) and aircraft &#64258;eet maintenance. Through the team's existing collaborations, the algorithms will also be used during the project in other areas including food safety, scientific discovery in astronomy sky surveys, and detection of geographic hot-spots of criminal activity. Together, these applications will demonstrate the methods' value across a wide spectrum of domains and tasks. <br\/><br\/>Key Words: anomalous patterns; pattern discovery; probabilistic models; incremental learning.","title":"III: Large: Discovering Complex Anomalous Patterns","awardID":"0911032","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["565056",406755,"550804","548334","432417"],"PO":["563727"]},"153405":{"abstract":"There has been increasing interest in affective dialogue systems, motivated by the belief that in human-human dialogues, participants seem to be (at least to some degree) detecting and responding to the emotions, attitudes and metacognitive states of other participants. The goal of the proposed research is to improve the state of the art in affective spoken dialogue systems along three dimensions, by drawing on the results of prior research in the wider spoken dialogue and affective system communities. First, prior research has<br\/>shown that not all users interact with a system in the same way; the proposed research hypothesizes that employing different affect adaptations for users with different domain aptitude levels will yield further performance improvement in affective spoken dialogue systems. Second, prior research has shown that users display a range of affective states and attitudes while interacting with a system; the proposed research hypothesizes that adapting to multiple user states will yield further performance improvement in affective spoken dialogue systems. Third, while prior research has shown preliminary performance gains for affect adaptation in semi-automated dialogue systems, similar gains have not yet been realized in fully automated systems. The proposed research will use state of the art empirical methods to build fully automated affect detectors. It is hypothesized that both fully and semi-automated versions of a dialogue systemthat either adapts to affect differently depending on user class, or that adapts to multiple user affective states, can improve performance compared to non-adaptive counterparts, with semi-automation generating the most improvement. The three hypotheses will be investigated in the context of an existing spoken dialogue tutoring system that adapts to the user state of uncertainty. The task domain is conceptual physics typically covered in a first-year physics course (e.g., Newtons Laws, gravity, etc.). To investigate the first hypothesis, a first enhanced system version will be developed; it will use the existing uncertainty adaptation for lower aptitude users with respect to domain knowledge, and a new uncertainty adaptation will be developed and implemented to be employed for higher aptitude users. To investigate the second hypothesis, a second enhanced systemversion will be developed; it will use the existing uncertainty adaptation for all turns displaying uncertainty, and a new disengagement adaptation will be developed and implemented to be employed for all student turns displaying a second state of disengagement. A controlled experiment with the two enhanced systems will then be conducted in a Wizard-of-Oz (WOZ) setup, with a human Wizard detecting affect and performing speech recognition and language understanding. To investigate the third hypothesis, a second controlled experiment will be conducted, which replaces the WOZ system versions with fully-automated systems.<br\/><br\/>The major intellectual contribution of this research will be to demonstrate whether significant performance gains can be achieved in both partially and fully-automated affective spoken dialogue tutoring systems 1) by adapting to user uncertainty based on user aptitude levels, and 2) by adapting to multiple user states hypothesized to be of primary importance within the tutoring domain, namely uncertainty and disengagement. The research project will thus advance the state of the art in both spoken dialogue and computer tutoring technologies, while at the same time demonstrating any differing effects of affect-adaptive systems under ideal versus realistic conditions. More broadly, the research and resulting technology will lead to more natural and effective spoken dialogue-based systems, both for tutoring as well as for more traditional information-seeking domains. In addition, improving the performance of computer tutors will expand their usefulness and thus have substantial benefits for education and society.","title":"RI: Small: An Affect-Adaptive Spoken Dialogue System that Responds Based on User Model and Multiple Affective States","awardID":"0914615","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["488661",408297],"PO":["565227"]},"153889":{"abstract":"Computing devices equipped with multiple radio interfaces and working on multiple channels are becoming predominant in wireless networks. These networks are usually Multi-Interface Multi-Channel Mobile Networks (MIMC-MANETs). However, the study of security vulnerabilities and the research of fundamental security mechanisms in channel management of MIMC-MANETs have been seriously lagging behind the rapid progress of other research. <br\/><br\/>This project studies the security of MIMC-MANETs in three aspects. <br\/><br\/>1. Investigating the unique (unknown) security vulnerabilities associated with channel management in MIMC-MANETs. <br\/><br\/>2. Developing MIMC-enabled security mechanisms. This project redefines channel conflict, reveals the fundamental causes and consequences of channel attacks, and develops novel and attack-resilient security mechanisms to secure channel management (and routing) in MIMC-MANETs. New security mechanisms utilize the capability of MIMC, and include collaborative channel monitoring, channel-utilization based channel conflict detection and resolution, logic-based attack investigation, and cross-layer security design. <br\/><br\/>3. Building MIMC security and performance evaluation toolkits: This project develops evaluation toolkits and builds experimental environments. The toolkits and experimental environments can serve as a major testbed for the whole research community to conduct future MIMC-MANET research.<br\/><br\/>This project will advance the understanding of the unique security problems in MIMC-MANETs. The developed techniques will greatly enhance the security of the MIMC network infrastructure and secure the mission critical applications built atop such networks. Broader impacts will result from the education, outreach, and dissemination initiatives. Educational resources from this project, including course modules and teaching laboratory designs, will be disseminated through a dedicated Website.","title":"NeTS: Small: Collaborative Research:Secure and Resilient Channel Allocation in Multi-Radio Wireless Networks","awardID":"0916469","effectiveDate":"2009-09-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["277956"],"PO":["557315"]},"152558":{"abstract":"The Internet suffers from insufficient service quality to reliably support many real-time, high bitrate applications. This shortcoming is due in large part to users or providers not considering the effect their choices have on others ? in other words the resulting externalities. For example, users who download movies during the work day reduce the quality of the network for more time-critical applications; in a non-neutral network, individual ISPs may overcharge high-value applications if they do not consider the interactions of such charges across ISPs. Depending on the circumstances, the problem can be due to a combination of the following three effects: i) the technology of the network does not enable the user or provider to make better choices; ii) the network does not give the user or provider the information to make better choices; iii) the user or provider lacks an incentive to make better choices even if he can. This project will investigate how these effects impact service quality in the network. Using this analysis as a basis, remedies for these effects will be investigated. The remedies may include combinations of new protocols and technology, pricing mechanisms, and regulation ? including requirements and\/or mechanisms for information disclosure. <br\/><br\/>Intellectual Merit: <br\/>This project addresses fundamental scientific and engineering questions in networking. The scientific questions include suitable formulation and analysis of the strategic choices that the users, content providers, service providers, and other parties in the network face when they interact. The properties of the resulting equilibrium strategies and their distributed computation raise novel mathematical and algorithmic questions of broad relevance. Other fundamental scientific issues addressed include how to provide incentives for network evolution and for improved reliability. Engineering questions concern the scalability of the proposed algorithms and protocols, their security and robustness, how they can be deployed incrementally, and their extensibility as new technologies, services, and applications get implemented. <br\/><br\/>Broader Impact: <br\/>The investigators expect that the work will contribute to a paradigm shift in the design of the future network. The focus on externalities, which is central to our project, has been largely unexplored and our preliminary investigations demonstrate its substantial importance. The investigations undertaken in the course of this project will suggest how network design should be modified to account for externalities and network informational imperfections. This project, with its focus on the intersection of the engineering and economic issues of network services, will offer ideal research experience to the project?s Ph.D. students. It is expected that the experiences and results from this project will greatly benefit the PI?s courses as well, in particular by making students aware of the inherent tradeoffs in engineering systems that function in a market context.","title":"NetSE: Large: Collaborative Research: Improving Internet Incentives","awardID":"0910695","effectiveDate":"2009-09-01","expirationDate":"2012-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":[406454],"PO":["565090"]},"153537":{"abstract":"Most real software systems consist of modules developed in<br\/>multiple programming languages. Different languages differ in their<br\/>security assumptions and guarantees. Consequently, even if single<br\/>modules are secure in some language model and with respect to some<br\/>security policy, there is usually no uniform security guarantee on a<br\/>whole multilingual system. This project focuses on low-overhead<br\/>techniques for providing security guarantees to software systems in<br\/>which type-safe languages such as Java interoperate with native code.<br\/>Native code is developed in low-level languages including C, C++, and<br\/>assembly languages. Although often used in software projects, native<br\/>code is notoriously insecure and is a rich source of security<br\/>vulnerabilities. The PIs are developing a two-layered approach to<br\/>alleviating security threats posed by native code to type-safe<br\/>languages: (1) Binary rewriting tools and their verifiers are being<br\/>incorporated into the Java Virtual Machine (JVM) for rewriting and<br\/>verifying native modules at the machine-instruction level to enforce<br\/>security policies; (2) A safe dialect of C for interoperation with<br\/>Java is being designed; with the help of programmer annotations, the<br\/>safety of programs in this dialect can be statically verified. The<br\/>outcome of this project will enable popular platforms such as the JVM<br\/>and .NET and other major programming languages (e.g., Python, OCaml,<br\/>etc.) to incorporate native modules safely. The developed principles<br\/>will also be applicable to web browsers and operating systems in which<br\/>there is a need of extending them with untrusted low-level modules<br\/>without comprising host security.","title":"TC: Small: Collaborative Research: Securing Multilingual Software Systems","awardID":"0915030","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["518022"],"PO":["564388"]},"153779":{"abstract":"Collaborative browsing, also known as co-browsing, allows multiple users to access the same web pages in a simultaneous manner and collaboratively fulfill certain tasks. As a useful and attractive technique, co-browsing has a wide range of important applications such as online training and customer supporting. Existing co-browsing solutions must use either a specific collaborative platform, a modified web server, or a dedicated proxy to coordinate the browsing activities between web users. Besides, these solutions usually require users to install special software on their computers. These requirements heavily impede the wide use of collaborative browsing among Internet users. We propose to design and develop an efficient framework for Real-time Collaborative Browsing. This framework is a pure browser-based solution. It leverages the power of Ajax (Asynchronous JavaScript and XML) techniques and the extensibility of modern web browsers for performing co-browsing. Our objective is to achieve real-time collaboration among web users, without the involvement of any third-party platforms, servers, or proxies. The proposed framework will enable fine-grained co-browsing on arbitrary web sites and web pages. The success of this project will provide significant research contributions to on-line collaboration. Our research results will be disseminated to industry and academia through high-quality publications and the development of prototypes. The educational aspect of this project focuses on integrating education and research activities, and enhancing the undergraduate and graduate system and networking curricula.","title":"CSR: Small: An Efficient Framework for Real-Time Collaborative Browsing","awardID":"0916022","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[409225],"PO":["493916"]},"157805":{"abstract":"CPS: Small: Collaborative Research: Localization and System Services for SpatioTemporal Actions in Cyber-Physical Systems<br\/><br\/>The objective of this research is to develop models, methods and tools for capturing and processing of events and actions in cyber-physical systems (CPS) in a manner that does not violate the underlying physics or computational logic. The project approach uses a novel notion of cyber-physical objects (CPO) to capture the mobility and localization of computation in cyber-physical systems using recent advances in geolocation and the Internet infrastructure and supports novel methods for spatiotemporal resource discovery.<br\/><br\/>Project innovations include a model for computing spatiotemporal relationships among events of interests in the physical and logical parts of a CPS, and its use in a novel cyberspatial reference model. Using this model the project builds a framework for locating cyber-physical application services and an operating environment for these services. The project plan includes an experimental platform to demonstrate capabilities for building new OS services for CPS applications including collaborative control applications drawn from the intermodal transportation system. <br\/><br\/>The project will enable design and analysis of societal scale applications such as the transportation and electrical power grid that also include a governance structure. It will directly contribute to educating an engineering talent pool by offering curricular training that range from degree programs in embedded systems to seminars and technology transfer opportunities coordinated through the CalIT2 institute at UCSD and the Institute for Sensing Systems (ISS) at OSU. The team will collaborate with the non-profit Milwaukee Institute to explore policies and mechanisms for enterprise governance systems.","title":"CPS:Small:Collaborative Research:Localization and System Services for SpatioTemporal Actions in Cyber-Physical Systems","awardID":"0932216","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["499286"],"PO":["561889"]},"155748":{"abstract":"Proposal #: CNS 09-23131<br\/>PI(s): Yang, Ruigang; <br\/> Crothers, George M.; Dinger, James S.; Seales, William B.; Weisenfluh, Gerald A.<br\/>Institution: University of Kentucky <br\/> Lexington, KY 40506-0057<br\/>Title: MRI\/Dev.: Versatile Mobile Range Scanning System Enabling Large-scale High-Density 3D Data Acquisition for Cross-Disciplinary Research<br\/><br\/>Project Proposed:<br\/>This project, developing a versatile mobile range system based on the principle of Light Detection and Ranging (LIDAR), enables:<br\/>- New data driven approaches in 3D reconstruction and modeling, pattern recognition, and data mining;<br\/>- Quantitative studies in geology (e.g., analysis of hill slope movement and characterization of outcrops;<br\/>- Archaeological recording of fragile sites with limited access (e.g., those in caves).<br\/>The system consists of 3 LIDAR sensor heads, GPS and inertial measurement unit, high-resolution digital cameras, and processing software to generate high-resolution, accuracy colored point clouds that are geo-referenced. Unlike typical laser scanning system, it supports both stationary and high-speed mobile scanning. For example, when mounted on a vehicle, it should be able to generate over 50 points per meter given a speed of 100km\/hr. In comparison, the typical density from an airborne LIDAR system is only 1-2 points per meter. This level of density at high scanning speeds allows rapid 3D scanning of large scenes not possible with either stationary systems (too slow) or airborne systems (too sparse). Through relatively simple hardware modification and more sophisticated processing algorithms, the state of the art in scanning range, density, and operational conditions is expected to advance as follows:<br\/>- Increasing the scanning range over 6 times in the mobile mode, from the original 100 m (specified by the LIDAR sensor vendor) to greater than 600 m.<br\/>- Improving the point density over 10 times by applying the principle of compressing sensing and information from the high-resolution color image, without changing the hardware configuration.<br\/>- Developing the ability to scan beyond line of sight with inexpensive self-calibrating reflective mirrors, and develop real-time vision and inertial-based navigation to allow GPS-free operations for mobile scan (critical for scanning in underground areas, where many archaeological sites reside).<br\/>Plans also include building a large scale 3D cityscape database with over 30 billions of raw data samples to cover the entire Lexington metro area. The database will be shared to enable research beyond graphics and vision, including, but not limited to, data compression, transmission, visualization, index and retrieval, and computational geometry.<br\/><br\/>Broader Impacts: The instrument is expected to be the first university-owned mobile laser range sensing system, which might inspire and facilitate many exciting new research venues. The scanning and processing tasks will be carried out and documented by undergraduate students. The geological and archaeological studies will be used to attract local students, in particular those underrepresented from Appalachia. The system will have commercial values to provide on-demand scanning for applications ranging from construction, city planning, law enforcement, survey and mapping, to 3D imaging. Commercial users will be charged a fee to maintain operation and sustain the enabling data beyond the life of the award.","title":"MRI: Development of Versatile Mobile Range Scanning System?Enabling Large-scale High-density 3D Data Acquisition for Cross-Disciplinary Research","awardID":"0923131","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["523441","494196",414969,414970,414971],"PO":["557609"]},"151029":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/>This study addresses a core problem in biology: to predict function from massive and diverse experimental data that identify individual cell components, such as proteins, or suggest interactions among them. The approach will model all such information as networks. New network analyses methods will then be developed to overcome conflicting information due to experimental errors or inherent biological complexities. Other methods will aim at weighing optimally different types of information so that they may be best combined together. The result will pool biological data on a dramatically larger scale than previously feasible to yield a self-consistent and improved picture of protein function. More broadly, however, the network analysis techniques developed here should apply widely and efficiently to any massive, diverse and conflicting data, typical of complex systems.<br\/><br\/>Specifically, the investigators will integrate information from frustrated networks by diffusing diverse evolutionary, structural and functional data along the edges of protein graphs. To cope with the large network sizes, and data inconsistencies or alternative interpretation, semi-supervised learning algorithms will be extended, in aim 1, to test prediction accuracy under different network information diffusion mechanisms and, in aim 2, under alternative weighing strategies to pool complementary information networks. The outcome will (1) implement realistic biological networks with millions of nodes and edges to benchmark computational efficiency; (2) predict protein function and the phenotypes they induce based on integrated, massive and heterogeneous biological data sets; and (3), since high computational efficiency will be maintained even in networks with spin glass type frustration, these results will be transformative across a wide variety of fields by extending graph-based semi-supervised learning to a broad, cross-discipline class of complex networks with random interactions. Students will be trained at the interface between computational science and biology and developed software tools will be made public to the research community.","title":"Data Flow across Heterogenous and Frustrated Protein Networks","awardID":"0905536","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["473954"],"PO":["565223"]},"158927":{"abstract":"In today's high-end computing (HEC) systems, the parallel file system (PFS) is at the core of the storage infrastructure. PFS deployments are shared by many users and applications, but currently there are no provisions for differentiation of service - data access is provided in a best-effort manner. As systems scale, this limitation can prevent applications from efficiently utilizing the HEC resources while achieving their desired performance and it presents a hurdle to support a large number of data-intensive applications concurrently. This NSF HECURA project tackles the challenges in quality of service (QoS) driven HEC storage management, aiming to support I\/O bandwidth guarantees in PFSs by addressing the following four research aspects: 1. Per-application I\/O bandwidth allocation based on PFS virtualization, where each application gets its specific I\/O bandwidth share through its dynamically created virtual PFS. 2. PFS management services that control the lifecycle and configuration of per-application virtual PFSs as well as support application I\/O monitoring and storage resource reservation. 3. Efficient I\/O bandwidth allocation through autonomic, fine-grained resource scheduling across applications that incorporate coordinated scheduling and optimizations based on profiling and prediction. 4. Scalable application checkpointing based on performance isolation and optimization on virtual PFSs customized for checkpointing I\/Os.","title":"HECURA: Collaborative Research: QoS-driven Storage Management for High-end Computing Systems","awardID":"0938045","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["534488"],"PO":["565272"]},"157739":{"abstract":"CPS:Small:Control Design for CyberPhysical Systems Using Slow Computing<br\/><br\/>The objective of this research is to develop principles and tools for the<br\/>design of control systems using highly distributed, but slow, computational<br\/>elements. The approach of this research is to build an architecture that<br\/>uses highly parallelized, simple computational elements incorporating<br\/>nonlinearities, time delay and asynchronous computation as integral design<br\/>elements. Tools for the design of non-deterministic protocols will be<br\/>developed and demonstrated using an existing multi-vehicle testbed at<br\/>Caltech.<br\/><br\/>The motivation for using \"slow computing\" is to develop new feedback control<br\/>architectures for applications where computational power is extremely<br\/>limited. Examples of such systems are those where the energy usage of the<br\/>system must remain small, either due to the source of power available<br\/>(e.g. batteries or solar cells) or the physical size of the device<br\/>(e.g. microscale and nanoscale robots). A longer term application area is<br\/>in the design of control systems using novel computing substrates, such as<br\/>biological circuits. A critical element in both cases is the tight coupling<br\/>between the dynamics of the underlying process and the temporal properties<br\/>of the algorithm that is controlling it.<br\/><br\/>The implementation plan for this project involves students from multiple<br\/>disciplines (including bioengineering, computer science, electrical<br\/>engineering and mechanical engineering) as well as at multiple experience<br\/>levels (sophomores through PhD students) working together on a set of<br\/>interlinked research problems. The project is centered in the Control and<br\/>Dynamical Systems department at Caltech, which has a strong record of<br\/>recruiting women and underrepresented minority students into its programs.","title":"CPS: Small: Control Design for CyberPhysical Systems Using Slow Computing","awardID":"0931746","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["549583"],"PO":["565274"]},"154109":{"abstract":"The award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Cognitive radio (CR) has the potential to improve spectrum utilization and expand wireless communication services by opportunistically utilizing underutilized spectrum bands. This project designs advanced cognitive radio access and power control algorithms that can achieve better spectrum efficiency while limiting interference to primary communications. Moving beyond the more traditional access strategies that rely only on secondary user (SU) spectral sensing to avoid collision with primary users (PUs), this research exploits various levels of primary network?s data link control (DLC) signaling and feedback information. Such DLC information is available in many practical wireless systems, such as transmission profile, receiver ACK\/NACK, channel quality indicator, and power control information. Utilizing such information elevates the level of SU cognition. It provides more efficient spectrum sharing, better PU protection (especially in the presence of multiple distributed SUs), and multiple levels of SU and PU interaction. The major outcomes include: 1) Distributed multi-SU cognitive access and power control based on PU receiver feedback information; 2) Optimal algorithms for distributed multi-SU access control in multi-channel cognitive environments; 3) Cognitive radio access robust to PU behavioral changes and incomplete PU feedback information; and 4) Hierarchical cognitive radio networks of users with varying degrees of cognition. This significantly broadens the future applications of wireless services in areas with limited open spectrum. The plan recruits students, especially from under-represented groups, and integrates the results into the classes for computer science and electrical engineering majors.","title":"NeTS: Small: Beyond Listen-Before-Talk: Advanced Cognitive Radio Access Control in Distributed Multiuser Networks","awardID":"0917251","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["436918","551148"],"PO":["557315"]},"148917":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Today's spoken dialogue systems (SDS) enable limited verbal communication between humans and machines. DialRC serves the whole SDS community with training, data, a common research platform and a challenge in order to push its results to the next level. DialRC coordinates workshops and tutorials for new and for advanced researchers, provides large amounts of data from deployed SDS, offers a platform where studies can be run and manages a challenge where research can be compared. A novel aspect of DialRC is the access to large quantities of real users. This translates into SDS that can be better adapted to real world conditions and thus to more natural and efficient communication. Coordinated challenges in other areas have helped focus research efforts and provided comparisons of techniques in one same environment. The result of these challenges has been a dramatic increase in findings in the area. DialRC's Spoken Dialogue Challenge will afford the same changes in the SDS domain.<br\/>DialRC is a central point of exchange of information, software, experimental techniques and data. It is transforming American research into a highly competitive and innovative force for human interaction with machines. Due to the coordinated and wide-reaching services that DialRC offers, SDS researchers are now able to improve information access for everyman.<br\/>www.dialrc.org","title":"CI-ADDO-NEW: Dialog Research Center (DialRC)","awardID":"0855058","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["561898",396893],"PO":["565215"]},"159807":{"abstract":"The study of gene regulation is central to modern biology. A significant portion of the nascent field of synthetic biology has revolved around building synthetic gene networks to recapitulate regulatory mechanisms found in nature or to engineer novel biological functions. However, artificial gene networks have not approached the sophistication of their natural counterparts in either design or performance. There are several technical and scientific challenges that currently limit the engineering of large-scale integrated synthetic genetic networks. This research centers on developing a framework for automating the process of gene network design by a) obtaining various working \"parts\" of gene regulatory mechanisms from nature and b) by applying engineering sciences to learn how to compose them reliably into novel systems which have predictable behaviors. The value of this project will be demonstrated through the development of the ?Programmable Rhizosphere?, which is a framework for engineering mutualism between model plant and soil microbe species. The Programmable Rhizosphere will allow control of interactions between disparate organisms, and represents a significant step towards our ability to manipulate complex ecosystems.<br\/><br\/>Broader impact: This project brings together researchers from top US institutions as well as establishes a collaboration with major universities in the UK. Graduate students and postdoctoral researchers associated with this project will get an opportunity to participate in a multi-institution, multidisciplinary research project. They will have the opportunity to train on a wide variety of techniques in computational and molecular biology. The results of the project will be disseminated to the broader public including middle and high school students through the development of informational materials and hands-on demonstrations designed for educating the public on the technologies and potential impact of synthetic biology. In addition to the advances in the understanding of engineering synthetic regulatory systems, the Programmable Rhizosphere technology has broad implications for sustainability in agriculture. In particular, these technologies could be used to engineer beneficial phenomena such as nitrogen fixation in agricultural crops, which would displace petroleum-based fertilizers currently used in agricultural production.","title":"COLLABORATIVE RESEARCH: Programming the rhizosphere through highly integrated genetic, spatio-temporal control systems","awardID":"0943386","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7552","name":"COFFES"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7954","name":"SANDPIT"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}}],"PIcoPI":[427476],"PO":["565223"]},"148939":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Given the growing global importance of water issues caused by dwindling water resources and global climate change, building and deploying a real-time sensing infrastructure across water bodies---including rivers, streams, and watersheds --- will be one of the great scientific hurdles and also one of the great research opportunities of the next several decades. Despite numerous technological advances in wireless sensor networks, a chasm separates what is offered by off-the-shelf products and what is needed by scientists for robust, easy deployment of a monitoring infrastructure over running waters. This research involves the design of a solar-powered river sensor network testbed that will enable the vision of perpetual river sensor deployments streaming data continually to laboratory servers.<br\/><br\/>This testbed will enable fundamental, cross-disciplinary research on developing robust, easily deployable over-water wireless networks as well as sensor platforms for monitoring rivers and streams. Specific research challenges include design of solar-powered wireless networks to address lack of electrical infrastructure, heterogeneous multi-radio sensor nodes and protocols to address problems posed by sparse deployments over large geographic regions, and self-managing sensor networks for unattended management. In addition to addressing Computer Science research problems, the testbed will enable environmental scientists to study several scientific research questions, while using the testbed as a test site for larger real-time monitoring deployments in other rivers. The proposed testbed will also directly impact undergraduate research and student diversity by 1) involving undergraduate students through REU programs, 2) impacting curriculum development by enabling field courses in sensor networks and ecology, and 3) involving local high schools to highlight river conservation issues.","title":"CRI:II-NEW: Design of a Solar-powered River Sensor Network Tested","awardID":"0855128","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["526997","558563"],"PO":["564993"]},"160940":{"abstract":"This proposed work seeks to develop a computational approach that can be used to learn a skill from humans and, through the same medium, turn around and teach other less proficient humans what it learned. The learning and teaching will be done through agents that contain the knowledge relevant to the desired skills. Such an agent can be referred to as a learning and teaching agent (LATA). The work plans to accomplish this through two sequential approaches: 1) observational learning (by the agent only), and 2) force feedback learning and teaching. Observational learning will be used to build a minimally proficient LATA agent by observing a human perform the desired task or display the desired skill on a simulator. This agent will be called the baseline agent. This baseline agent will then be enhanced through force feedback learning, where a human will coach the system by providing corrective counter force in real time when the LATA agent errs in its performance of the task. The skills to be learned\/taught will require the use of a haptic device such as a joystick or steering wheel as the primary interface. It will learn the actions that the trainer employs to execute the task competently, and use the same haptic device to coach and\/or evaluate a less proficient human trainee in learning the same skill. The planned approach centers on using neuroevolutionary techniques. Neuroevolution has been successfully used to address highly complex problems such as pole balancing, abnormal behavior in drivers, and to evolve bots in video games that gradually improve their performance. The proposed work will modify the basic concept of neuroevolutionary techniques as necessary, and apply the resulting system to observational learning as well as force feedback refinement. The testbed domain will be a crane that off-loads boxes or containers from a ship and places them in some other conveyance such as a railroad car or truck. A computer simulation will be used for teaching the LATA agents how to do this. <br\/><br\/>Instructors are increasingly difficult to find, especially for specialty areas that require special skills. From a practical standpoint, this research would give organizations involved in training new tools to teach their constituents. Specific beneficiaries of this technology would include organizations that train students to perform tasks requiring complex motor skills such as driving a car, flying an airplane or operating a crane. The resulting agents could also be used to train operators of tele-operated robots, cranes, unmanned aerial vehicles and other such devices. Surgery training is another potential application of this approach given the appropriate haptic devices. Another interesting application could be for training disabled people basic motor skills.","title":"EAGER: Machines that Learn and Teach Seamlessly","awardID":"0948820","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["496768"],"PO":["564456"]},"160830":{"abstract":"Scientific computing has entered a new era of scale and sharing with the arrival of cyberinfrastructure for computational experimentation. A key emerging concept is scientific workflows, which provide a declarative representation of scientific applications as complex compositions of software components and the dataflow among them. Workflow systems manage their execution in distributed resources, track provenance of analysis products, and enable rapid reproducibility of results. In current cyberinfrastructure, there are well-understood mechanisms for sharing data, instruments, and computing resources. This is not the case for sharing workflows, though there is an emerging movement for sharing analysis processes in the scientific community.<br\/><br\/>This project explores computational mechanisms for sharing workflows as a key missing element of cyberinfrastructure for scientific research, with three major research foci: (1) Elicitation of new requirements that workflow sharing poses over current techniques to share software tools and libraries; (2) Understanding how shared workflow catalogs should be designed, as the existing data catalogs are a successful model, and software components require different representations and access functions; and (3) Studying what sharing paradigms might be appropriate for scientific communities. <br\/><br\/>Expected results from this work include: use cases for workflow sharing and reuse that motivate this research area, a comparison between software reuse and workflow reuse requirements, a specification of a workflow catalog defining expected functions and services, and an investigation of social issues that arise in building this new kind of shared resource in scientific communities. Results are available at the project Web site (http:\/\/workflow-sharing.isi.edu).","title":"III\/EAGER: Towards Workflows as First-Class Citizens in Cyberinfrastructure: Designing Shared Repositories","awardID":"0948429","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563687"],"PO":["563751"]},"150941":{"abstract":"Last Modified Date: 05\/02\/09 Last Modified By: Tatiana D. Korelsky <br\/><br\/>Abstract <br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Despite large acoustic differences in the speech of various talkers, humans are generally able to understand each other quickly and easily. The mechanisms by which humans map such variability onto a set of phonemes has been the subject of research for more than 50 years. This \"speaker normalization\" problem has generally been thought of in terms of normalizing the formant frequencies of a particular speaker with a reference set of formants. In this project, a novel approach to speaker normalization is explored, in which not formants but subglottal resonances <br\/>(SGRs) are normalized. SGRs have previously been shown to define a set of frequency bands within which formants may vary, yet retaining the same phonemic vowel quality. Normalizing SGRs (and associated frequency bands) therefore reduces formant variability in an effective way. In this project, effects of SGR normalization on automatic speech recognition <br\/>(ASR) performance are evaluated for both adult and child speakers of English and Spanish. In parallel, effects on human speech perception in multi-talker conditions are explored. Results are expected to improve ASR performance and shed light on human speech production and perception. The project will result in speech databases (including direct recordings of SGR acoustics) and ASR tools, which are critically useful for research in speech production, perception, speaker identification, and speech processing algorithms for cochlear implants and multi-lingual ASR. The collaboration in Engineering, Linguistics, Speech & Hearing, and Psychology facilitates a multidisciplinary learning environment. <br\/>Publications, results, databases, and tools will be disseminated to the research community.","title":"RI: Medium: Collaborative Research: The Effect of Subglottal Resonances on Machine and Human Speaker Normalization","awardID":"0905250","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[402370,402371],"PO":["565215"]},"160863":{"abstract":"This is funding to support a doctoral research symposium (workshop) of approximately 8 promising doctoral students from the United States and abroad, along with distinguished research faculty. The event will take place in conjunction with and immediately preceding the 22nd ACM Symposium on User Interface Software and Technology (UIST 2009), to be held October 4-7 in Victoria, British Columbia, Canada, and sponsored by the Association for Computing Machinery's Special Interest Group on Human Computer Interaction (SIGCHI). The UIST conference is the premier international forum for presenting innovations in the software and technology of human computer interaction. It brings together researchers and practitioners from diverse areas that include traditional graphical and web user interfaces, tangible and ubiquitous computing, virtual and augmented reality, multimedia, new input and output devices, and computer-supported cooperative work. Although UIST is a long-standing annual conference, this workshop will be just the 7th doctoral research symposium associated with the conference (NSF has supported these events from their inception). The three goals of this full-day event are to increase the exposure and visibility of the participants' work within the community, to help establish a sense of community among this next generation of researchers, and to help foster their research efforts by providing substantive feedback and guidance from a group of senior researchers in a supportive and interactive environment. Student participants will make formal presentations of their work during the workshop, and will receive feedback from a faculty panel. The feedback is geared to helping students understand and articulate how their work is positioned relative to other research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. Student position papers will be published in the UIST Conference Companion, and the students will also present posters relating to their work at a special session the first night of the conference. <br\/><br\/>Broader Impacts: The doctoral symposium will help expand the participation of young researchers pursuing graduate studies in the field of user interface software and technology, by providing them an opportunity to gain wider exposure in the community for their innovative work and to obtain feedback and guidance from senior members of the research community. It will further help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Because the students and faculty constitute a diverse group across a variety of dimensions, the students' horizons are broadened to the future benefit of the field. The organizers of the event will make special efforts to attract students from institutions not historically heavily represented at UIST and to foster diversity across under-represented groups.","title":"Workshop: User Interface Software and Technology (UIST) 2009 Doctoral Symposium","awardID":"0948521","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["530199"],"PO":["565227"]},"162810":{"abstract":"Peer-to-peer (P2P) networks have increased in popularity partly because they can be implemented atop a diverse collection of hardware and software, making them relatively inexpensive to deploy and maintain. The network infrastructure also tends to be highly fault-tolerant, and bandwidth and other computational resources tend to be well balanced across peers, making the network highly robust. In practice, many P2P networks remain vulnerable to denial of service attacks because the homogeneity of the network results in greater interdependence among hosts. Many existing P2P networks also suffer from serious data integrity vulnerabilities because it is easy for peers in the network to lie to other peers about the data they serve. The confidentiality desired by P2P users typically comes in two forms: Data confidentiality policies prohibit the leaking of high confidentiality, shared objects to low-privileged peers, while user anonymity policies prohibit the divulging of a user?s private information. Trusted data management is a key layer in providing environments for trusted collaboration. The team will use their secure P2P infrastructure with low level security enforcement mechanisms as a basis for developing a reputation-based trust management system to enforce discretionary access control. They will provide a comprehensive solution for the design and development of secure data management hosted on a peer to peer network, focused on query processing in such an environment with considerations for confidentiality, integrity, and trust.","title":"EAGER: Secure Peer-to-peer Data Management","awardID":"0959096","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["562519","522482"],"PO":["565136"]},"161732":{"abstract":"NSF funds are requested in support of the 9th International Seminar on EXPERIMENTAL TECHNIQUES AND DESIGN IN COMPOSITE MATERIALS. This seminar will focus on composite materials, both with polymeric and metallic matrix. The main topics are:<br\/>- Experimental techniques<br\/>- Damage mechanics and characterization<br\/>- Fatigue and fracture<br\/>- Impact and crashworthiness<br\/>- Mathematical and numerical modelling<br\/>- Nanocomposites<br\/>- Processing and properties<br\/>- Structural design and optimisation<br\/>Although the general aspects of composites will be discussed, particular emphasis will be given to the integration among testing, design and manufacturing for the definition of reliable design procedures. The area of nanocomposites will receive a special attention. <br\/><br\/>The seminar, covering the topics mentioned above, aims to represent a forum for researchers, scientist, engineers and designers, both of academic and industrial field, for exchanging ideas, proposing new solutions or even to put on the table questions still open about the development of reliable tools for an effective and safe design of composite components. Moreover the development of design procedures, the integration between testing, design and process are among the subjects expected to be discussed during the seminar.<br\/><br\/>The intellectual merit of the proposed activity is that it will represent a forum for researchers, scientist, engineers and designers, both of academic and industrial field, for exchanging ideas, proposing new solutions or even to put on the table questions still open about the development of reliable tools for an effective and safe design of composite components.<br\/><br\/>The broader impacts resulting from the proposed activity will include the development of design procedures, the integration between testing, design and process are among the subjects expected to be discussed during the seminar.","title":"NSF Support for 9th International Seminar on Experimental Techniques and Design in Composite Materials","awardID":"0953482","effectiveDate":"2009-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["491861"],"PO":["565223"]},"162821":{"abstract":"As the Tor network has grown since 2003 to almost 2000 volunteer relays, the anonymity that it can provide has grown too. This project is measuring Tor's network characteristics and usage, laying the foundation for evaluating its anonymity and improving performance. The project is addressing three components of this challenge. First, it invents new algorithms for collecting Tor network load and usage data safely, including new metrics to ensure that collected data doesn't harm privacy too much yet is still useful for research. Second, it collects and make available aggregated data about the live Tor network over time, and design and deploy new tools to manipulate and understand this data. Third, it identifies which measurements are necessary to support the wider performance and anonymity research questions, do the measurements, and feed the results into the anonymity community's ongoing research projects. <br\/><br\/><br\/>Research Activity 1: Directory and network data. Analyze patterns in directory authority opinions to tune them for better network anonymity and performance, and then track long-term characteristics like churn rate so researchers can simulate design changes. <br\/><br\/>Research Activity 2: Performance data. Design and perform measurements <br\/>to better understand why the Tor network has high (and highly variable) latency. Early investigations show that queuing inside Tor's relays contributes to this latency. Discovering what exactly is wrong with Tor's congestion control mechanisms will allow designers to learn whether proposed <br\/>improvements actually help. The project will also investigate other theories of how to improve performance, such as: a) Tor's round-robin scheduling approach should prioritize interactive traffic over bulk traffic; b) incentive systems could encourage users to relay traffic; c) Tor's path selection <br\/>algorithms should load balance better over the relays; and d) clients should handle variable latency and connection failures by dynamically adapting to observed network quality.","title":"EAGER: Privacy-preserving measurements of the Tor network to improve performance and anonymity","awardID":"0959138","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560676","548225","548225"],"PO":["497499"]},"150974":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project determines the fundamental limits of network secrecy from a network coding perspective, and then applies this theory to improve security guarantees in peer-to-peer and wireless networks. As network coding gains prominence as an important strategy for both wired and wireless networks, the project identifies both the advantages and vulnerabilities from using network coding. Subsequently, the effort develops a design methodology that exploits the advantages while carefully compensating for the vulnerabilities.<br\/><br\/>This project analyzes networks under both outsider and insider attacks. Specifically, coding mechanisms are developed to combat an external eavesdropper. Also, a combination of cryptographic and information-theoretic tools are used to combat internal modification attacks on the network. The results are then used in two case studies: eavesdropper attacks on wireless mesh networks and pollution attacks on P2P content distribution systems.<br\/><br\/>Secure network coded systems, once well understood, can greatly impact how networks are designed and deployed. Nearly every network setting (wireless, wired or heterogeneous) can benefit in terms of improved resilience (in addition to other performance benefits such as throughput) in its design. Case studies in this effort are designed to help transition the theoretical principles developed into practical algorithms.<br\/><br\/>The research team includes an industry member which will aid in transitioning our research ideas from theory to practice. The team will disseminate its findings through traditional scholarly venues, through the web and to the local community at each partner institution.","title":"NeTS: Medium: Collaborative Research: Secure Networking Using Network Coding","awardID":"0905370","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[402458,"539208"],"PO":["557315"]},"161501":{"abstract":"This exploratory research addresses the increasingly more critical performance, power, and functional requirements of search operations in key inter-networking devices like routers and firewalls. This project will investigate a specialized yet flexible search substrate called CA-RAM (Content Addressable Random Access Memory) that possesses great promise for high search performance at low power consumption. CA-RAM is based on the hashing theory and techniques. By decoupling dense memory array from compute components, CA-RAM achieves high storage density and configurability. This project will focus on how CA-RAM can effectively tackle all major packet processing applications, including packet forwarding, packet filtering, and deep packet inspection, in a scalable and complexity-effective manner. The project will also look at how new emerging memory and chip integration technologies can be used in CA-RAM to further demonstrate the effectiveness of the proposed approach. <br\/><br\/>Intellectual Merit: This research has the potential for breakthroughs in the design of future inter-networking devices. The expected contributions include a directed exploration of the CA-RAM designs. Additionally, the researchers will gain an understanding of how the emerging 3-D chip integration and Phase-Change Memory technologies will further enhance the capabilities of CA-RAM and the packet processing devices built with CA-RAM.<br\/><br\/>Broader Impact: This research will impact the design practices of inter-networking devices, a critical and essential infrastructure for our society. This project will help sustain the historical scaling rate of the network and Internet performance. The enhanced Internet will foster new exciting applications and services in global communications, commerce and entertainment, as well as cultural and technical advances. The researchers will document the approaches and findings in detail, and publish them in a timely manner.","title":"EAGER: CA-RAM: Enabling Fast and Versatile Packet Processing for Future Large-Scale Networks","awardID":"0952273","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["475186"],"PO":["564924"]},"150864":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Traffic measurement is central to network operation, management, and security. Yet, support for measurement was not an integral part of the original Internet architecture. This project aims to develop a programmable measurement architecture that is versatile enough to support current and future measurement needs, adaptable to dynamic network conditions, modular\/lightweight, and scalable to high link speeds. <br\/><br\/>This project proposes a new flow abstraction module and query language that can specify arbitrary traffic sub-populations for statistics collection. Efficient data structures to encode these queries will be developed. The team also strives to identify a core set of data streaming and sampling primitives that can be composed together to satisfy most of the queries. Efficient hardware implementation for these core set of primitives will constitute the basic measurement modules that can be easily reconfigured to measure traffic at different desired granularity. Measurement application case studies will be carried out to evaluate and showcase the capabilities of the proposed approach. <br\/><br\/>This project has great potential in guiding the design of a clean-slate measurement instrumentation for future Internet. It will provide both graduate and undergraduate students with training that span multiple disciplines, from fundamental statistical theory, algorithm design, to hardware implementation. The results (including the query language and underlying data structures, sampling\/streaming algorithms, and hardware building blocks) will be broadly disseminated through publications, invited talks\/tutorials, and open-sourcing software distribution.","title":"NeTS: Medium: Collaborative Research: Towards Versatile and Programmable Measurement Architecture for Future Networks","awardID":"0905037","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543509"],"PO":["565303"]},"153922":{"abstract":"Although persistent and long-duration tracking of general targets is a basic function in the human vision system, this task is quite challenging for computer vision algorithms, because the visual appearances of real world targets vary greatly and the environments are heavily cluttered and distractive. This large gap has been a bottleneck in many video analysis applications. This project aims to bridge this gap and to overcome the challenges that confront the design of long-duration tracking systems, by developing new computational models to integrate and represent some important aspects in the human visual perception of dynamics, including selective attention and context-awareness that have been largely ignored in existing computer vision algorithms. <br\/><br\/>This project performs in-depth investigations of a new computational paradigm, called the synergetic selective attention model that integrates four processes: the early selection process that extracts informative attentional regions (ARs), the synergetic tracking process that estimates the target motion based on these ARs, the robust integration process that resolves the inconsistency among the motion estimates of these ARs for robust information fusion, and the context-aware learning process that performs late selection and learning on-the-fly to discover contextual associations and to learn discriminative-ARs for adaptation. <br\/><br\/>This research enriches the study of visual motion analysis by accommodating aspects from the human visual perception and leads to significant improvements for video analysis. It benefits many important areas including intelligent video surveillance, human-computer interaction and video information management. The project is linked to educational activities to promote learning and innovation through curriculum development, research opportunities, knowledge dissemination through conferences and the internet as well as other outreach activities, and the involvements of underrepresented groups.","title":"RI: Small: Computational Models of Context-awareness and Selective Attention for Persistent Visual Target Tracking","awardID":"0916607","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["182691"],"PO":["564316"]},"150897":{"abstract":"TC: MEDIUM: COLLABORATIVE RESEARCH: TOWARDS SELF-PROTECTING DATA CENTERS: A SYSTEMATIC APPROACH<br\/><br\/>TC-0905189 Sushil Jajodia, George Mason University<br\/>TC-0905131 Peng Liu, Pennsylvania State University<br\/>TC-0905153 Meng Yu, Western Illinois University<br\/><br\/><br\/>Abstract<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). Data centers using virtual machine (VM) consolidation are taking over old computer rooms run by individual companies. However, consolidating services and resources does not consolidate security automatically. To meet the top two requirements for modern data centers, namely business continuity and information security, this research will take a systematic approach that leverages the emerging VM technologies to consolidate four areas of systems security research: redundancy, microscopic intrusion analysis and detection, automatic response, and diversity-driven protection. We will make innovative contributions on various aspects of security consolidation, including (1) An architecture and underlying techniques based on diversified replication towards defensive protection against unknown attacks; (2) Novel cross-layer and cross-VM methods for causal relation logging, event correlation, damage assessment, and forensics; (3) New intrusion detection techniques based on unique cross-VM-replica inconsistency checking techniques, and new cross-layer inconsistency checking methods; (4) A novel pipelining approach towards automated intrusion response; and (5) New techniques for on-the-fly data center intrusion confinement and recovery.<br\/><br\/>Our research will result in significant advances in helping mission\/life\/business critical applications and information systems reduce risk, increase business continuity, and deliver data assurance in the presence of severe cyber attacks. Broader impact will also result from the education, outreach, and dissemination initiatives. Educational resources from this project, including course modules and teaching laboratory designs, will be disseminated through a dedicated Website.<br\/><br\/>Key Words: self-protection; recovery; virtual machine monitor; causal relations; availability","title":"TC: Medium: Collaborative Research: Towards Self-Protecting Data Centers: A Systematic Approach","awardID":"0905153","effectiveDate":"2009-09-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["559867"],"PO":["564223"]},"153933":{"abstract":"Resource allocation in wireless networks concerns the decisions of what rate each node injects data into the network, where and when it sends out data packets with potentially different destinations, and what level of transmit power it uses at every point in time, based on the information available at the node on the system state. It is well-known that feedback of relevant ``network state information'' is of paramount importance to the efficient utilization of the scarce network resources. Therefore, in a realistic system, the cost and value of obtaining the necessary network state information is of crucial importance and demands a comprehensive study, which constitutes the broad objective of this research. The inclusion of these factors causes drastic changes to the widely-used design paradigms.<br\/>To that end, the main objectives of this project are: to develop a well-founded theoretical framework for (1) establishing the value and cost of information obtained by distributed network state estimators; (2) building a joint estimation and resource allocation component for new generation wireless networks; and (3) designing distributed network controllers with asymmetric partial information. This study requires fundamental developments in wireless communications, estimation theory, information theory and optimization theory.","title":"CIF: Small: Cost and Value of Information for Resource Allocation in Wireless Networks","awardID":"0916664","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["506208","432497"],"PO":["564924"]},"150435":{"abstract":"The objective of this research is to create a reliable hybrid photonic-electronic network-on-chip for high performance multicore chips. This is achieved through backend integration of a silicon-compatible nanophotonic optical network configured and monitored using an electronic packet-switched network.<br\/><br\/>Intellectual Merit: Metal interconnects have emerged as the critical bottleneck in meeting reliability, performance and energy constraints in chip multiprocessors. Silicon nanophotonics offers a compelling alternative, because of its inherently large bandwidth, low loss, low energy consumption and CMOS compatibility. This research addresses barriers challenging the efficient and cost-effective integration of on-chip photonic networks by (1) investigating CMOS compatible fabrication of amorphous silicon nanophotonic components for maximum backend flexibility; (2) examining scalable architectures, topologies and routing mechanisms for these photonic-electronic on-chip networks; (3) exploring error control methods for reliable energy-efficient multicore communication; (4) developing robust low-jitter mode-locked quantum-dot lasers that supply light to the photonic network.<br\/><br\/>Broader Impact: Successful demonstration of the hybrid photonic-electronic network-on-chip will accelerate realization of reliable energy efficient data-centers and high performance computational systems for a multitude of societal applications. Integration of research and education builds on the PIs' own community involvement and excellent campus-wide resources offered by the participating universities to (1) train the next generation of scholars through a joint course to be developed by the PIs and planned workshops that enable student participants to interact with experts; (2) actively recruit and mentor qualified underrepresented students; (3) inspire participation of K-12 groups through hands-on laboratory activities; (4) extend outreach through international collaborations.","title":"Reliable Backend Integrated Hybrid Photonic-Electronic Network-on-Chip","awardID":"0903448","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["463752","556991","433004"],"PO":["565185"]},"161204":{"abstract":"To develop computer security as a science and engineering discipline, metrics need to be defined to evaluate the safety and security of alternative system designs. Security policies are often specified by large organizations but there are no direct means to evaluate how well these policies are followed by human users. The proposed project explores fundamental means of measuring the security posture of large enterprises. Risk management and risk mitigation requires measurement to assess alternative outcomes in any decision process. The project is intended to devise metrics and measurement methods, and test and evaluate these in a real institution, to evaluate how human users behave in a security context. Financial institutions in particular require significant controls over the handling of confidential financial information and employees must adhere to these policies to protect assets, which are subject to continual adversarial attack by thieves and fraudsters. Hence, financial institutions are the primary focus of the measurement work. The technical means of measuring user actions that may violate security policy is performed in a non-intrusive manner. The measurement system uses specially crafted decoy documents and email messages that signal when they have been opened or copied by a user in violation of policy. The project will develop collaborations with financial experts to devise risk models associated with users of information technology within large enterprises. This line of work extends traditional research in computer security by opening up a new area focused on the human aspect of security.","title":"Measuring the Security Posture of Large Financial Enterprises: An EAGER Proposal to NSF CCF","awardID":"0950373","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[431190],"PO":["565264"]},"153955":{"abstract":"TC: Small: Taint-Based Information Tracking in Networked Systems<br\/>PI: Nick Feamster (Georgia Tech)<br\/><br\/>Network operators must control and monitor the flow of information within and across their networks. Existing mechanisms for controlling information flow are primarily host-based: operating systems can \"taint\" portions of memory or applications based on the inputs to a particular process or resource. Unfortunately, if a host is compromised or otherwise breached, that information may propagate in unintended ways. Once information has leaked, tracking the provenance of the leaked data is challenging. This project is developing a mechanism for tracking and controlling information flow across the network to cope with these problems. This mechanism would allow operators to control how information propagates within and between networks and to devise more complex policies; for example, it might be used to control which application traffic was allowed on which part of the network. The information carried in the network traffic might ultimately be attributed to a specific user or process, thus allowing operators to express policies according to the process and user that generated the traffic.<br\/><br\/>We are addressing several research challenges. First, we are exploring the appropriate granularity for tainting that preserves semantics without imposing unacceptable memory and performance overhead. Second, we are designing the system to minimize performance overhead on applications. Third, we are exploring translation mechanisms between host-based taints and network-based taints, so that taints carried in network traffic convey meaningful semantics without imposing prohibitive network overhead. The research will result in an information tracking and control system that is deployed<br\/>in experimental settings (e.g., the Georgia Tech campus network) using the existing and forthcoming programmable switch implementations, and integrated into undergraduate and graduate networking and security courses.","title":"TC: Small: Taint-Based Information Tracking in Networked Systems","awardID":"0916732","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["561756"],"PO":["565327"]},"155902":{"abstract":"Proposal #: CNS 09-23511 <br\/>PI(s): Janin, Adam <br\/>Institution: International Computer Science Institute<br\/>Title: MRI\/Acq.: Acquisition of Tesla Hardware for Speech Recognition <br\/>Project Proposed:<br\/>This project, acquiring an nVidia Tesla architecture system, facilitates development parallel code algorithms for automatic speech recognition (ASR). The Tesla Hardware for Speech Recognition consists of a cluster of 10 nVidia Tesla rack-mounted units with associated infrastructure. New parallel codes must be developed to improve the accuracy of speech recognition, since computer systems now obey ?Core?s Law? (where the number of cores on a chip doubles once every two years). The system provides a large-scale multi-core general purpose computing environment that enables the development of scalable parallel code algorithms. The instrument provides a testbed in which to investigate future scalable algorithms that are expected to facilitate continued leadership in the commercial and industrial markets in terms of advanced and novel algorithms. Thus, envisioning the state of computing in 5 to 10 years when multi-core architectures prevail, the project aims to first<br\/>- Secure appropriate computing resources for research in speech recognition and then<br\/>- Eclipse the current 2- and 4-core basic desktop systems.<br\/>The institute performs extensive training for machine learning and speech recognition in realistic settings with challenging acoustic properties and natural, human to human communication. Applications run from hands-free access to disabled users and natural speech-driven interfaces for the non-computer literate to automatic meeting assistants and browsers, in which meetings are recorded in real-time and tools are provided that allow access to content both during and after the meeting. The following two relevant methods improve accuracy:<br\/>- Multi-stream methods that involve combinations at many levels within the system, including multiple features, multiple machine learning estimators, and multiple word-streams combinations and<br\/>- Increasing the size of the training set.<br\/>Careful integration of data can improve the accuracy even when the training data does not exactly match the conditions of actual application. Both methods require increasing computational power hard to fulfill with current conventional hardware.<br\/><br\/>Broader Impacts: The acquisition contributes to continue attracting young researchers and aiding in their training. The improved computational capability facilitates the demonstration of speech research to local high school students. The BFOIT Foundation for Opportunities in Information Technology aims to attract more women and underrepresented minorities in computer science and engineering.","title":"MRI: Acquisition of Tesla Hardware for Speech Recognition","awardID":"0923511","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["434804"],"PO":["557609"]},"153724":{"abstract":"With the advances of modern computer architectures, interconnects are playing an ever increasingly important role for providing an effective communication medium. Advanced optical switching technologies, such as optical packet switching and wavelength-division-multiplexing, provide a platform to exploit the huge capacity of optical fiber to meet the increasing needs. This research proposes a new switching paradigm - optical cut-through with electronic packet buffering, and systematically investigates the fundamental and challenging issues in the optical interconnect under this switching scheme, with the objective of designing cost-effective, ultra-low latency and pragmatic interconnects for future high-performance computing and communications systems.<br\/><br\/>A unique feature of the proposed interconnect is that those packets that do not cause contention can pass the interconnect directly in optical form and experience minimum delay, while only those that cause contention are buffered. This research proposes to combine optical packet switching with electronic buffering, such that the interconnect will enjoy both fast switching and large buffering capacity. This research will (1) design the switching fabric and packet scheduling algorithms, (2) design practical Forward Error Control (FEC) for the interconnect, and (3) conduct extensive performance evaluations by means of simulation and emulation tools and analytical models. The outcome of this project will have a significant impact on fundamental design principles and infrastructures for the development of future high-performance computing and communications systems. The PIs will integrate graduate and undergraduate students into the project and promote the participation of female and minority students. The findings will be disseminated to the research community by way of conferences, journals, and web site access.","title":"SHF: Small: Collaborative Research: Ultra-Low Latency Optical Packet Switched Interconnects with Novel Switching Paradigm","awardID":"0915823","effectiveDate":"2009-09-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["550688"],"PO":["366560"]},"153845":{"abstract":"This proposal will be awarded using funds made available by the American Recovery and Reinvestment Act of 2009 (Public Law 111-5), and meets the requirements established in Section 2 of the White House Memorandum entitled, Ensuring Responsible Spending of Recovery Act Funds, dated March 20, 2009. I also affirm, as the cognizant Program Officer, that the proposal does not support projects described in Section 1604 of Division A of the Recovery Act.<br\/><br\/>This collaborative research will create techniques that improve the reliability of software product lines. A software product line is a family of software systems that share certain common features and differ according to a set of specified variations. Use of software product lines has grown rapidly in industry because such reuse reduces the cost of building new systems. <br\/>Reliability is important to product-line developers since many product lines, such as mobile phones, industrial robots, and surgical imaging systems, require reliable operation. This project focuses on development of a rigorous framework for incremental assessment and prediction of software product line reliability (SPL-iRAP). The research has three major thrusts: (1) developing reliability modeling techniques for software product lines to handle the effects of variations and ongoing changes, (2) investigating the use of reliability models for prediction across the product line based on empirical data, and (3) quantifying the benefit of the reuse on software quality. The researchers will train students, particularly women and underrepresented groups, in software reliability techniques, create new curriculum units for teaching, and partner with industrial developers of product lines to demonstrate the new techniques.","title":"SHF: Small: Collaborative Research: Evidence-based Reliability Assessment of Software Product Lines","awardID":"0916284","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[409382],"PO":["564388"]},"153614":{"abstract":"Ensuring reliable computation at the nanoscale requires mechanisms to detect errors. The PIs propose fundamental research for developing efficient hardware techniques to support online error detection and manufacturing test by monitoring invariant relationships. These invariant relationships naturally occur across multiple levels of digital logic and across multiple time cycles. Violations of these relationships indicate that errors have occurred, either because of transient faults or manufacturing defects; thus monitoring them in hardware can significantly improve circuit reliability. While other techniques exist for error detection, this approach has several advantages, including significantly lower power dissipation, no high-level information requirements, fine-grained optimization capabilities, and providing a potentially powerful source of diagnostic information. A key challenge in this project is the efficient selection of an optimal set of implications to include in the hardware, such that desired reliability is obtained with low overhead.<br\/><br\/>Reliable operation of logic devices is key for the continued push for smaller and faster electronic circuits. Any benefit in performance and power brought forth by rapid scaling of transistors cannot be fully realized if high reliability cannot be guaranteed for systems composed of these devices. The proposed research is a collaborative effort between Brown and Bucknell Universities. The project involves undergraduate students, many of whom are women and under-represented minorities. The PIs will use this project to create new opportunities to expose undergraduates to research, and to develop outreach workshops to encourage women and under-represented minorities to pursue degrees in computing.","title":"SHF: Small: Collaborative Research: Using Identified Circuit Invariance for Online error Detection","awardID":"0915302","effectiveDate":"2009-09-01","expirationDate":"2011-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["550256","482799"],"PO":["562984"]},"153856":{"abstract":"This project investigates how a new processor paradigm (multi-core architectures) changes the way Parallel Discrete Event Simulation (PDES) is done. This topic is important given the wide use of simulation and the emergence of multi-core architectures. PDES is likely to play an increasingly important role in discrete event simulation as Moore?s Law is sharply curtailed and explicit parallelism becomes the major avenue for improving performance of sequential applications. Improving PDES performance translates to improved.<br\/><br\/>Discrete Event Simulation (DES) is widely used for performance evaluation in many application domains. The fine grained nature of PDES causes its performance and scalability to be limited by communication latency. The emergence of multi-core architectures and their expected evolution into manycore systems offers potential relief to PDES and other fine grained parallel applications because the cost of communication within a chip is dramatically lower than conventional networked communication. Absent this dominant effect, PDES performance will be determined by issues such as load balancing, synchronization and optimism control, and the choice and configuration of various other algorithms and data structures of the simulator. Operation in a manycore environment introduces new system tradeoffs that must be effectively balanced by the system software. Primarily, the pressure on the memory system and resilience to load fluctuations will emerge as critical issues that we address in the proposed research. Finally, the more predictable nature of communication cost in this environment (due in part to the more frequent synchronization possible between nearby cores) can be exploited, especially by static analysis, for effective simulation. <br\/><br\/>As multi-cores become the default microprocessor architecture, applications that are performance constrained must evolve to use parallelism to take advantage of the resources available on the cores. This project?s new PDES can have a significant impact on a number of applications that rely on discrete event simulations. The PIs plan to incorporate the research results into a graduate level course on parallel simulation techniques and to involve undergraduate students in the project.","title":"CSR: Small: Collaborative Research: Combining Static Analysis and Dynamic Run-time Optimization for Parallel Discrete Event Simulation in Many-Core Environments","awardID":"0916323","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["451773","451774"],"PO":["565255"]},"153977":{"abstract":"Modern software is increasingly developed using managed programming languages, such as Java and C#, because they eliminate a large class of low-level memory-related errors that have plagued languages such as C and C++ and caused countless failures and security vulnerabilities. Unfortunately, software still suffers from a troubling array of higher-level semantic errors, which can cause programs to misbehave without necessarily triggering an overt failure. Prior techniques for detecting these errors suffer from some combination of imprecision (false positives), poor scalability on large programs, or extremely high run-time overheads.<br\/><br\/>This project will explore a new approach for detecting programming errors that is precise, informative, scalable, and efficient enough to use in deployed software. The approach leverages techniques from static analysis that allow programmers to express expected program properties, but overcomes prior limitations by checking the properties at run-time. The key idea is to piggyback error checking on the garbage collector, which can check and elucidate complex program properties with very low overhead because it periodically visits all objects in the heap. The result of this research will be a much-needed technique for detecting and diagnosing bugs in deployed software -- especially large, complex, and highly dynamic programs, such as server applications.","title":"Efficient Dynamic Checking of Heap Invariants using the Garbage Collector","awardID":"0916810","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["553399"],"PO":["564388"]},"152646":{"abstract":"Wireless sensor networks (WSNs) composed of smart sensors interconnected over wireless links are quickly becoming the technology of choice for monitoring and measuring geographically distributed physical, chemical, or biological phenomena in real time. Dynamic WSN environments encountered in environmental monitoring, surveillance, pollution control, and reconnaissance applications, require responsive management of WSN resources and their adaptive allocation to sensing, networking support, localization, and planning tasks, based on user requests and changes in the environment. A specified quality of service should however be ensured for criteria such as resolution of the raw-data, latency, network reconfiguration delay, and resource utilization in the steady-state. This project develops an integrated cross-layered approach to networking, databases, control, mobility management, and information processing in WSNs. In particular, context-aware and energy-efficient solutions are pursued that are based on opportunistic sensing and processing techniques, dynamic indexing structures, novel query language constructs, reactive mobility control algorithms, and distributed compression based routing algorithms.<br\/><br\/>The technological advances from this research will significantly simplify the deployment of WSNs and lead to novel context-aware applications. The advances will directly benefit domains such as emergency-response management, environmental threat remediation, and biological habitat monitoring. Apart from developing the required algorithms, the project will implement simulation platforms and a monitoring environment using physical devices. The platforms will provide students with new educational opportunities to actively explore information acquisition and resource management in resource-constrained environments. All project resources will be shared with the public through a project webpage.","title":"NeTS: Large:Collaborative Research: Context-Driven Management of Heterogeneous Sensor Networks","awardID":"0910952","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[406694,"560392","515786"],"PO":["565303"]},"161116":{"abstract":"This EAGER project is focused on:<br\/><br\/>- Multi-level simulation tools for circuits consisting of quantum tunneling devices such as resonant tunneling diode (RTDs) and quantum dots. <br\/>- The design of new integrated circuits using these tools both at mesoscale (RTD-based design) and at nanoscale (0-dimensional RTD- or quantum dot, QD-based design).<br\/><br\/>The overall research project will be divided into two different tasks: task-1: Reverse Synthesis of RTD structures in order to optimize the overall circuit performance; and, task-2: Design, Fabrication and Simulation of RTD and Quantum Dot based integrated circuits.<br\/><br\/>The US National Nanotechnology Initiative has projected the nanotech market to grow to $1 Trillion by year 2015, and integrated nanoelectronics and nanosystems are expected to make heavy commercial inroad within a decade. However, one of the chief obstacles to their adoption at present is the lack of integrated, multi-level software for studying their properties, and aiding their design, simulation, optimization and interaction with peripheral systems. Many of the desirable features and characteristics of such software, identified by the International Technology Roadmap for Semiconductors (ITRS) in 2005, are integral to this project?s research work.<br\/><br\/>This project develops the theory and prototype software that will aid in the multilevel design, simulation and optimization of circuits consisting of quantum tunneling devices as well as conventional devices. To insulate circuit designers from the quantum-physical transport details in device operation, this project develops a Q-Device Model module that operates in conjunction with QSPICE so that system-level optimization is possible in a reverse-synthesis approach. <br\/><br\/>This project's research may have the following broader impacts: <br\/>- new and efficient nanocircuits and nanoarchitectures to supplement and complement existing applications and products, <br\/>- a new tool for design of such integrated nanoelectronics, <br\/>- pedagogical methodology in inter-disciplinary training to the next generation of circuit engineers who will then be equipped to transfer principles and skills gained in this new paradigm to still further technologies like molecular electronics, <br\/>- audio\/visual material clips showing the growth of self-assembled nanowires and colorful images of strings of atoms viewed through Scanning Electron Microscopes to stimulate excitement in high-school and community-college students and in the community at large, <br\/>- promotion of female and minority students in doctoral degree program in electrical and computer engineering, and <br\/>- collaboration between theory, simulation and experiment, and between academia and US industry, and international institutes.","title":"EAGER: Software Development for Simulation and Optimization of Nanoscale Integrated Circuits","awardID":"0949667","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["521045","434309"],"PO":["535244"]},"153626":{"abstract":"A central goal in foundational cryptography is to find a primitive that realizes all interesting cryptographic applications, and yet has its security based on a simple assumption --- ideally a weak general assumption. Recently, a significant step in this direction was made with the introduction of Lossy Trapdoor Functions. A family of Lossy Trapdoor Functions (TDF) lets a user generate a publicly computable function, f, and corresponding trapdoor, t, such the user can recover x given f(x). Alternatively, the user can generate a function g such that g looses information about the input x; moreover, no computationally bounded adversary can distinguish whether it is given the description of an injective or lossy function.<br\/><br\/>Lossy Trapdoor Functions give rise to a host of cryptographic applications including: injective trapdoor functions, chosen-ciphertext secure encryption, collision-resistant hash functions, and oblivious transfer (OT). Furthermore, one can realize Lossy TDFs from several standard number theoretic assumptions: Decisional Diffie-Hellman, the Shortest Vector (SVP) problem in lattices, and the Composite Residuosity problem. Taken all together this solved two longstanding open problems: realizing non-factoring based trapdoor functions; and building chosen ciphertext secure encryption systems from lattice-based assumptions.<br\/><br\/>This work will endeavor to make significant progress towards realizing the ultimate goal of building all of cryptography from simple general assumptions. The following directions will be pursued. First, the work will aim to create new constructions from both weaker number theoretic assumptions and from general assumptions. Second, the project will build trapdoors into Identity-Based Cryptosystems. Constructing identity-based trapdoors will enable applications such as ``deterministic encryption'' in the Identity-Based context. Third, it will build new Non-Interactive Proof Systems. The project will study the relationship to Universal Hash Proof Systems and create new Non-Interactive Zero Knowledge Proof Systems.<br\/><br\/>This project will contribute to our foundational understanding of cryptography. Results will be disseminated through conferences, journals, and invited talks. In addition, funding will be used to support graduate students and build a cryptography program at UT Austin.","title":"TC: Small: Lossy Trapdoor Functions - Applications, Realizations and Beyond","awardID":"0915361","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521455"],"PO":["565264"]},"153747":{"abstract":"Images and video are analyzed in terms of parts. Qualitatively,<br\/>a part of an image is a region that can be extracted consistently, even if the image changes somewhat because of differences in quality, resolution, lighting, viewpoint, or small variations in the shape of the objects being depicted. In video, these regions are extruded into time, forming tubes of sorts that persist over relatively long time intervals.<br\/><br\/>Technically, parts are regions with high saliency and stability, two notions that are defined anew in this research based on mathematical tools that span from harmonic functions to new developments in computational topology and spectral graph theory.<br\/><br\/>Parts are a key handle into image and video structure, as they allow describing the visual information succinctly and in a stable manner. They lead to indices for retrieval, and provide primitives that make it possible for computer software to recognize objects and activities. The main result from this effort is a systematic comparison of advantages and limitations of the new definition with descriptors from the literature.<br\/><br\/>Applications of part-based visual analysis range from image retrieval, medical and biological imaging, and video interpretation for military and intelligence scenarios, to surveillance, the annotation and editing of images and video clips, and more. Work involves graduate students and undergraduates funded through the NSF REU program. Results of this research are disseminated through scholarly publications and classes at Duke University. A benchmark of evaluation images and video is developed for open use by the research community.","title":"RI: Small: Visual Parts for Image and Video Analysis","awardID":"0915924","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["513187"],"PO":["564316"]},"153868":{"abstract":"Recent advances in high-throughput sequencing (HTS) technologies provide opportunities to study genome structure, function, and evolution at an unprecedented scale, and are profoundly transforming genomic research. <br\/>However, fully realizing the potential of HTS technologies requires sophisticated data analysis methods. This research project is aimed at developing efficient computational methods for reconstructing the full spectrum of haplotype sequences from HTS data. Working in collaboration with molecular biologists from the University of Connecticut Health Center and the Centers for Disease Control, the investigators will develop methods enabling three novel applications of HTS, namely (a) reconstruction of diploid genome sequences, including complete haplotype sequences of each CNV copy, (b) reconstruction of alternative splicing isoform sequences and their frequencies, and (c) reconstruction of viral quasispecies sequences and their frequencies. Major outcomes of the project will include the development of a comprehensive analytical toolkit for these problems, and high-quality open source software implementations that will be made available free of charge to the research community. The project will provide opportunities for participation of undergraduate and graduate students in bioinformatics research at UCONN and Georgia State University, and will especially encourage participation of women and underrepresented groups.","title":"III: Small: Collaborative Research: Reconstruction of Haplotype Spectra from High-Throughput Sequencing Data","awardID":"0916401","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["525687"],"PO":["565136"]},"152537":{"abstract":"Information and communication technology (ICT) promises to help reduce impacts of large-scale disruptions from natural hazards, pandemics, and terrorist threat. This research focuses on a critical aspect of large-scale emergency response -- the needs and roles of members of the public. By viewing the citizenry as a powerful, self-organizing, and collectively intelligent force, ICT can play a transformational role in crisis situations. This view of a civil society augmented by ICT is based on socio-behavioral knowledge about how people behave in crisis, rather than on simplified and mythical portrayals. With a critical reframing of emergency response as a socially-distributed information system, the project aims to leverage the knowledge of members of the public through reuse of publicly available computer mediated communications (CMCs) (e.g., community, mapping, and social networking sites; blogs; Twitter). The project will study and integrate that heterogeneous information and -- with techniques of information extraction through natural language processing as well as trust and reputation modeling -- add meta-information to help users assess context, validity, source, credibility, and timeliness to make the best decisions for their highly localized, changing conditions. <br\/><br\/><br\/>The results of this research addresses matters of policy, practice and technological innovation, responding directly to needs identified in national policy statements, including Grand Challenge #1 of the National Science and Technology Council's Subcommittee on Disaster Reduction, which calls for the provision of \"hazard and disaster information where and when it is needed\" (SDR, 2005). At-risk populations are disproportionately affected by crises; the results of this research could mitigate the impacts on these communities. The research is also inclusive of people across different cultures\/ethnic groups within the U.S. and from different countries. The project broadens the future STEM workforce, since socio-technical and practical orientations to computational research attract women to study STEM disciplines. The research contributions include cyberinfrastructure-aware applications, techniques, and services built from empirical knowledge of the social structures that produce crisis data.","title":"HCC: Large: Collaborative Research: Widescale Computer-Mediated Communication in Crisis Response: Roles, Trust & Accuracy in the Social Distribution of Information","awardID":"0910640","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["518420"],"PO":["565227"]},"152658":{"abstract":"Pollution sensing and diagnosis have long been separated from the people most impacted by them. It was conducted by specialists with expensive and scarce equipment. As a result, testing was infrequent and decisions on mitigation were made by central planners with limited access to data. Worse yet, individuals with the ability to dramatically limit dangerous exposure via minor changes in behavior have been left blind to the relationship between their daily actions and exposure to pollution. Advances in computing, sensing, and wireless communication technologies have the potential to allow those most affected by pollution to participate in pollution sensing, rational cost assessment, and mitigation.<br\/><br\/>This project focuses on developing a distributed mobile system for socially-collaborative environmental monitoring, which greatly reduces the problem of environmental sensing data scarcity, supports richer environmental sensing data analysis, and enables better environment awareness and protection via social collaboration. This project will develop a system composed of inexpensive sensing and computation devices purchased by individuals for their own edification and protection. These embedded systems will communicate with each other and aggregate data, enabling multi-sensor localization of pollution<br\/>sources and quantification of the potential damage by each polluter. By measuring pollution and modeling its impact, it will be possible to associate pollution sources with the costs they impose. Furthermore distributed networking will allow individuals to actively participate in and socially collaborate on environmental monitoring and protection.","title":"CSR: Large: Collaborative Research: CommonSense--A Distributed Mobile System for Socially-Collaborative Environmental Monitoring","awardID":"0910995","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["527837","485555","555576"],"PO":["565274"]},"162217":{"abstract":"Objective<br\/><br\/>The science of information and decision systems encompasses a substantial and exceptionally pervasive set of interrelated disciplines, ranging from signal and image processing; to embedded control systems; to the analysis, design, and optimization of complex distributed systems and networks. Thanks both to the richness of the challenges throughout engineering and the physical, biological and social sciences and the continuing developments of the foundations of our disciplines, the information and decision sciences stand today as an exciting, continually evolving, and critical domain of intellectual inquiry. We are excited to propose a major event, a workshop aimed at articulating a picture of the challenges and ideas that will shape the future directions and potential areas of impact of research in the science of information and decision systems.<br\/><br\/>Intellectual Merit<br\/><br\/>This meeting will bring together leading researchers from all around the world who have been influential in shaping the vision of and leading this field. The community of leaders whom we intend to invite will include many of the most recognized names in the field, as well as some of the rising stars in our field. This event will be open to the broad national and international community. The meeting will consist of several keynote addresses, providing context and a sense of history as well as some views toward the challenges of the future. Sessions to be held will focus on core disciplines, including Systems and Control; Networks and Networked Systems; Estimation, Inference and Learning; and Optimization and Decision Sciences. The workshop will include several panel discussions aimed at articulating paths ahead and major practical and societal challenges that are driving and will drive our field in the future.<br\/><br\/>Broader Impact<br\/><br\/>This meeting will be a first of its kind bringing together researchers from many disciplines in order to articulate the challenges emerging in information systems. As a particular outcome of the workshop, we will invite some of the participants to produce a handful of position papers. These papers will address new and exciting formulations and highlight the practical relevance of information systems in engineering, biology, social science, and other related disciplines. We intend to make these papers, together with all the presentations, publicly available to our community. More so, we will encourage and partially support the participation of students from all institutions. In addition, Industrial partners and government agencies will be asked to provide their inputs and perspectives to guide the panel discussions and to influence the position papers. These position papers will have a far reaching effect to researchers beyond the attendees of the workshop.","title":"Worshop on LIDS 2010: Paths Ahead in the Science of Information and Decision Systems To be Held at MIT Stata Center on November 11-13, 2009","awardID":"0956244","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7607","name":"ENERGY,POWER,ADAPTIVE SYS"}}],"PIcoPI":["496085"],"PO":["564728"]},"153637":{"abstract":"Testing is essential for database applications to function correctly and with acceptable performance when deployed. In practice, it is often necessary for vendors of database application software to test their software adequately before selling or integrating their software to the database owner. However, testing database applications is very costly. In particular, it is time-consuming and challenging to generate desirable database states, an important portion of test inputs for testing database applications. However, little research has been conducted to provide scalable, effective tool support for generating database states to achieve various testing objectives.<br\/><br\/>This research aims to adequately generate database states for database applications by developing novel techniques for (1) generating desirable database states to satisfy the given constraints on result sets from the given query, (2) applying this preceding technique on a variety of testing tasks, and (3) exploring more complicated situations such as constraints in multiple interacting queries. The research advances understanding of fundamental issues related to testing database applications and the design and implementation of practical techniques to carry out such testing. Among the broader impacts of the project includes integration of the research into education programs and enhancement of teaching and research infrastructure.","title":"SHF: Small: Collaborative Research: Constraint-Based Generation of Database States for Testing Database Applications","awardID":"0915400","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["562727"],"PO":["564388"]},"153879":{"abstract":"The objective of this project is to advance the state-of-the-art in acquiring and modeling dynamic non-rigid objects. The specific examples of non-rigid objects that the project is to focus on include: human faces, hands, soft tissues, cloths, and animals. The PI seeks to address the following two fundamental questions: (1) How can non-contact optical methods be used to measure dense 3D surface motion without physically modifying the appearance of the surface? (2) What physical and\/or biological properties can be inferred from the acquired dense 3D motion data?<br\/><br\/>The research team addresses these two questions by two simple but general ideas, namely the space-time approach and data-driven models. The space-time approach builds upon space-time stereo, and enables accurate optical measurements of 3D surface motion, as well as automatic registration of shape sequences among different dynamic objects. The data-driven models are used for both material recognition and deformation-EMG correlation. The project has a wide range of scientific impacts, including generating data for 2D face alignment and 3D face recognition in biometrics, generating data for 3D face emotion recognition in human computer interaction, measuring human body deformation in biomechanics, modeling soft tissues for orthopedics and computer-aided surgery, and building virtual human models for entertainment and education. These scientific impacts translate into benefits to society, for example, by building more accurate biometric systems to secure our country, innovating surgery procedure to reduce health insurance cost, and creating 3D digital replicas of great teachers to make our education available anywhere, anytime, at a lower cost.","title":"RI: Small: Acquisition and Modeling of Dense Nonrigid Shape and Motion","awardID":"0916441","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["490501"],"PO":["564316"]},"152669":{"abstract":"The commercial success of data mining, and the great research interest<br\/>that this area attracts, prove that there is a need for analyzing and<br\/>understanding data that goes well beyond classical database queries.<br\/>Users are often particularly interested in understanding the causal<br\/>relationship between data items and the reasons for observations.<br\/><br\/>Current database systems cannot explicitly model the causal structure<br\/>within data (although it is often implicit in the data), and thus offer<br\/>no specific support for causal queries. In the absence of information<br\/>about causal relationships, users have to rely on techniques for mining<br\/>for statistically significant patterns in data. Causal relationships<br\/>are often simply concluded from statistical dependencies. This can lead<br\/>to inaccurate conclusions; correlation does not necessarily imply<br\/>causation.<br\/><br\/>This project creates the foundations for a new breed of databases<br\/>called causal databases. Causal databases can model causal information,<br\/>and allow for queries regarding causality and explanations, which are<br\/>beyond the scope of current databases. They can also take advantage of<br\/>causal information that is implicit, but unexploited, in some current<br\/>databases, such as those for large engineering projects. In the<br\/>project, new database models and query languages for representing and<br\/>transforming causal information are developed, with particular focus on<br\/>large engineering databases and scientific databases. In addition,<br\/>efficient and scalable techniques for processing causality and<br\/>computing explanations in large causal databases are developed. This<br\/>involves both work on integrating causality processing into traditional<br\/>database query processing architectures and the development of special<br\/>datastream techniques for scaling up to the most data-intensive<br\/>applications.<br\/><br\/>Further information on the project can be found at the project web<br\/>page: http:\/\/www.cs.cornell.edu\/databases\/causality\/","title":"III: Large: Causal Databases","awardID":"0911036","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["516488","516488","448955","531543","564021",406765],"PO":["563751"]},"153527":{"abstract":"Images form the largest source of data and information in our digital society. Many application domains, such as medical diagnostics, homeland security, military surveillance, and Internet communication, can benefit from automated techniques for analyzing images and, in particular, for detection, classification, and analysis of objects in images. Fast techniques for object detection in images often work in two steps: (1) Extract certain basic primitives (prominent points, edges, arcs, etc) from images using fast techniques and, (2) glean objects of interest in these extracted primitives. This second step -- a statistical framework for shape-based discovery of objects in 2D and 3D point clouds -- is the focus of this research. Since the extracted primitives may belong either to objects or backgrounds, the given data is both noisy and cluttered. In simple terms, this problem is akin to finding the big dipper in the sky on a starry night. A simple combinatorial search is impossible, as the computational cost of organizing points into polygonal shapes are prohibitive. The framework proposed here is analysis by synthesis: one starts by synthesizing continuous shapes \u00d0 contours for 2D and surfaces for 3D -- for the shape classes of interest and samples these shapes into sets of points. These synthesized point sets are then (probabilistically) compared with the given point cloud to decide if a shape class is present in the image. <br\/><br\/><br\/>This research will take a Bayesian approach to shape classification where one estimates the posterior probabilities of different shape classes being present in the given point cloud. This involves a fundamental step of integrating out certain nuisance variables: (i) the unknown shape of object present in the data, (ii) the unknown pose and scale at which it appears in the scene, and (iii) the unknown sampling of a continuous shape into discrete points. The investigators will develop class-specific statistical models to capture variability of these nuisance variables, and will use a Monte Carlo approach that simulates from these models to approximate the desired posterior. This framework relies on the following ingredients: (1) Statistical shape models: Firstly, the investigators will derive mathematical representations of shapes (of curves and surfaces), impose Riemannian metrics on their shape spaces and develop algorithms for computing geodesics. Secondly, they will define and estimate probability models on the resulting shape spaces and simulate shapes from those models for use in generating stochastic inferences. Since shape spaces are typically infinite-dimensional, nonlinear manifolds, the prospect of efficient statistical inferences of shapes is both novel and challenging. (2) Shape Sampling: To synthesize a hypothesized point set, one takes a continuous shape and samples it with a finite number of points. The researchers will develop mathematical representations and stochastic models for this sampling process. (3) Likelihood Evaluation: Lastly, one needs to calculate the likelihood of the given point cloud. This involves optimally registering and transforming (rotating, translating, and scaling) the synthetic point set to match the given data. The cost function is based on probability models for the observation noise and the background clutter. This project will research, develop, and implement these fundamental ingredients for finding shapes in point clouds. The proposed framework will be tested for performance and efficiency in detecting and classifying objects in images.","title":"MCS: Research on Detection and Classification of 2D and 3D Shapes in Cluttered Point Clouds","awardID":"0915003","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[408597,"550508",408599],"PO":["565286"]},"153769":{"abstract":"This project aims to modify the representation of binary executable files by retaining information generated during various program transformations using an XML notation. If retrievable, the information lost during transformation processes could potentially improve the hardware\/runtime system. <br\/><br\/>While high level programming languages support software development, computer architecture is implemented more efficiently around low level assembly\/machine programming language. This gap between high level and machine level programming languages is bridged by translations performed by a compiler. A compiler performs significant analysis and translation on the high level program code program in order to generate optimized low level code. However, the original program's structural information is lost by the time the program has been translated into a low level representation. Consequently, an existing processor's architectures cannot benefit from such structural information.<br\/><br\/>Many dynamic optimizations performed in a processor, such as branch and value prediction, and many dynamic compiler optimizations, such as dynamic loop unrolling, can be expressed in a semantically rich binary file format. This project uses an XML based binary file format to express program structure. The program metadata is expressed as XML namespace tags. A processor, consisting of a meta-engine to interpret the program level structure semantic metadata, transforms the binary program in order to affect the specified dynamic optimizations before handing it over to a classical execution engine. This approach opens up many performance enhancement opportunities, controlled by the program itself. In this seed project, the execution engine is realized through a simulation environment based on Open DOS (Open Source Dynamic Optimization). A proof-of-concept compiler, XMLgcc, generates the metadata tagged binary files. <br\/><br\/>This project will result in a transformative view of processor and compiler design. This may spur processor development activity due to \"soft\"ization of many of the current hard features of an architecture - a corresponding compiler development has significantly lower overhead. The empirical nature of computer architecture and compilers requires a platform on which architecture and compiler variations can be implemented with low cost. Such a platform is an ideal pedagogical tool for exposing such \"what if\" iterative design process to computer architecture and compiler students. <br\/><br\/>The team will also develop instructional modules based on the SeeMe platform for various computer architecture and compiler (dynamic optimization) topics for graduate classes.","title":"CSR: Small: Meta Analysis Directed Execution","awardID":"0915992","effectiveDate":"2009-09-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[409195,"521840",409197],"PO":["565255"]},"151008":{"abstract":"A current industry trend aimed at addressing platform performance\/power requirements is to create heterogeneous manycore systems, comprised of general purpose and specialized cores designed to accelerate certain application or system functions. A second trend, designed to make it easier to map a wide variety of functions and components to manycore platforms, is platform-level support for system virtualization. This research innovates, implements, and evaluates new virtualization technologies for heterogeneous manycore architectures composed of commodity general-purpose and accelerator cores. The goal is to realize an efficient execution environment for composing and executing a range of computationally and data-intensive applications.<br\/><br\/>The system abstractions innovated include (i) the HVM (heterogeneous virtual machine) platform abstraction for dynamic composition of resources (e.g., cores, accelerators, memory, I\/O) (ii) new methods for managing heterogeneous manycore resources, including power, and (iii) specialized execution environments for optimizing accelerator interactions. These components are implicitly integrated through an execution model wherein the same abstractions and mechanisms are used to dynamically manage diverse accelerator platforms, thereby realizing our vision of freely shared and customized platform resources provided to applications.","title":"SHF: Medium: Heterogeneous Virtual Machine: Future Execution Environments for Heterogeneous Many-core Architectures","awardID":"0905459","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"6892","name":"CI REUSE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["406494","517873","523077","556660"],"PO":["565272"]},"151019":{"abstract":"This project is developing and evaluating the application of iterative process improvement technology to assure the privacy, security, reliability, and trustworthiness of elections, which are the very cornerstone of democracy. The focus of the project is to locate mismatches between existing voting systems and the processes that are currently using them in the conduct of elections. These mismatches can result in vulnerabilities or inaccuracy in elections. This project demonstrates how to remediate such vulnerabilities through the use of iterative process improvement. The methodology uncovers vulnerabilities by modeling processes and examining how discrepancies between the characteristics of these processes and the behaviors of voting systems that are used by the processes can lead to such vulnerabilities. In this way, this project is making a novel and important contribution to defending one of the most critical processes of democracy.<br\/><br\/>The project tests the results on the election processes and systems of Yolo County. Part of the research is to model that county's processes using the process definition language, and examining what these processes require and expect from the voting systems they use. The existing voting systems can then be examined to determine whether they meet the requirements and expectations of the processes using them. Where mismatches occur, the vulnerabilities created by such mismatches can be assessed, improvements suggested, and the methodology can show how the suggested improvements address the mismatches and remove the vulnerabilities.","title":"TC:Medium:Collaborative Research: Technological Support for Improving Election Processes","awardID":"0905503","effectiveDate":"2009-09-15","expirationDate":"2013-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["560876"],"PO":["565264"]},"158906":{"abstract":"In today's high-end computing (HEC) systems, the parallel file system (PFS) is at the core of the storage infrastructure. PFS deployments are shared by many users and applications, but currently there are no provisions for differentiation of service - data access is provided in a best-effort manner. As systems scale, this limitation can prevent applications from efficiently utilizing the HEC resources while achieving their desired performance and it presents a hurdle to support a large number of data-intensive applications concurrently. This NSF HECURA project tackles the challenges in quality of service (QoS) driven HEC storage management, aiming to support I\/O bandwidth guarantees in PFSs by addressing the following four research aspects: 1. Per-application I\/O bandwidth allocation based on PFS virtualization, where each application gets its specific I\/O bandwidth share through its dynamically created virtual PFS. 2. PFS management services that control the lifecycle and configuration of per-application virtual PFSs as well as support application I\/O monitoring and storage resource reservation. 3. Efficient I\/O bandwidth allocation through autonomic, fine-grained resource scheduling across applications that incorporate coordinated scheduling and optimizations based on profiling and prediction. 4. Scalable application checkpointing based on performance isolation and optimization on virtual PFSs customized for checkpointing I\/Os.","title":"HECURA: Collaborative Research: QoS-driven Storage Management for High-end Computing Systems","awardID":"0937973","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["558495"],"PO":["565272"]},"157828":{"abstract":"The objective of this research is to develop the theoretical<br\/>foundations for understanding implicit and explicit<br\/>communication within cyber-physical systems. The approach is<br\/>two-fold: (a) developing new information-theoretic tools to<br\/>reveal the essential nature of implicit communication in a<br\/>manner analogous to (and compatible with) classical network<br\/>information theory; (b) viewing the wireless ecosystem itself<br\/>as a cyber-physical system in which spectrum is the physical<br\/>substrate that is manipulated by heterogeneous interacting<br\/>cyber-systems that must be certified to meet safety and<br\/>performance objectives.<br\/><br\/>The intellectual merit of this project comes from the<br\/>transformative technical approaches being developed. The key to<br\/>understanding implicit communication is a conceptual<br\/>breakthrough in attacking the unsolved 40-year-old Witsenhausen<br\/>counterexample by using an approximate-optimality paradigm<br\/>combined with new ideas from sphere-packing and cognitive radio<br\/>channels. These techniques open up radically new mathematical<br\/>avenues to attack distributed-control problems that have long<br\/>been considered fundamentally intractable. They guide the<br\/>development of nonlinear control strategies that are provably<br\/>orders-of-magnitude better than the best linear strategies. The<br\/>keys to understanding explicit communication in cyber-physical<br\/>systems are new approaches to active learning, detection, and<br\/>estimation in distributed environments that combine worst-case<br\/>and probabilistic elements.<br\/><br\/>Beyond the many diverse applications (the Internet, the smart<br\/>grid, intelligent transportation, etc.) of heterogeneous<br\/>cyber-physical systems themselves, this research reaches out to<br\/>wireless policy: allowing the principled formulation of<br\/>government regulations for next-generation networks. Graduate<br\/>students (including female ones) and postdoctoral scholars will<br\/>be trained and research results incorporated into both the<br\/>undergraduate and graduate curricula.","title":"CPS: Medium: Collaborative Research: The Foundations of Implicit and Explicit Communication in Cyberphysical Systems","awardID":"0932410","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560235"],"PO":["562984"]},"157718":{"abstract":"CPS: Small: Collaborative Research: Distributed Coordination of Agents For Air Traffic Flow Management<br\/><br\/>This objective of this proposal is to improve the management of the air traffic system, a cyber-physical system where the need for a tight connection between the computational algorithms and the physical system is critical to safe, reliable and efficient performance. <br\/>The approach is based on an adaptive multiagent coordination algorithm with a particular emphasis on the systematic selection of the agents, their actions and the agents' reward functions. <br\/><br\/>The intellectual merit lies in addressing the agent coordination problem in a physical setting by shifting the focus from ``how to learn\" to ``what to learn.\" <br\/>This paradigm shift allows a separation between the learning algorithms used by agents, and the reward functions used to tie those learning systems into system performance. By exploring agent reward functions that implicitly model agent interactions based on feedback from the real world, this work aims to build cyber-physical systems where an agent that learns to optimize its own reward leads to the optimization of the system objective function. <br\/><br\/>The broader impact is in providing new air traffic flow management algorithms that will significantly reduce air traffic congestion. The potential impact cannot only be measured in currency ($41B loss in 2007) but in terms of improved experience by all travelers, providing a significant benefit to society. In addition, the PIs will use this project to train graduate and undergraduate students (i) by developing new courses in multiagent learning for transportation systems; and (ii) by providing summer internship opportunities at NASA Ames Research Center.","title":"CPS: Small: Collaborative Research: Distributed Coordination of Agents For Air Traffic Flow Management","awardID":"0931591","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["434734"],"PO":["565274"]},"148907":{"abstract":"Through Grid and Cloud computing, the importance of distributed computing has risen dramatically in recent years, increasing the computational power available to a widening audience of scientific and commercial users. Gains in computing power have caused a drastic increase in the volume of data produced by users, requiring new research on improved management and access to distributed data. These gains also drive the need for efficient scheduling and leasing of computational resources and for adapting current work in machine virtualization to a distributed context. These research directions require the development and evaluation of new models for computational, communication, and storage costs, but existing infrastructure makes model evaluation difficult or impossible, since they are in constant use by other researchers.<br\/>This project addresses these concerns by providing a diverse group of researchers with a Distributed Research Testbed (DiRT) on which to develop and evaluate new technologies. The clusters making up the testbed are located at the University of Chicago, the University of Florida, the University of Hawai?i, the University of Notre Dame, and the University of Mississippi. Unlike working grid environments, we have complete low-level control of the hardware and complete knowledge of where the data and computation are located. We will use the testbed to address problems faced today by the growing number of users of distributed computing. Because high performance computing is essential to the conduct of modern science, this project will have significant impact on research and education in a a wide variety of scientific disciplines.","title":"Collaborative Research: II-New: Distributed Research Testbed (DiRT)","awardID":"0855031","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["558495"],"PO":["564778"]},"148918":{"abstract":"In the Information Age, processing and representation of multidimensional data has gained critical importance. The goal of this project is to train students at Northern New Mexico College in effective use of the power of parallel computing in processing and visual representation of large volumes of data. The High Performance Cluster of computers will be used for both and research and educational projects. At least, ten of the faculty at the College will actively use the cluster for research. The PI will model the nanotechnology of semiconducting materials like gallium arsenide and its applications to solar devices. Dr. David Torres, Co-Principal Investigator, will conduct simulations of incompressible fluid flow and surface tension. Surface tension is important in many industrial settings, including casting, fuel injection sprays and inkjet printers. Dr. Cathy Berryhill and Mr. Jean Constant will team up with the PI to conduct research on scientific visualization, including the study of novel ways of displaying information and the effective use of visualization software in the classroom. Dr. Claudia Aprea will use the cluster for research in Earth and Planetary Science and Environmental Science, including work on mapping the subsurface of Mars, on creating a 3-dimensional geophysical model database for the state of New Mexico, and on the mapping the surface of the Earth for scientific or prospecting purposes. Research areas of interest to other faculty include a database of local pollen counts, the design of feedback control systems, the performance of solar photovoltaic systems, and the reliability of computer storage systems. The project will facilitate research, teaching and outreach activities at the host institution.","title":"Parallel Computing to Promote Research and Education Opportunities at Northern New Mexico College","awardID":"0855059","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[396895,"510289"],"PO":["565272"]},"160952":{"abstract":"State-of-the-art data stream clustering algorithms developed by the data mining community do not utilize the temporal order of events and therefore in the resulting clustering all temporal information is lost. This is quite strange as one of the salient features of data streams is temporal ordering of events. In this project we develop a technique to efficiently incorporate temporal ordering into the clustering process and prove its usefulness on large, high-throughput data streams. Temporal ordering is introduced into the data stream clustering process by dynamically constructing an evolving Markov Chain where the states represent clusters. Our approach is based on the previously developed Extensible Markov Model (EMM). The results of this project will provide a framework upon which important stream mining applications such as anomaly detection and prediction of future events are easily implemented. <br\/><br\/>By showing that state-of-the-art data steam clustering algorithms can incorporate temporal order information efficiently, this project will have a broad impact on many areas where temporal order is essential. As examples, NOAA Hurricane Data and NASA satellite data will be used throughout this project. Results, including open source software will be distributed via the project Web site (http:\/\/lyle.smu.edu\/ida\/tracds).","title":"III\/EAGER: Temporal Relationships Among Clusters in Data Streams (TRACDS)","awardID":"0948893","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[430435,430436],"PO":["563751"]},"150920":{"abstract":"Computing substrates such as multi-core processors or Field Programmable Gate Arrays (FPGAs) share the characteristic of having two-dimensional arrays of processing elements interconnected by a routing fabric. At one end of the spectrum, FPGAs have single-output programmable logic functions, and at the other end, multi-core chips have complex 32\/64-bit processing cores. For different applications, different programmable substrates produce the best area-power-performance tradeoffs. This project is developing a large-scale multi-core substrate that has hundreds or thousands of simple processing cores along with a compilation system that maps computations onto this fabric. This many-core architecture, named Diastolic Array, is coarser-grained than FPGAs but &#64257;ner-grained than conventional multi-cores. To efficiently exploit such a large number of processing cores, the architecture needs spatially mapping a computation to processing cores and communication to the point-to-point interconnect network. To be practically viable, this mapping process must be automated and effective. The project addresses this challenge by simultaneously developing hardware architecture and a compilation system. <br\/><br\/><br\/>A diastolic array chip is expected to outperform FPGAs or general-purpose processors on an interesting class of applications, enabling more efficient prototyping and low-volume production. The outcomes of this project such as statically-con&#64257;gured interconnection architecture with associated algorithms for routing and resource allocation will also be applicable to other multi-core designs. Finally, the project is developing a new parallel processing module for an undergraduate computer architecture class to give sophomores early exposure to parallel hardware, experience with writing parallel programs and using compilers that exploit parallelism.","title":"SHF: Medium: Collaborative Research: Throughput-Driven Multi-Core Architecture and a Compilation System","awardID":"0905208","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["519715"],"PO":["562984"]},"160743":{"abstract":"Abstract: This proposal focuses on conducting a feasibility study for the institution of an open access National Science Foundation (NSF) publication repository. Specifically, the Johns Hopkins University, in conjunction with the Council on Library and Information Resources (CLIR) and the University of Michigan (UM) will evaluate the technical, policy, and business implications of several approaches that range in options from developing a new system to adopting and customizing distributed technologies to federating a network of institutional repositories. The outcome of this feasibility study will help to better characterize and inform decision makers on the relative strengths and weaknesses for both the technological and economic dimensions characterizing current dialogues on the subject and to further address lingering questions, community wide, about the functional nature and designs for future open access repositories. This feasibility study will similarly address a challenging set of activities pertaining to the integration of traditionally shared data and open-source electronic publishing systems through shared stewardship and infrastructure architectures.","title":"A Feasibility Study for a National Science Foundation Open-Access Publication Repository","awardID":"0948134","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[429903,"563069","555532"],"PO":["565292"]},"160985":{"abstract":"E-government information can be difficult to find, access, and use because much of it is hidden in the deep Web, e.g. dynamic content automatically generated from databases. Although commercial and governmental search engines and directories provide access to much Federal information, significant challenges remain. Techniques for exposing Deep Web portal pages are not nearly as well defined as the field of full text searching. Since databases typically have far more dimensions than regular web pages, the question is how to create a topical index that is detailed enough to get potential users to a site portal page, but not so enormous as overwhelm users with a large set of databases for any query. The access of Deep Web portals requires extra data structures such indexes. Although automatic computational software may be able to generate preliminary index words and descriptions for the Deep Web portals, the automatically generated data structure is highly noisy and inaccurate. In this project, the team plans to solve this by combining automatic information processing with social computing mechanisms, particularly collective knowledge accumulation and collaborative sense-making ? social cognitive processes by which people collectively gather, organize, and understand information and knowledge. By introducing social computing mechanisms, the challenge of designing incentive mechanisms is introduced. These will be explored using mechanisms from incentive centered design. The major pay-off in this proposal is the improvement in transparency and information services provided by government websites, exposing resources and helping users to understand them.","title":"EAGER: True Government Transparency: Comprehensive National Data Finding and Navigation Tools","awardID":"0949025","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[430566,430567,"507380"],"PO":["565136"]},"150953":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5). This project will investigate people's social and moral relationships with personified robots. These robots, in various ways and to varying degrees, embody aspects of people insofar as they have a persona, are adaptive and autonomous, and can talk, learn, use natural cues, and self organize. This project will complete five complementary investigations: (1) Research on whether adults believe that a humanoid robot has feelings, is intelligent, can be a friend, is autonomous, and has moral standing (i.e., can be the recipient of unfair actions and unwarranted psychological harm). (2) A study of the extent to which children, adolescents, and adults believe that a robot can be responsible for harm it causes humans. (3) A study of moral standing and accountability that examines whether children, adolescents, and adults consider a humanoid robot most like a human, child, animal, or object - or as a new technological genre. (4) Research on whether children, adolescents, and adults believe that a robot is an entity that engenders trust and can be trusted. (5) A design study of patterns for sociality in human-robot interaction that characterizes essential features of social interaction between humans and robots. <br\/><br\/>Taken together, this body of work would provide for the first time a systematic account of social and moral behavior and reasoning with a humanoid robot that cuts across childhood, adolescence, and adulthood. In terms of basic science, this project will test the hypothesis that people do not simply act \"as if \" personified robots are social (like \"characters\" in a play), but engage personified robots sincerely and meaningfully as social others, and in some ways even as moral others. At the same time, this project would determine the extent to which human-robot interaction is not simply the mapping of human-human interactions (or human-animal interactions) onto robots, but represents a new genre: technological yet animate, personified, responsive, and seemingly autonomous.<br\/><br\/>As personified robots become more prevalent and integrated into people's everyday social lives, they will pose children and adults with significant challenges, socially and morally. The specific challenges will depend on how the robots are designed, their context of use, and on how people actually interact with such robots. In future, robots may become caretaking assistants for the elderly, academic tutors for children, or medical assistants, day care assistants, or psychological counselors. Thus, it is important to understand at the outset how different age groups respond to robots and conceptualize their increasingly complex behavior. It is likely in the near future that the public will raise serious concerns about the introduction of personified robots into society. Concerns may be voiced, for example, that interacting with personified robots will reify a master-servant relationship (with the robot as servant), or undermine authenticity of real social relationships. Parents, in particular, may voice concerns about the impacts of personified robots on their children. The results of this proactive research and design project will provide guidance in responding most appropriately to such concerns and will establish principles for assuring that robots will be used only for human benefit.","title":"HCC: Medium: Social and Moral Relationships With Personified Robots","awardID":"0905289","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["546850"],"PO":["564456"]},"153901":{"abstract":"Businesses and other organizations increasingly rely on business<br\/>process management, and in particular the management of electronic<br\/>workflows underlying business processes. These workflows are often<br\/>centered around a database. They are typically very complex and prone<br\/>to costly bugs, which leads to a critical need for computer-aided<br\/>design and static analysis tools. Such tools would result in enhanced<br\/>functionality, as well as increased confidence in the robustness and<br\/>correctness of complex business processes. They would potentially<br\/>benefit a wide variety of applications ranging from e-commerce to<br\/>digital government to healthcare and scientific applications. <br\/><br\/>Classical software verification techniques applicable to static analysis <br\/>include model checking and theorem proving. However, both have serious<br\/>limitations: Model checking requires finite-state abstraction, which<br\/>results in serious loss of semantics for both the business process and<br\/>verified properties. Theorem proving is incomplete and requires expert<br\/>user feedback. This project proposes an alternative approach to<br\/>static analysis. Instead of applying general-purpose techniques with<br\/>only partial guarantees of success, it aims to identify restricted but<br\/>sufficiently expressive classes of business processes for which sound<br\/>and complete static analysis can be performed in a fully automatic way.<br\/><br\/>Moreover, the target of verification consists of semantically rich<br\/>data-aware workflows, in contrast to the traditional process-centric<br\/>workflows. Data awareness is a feature of central importance in<br\/>applications such as the above, which has recently led to the<br\/>emergence of a new approach to workflow specification in which data is<br\/>pre-eminent. This approach, introduced by IBM, focuses on data records,<br\/>known as \"business artifacts\" or simply \"artifacts\", that correspond<br\/>to key business-relevant objects, their life cycles, and the<br\/>services (or tasks) that are invoked on the artifacts.<br\/>IBM's artifact-centric approach has been demonstrated to yield<br\/>substantial improvements to the operations of medium- and large-sized<br\/>businesses. <br\/><br\/>The main objective of the present project is to develop<br\/>new tools for the high-level specification and verification of such<br\/>data-centric business processes. The project investigates the<br\/>trade-offs between the expressiveness of the specification language<br\/>and the feasibility of the analysis tasks. It aims to establish<br\/>tractability boundaries for static analysis and to develop practical<br\/>algorithms and heuristics. Tools are to be developed for carrying out<br\/>analysis tasks, that will be integrated with Siena, IBM's prototype<br\/>for compiling artifact-centric business process specifications into<br\/>workflow support code. The technical problems raised are<br\/>intellectually quite challenging, and bring into play techniques from<br\/>logic, automata theory, computational complexity, algorithms, and<br\/>computer-aided verification. The resulting static analysis tools have<br\/>high potential for becoming a transformational technology in the area<br\/>of business processes.<br\/><br\/>For further information see the project web page<br\/>http:\/\/db.ucsd.edu\/artifacts","title":"III: Small: Data-Centric Business Processes: Specification and Static Analysis","awardID":"0916515","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[409520,"518657"],"PO":["565136"]},"150755":{"abstract":"Industry will soon manufacture transistors whose sizes are on the order of atoms. These tiny transistors are fragile, meaning each transistor will be different and will change during use. Many transistors will be unusable when first built; still others will degrade or fail with use. Like people or snowflakes, each of our components (e.g. microprocessors, graphic chips, memories) and systems (e.g. cell phones, mp3 players, anti-lock brakes) built with these tiny transistors will be unique. Traditional, one-size-fits-all approaches assign tasks to transistors oblivious of their unique strengths and weaknesses; these approaches waste much of the potential benefits of these tiny transistors, leading to systems that cost too much, use too much energy, and fail too soon. This research explores a novel assignment approach that assigns tasks adaptively based on measured transistor characteristics. The fastest transistors are assigned where they most accelerate performance, while the slower transistors can still be used for less time-critical tasks. Assignments are further re-evaluated during system operation, allowing fresh transistors to replace transistors that wear out.<br\/><br\/> Practically, this means IC manufacturers can produce smaller transistors and continue to deliver more capable electronics (e.g. digital video recorders, cell phones, laptops, supercomputers) for fixed dollar budgets. These capabilities continue to improve our quality of life, providing richer media, better communication, greater automation, and greater safety. This work will reduce the energy per computational task thereby extending battery life, reducing energy bills, and facilitating cooler operation. Replacement and reassignment mean electronic components will last longer and degrade gracefully.","title":"SHF: MEDIUM: Semiconductor Life Extenstion through Reconfiguration","awardID":"0904577","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["497005"],"PO":["366560"]},"153912":{"abstract":"In just a decade, dynamic invariant inference has emerged as one of the most promising directions in program analysis, with a variety of applications. An invariant inference system observes a program during test execution and filters a large number of candidate invariants (i.e., suspected relations between program data), finally reporting only those that hold with high confidence. However, inferred invariants are not always true (they depend on the quality of a test suite), and the few really useful invariants discovered are often accompanied by many more true but trivial and irrelevant facts. This work improves the quality of discovered invariants by ensuring their consistency with facts that are known statically. For instance, even though the invariants describing the behavior of two functions f1 and f2 may be unknown, we may know that any valid input for f1 is also valid for f2. This fact can be incorporated in the inference process to eliminate inconsistent invariants. More generally, the work explores techniques for expressing, discovering, and employing such consistency constraints to improve the quality of produced invariants, from type information and other sources including static analysis and user-supplied annotation.<br\/><br\/>The work will impact many aspects of software engineering, including scientific and industrial uses. Concrete benefits will be in the form of publications, usable software (released under an academic open-source license), software prototypes, and educational activities and resources (enhancement of a textbook and current courses, internships for high school students).","title":"SHF:Small:Collaborative Research:Dynamic Invariant Inference, Enhanced","awardID":"0916569","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["422657"],"PO":["565264"]},"152702":{"abstract":"The goal of this work is to develop a better fundamental understanding of the actuation and force sensing required for micromanipulation (objects from 5-500 microns) by exploring the following hypothesis: it is possible to manipulate micro-sized rigid and flexible objects while measuring physical properties, such as stiffness, by using the same microfinger to act simultaneously as an actuator and sensor. This hypothesis is explored both theoretically and experimentally by creating a set of smaller and smaller microgrippers. Two models, one analytical, the other numeric, of this new microfinger will be developed to predict performance as a function of size. Experiments using actual microgrippers verify the quality of the model.<br\/><br\/>The work impacts science, education, and outreach to minority populations. A compliant microgripper is an enabling technology to manipulate flexible and fragile bio-objects for applications in bioengineering, microbiology and genomics. A microgripper squeezes an oocyte to determine its viability by measuring the stiffness of the cell before subsequent injection of DNA or RNA, turning tedious manual procedures into programmed, automatic sequences, thereby reducing cost. New ways of detecting diseases, such as malaria, by measuring physical properties of cells with the microgripper become possible. Broader impacts include education and outreach. Great emphasis is spent on having supported students give talks about this technology at local middle schools and high schools to entice the next generation to become engineers. These talks improve the professional capabilities of the graduate students while simultaneously demonstrating to young students the purpose of studying math and science.","title":"RI: Small: A Microgripper with Concurrent Actuation and Force Sensing","awardID":"0911133","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["449805"],"PO":["564069"]},"150887":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009(Public Law 111-5). The goals of this research project are to understand how variables within social computing environments improve older adult cognition, what properties of an environment are critical, and empirically test these properties in interventions with older adults. The applied output will be design guidelines for a class of cognitive games for older adults and a new social computing environment. Two interventions will be run using video games to improve older adult cognitive and everyday abilities. The first intervention will use a commercial game (Boomblox-Wii) that contains the hypothesized variables necessary for cognitive improvement: novelty, attentional demand, and social interaction. The groups in this intervention will allow measurement of the individual and moderating effects of these variables. Pre-test and post-test ability measures will determine which variables or combinations of variables most improve the cognition and everyday functioning of older adults. The second phase is to use performance and preference data from Intervention 1 to maximally implement the variables shown to most improve cognition and functioning in a game specifically for older adults. The process of design will result in a set of guidelines for cognitive interventions to be used by other developers and researchers, ideally leading to a new class of \"brain games\" with reliable effectiveness.<br\/><br\/>These results will advance the knowledge and understanding of how cognitive training reduces age-related decline. The theory that social interaction can facilitate cognitive improvement by increasing effortful attention on a task is suggested by both behavioral and neurological evidence, but this project represents the first time these variables will be empirically tested, and the first intervention in a computing environment. Knowledge gained from this project touches the fields of cognitive aging, human-computer interaction, and social computing - all of which need data on effective cognitive training interventions. Results will aid designers who currently have little knowledge of the interface and game-play needs of older players.<br\/><br\/>This research advances the understanding of age-related change and social interaction by discovering the crucial components of successful cognitive training for older adults. Studying these components in the context of social computing and virtual worlds allows for world-wide impact and use by physically isolated individuals. A social computing environment may be used by older adults in rural communities, those separated geographically from their cohort, and those unable to leave their homes (all under-served populations). This project involves significant student involvement, providing varied mentorship opportunities to the students as well as exposure to differing methodologies. Specialized coursework will result from this project in developmental psychology, skill acquisition, and video game design.","title":"HCC: Medium: Collaborative Research: Improving Older Adult Cognition: The Unexamined Role of Games and Social Computing Environments","awardID":"0905127","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[402237,402238],"PO":["564456"]},"153923":{"abstract":"Recognizing objects in images is the central problem of computer vision. One approach (``bag of words'') compiles simple statistics on the image brightness patterns and recognizes by correlating these statistics, via learning, with the imaged objects. It cannot exploit important information on the image's spatial layout. Another approach, perceptual organization (PO), computes a distinctive, structural description of the image contents and recognizes based on this. Researchers agree that PO is a crucial early stage of recognition--and that its results are unreliable. (Images compress the 3D world and are ambiguous; PO cannot eliminate the ambiguity since it has no high-level knowledge of what the image is ``about.'') This leads to a fundamental dilemma: How can a recognition system use the result of PO if it cannot be trusted?<br\/><br\/>To exploit perceptual organizations without succumbing to their unreliability, this project uses a strategy that averages over all possible organizations weighted by their probability, instead of computing a single, ``most likely'' image description. This strategy is applied to diverse tasks such as matching images by the shapes of the objects within; recognizing articulated objects such as people and animals; tracking objects through video; and computing stable perceptual organizations. The project also studies the integration of this approach with older ones into a flexible and capable recognition system. The result will be new techniques for the analysis, manipulation, and search of images. The methods developed will be integrated in the curriculum and disseminated to researchers, and the software will be made publicly available.","title":"RI: Small: Organizing recognition: the uses of perceptual organization","awardID":"0916610","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[409574,409575,"551285"],"PO":["564316"]},"153813":{"abstract":"Software developers rely on reusing source code snippets from existing libraries or applications to develop software features on time and within budget. The reality is such that most previously implemented features are embedded in billions of lines of scattered source code. State-of-the-art code search engines provide no guarantee that retrieved code snippets implement these features. Even if relevant code fragments are located, developers face rather complex task of selecting and moving these fragments into their applications. Finally, synthesizing new functionality by composing selected code fragments requires sophisticated reasoning about the behavior of these fragments and the consequent code. The result of this process is an overwhelming complexity, a steep learning curve, and a significant cost of building customized software.<br\/><br\/>This research program proposes an integrated model for addressing fundamental problems of searching, selecting, and synthesizing (S3) source code. The S3 model relies on integrating program analysis and information retrieval to produce transformative models to automatically search, select, and synthesize relevant source code fragments. The S3 model will directly support new methodologies for software change and automated tools that assist programmers with various development, reuse and maintenance activities. Among the broader impacts the project includes collaboration with industry to transfer technology.","title":"III: Small: Collaborative Research: Creating and Evolving Software via Searching, Selecting and Synthesizing Relevant Source Code","awardID":"0916139","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["564387"],"PO":["564388"]},"153934":{"abstract":"Multicommodity flows, or multiflows in short, are central topics in all types of communication networks, whether wired or wireless. Computing a maximum (concurrent) multiflow in multihop wireless networks is particularly challenging because the capacities of the communication links, rather than being fixed, vary with the underlying link schedule. A unique challenge is thus how to compute a link schedule subject to the wireless interference constraint which induces a link capacity function supporting a maximum (concurrent) multiflow. This project establishes both the computational hardness and approximation hardness of computing maximum (concurrent) multiflows in multihop wireless networks, and develops practical approximation algorithms with provably good performance. A polyhedral approach is taken by the project to construct various polynomial approximate capacity subregions of multihop wireless networks. These approximate capacity subregions not only are the algorithmic foundation of the computing maximum (concurrent) multiflows, but also serve as a basis for interesting future projects on network capacity and cross-layer design and optimizations in multihop wireless networks. They are also of independent interest to the theoretical computer science community at large. This project provides scholarships to graduate students and offers research topics for strong dissertation works on multihop wireless networks. The outcome of this project will not only be disseminated to the professional researchers through journals and conference proceedings, but also be integrated into the lecture notes targeted for senior undergraduate students and graduate students.","title":"NeTS: Small: Multicommodity Flows in Multihop Wireless Networks","awardID":"0916666","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518604"],"PO":["557315"]},"163977":{"abstract":"Emmanuel Candes, a mathematician at the California Institute of Technology, has been selected to receive the National Science Board's prestigious Alan T. Waterman Award. The board cited Candes' development of new mathematical tools that allow efficient digital representation of wave signals, together with his discovery of new methods to translate analog data into a cleaner, tighter digital form--work that promises to improve the digital processing of signals in a vast array of modern technologies.<br\/><br\/>With the advent of digital technologies, translating analog information faithfully into digital representations has been a major challenge. The translating method, called sampling, must select enough information from the analog object to adequately reproduce it in digital form. Otherwise, key information may be lost.<br\/><br\/>Recently, Candes developed a new sampling mechanism that allows the faithful recovery of signals and images from far fewer data bits than traditional methods use. This new sampling theory may come to underlie protocols that sample and compress data simultaneously and much faster. \"In practice,\" Candes said, \"this means one could obtain super-resolved signals from just a few sensors.\"<br\/><br\/>The annual Waterman award recognizes an outstanding young researcher in any field of science or engineering supported by the National Science Foundation (NSF). Candidates may not be more than 35 years old, or seven years beyond receiving a doctorate. In addition to a medal, the awardee receives a grant of $500,000 over a 3-year period for scientific research or advanced study in the mathematical, physical, medical, biological, engineering, social, or other sciences at the institution of the recipient's choice.","title":"Alan T. Waterman Award","awardID":"0965028","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":[438963],"PO":["564898"]},"153824":{"abstract":"The Center for Computational Learning Systems (CCLS) is collaborating with the Computational Neurophysiology Laboratory (CNL) in the Department of Neurology, Columbia University Medical School (CUMC) to develop a distributed framework for data management and machine learning on intracranial EEG data obtained from patients suffering from epilepsy. <br\/><br\/>Drs. Schevon and Emerson have initiated a trial of a dense, two-dimensional microelectrode array which can record over long periods of time at a sampling rate of up to 30 kHz per channel. To date approximately 30 TB of data has been collected. The large volume of complex EEG data compels us to rethink how we will deal with this \"data avalanche.\" The design of a data center for storage and analysis is particularly challenging since traditional methods of storing data on a single server do not allow machine learning algorithms to be computed within a reasonable time. Further, due to the conditions under which the data is collected, noise of multiple types and sources is pervasive; the data must be extensively cleaned and potential seizure precursors carefully labeled. The project is investigating mechanisms to develop a cluster architecture (using Apache Hadoop) for the EEGMine Data Center that incorporates reliable storage and backup; developing a library of machine learning algorithms (EEGMine- ML library) and addressing their scalability issues, potentially leveraging the MapReduce programming paradigm. <br\/><br\/>This research will have immediate impact for both epilepsy and computer science research. Because of the uniqueness and value of human-derived microelectrode EEG data, it would be beneficial for the seizure prediction community to enable data sharing and long-distance collaborations. The most practical means of sifting through terabytes of complex EEG data is to combine distributed storage on a cluster with local processing to prepare data and generate meta-data that can be used as inputs for machine learning algorithms thus enabling identification of physiologically significant patterns. From an education perspective, the project will benefit the EWarn Research Group which is part of CCLS and CUMC by training them in signal processing, machine learning and basics of EEG. <br\/><br\/>Website Address: http:\/\/www1.ccls.columbia.edu\/~dutta\/EEGMine","title":"DC: Small: EEGMine: A Distributed Framework for Learning on EEG Data obtained from Epilepsy Patients","awardID":"0916186","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":[409330,409331,"409341",409333],"PO":["565136"]},"153945":{"abstract":"A major obstacle to delivering the increasingly complex software systems that society demands is the resource drain from maintaining existing systems. The high expense of maintenance is related to the tendency of software quality to decline over time. Maintenance is often performed under tight resource constraints, with the minimal amount of effort required. Typically, there is a gap between this minimal amount of work and the amount required to maintain the software's quality. This gap can be viewed as a type of debt, which brings a short-term benefit (usually shorter release time) but which might have to be paid back, with ?interest? (decreased productivity), later. Many practitioners find this metaphor intuitively appealing and it is already transforming the way that long-term software maintenance is viewed. But its lack of a sound theoretical basis, empirically-based models, and practical implementation hinder its ability to transform how maintenance is done. Thus the contribution of this work is to provide empirically based models describing, and validated mechanisms for managing, technical debt. This project also supports the PI's activities in mentoring a diverse population of students, as well as UMBC's nation-wide prominence in the advancement of women and minorities in science and technology.","title":"III:HCC:Small: Measuring and Monitoring Technical Debt","awardID":"0916699","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["559100"],"PO":["564388"]},"150436":{"abstract":"The objective of this research is to overcome barriers limiting multicore processor clock frequencies and to achieve faster clock and data throughput rates with technology scaling than currently possible. The approach is to design hardware and software infrastructure into multicore processors that enables low cost comparison testing of the individual processor cores and test driven tuning of processor circuitry for high-speed core operation. <br\/><br\/>The intellectual merit of this work lies in the ability of the underlying test and adaptation algorithms to extract the maximum amount of performance from the process cores that they are capable of delivering under inter and intra die process variations and electrical field degradation. Such adaptation is achieved with limited test and diagnosis cost while allowing possible \"test escapes\" to be handled in a fail-safe manner that does not result in a system crash. The diagnostics information generated is used to tune individual processor core circuitry for speed purposes. <br\/><br\/>The broader impacts of this research include the ability to run advanced applications on multicore processors in, for example, future 4G mobile wireless systems including high definition video, interactive displays, image processing, data mining algorithms and other pervasive computing tasks that demand high processor throughput at low power for low heat dissipation and high device reliability. The project will also enable training of students and industry personnel in a new interdisciplinary field that involves fundamental concepts from electrical engineering, device physics and computer science through prototype demonstrations, seminars, workshops, cooperative research and student internships in industry.","title":"Collaborative Research: Targeting Multi-Core Clock Performance Gains in the face of Extreme Process Variations","awardID":"0903449","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["550443"],"PO":["565185"]},"162778":{"abstract":"The medium-term goal of this project is to develop a Bio-enabled Sensor Network (BSN) composed of sensing devices that can enter a full sleep mode but still be woken up by a long-range RF signal. The idea is to transduce a weak Electro-Magnetic signal into biological signals and use a biological device to demodulate the information embedded in the EM signal. The short-term goal of this project is to develop a clear vision for the potential of biological communications and computation in the specific context of wireless sensor networks (WSN) and articulate a research path and preliminary answers to the following questions. What are the fundamental limits of EM energy harvesting? In the specific case of address recognition in WSN, what are the potential, means and limits of computation, communication, of a distributed network of biological processes? Beyond, the intra-node networked bio-communications and computation, the wake-up mechanism results in optimization problems because of its high delay and limited capacity. How can hybrid, biological and periodic, wake up mechanisms be combined to satisfy the system requirements? What is the viability of using biological organisms in WSNs? <br\/><br\/>Research in biological and molecular communications and computation holds the promise to revolutionize and bridge the fields of computer science, biology, electrical engineering, and mechanical engineering. The PI aims at obtaining preliminary results, and assembling a cross-disciplinary team with expertise in computation, communication, networking, biology, and nano-mechanics, to write a full proposal with clear, focused, and realistic objectives to develop a prototype BSN.","title":"EAGER: RF Control of Biological Systems -- Bio-enabled Wireless Sensor Networks","awardID":"0958927","effectiveDate":"2009-09-15","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518182"],"PO":["565303"]},"150799":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The project develops cryptographic protocol reasoning techniques<br\/>that take into account algebraic properties of cryptosystems.<br\/>Traditionally, formal methods for cryptographic protocol<br\/>verification view cryptographic operations as a black box,<br\/>ignoring the properties of cryptographic algorithms that can be<br\/>exploited to design attacks. The proposed research uses a novel<br\/>approach based on equational unification to build new more<br\/>expressive and efficient search algorithms for algebraic theories<br\/>relevant to cryptographic protocols. Equational unification gives<br\/>a compact representation of all circumstances under which two<br\/>different terms correspond to the same behavior. The algorithms<br\/>are implemented and integrated into Maude-NPA, a system that has<br\/>been successful in symbolic protocol analysis. It is demonstrated<br\/>that Maude-NPA when enriched with such powerful unification<br\/>algorithms can analyze protocols and ensure their reliability,<br\/>which could not be done otherwise.<br\/><br\/>Improved techniques for analyzing security are helpful both in<br\/>assuring that systems are free of bugs, and in speeding up the<br\/>acceptance of new systems based on the confidence gained by a<br\/>formal analysis. This research will lead to the design and<br\/>implementation of next generation tools for protocol analysis.<br\/>Algorithms developed will be made available to researchers as a<br\/>library suitable for use with protocol analysis tools. Tools from<br\/>the project will help students understand concepts relevant to<br\/>protocol design and get hands-on experience. Equational<br\/>unification for algebraic theories is not only useful for<br\/>protocol analysis, but also for program analysis in general, thus<br\/>making the results of this project to be widely relevant.","title":"TC: Medium: Collaborative Research: Unification Laboratory: Increasing the Power of Cryptographic Protocol Analysis Tools","awardID":"0904749","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550264"],"PO":["565264"]},"153835":{"abstract":"Society is faced today with three main energy-related challenges: US dependence on foreign energy sources, world-wide dependence on non-renewable energy, and climate change induced at least in part by greenhouse-gas emissions. The computer industry also faces an energy crisis: the nation's data centers consume a gigantic amount of energy, which translates into large greenhouse gas footprints. This research explores the implications of these trends on data center design. In particular, the work considers how to optimize data center operation in the face of Kyoto-style cap-and-trade frameworks, related cap-and-pay frameworks, and unregulated scenarios where businesses optimize energy usage to save money or achieve carbon neutrality. In both cap-and-trade and cap-and-pay, caps are imposed on activities society wants to discourage. In large computer systems, excessive brown energy consumption is one activity to discourage. Through caps on brown energy, society can also promote renewable energy. <br\/>Research challenges include: (i) balancing reductions in brown energy consumption against cost, performance and service-level agreement (SLA) impact, (ii) managing energy consumption in the context of variable electricity prices; and (iii) designing multiple system layers that effectively integrate and coordinate electricity and performance management, even in the face of highly volatile request distributions and electricity\/carbon prices. This research has the potential for broad impact both on computer systems design, and more broadly on an increasingly carbon-conscious world.","title":"CSR: Small: Collaborative Research: System Support for Managing Carbon Footprints and Electricity Costs in Internet Services","awardID":"0916246","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["495323"],"PO":["565255"]},"152625":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Obtaining physiological\/behavioral data from human subjects in their natural environments is essential to conducting ecologically valid social and behavioral research. While several body area wireless sensor network (BAWSN) systems exist today for physiological data collection, their use has been restricted to controlled settings (laboratories, driving\/flying scenarios, etc.); significant noise, motion artifacts, and existence of other uncontrollable confounding factors are the often cited reasons for not using physiological measurements from natural environments. In order to provide scientifically valid data from natural environments, a BAWSN system must meet several unique requirements (1) Stringent data quality without sensing redundancy, (2) Personalization to account for wide between person differences in physiological measurements, and (3) Real-time inferencing to allow for subject confirmation and timely intervention. <br\/><br\/>Intellectual Merit: In this project, a multidisciplinary team of researchers spanning various computing disciplines and behavioral sciences are developing a general purpose framework called FieldStream that will make it possible for BAWSN systems to provide long term unattended collection of objective, continuous, and reliable physiological\/behavioral data from natural environments that can be used for conducting population based scientific studies. FieldStream is being incorporated in two real-life projects ? NIH sponsored AutoSense at Memphis and NSF sponsored Urban Sensing at UCLA, to help validate the assumptions, establish the feasibility of developed solutions, and to uncover new requirements. <br\/><br\/>Broader Impact: By making it possible to obtain scientifically valid objective data from the field, FieldStream promises to help solve several behavioral problems of critical importance to human society that have remained unanswered for lack of such data.","title":"NetSE: Large: Collaborative Research: FieldStream: Network Data Services for Exposure Biology Studies in Natural Environments","awardID":"0910900","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["526997"],"PO":["565090"]},"161337":{"abstract":"This project addresses the problem of fitting an articulated body model to a person in an image. The task is challenging due to large variation in appearance caused by body pose, clothing, illumination, viewpoint and background clutter. Unlike current methods that try to fit a full body model to every image, this approach uses opportunistic search within a space of partial body models to find only those body parts that are currently visible and detected with high confidence. Not trying to fit occluded or poorly visible parts reduces the chances of making a mistake, so subsequent processes can rely on receiving a high-quality partial model solution. A stochastic search technique employing high-level subroutines to propose candidate body configurations searches for the globally optimal solution in terms of number and configuration of visible body parts, removing the need for a close initial estimate and allowing more thorough exploration of the solution space. The proposed partial body configurations also provide top-down guidance for image segmentation of individual body parts, yielding better delineation of body shape than simple parameterized models or bottom-up segmentation. An implementation of the approach is being compared against existing work using publicly available datasets. Robust segmentation of torso and limbs from still images provides a natural representation of the human body that can have broad impact on tasks such as human activity recognition and markerless body tracking within interactive smart spaces.","title":"RI: EAGER: Robust Opportunistic Fitting of Partial Body Models","awardID":"0951386","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["518440"],"PO":["564316"]},"153846":{"abstract":"This project investigates the computational conformal geometric methods applied for computer vision. The research team develops novel algorithms for shape analysis, surface matching and registration based on Ricci flow, and compared with conventional vision methods thoroughly. <br\/><br\/>The basic of idea of the research is to conformally deform all surfaces as one of three canonical shapes, and then perform matching and registering these 3D surfaces in 2D planes. The research team uses the Ricci for shape analysis to preserve the intrinsic geometric characteristics, and to map the surfaces to the canonical shapes.. Ricci flow is the process to deform the metric proportional to the curvature, such that the curvature evolves according to a heat diffusion process. The research team conducts thoroughly comparison with conventional vision methods through extensive experiments using real world datasets. The research benefits many computer vision and visualization applications with methods for computing and visualizing conformal structures and conformal invariants on surfaces. The project also provides opportunity for training students in the areas of differential geometry, hyperbolic geometry, Riemannian geometry, computer vision.","title":"IIS: III: Small: Conformal Geometry for Computer Vision","awardID":"0916286","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["508251","519258"],"PO":["564316"]},"166804":{"abstract":"Project Abstract<br\/><br\/>The evolution of semiconductor technology and computer systems has made interconnection networks, and particularly on-chip interconnection networks (OCNs), a critical technology. In recent years, single-processor performance has reached a plateau, leading processor manufacturers to combine many processors on a chip. Such multi-core or many-core chip multi-processor (CMP) architectures depend on an OCN to provide communication between processors, cache memory modules, and external memories and I\/O devices. A large fraction of area and power in such systems is consumed by communication making OCNs even more critical.<br\/><br\/>The PIs propose to develop enabling technology (circuits and architecture) for OCNs. They will develop circuits that are expected to reduce OCN power by 10x and decrease cost by 4x for an OCN with constant performance. This circuit-level work will enable the development of accurate models for the cost, power, and performance for key OCN components. Using these models, new network architectures will be developed that are expected to close much of the gap between an OCN and the ideal interconnect to 1\/3 of its present size. The technology developed will be demonstrated through implementing an optimized OCN to the level of completed layout. While the OCN will be targeted for CMPs and driven by CMP workloads through the RAMP infrastructure, the PIs will also be working with systems-on-chip groups to inject the proposed circuit macros and architectural designs into their design tool-chains.","title":"Collaborative Research: Enabling Technology for On-Chip Networks","awardID":"1008324","effectiveDate":"2009-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["446736"],"PO":["559883"]},"153857":{"abstract":"CSR: Small: Monitoring for Error Detection in Today?s High Throughput Applications<br\/><br\/>Abstract: Much of our critical infrastructure is formed by distributed systems with real-time requirements. Downtime of a system providing critical services in power systems, air traffic control, banking, and railways signaling could be catastrophic. The errors may come from individual software components, interactions between multiple components, or misconfiguration of these components. It is therefore imperative to build low latency detection systems that can subsequently trigger the diagnosis and recovery phases leading to systems that are robust to failures. A powerful approach for error detection is the stateful approach, in which the error detection system builds up state related to the application by aggregating multiple messages. The rules are then based on the state, thus on aggregated information rather than on instantaneous information. Though the merits of stateful detection seem to be well accepted, it is difficult to scale stateful detection with an increasing number of application components or increasing data rate. This is due to the increased processing load of tracking application state and rule matching based on the state. In this project, we address this issue through designing a runtime monitoring system focused on high throughput distributed applications. Our solution is based on intelligent sampling, probabilistic reasoning on the application state, and opportunistic monitoring of the heavy-duty rules. A successful solution will allow reliable operation of high bandwidth distributed applications and those with a large number of consumers. We will also achieve broader impact through an innovative service learning program at Purdue called EPICS and a new course.","title":"CSR: Small: Monitoring for Error Detection in Today's High Throughput Applications","awardID":"0916337","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["556632"],"PO":["565255"]},"153978":{"abstract":"The ability to estimate motion of objects from video is a fundamental scientific problem that arises in many tasks: finding out how the human body moves, tracking vehicles movements on a highway or the motility of schools of fish. Despite many advancements the problem remains hard because of sudden, often highly nonlinear changes and the high dimensionality of the object's configuration spaces. Much prior work has focused on building complex physics-based models, in an \"analysis-by-synthesis\" paradigm dominated by expert's domain knowledge. When such knowledge is lacking, the resulting models may produce inaccurate predictions. <br\/><br\/>To address these issues, this project investigates a new paradigm of using limited amounts of carefully collected data to learn direct predictive models of high-dimensional motion. We approach the problem as that of the structured regression, a novel generalization of traditional statistical methods that specifically exploits the spatio-temporal structure of the data to avoid the need for \"analysis-by-synthesis\". This research will result in a set of robust techniques and computational algorithms that support this new modeling framework.<br\/><br\/>The tools and techniques developed here will have wide applicability in many areas of technology and industry that rely on design of accurate prediction models in complex space-time domains, leading to more general and sustainable forecasting solutions. Through engagement of graduate and undergraduate students in key research activities, the project also provides advanced technical training vital for success of a new generation of computer scientists.","title":"RI: Small: Novel structured regression approaches to high-dimensional motion analysis","awardID":"0916812","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["522466"],"PO":["564316"]},"153627":{"abstract":"Device drivers constitute a large fraction of the code in commodity operating systems. Over 35,000 drivers with over 112,000 versions exist for Windows XP, while over 3.1 million lines out of 5.4 million lines of the Linux kernel is device driver code. As several recent exploits against device drivers show, drivers are rife with bugs that compromise system security.<br\/><br\/>Exploits against device drivers are dangerous because commodity operating systems execute drivers in kernel address space. A compromised driver can modify kernel data structures or execute arbitrary code with kernel privilege. Prior techniques that protect commodity OS kernels from device drivers either suffer from low performance or are limited to specific classes of vulnerabilities, such as memory errors.<br\/>Inspired by user-mode driver frameworks, this project applies a three-pronged approach to the problem of protecting kernel data from vulnerabilities in device drivers. First, this project will develop techniques to monitor kernel data structure updates initiated by device drivers and ensure that they do not compromise the integrity of these data structures. Second, it will develop techniques to limit driver access to kernel memory via DMA without requiring hardware support yet taking advantage of it if available. Third, it will develop new techniques for recovering from compromised drivers.<br\/><br\/>These techniques are applicable to legacy device drivers on standalone commodity operating systems and require minimal changes to the operating system. In addition, they impose negligible overheads on common-case performance of device drivers and are thus practical for use even with high-throughput devices.","title":"TC: Small: Collaborative Research:Protecting Commodity Operating Systems From Vulnerable Device Drivers","awardID":"0915363","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["559530"],"PO":["565327"]},"153748":{"abstract":"Mobile computer systems and software are increasingly subject to a host of security threats and malicious software (malware) attacks due to vulnerabilities in their coding. The difficulty in achieving secure systems is further compounded by prevalence of unsophisticated users and the increasing reliance on third party software integration by enabling software module plugins for such user applications as web browsers and search engines. Traditional approaches have sought to provide an absolute defense to specific malware attacks by patching software vulnerabilities or detecting and blocking malware. One difficulty with these approaches for small mobile platforms is that the design constraints on these devices often favor low power to maximize battery life over enhancements to support security protocols. The current situation also represents a programmatic arms race between patching existing vulnerabilities and exploiting vulnerabilities in new application code. This research develops a new secure mobile computing environment based on current mobile technology widely available as consumer end products that seeks to use program differentiation to reduce the propagation rate of malware when a software vulnerability exists. This results not in the direct elimination of security vulnerabilities, but in the dramatic reduction in scope of any security exploit to infect large numbers of systems. By constraining the outbreak to only a few systems, counter measures can be employed before significant economic damage can result. By modifying aspects of the execution of the application, application executables can be permuted into unique versions for each distributed instance. Differentiation is achieved using hardware and\/or systems software modifications. Areas of differentiation include function call\/return and system call semantics, as well as a proposal for hardware-supported Instruction Register File access and intrusion detection monitoring. Differentiation of executables hinders analysis for vulnerabilities as well as prevents the exploitation of a vulnerability in a single distributed version from propagating to other instances of that application. By focusing on prevention of malware propagation in addition to traditional absolute defenses, we target the economics of malware in order to make attacks prohibitively expensive and infeasible.<br\/>This approach can be more feasible than some conventional security approaches since it can be readily applied to the restricted performance capabilities of mobile systems and the legal constraints on the export of encryption technology. Further information and software distribution related to this project can be accessed at: http:\/\/www.cs.fsu.edu\/~tyson\/differentiation.","title":"TC: Small: Reducing Virus Propagation in Mobile Devices","awardID":"0915926","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["537231","537232"],"PO":["565327"]},"161008":{"abstract":"International travel support enables U.S.-based graduate students to attend the 2009 IEEE International Conference on Data Mining (ICDM 2009), held in Miami, Florida, USA December 6-9, 2009 (http:\/\/www.cs.umbc.edu\/ICDM09\/). ICDM is the world's premier research conference in data mining. It provides an international forum for presentation of original research results, as well as exchange and dissemination of innovative, practical development experiences. The conference covers all aspects of data mining, including algorithms, software and systems, and applications, as well as related areas such as data management, machine learning and bioinformatics. The conference proceedings are published by IEEE.<br\/><br\/>With the growth of the Web, the Internet, and data intensive technologies such as Sensor Networks and Bioinformatics, ICDM seeks to continuously advance the state-of-the-art in data mining as an extremely important area in Information Technology. The total number of ICDM participants in the past has been in excess of 300, with a majority of the participants from the U.S., then Europe and Asia. This travel support is expected to provide scholarships to 15 U.S.-based graduate student participants to partially defray travel costs for the qualified student participants. An additional aim is to broaden participation in computer science among the underrepresented students. A strong representation of U.S. junior researchers at the ICDM 2009 is useful in fostering U.S. competitiveness in this important area.","title":"III: Travel Support for US-Based Students to Attend the 2009 IEEE International Conference on Data Mining (ICDM 2009)","awardID":"0949134","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["526618",430635,"516939"],"PO":["563751"]},"153638":{"abstract":"During software maintenance, 50% to 90% of developer effort is spent on program comprehension activities, which are performed by developers to better understand source code. Reducing the effort spent by developers on these activities can reduce software maintenance costs. Researchers have developed techniques and tools to detect code clones (similar or identical segments of source code), because their presence can diminish program comprehensibility. However, knowledge only of the presence of clones does not allow a developer to perform maintenance tasks correctly and completely; proper performance of these tasks requires a thorough understanding of the relationships among the detected clones. Existing approaches for investigating these relationships are limited in their applicability and effectiveness.<br\/><br\/>The goal of this collaborative project is to develop an automated and rigorous analysis process for identifying and codifying the relationships among clones using their structural and semantic properties. To maximize the impact of the techniques and tools on the effectiveness and efficiency of performing maintenance tasks when clones are present, the investigators will perform a domain analysis. After initial development, the team will validate and refine the techniques and tools. The research will help developers to maintain software, reducing total software cost and improving overall software quality.","title":"SHF:Small:Collaborative Research: Improving Code Clone Categorization","awardID":"0915403","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[408870],"PO":["564388"]},"153539":{"abstract":"Many routine, real-world tasks can be seen as sequential decision tasks. For instance, navigating a robot through a complex environment, driving a car in congested traffic, and routing packets in a computer network requires making a sequence of decisions that together minimize time and resources used. It would be desirable to automate these tasks, yet it is difficult because the optimal decisions are generally not known. Many existing learning methods lead to reactive behaviors that perform well in short term, but do not amount to intelligent high-level behavior in the long term. <br\/><br\/>This project is developing methods for learning strategic high-level behavior. Strategic methods need to (1) retain information from past states, (2) learn multimodal behavior, (3) choose between the different behaviors based on crucial detail, and (4) implement a sequential high-level strategy based on those behaviors. The neuroevolution methods developed in prior work solve the first problem by evolving (through genetic algorithms) recurrent neural networks to represent the behavior. To solve the remaining problems, these methods are being extended in the proposed work with multi-objective optimization, local nodes with cascaded structure, and with evolution of modules and their combinations. Preliminary results indicate that this approach is indeed feasible. <br\/><br\/>In the long term, developed technology will make it possible to build robust sequential decision systems for real-world tasks. It leads to safer and more efficient vehicle, traffic, and robot control, improved process and manufacturing optimization, and more efficient computer and communication systems. It will also make the next generation of video games possible, with characters that exhibit realistic, strategic behaviors: Such technology should lead to more effective educational and training games in the future. The OpenNERO open source software platform developed in this work will be made available to the research community.","title":"RI: Small: Learning Strategic Behavior in Sequential Decision Tasks","awardID":"0915038","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[408627],"PO":["562760"]},"151009":{"abstract":"This project will develop techniques that will allow users to help each other create and maintain configurations of complex, pervasive computing and communication environments. As personal computing environments become ever more complex, growing to include not just desktop and laptop computers, but also mobile phones, media devices, sensors, and more, configuration tasks grow in importance and difficulty. In particular, it becomes challenging for end-users to create, understand, and maintain the hardware and software configurations that allow them to carry out the activities that matter to them. Moreover, this problem will only get worse with time as computing environments grow to include the hundreds or even thousands of different devices and software services that have been forecast by computer scientists. <br\/><br\/>The approach taken in this project derives from the observation that, even as each user may have specific devices, services, and preferences that make it difficult for her to find information relevant to their particular needs, there frequently exists some other user, somewhere, who has experienced and solved a similar problem. This other user's knowledge would doubtless be of great benefit to the first user, but existing tools for seeking help and modifying configurations do not make it easy for such information exchange to take place. An important goal, then, is to match each user with the knowledge she needs in order to accomplish the configuration tasks facing her, on the assumption that such knowledge resides with some other user with a similar system. <br\/><br\/>This project will address a number of challenges, including: 1) How can \"configuration knowledge\" be identified and made available without placing undue burden on the individuals who possess it? 2) How can help-seekers be presented with information in a way that allows them to act on it with minimal effort and likelihood of error? 3) How can the complexity of large spaces of possible configurations be reduced to only the dimensions that matter for users' decision-making? In order to address these challenges, this project will develop the Collaborative Configuration Service (CCS) - a general service that collects configuration information from various users of a particular system and matches similar users with each other for the purpose of providing help. Through an iterative study-build-evaluate process, research will construct and refine CCS by adapting it successively to three different user communities: users of an ambient information device (Chumby), users of an open source software-based home media system (MythTV), and people representing the \"early majority\" of home media networking users. <br\/><br\/>Supporting users to gain control and receive help with the configuration and operation of open, evolving pervasive computing environments will lower the barrier to the adoption of those environments. This will lead to benefits to both the end-users themselves and to the companies for whom an open marketplace for pervasive computing services and components will present opportunities for competition and technological innovation.","title":"HCC: Medium: Collaborative Configuration: Supporting End-User Control of Complex Computing","awardID":"0905460","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["502149","430298"],"PO":["564456"]},"163109":{"abstract":"With the globalization of the economy, business data needs to be available twenty-four hours a day, seven days a week. Furthermore, in the event of a disaster, the data must be restored as quickly as possible to minimize the business? financial loss. Since our current Internet environment is truly distributed, data are copied and revised many times. Therefore, the data or portions of the data are highly redundant. How to store, preserve and manage the enormous amount of digital data with a reasonable cost become very challenging. Data de-duplication is used to support many data driven applications in our daily life, and is widely deployed for data redundancy elimination so that the huge volumes of data can be easily managed and better preserved. However, the theoretical understanding of the problem is still largely missing. In this project, the PI plans first to investigate several fundamental issues of data de-duplication and then use these new insights to design more efficient data new algorithms for efficient data archiving and backup. The anticipated prototype system will be open source and made available to others. The proposed project will enhance the education process by bringing input from industry, developing new courses at both undergraduate and graduate levels and emphasizing the diversity of the student population. The efficiency of data de-duplication has a great impact on both long-term data preservation and ease of managing the existing huge volume of digital data. Many crucial applications from large scale simulation and modeling to electronic patient records to preserving and managing our personal data depend on both preservation and management, enhancing the impact of this work","title":"EAGER: Data Deduplication with Consideration of Data Chunk Frequency","awardID":"0960833","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543507"],"PO":["565136"]},"155629":{"abstract":"Proposal #: CNS 09-22888<br\/>PI(s): Sun, Bo<br\/> Makki, Kami; Osborne, Lawrence J.<br\/>Institution: Lamar University Beaumont<br\/> Beaumont, TX 77705-5748<br\/>Title: MRI\/Acq.: Acq. of Equipment to Develop an Energy Efficient and Reliaable Wireless Sensor Network for Urban Landscape Irrigation Management System <br\/>Project Proposed:<br\/>This project, designing and implementing an energy efficient and reliable Wireless Sensor Network (WSN) for Urban Landscape Management System (ULIMS), aims to provide significant cost-savings and alleviate urban water shortage problem by combining WSNs, data management, system integration, and web-based delivery. The constructed WSN will consist of a long-lived, real-time reliable network with remote control capability. Based on engineer portable, low-energy sensor nodes that can provide sensed data, the resulting system (W-ULIMS) addresses fundamental constraints faced by WSNs deployed in outdoor harsh environments, including energy supply, limited memory, the need for unattended operation for a long period of time, and the lossy and transient behavior of WSN communication. The project presents the following activities:<br\/>- Randomized scheduling with a connectivity guarantee,<br\/>- Extremely low duty-cycle data forwarding, and<br\/>- Remote control (using the idea of Trickle).<br\/>The randomized scheduling with connectivity guarantee and extremely low-duty cycle data forwarding protocols under study are expected to collect sensor data in an energy efficient manner. The testbed provides an infrastructure to study practical estimation, data collection and dissemination, and energy conservation faced by WSNs in harsh environments.<br\/><br\/>Broader Impacts: This project applies new technologies to traditional agricultural environments and other applications while advancing the complex behaviors of WSNs. It should contribute to alleviate the significant water shortage problem facing many cities by providing cost-savings through efficient usage of agricultural labor and timely notification of situations requiring managerial decisions. Furthermore, it establishes an environment to broaden student?s knowledge and research experience.","title":"MRI: Acquisition of Equipment to Develop an Energy Efficient and Reliable Wireless Sensor Network for Urban Landscape Irrigation Management System","awardID":"0922888","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["504575","468323",414431],"PO":["557609"]},"157719":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to develop a cyber-physical system composed of accelerometers and novel machine learning algorithms to analyze data in the context of a set of driving health care applications. The approach is to develop novel machine learning algorithms for temporal segmentation, classification, and detection of subtle elements of human motion. These techniques will allow quantification of human motion and improved full-time monitoring and assessment of medical conditions using a lightweight wearable system. The scientific contribution of this research is in advancing machine learning and human sensing in support of improved medical diagnoses and treatment monitoring by (i) modeling human activity and symptoms through sensor data analysis, (ii) integrating and fusing information from several accelerometers to monitor in real-time, (iii) validating the efficacy of the automated detection through assessments applying the state of the art in diagnostic evaluation, (iv) developing novel machine learning methods for temporal segmentation, classification, and discovery of multiple temporal patterns that discriminate between temporal signals, and (v) providing quality measures to characterize subtle human motion. These algorithms will advance machine learning in the area of unsupervised and semisupervised learning. The driving applications for this research are job coaching for people with cognitive disabilities, tele-rehabilitation for knee osteo-arthritis, assessing variability in balance and gait as an indicator of health of older adults, and measures for assessing Parkinson's patients. This research is highly interdisciplinary and will train graduate students for careers in developing technological innovations in health and monitoring systems.","title":"CPS:Medium:Collaborative Research:Monitoring Human Performance with Wearable Accelerometers","awardID":"0931595","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["438568"],"PO":["565136"]},"158819":{"abstract":"Established software approaches in mapping and matching of a large collection of multimodality cross-subject data is becoming a bottleneck for the overall work stream and hindering progress in understanding and utilization of large-scale data for scienti\u00dec discovery. In many scenarios, intrinsic geometric structures embedded in 3D imaging of real-world objects are very effective in mapping individual objects for interpretation of their similarity and disparity. But recent computational techniques are still focused on the extraction and measurement of geometric and physical properties in a single dataset. Global modeling of geometric data and assessment of patterns and relationships of related information within and across large individual datasets are under-explored. A rigorous computational framework that tightly couples geometric mapping and matching is of great importance to accomplish integrative analysis of a variety of underlying relationships in features of contained in large-scale image datasets and advance 3D imaging informatics substantially. This EAGER proposal focuses on potentially transformative research ideas and approaches in Riemannian geometry mapping and geometric diffusion, which are tightly coupled together to establish the accurate mapping and matching across a large number of subjects","title":"EAGER: Geometric Mapping and Diffusion for 3D Imaging Informatics","awardID":"0937586","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[424417],"PO":["563751"]},"146609":{"abstract":"Abstract:<br\/>PI: Ju, Tao (0846072)<br\/>CAREER: Reconstructing Geometrically and Topologically Correct Models<br\/><br\/><br\/>Bio-medical imaging and 3D scanning are widely used for acquiring realistic digital models of real-world objects, from those that are around us, like coffee mugs and statues, to those within us, like proteins and organs. In many applications, polygonal surfaces need to be reconstructed from the data captured by scanning or imaging. Besides visualization, these polygonal models have wide uses in computation and manufacturing, where geometrically and topologically correct models are required. However, as the input data is often noisy or incomplete, it is still difficult in practice to obtain correct polygonal surfaces using existing reconstruction algorithms. The reconstructed surface may exhibit geometric inconsistencies including gaps, holes and intersections, and more often, topological artifacts such as handles and disconnections. Furthermore, most reconstruction algorithms that promise geometrically correct outputs are designed for closed surfaces with well-defined inside and outside, and hence not applicable to surfaces that contain intended open boundaries or interior membranes. These more general surfaces are commonly used in CAD as well as bio-medical modeling.<br\/><br\/>This research is developing robust polygonal surface reconstruction algorithms that offer guarantees for geometric and topological correctness. To achieve this goal, an integrated framework is developed that combines and extends existing surface reconstruction and model repair algorithms to produce correct polygonal models that best represent the input data, in the form of either 3D point clouds or grayscale volumes. The research is also exploring new reconstruction and repair algorithms for open and non-manifold surfaces, thereby extending the correctness guarantees to a much larger class of models than those can be handled by existing methods.","title":"CAREER: Reconstructing Geometrically and Topologically Correct Models","awardID":"0846072","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["550459"],"PO":["532791"]},"150910":{"abstract":"Massive energy consumption is an escalating threat to the environment. Large-scale computational grids consume a substantial amount of energy, and <br\/>their energy requirements for powering and cooling are becoming comparable to the costs of acquisition. There is a lack of generally applicable methods for reducing energy consumption while ensuring good quality of service. This project will develop GridPac (Grid with Power-Aware Computing), a middleware environment that will allow grid managers and service providers to schedule multiple workflows across a distributed grid for system-wide optimization. GridPac will be based on a novel framework to support a variety of task-level workflows. The main features of this work are to develop:<br\/><br\/>(a) Novel static and dynamic algorithms for scheduling single and multiple workflows, which can be flexibly utilized by service providers in scalable grid environments.<br\/><br\/>(b) Control algorithms to account for dynamic adjustment of schedules using energy monitoring of the grid resources.<br\/><br\/>(c) Extensive benchmarking using a suite of commonly used grid workflows.<br\/><br\/>(d) A prototype middleware to assist IT organizations to better support their users while reducing energy costs.<br\/><br\/>The proposed work will lead to original scholarly contributions while harnessing the usage of computational grids. The project carries tremendous potential for economic, environmental, and societal impact. We will initiate new graduate and undergraduate level courses on related topics, and develop relevant tutorials, which will help to create awareness and educate a large audience on a critically important research topic.","title":"CSR: Medium: Collaborative Research: GridPac: A Resource Management System for Energy and Performance Optimization on Computational Grids","awardID":"0905188","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558550"],"PO":["565255"]},"161921":{"abstract":"The proposed workshop will provide a forum to stimulate creative thought and?@productive interactions among scientists whose research interests lie at the interface between two diverse and vibrant fields, Computing Science and Biology.?@?@These two scientific communities have a history of mutual influence whereby the?@transfer of ideas, approaches, and technologies has significantly advanced both?@fields. Recently, it has become apparent that a similar set of scientific questions?@are being asked by computer scientists and biologists. The identification and?@articulation of shared organizing principles is the next logical step in the ongoing?@dialogue, and a workshop that brings together leading researchers whose?@research bridges the two fields is an ideal venue to achieve these goals. The?@proposed workshop will include both informational and ?gbrainstorming?h sessions?@in which participants will discuss the current state of the art, key challenges and?@mechanisms to catalyze advances in this important emerging research area.?@?@The specific topics to be covered are (1) information representation and?@processing; (2) networks and communication; (3) system synthesis and design;?@(4) control systems; and (5) learning and adaptation.<br\/><br\/>Intellectual merit: <br\/><br\/>The proposed workshop is an outgrowth of the activities of?@the CISE-BIO Working Group, which is comprised of NSF Program Directors who?@have been meeting for over a year to discuss strategies to promote research at?@the interface between these two Directorates. Through an exploration of the?@above mentioned areas, the proposed workshop seeks to enhance existing?@programs and identify new directions, with the ultimate goal of creating an?@integrated discipline in which shared organizing principles from the Biological and?@Computing Sciences will give rise to new paradigms that are distinct from, yet?@related to, those that drive research in the parent fields.<br\/><br\/>Broader impacts: <br\/><br\/>The proposed workshop will be a true ?gmeeting of minds?h by?@virtue of bringing together a diverse group of scientists who do not normally?@attend the same conferences. In addition to developing a clearer vision for future?@research at the interface between Computing and Biological Science, it is?@expected that specific new collaborations will be forged at the workshop. The?@discussion topics, identified challenges and proposed future directions will be?@disseminated online after the workshop to enhance awareness of these initiatives?@among a broad and diverse audience. This is expected to attract students as?@well as more established scientists to undertake research at the CISE-BIO?@interface.","title":"WORKSHOP: Shared Organizing Principles in the Biological and Computing Sciences","awardID":"0954608","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1112","name":"Genetic Mechanisms"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7659","name":"ANIMAL BEHAVIOR"}}],"PIcoPI":["515695","553946","553946","451985",432877],"PO":["565223"]},"150921":{"abstract":"Assuring deadlines of embedded tasks for contemporary multicore architectures is becoming increasingly difficult. Real-time scheduling relies on task migration to exploit multicores, yet migration actually reduces timing predictability due to cache warm-up overheads and increased interconnect traffic.<br\/><br\/>This work promotes a fundamentally new approach to increase the timing predictability of multicore architectures aimed at task migration in embedded environments making three major contributions:<br\/><br\/>1. The development of novel strategies to guide migration based on cost\/benefit tradeoffs exploiting both static and dynamic analyses.<br\/><br\/>2. The devising of mechanisms to increase timing predictability under task migration providing explicit support for proactive and reactive real-time data movement across cores and their caches.<br\/><br\/>3. The promotion of rate- and bandwidth-adaptive mechanisms as well as monitoring capabilities to increase predictability under task migration.<br\/><br\/>The work aims at initiating a novel research direction investigating the benefits of interactions between hardware and software for embedded multicores with respect to timing predictability. This project fundamentally contributes to the research and educational infrastructure for the design and development of safety- and mission-critical embedded systems.","title":"CSR: Medium: Collaborative Research: Providing Predictable Timing for Task Migration in Embedded Multi-Core Environments (TiME-ME)","awardID":"0905212","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[402317],"PO":["565255"]},"150932":{"abstract":"This interdisciplinary project studies the nature of the risks inherent in normal activity on the Internet, the perception of those risks, the judgment about trade-offs in behavior and the design of a personalized agent that can alert users to risky behavior and help to protect them. The key insight is that adequate security and privacy protection requires the concerted efforts of both the computer and the user. The interdisciplinary research team combines expertise from psychology, computer security and artificial intelligence to propose MIPA (MIxed Initiative Protective Agent) -- a semi-autonomous, intelligent and personalized agent approach that leverages psychological studies of what users want\/need and what security and privacy risks are imminent. The techniques will be developed for and tested on a real problem that challenges the current state of the art in artificial intelligence, security and user models.<br\/><br\/>As it is becoming increasingly difficult for users to protect themselves and understand the risks they are taking on the Internet, this project has the potential to positively impact system design to effectively enhance user security. Focusing on home computer users (college students and senior citizens), the proposed research will investigate how they perceive, use and can best be served by Internet application software. Results could improve the experiences of these users as well as significantly advance techniques in intelligent agents and computer security. Additionally, because home users and machines tend to be the weak link in security, protecting them may better protect others.","title":"HCC: Medium: Intelligent Agents for Protecting Users in Cyberspace","awardID":"0905232","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["424402",402347,402348],"PO":["565136"]},"160733":{"abstract":"At a September, 2009 NSF-sponsored meeting in New York City, the NLP community is discussing the standardization and harmonization of the content of manual\/automatic linguistic annotation. The meeting is building on the results of the previous Computing Research Infrastructure (CRI) award \"Towards a Comprehensive Linguistic Annotation of Language\" by establishing standards that researchers and developers are likely to follow. These standards govern tokenization, part of speech, head selection and other basic components<br\/>of linguistic content that higher level annotation schema assume in common. Once standards are set, violations should be conscious (not accidental) and researchers should justify any violations. The meeting also aims to set up incentives, in the form of grants for small (e.g., student) projects, because several initial standard-compliant annotation projects could plant the seeds needed for the standards to take root.<br\/><br\/>Intellectual merit: Establishing a common base for linguistic annotation will: (1) make it easier to use, merge and compare different types of annotation (from different transducers, different manual sets of annotation, etc.); (2) make a more rigorous set of annoation standards possible; and (3) facilitate the use of sophisticated natural language informed applications that can draw on annotation created by several different projects simultaneously.<br\/><br\/>Broader impact: This standardization process will bring about greater cooperation among annotation researchers and, as a result, greatly improve the efficiency of such research. This could significantly improve the state of the art of all linguistic processing, and thus, all applications (automatic search, translation, etc.) that rely on the automatic linguistic analysis of text.","title":"Workshop Proposal: Content of Linguistic Annotation: Standards and Practices (CLASP)","awardID":"0948101","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[429881],"PO":["565215"]},"150811":{"abstract":"Solving for the structure and reactions of the atomic nucleus<br\/><br\/>The discovery of nuclear fission revealed the tremendous amount of energy that can be released when the strong bonds between the neutrons and protons forming atomic nuclei are broken. Ever since that history-making discovery, theoretical nuclear physicists have sought a detailed explanation of the properties of the atomic nucleus based on knowledge of the strong force between these constituents. When this goal is achieved, we will be able to predict reactions that take place in extreme environments ? from the interiors of stars to the core of nuclear reactors. Improving our knowledge of nuclear structure and reactions will help us economically and safely harness nuclear phenomena in support of a broad spectrum of humanitarian needs. Future nuclear science and technology advances promise a growing line of medical, industrial and energy applications. Nuclear medicine and nuclear magnetic resonance imaging provide just two prominent medical applications that rely on elementary properties of atomic nuclei.<br\/><br\/>This project aims to expand dramatically the reach as well as the impact of nuclear theory by harnessing the vast computational power of NSF's leadership class computer facilities under construction. The goal is to develop and implement a symmetry-based extension of the ab initio no-core shell model. By effectively ferreting out important interactions at the fundamental quantum level, we can achieve accurate predictions of nuclear properties based upon a deep understanding of the underlying forces. All participating particles are treated on the same footing within a matrix (?shell model?) picture of the quantum many-particle system, the nucleus. We aim to predict the structure and reactions of light-nuclei important for stellar processes and, possibly, for fusion reactors within five years. As part of this PetaApps grant, future leaders ? primarily graduate students and postdocs, will be supported to conduct this research under the guidance of senior investigators.","title":"Collaborative Research: Taming the scale explosion in nuclear structure calculations","awardID":"0904809","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7244","name":"COMPUTATIONAL PHYSICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["530803"],"PO":["564022"]},"150822":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009(Public Law 111-5). The goals of this research project are to understand how variables within social computing environments improve older adult cognition, what properties of an environment are critical, and empirically test these properties in interventions with older adults. The applied output will be design guidelines for a class of cognitive games for older adults and a new social computing environment. Two interventions will be run using video games to improve older adult cognitive and everyday abilities. The first intervention will use a commercial game (Boomblox-Wii) that contains the hypothesized variables necessary for cognitive improvement: novelty, attentional demand, and social interaction. The groups in this intervention will allow measurement of the individual and moderating effects of these variables. Pre-test and post-test ability measures will determine which variables or combinations of variables most improve the cognition and everyday functioning of older adults. The second phase is to use performance and preference data from Intervention 1 to maximally implement the variables shown to most improve cognition and functioning in a game specifically for older adults. The process of design will result in a set of guidelines for cognitive interventions to be used by other developers and researchers, ideally leading to a new class of \"brain games\" with reliable effectiveness. <br\/><br\/>These results will advance the knowledge and understanding of how cognitive training reduces age-related decline. The theory that social interaction can facilitate cognitive improvement by increasing effortful attention on a task is suggested by both behavioral and neurological evidence, but this project represents the first time these variables will be empirically tested, and the first intervention in a computing environment. Knowledge gained from this project touches the fields of cognitive aging, human-computer interaction, and social computing - all of which need data on effective cognitive training interventions. Results will aid designers who currently have little knowledge of the interface and game-play needs of older players. <br\/><br\/>This research advances the understanding of age-related change and social interaction by discovering the crucial components of successful cognitive training for older adults. Studying these components in the context of social computing and virtual worlds allows for world-wide impact and use by physically isolated individuals. A social computing environment may be used by older adults in rural communities, those separated geographically from their cohort, and those unable to leave their homes (all under-served populations). This project involves significant student involvement, providing varied mentorship opportunities to the students as well as exposure to differing methodologies. Specialized coursework will result from this project in developmental psychology, skill acquisition, and video game design.","title":"HCC: Medium: Collaborative Research: Improving Older Adult Cognition: The Unexamined Role of Games and Social Computing Environments","awardID":"0904855","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[402042],"PO":["564456"]},"160876":{"abstract":"Twitter is an electronic medium that allows a large user populace to communicate with each other simultaneously. Inherent to Twitter is an asymmetrical relationship between friends and followers thereby provides an interesting social network-like structure among the users of Twitter. Twitter messages, called tweets, are restricted to 140 characters and thus are usually very focused. Twitter is becoming the medium of choice for keeping abreast of rapidly breaking news. This project explores the use of Twitter to build a news processing system from Twitter tweets. The result is analogous to a distributed news wire service. The difference is that the identities of the contributors\/reporters are not known in advance and there may be many of them. The tweets are not sent according to a schedule. The tweets occur as news is happening and are noisy while usually arriving at a high throughput rate. <br\/><br\/>The goal of this exploratory research project is to find effective methods for making Twitter a useful news gathering mechanism. Challenges addressed in this project include: removing the noise; determining tweet clusters of interest bearing in mind that the methods must be online; and determining the relevant location associated with the tweets. <br\/><br\/>The broad impact of this research is to make it easier to disseminate late breaking news and enhancing the distributed news gathering and reporting process. Web site (http:\/\/www.cs.umd.edu\/~hjs\/hjscat.html) reports results of this and related research.","title":"III\/EAGER: TwitterStand: Separating the Wheat from the Chaff in Breaking News","awardID":"0948548","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["551003"],"PO":["563751"]},"150723":{"abstract":"As networks move outside professionally-managed environments to end-users become tasked with deploying, managing, securing, and troubleshooting their networks. Evidence shows that end-users cannot manage networks, and their rejection of these technologies represents a significant barrier to the adoption of advanced applications. This research will lower the barrier, by demonstrating how the challenges of human-network interaction must be solved with new technical approaches. Through empirical methods, we will produce datasets detailing the challenges, the needs of the users who both manage and live with such networks, and the opportunities for network design. We will develop an initial architecture that centralizes many network functions. This research will extend this architecture and deploy and evaluate it in people?s homes. The results will produce sound, generally-applicable principles for more usable network design. These principles will be particularly applicable to contexts where no formal network administrator is present.<br\/><br\/>Our work benefits society in three distinct ways. Usable home networking is on the critical path for computing research innovation. Research results will teach the next generation of engineers how to design usable networking. The integration of usability concerns into the core of computing reflects the growing diversity of careers in IT, and opens up the possibility of increasing the participation of women and minorities in computing.","title":"NetSE: Medium: Collaborative Research: Towards Human- Network Interaction (HNI) for the Home","awardID":"0904431","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["472141","450731"],"PO":["565342"]},"160546":{"abstract":"In what has become an annual event, the French Government and The National Science Foundation jointly sponsor symposia, at the French Embassy, that bring together young investigators from both countries on a topic of current importance and that involves scientific challenges. For 2009, the topic was digital identity management, an important subtopic under the Trustworthy Computing Program?s emphasis area on ?fundamentals?. In bringing together these young scientists, it is anticipated that the field will be advanced by getting researchers together on problems that benefit from consideration of culture differences between the two countries (as is the case with the study of privacy issues), <br\/><br\/>A very broad view of identity management is being considered, including biometrics and other methods for authentication, forensics to determine if after-the-fact an authentication violation took place, cryptographic and other methods to achieve anonymity, and metrics to determine the effectiveness of methods individually and in combination.<br\/><br\/>The PI created a program that consists of invited talks, talks by young investigators, talks by Government research agencies in which important research areas for both countries are declared, and panels. <br\/><br\/>The funds requested would be used to reimburse the expenses of graduate and undergraduate students. The workshop is to take place on July 7-10, 2009 in Washington, DC. <br\/><br\/>Our systems are experiencing an increasing number of attacks from all kinds of attackers: underground criminals, nation states, terrorists, etc. Knowing who is on your system is vital to discouraging attacks but also to achieve accountability in the face of an attack.","title":"TC: A U.S.-France Collaborative Symposium of Young Engineering Scientists (YESS 2009)","awardID":"0946768","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["532213"],"PO":["529429"]},"150998":{"abstract":"To survive and flourish, people must interact with their environment in an organized fashion. To do so, they need to learn, imagine, and perform an assortment of transformations on and in the world. Primary among these are manipulation of objects and navigation in space. This project integrates research in computer science and cognitive science to develop and evaluate augmented reality tools to create effective dynamic explanations that enhance manipulation and navigation, in conjunction with identification and visualization. Augmented reality refers to user interfaces in which virtual material is integrated with and overlaid on the user?s experience of the real world; for example, by using tracked head-worn and hand-held displays. Dynamic explanations are task-appropriate sequences of actions, presented interactively, with appropriate added information. The tools will be created in collaboration with subject matter experts for exploratory use in indoor and outdoor real world domains: navigating and identifying landmarks in a wooded park area, assembling a piece of furniture, and navigating and visualizing for planning the site of a new urban campus. Cognitive science research will determine the best ways to convey explanations and information to people. Computer science research will address the design and implementation of systems that embody the best candidate approaches for identifying objects and locations, specifying actions, and adding non-visible information. In situ experiments will be used to assess and refine the systems. <br\/><br\/>Manipulation, navigation, identification, and visualization are representative of important things that people do every day, ranging from fixing broken equipment to reaching a desired destination in an unfamiliar environment. The ways in which we perform these tasks could potentially be improved significantly through augmented reality systems designed using the principles to be developed by this project. Both the cognitive principles and the augmented reality tools will have broad applicability. The systems developed will inform the design of future systems that can aid the general public, for educational and recreational ends, as well as systems that can assist people with auditory, visual, or physical impairments.","title":"HCC: Medium: Collaborative Research: Generating Effective Dynamic Explanations in Augmented Reality","awardID":"0905417","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[402519],"PO":["564456"]},"153902":{"abstract":"Society is faced today with three main energy-related challenges: US dependence on foreign energy sources, world-wide dependence on non-renewable energy, and climate change induced at least in part by greenhouse-gas emissions. The computer industry also faces an energy crisis: the nation's data centers consume a gigantic amount of energy, which translates into large greenhouse gas footprints. This research explores the implications of these trends on data center design. In particular, the work considers how to optimize data center operation in the face of Kyoto-style cap-and-trade frameworks, related cap-and-pay frameworks, and unregulated scenarios where businesses optimize energy usage to save money or achieve carbon neutrality. In both cap-and-trade and cap-and-pay, caps are imposed on activities society wants to discourage. In large computer systems, excessive brown energy consumption is one activity to discourage. Through caps on brown energy, society can also promote renewable energy. <br\/>Research challenges include: (i) balancing reductions in brown energy consumption against cost, performance and service-level agreement (SLA) impact, (ii) managing energy consumption in the context of variable electricity prices; and (iii) designing multiple system layers that effectively integrate and coordinate electricity and performance management, even in the face of highly volatile request distributions and electricity\/carbon prices. This research has the potential for broad impact both on computer systems design, and more broadly on an increasingly carbon-conscious world.","title":"CSR: Small: Collaborative Research: System Support for Managing Carbon Footprints and Electricity Costs in Internet Services","awardID":"0916518","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["556616"],"PO":["565255"]},"153913":{"abstract":"The traditional goal of cryptography is to design cryptographic algorithms for well-defined tasks, such as public-key encryption. We propose to study the following conceptually intriguing question: when can we embed a cryptographic function into a function which was not designed for this purpose, say a function created by nature?<br\/><br\/>In a more abstract setting, the collection of possible concepts or ?objects? is represented by a function class {f_c}, where c is a description of the (unknown) object. We do not have control over the function class {f_c}, but rather it is given by ?nature?. We assume that an object c is chosen (by ?nature?) from a distribution which has a sufficiently large entropy. Each input x represents a different measurement, or ?query?, that can be made to the object. The goal is to design an algorithm for learning c (or a ?good approximation? of c) by making queries x and observing the answers y = f_c(x). The algorithm should have the following nontrivial hiding property. Any computationally bounded eavesdropper who only observes the sequence of queries and responses (x,y) cannot learn any ?useful information? about c.","title":"AF: Small: A Theory of Cryptography and the Physical World","awardID":"0916574","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["521734","533831"],"PO":["565157"]},"150888":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Data centers using virtual machine (VM) consolidation are taking over old computer rooms run by individual companies. However, consolidating services and resources does not consolidate security automatically. To meet the top two requirements for modern data centers, namely business continuity and information security, this research will take a systematic approach that leverages the emerging VM technologies to consolidate four areas of systems security research: redundancy, microscopic intrusion analysis and detection, automatic response, and diversity-driven protection. We will make innovative contributions on various aspects of security consolidation, including (1) An architecture and underlying techniques based on diversified replication towards defensive protection against unknown attacks; (2) Novel cross-layer and cross-VM methods for causal relation logging, event correlation, damage assessment, and forensics; (3) New intrusion detection techniques based on unique cross-VM-replica inconsistency checking techniques, and new cross-layer inconsistency checking methods; (4) A novel pipelining approach towards automated intrusion response; and (5) New techniques for on-the-fly data center intrusion confinement and recovery. <br\/><br\/>Our research will result in significant advances in helping mission\/life\/business critical applications and information systems reduce risk, increase business continuity, and deliver data assurance in the presence of severe cyber attacks. Broader impact will also result from the education, outreach, and dissemination initiatives. Educational resources from this project, including course modules and teaching laboratory designs, will be disseminated through a dedicated Website. <br\/><br\/>Key Words: self-protection; recovery; virtual machine monitor; causal relations; availability","title":"TC: Medium: Collaborative Research: Towards Self-Protecting Data Centers: A Systematic Approach","awardID":"0905131","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["277956"],"PO":["565136"]},"161789":{"abstract":"In multi-core computing, programmers must write concurrent code to obtain<br\/>performance, much harder than sequential code. Transactions are part of the<br\/>solution: they reduce concurrent reasoning to sequential reasoning. But<br\/>high-performance data structures require relaxed transactional memory<br\/>techniques like open nesting. This places a tricky correctness burden on the<br\/>programmer: identifying which operations on the data structure conflict<br\/>(cannot run in simultaneous transactions), and how to undo operations to back<br\/>out incomplete transactions.<br\/><br\/>The proposed solution is to specify what a data structure ought to do, and to<br\/>prove that the programmer's conflict and undo specifications are correct. The<br\/>project will complete a proof-of-concept tool to demonstrate the feasibility<br\/>of the approach.<br\/><br\/>The intellectual merit includes: a language for specifying data abstractions<br\/>as abstract models amenable to the proofs required; a way to describe<br\/>conflicts between operations on the data type, and undos; a tool to process<br\/>the descriptions and build proofs as satisfiability problems; and algorithms<br\/>to prove correctness of abstract locking procotols. The project will be more<br\/>successful than general program proving since it works with abstractions, not<br\/>implementations, and it deals with specific properties of interest. Future<br\/>work can address correctness of implementation.<br\/><br\/>The broader impact consists in assisting programmers in building safe<br\/>high-performance concurrent data structures for multi-core platforms. The<br\/>tools and libraries produced will be widely available. Helping solve the<br\/>multi-core software problem has huge implications for our economy and society.","title":"EAGER: Automating Correctness Proofs of Transactionalized Data Structures","awardID":"0953761","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["550864"],"PO":["565264"]},"153803":{"abstract":"Web applications contain numerous vulnerabilities that can be exploited<br\/>by attackers to gain unauthorized access to confidential information and<br\/>to manipulate sensitive data. Many of these vulnerabilities are due to<br\/>inadequate manipulation of string variables. String analysis, a technique<br\/>that captures the string values that a certain variable might hold at a<br\/>particular program point, can be used to identify such flaws. In this<br\/>project, novel and precise string analysis techniques will be developed<br\/>using an automata-based approach that represents possible values of a<br\/>string variable at a program point as an automaton. Techniques that<br\/>support path-sensitivity and that enable precise analysis of loops using<br\/>automata-based widening operations will be developed. Basic string analysis<br\/>techniques will be extended to a composite analysis where relationships among<br\/>string variables and other types of variables can be automatically discovered<br\/>and analyzed. The precision of string analysis plays a central role for<br\/>obtaining good results with static vulnerability detection tools. The<br\/>precise string analysis techniques developed in this project will enable<br\/>analysis of programs that cannot be analyzed with existing techniques. The<br\/>results of these improved string analysis techniques will lead to novel<br\/>software security solutions and detection of novel types of vulnerabilities.","title":"TC: Small:Automata Based String Analysis for Detecting Vulnerabilities in Web Applications","awardID":"0916112","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486421","535036"],"PO":["565264"]},"153924":{"abstract":"This projects investigates the external and internal factors (e.g., demographic, personal, and psychological aspects) that impact senior citizens' online privacy behavior. The multi-perspective approach to address this question consists of surveys (standardized), intensive in-person interviews, focus groups, key stroke logging and log analysis and scenario based questionnaires to understand online privacy behavior and attitude. A computational framework for online privacy protection using Bayesian Networks will be developed that includes a privacy architecture incorporating security policies, enforceable measures and a set of recommendations for proper design of privacy-enhancing technologies. This research will also explore senior citizens' perceived value of their personal information and the impact of cyber security education on online privacy behavior.<br\/><br\/>Since there is limited empirical data and research about senior citizens and online privacy, this project has the potential to significantly contribute to the design of more usable and unbiased online privacy protection technology for elderly users of the Internet. Ultimately, the wider societal importance of the proposed research is that a deeper understanding of the interaction between personal, social and institutional factors in determining senior citizens' experience with online privacy is needed to facilitate the continuing effort in enhancing online privacy assurance on the Internet.","title":"TC: Small: Online Privacy and Senior Citizens: A Socio-Technical Multi-Perspective Framework for Trustworthy Operations","awardID":"0916612","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["548305","563364","558161"],"PO":["564456"]},"153814":{"abstract":"This proposed project will develop a framework for organizing images that allows the specific types of relationships between those images to be represented, manipulated, highlighted, enhanced, and studied. The technical challenges involve building new representational and algorithmic systems to capture the major \"longitudinal categories\" that relate heterogeneous images to each other within collections. The problem of relationship between images is normally posed through registration, which is most often highly contextualized. This work will capture the steps necessary to specify registration as a metadata construction that enables a range of granularities in mapping images to each other, and heterogeneous relationship across organizational categories such as time (diachronic), multi-modal, and instances related by a semantic object. The work is highly interdisciplinary and results can be generalized to other problem sets.","title":"III: SMALL: FoLIO-Framework for Longitudinal Image-based Organization","awardID":"0916148","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["463789"],"PO":["563751"]},"153935":{"abstract":"III:Small: Inference of Causal Regulatory Relationships from Genetic <br\/>Studies<br\/><br\/>Inference of biological networks from high-throughput genomic data is a central problem in bioinformatics where many different types of methods have been proposed and applied to a wide diversity of datasets. Several recent studies have collected data which contain both genetic variation information as well as gene expression information from a set of genetically distinct strains of an organism which have several advantageous properties for inferring causal regulatory relationships between genes. A principled way of representing causal relationships is using graphical causal models and a rich theory of inference of such models from observational data and interventions has been developed. However, this theory assumes full knowledge of the joint distribution which is equivalent to having very large samples and so is only guaranteed to work asymptotically. In this proposal, the team will extend causal inference methods in several directions motivated by applications to genetic views of genomics datasets where there are relatively small samples. In particular they will apply their new methods to detecting the presence and absence of causal relationships between yeast genes. While the focus of this proposal is on applying the developed techniques to a specific problem in bioinformatics, the causal inference issues addressed in this proposal are the general issues faced when applying causal inference to finite samples. Many of the approaches developed in this proposal will be applicable to a wide range of problems. The resulting methods developed in this proposal will be made available to the scientific community through publicly available software.<br\/><br\/>The project involves the training of a graduate and undergraduate students. The collaborative nature of the project will expose the students to the medical and genetics worlds, and at the same time, it will improve their abilities to design and implement solutions to complex algorithmic and statistical problems. The research will be converted into course materials for the interdisciplinary course, Computational Genetics, which is taken by both undergrad and graduate students as well as students from the medical school.","title":"III: Small: Inference of Causal Regulatory Relationships from Genetic Studies","awardID":"0916676","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["554197"],"PO":["565136"]},"160227":{"abstract":"Computer instrumentation of living environments promises to extend the independent life span of our aging populations. This technological potential will not be realized unless people are willing to trust their lives to such support systems, as a replacement for human support. Very little is known about how and why people make these important decisions. The proposed research will study this issue using a widely adopted, computer-dependent life-saving device, the Implantable Cardiac Device (ICD). This research will provide a foundation for understanding how and why people agree to place their life in the hands of computerized equipment that they cannot fully understand or control. The study will design and validate instruments for gathering data on this decision. The study will use in-depth interviews, and survey methods, and will gather data from persons who have accepted or refused implantable defibrillators. Phase I, will be an interview study, working through cardiologists, to reach their patients. Phase II will develop, an extensible Web-based survey that can be readily adapted to other patient populations and other technologies. Both graduate and undergraduate students will be involved in the research plan. In addition, there are a number of broader impacts. First, this research will enhance our understanding of the key factors in the decision to entrust one?s life to a complex computer whose workings are not understood. It will also add to the meager collection of instruments for collecting this kind of data. Second, the information gained about the decision to accept implant will be new, and can serve as a guide in the design of patient information material. Third, the information will guide the design of patient information for ?pervasive computing home environments? and will therefore be useful to scientists and engineers as they consider what will be the most useful features of any proposed design.","title":"EAGER: Assessment of Barriers to Trusting Computer-Based Home Assistance","awardID":"0945192","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["210763",428529,428530],"PO":["565136"]},"153825":{"abstract":"Several application domains require processing of tera\/peta-bytes of data. Developing data-intensive applications with such massive datasets poses several challenges, with respect to data management, processing, and resource allocation. Furthermore, algorithms and their pertinent parameters that yield robust and near-optimal results are often determined through an iterative process for which interactive response times are essential. Thus, there is a need for being able to rapidly create scalable and parallel implementations of a variety of data analysis algorithms. <br\/><br\/>An emerging and critical area requiring large-scale data analysis is medical imaging. Complex algorithms and novel tools are required to be able to analyze such data. In the project, we consider data obtained from fMRI (functional MRI). Driven by this domain, this project focuses on how algorithm design, API design, and runtime system development can be combined to provide effective data-intensive solutions for spatio-temporal data analysis. Particularly, we target the following four questions: <br\/>1) How can we exploit the map-reduce paradigm to accelerate advances in neuroimaging and related medical fields? . <br\/>2) What are some of the challenges in using map-reduce paradigm for neuroimage analysis?<br\/>3) What alternative interface to the current map-reduce API can provide still provide ease of expression of data analysis algorithms, while enabling better performance? <br\/>4) Can we use the map-reduce and similar paradigms starting from high-level languages, such as Matlab? <br\/><br\/><br\/>This project will also make substantial contributions towards teaching, human resource development, and increasing diversity. Most of the requested funds will be used for supporting Ph.D students on this project. PI Agrawal expects to involve at least one of his three current female Ph.D students in this project. PI Machiraju also engages with several undergraduate students at the medical campus of OSU.","title":"DC: SMALL - Data-Intensive Computing Solutions for Neuroimage Analysis","awardID":"0916196","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["475211","558505"],"PO":["560586"]},"153946":{"abstract":"This project studies evolving knowledge bases, using tools from theoretical computer science. As opposed to a database containing facts that can be queried, a knowledge base contains general statements that can be used to derive further implications. Developing a knowledge base, in particular, a knowledge base containing commonsense knowledge that can be used for commonsense reasoning, is a fundamental task of artificial intelligence (AI). This task is taking on a somewhat different focus nowadays, as even partial solutions would have important applications in intelligent agent technology. One common feature of current approaches to the development of commonsense knowledge bases is the interactive acquisition of web-based user input of knowledge.<br\/><br\/>Algorithms for developing commonsense knowledge bases have to perform several different tasks, such as reasoning, revising (i.e., updating the current knowledge in the presence of new, potentially conflicting information), and learning (i.e., improving the quality of the knowledge base over the long run). This research addresses all three of these areas.<br\/><br\/>The bulk of the research uses Horn formulas as the formalism for knowledge representation. Horn formulas are an important class of logical expressions that have been studied for decades in complexity theory, logic programming, databases, and AI, with efficient algorithms for basic reasoning tasks. Evolving knowledge bases present many new problems for Horn knowledge bases. Particular problems addressed by this research, based on the challenges referred to above, include: Horn-to-Horn belief revision, learning Horn formulas in the model of learning from entailment, approximate minimization of Horn formulas, probabilistic analysis of the set of consequences of random Horn formulas and related combinatorial problems, Horn approximation of knowledge bases and complexity problems for non-classical generalizations of Horn formulas. The latter point towards extending the knowledge representation formalism to handle different aspects of commonsense reasoning.<br\/><br\/>In more general terms, the objective of the research is to develop algorithms for building knowledge bases that can evolve over time. This task is relevant for both short and long term applications. The research contains a comprehensive approach to several important areas which so far have been mostly been studied separately. In the long term, research in this area will contribute to the development of tools for building better intelligent agents possessing commonsense knowledge and capable of commonsense reasoning. Such agents will expand the scope of and improve the quality of automated services.","title":"Theoretical Foundations of Evolving Knowledge Bases","awardID":"0916708","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["528421",409637],"PO":["565251"]},"161569":{"abstract":"Microprocessors use branch predictors to predict the near-term behavior of a program so that work on future instructions may begin early, reducing the amount of time a program takes to run. Each incorrect prediction wastes time and energy. Thus, branch predictors must be highly accurate, and a small improvement in accuracy can give a large benefit for performance. Branch predictor accuracy can be significantly affected by choices made in the compiler that translates high-level programs to machine-language. However, current compilers do not take into account many of the ways in which their choices during translation may have an impact on branch prediction. In this project, technologies are developed for improving program performance and reducing energy consumption based on improved branch prediction through compiler techniques. Specifically, the impact of code placement on branch predictors is studied and new code-improving transformations are developed that improve branch predictor accuracy. The studies are carried out on real systems including Intel and AMD microprocessors. The impact of the new code-improving transformations is measured using performance monitoring software to determine the magnitude of the improvement. This work will result in improved performance and energy-efficiency for programs running on modern microprocessors.","title":"EAGER: Code-Improving Transformations for Branch Prediction","awardID":"0952604","effectiveDate":"2009-09-15","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["554979"],"PO":["565272"]},"153836":{"abstract":"This protein threading project at University of Georgia develops high throughput computer programs for accurate protein tertiary structure prediction based on a new conformational graph modeling of protein amino acid tertiary interactions. The modeling approach enables the following three novel, effective components together to achieve the project goal: (1) a very efficient sequence-structure alignment method that can incorporate sophisticated energy functions to improve fold recognition accuracy, (2) a simultaneous backbone prediction and side chain packing method to improve threading alignment accuracy, and (3) a semi-threading method to improve the accuracy of new structure prediction. This project also enriches the interdisciplinary education programs at University of Georgia, allowing computer science students to implement protein threading programs and visualization tools, and bioinformatics and biology students to develop threading methods, test data, and evaluate and disseminate results. <br\/><br\/>For further information see the project web page at <br\/>URL: http:\/\/www.uga.edu\/RNA-Informatics\/?p=projects","title":"III: Small: Accurate Protein Threading via Tree-Decomposable Graph Modeling","awardID":"0916250","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[409364],"PO":["565136"]},"162306":{"abstract":"This travel support enables U.S.-based graduate students to attend the 26th International Conference on Data Engineering (ICDE), held in Long Beach, California, USA, March 1-6, 2010 (http:\/\/www.icde2010.org\/). The ICDE conference has established itself as one of the prominent data and information engineering meetings. It addresses research issues in designing, building, managing, and evaluating advanced data-intensive systems and applications. As a leading international forum it provides for researchers, practitioners, developers, and users to present and explore cutting-edge ideas, exchange techniques, tools, and experiences and disseminate innovative, practical development experiences. The ICDE conference covers all aspects of data and information engineering that include, but are not limited to: query processing and optimization; data integration and interoperability; indexing and storage; systems and architectures; distributed, mobile and sensor databases; data and knowledge discovery; web applications; semi-structured data; social networks; privacy and security; scientific and spatio-temporal databases; etc. <br\/><br\/>The conference seeks to continuously advance the state of-the-art in data engineering and broaden its impact. This grant provides partial travel support and registration for 20 qualified U.S. based graduate student participants. The students will greatly benefit from attending this conference, as they will be able to present their work and make research collaboration connections. Work presented at ICDE gets high visibility; as the ICDE Proceedings are published by IEEE. The total number of ICDE participants in the past has been in excess of 500, with a majority of the participants from the U.S., then Europe and Asia. A strong representation of U.S.-based graduate students at ICDE is useful in maintaining U.S. competitiveness in these important research areas.","title":"III: Travel Support for U.S.-Based Graduate Students to Attend the 26th IEEE International Conference on Data Engineering (ICDE 2010)","awardID":"0956600","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543515"],"PO":["563751"]},"153605":{"abstract":"ABSTRACT<br\/>In the semiconductor industry, manufacturing yield, measured as the percentage of salable products produced, is a key metric that determines the financial success of a product line. Low yield translates into increased design cost, delayed time-to-market, and reduced productivity. When low yield occurs, tremendous engineering resources are spent to diagnose and resolve the problems. <br\/>This project proposes to develop a novel data learning framework that greatly improves the efficiency and effectiveness of the diagnosis and resolution process. The framework consists of a newly developed software infrastructure that interfaces with the existing Electronic Design Automation (EDA) and silicon test software infrastructures, through the design and silicon test data they produce. A collection of data learning software tools and methodologies that analyze said data are utilized to automatically extract knowledge for yield improvement. <br\/><br\/>The research is integrated with educational activities to develop course and tutorial materials released to the industry for broad impact, a state-of-the-art laboratory for education, and a research program to attract undergraduate and underrepresented students. The research strives to achieve a comprehensive understanding of state-of-the-art design and manufacturing practices including anticipated issues in the future, and to accomplish multidisciplinary studies merging knowledge from EDA, silicon test, data mining, and machine learning. Knowledge discovered through this research will provide the industry with a clear direction on where to invest resources to better cope with yield related issues in future ultra nanometer manufacturing technologies. The framework is designed to efficiently improve yield, which helps improve productivity in the semiconductor design industry.","title":"SHF: Small: Data Learning Framework for Diagnosis Based Yield Optimization","awardID":"0915259","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["535169"],"PO":["562984"]},"153847":{"abstract":"Lagrangian methods assume a central role in the analysis and visualization of vector fields resulting from simulation and measurement across many application domains. These methods provide key insight into vector field structures and dynamics, but are based on the expensive computation of integral curves. Applied to large-scale problems and data sets, they are burdened heavily by enormous computational cost.<br\/><br\/><br\/>To improve this situation, the problem-specific computation of integral curves employed in vector field visualization techniques is replaced by a two-stage process consisting of an adaptive pre-computation of integral curve sets and methods for interpolation within these sets, effectively transferring the vector field representation to the Lagrangian domain. Hence, the computational burden is isolated into a pre-computation stage. The obtained Lagrangian representation is stored into efficient out-of-core data structures. Integration-based visualization algorithms can leverage the resulting fast interpolation of integral curves, whose approximative characteristics are examined in detail, from this pre-computed data. This generic framework permits enhancement of existing integration-based visualization methods to become interactive and provides a basis for research into novel efficient and interactive vector field visualization for very large vector fields. Taking advantage of these properties, new visualization tools are developed to study transport processes in vector fields using Lagrangian analysis. <br\/><br\/>To increase the impact of this research and distribute it to a large community of scientists and engineers, the developed algorithms are integrated with an open-source visualization package. These new techniques are integrated into coursework and student projects that enable students to study new methods of analysis of flow computations. Information concerning these new methods are found on the project website (http:\/\/idav.ucdavis.edu\/~joy\/NSF-IIS-0916289).","title":"GV:Small: Lagrangian Visualization Methods for Very Large Time-Dependent Vector Fields","awardID":"0916289","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["451576","451577"],"PO":["563751"]},"162317":{"abstract":"Small businesses that produce innovative products are a key element for creating new job opportunities. But the current generation of high school students is poorly prepared to take advantage of these types of opportunities; the elimination of wood shop and metal shop facilities from schools, the demise of home workshops, and commercial pressures for off-shore manufacturing of low-cost consumer products have conditioned young people to believe there is no longer any need for them to know how to make things - they can just buy what they need ready-made. An unfortunate consequence is that many students have no practical grounding and appreciation for the relevance of applying science, technology, engineering, and mathematics (STEM), and little motivation to learn these topics. In prior work the PI developed the concept of a Makery, a self-contained facility that offered a selection of hand tools, manually operated machines, and modern computer numerically controlled (CNC) machines for working with wood, plastic and metal. Makery activities were designed to reinforce theoretical learning with practical skills such as visualization, computer aided design (CAD), and a variety of manual and computer based fabrication techniques. A more compact version, the Classroom Makery, enabled students to design and fabricate objects within their own classroom rather than in a large-scale workshop environment. The Makery and Classroom Makery prototypes allowed the PI to demonstrate that students who learn to use modern CNC equipment become more interested and more involved in STEM. Yet schools that are lucky enough to own expensive CNC machinery often find teachers lack the time to learn how to use and integrate it into their teaching.<br\/><br\/>The PI's goal in this exploratory research is to create and conduct an initial evaluation of a Makery Cloud in an effort to overcome space and knowledge limitations by enabling teachers, and eventually their students, to learn about and use CNC machines over the Internet. The PI will seek answers to questions such as the following. What telecommunication functions are required for providing a meaningful learning experience when teachers and students are learning to operate CNC machines remotely via the Internet? What additional physical, electronic, and software interlocks and control functions are required to cope with network latency and multiple control points, to ensure that CNC machines can be safely accessed and used when remotely controlled over the Internet? Does operating a CNC machine remotely via the Internet provide learning experiences for teachers and students that are equivalent to operating the same CNC machine directly, particularly with respect to safety and the acquisition of practical skils? To address these issues, a four-node collaborative network will be set up and operated on the Manoa campus of the University of Hawaii (the lead organization for the project), at the Connections Charter School in Hilo, at the West Hawaii Explorations Academy Public Charter School in Kona, and at the Hawaii Academy of Arts & Sciences Public Charter School in Pahoa. Project outcomes will include: Classroom Makeries will be established in Hilo and Kona; specialized skills and resources will be developed in Hilo (CNC Routing), Pahoa (CNC Turning), and Kona (CNC Milling); the existing Makery Portal will be expanded to include interactive project planning and management, resource location, instruction and production scheduling, distance learning with multiple audio and video streams, file transfers, and real-time control of CNC machines; two teachers from each school will be trained to teach project management and CNC fabrication; students will be involved as required by teachers to test remote teaching and experience-building strategies related to using Makeries to design and fabricate components for projects relevant to their class projects; exemplars of curricula and CNC projects for student and teacher training; and recommendations for setting up systems that enable students to fabricate parts for STEM-related projects by remotely controlling CNC machines over the Internet.<br\/><br\/>Broader Impacts: The Classroom Makery was designed to provide students with a practical grounding for their STEM studies by giving them basic design and fabrication capabilities within individual classrooms. The Makery Cloud extends this to enable teachers and students to fabricate objects that are too large or too complex to be done in their own Classroom Makery, by enabling them to control remotely located CNC machines. These capabilities will provide many benefits to schools, particularly those located in remote and under populated areas, including: collaborative hands-on training from highly qualified teachers and industrial trainers regardless of location; sharing of specialized knowledge and CNC machines among schools while still providing hands-on training and experience for users; access to sp","title":"EAGER: Creating and Evaluating a Makery Cloud","awardID":"0956632","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[433796,433797],"PO":["565227"]},"150459":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/><br\/><br\/>Domain specific multi-core processors (DSMPs) are aimed at high performance embedded system applications (image\/signal processing, networking, graphics, medical instrumentation, and so on). DSMPs incorporate several architectural innovations including symmetric multi-processing, block multi-threading, hardware accelerators, scratch-pad memories and support for inter-processor communication. However, there is a lack of application development tools which requires the designer to manually divide the functionality among threads and processors, and determine the data mapping on the memory elements. This low level approach to programming leads to increased design time in the best case, and poor quality designs in the worst case. Further, with increasing power densities in each successive generation of processors, it is expected that eventually performance optimization on DSMPs would have to consider power and thermal constraints. <br\/><br\/>The proposal aims to address two research issues. First is the development of system-level design techniques for programming on DSMPs. The techniques will take a streaming application description and target processor features as inputs, and automatically generate a mapping of the application on the DSMP with an objective of maximizing the performance. The second task focuses on development of power and thermal-aware design techniques for DSMPs. The power and thermal-aware design techniques will perform automated system-level application mapping on DSMP architectures under respective peak power and temperature constraints. <br\/><br\/>As DSMP architectures are aimed at embedded system applications, the research will have an impact on many interfaces of human-computer interaction. Education activities will include training of graduate students, dissemination of research outcomes, and incorporation of the results in undergraduate\/graduate coursework.","title":"System-level Design of Streaming Applications on Domain Specific Multi-core Processors","awardID":"0903513","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":[401064,401065],"PO":["366560"]},"166805":{"abstract":"The focus of this proposal is to evaluate the use of instantaneous, chip-wide global information for increasing performance and reducing power and cost in large-scale, chip multi-processors (CMPs). Using global information contradicts conventional thinking because it has been assumed that traversing the entire chip requires many clock periods. Recently developed circuits, however, enable single-cycle, chip-wide signaling, suggesting new possibilities of combining global and local information simultaneously. Further, similar ideas have not been previously implemented in large, traditional multi-chip systems because design flexibility, interconnect configurability, and transistor performance improvements exist only on chip. <br\/><br\/>Preliminary exploration has identified both the required interconnect circuits and opportunities for hardware and software to take advantage of up-to-date global information. The research plans to exploit new circuit techniques that will enable the proposed network-on-chip (NOC)with hybrid interconnect (NOCHI) architecture, which has both a data plane using conventional interconnect techniques and an ultra low-latency control plane with a global interconnect. Because NOCHI ignores established design patterns, understanding the circuit properties is essential for the architectural studies, which include: new algorithms that can better control and regulate power consumption within the network and across cores; improved interaction of the cores with the off-chip memory system to reduce demands on on-chip network resources; the ramifications of global information on cache coherence and management; and software controlled, ultra low-latency efficient synchronization for multicores.","title":"Collaborative Research: CPA-CSA: CMP Architectures with Global Communication","awardID":"1008325","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[446736],"PO":["366560"]},"153616":{"abstract":"The MCDB Database System for Managing and Modeling Uncertainty<br\/>Analysts working with large data sets often use statistical models to<br\/>``guess'' at unknown, inaccurate, or missing information associated<br\/>with the data stored in a database. For example, an analyst for a<br\/>manufacturer may wish to know, \"What would my profits have been if<br\/>I'd increased my margins by 5% last year?\" The answer to this<br\/>question depends upon the extent to which the higher prices would have<br\/>affected each customer's demand, which is undoubtedly guessed via the<br\/>application of some statistical model.<br\/><br\/>The MCDB project is concerned with the design and implementation of a<br\/>prototype database system called the \"Monte Carlo Database System,\" or<br\/>\"MCDB\" for short. MCDB allows an expert-level analyst or statistician<br\/>to attach arbitrary stochastic models to the database data in order to<br\/>\"guess\" the values for unknown or inaccurate data, such as each<br\/>customer's unseen demand function. These stochastic models reside in<br\/>the database, and are always up-to-date in the sense that they are<br\/>parameterized on the current state of the database (using each<br\/>customer's most recent purchases in the above example).<br\/><br\/>The project attacks a number of key intellectual and scientific<br\/>challenges. Most of these are related to the fact that for<br\/>performance reasons, it is not possible to materialize one thousand<br\/>stochastic instances of a one terabyte data warehouse, and query each<br\/>of them in sequence. Novel methods for avoiding such materializations<br\/>are being considered, such as skipping Monte Carlo trials that produce<br\/>data which will never be used to answer a specific query. The project<br\/>also considers statistical challenges, such as generating database<br\/>instances that fall far out in the tail of the answer distribution,<br\/>which is necessary for specific applications such as risk assessment.<br\/><br\/>Further information is available at http:\/\/mcdb.cs.rice.edu.","title":"Small: The MCDB Database System for Managing and Modeling Uncertainty","awardID":"0915315","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543599"],"PO":["563727"]},"153737":{"abstract":"Formal reasoning about concurrent programs is usually done at a<br\/>high-level with strong assumptions such as built-in thread primitives<br\/>(e.g., locks) and simplified memory models (e.g., sequential<br\/>consistency). Existing formal techniques (including Hoare logic and<br\/>type system) have consistently ignored important issues such as<br\/>relaxed memory models, hardware interrupts, implementation of<br\/>synchronization primitives, and support for software transactional<br\/>memory and privatization. This severely limits their applicability.<br\/><br\/>This research focuses on extending and adapting existing formal<br\/>techniques so that they can also support realistic low-level<br\/>concurrent programs running on modern multicore and multiprocessor<br\/>machines. The PI is developing a new operational approach for<br\/>reasoning about programs running under relaxed memory models;<br\/>designing new program logics for certifying both weak and strong<br\/>memory operations (including the memory-fence and compare-and-swap<br\/>instructions); and showing how to scale his approach to real-world<br\/>thread implementation and to machines with relaxed memory models. If<br\/>successful, this research will help improve the reliability of<br\/>concurrent software components, which form the backbone of many<br\/>critical systems in the world. It will also facilitate the<br\/>community-wide effort for finding new programming models for safe and<br\/>scalable multicore computing.","title":"TC:Small: Formal Reasoning about Concurrent Programs for Multicore and Multiprocessor Machines","awardID":"0915888","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550517"],"PO":["565264"]},"160029":{"abstract":"This proposal describes prototype development for a Virtual Solar-Terrestrial Observatory (VSTO), a shared distributed infrastructure for the solar-terrestrial physics community. The VSTO, through ontology and schema development, web portal and analysis tool provision, and data assimilation tools, will enable mining and processing of large distributed data sets in a grid environment linking together compute and storage resources at NCAR to the solar-terrestrial physics community. The targeted user field of science is solar, solar-terrestrial, and space physics (SSTSP).<br\/><br\/>Broader impact and intellectual merit extend across the main technical work areas: ontology development will allow for new integration and merging of existing semantic metadata in an interdisciplinary setting with resulting tool creation for ontologies and their upkeep; data assimilation techniques will be developed and applied by leveraging ongoing efforts at NCAR, such as the Virtual Solar Observatory; and at the system level serve as an operational prototype for a new distributed cyberinfrastructure serving a broader community dealing with space weather activities.","title":"SCI: SEI +II: Towards a Virtual Solar-Terrestrial Observatory","awardID":"0944256","effectiveDate":"2009-09-15","expirationDate":"2010-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7368","name":"SCI TESTBEDS"}}],"PIcoPI":["527613"],"PO":["558205"]},"153628":{"abstract":"As the web continues to play an increasing role in information<br\/>exchange, so too is it becoming the prevailing platform for infecting<br\/>vulnerable hosts. One commonly deployed strategy for delivering<br\/>web-malware involves the underhanded tactic of targeting browser<br\/>vulnerabilities to automatically download and run malicious software<br\/>upon visiting a website. When popular websites are exploited, the<br\/>victim base from these so-called drive-by downloads can be far greater<br\/>than other forms of exploitation because traditional defenses (e.g.,<br\/>firewalls) pose no barrier to infection. Unfortunately, with the<br\/>plethora of (insecure) web applications being deployed today, it is<br\/>likely that web servers will continue to be popular targets for<br\/>exploitation for the foreseeable future.<br\/><br\/>One of our primary goals is to take an in-depth look at the malware<br\/>serving network on the Web by building a scalable malware execution<br\/>and analysis infrastructure. Specifically, we plan to build a<br\/>resource-efficient host architecture that permits lightweight process<br\/>monitoring via tracking of interactions with the OS. An important<br\/>facet of our research direction is to explore a transactional<br\/>framework that unifies virtualization and logging to allow efficient<br\/>analysis. In this framework, the granularity of recorded transactions<br\/>is dynamically adjusted based on execution contexts, aggregating<br\/>multiple transactions to a single, summarized, transaction whenever<br\/>possible. Broader impats of this project will result from the<br\/>comprehensive analysis of the different aspects of the problem posed<br\/>by web-based malware, and the tools, methods, and analytical<br\/>techniques that will ultimately allow for large-scale malware analysis<br\/>by the security community at large.","title":"TC: Small: Collaborative Research: Scalable Malware Analysis Using Lightweight Virtualization","awardID":"0915364","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["565326"],"PO":["565327"]},"153749":{"abstract":"0915928 - NeTS: Small: Collaborative Research: Supporting unstructured peer-to-peer social networking<br\/><br\/>09\/01\/09-08\/31\/12<br\/><br\/>G. de Veciana, PI, U.T. Austin, and G. Kesidis, PI, Penn State<br\/><br\/>Award Abstract:<br\/><br\/>Peer-to-peer systems have seen continued growth, in terms of traffic volume, and as the architecture of choice to build new applications and network services ? notable benefits lie in their distributed design leading to higher reliability and flexibility. However as users\/peers increasingly become content providers, and generally conduct more of their business on the network, privacy is a critical concern.<br\/><br\/>By leveraging peers? trust relationships through referral mechanisms based on underlying reputation systems, applications that deliver a new standard of privacy are being devised. Peer-to-peer systems that dynamically adapt, in a distributed and scalable manner, based on the outcomes of peer transactions, are being modeled and analyzed. The focus is on unstructured networks where peer-membership correlations among communities of interest can be learned to improve the search performance of reputation-biased random walks and limited-scope flooding. Content-sharing applications are being designed based that leverage this framework to incentivize cooperative behavior while enabling collaborative filtering and content pushing.<br\/><br\/>Expected results include the development analysis and testing of a new framework for privacy-preserving search for large-scale, unstructured, on-line, peer-to-peer networks. Complementary incentive mechanisms resulting in improve file sharing and promoting honest referrals will be devised. The results will be disseminated through peer-reviewed venues and, where possible, industry concerns, while data and simulation tools are made available on the web.<br\/><br\/>The efforts impact will lie in contributing new ways to improve privacy and promote more honest and efficient cooperation in large-scale on-line peer-to-peer systems, for content sharing, as well as a broader set of social networking applications.","title":"NeTS: Small: Collaborative Research: Supporting unstructured peer-to-peer social networking","awardID":"0915928","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560221"],"PO":["565303"]},"153518":{"abstract":"This project studies several classes of counting problems in computational complexity theory. These counting problems are naturally defined and include such counting problems as vertex covers, graph colorings, graph matchings etc. This framework for counting problems is called Holant Problems. Graph homomorphism is a special case and they are closely related to Constrained Satisfaction Problems. One major new technique this project will bring to bear on these problems is holographic reductions and holographic algorithms.<br\/><br\/>This theory will be developed in terms of what function sets (signatures) are tractable and what lead to #P-hardness. The theory of Holant Problems will aim to prove complexity dichotomy theorems. These theorems assert for every problem in a class of problems expressible in the framework, depending on the exact signature set, either the problem is tractable in P, or the problem is #P-hard.<br\/><br\/>The goal of computational complexity theory is to gain a fundamental understanding of the nature of efficient computation. This study will sharpen the boundary of what is and what is not efficiently computable. Holographic reductions offer a novel technique. The proof techniques developed may also be broadly applicable in related areas of complexity theory.<br\/><br\/>There has been strong interest with the concept of holographic algorithms and holographic reductions (see \"American Scientist\" magazine, Jan-Feb 2008). A sharper delineation between what is efficiently computable and what is not may also have broader implications. The new holographic reductions together with interpolations are likely to bring new perspectives to computational complexity.","title":"Counting Problems and Dichotomy Theorems","awardID":"0914969","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["517847"],"PO":["565157"]},"158919":{"abstract":"A major challenge for future High End Computing (HEC) systems built using many-core chips is the storage system since the available memory and bandwidth per processor core is starting to decline at an alarming rate, with the rapid increase in the number of cores per chip. Data-intensive applications that require large data sets and\/or high input-output bandwidth will be especially vulnerable to these trends. Historically, the storage architecture of an HEC system has been constrained to a large degree by the filesystem interfaces in the underlying Operating System (OS). The specific focus of this research is on exploring a new storage model based on write-once tree structures. This research will explore three programming models for users of the storage system, all of which can inter-operate through shared persistent data: 1) a declarative programming model in which any data structure can be directly made persistent in the storage system, with no programmer intervention, 2) a strongly-typed imperative programming model in which a type system extension will be used to enforce a separation between data structures that can be directly made persistent and those that cannot, and 3) a weakly-typed runtime interface that enables low-level C programs to access the storage system.","title":"Collaborative Research: Programming Models and Storage System for High Performance Computation with Many-Core Processors","awardID":"0938018","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["557772"],"PO":["565272"]},"148909":{"abstract":"Proposal Title: Collaborative Research: II-New: OpenVMI: A Software Instrument<br\/>for Virtual Machine Introspection<br\/>Institution: Purdue University<br\/>Abstract Date: 07\/09\/09<br\/>This project develops the OpenVMI, an open-source, software-based research<br\/>instrument for virtual machine introspection (VMI). VMI is important to certain research<br\/>areas such as distributed computing, automated system management and<br\/>configuration, and computer security.<br\/>Virtualization technologies have created new momentumfor a number of research areas<br\/>such as distributed computing, automated system management and configuration, and<br\/>computer security. One basic yet powerful instrumentation function in<br\/>virtualization-based research is virtual machine introspection (VMI): observing a VM?s<br\/>semantic states and events from outside the VM. VMI is hard to implement, mainly<br\/>because of the semantic gap between the external and internal observations of the VM.<br\/>Thus a generic VMI software instrument becomes highly desirable to virtualization<br\/>researchers.<br\/>This project develops and deploys OpenVMI, an open-source, software-based research<br\/>instrument for VMI at Purdue University and North Carolina State University. OpenVMI<br\/>can be thought of as a ?fluoroscopic? instrument for VMs. Through the OpenVMI API, a<br\/>user will be able to obtain the VM?s semantic states and events in both kernel and user<br\/>spaces without modifying or instrumenting the VM.<br\/>Three research areas are identified at the PIs? institutions that will benefit from the<br\/>development and deployment of OpenVMI:<br\/>-Management of hosted virtual environments: This research involves monitoring,<br\/>provisioning and regulating autonomous virtual environments running in a shared<br\/>distributed hosting infrastructure. Open- VMI will enable non-intrusive, semantic<br\/>monitoring of VMs, which will trigger VM management operations at runtime such as<br\/>VM migration, resource adaptation and access control.<br\/>-Monitoring, detection and investigation of user-level malware: This research is<br\/>concerned with OSlevel policies and mechanisms for malware detection and<br\/>investigation. By using OpenVMI, these policies and mechanisms can be moved out of<br\/>the target VM, achieving stronger tamper-resistance without losing VM observability.<br\/>-Monitoring of OS integrity: This research addresses the integrity of the guest OS<br\/>against kernel-level attacks. It also involves detailed profiling of kernel-level attacks for<br\/>future detection and recovery. OpenVMI will provide a unique vintage point to observe<br\/>runtime state changes of kernel objects, which will help reveal details of an OS integrity<br\/>violation.<br\/>Six research projects in the above areas are designated for OpenVMI deployment.<br\/>NATIONAL SCIENCE FOUNDATION<br\/>Proposal Abstract<br\/>Proposal:0855141 PI Name:Xu, Dongyan<br\/>Printed from eJacket: 07\/25\/09 Page 1 of 1","title":"Collaborative Research: II-NEW: OpenVMI: A Software Instrument for Virtual Machine Introspection","awardID":"0855036","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["434616"],"PO":["564181"]},"150911":{"abstract":"TC: MEDIUM: COLLABORATIVE RESEARCH: TOWARDS SELF-PROTECTING DATA CENTERS: A SYSTEMATIC APPROACH<br\/><br\/>TC-0905189 Sushil Jajodia, George Mason University<br\/>TC-0905131 Peng Liu, Pennsylvania State University<br\/>TC-0905153 Meng Yu, Western Illinois University<br\/><br\/><br\/>Abstract<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). Data centers using virtual machine (VM) consolidation are taking over old computer rooms run by individual companies. However, consolidating services and resources does not consolidate security automatically. To meet the top two requirements for modern data centers, namely business continuity and information security, this research will take a systematic approach that leverages the emerging VM technologies to consolidate four areas of systems security research: redundancy, microscopic intrusion analysis and detection, automatic response, and diversity-driven protection. We will make innovative contributions on various aspects of security consolidation, including (1) An architecture and underlying techniques based on diversified replication towards defensive protection against unknown attacks; (2) Novel cross-layer and cross-VM methods for causal relation logging, event correlation, damage assessment, and forensics; (3) New intrusion detection techniques based on unique cross-VM-replica inconsistency checking techniques, and new cross-layer inconsistency checking methods; (4) A novel pipelining approach towards automated intrusion response; and (5) New techniques for on-the-fly data center intrusion confinement and recovery.<br\/><br\/>Our research will result in significant advances in helping mission\/life\/business critical applications and information systems reduce risk, increase business continuity, and deliver data assurance in the presence of severe cyber attacks. Broader impact will also result from the education, outreach, and dissemination initiatives. Educational resources from this project, including course modules and teaching laboratory designs, will be disseminated through a dedicated Website. <br\/><br\/>Key Words: self-protection; recovery; virtual machine monitor; causal relations; availability","title":"TC: Medium: Collaborative Research: Towards Self-Protecting Data Centers: A Systematic Approach","awardID":"0905189","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["540637"],"PO":["497499"]},"150933":{"abstract":"The design of computational systems that support group decisions, allocate resources to distributed tasks, or mediate social interactions is fundamentally different from the corresponding design problem serving individual or centralized users. When multiple parties, or agents, are involved, the designer's objectives are complicated by the fact that the interests of these parties are rarely, if ever, perfectly aligned. The field of mechanism design offers a theoretical framework that directly addresses the issue of incentives as it relates to the design of multiagent systems. However, this purely analytical approach carries with it inherent practical limitations. The investigators introduce a new approach, empirical mechanism design (EMD), whose premise is to extend the basic foundation of mechanism design with empirical methods such as simulation and statistical analysis. These extensions promise to dramatically expand the scope of mechanism design beyond the small-scale, stylized, or idealized domains to which it has been predominantly limited to date. <br\/><br\/>The project will investigate several concrete EMD problems, within the general theme of market design. Improved market design has significant implications for the public and private sectors. In public policy, market-based approaches are likely to play a major role in, for example, instituting measures to cope with climate change, banking reform and regulation, and adoption of new energy sources. In the commercial domain, new markets for advertising placement, computational services, and other goods will also entail significant mechanism design efforts. Regardless of the sector, design outcomes bear on important social objectives including efficiency, transparency, and stability (e.g., of financial relationships). An empirical basis for evaluating candidate mechanisms will complement existing theoretical perspectives, enriching the tools available to designers and other stakeholders.","title":"RI: Medium: Collaborative Research: Methods of Empirical Mechanism Design","awardID":"0905234","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["517963"],"PO":["565251"]},"150944":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project determines the fundamental limits of network secrecy from a network coding perspective, and then applies this theory to improve security guarantees in peer-to-peer and wireless networks. As network coding gains prominence as an important strategy for both wired and wireless networks, the project identifies both the advantages and vulnerabilities from using network coding. Subsequently, the effort develops a design methodology that exploits the advantages while carefully compensating for the vulnerabilities. <br\/><br\/>This project analyzes networks under both outsider and insider attacks. Specifically, coding mechanisms are developed to combat an external eavesdropper. Also, a combination of cryptographic and information-theoretic tools are used to combat internal modification attacks on the network. The results are then used in two case studies: eavesdropper attacks on wireless mesh networks and pollution attacks on P2P content distribution systems. <br\/><br\/>Secure network coded systems, once well understood, can greatly impact how networks are designed and deployed. Nearly every network setting (wireless, wired or heterogeneous) can benefit in terms of improved resilience (in addition to other performance benefits such as throughput) in its design. Case studies in this effort are designed to help transition the theoretical principles developed into practical algorithms. <br\/><br\/>The research team includes an industry member which will aid in transitioning our research ideas from theory to practice. The team will disseminate its findings through traditional scholarly venues, through the web and to the local community at each partner institution.","title":"NeTS: Medium: Collaborative Research: Secure Networking Using Network Coding","awardID":"0905266","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["519699"],"PO":["557315"]},"150702":{"abstract":"As networks move outside professionally-managed environments to end-users become tasked with deploying, managing, securing, and troubleshooting their networks. Evidence shows that end-users cannot manage networks, and their rejection of these technologies represents a significant barrier to the adoption of advanced applications. This research will lower the barrier, by demonstrating how the challenges of human-network interaction must be solved with new technical approaches. Through empirical methods, we will produce datasets detailing the challenges, the needs of the users who both manage and live with such networks, and the opportunities for network design. We will develop an initial architecture that centralizes many network functions. This research will extend this architecture and deploy and evaluate it in people?s homes. The results will produce sound, generally-applicable principles for more usable network design. These principles will be particularly applicable to contexts where no formal network administrator is present. <br\/><br\/>Our work benefits society in three distinct ways. Usable home networking is on the critical path for computing research innovation. Research results will teach the next generation of engineers how to design usable networking. The integration of usability concerns into the core of computing reflects the growing diversity of careers in IT, and opens up the possibility of increasing the participation of women and minorities in computing.","title":"NetSE: Medium: Collaborative Research: Towards Human-Network Interaction (HNI) for the Home","awardID":"0904350","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["483390"],"PO":["565342"]},"161614":{"abstract":"Effective dynamic memory disambiguation limits many practical approaches for code analysis, optimization, and debugging. An efficient solution to this problem could unlock additional performance and increase the reliability of computer systems.<br\/>A potential avenue for overcoming the traditional limits of hardware memory disambiguation is through the use of signature registers. Such registers can operate on hundreds of addresses simultaneously and can be exposed to software through a flexible and general interface for use in a wide variety of systems. However, because signatures represent sets of addresses imprecisely, they are prone to false positives which limit their accuracy and effectiveness.<br\/><br\/><br\/>This research investigates the effectiveness of exposing signature registers to software. Using scenarios from code analysis, optimization, and debugging as case studies, the effectiveness of signatures is compared to other hardware memory disambiguation techniques to evaluate their performance, complexity, and power costs. The hardware implementation for signature registers is investigated and refined to reduce false positives.","title":"EAGER: Software Exposed Hardware Signatures for Code Analysis, Optimization and Debugging","awardID":"0952832","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["550815"],"PO":["565272"]},"150966":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Though perhaps unfortunate, as a practical matter software is often<br\/>built with functionality as a primary goal, and security features are<br\/>only added later, often after vulnerabilities have been identified.<br\/>To reduce the cost and increase assurance in the process of security<br\/>retrofitting, the aim to develop a methodology involving automated and<br\/>semi-automated tools and techniques to add authorization policy<br\/>enforcement functionality to legacy software systems.<br\/><br\/>The main insight is that major portions of the tasks involved in<br\/>retrofitting code can be or already have been automated, so the design<br\/>process focuses on enabling further automation and aggregating these<br\/>tasks into a single, coherent approach.<br\/><br\/>More specifically, techniques and tools are being developed to: (1)<br\/>identify and label security-relevant objects and I\/O channels by<br\/>analyzing and instrumenting annotated application source code; (2)<br\/>insert code to mediate access to labeled entities; (3) abstract the<br\/>inserted checks into policy-relevant, security-sensitive operations<br\/>that are authorized (or denied) by the application's security policy;<br\/>(4) integrate the retrofitted legacy code with the site's specific<br\/>policy at deployment time to ensure, through advanced policy analysis,<br\/>that the application enforces that site's policy correctly, and (5)<br\/>verify correct enforcement of OS policy delegation by the retrofitted<br\/>application.<br\/><br\/>The techniques and tools being developed are useful not only<br\/>for retrofitting, but also for augmenting and verifying existing code<br\/>already outfitted with security functionality; hence improving the<br\/>state-of-the-art in creating more secure software.","title":"TC: Medium: Collaborative Research: Techniques to Retrofit Legacy Code with Security","awardID":"0905343","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["547471"],"PO":["565264"]},"150977":{"abstract":"The objective of this research is to create an approach to software development for critical systems where a high level of assurance is essential to prevent failures from having serious consequences. The approach being developed, Assurance Based Development (ABD), is based on two rigorous arguments that evolve throughout development. A fitness argument shows that the system has the functional, non-functional (include legal and ethical) and dependability properties necessary to satisfy all stakeholders, and a success argument shows how the development activities will yield a satisfactory system within time and budget constraints. Because these arguments capture the concerns of all stakeholders, their state at any given time reveals the obligations incident on the developers. Choosing development activities to meet these obligations facilitates early detection and avoidance of potential assurance difficulties. Choice also allows the developer to deploy expensive technology, such as formal verification, only on components whose assurance needs demand it.Evaluation and assessment of ABD is being conducted using case studies of a prototype artificial heart pump and a security-critical application.","title":"SHF: Medium: Assurance Based Development: A Rational Approach To Creating High Assurance Software","awardID":"0905375","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["417453",402466,402467],"PO":["564388"]},"150614":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>All animals rely on the integration of sensory, postural and environmental information to generate complex motor behaviors such as swimming, playing tennis or flying. This collaborative project will study how the nervous system transforms information gathered by the senses into motor commands, based on the biomechanical properties of the muscles as well as the mechanical and environmental constraints imposed on the body by the outside world through the laws of physics. A favorable model system to study these complex aspects of behavior is the generation of collision avoidance maneuvers in flying insects, as much is known about their nervous system and the aerodynamic mechanisms underlying insect flight. The three groups that will collaborate on this project are based at Baylor College of Medicine, Rice University and the University of Arizona and will bring complementary expertise in neurophysiology, advanced computer modeling techniques, and aerodynamic engineering, respectively. This work will provide a comprehensive description of in-flight collision avoidance in response to visual threats and will thus contribute to an integrated understanding of the basis of complex sensory-motor transformations underlying behavior. The new insights that will be gathered over the course of the work could be applied to the design of real-time artificial vision systems and collision avoidance systems for various vehicles. Finally, this project will contribute to research education by allowing interested students to acquire interdisciplinary laboratory experience at the graduate as well as the undergraduate level, through various summer research programs. Students involved in the project at Baylor College of Medicine will learn how to record nervous activity from the brain of behaving animals and model its impact on behavior.","title":"Collaborative Research: Integrated Analysis of In-Flight Collision Avoidance Systems","awardID":"0904065","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7713","name":"ACTIVATION"}}],"PIcoPI":["487987"],"PO":["565284"]},"162835":{"abstract":"The goal of this research aims to produce a general-purpose but domain-customizable collaborative scientific workflow tool for accelerating scientific discovery, particularly facilitating large-scale and cross-disciplinary research projects that are collaborative in nature and require intensive user interaction from multiple distributed domain scientists. As a natural extension to the existing single user-oriented scientific workflow management tools by providing direct system support for scientific collaboration, this project seeks to pave a way toward a next-generation tool supporting scientific collaboration over the Internet. The expected tool can be easily expanded to support data-centric collaborative information management in any intelligence community.<br\/><br\/> To achieve this broader impact, this research seeks to establish a set of foundational models and techniques supporting collaborative scientific workflow composition and management; and based on them, construct an Internet-based collaborative scientific workflow tool framed with an open-source initiative. The initial focus of the Early Concept Grants Exploratory Research(EAGER) project is on rapidly creating a prototype tool as a proof of concept, equipped with basic dataflow-oriented scientific workflow models and collaboration patterns integrated in an agile service-oriented architecture. To avoid reinventing the wheel, the efforts will be concentrated on transforming and extending Taverna, a known open-source scientific workflow management tool, into a collaborative version. Evaluations and validations will be conducted through partnerships with multiple collaborative scientific communities.<br\/><br\/>For further information, see the project website at http:\/\/www.CollaborativeScientificWorkflows.org\/","title":"III:EAGER:Collaborative Research:A Collaborative Scientific Workflow Composition Tool Supporting Scientific Collaboration","awardID":"0959215","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["196501"],"PO":["543481"]},"150988":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>There is a growing need for wireless networks that can sustain high data rates, are robust to interference, make efficient use of battery resources, and offer secure communications. This project introduces cooperative beamforming (CB), a novel technique that enables high throughput and power efficient communications in a secure manner. CB consists of two stages. In the first stage, the sources share their data with neighboring nodes via low-power communications. Various approaches for such information sharing are considered, with a goal to minimize queuing delays, conserve energy, and achieve high throughput. In the second stage, the cooperative nodes apply a weight to the signal received during first stage, and transmit. The weights are such that a specific objective criterion (e.g., signal to interference at the destination) is maximized. In CB, although each node uses low power, all nodes together can deliver high power to a faraway destination. This increase in power offsets power reduction due to propagation attenuation. CB can be viewed as an alternative to multihop transmission and, unlike multihop transmission, does not deplete the power resources of other nodes. Since CB can achieve long distance communication, new paths can be found to improve the overall network performance. Also, CB improves network security by avoiding eavesdroppers; unlike traditional cryptographic-based protocols that operate at higher layers and are sensitive to the broadcast nature of the transmission medium, CB improves security at the physical layer. CB will be implemented on a hardware network testbed to demonstrate how the developed techniques can revolutionize wireless communications.","title":"NeTS: Medium:Collaborative Research: Cooperative beamforming for efficient and secure wireless communication","awardID":"0905398","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560130"],"PO":["557315"]},"161878":{"abstract":"Query response time and system throughput are the most important metrics when it comes to database and file access performance. Because of data proliferation, efficient access methods and data storage techniques have become increasingly critical to maintain an acceptable query response time and system throughput. One of the common ways to reduce disk I\/Os and therefore improve query response time is database clustering, which is a process that partitions the database\/file vertically (attribute clustering) and\/or horizontally (record clustering). To take advantage of parallelism to improve system throughput, clusters can be placed on different nodes in a cluster machine. <br\/><br\/>This project develops a novel algorithm, AutoClust, for database\/file clustering that dynamically and automatically generates attribute and record clusters based on closed item sets mined from the attributes and records sets found in the queries running against the database\/files. The algorithm is capable of re-clustering the database\/file in order to continue achieving good system performance despite changes in the data and\/or query sets. The project then develops innovative ways to implement AutoClust using the cluster computing paradigm to reduce query response time and system throughput even further through parallelism and data redundancy. The algorithms are prototyped on a Dell Linux Cluster computer with 486 compute nodes available at the University of Oklahoma. For broader impacts, performance studies are conducted using not only the decision support system database benchmark (TPC-H) but also real data recorded in database and file formats collected from science and healthcare applications in collaboration with domain experts, including scientists at the Center for Analysis and Prediction of Storms (CAPS) at the University of Oklahoma. The project also makes important impacts on education as it provides training for graduate and undergraduate students working on this project in the areas of national critical needs: database and file management systems, and high-end computing and applications. The developed algorithm and prototype, real datasets and performance evaluation results are made available to the public at the Website: http:\/\/www.cs.ou.edu\/~database\/AutoClust.html.","title":"EAGER: Autonomous Data Partitioning Using Data Mining for High End Computing","awardID":"0954310","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":[432786,"562677"],"PO":["565272"]},"150867":{"abstract":"This award supports the preparation and sharing of high-resolution, high-quality, whole mouse brain neuronal and vascular data obtained from the Knife-Edge Scanning Microscope (KESM). KESM is capable of slicing and imaging whole small animal organs (such as the mouse brain) at less than 1 um resolution within 100 hours, with a resulting data size exceeding 2 TB per specimen. The amount and complexity of the KESM data necessitates innovative approaches in data organization, storage\/retrieval, and dissemination. The research team will develop an informatics framework for 3D volume data dissemination and visualization.<br\/><br\/>The KESM, developed and housed in the PI's laboratory, has been used to dissect and image two whole mouse brains so far, one stained in Golgi to reveal the neuronal morphology, and the other in India ink to show the microvascular network in fine detail. The two data sets are unique in their detail and extent compared to other currently available data sets (orders of magnitude higher resolution along one or more of the x-, y-, and z-axis, and\/or higher extent in the imaged volume). Such data enable researchers to conduct a full quantitative analysis of various morphological statistics and their variability across different brain regions and nuclei, estimate morphological parameters for computational simulation, and eventually help link structure to function.<br\/><br\/>A hybrid approach will be employed that integrates a web-based light-weight data browser and a local data viewer\/analyzer, under a multi-scale data scheme. The specific objectives of this project are as follows: (1) Standardized data sets for improved access and interoperability with other data sources, (2) Light-weight web-based volume browser with an open Application Programming Interface (API) for enhanced freedom of access and annotation, and (3) Unit volume viewer for the visualization and analysis of small unit volumes downloaded through the web-based interface.<br\/><br\/>The data and software tools, including documentation, will be released in the public domain, to build a user\/developer community that will help continued use and evolution of the framework.","title":"CRCNS data sharing: Whole Mouse Brain Neuronal Morphology and Neurovasculature Browser","awardID":"0905041","effectiveDate":"2009-09-15","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["535313","535314","535315"],"PO":["564318"]},"150999":{"abstract":"Stochastically Robust Resource Allocation for Computing<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Parallel, distributed, and Internet-based computing, communication, and information systems are heterogeneous mixtures of machines and networks. They frequently experience degraded performance due to uncertainties, such as unexpected machine failures, changes in system workload, or inaccurate estimates of system parameters. It is important for system performance to be robust against uncertainties.<br\/>What does it mean for a computer system to be ?robust?? How can robustness be described? How does one determine if a claim of robustness is true, or if a system will fail? How can one decide which of two systems is more robust? These are the types of issues we address in this project, with our team of faculty, graduate students, and undergraduate students from Colorado State University and the University of Colorado, and colleagues in industry (DigitalGlobe) and a national laboratory (NCAR, National Center for Atmospheric Research).<br\/>We are designing models, metrics, mathematical and algorithmic tools, and strategies for (1) deriving system resource management schemes that are robust, and (2) quantifying the probability of meeting performance requirements given uncertainties. We are validating our research by working with DigitalGlobe, which supplies images to Google Maps and Microsoft Virtual Earth, and NCAR, whose research activities include the prediction of severe and catastrophic weather. The robustness concepts being developed have broad applicability, and will significantly contribute to meeting national needs to build and maintain robust information technology infrastructures.","title":"CSR:Medium:Collaborative Research: Stochastically Robust Resource Allocation for Computing","awardID":"0905418","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562746"],"PO":["565255"]},"160448":{"abstract":"We propose to arrange US participation in the workshop entitled \"Intelligent Software: The Interface Between Algorithms and Machines\", to be held on October 19-21, 2009 at the University of Edinburgh, hosted by the Centre for Numerical Algorithms and Intelligent Software (NAIS)[1], that will support research in the efficient application of algorithms to next generation computer architectures. The goal of this workshop is to bring together leading US and European researchers at the interface between computational science, applied mathematics, and computer science to discuss algorithms pervasive in the scientific applications community, and their implementation and deployment for evolving target architectures. By bringing together researchers working together across this divide, a scheme will be suggested with the goal of advancing computational science infrastructure so that it can live up to its full potential.","title":"Workshop: Intelligent Software: The Interface Between Algorithms and Machines","awardID":"0946375","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["521525","521813"],"PO":["562944"]},"153914":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Cheap commercial off-the-shelf wireless devices are being increasingly deployed for performance-sensitive applications such as patient monitoring with body sensors and home networking for multimedia and gaming. However, wireless communications may interfere with each other when they use the same or adjacent radio frequencies. This becomes a growing issue as the public 2.4GHz spectrum is being populated by a variety of devices, including 802.11b\/g routers, ZigBee sensors, Bluetooth headsets, and cordless phones. Existing interference mitigation schemes are tightly tied with the physical\/MAC layers of particular platforms, and hence often cannot co-exist in the same network without sacrificing the system performance. <br\/><br\/>This project develops a Holistic Transparent Performance Assurance (HTPA) framework to support performance-sensitive applications in the crowded spectrum. HTPA consists of 1) a spectrum profiler that models the spectrum usage and dynamic external, intra- and inter-platform interferences in heterogeneous wireless environments; 2) a virtualized medium access control layer that provides unified interfaces for transparently representing, monitoring, and scheduling the underlying radio resources; and 3) a stream and system performance assurance component that schedules radio resources for each individual data stream, and harnesses network interference based on the system knowledge, MAC abstractions, and dynamic spectrum models. <br\/><br\/>HTPA enables network designers to systematically understand and mitigate the impact of complex interference that exist between heterogeneous wireless devices, and provides reference models for the standardization of future commercial wireless platforms operating in unlicensed spectrums.","title":"NeTS:Small:Collaborative Research:Holistic Transparent Performance Assurance within the Crowded Spectrum","awardID":"0916576","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["554514"],"PO":["557315"]},"150889":{"abstract":"Different Internet users often access similar content resulting in identical data repeatedly traversing the network. Several systems have attempted to eliminate this redundant data from network links to improve network performance. However, these only apply to point-deployments, i.e. to specific applications, protocols, or links. Because of this, their benefits are limited.<br\/><br\/>This project develops an Internet architecture where redundancy elimination (RE) is inherently supported by the network. This architecture subsumes localized deployments and extends the benefits of RE to all end-to-end flows. Crucially, it improves the design of applications and protocols. It frees application designers from concerns about using network resources efficiently. Network protocols can leverage inherent RE to better meet application and network constraints. This work will consider the technical, algorithmic and economic issues in this new architecture, including supporting RE in networks and end-hosts, reconfiguring applications to optimally leverage RE, and incentives for ISPs and end-hosts to deploy RE.<br\/><br\/>Intellectual merit: The new architecture will improve end-to-end performance, enhance applications and protocols, and give rise to new applications. The research will consider technical, algorithmic, and economic issues in supporting RE and leveraging it optimally. It will advance various fields of Computer Science, including network hardware, protocols and applications, algorithms, game-theory and network economics.<br\/><br\/>Broader impact: This project will have a broad impact on future applications and protocols. It will improve network management and routing. It will also impact ISP pricing. The project has a substantial educational component involving the introduction of new courses and cross-site mentoring.","title":"NetSE: Medium: Collaborative Research: Foundational Issues in Network Redundancy Elimination","awardID":"0905134","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["553786","551023"],"PO":["565090"]},"153804":{"abstract":"Answer Set Programming (ASP) is a recent form of declarative programming that has been applied to many knowledge-intensive tasks, such as product configuration, planning, diagnosis, and information integration. Like other computing paradigms, such as SAT (Satisfiability Checking) and CP (Constraint Programming), ASP provides a common basis for formalizing and solving various problems, but is distinct from others in that it focuses on knowledge representation and has proved to be useful for rapid prototyping. While the research on ASP has produced many promising results, it has also identified serious limitations.<br\/><br\/>The project aims at overcoming the limitations by merging ASP with other computing paradigms, such as satisfiability checking, first-order logic and constraint programming, and exploring the synergy between them. This project is expected to provide a transformative understanding of ASP's relation to other computing paradigms, to enhance ASP's reasoning capability and broaden the areas in which it is effective. Within knowledge representation, the study will clarify the role of ASP as a major knowledge representation formalism with effective computation methods that combines various methods available in other computing paradigms.","title":"RI: Small: Enhancing Nonmonotonic Declarative Knowledge Representation and Reasoning by Merging Answer Set Programming with Other Computing Paradigms","awardID":"0916116","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550578"],"PO":["562760"]},"153925":{"abstract":"The goal of this project is to build Commugrate, a community-driven <br\/>data integration system that capitalizes on the information gained<br\/>from the interactions of communities of humans with data sources.<br\/><br\/>Commugrate tackles key challenges raised by the increase in the<br\/>number of information sources used in science, engineering, and<br\/>industry, as well as the need for large-scale data integration<br\/>solutions to enable effective access to these sources. These challenges<br\/>include schema matching and mapping, record-linkage, and data repair.<br\/><br\/>More specifically, Commugrate (i) utilizes both direct and indirect<br\/>contributions from different types of human communities with a focus on<br\/>the latter contributions, (ii) solves key data integration issues using <br\/>new evidences like usage and behavior data which have not been previously <br\/>used, (iii) adopts a new technique for schema matching, which defines <br\/>a new class of its own, namely usage-based schema matching, <br\/>(iv) introduces the first of its genre technique for record linkage based <br\/>on entities' behavior, and (v) provides an adaptive feedback system to <br\/>improve the quality of the data by making the best use of users feedback. <br\/><br\/>Commugrate has a broad impact across multiple segments of society as data <br\/>integration is by far the most important and in the same time vexing issue <br\/>in many areas in sciences, engineering, and industry. Furthermore, <br\/>leveraging users' interactions with data sources, especially indirect <br\/>interaction, may provide several benefits and help solve many intractable <br\/>data integration tasks which cannot be done without human intervention. <br\/><br\/>PhD students will pursue research in this project. Publications, technical <br\/>reports, software and experimental data from this research will be <br\/>disseminated via the project web site at <br\/>http:\/\/www.purdue.edu\/cybercenter\/commugrate.","title":"III:Small: Commugrate -- A Community-based Data Integration System","awardID":"0916614","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["438745","486458","486459","486459"],"PO":["565136"]},"153815":{"abstract":"Cyber-violence is increasing exponentially as social networking applications such as Instant Messaging, Facebook, and MySpace are developed, deployed, and reach increasingly younger users. These young users frequently fall victim to cyber-predators and cyber-bullies. To address this ongoing concern, this research project will study of the communicative strategies employed by both aggressors and victims in cases of online predation and cyber-bullying. The primary outcome of this project is the development of theoretical communicative models and technology for the detection of online predation and cyber-bullying. In addition to flagging aggressive communication and notifying parents, the open-source software developed with these funds will suggest appropriate responses so a teen or tween can immediately defend him or herself against an aggressor. The response software will also subtly teach effective defense communication strategies that children can take into other situations (in the real or online world). Existing data resources for research in this area are scant and problematic. The data to be collected and disseminated as part of this project can be used to for future research in the development of theoretical communicative models of online predation and response, and of cyber-bullying communication and response. A data set for research in resolving multiple Internet identities will also be created and distributed. <br\/><br\/>This research project will bring together two fields, Computer Science and Media and Communication Studies, which have been dramatically impacted by the explosive growth of Internet social networking sites. The study will build upon existing web-centered technologies and tools, as well as theories of communication that were developed by close analysis of other media forms, such as television and print media. Existing machine learning algorithms will be enhanced by the development and integration of communicative theories that have been updated for online interactions. The focus on cyber-violence, especially cyber-violence directed at children, supplies a socially relevant test-bed that has suffered from neglect by researchers in Computer Science, primarily due to the lack of standard data sets. This project will provide collections of annotated data that will be used by other researchers in both fields.","title":"III: RI: Small: RUI: Tracking Predators and Bullies Via Chat Log Transcripts","awardID":"0916152","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[409309,"444168"],"PO":["499958"]},"153705":{"abstract":"As trusted computing technology, and trusted platform modules (TPMs) in particular, become widespread, it is important to build a strong foundation for applications built on this new technology. This project is a structured effort to develop a model for trusted platform applications, using a layered approach that supports rigorous analysis and security proofs, and provides a basis for modular software design that directly maps to the analytic model. Project activities are organized toward five specific objectives: development of concrete mathematical models for rigorous security analysis; analysis of specific widely-applicable functionality built on TPMs; development of a timing-accurate, extensible TPM simulator; study of TPM use in applications; and development of a layered security framework corresponding to the formal model. The project's approach is guided by two philosophies: keep it structured and simple (the principle of economy of mechanism) and justify constructions through rigorous analysis and proof.<br\/><br\/>Despite the growing use of trusted computing technology in modern systems, there has been very little formal research regarding this new technology. This project will fill this gap and provide a basis for future work in both using trusted computing technology and in designing extensions to the current technology. In addition to publications describing the knowledge gained, software for the extensible TPM simulator and the layered trusted computing framework will be distributed freely. The project will also result in the creation of a website that will be a portal for information on trusted computing and related research, and will include the development of a course on trusted computing and trusted platforms that will prepare both undergraduates and graduate students for work in this emerging area.","title":"TC: Small: Layered Modeling for Design, Analysis, and Implementation of Trusted Platform Applications","awardID":"0915735","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["552320"],"PO":["565264"]},"153947":{"abstract":"Abstract<br\/>0916713 - CIF: Small: Structured Transmission Strategies for Wireless Networks<br\/><br\/>In this project, we use lattice and other structured coding techniques to induce alignment in wireless networks. This effort uses these codes on three different fronts: a.) Interference networks, where we use structured codes to align the interference seen at each receiver. The objective is to determine the capacity of this channel to within a constant gap using these codes. b.) Cognitive networks - where we use lattice codes to mitigate the interference seen by both the licensed and the cognitive radios. We exploit code structure to both (partially) learn the interfering signal at the cognitive radio and then use this knowledge to precode\/align our interference signal. c.) Secure wireless networks: again, we utilize the structure of the codebook to determine simple transformations at the source in order to keep eavesdroppers in the network at bay. We employ these codes to detect, and depending on code structure, correct for modification attacks on the codebook.","title":"CIF: Small: Structured Transmission Strategies for Wireless Networks","awardID":"0916713","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["539208"],"PO":["564924"]},"152616":{"abstract":"This project develops a high-level notion of context that exploits the capabilities of next generation networks to enable applications that deliver better user experiences. In particular, it exploits mobile devices -- always with a user -- to capture key elements of context: the user's location and, through localization, characteristics of the user's environment. What matters for the user experience is the user's place: a location in conceptual terms such as \"at home,\" \"jogging,\" or \"grocery shopping\" -- descriptions that combine positions with activities, environmental properties, and the activities of other nearby people. Realizing this notion of place requires that information from devices and infrastructure flow in ways unanticipated in current network architectures. It presumes enabling opportunistic interactions while preserving the users' privacy and designing incentive mechanisms to promote cooperation without exploitation of any. The above architectural concerns lie far beyond traditional network topics such as routing.<br\/><br\/>This project will develop, demonstrate, and evaluate a novel network architecture that gives primacy to user experience. It will lead to theoretical advances in semantic context modeling, mobility tracking at multiple levels of abstraction, collaborative localization, and incentive mechanisms. Networked applications offering enhanced user experience will have significant payoffs for industry and the productivity and quality of life of citizens. A prototype system will implement and evaluate context-aware services in university settings with prospects of expansion to K-12 schools and public facilities.","title":"NetSE: Large: Collaborative Research: Platys: From Position to Place in Next Generation Networks","awardID":"0910868","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["450636","565158"],"PO":["565342"]},"150438":{"abstract":"The objective of this research is to overcome barriers limiting multicore processor clock frequencies and to achieve faster clock and data throughput rates with technology scaling than currently possible. The approach is to design hardware and software infrastructure into multicore processors that enables low cost comparison testing of the individual processor cores and test driven tuning of processor circuitry for high-speed core operation. <br\/><br\/>The intellectual merit of this work lies in the ability of the underlying test and adaptation algorithms to extract the maximum amount of performance from the process cores that they are capable of delivering under inter and intra die process variations and electrical field degradation. Such adaptation is achieved with limited test and diagnosis cost while allowing possible \"test escapes\" to be handled in a fail-safe manner that does not result in a system crash. The diagnostics information generated is used to tune individual processor core circuitry for speed purposes. <br\/><br\/>The broader impacts of this research include the ability to run advanced applications on multicore processors in, for example, future 4G mobile wireless systems including high definition video, interactive displays, image processing, data mining algorithms and other pervasive computing tasks that demand high processor throughput at low power for low heat dissipation and high device reliability. The project will also enable training of students and industry personnel in a new interdisciplinary field that involves fundamental concepts from electrical engineering, device physics and computer science through prototype demonstrations, seminars, workshops, cooperative research and student internships in industry.","title":"Collaborative Resarch: Targeting Multi-Core Clock Performance Gains in the Face of Extreme Process Variations","awardID":"0903454","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["550643"],"PO":["565185"]},"153716":{"abstract":"Elections are a broad model for collective decision-making. Since around 1990, worst-case hardness notions (most particularly, NP-hardness) have been widely studied as a method for protecting election systems from manipulation, bribery, and control. Such protective worst-case results have by now been obtained for many problems and many election systems.<br\/><br\/>The goal of this project is to study the ways that these protective results can be bypassed for the election manipulation, bribery, and control problems. This project will seek to transform the way security of elections is viewed: to make vividly clear by actual proofs and algorithms that worst-case protections can on important real-word systems and situations be shredded, and thus that bypass attacks are a true threat. The project will do this through exploring the extent of worst-case protections and by finding the extent to which those protections can be bypassed, via studying restrictions on and assumptions about models, domains, and distributions.<br\/><br\/>This project involves a wide range of broader impacts, including information dissemination, bringing together local researchers interested in computational social choice, training of students, and service to the community. In addition, the topic itself is of broad relevance to society. Elections are of great importance both in human settings and in a rapidly expanding range of electronic settings, and indeed the study of elections is of active interest in computer science, economics, political science, operations research, and mathematics. The core research of this project seeks to better understand when the protection offered by worst-case hardness results about election systems can be bypassed, and thus is relevant within a broad range of contexts in which elections are used for collective decision-making: from spam filtering to critical human elections to sports tournaments to multiagent systems. Showing which important, known-worst-case-safe election systems are vulnerable to bypass attacks serves the interest of the citizenry, since system designers can then avoid those systems, and in the long run more broadly secure systems can be developed.","title":"RI:HCC:Small:Preference Aggregation: Bypassing Worst-Case Protections","awardID":"0915792","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["478022"],"PO":["565251"]},"153837":{"abstract":"Software developers rely on reusing source code snippets from existing libraries or applications to develop software features on time and within budget. The reality is such that most previously implemented features are embedded in billions of lines of scattered source code. State-of-the-art code search engines provide no guarantee that retrieved code snippets implement these features. Even if relevant code fragments are located, developers face rather complex task of selecting and moving these fragments into their applications. Finally, synthesizing new functionality by composing selected code fragments requires sophisticated reasoning about the behavior of these fragments and the consequent code. The result of this process is an overwhelming complexity, a steep learning curve, and a significant cost of building customized software.<br\/><br\/>This research program proposes an integrated model for addressing fundamental problems of searching, selecting, and synthesizing (S3) source code. The S3 model relies on integrating program analysis and information retrieval to produce transformative models to automatically search, select, and synthesize relevant source code fragments. The S3 model will directly support new methodologies for software change and automated tools that assist programmers with various development, reuse and maintenance activities. Among the broader impacts the project includes collaboration with industry to transfer technology.","title":"III: Small: Collaborative Research: Creating and Evolving Software via Searching, Selecting and Synthesizing Relevant Source Code","awardID":"0916260","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["534438"],"PO":["564388"]},"153958":{"abstract":"Increasing numbers of real-world application domains are generating data that is<br\/>inherently noisy, incomplete, and probabilistic in nature. Examples of such<br\/>data include measurement data collected by sensor networks, observation data in<br\/>the context of social networks, scientific and biomedical data, and data<br\/>collected by various online cyber-sources. The data uncertainties may be a<br\/>result of the fundamental limitations of the underlying measurement<br\/>infrastructures, the inherent ambiguity in the domain, or they may be a<br\/>side-effect of the rich probabilistic modeling typically performed to extract<br\/>high-level events from sensor and cyber data. Similarly, when attempting to<br\/>integrate heterogeneous data sources (\"data integration\") or extracting<br\/>structured information from text (\"information extraction\"), the results are<br\/>approximate and uncertain at best. However, there is currently a lack of data<br\/>management tools that can reason about large volumes of uncertain data, and<br\/>hence the information about the uncertainty is often either discarded or<br\/>reasoned about only superficially.<br\/><br\/>In this project, we are building a complete probabilistic data management<br\/>system, called PrDB, that can manage, store, and process large-scale<br\/>repositories of uncertain data. PrDB unifies ideas from \"large-scale structured<br\/>graphical models\" like probabilistic relational models (PRMs), developed in the<br\/>machine learning literature, and \"probabilistic query processing\", studied in<br\/>the database literature. PrDB framework is based on the notion of \"shared<br\/>factors\", which not only allows us to express and manipulate uncertainties at<br\/>various levels of abstractions, but also supports capturing rich correlations<br\/>among the uncertain data. PrDB supports a declarative SQL-like language for<br\/>specifying uncertain data and the correlations among them. PrDB also supports<br\/>exact and approximate evaluation of a wide range of queries including inference<br\/>queries, SQL queries, and decision-support queries.<br\/><br\/>The cross-disciplinary research undertaken during this project will enable us to<br\/>simultaneously address the challenges in the areas of probabilistic databases<br\/>and machine learning, and allow us to transfer the key technologies developed<br\/>between those areas, thus advancing the research in both areas. It will enable<br\/>the development of a significant and high-impact new class of real-world<br\/>applications, in a variety of domains including health informatics, social media<br\/>management, World Wide Web, and scientific databases. The PrDB system source<br\/>code, and the datasets generated during the project, will be released using an<br\/>appropriate open source license, at the project web site:<br\/>http:\/\/www.cs.umd.edu\/db\/PrDB.html","title":"III: Small: Managing Large-scale Uncertain Data Repositories","awardID":"0916736","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["518332","550401"],"PO":["563727"]},"161218":{"abstract":"This award supports a workshop to explore the state of parallel and distributed computing education and curricula, assess national education needs in the area of parallel and distributed computing, and provide action plans and recommend mechanisms for how best to address curricular needs in short and long term. <br\/><br\/>The planning workshop and its related set of activities will draw experts from various stakeholders, and engage the parallel and distributed computing community as providers of information on the current state of practice as well as consumers and evaluator of its results. <br\/><br\/>There is an urgent need for curricular guidance on parallel and distributed computing. This need emanates both from rapid technological changes and from mass marketing of multicores and general-purpose graphics processing units. Educators struggle to determine the right balance between theory and practice, and to choose from the diverse set of models of computation, languages, software and hardware platforms, and tools. There are many stakeholders in this domain, including faculty and students, employers, researchers, authors, developers, users, and industry, all who can benefit from standards in curricula at various levels and in different courses which are impacted by parallel and distributed computing.<br\/><br\/>The goal of the workshop is to involve all stakeholder experts working together and annually\/biannually providing guidance on restructuring standard curricula across various courses and modules related to parallel and distributed computing. The community may employ these for teaching, for producing course material, textbooks and tutorials, setting standards for certifications and exams, and for creating programming environments and tools. <br\/><br\/>The workshop involves collaboration among experts from all stakeholder groups to explore the needs and current problems, assess the state of parallel processing education across curricula, and lay out long term plans for setting up mechanisms to meet new curricular challenges. Two outcomes expected are an annual curricular workshop at the IEEE International Parallel and Distributed Processing Symposium (IPDPS), the IEEE's Computer Society Technical Committee on Parallel Processing (TCPP) flagship conference (2010 being held in Atlanta in April) and formation of TCPP's Standards Committee on Curriculum.","title":"A Planning Workshop on Curriculum Standards for Parallel and Distributed Computing","awardID":"0950432","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526127"],"PO":["535244"]},"155905":{"abstract":"Proposal #: CNS 09-23518 Institution: University of Denver<br\/>PI(s): Voyles, Richard M.; Denver, CO 80208-0000 Mangharam, Rahul; Anaraki Siavash Pourkamali; Rutherford, Matthew J.; Valavanis, Kimon P.<br\/>Title: MRI\/Dev.: Heterogeneous, Autonomic Wireless Control Networks for Scalable Cyber-Physical Systems<br\/>Project Proposed:<br\/>This collaborative project, creating an instrument consisting of a new class of heterogeneous wireless sensor-actuator-controller platforms, facilitates a wide range of experimental research on Networked CyberPhysical Systems (CPS). A key aim is to arrive at standardization for hardware and software interfaces over the platform categories that will support protocols for time- and safety-critical applications. Involving four universities (U Denver, Notre Dame U., U Penn, and UT-Arlington), three categories of Networked CPS research platforms are developed across a wide range of hardware- and software-based runtime re-configuration. The goals also include developing standardized hardware and software interfaces across these platforms so that nodes may be plug-n-play, evolve parametrically and programmatically at runtime, and maintain timeliness and reliability as connected objects for control and actuation. Existing computational node prototypes from Penn and U Denver will be refined and harmonized to provide a suite of interoperable nodes. These nodes will have dual radios for the data-plane and a passive analog radio for fine-grained hardware-based global time synchronization to add determination. An Embedded Virtual Machine (EVM), a powerful distributed runtime system where virtual components and their properties are maintained across node boundaries, is introduced to maintain a set of functional invariants, such as control law and para-functional invariants such as timeliness constraints, fault tolerance and safety standard across a set of controllers given the spatio-temporal changes in the physical network. The EVM software allows tightly coupled communication and runtime control across the different hardware categories. Programming mechanisms treat the set of physical sensors, actuators, and controllers as a single virtual component and allow tasks to be assigned at runtime since the links, nodes, and topology of wireless systems are inherently unreliable. The system is expected to lower the barriers for research into reconfigurable computing across hardware, software, and virtual autonomic computing structures, heterogeneous sensor network timing, synchronization and task allocation strategies, and also serve as a springboard to applications in biomedical modeling, human surveillance and monitoring, and search and rescue robotics. Each node will interface to a suite of modular I\/O devices with attendant sensors and actuators. Recent research activity on future wireless sensor networks and applications has been limited to open-loop sensing and monitoring giving rise to predominantly event-based, asynchronous platforms and systems software. Not much research has been devoted to heterogeneous wireless sensor networks that integrate across a range of computational and communication capabilities. When networks are integrated with higher-rate sensors (e.g., video surveillance), actuators with timeliness and safety constraints (e.g., real-time control), and networks requiring significant distributed in-network processing (e.g., video analytics and autonomous systems), investigators have to go beyond the platforms for low-rate sensors and applications for which time-stamping is sufficient. Consequently, heterogeneous wireless sensor networks that integrate computational and communication capabilities are necessary.<br\/><br\/>Broader Impacts: <br\/>The project, involving four institutions, provides a range of interoperable control nodes to develop applications from the MEMS\/NEMS (Micro\/Nano ElectroMechanical Systems) scale to the macro scale, develops building blocks for wireless control networks with applications in search and rescue, industrial automation, medical devices and vehicular control. Students are involved in developing the instrumentation.","title":"MRI Development: Heterogeneous, Autonomic Wireless Control Networks for Scalable Cyber-Physical Systems","awardID":"0923518","effectiveDate":"2009-09-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["522051","554621","526208","543539","561114","534440","522052"],"PO":["557609"]},"153727":{"abstract":"The goal of this project is to make possible database searching in a privacy-constrained manner: A private database provider allows only properly authorized searches by clients, in a manner that does not reveal the search criteria yet enforces the requirement that the client learns only what is authorized by the search. The initial focus will be on techniques for the case of exact matches, later extended to the much more difficult case of approximate matching. If multiple matches are found, either all of them are returned, or a subset of the \"best\" of them, under appropriately defined notions of quality, is returned; in approximate matching there is a natural notion of quality, namely, having smaller distance to the target of the search as specified by the query. The technical challenges include verification of the validity of a search request, and then carrying out the search, in manner that enforces the search's authorized criteria without revealing them. The project holds the promise of leading to substantial improvements in the highly unsatisfactory current \"state of the practice\" for searches carried out on private and sensitive databases, that unnecessarily reveal too much information and prevent useful collaborations from taking place due to concerns over the leakage of sensitive information. The minimal-disclosure feature of the protocols will also make possible a de facto \"defense in depth\", in that a compromised server will no longer automatically imply the compromise of all the clients' interactions with that server.","title":"TC: Small: Collaborative Research: Privacy-Constrained Searching","awardID":"0915843","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[409095],"PO":["565136"]},"153848":{"abstract":"In the United States, Congress has in place a number of institutions and services to provide members and committees with up-to-date, expert knowledge. The acquisition of expert scientific testimony for congressional members and committees costs Congress over $2 billion per year. Clearly, science and technology testimony is important to legislative and policy making bodies. This project studies the quality of expert scientific testimony. The challenge we propose to address is this: Can the quality of the expert testimony of scientists, engineers, and technologists be improved through the introduction of new ideas and new technologies of peer review and peer production? In the design of the proposed system we will integrate new insights and techniques of peer-production from studies of Open Source Software development; game-based co-production of useful information by non-experts; and, an emerging subfield of knowledge management, online expertise sharing between experts and non-experts. The combination and extension of these techniques will provide new tools for exploring online, peer-production processes.<br\/><br\/>The research results will create a set of concrete tools for providing science, technology, and engineering input into legal, legislative or policy decision making processes. In terms of the possible, pedagogical impacts of the project, its budget and plan have been developed to foster collaborative working relationships between faculty, staff, graduate students, undergraduates, university and non-university based scientists and engineers from a diverse set of fields.<br\/><br\/><br\/>Information provided to or discovered by Congress has a profound effect on the legislative process. The acquisition of policy information for its members and committees costs Congress well over $2 billion per year of which about $100 million is spent on House and Senate committees. If the proposed project is successful, we will have a set of concrete, implemented proposals to show how Congress and the communities of science, technology, and engineering could be better integrated using tools and techniques of information technology. In terms of the possible, pedagogical impacts of the project, its budget and plan have been developed to foster collaborative working relationships between faculty, staff, graduate students, undergraduates, university and non-university based scientists and engineers from a diverse set of fields, in addition to, potentially, congressional staff and members of Congress.","title":"HCC: Small: \"Peer Review for Scientific Testimony.\"","awardID":"0916292","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["522609"],"PO":["564456"]},"153969":{"abstract":"Electronic System Level (ESL) designs, specified behaviorally using<br\/>high-level languages such as SystemC, raise the level of hardware<br\/>design abstraction. This approach crucially depends on behavioral<br\/>synthesis, which compiles ESL designs to Register Transfer Level (RTL)<br\/>designs. However, optimizations performed by synthesis tools make<br\/>their implementation error-prone, undermining the trustworthiness of<br\/>synthesized hardware. <br\/><br\/>This research develops a mechanized infrastructure for certifying<br\/>hardware designs generated by behavioral synthesis. It entails<br\/>developing a certified \"reference flow\" of synthesis transformations. <br\/>The reference flow is disentangled from the workings of a production<br\/>synthesis tool through new formal structure called \"clocked control<br\/>data flow graph\" (CCDFG) formalizing internal design representation. <br\/>Given an ESL design and its synthesized RTL, certification entails the<br\/>following automatic steps: (1) extracting initial CCDFG; (2) applying<br\/>certified \"primitive transformations\" from the reference flow,<br\/>following the application sequence by the synthesis tool, and (3)<br\/>checking equivalence between the transformed CCDFG and RTL. Theorem<br\/>proving is used to certify primitive transformations off-line;<br\/>equivalence checking accounts for low-level transformations and<br\/>manual tweaks. The correspondence between the transformed CCDFG and<br\/>the synthesized hardware makes equivalence checking efficient. <br\/><br\/>The project facilitates development of scalable and trustworthy<br\/>hardware: adoption of ESL approach expedites design cycle while formal<br\/>analysis guarantees trust in the synthesized hardware. The reference<br\/>flow makes explicit key design invariants implicitly assumed by<br\/>synthesis tools, facilitating development of more aggressive synthesis<br\/>tools. Finally, the tight integration of two complementary techniques<br\/>--- model checking and theorem proving --- in the certification is<br\/>applicable to other domains.","title":"TC: Small: Collaborative Research: Trustworthy Hardware from Certified Behavioral Synthesis","awardID":"0916772","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[409703,"503869","503869"],"PO":["565327"]},"153617":{"abstract":"Computing devices equipped with multiple radio interfaces and working on multiple channels are becoming predominant in wireless networks. These networks are usually Multi-Interface Multi-Channel Mobile Networks (MIMC-MANETs). However, the study of security vulnerabilities and the research of fundamental security mechanisms in channel management of MIMC-MANETs have been seriously lagging behind the rapid progress of other research. <br\/><br\/>This project studies the security of MIMC-MANETs in three aspects. <br\/><br\/>1. Investigating the unique (unknown) security vulnerabilities associated with channel management in MIMC-MANETs. <br\/><br\/>2. Developing MIMC-enabled security mechanisms. This project redefines channel conflict, reveals the fundamental causes and consequences of channel attacks, and develops novel and attack-resilient security mechanisms to secure channel management (and routing) in MIMC-MANETs. New security mechanisms utilize the capability of MIMC, and include collaborative channel monitoring, channel-utilization based channel conflict detection and resolution, logic-based attack investigation, and cross-layer security design. <br\/><br\/>3. Building MIMC security and performance evaluation toolkits: This project develops evaluation toolkits and builds experimental environments. The toolkits and experimental environments can serve as a major testbed for the whole research community to conduct future MIMC-MANET research. <br\/><br\/>This project will advance the understanding of the unique security problems in MIMC-MANETs. The developed techniques will greatly enhance the security of the MIMC network infrastructure and secure the mission critical applications built atop such networks. Broader impacts will result from the education, outreach, and dissemination initiatives. Educational resources from this project, including course modules and teaching laboratory designs, will be disseminated through a dedicated Website.","title":"NeTS: Small: Collaborative Research:Secure and Resilient Channel Allocation in Multi-Radio Wireless Networks","awardID":"0915318","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["543570"],"PO":["557315"]},"152528":{"abstract":"Research in machine translation of human languages has made substantial progress recently, and surface patterns gleaned automatically from online bilingual texts work remarkably well for some language pairs. However, for many language pairs, the output of even the best systems is garbled, ungrammatical, and difficult to interpret. Chinese-to-English systems need particular improvement, despite the importance of this language pair, while English-to-Chinese translation, equally important for communication between individuals, is rarely studied. This project develops methods for automatically learning correspondences between Chinese and English at a semantic rather than surface level, allowing machine translation to benefit from recent work in semantic analysis of text and natural language <br\/>generation. One part of this work determines what types of semantic <br\/>analysis of source language sentences can best inform a translation system, focusing on analyzing dropped arguments, co-reference links, and discourse relations between clauses. These linguistic phenomena must generally be made more explicit when translating from Chinese to English. A second part of the work integrates natural language generation into statistical machine translation, leveraging generation technology to determine sentence boundaries, ordering of constituents, and production of function words that translation systems tend to get wrong. A third part develops and compares algorithms for training and decoding machine translation models defined on semantic representations. All of this research exploits newly-developed linguistic resources for semantic analysis of both Chinese and English. <br\/><br\/>The ultimate benefits of improved machine translation technology are easier access to information and easier communication between individuals. This in turn leads to increased opportunities for trade, as well as better understanding between cultures. This project's systems for both Chinese-to-English and English-to-Chinese are developed with the expectation that the approaches will be applied to other language pairs in the future.","title":"RI: Large:Collaborative Research: Richer Representations for Machine Translation","awardID":"0910611","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["518197"],"PO":["565215"]},"153629":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>A recently developed technology, called opportunistic coding, can greatly improve the e\u00b1ciency of wireless networks. However, the problems of cooperation and security in opportunistic-coding-based (OCB) wireless networks have not received su\u00b1cient attention. Here cooperation problems<br\/>are the problems introduced by the existence of sel\u00afsh nodes in the wireless networks, while security problems are the problems introduced by the existence of adversarial nodes. This work is to design and implement solutions that can provide cooperation and security guarantees for OCB wireless networks. The research work can be divided into studied of three problem areas, namely the cooperation problems, the security problems, and the interplays of<br\/>cooperation and security. The work also includes the dissemination of related knowledge to students at various levels.<br\/><br\/>Intellectual Merit: The results of this work will signi\u00afcantly improve OCB wireless networks in terms of cooperation and security. Furthermore, these results will also have broader theoretical interests, because a part of the techniques to be developed will be applicable to economic incentives<br\/>problems in other settings as well.<br\/><br\/>Broader Impacts: First, the developed technical solutions will bene\u00aft the society because they make it possible to widely deploy OCB wireless networks to environments with sel\u00afsh or adversarial nodes. Second, the educational component of this work will build capacity in cooperation and security at various levels.","title":"NetSE: Small: Cooperation and Security for Opportunistic-Coding-based Wireless Networks","awardID":"0915374","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["536356"],"PO":["564924"]},"153409":{"abstract":"Intermittently-Connected Mobile Ad-hoc Networks (ICMANET) are one of the new areas in the field of wireless communication. Networks under this class are potentially deployed in challenged environments using isolated mobile devices with limited resources. They are emerging as a promising technology in applications such as in wildlife management, military surveillance, underwater networks, and vehicular networks. Recent focus on these networks has naturally generated efforts to analytically understand them. In contrast to conventional Mobile Ad-hoc Networks (MANETs), links on an end-to-end path in ICMANETs do not exist contemporaneously. This compounds the analysis of such networks. The research provides one of the first steps for performance modeling of ICMANETs. This is very crucial in the design of practical schemes targeted to offer good performance across different mobility scenarios.<br\/><br\/>Most current analytical research employs simple mobility models such as the Poisson-contact model, which are unrealistic. Departing heavily from this trend, the investigator has developed performance analysis under the very general class of stationary mobility models. This paves the way to analytically understand the effect of mobility parameters on performance. In particular, the research answers questions of the following nature: What parameters of the mobility model affect ICMANETs performance? How does one extract the necessary information? The research objective is to develop novel approaches in performance modeling of ICMANETs, drawing out key ideas from Markov-chain- and queuing- theory. The research attempts to arrive at a novel framework which is capable of capturing key network characteristics under practical constraints such as finite bandwidth, random contact durations, and finite node buffers. Key performance measures such as throughput will be explored for various communication scenarios, routing protocols, network coding and buffer management schemes.","title":"CIF: Small: An Analytical Framework for Comprehensive Study of Intermittently-Connected Mobile Ad-Hoc Networks","awardID":"0914630","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["485126"],"PO":["564924"]},"150901":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Traffic measurement is central to network operation, management, and security. Yet, support for measurement was not an integral part of the original Internet architecture. This project aims to develop a programmable measurement architecture that is versatile enough to support current and future measurement needs, adaptable to dynamic network conditions, modular\/lightweight, and scalable to high link speeds. <br\/><br\/>This project proposes a new flow abstraction module and query language that can specify arbitrary traffic sub-populations for statistics collection. Efficient data structures to encode these queries will be developed. The team also strives to identify a core set of data streaming and sampling primitives that can be composed together to satisfy most of the queries. Efficient hardware implementation for these core set of primitives will constitute the basic measurement modules that can be easily reconfigured to measure traffic at different desired granularity. Measurement application case studies will be carried out to evaluate and showcase the capabilities of the proposed approach. <br\/><br\/>This project has great potential in guiding the design of a clean-slate measurement instrumentation for future Internet. It will provide both graduate and undergraduate students with training that span multiple disciplines, from fundamental statistical theory, algorithm design, to hardware implementation. The results (including the query language and underlying data structures, sampling\/streaming algorithms, and hardware building blocks) will be broadly disseminated through publications, invited talks\/tutorials, and open-sourcing software distribution.","title":"NeTS: Medium:Collaborative Research: Towards Versatile and Programmable Measurement Architecture for Future Networks","awardID":"0905169","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["349186"],"PO":["565303"]},"160955":{"abstract":"Personified technologies are designed to communicate information and interact with people using a repertoire of highly social behaviors and human-like personality traits. Although interactions with personified technologies are increasingly common in children's everyday experience, little is known about the implications of such interactions for children?s social and moral development. In this exploratory project the PI's goal is to seek rigorous empirical evidence to support the design of personified technologies for children, by investigating the influence of social features of the technology (e.g., apparent race) on children's construction of social and moral concepts. Children's experiences in interacting with technologies appear to extend beyond a simple notion of tool use, to include emotional connection, social support, and moral judgments which suggest a highly complex and interactive phenomenon. This research will take first steps toward the development of a guiding framework that is intended to better account for children's multifaceted relationships with technology and, in so doing, will provide insight into implications for design. Though such approaches are common in the social sciences, few attempts have been made to develop useful, empirically-informed theoretical frames to guide the design of (children's) technology. Project outcomes will include examples of personified technologies that support children's social and moral development, robust design recommendations that can inform the long-term development of technologies for adults and children alike, and increased interdisciplinary knowledge about children's social and moral conceptions of technology.<br\/><br\/>Broader Impacts: Children navigate a complex world of social entities, natural phenomena, constructed artifacts, and information systems. What are the potential consequences of frequent interaction with embodied, socially intelligent, autonomous entities that exhibit characteristics such as biological motion, social grace, communicative ability, and apparent intentionality? Will children begin to conceptualize these technologies as entities that have moral standing in the world? Does the ability of the technology to recognize and respond to morally-charged contexts of interaction lead to specific types of social and moral attributions? This project will provide first answers to questions such as these. Research outcomes and the design recommendations that result from this work will impact the design of personified technologies for children in diverse application domains such as education, entertainment, therapy, and caretaking. The PI will disseminate project outcomes to the scholarly and technology design communities, and will work with game designers in industry to apply the findings directly to off-the-shelf market products.","title":"EAGER: Designing Personified Technologies to Account for Children's Social and Moral Development","awardID":"0948901","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["503742",430449],"PO":["565227"]},"160966":{"abstract":"This is funding to support attendance by approximately 12 graduate students in a Doctoral Spotlight (workshop) to be held in conjunction with the 2009 International Conference on Multimodal Interfaces\/Machine Learning for Multimodal Interfaces (ICMI-MLMI 2009), which will take place November 2-6 in Cambridge, Mass., and is organized by the Association for Computing Machinery (ACM) with co-sponsorship from the Institute of Electrical and Electronics Engineers (IEEE). This year the Eleventh International Conference on Multimodal Interfaces (ICMI 2009) will merge with the Workshop on Machine Learning for Multimodal Interfaces; the combined ICMI-MLMI will be the premier event representing the growing interest in next-generation perceptive, adaptive and multimodal user interfaces. Such interfaces represent an emerging interdisciplinary research direction, involving spoken and natural language understanding, image processing, computer vision, pattern recognition, experimental psychology, etc. They aim to promote efficient and natural interaction and communication between computers and human users, and represent a radical departure from previous computing that should ultimately enable users to interact with computers using everyday skills. The main goals of ICMI-MLMI 2009 are to further scientific research within the broad field of multimodal interaction and systems, to focus on major trends and challenges, and to help identify a roadmap for future research and commercial success. Topics of interest this year include: multimodal and multimedia processing; multimodal input and output interfaces; multimodal applications; human interaction analysis and modeling; and multimodal data, evaluation, and standards. The 3-day main event on the MIT campus, to be followed by 5 affiliated workshops, will bring together researchers from academia and industry from around the world to present and discuss the latest multi-disciplinary work in the field. The invited talks, panels, and single-track oral and poster presentations will facilitate interaction and discussion among researchers; the conference promises to be an international venue for brainstorming and coming up with creative directions for future research in multimodal interfaces. Participants in the Doctoral Spotlight will get to showcase their ongoing thesis work, either orally or via posters, in a special \"spotlight session\" during which they will receive feedback from an invited committee composed of senior personnel, and including the Advisory Committee chair and the General and Program chairs. As a further incentive for high-quality student participation, ICMI-MLMI will be awarding outstanding paper awards, with a special category just for student papers. More information about ICMI-MLMI is available online at http:\/\/icmi2009.acm.org.<br\/><br\/>Broader Impacts: The Doctoral Spotlight will give student participants exposure to their new research community, both by presenting their own work and by observing and interacting with established professionals in the field. It will encourage students at this critical time in their careers to begin building a social support network of peers and mentors. Student participants will be selected by the PI with oversight from the Advisory Committee chair and the Conference General chair, with the goal of increasing breadth of participation; to this end, priority will be given to students whose advisors or departments have insufficient funds to otherwise support their participation. Students funded under this award will predominantly be U.S. residents enrolled at U.S. institutions of higher education.","title":"Support for Student Participation in the International Conference on Multimodal Interfaces \/ Machine Learning for Multimodal Interfaces '09","awardID":"0948946","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["457546"],"PO":["565227"]},"150945":{"abstract":"Cooperative networking exploits the broadcast nature of the wireless channel by effectively pooling the overheard information, which is traditionally treated as harmful interference. While there is a mature suite of tools at the physical (PHY) layer to harvest cooperative gains, it is still unclear how these tools can be employed to deliver significant network capacity gains. The goal of this project is to design and implement cross-layer mechanisms for cooperative networking. By integrating PHY layer cooperation with Medium Access Control (MAC) and application layers, the project will provide higher network capacity and improved multimedia quality. <br\/><br\/>The project has two interrelated components investigating basic architectures for next generation cooperative networks: (i) Cooperative data transmission, which focuses on a robust cooperative MAC-PHY incorporating multiple relays under mobility and loose requirements on synchronization and network topology. (ii) Cooperative video transmission, which exploits the synergy between cooperation and layered compression in providing unequal error protection, as well as differential quality in multicast. <br\/><br\/>Apart from potential impacts on the theory and practice of new wireless technologies, this project will train undergraduate and graduate students in all aspects of wireless communications. The impact on industry will be facilitated by the close relationship of NYU-Poly with WICAT member companies. <br\/><br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).","title":"NeTS: Medium: Collaborative Research: Unlocking Capacity for Wireless Access Networks through Robust Cooperative Cross-Layer Design","awardID":"0905267","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550699"],"PO":["557315"]},"161835":{"abstract":"This research explores the concept of grounded imagination where creativity is grounded in knowledge and informed by experience. How might one nurture and cultivate such grounded imagination in K-12 students? To address this question, this project will develop and deploy a storytelling system for authoring and interacting with hyper-dramas. It incorporates the theory advanced by Lev Vygotsky, that creativity involves a process of combinatory imagination by which an individual creates new things for herself from elements of prior experience encoded in everyday concepts and new culturally transmitted information. This situates creativity within two developmental streams: intellectual development (acquiring grounding in the form of knowledge and experience), and the process of flexible re-combination. The aspect of social-cultural engagement suggests that creativity is a discourse with the larger culture and society. Drawing from this theoretical foundation, this project explores whether the creativity trough (decline in creativity from the 4th grade through middle school) may occur because social-cultural awareness precedes intellectual development so that the student judges herself an inadequate contributor. Facilitating hyper-drama authoring will allow students to draw on their experience in hyper-media and dramatic presentation, and thus nurture the combinatory creativity process.<br\/><br\/>In this research, students will construct non-linear hyper-narratives in which each path through the narrative tree represents an individual narrative arc. Each node represents an occurrence along the narrative timeline, called a story fragment, that may happen in one or more places. The occurrence in each place takes the form of an animated dramatic scene. Storytelling, then, becomes a process of authoring the story along with the hyper-narrative, and the content and goings on within each scene (including the characters, activities, animation, scenes, and dialogue). This project will test the system and address two scientific questions by deploying different versions of the authoring system in classes at the elementary, middle, and high school levels within the Roanoke County School District. The complexity of stories constructed and the kinds of content will be graduated to match the learning goals within each level. This research will follow cohorts of these students over a period of two years as they transition between elementary, middle, and high school. Two key questions are: 1. How does a situated process of storytelling employing a hyperdrama model support creative imagination? 2. How does one engage a generation of students in a media-saturated world to become creative participants, rather than passive consumers of digital media? <br\/><br\/>The immediate research aim, to enhance and nurture creative processes in K-12 students, has significant implications for society. A more innovative workforce is critical to the success both of the nation and of the individual worker. Furthermore, creativity is necessary for all learning, including mathematics and science. By addressing the fundamental process of creativity, this project can positively impact learning of all domains including STEM. More directly, the explicit construction of hyper-narratives, and the assembly of resources (graphics, animation, characters, etc.) for each hyper-drama node make explicit the algorithmic and flow-of-control mechanisms necessary for mathematics, science, and engineering. Second, the will develop interest in scientific research among elementary, middle, and high school students. Third, the software and intellectual product of this research will be disseminated broadly through publications and open source mechanisms.","title":"EAGER: Creative IT: Hyper Drama Storytelling: Engaging and Nurturing Creativity in K-12 Students","awardID":"0954048","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["486496","543501"],"PO":["564456"]},"150835":{"abstract":"TC: Medium: Collaborative Research: Novel Forensic Analysis for Crimes Involving Mobile Systems<br\/><br\/>Abstract:<br\/><br\/>Our project will significantly advance forensic methods of investigating mobile devices used for trafficking in digital contraband. While current methods and legislation focus heavily on logical identifiers, we will design, evaluate, and deploy new forensic techniques that focus on consistent and trackable characteristics of mobile computing. Additionally, our work will play an important role in understanding the limits of personal privacy in these settings.<br\/><br\/>We will develop new radio fingerprinting techniques that detect identifying information present in a radio's low-level components. We seek the comprehensive understanding available from an accurate model of these processes so that we can both determine the key causes of anonymity loss and investigate new countermeasures.<br\/><br\/>We will develop novel techniques of traffic analysis that determine the source of encrypted Web traffic. Our focus will be on real-world traffic scenarios, where background traffic is present and the entire Internet is a potential source.<br\/><br\/>We will empirically evaluate our methods in a real-world setting by using two large, outdoor and indoor wireless testbeds that we have deployed.<br\/><br\/>Our research will directly assist law enforcement that investigate network trafficking of images of child sexual exploitation, demonstrating the usability of trustworthy computing. We will disseminate our results to the Internet Crimes Against Children Task Force and the Massachusetts State Police. Additionally, this project will define research pathways to allow students who complete their BS and MS degrees at John Jay (a minority-serving institution) to continue their PhD work at UMass Amherst.","title":"TC: Medium: Collaborative Research: Novel Forensic Analysis for Crimes Involving Mobile Systems","awardID":"0904901","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[402073],"PO":["565136"]},"150978":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The project develops cryptographic protocol reasoning techniques<br\/>that take into account algebraic properties of cryptosystems.<br\/>Traditionally, formal methods for cryptographic protocol<br\/>verification view cryptographic operations as a black box,<br\/>ignoring the properties of cryptographic algorithms that can be<br\/>exploited to design attacks. The proposed research uses a novel<br\/>approach based on equational unification to build new more<br\/>expressive and efficient search algorithms for algebraic theories<br\/>relevant to cryptographic protocols. Equational unification gives<br\/>a compact representation of all circumstances under which two<br\/>different terms correspond to the same behavior. The algorithms<br\/>are implemented and integrated into Maude-NPA, a system that has<br\/>been successful in symbolic protocol analysis. It is demonstrated<br\/>that Maude-NPA when enriched with such powerful unification<br\/>algorithms can analyze protocols and ensure their reliability,<br\/>which could not be done otherwise.<br\/><br\/>Improved techniques for analyzing security are helpful both in<br\/>assuring that systems are free of bugs, and in speeding up the<br\/>acceptance of new systems based on the confidence gained by a<br\/>formal analysis. This research will lead to the design and<br\/>implementation of next generation tools for protocol analysis.<br\/>Algorithms developed will be made available to researchers as a<br\/>library suitable for use with protocol analysis tools. Tools from<br\/>the project will help students understand concepts relevant to<br\/>protocol design and get hands-on experience. Equational<br\/>unification for algebraic theories is not only useful for<br\/>protocol analysis, but also for program analysis in general, thus<br\/>making the results of this project to be widely relevant.","title":"TC: Medium: Collaborative Research: Unification Laboratory: Increasing the Power of Cryptographic Protocol Analysis Tools","awardID":"0905378","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[402469],"PO":["565264"]},"150989":{"abstract":"Stochastically Robust Resource Allocation for Computing<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Parallel, distributed, and Internet-based computing, communication, and information systems are heterogeneous mixtures of machines and networks. They frequently experience degraded performance due to uncertainties, such as unexpected machine failures, changes in system workload, or inaccurate estimates of system parameters. It is important for system performance to be robust against uncertainties.<br\/>What does it mean for a computer system to be ?robust?? How can robustness be described? How does one determine if a claim of robustness is true, or if a system will fail? How can one decide which of two systems is more robust? These are the types of issues we address in this project, with our team of faculty, graduate students, and undergraduate students from Colorado State University and the University of Colorado, and colleagues in industry (DigitalGlobe) and a national laboratory (NCAR, National Center for Atmospheric Research).<br\/>We are designing models, metrics, mathematical and algorithmic tools, and strategies for (1) deriving system resource management schemes that are robust, and (2) quantifying the probability of meeting performance requirements given uncertainties. We are validating our research by working with DigitalGlobe, which supplies images to Google Maps and Microsoft Virtual Earth, and NCAR, whose research activities include the prediction of severe and catastrophic weather. The robustness concepts being developed have broad applicability, and will significantly contribute to meeting national needs to build and maintain robust information technology infrastructures.","title":"CSR:Medium:Collaborative Research: Stochastically Robust Resource Allocation for Computing","awardID":"0905399","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["542086","552216","542088","518069"],"PO":["565255"]},"153915":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Many sensor network deployments are in harsh terrain that lack infrastructure but also need to use solar energy harvesting for self-sustained operation. The design of harvesting-aware solar sensor networks raises numerous systems and networking challenges. From a systems perspective, a design should be able to operate under a wide dynamic range of energy harvesting scenarios, from plentiful sunlight to very limited light (e.g., thickly forested areas). From a network perspective, a protocol stack should be able to adapt to spatio-temporal variability in harvesting rates due to foliage and day-to-day vagaries.<br\/><br\/>In this project, we will design systems and network support for harvesting-aware solar sensor networks. Our systems contributions include novel sensor platforms that use thin-film batteries for harvesting under low-light conditions, predictive duty-cycling under highly variable harvesting conditions, and lightweight checkpointing and restart to handle intermittent loss of power. Our networking contributions include a link layer that is optimized for duty-cycle variability, a network layer that uses harvesting-aware path metrics, and a transport layer can offer high throughput under diverse harvesting conditions.<br\/><br\/>Our educational plans consist of K-12 teaching through a summer high school outreach program, and inter-disciplinary REU programs in collaboration with Harvard Forest for deploying solar-powered sensor networks for ecological monitoring.","title":"CSR: Small: System and Network Support for Harvesting-aware Solar Sensor Networks","awardID":"0916577","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558563","526997"],"PO":["565255"]},"153816":{"abstract":"The goal of this project is to develop statistical models to accurately and efficiently decode population neuronal activity in the motor and premotor cortex. The study focuses on motor behavior as it is easily measured and strongly correlated with neuronal activity. Recent advances in motor cortical brain-machine interfaces have shown that research animals and paralyzed human patients were able to perform rudimentary actions with external devices such as robotic limbs and computer cursors. Neural decoding, which provides control commands to external devices, plays a key role in such interfaces by converting brain signals (e.g., spiking rates of a population of neurons) to kinematic states (e.g., hand position, hand movement direction).<br\/><br\/>Current decoding models are often based on the strong assumption that the neural signal sequence is a stationary process. This assumption, however, does not take into account the significant dynamic variability of spiking activity over time. Moreover, these methods have either focused on decoding the entire trajectory or on the occurrence times of a few \"landmarks\" during the movement. Effective coupling of these two complementary strategies can be expected to improve the decoding performance by better exploiting the nature of the landmark-defined movement. This project will develop computational methods to address these two issues. For the non-stationarity, the research team will develop adaptive versions of state-of-the-art decoding methods such as particle filters and point process filters that can capture the varying patterns in neural signals and update the model accordingly. To couple trajectory decoding and time decoding, landmark times will be identified from the neural activity, and then incorporated into the kinematic model. The team will use simultaneous recordings from multi-electrode arrays in the primary motor cortex, the dorsal premotor cortex, and the ventral premotor cortex that were recorded during behavior or visuo-motor tasks. Improved decoding methods are expected to have significant impacts on neural prosthetics.","title":"RI-Small: Statistical Decoding Models to Improve the Performance of Motor Cortical Brain-Machine Interfaces","awardID":"0916154","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["480987"],"PO":["564318"]},"153937":{"abstract":"Carbon-based nano-materials such as carbon nanotubes (CNTs) and, more recently, graphene layers and graphene nanoribbons (GNRs), have attracted strong interest as alternative device technologies for future nanoelectronics applications. This collaborative research project will potentially result in transformative advances required to harness the early science of these nano-materials into practical design technologies.<br\/><br\/>Specifically, PIs will develop a multi-scale simulation framework that integrates quantum simulations with compact model development for CNT and GNR field-effect transistors (CNTFETs and GNRFETs). They will develop ambipolar logic circuits and ultra-steep sub-threshold logic circuits as two promising candidate solutions with applications to both CNTFETs and GNRFETs. PIs will identify, model, and explore the effect of different variability and defect mechanisms in these devices to provide expedient means to systematically understand and predict their effects on the performance and reliability of practical carbon-based circuits.<br\/><br\/>Results will be disseminated through an integrated testbed for research and education in beyond-silicon computing, with an emphasis on carbon-based electronics. Through collaborations with a broad range of academic investigators as well as government and industry affiliates, this collaborative effort will strengthen ties between the device and CAD communities, help create links among them, and accelerate convergence to key design parameters essential for large scale integration of carbon-based electronics. Additionally, the development of learning modules, inter-disciplinary courses, and outreach efforts such as the Design Automation Summer School will bring the architectures, design tools and methodologies -- alongside fabrication and basic physics -- that will most likely define the first generation of nano-computing systems into the mainstream academic curriculum.","title":"SHF: Small: Collaborative Research: Modeling, Simulation, and Design for Performance and Reliability in Carbon-based Electronics","awardID":"0916683","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["523600"],"PO":["565157"]},"162528":{"abstract":"In the past decade, the Web has become one of the most used and transformative social applications in the history of human communications. Our everyday use of the Web depends on fundamental developments in computer science that took place long before the Web was invented. Today?s search engines, for example, are based on developments in information retrieval with a legacy going back to the 1960s. The innovations of the 1990s provided the crucial algorithms underlying the modern search engines that are so fundamental to Web use. Many interesting aspects of Web use, such as social networking, tagging, data integration, information retrieval, and Web ontologies, have emerged as ?social computing? at some of the top information schools and computing programs. However, in too many cases the Web is studied exclusively as a technical or social artifact rather than as an object of study in its own right, whose architectural properties actively shape the human interactions it supports. <br\/><br\/>The results of this project will define interdisciplinary methodologies that can be used to help develop the critical science, technology, and eventually curriculum at the heart of the emerging interdisciplinary field of Web Science. We will focus on establishing the methods of understanding and developing systems that allow large numbers of users to work together to form communities to solve scientific and social problems.","title":"EAGER: Using the Web for Science and Society","awardID":"0957718","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["499228",434316],"PO":["564456"]},"153706":{"abstract":"This project focuses on applying a model used in text-to-speech synthesis (TTS) to the task of automatic speech recognition (ASR). The standard method in ASR for addressing variability due to phonemic context, or ?coarticulation,? requires a large amount of training data and is sensitive to differences between training and testing conditions. Despite the effective use of stochastic models, current ASR systems are often unable to sufficiently account for the large degree of variability observed in speech. In many cases, this variability is not due to random factors, but is due to predictable changes in the speech signal. These factors are currently modeled in order to generate speech via TTS, but they are not yet modeled in order to recognize speech, largely because of non-local dependencies. We apply the Asynchronous Interpolation Model (AIM) used in TTS to the task of speech recognition, by decomposing the speech signal into target vectors and weight trajectories, and then searching weight-trajectory and stochastic target-vector models for the highest-probability match to the input signal. <br\/><br\/>The goal of this research is improve the robustness of ASR to variability that is due to phonemic and lexical context. This improvement will increase the use of ASR technology in automated information access by telephone, educational software, and universal access for individuals with visual, auditory, or speech-production challenges. More effective models of coarticulation may increase our understanding of both human speech perception and speech production. Results from this project are disseminated through technical papers and the CSLU Toolkit software package.","title":"RI: Small: Modeling Coarticulation for Automatic Speech Recognition","awardID":"0915754","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["438631",409042],"PO":["565215"]},"153827":{"abstract":"Modern machine learning is limited in its ability to use diverse information during training. This project is developing algorithms in the SVM family that allow extra information to be used effectively during training, with the understanding that this extra information will not be available during actual operation. Examples of extra information include structural homologies between proteins in a system designed to predict structure from amino acid sequences; and values for a financial time series between the time where a prediction is made and the time of the value being predicted. Preliminary testing has shown that such extra information can dramatically reduce prediction error in the learned system compared with current generation machine learning methods that cannot use this extra information. <br\/><br\/>This project encompasses analytic research to establish performance bounds on our new algorithms, and to explore the relationships of this work to human learning. The project also includes experimental work, including construction of novel training and testing datasets; software implementation of the algorithms; and training, testing and analysis of experimental results. Areas of application include handwritten character recognition; 3-D protein structure prediction; non-linear time series prediction, for example of financial time series; and prediction of likelihood of hospital readmittance for elderly patients. This project aims to give greater insight into the nature of learning, whether in humans or machines, and seeks to formally take into account data that is today seen as only peripheral to the learning task, and impossible for current machine learning algorithms to use. <br\/><br\/>The project will produce technical articles, a book, and teaching materials explaining this research. In addition the project will produce sharable software that implements the best version of the algorithm devised during the life of the project.","title":"RI: Small: An Advanced Learning Paradigm: Learning Using Hidden Information","awardID":"0916200","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[409341,409342],"PO":["562760"]},"153717":{"abstract":"The dramatic increase in throughput demands on transport systems has propelled the development of all-optical networks. These networks can provide tremendous capacity when they are designed with their own limitations in mind, such as coarse wavelength granularity and physical impairments. In this research we consider the holistic design of optical networks that include the interdependence of three network layers: the traffic grooming layer, the lightpath management layer, and the physical fiber layer.<br\/><br\/>The network is first viewed from the top-down, where sub-wavelength circuit requests arrive with specific quality of service requirements. Current traffic grooming approaches are altered to incorporate their dependence on the lightpath management and physical layer constraints.<br\/>The system is then examined from the bottom-up, so that the quality of transmission and efficiency of resource utilization can be optimized as the higher layer protocols evolve. Total capacity is measured from an information theoretic view point and system optimization uses ideas from game theory.<br\/><br\/>The results of the research will be practical algorithms for improved capacity and survivability of future optical networks as well as providing a quantitative proof of their superiority. The enhancement of network capability will help satisfy our society?s ever-increasing need for information. It encourages the development of applications that require significant bandwidth. It also stimulates cross-fertilization of ideas from the two fields of networking and communications. The algorithms and software will be made publicly available via a web-site. The research enhances the education of the diverse group of graduate and undergraduate students participating in it.","title":"NeTS:Small:Collaborative Research:Holistic and Integrated Design of Layered Optical Networks","awardID":"0915795","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["564881"],"PO":["564993"]},"152507":{"abstract":"TC:Large: Collaborative Research: AUSTIN?An Initiative to Assure Software Radios have Trusted Interactions (CNS-0910557)<br\/><br\/>Software and cognitive radios will greatly improve the capabilities of wireless devices to adapt their protocols and improve communication. Unfortunately, the benefits that such technology will bring are coupled with the ability to easily reprogram the protocol stack. Thus it is possible to bypass protections that have generally been locked within firmware. If security mechanisms are not developed to prevent the abuse of software radios, adversaries may exploit these programmable radios at the expense of the greater good.<br\/>Regulating software radios requires a holistic approach, as addressing threats separately will be ineffective against adversaries that can acquire, and reprogram these devices. The AUSTIN project involves a multidisciplinary team from the Wireless Information Network Laboratory (WINLAB) at Rutgers University, the Wireless@Virginia Tech University group, and the University of Massachusetts. AUSTIN will identify the threats facing software radios, and will address these threats across the various interacting elements related to cognitive radio networks. Specifically, AUSTIN will examine: (1) the theoretical underpinnings related to distributed system regulation for software radios; (2) the development of an architecture that includes trusted components and a security management plane for enhanced regulation; (3) onboard defense mechanisms that involve hardware and software-based security; and (4) a algorithms that conduct policy regulation, anomaly detection\/punishment, and secure accounting of resources. <br\/>Developing solutions that ensure the trustworthy operation of software radios is critical to supporting the next generation of wireless technology. AUSTIN will provide a holistic system view that will result in a deeper understanding of security for highly-programmable wireless devices.","title":"TC:Large: Collaborative Research: AUSTIN-- An Initiative to Assure Software Radios have Trusted Interactions","awardID":"0910557","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[406322,"540234","564747","531726"],"PO":["497499"]},"153959":{"abstract":"Interfaces are used to specify and verify the interaction between components of a system in a wide variety of programming languages and distributed systems. Stateful interfaces add expressive power by allowing the possible interactions to change over time. The goals of this project are to develop a foundational framework for stateful interfaces, and to apply the framework in two domains: (a) typesafe, generic components for efficient XML stream processing, with application to web services and related distributed system components; (b) memory consistency specifications, with application to reliable shared-memory programs that take advantage of increasingly common multi-processor systems. This project integrates session types for communication centered programming and typestates for object protocols by providing a common foundational framework that includes the following key features: (a) polymorphism, allowing reuse of typed code; (b) copyable, non-linear use of objects and channels, allowing several clients to share a single reference to a server; (c) expressive quantificiation, allowing the specification of memory-consistency guarantees that are ubiquitous in shared-memory programming. The research will advance foundations that will help improve software development and debugging of shared memory multi-core programming.","title":"SHF: SMALL: Stateful Interfaces","awardID":"0916741","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[409672,409673,409674],"PO":["564588"]},"155906":{"abstract":"Proposal #: CNS 09-23523 <br\/>PI(s): Papen, George Fainman, Y.; Vahdat, Amin M.<br\/>Institution: University of California - San Diego<br\/> La Jolla, CA 92093-0934<br\/>Title: MRI\/Dev.: Development of a Scalable Energy Efficient Datacenter (SEED)<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Project Proposed:<br\/>This project, building a Scalable Energy Efficient Datacenter (SEED), develops an integrated solution that encompasses physical layer hardware, protocols, and topologies that can provide the expected size and performance scaling for future data centers while minimizing the cost and energy per switched bit. The work creates the knowledge base required for the development of next generation scalable, energy efficient datacenters. Unique features of this instrument include novel statistical multiplexing modules to reduce connection complexity, a circuit switched optical interconnection fabric, and the ability to accommodate novel protocols, components and subsystems in a realistic system environment. With a design based entirely on commodity components and a non-blocking and scalable switch, the baseline configuration of the SEED instrument will connect more than 250 servers, each operating at 10 Gb\/s. The fully configured instrument is a hybrid electrical packet\/optically circuit-switched network designed to efficiently route large data flows into a circuit-switched optical core utilizing an optical switch from a previously funded MRI, Quartzite. The instrument supports several newly established multidisciplinary projects including the ERC Center for Integrated Access Networks (CIAN), the MRI GreenLight project, the Center of Interdisciplinary Science for Art, Architecture, and Archaeology (CISA3), and projects at the San Diego Supercomputer center. Specifically, SEED is expected to create the technology base for an order of magnitude improvement in both the cost and energy per switched bit. This will be accomplished by the development of new protocols and topologies, measuring and optimizing application dependent traffic patterns, providing critical system-driven specifications of a technology roadmap for the development of novel photonic technologies, and acting as a platform for training the next generation network engineers that are equally versed in both optical and electrical networks. The following four issues are associated with the SEED instrument.<br\/>- Design of flow scheduling techniques for fat trees that fit both electrical and hybrid systems,<br\/>- Algorithms for fault tolerance (components in large scale communication switches fail),<br\/>- Optimal Wavelength Division Multiplexing (WDM) design (uses multiple lasers and transmits several wavelengths of light (lambdas) simultaneously over a single optical fiber)<br\/>- Technology road map based on findings on performance metrics pertaining to building, testing, and operating the initial optical aggregation, transmission, and switching hardware to inform the Center for Integrated Access Networks (CIAN) ERC.<br\/><br\/>Broader Impacts: The engine of the 21st century economy, the creation of wealth through information processing, utilizes data centers as its cornerstones. Hence, technologies that can enable larger and more energy efficient information processing will affect many, if not every, aspect of modern life. Access to efficient remote processing should dramatically reduce the amount of physical transport and avoid the expense and human costs of unnecessary commuting, minimize environmental impact from infrastructure and pollution, substantially reduce our dependence on energy imports, improve educational opportunities, enhance the distribution of medical services, and increase overall national security. Thus, the infrastructure to carry these services constitutes a precious national resource, perhaps as precious as the air, rail, and road transportation. Indeed, it should enable this country to better compete globally.","title":"MRI: Development of a Scalable Energy Efficient Datacenter (SEED)","awardID":"0923523","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["522499","548361","485593"],"PO":["557609"]},"153607":{"abstract":"Natural language processing systems currently degrade when used outside of their training domains and languages. However, when text is analyzed along with translations into another language, the two languages provide powerful constraints on each other. For example, a syntactic construction which is ambiguous in one language may be unambiguous in another. We exploit such constraints by using multilingual models that capture the ways in which linguistic structures correspond between one language and another. These models are then used to accurately analyze both sides of parallel texts, which can in turn be used to train new, better, models for each language alone. Multilingual models are challenging because each language alone is complex, and the correspondences between languages can include deep syntactic and semantic restructurings. Focusing on syntactic parsing, we address these complexities with a hierarchy of increasingly complex models, each constraining the next. Our approach of multilingual analysis improves three technologies: resource projection, wherein tools for resource-rich languages are transferred to resource-poor ones, domain adaptation, wherein tools are transferred from one domain to another, and multilingual alignment, wherein correspondences between languages are extracted for use in machine translation pipelines. In addition to publishing the research results from this work, we also make freely available the multilingual modeling tools we develop.","title":"RI: Small: Exploiting Bilingual Resources to Improve Monolingual Syntactic Tools","awardID":"0915265","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["491648"],"PO":["565215"]},"153849":{"abstract":"Modern networks invalidate many of the assumptions of traditional networking. For example, mobile ad hoc networks (MANETs) invalidate the assumption that there will be stable routes in the network, throwing traditional routing techniques into disarray. Handheld computing devices further challenge assumptions about platform mobility. While the need for cross-layer design to meet these new challenges has become well known, no replacement for the traditional network stack has emerged yet. Implementing experimental cross-layer approaches on commodity hardware and software remains challenging.<br\/><br\/>In this project we are building a framework for modular, extensible, experimental, network stack implementation, called the FINS (Flexible Internetwork Stack) Framework. The framework allows users to leverage existing protocols (such as TCP and IP) where needed, providing implementations that provide more real-time control and transparency than is available in existing implementations, while allowing users to replace or modify components as desired. Thus, the FINS Framework allows researchers ready access to the network stack in a manner previously possible only in simulation or by making painstaking operating system modifications.<br\/><br\/>The FINS Framework facilitates ready implementation of new network technologies and context-aware applications thereby lowering the bar for participation in experimental networking research. The initial implementation of the framework is on handheld devices. The framework is being released via open source license, making it broadly available to the research community. A set of hands-on networking course modules utilizing the FINS Framework and handheld devices is being developed, and utilized for undergraduate research at a predominantly undergraduate institution.","title":"NeTS: Small: Collaborative Research: The Flexible Internetwork Stack (FINS) Framework","awardID":"0916300","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["540088","540078"],"PO":["565090"]},"153618":{"abstract":"Title: CSR: Small: Materialized Views over Heterogeneous Structured Data Sources in a Distributed Event Stream Processing Environment<br\/>Investigator: Suzanne W. Dietrich<br\/>Institution: Arizona State University<br\/>Proposal #: 0915325<br\/><br\/><br\/>Project Abstract: Software systems are becoming increasingly complex, requiring the coordination of heterogeneous structured data sources in a loosely-coupled distributed environment with support for handling events and streaming data. Some sample systems include homeland security, criminal justice, supply chain management, health care, and consumer monitoring. Such software systems involve numerous query expressions for detecting events, monitoring conditions, handling streams, and querying data. This research analyzes the dependencies among these query expressions over structured data sources defined in different language components over relational or data-centric XML to detect common subexpressions as candidates for materialized views. When views are materialized, the results of the computed view are stored so that subsequent references efficiently access the materialized view, avoiding the cost of recomputation. This performance improvement is even more critical with distributed data sources. However, the materialized view must be updated if any data source that it depends on has changed. To avoid costly recomputation, an incremental view maintenance algorithm uses the change to incrementally compute updates to the materialized view. A unique aspect of this research is the efficient maintenance of the materialized views while respecting the native format of the underlying loosely-coupled, heterogeneous data sources. Using state-of-the-art commercial and open-source components, a prototype environment that supports a distributed event stream processing framework provides a research and evaluation platform for the exploration of the identification, specification, and incremental evaluation of materialized views over heterogeneous, distributed structured data. This environment also provides a shared infrastructure for undergraduate research and curriculum enhancement.","title":"CSR: Small: Materialized Views over Heterogeneous Structured Data Sources in a Distributed Event Stream Processing Environment","awardID":"0915325","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["426529"],"PO":["565255"]},"153739":{"abstract":"The project seeks to develop scalable synchronization mechanisms based on software transactional memory (or STM) for handling concurrency control in distributed, embedded, multiprocessor real-time systems. The project explores several competing abstractions for supporting STM (in such systems), investigate the relative merits of these approaches, and design and develop the protocols and algorithms necessary to support them. The project also seeks to identify the tradeoffs between semantic simplicity and efficient implementations of different STM systems, with particular emphasis on augmenting obstruction-free STM implementations with real-time contention managers. Among the algorithms that are being designed include real-time distributed commit protocols, distributed real-time cache coherence protocols, scheduling algorithms that can provide timeliness assurances given the retry behavior of STM, and efficient STM implementations. <br\/>The project?s algorithms and protocols are being implemented and made publicly available in an open source form suitable for a real-time operating system or a real-time virtual machine. The project?s algorithms, protocols, analysis techniques, and implementations will allow distributed embedded real-time system programmers to use STM to simplify (distributed) concurrency control.<br\/>Broader impacts of the project are sought through efforts to transition the project's results by collaboration with The MITRE Corporation and US Naval Surface Warfare Center, and increasing cultural interaction between students and faculty in the US and students and faculty in the Middle East and North Africa region, through graduate advising and teaching in the VT-MENA (Virginia Tech ? Middle East and North Africa) program.","title":"SHF:Small: Scalable Synchronization for Distributed Embedded Real-Time Systems","awardID":"0915895","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["517750"],"PO":["565255"]},"153509":{"abstract":"People rely on two types of trust when making everyday decisions:<br\/>vertical and horizontal trust. Vertical trust captures trust<br\/>relationships between individuals and institutions, while horizontal<br\/>trust represents the trust inferred from the observations and opinions<br\/>of other peers. Although significant benefit could be realized by<br\/>combining horizontal and vertical trust mechanisms, they have evolved<br\/>independently in computing systems.<br\/><br\/>This project focuses on developing a composable trust model capable of<br\/>tightly coupling vertical and horizontal trust in a manner that is<br\/>both amenable to formal analysis and efficiently deployable. This<br\/>research advances the state of the art in trust management through a<br\/>series of innovative results, including the design of a unified<br\/>framework for specifying composite trust policies and the design and<br\/>analysis of efficient algorithms for policy evaluation. The composite<br\/>trust management approach championed by this project also enables<br\/>policy authors to move beyond simple proof of compliance to identify<br\/>the \"top-k\" preferred users satisfying security policies including<br\/>subjective assessments. The beneficiaries of this research range from<br\/>administrators of traditional computing systems who can better<br\/>incorporate previous history into their decision-making processes, to<br\/>users in social networks who can more carefully manage the exposure of<br\/>their personal data.","title":"TC: Small: Collaborative Research: Towards a Dynamic and Composable Model of Trust","awardID":"0914946","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548078"],"PO":["564388"]},"160945":{"abstract":"This project preserves and provides access to the image data associated with the ClueWeb09 dataset. The ClueWeb09 dataset was created by the PI in early 2009 to support research on the web, information retrieval, and related human language technologies. The dataset contains the texts of about 1 billion of the most important web pages written in ten major languages. The dataset was adopted quickly by the research community: 55 copies were licensed in the first 3 months of availability, and it was used in 4 out of 7 tracks of the National Institute of Standards and Technology's (NIST's) 2009 TREC evaluation of information retrieval research.","title":"Preservation and Access for ClueWeb09 Image Data","awardID":"0948856","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["541869"],"PO":["563751"]},"150924":{"abstract":"The recent development of various government and University funded screening centers has provided the academic research community with access to state-of-the-art high-throughput and high-content screening facilities. As a result, chemical genetics, which uses small organic molecules to alter the function of proteins, has emerged as an important experimental technique for studying and understanding complex biological systems. However, the methods used to develop small-molecule modulators (chemical probes) of specific protein functions and analyze the phenotypes induced by them have not kept pace with advances in the experimental screening technologies. Developing probes for novel protein targets remains a laborious process, whereas experimental approaches to identify the proteins that are responsible for the phenotypes induced by small molecules require a large amount of time and capital expenditure. There is a critical need to develop new methods for probe development and target identification and make them publicly available to the research community. Lack of such tools represents an important problem as it impedes the identification of chemical probes for various proteins and reduces our ability to effectively analyze the experimental results in order to elucidate the molecular mechanisms underlying biological processes. <br\/><br\/>Intellectual Merit <br\/>This project will develop novel algorithms in the areas of cheminformatics, bioinformatics, and machine learning to analyze the publicly available information associated with proteins and the molecules that modulate their functions (target-ligand activity matrix). These algorithms will be used to develop new classes of computational methods and tools to aid in the development of chemical probes and the analysis of the phenotypes elicited by small molecules. The key hypothesis underlying this research is that the target-ligand activity matrix contains a wealth of information that if properly analyzed can provide insights connecting the structure of the chemical compounds (chemical space) to the structure of the proteins and their functions (biological space). Novel methods will be developed to: (i) better analyze the screening results and identify high affinity and selective hits, (ii) build models that can predict the compounds that are active against a novel protein target and select a set of compounds to be included in a high-throughput screen that will be enriched in actives, (iii) virtually generate a set of core molecules (scaffolds) for a given protein target that can be significantly different from those currently available in the various libraries and have a high probability of being active against the target, and (iv) identify the proteins being targeted by compounds in phenotypic assays. In addition, the research will be facilitated by creating a database to integrate a large portion of the publicly-available target-ligand binding data along with information about the targets and the compounds involved. The successful completion of this research will transform the &#64257;eld of chemical genetics by establishing a new methodology by which the increasing amount of target-ligand activity information is used in a systematic way to explicitly guide the discovery of new probes and the analysis of phenotypic assays. <br\/><br\/>Broader Impact <br\/>The ability to discover chemical probes for a wide range of novel protein targets will make it possible to identify drugs for pharmaceutically relevant proteins, positively impacting the rate of drug discovery. In addition, it will greatly increase the set of proteins that can be selectively modulated via small organic molecules, expand the various biological processes that can be investigated via chemical genetics approaches, and allow researchers to use chemical genetics techniques to gain insights on the mechanisms of action associated with certain phenotypes. This will provide a better understanding of the dynamics of these processes and will supplement existing approaches based on molecular genetics. To further aid in the broad dissemination of the results and enhance scientific understanding, the computational methods developed will be made freely available via stand-alone or web-based services to aid researchers working in the area of chemical genomics. Finally, the project integrates the research with an educational plan that focuses on interdisciplinary undergraduate, graduate, and post-graduate education in the areas of Computer Science, Medicinal Chemistry, and Chemical Genetics. <br\/><br\/>Key Words: supervised learning; semi-supervised learning; cheminformatics; structural bioinformatics; data mining; graph algorithms","title":"III: Medium: Collaborative Research: Computational Methods to Advance Chemical Genetics by Bridging Chemical and Biological Spaces","awardID":"0905220","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["531622",402329],"PO":["565136"]},"161825":{"abstract":"Automatic controller synthesis algorithms hold the promise of producing correct-by-construction systems, obviating the need for costly post facto verification. However, there is currently a gap between theoretical foundations of controller synthesis and their practical implementations on hardware and software platforms. This project addresses challenges in closing the gap in control synthesis. In particular, we consider two fundamental problems. First, we consider the problem of implementation complexity of controllers. While theoretical results have focused on the optimal memory requirements for controllers, in practice, a controller implementation may have several other optimality requirements such as the size of the implementing (combinational and sequential) circuit, the complexity and frequency of computing the control action, and the sensing and actuation bandwidth. Accordingly, we study algorithms for the construction of optimal controllers under these metrics. Second, we consider the problem of fault tolerance in controllers, in which we consider effects of (possibly stochastic) errors in controller implementations. While traditional fault tolerance techniques such as error-correcting codes and redundancy can be applied directly, our thesis is that a closer interaction of fault tolerance with controller synthesis algorithms can lead to fault tolerant designs at costs lower than traditional techniques. For example, by distinguishing the \"importance\" of signals to the control objective, the costs associated with error-correction and redundancy can be decreased while having a negligible effect on the control objective. The research performed in this project is prerequisite for a more widespread adoption of correct-by-construction techniques.<br\/><br\/>The tools and techniques developed in this project have the potential to significantly enhance our ability to produce robust cyber-physical systems, thus affecting several large-scale application areas beyond the computer science and control engineering domains. Practically, the results of the research will lead to better controller synthesis tools. Theoretically, the research will bring together cross-cutting techniques, ranging from theoretical foundations in logics and algorithms for control, to optimization techniques, real-time systems, and hardware and software synthesis. In addition, by fostering collaboration between software foundations, control foundations, and hardware synthesis foundations, the project will train graduate and undergraduate students in the emerging and important domain of formal techniques for cyber-physical systems.","title":"SHF: EAGER: Closing the gap in Controller Synthesis","awardID":"0953994","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["460594","526859"],"PO":["565264"]},"150946":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Traffic measurement is central to network operation, management, and security. Yet, support for measurement was not an integral part of the original Internet architecture. This project aims to develop a programmable measurement architecture that is versatile enough to support current and future measurement needs, adaptable to dynamic network conditions, modular\/lightweight, and scalable to high link speeds. <br\/><br\/>This project proposes a new flow abstraction module and query language that can specify arbitrary traffic sub-populations for statistics collection. Efficient data structures to encode these queries will be developed. The team also strives to identify a core set of data streaming and sampling primitives that can be composed together to satisfy most of the queries. Efficient hardware implementation for these core set of primitives will constitute the basic measurement modules that can be easily reconfigured to measure traffic at different desired granularity. Measurement application case studies will be carried out to evaluate and showcase the capabilities of the proposed approach.<br\/><br\/>This project has great potential in guiding the design of a clean-slate measurement instrumentation for future Internet. It will provide both graduate and undergraduate students with training that span multiple disciplines, from fundamental statistical theory, algorithm design, to hardware implementation. The results (including the query language and underlying data structures, sampling\/streaming algorithms, and hardware building blocks) will be broadly disseminated through publications, invited talks\/tutorials, and open-sourcing software distribution.","title":"NeTS: Medium: Collaborative Research: Towards Versatile and Programmable Measurement Architecture for Future Networks","awardID":"0905273","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551132"],"PO":["557315"]},"150957":{"abstract":"Massive energy consumption is an escalating threat to the environment. Large-scale computational grids consume a substantial amount of energy, and <br\/>their energy requirements for powering and cooling are becoming comparable to the costs of acquisition. There is a lack of generally applicable methods for reducing energy consumption while ensuring good quality of service. This project will develop GridPac (Grid with Power-Aware Computing), a middleware environment that will allow grid managers and service providers to schedule multiple workflows across a distributed grid for system-wide optimization. GridPac will be based on a novel framework to support a variety of task-level workflows. The main features of this work are to develop: <br\/><br\/>(a) Novel static and dynamic algorithms for scheduling single and multiple workflows, which can be flexibly utilized by service providers in scalable grid environments. <br\/><br\/>(b) Control algorithms to account for dynamic adjustment of schedules using energy monitoring of the grid resources. <br\/><br\/>(c) Extensive benchmarking using a suite of commonly used grid workflows. <br\/><br\/>(d) A prototype middleware to assist IT organizations to better support their users while reducing energy costs. <br\/><br\/>The proposed work will lead to original scholarly contributions while harnessing the usage of computational grids. The project carries tremendous potential for economic, environmental, and societal impact. We will initiate new graduate and undergraduate level courses on related topics, and develop relevant tutorials, which will help to create awareness and educate a large audience on a critically important research topic.","title":"CSR: Medium: Collaborative Research: GridPac: A Resource Management System for Energy and Performance Optimization on Computational Grids","awardID":"0905308","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["530024"],"PO":["565255"]},"162815":{"abstract":"This project addresses the question: What privacy rules should bind private corporations? It does so through a collaboration between a legal scholar knowledgeable about computer science issues and a computer scientist knowledgeable about legal and policy issues. The common themes running<br\/>through the research are the current lack of agreed social norms concerning privacy, the interplay between computer security and privacy concerns, and the economic motivations that often are an important part of understanding various agents? actions. The goal is to contribute to the development of social norms concerning privacy that will simultaneously shape and inform both the development of appropriate technologies and appropriate business practices and laws. The interdisciplinary approach is essential to achieving this goal; it is also surprisingly unusual: There are remarkably few interdisciplinary examinations of privacy that effectively combine legal and computer science expertise. This project is a step toward remedying this lack. Together, the four aims address the immediate, serious, and unmet need for an approach to information privacy that is at once technically and legally sophisticated. The research will simultaneously shape and inform both the development of appropriate technologies and appropriate laws.","title":"EAGER: Privacy with Respect to Private Corporations in the 21st Century: Legal and Computer Security Issues","awardID":"0959116","effectiveDate":"2009-09-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["528421"],"PO":["565136"]},"162826":{"abstract":"This proposal represents an opportunity to seed a highly innovative interdisciplinary research project that has the potential for significant practical and theoretical impact for the management of information security ? an area which is receiving more and more public attention. During the past decade, research in information security has expanded from a purely technical focus to a more general technology-economic focus. Despite its expansion, a multidisciplinary approach to understand and theoretically explain the interaction of security and economy within complex systems of partners is still missing. The principle objective of this proposed research is to develop an innovative interdisciplinary information security framework in collaboration with a healthcare system to optimize and substantially advance both its system information security and system productivity. For example, consider a hospital that exchanges data records of patients with governmental data bases that ? on the other hand ? are accessed by insurance companies. Furthermore, hospitals directly exchange information with these insurance companies. This may allow an insurance company to combine and deduce information from different data sources that could pose a security threat which is not addressed by traditional security considerations. From a security economics perspective, the impact of information exchange between partners on their productivity has to be considered to understand the conditions under which partners will obey or violate information security policies. The proposed project provides the potential for high impact in substantially advancing research in information security as well as in management science. Although the project will address systems information security within the health care industry, its outcomes are expected to be applicable in other industries, e.g., defense. The cross-disciplinary nature of the proposed project is also expected to identify opportunities for interdisciplinary education.","title":"EAGER: Quantifying Information Security Risks in Complex Systems at the Interface of Users, Policies, and Technologies","awardID":"0959167","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["456465",435208],"PO":["565136"]},"160417":{"abstract":"The goal of this project is to investigate the impact of network coding on cooperative communications and to lay a theoretical foundation in this new and growing field. In their preliminary results, the PIs found that the use of analog network coding will inevitably introduce new noise during signal extraction at a destination node. Such new noise will directly affect capacity calculation and result in smaller capacity in cooperative communications. That is, the use of network coding may not always benefit cooperative communications, which is against some researchers? belief. Enlightened by this result, the PIs plan to systematically investigate the impact of network coding on cooperative communications in a general multi-session environment. The intellectual merit includes exploring and understanding various approaches in signal extraction and the potential noise introduced during the signal extraction process. Based on this new knowledge, the PIs also plan to re-visit a number of important problems that employ network coding in cooperative communications and offer new and correct understanding. Such understanding will not only offer a solid foundation for further research, but also has transformative potential to bring the existing network coding and cooperative communications theories one step closer to practice. The broader impact of this project includes the development of cross-disciplinary educational materials and courses. Throughout the PIs? experience with wireless networking research, they have found that advance materials in wireless communications are beyond the typical education for students in networking. An integral part of this project will be to bridge the gap between networking and wireless communications curricula via new cross-disciplinary courses.","title":"EAGER: Developing Theoretical Foundation for Cooperative Communications with Network Coding","awardID":"0946273","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["564848","549690"],"PO":["564898"]},"161506":{"abstract":"A system has resilient security if it retains a degree of secure functioning despite the compromise of some components. Since vulnerable components will long be in widespread use, resilient security is what counts against sophisticated adversaries with persistent footholds in American systems.<br\/><br\/>Resiliency infrastructures can help secure application components that may have many intrinsic weaknesses. They can structure systems so the risk of successful attack can be meaningfully measured.<br\/><br\/>Resiliency is more achievable than previously, because of recent architectural changes. One is virtualization , allowing many virtual machines to execute on a physical platform. Some virtual machines may serve as resiliency infrastructure nodes, controlling adjacent application nodes. Second, software attestation and appraisal, supported by Trusted Platform Modules and secure virtualization, allow a component to appraise the software state of remote peers.<br\/><br\/>We add three architectural ideas. Emulsification means breaking application functionality into small pieces, implemented as separate virtual machines. Second, their interactions can be monitored and secured by infrastructure nodes. Monitoring includes auditing, filtering , and modifying messages among application components. Third, data provenance uses annotations prepared by infrastructure nodes and stored with data objects.<br\/><br\/>Game theory applies to attacks that must succeed against several components, spread between the infrastructure level and the application level. Networks with randomized components force the adversary to use probabilistic strategies with low probability of defeating all of a sequence of components.<br\/><br\/>Broader impacts: Our society depends on information systems riddled with vulnerabilities. New architectures will reduce the severity of this problem , and provide measurements of risk.","title":"TC: EAGER: Measuring Architectures for Resilient Security (MARS)","awardID":"0952287","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["485802","485805"],"PO":["497499"]},"162606":{"abstract":"This is funding to support the participation of approximately 15 students, both undergraduate and graduate, in the 2009 Performance Metrics for Intelligent Systems (PerMIS) Workshop, which will be held in Gaithersburg, Maryland, on September 21-23, 2009. The PerMIS workshop brings together researchers from colleges, universities, research laboratories, and government laboratories to discuss how to design and evaluate intelligent systems. This workshop is the only one of its kind dedicated to defining measures and methodologies of evaluating performance of intelligent systems. Started in 2000, the PerMIS series focuses on applications of performance measures to practical problems in commercial, industrial, homeland security, and military applications. It has proved to be an excellent forum for discussions and partnerships, dissemination of ideas, and future collaborations between researchers, graduate students, and practitioners from industry, academia, and government agencies. As its main theme, this year's workshop seeks to address the question: Does performance measurement accelerate the pace of advancement for intelligent systems? In addition to the benefits students derive from attending a workshop where they can learn about current research, present their own work, and get feedback from professionals in their field, PerMIS organizers will provide structured opportunities for mentoring and networking. Students will meet at the start of the workshop to be introduced to one another and some of the workshop organizers. They will also have a luncheon with select senior researchers, to encourage interaction. And they will be given guidance about how to listen to research presentations and think critically about them. The organizers will take proactive steps to encourage diversity in the applicant pool by announcing the availability of funding to mailing lists for women in computer science, the Tapia Workshop mailing list, and through NSF's Broadening Participation in Computing Alliances.<br\/><br\/>Broader Impacts: Participation in workshops and conferences during one's student years can contribute to a successful research career. Student funding for travel to the PerMIS workshop will serve to introduce students to other researchers in the field, increase their knowledge of the research done in the field, and encourage them to continue their pursuit of research. Each student will be asked to write a report on his or her experiences at PerMIS 2009, which will be due with the travel reimbursement paperwork. In their reports, the students will be asked to write brief summaries of the plenary talks and their reactions to them. They will also be asked to discuss how each of the plenary talks relates to at least two other talks at the workshop. These reports will be used to evaluate the success of the funded student participation in the event, and will be submitted to NSF with the final project report.","title":"Student Travel for PerMIS 2009","awardID":"0958132","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["526078"],"PO":["565227"]},"153905":{"abstract":"Our society is becoming increasingly dependent on various technological networks, such as transportation systems, electrical power?distribution grids, computer networks, and so on. As those networks evolve and grow in complexity, their dynamical behavior is becoming difficult to understand and predict. This project will develop a general framework for modeling growth and evolution of such complex adaptive networks, based on the notion of interacting stochastic processes. The intuition behind this approach is that the interactions that form the network are informed by the collective state of the stochastic processes, while those processes themselves are affected by the forming network structure. The presence of such a feedback mechanism is vital for capturing realistic behavior of many real-world networks. The research will develop rigorous mathematical methods for analyzing structural and dynamical properties of adaptive networks, and define novel information?theoretic measures for quantifying their complexity.<br\/><br\/>Broader Impact: Our nation?s technological infrastructure of future will depend on our ability to control large?scale, dynamic networks of interconnected heterogeneous entities. This work will help to better understand, characterize, and predict the collective behavior of such networks. The project will train new professionals and scientists in an important interdisciplinary area, and develop a graduate course material on complex adaptive networks.","title":"NetSE: Small: Complex Adaptive Networks: Generative Models and Statistical Analysis","awardID":"0916534","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":[409529,"427568"],"PO":["564924"]},"153927":{"abstract":"Detection and analysis of branching structures and\/or texture is very challenging; it arises in many areas of science and engineering (e.g., medical images, chemical compounds, etc). The objective of this proposal is to develop novel approaches to model, detect, and analyze branching structures obtained from multimodality data. Such representation and analysis tools are expected to make many complex problems more tractable. Examples include identifying and recognizing a large number of structure classes; discovering new relationships among structure, texture, and function or pathology; evaluating hypotheses; developing modeling tools; assisting with surgical design; and managing medical image data efficiently.<br\/> Specifically, the investigators plan to explore three research topics under this project: (1) To develop descriptors of branching structures and texture, and knowledge discovery tools that will enable hypotheses generation and evaluation and improve modeling of branching structures; (2) To design automated algorithms and a flexible framework to detect branching structures. The investigators are especially interested in addressing challenges of occlusion and topology change; (3) To demonstrate the applicability of the proposed tools to breast imaging by building a prototype database of images from various modalities and associated clinical data that will provide advanced analysis and visualization capabilities. <br\/> Though the investigators use breast imaging as the driving application, the proposed project is expected to provide software and data resources that can assist clinical tasks and scientific discoveries in general. Developing automated tools to effectively characterize, detect, and classify tree-like structures in images would provide great insight into the relationship between the branching topology and function or pathology. The investigators plan to further contribute to the medical\/scientific community by disseminating the related software and annotated data sets.<br\/> The educational goals include incorporating research findings to graduate courses at Temple (data mining course and medical image analysis seminar) and at the University of Pennsylvania (medical image analysis course).","title":"III: Small: Collaborative Research: Modeling, Detection, and Analysis of Branching Structures in Medical Imaging","awardID":"0916624","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["562889",409593],"PO":["565136"]},"153817":{"abstract":"As silicon integrated circuit technology approaches its ultimate scaling and performance limits, we can expect a rapid proliferation of innovative proposals for fundamentally new information processing technologies. The quest for the first post-CMOS general purpose computing machines will likely emphasize digital computation in systems constructed from nanoscale building blocks. Proposals for new nanocomputing technologies will, however, be dificult to evaluate, both because nanocircuits are dificult to build and test experimentally and because phenomena that compromise the reliable physical representation and manipulation of information in nanoscale systems will pose new and unfamiliar challenges. These considerations motivate the development of new theoretical tools for assessing the fundamental physical limits to reliable processing of classical information in nanoscale systems, limits that follow from generic space, time and power constraints imposed by the technological objective of superseding silicon technology at the end of scaling.<br\/><br\/>This project aims to advance the fundamental physical description of digital information processing in (generally noisy and faulty) nanosystems and to develop approaches, built from such a description, that can be used to evaluate the ultimate information processing capabilities of proposed nanocomputing technologies. The first prototype assessment studies will emphasize two existing proposals---quantum-dot cellular automata and nanowire-based NASIC fabric implementations---and will integrate results from physical information theoretic analyses and physical circuit models. Other explorations will aim to provide technology-independent insights into issues of generic importance for nanocomputation, such as the physical costs of error correction. These investigations, taken together, will help to clarify the nature of fundamental physical limits in information processing and their practical consequences, which will become increasingly important as the quest<br\/>for new nanocomputing technologies intensifies.","title":"SHF: Small: Nanocomputing Processes and Artifacts: Fundamental Description and Physical-Information-Theoretic Assessment","awardID":"0916156","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":[409314],"PO":["565157"]},"153938":{"abstract":"Abstract below:<br\/><br\/>Graphs and networks are a natural representation across a wide range<br\/>of disciplines and domains. Statistical tools have recently been<br\/>brought to bear on the analysis of graphs, yielding rich dividends in<br\/>various application areas. The aim of this project is to use tools<br\/>from statistics and graph theory to develop algorithms that generate<br\/>similar graphs efficiently. Since graph data is often expensive to<br\/>collect, it is desirable to synthetically generate graphs. To be<br\/>widely applicable however, the generated graphs need to both preserve<br\/>the semantics of the original data (i.e., be drawn from the same<br\/>distribution) and be efficient to compute.<br\/><br\/>Two key questions form the core emphasis of the current project.<br\/>First, how does one measure similarity between two graphs? Second, how<br\/>can this notion of similarity be used to generate new graphs? On the<br\/>topic of similarity, the project will investigate representations to<br\/>preserve global properties, propose new, efficient, representations<br\/>for signatures, and explore sampling techniques and their convergence<br\/>behavior. On the topic of generation of new graphs, the project will<br\/>develop an exponential random graph model using signatures,<br\/>investigate feature selection via regularization, propose novel<br\/>methods to sample from the exponential random graph model and novel<br\/>techniques to produce proposal graphs, and provide rigorous empirical<br\/>validation across a range of application areas.<br\/><br\/>The project will facilitate the study of large complex structures of<br\/>the kind frequently encountered in domains like theoretical ecology,<br\/>social networks, and chemo-informatics, allowing researchers in these<br\/>domains to leverage statistical network analysis tools to identify<br\/>significant patterns and understand algorithm performance.<br\/><br\/>For further information see the project web page:<br\/>URL: http:\/\/www.stat.purdue.edu\/~vishy\/graphs.html","title":"RI: Small: Algorithms for Sampling Similar Graphs Using Subgraph Signatures","awardID":"0916686","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["485110","541857","559403"],"PO":["563727"]},"153707":{"abstract":"CSR proposal #0917137<br\/><br\/>CSR:Small:Collaborative Research: FastStor: Data-Mining-Based<br\/>Multilayer Prefetching for Hybrid Storage Systems<br\/><br\/><br\/>Abstract<br\/><br\/>A large number of existing parallel storage systems consist of hybrid storage components, including solid-state drives (SSD), hard disks (HDD), and tapes. Compared with high-speed storage components (e.g. SSD and HDD), tapes inevitably become an I\/O performance bottleneck. Prefetching and caching are commonly employed techniques to boost I\/O performance by increasing the data hitting rate of high-end storage components. However, prefetching in the context of hybrid storage systems is technically challenging due to an interesting dilemma: aggressive prefetching schemes can efficiently reduce I\/O latency, whereas overaggressive schemes may waste I\/O bandwidth by transferring useless data from HDDs to SSDs or from tapes to HDDs. In this research project, called FastStor, we investigate new data-mining-based multilayer prefetching techniques to improve performance of hybrid storage systems. The goals of this research are to (1) design data-mining algorithms for multilayer prefetching; (2) develop predictive parallel prefetching mechanism for SSD-based storage systems; (3) implement parallel data transfer among SSDs, HDDs, and tapes; (4) develop meta-data management schemes; and (5) implement a simulation framework named FastStor-SIM. The developed toolkit can be used to improve the I\/O performance of data centers with hybrid storage systems. The research findings of this project are published in conferences or journals for public knowledge. Through the collaboration of Auburn University, South Dakota School of Mines and Technology, and the University of Southern Mississippi, PIs promote learning and training by exposing graduate and undergraduate students to technological underpinnings in the fields of storage systems.","title":"CSR: Small: Collaborative Research: FastStor: Data-Mining-Based Multilayer Prefetching for Hybrid Storage Systems","awardID":"0915762","effectiveDate":"2009-09-01","expirationDate":"2012-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[409044,"543571"],"PO":["535244"]},"152629":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>The ability to reason about the complexity of living organisms in diverse environments is one of the hallmarks of intelligence. In this project the PI and her interdisciplinary team of investigators will design computer vision algorithms for intelligent tracking of large groups of living individuals in three-dimensional space. She will develop specific systems for tracking groups of microorganisms, bats, birds, and humans. And she will formulate machine learning methods for analyzing group behavior, specifically the conditions for formation and dispersal of groups, and the interactions of individuals within a group. An important innovative aspect of this research is the systematic and comprehensive approach to reasoning about the motion of large groups of living organisms observed in video data, independently of whether they happen to be humans, animals, or cells. Previous efforts in this area have typically focused on studying the behavior of a single type of organism, and on testing theories of behavior based predominately on simulations, without the appropriate analytical tools to automatically explore and quantify the vast number of visual data sets. This project, on the other hand, will base research findings on the analysis of thousands of trajectories of individual group members moving in 3D space. To this end, the PI and her team will collect video data in the field and in public spaces to ensure optimal data capture conditions. They will use these data to develop robust solutions for the problem of matching hundreds of individual bats, birds, or people from frame to frame. They will generate stereoscopic reconstructions of movement trajectories based on multiple calibrated cameras, and use machine learning to model group behavior and mine the trajectory data. Finally, they will compare the findings of their reasoning system against current theories about the formation of groups and the interactions of individuals within a group. A similar, systematic research strategy will be employed to address understanding of the behavior of single cells. The team will design microscope imaging protocols, develop solutions for the segmentation and tracking of individual cells, and use statistical learning techniques to discover patterns and correlations in the behavior of the cells on physiologically relevant substrates.<br\/><br\/>Broader Impacts: Understanding the processes by which groups of animals and microorganisms behave is crucial to the effective conservation of populations and ecosystems and the management of cellular environments. Project outcomes will advance knowledge across the fields of computer vision, artificial intelligence, behavioral ecology, and biological engineering, and will provide new tools for answering urgent economic and ethical questions, for example about the mortality of birds and bats in wind energy facilities.","title":"HCC: Large: Intelligent Tracking Systems that Reason about Group Behavior","awardID":"0910908","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["514728","524942","557296","472054"],"PO":["565227"]},"153619":{"abstract":"Machine Translation (MT) into morphologically-rich languages poses unique<br\/>challenges that have so far not been adequately addressed in state-of-the-art<br\/>approaches. Even the best available MT systems into languages such as Arabic<br\/>frequently produce translations that are disfluent and lack proper grammatical<br\/>structure. This project explores novel approaches that address these issues by<br\/>the development of a statistical MT framework that incorporates deeper levels<br\/>of modeling of syntax and morphology. While the methods explored are largely<br\/>language independent, the research is conducted and experimentally evaluated<br\/>within the context of a large-scale English-to-Arabic MT system constructed<br\/>using vast corpora available from LDC.<br\/><br\/>The research in this project focuses on novel approaches for combining<br\/>syntactic and non-syntactic translation resources that are automatically<br\/>acquired from vast amounts of parallel data and on exploring several<br\/>alternative pathways for the integration of information provided by a<br\/>high-accuracy morphological analysis and generation engine for Arabic into the<br\/>MT framework. The project also explores methods for improving the syntax of MT<br\/>output in Arabic using syntactic transfer rules that model syntactic<br\/>divergences between English and Arabic. The goal is to develop an<br\/>English-to-Arabic MT system that produces significantly more fluent,<br\/>grammatical and accurate Arabic output than the current best systems, as<br\/>measured by MT evaluation metrics (such as BLEU and METEOR), and as judged by<br\/>human evaluators.<br\/><br\/>The availability of high-accuracy fully-automatic Machine Translation from<br\/>English into Arabic has high potential value to the Arabic-speaking population<br\/>at large, by opening up access to all English content available over the web.<br\/>Such high-quality MT into Arabic may potentially also improve access to<br\/>markets in the Arabic-speaking world for US and international companies.","title":"Small: RI: Broad-Coverage High-Accuracy Machine Translation into Morphologically-Rich Languages","awardID":"0915327","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["502549"],"PO":["565215"]},"160902":{"abstract":"This is an exploratory study of question and answer (Q&A) communities, which constitute one of the most interesting and pervasive forms of informal knowledge production on the Web. The wide-scale adoption of the Web and of networking in general has led to knowledge production on a scale never seen before. However, the computer and information science research community lacks an understanding of many of the characteristics of Internet-based knowledge production. It has not yet been established which characteristics are important for knowledge production, especially how expertise is arranged within these communities in order to provide adequate information. It is also important to discover which structural characteristics -- such as reward structures, participation rates, and network of interactions -- influence knowledge production or expertise provision. Researchers especially do not understand how cultural differences affect these issues -- from participation, to motivation, to types of interaction, to the likelihood users will remain on the site or change their participation role.<br\/><br\/>A large number of Q&A forums exist, creating ample opportunities for cultural comparisons within similar topics. The present work is necessarily explorative, as even the measures by which to compare sites are unclear in the research literature, and relatively few cross-cultural studies of online communities exist. While the ultimate goal of this work is to design better systems and online spaces to support people in sharing knowledge and expertise across cultural divides, a better understanding of current use is first required. This project therefore consists of two phases. The first phase investigates a number of Q&A communities empirically to understand their current use and to create metrics for cross-site comparison. The second phase examines key issues believed to be influenced by culture, including evolution of key users, points and incentives, and consistency of participation, and cross-cultural differences. <br\/><br\/>This work could add substantially to what is understood about Internet-scale communities. It will examine how culture affects the distribution of expertise, knowledge provision, and expertise networks. The network metrics to be developed will help systematize the study of online communities and should find applications in other areas of network science. As such, this exploratory work will lead to the development of a deeper scientific understanding of knowledge production, especially for informal knowledge, across cultures. It could also substantially improve citizens' everyday lives, since Q&A sites are vital for providing immediate, everyday help and information to citizens, and help foster a more productive knowledge economy.","title":"EAGER: Cultural Issues in Sharing Expertise: Characterizing and Evaluating Online Question-Answer Communities","awardID":"0948639","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["430298",430297,430298],"PO":["564456"]},"170714":{"abstract":"Proposal #: CNS 08-21713<br\/>PI(s): Dyke, Shirley J.<br\/> Gill, Christopher; Lu, Chenyang<br\/>Institution: Washington University <br\/> St Louis, MO 63130-4899 <br\/>Title: MRI\/Dev.: Dev of A Configurable Cyberphysical Instrument for Real-Time Hybrid Testing<br\/><br\/>Project Proposed:<br\/>This project, developing a Cyber-physical Instrument for Real-time hybrid Structural Testing (CIRST), <br\/>supports the development and evaluation of new system design, implementation, and analysis techniques involving both cyber (computer hardware and software) and physical elements. The work aims to advance the state-of-the-art regarding real-time hybrid testing of structural systems, validate the next generation of structural monitoring and control systems, and study realistic limitations on issues such as fault tolerance, reliability, and stability in cyber-physical systems. The challenge in real-time hybrid testing revolves around the timely and appropriate coordination of<br\/>? Applying the input motions and forces to physical components and<br\/>? Communicating values of the input motions and forces to simulated components.<br\/>Actuator dynamics, complex interactions between the cyber and physical elements and computational time delays all hamper the ability to conduct accurate tests. Precise temporal synchronization, timely interactions, high fidelity numerical models of the physical components and predictive modeling and control techniques are thus crucial elements for integration control and simulation of such complex system dynamics. Thus, configurability and real-time operation constitute the instrument?s novel aspect. It is expected to provide the ability to consider large variety of structures and configuration in a single series of tests, and to operate and control those large-scale tests at finer time scales. The instrument should enable validation of new real-time scheduling and resource management techniques while facing the very realistic constraints needed to achieve real-time control. This time-scale aware distributed real-time control system component integrates and extends existing open-source tools and system software. Each experiment may be set up and controlled using an interactive dashboard that will provide visual tools for real-time data observation and analysis. CIRST will use the adjacent shake table facility for acceptance testing.<br\/><br\/>Broader Impacts: Details for this unique instrument will be documented through the project website and made available to the research community, including open-source distribution of system software and design documentation. Moreover, the instrument will enable training students through workshops. Several courses will also employ the instrument.","title":"MRI: Development of Configurable Cyberphysical Instrument for Real-time Hybrid Testin","awardID":"1028668","effectiveDate":"2009-09-15","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["501588"],"PO":["557609"]},"150914":{"abstract":"Massive energy consumption is an escalating threat to the environment. Large-scale computational grids consume a substantial amount of energy, and <br\/>their energy requirements for powering and cooling are becoming comparable to the costs of acquisition. There is a lack of generally applicable methods for reducing energy consumption while ensuring good quality of service. This project will develop GridPac (Grid with Power-Aware Computing), a middleware environment that will allow grid managers and service providers to schedule multiple workflows across a distributed grid for system-wide optimization. GridPac will be based on a novel framework to support a variety of task-level workflows. The main features of this work are to develop: <br\/><br\/>(a) Novel static and dynamic algorithms for scheduling single and multiple workflows, which can be flexibly utilized by service providers in scalable grid environments. <br\/><br\/>(b) Control algorithms to account for dynamic adjustment of schedules using energy monitoring of the grid resources. <br\/><br\/>(c) Extensive benchmarking using a suite of commonly used grid workflows. <br\/><br\/>(d) A prototype middleware to assist IT organizations to better support their users while reducing energy costs. <br\/><br\/>The proposed work will lead to original scholarly contributions while harnessing the usage of computational grids. The project carries tremendous potential for economic, environmental, and societal impact. We will initiate new graduate and undergraduate level courses on related topics, and develop relevant tutorials, which will help to create awareness and educate a large audience on a critically important research topic.","title":"CSR: Medium: Collaborative Research: GridPac: A Resource Management System for Energy and Performance Optimization on Computational Grids","awardID":"0905196","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559680"],"PO":["565255"]},"150925":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/><br\/>The project develops cryptographic protocol reasoning techniques<br\/>that take into account algebraic properties of cryptosystems.<br\/>Traditionally, formal methods for cryptographic protocol<br\/>verification view cryptographic operations as a black box,<br\/>ignoring the properties of cryptographic algorithms that can be<br\/>exploited to design attacks. The proposed research uses a novel<br\/>approach based on equational unification to build new more<br\/>expressive and efficient search algorithms for algebraic theories<br\/>relevant to cryptographic protocols. Equational unification gives<br\/>a compact representation of all circumstances under which two<br\/>different terms correspond to the same behavior. The algorithms<br\/>are implemented and integrated into Maude-NPA, a system that has<br\/>been successful in symbolic protocol analysis. It is demonstrated<br\/>that Maude-NPA when enriched with such powerful unification<br\/>algorithms can analyze protocols and ensure their reliability,<br\/>which could not be done otherwise.<br\/><br\/>Improved techniques for analyzing security are helpful both in<br\/>assuring that systems are free of bugs, and in speeding up the<br\/>acceptance of new systems based on the confidence gained by a<br\/>formal analysis. This research will lead to the design and<br\/>implementation of next generation tools for protocol analysis.<br\/>Algorithms developed will be made available to researchers as a<br\/>library suitable for use with protocol analysis tools. Tools from<br\/>the project will help students understand concepts relevant to<br\/>protocol design and get hands-on experience. Equational<br\/>unification for algebraic theories is not only useful for<br\/>protocol analysis, but also for program analysis in general, thus<br\/>making the results of this project to be widely relevant.","title":"TC: Medium: Collaborative Research: Unification Laboratory: Increasing the Power of Cryptographic Protocol Analysis Tools","awardID":"0905222","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["531861"],"PO":["565264"]},"150837":{"abstract":"The objective of this research program is the development of reliable, high-accuracy and high-resolution biolectromagnetics (BIOEM) simulators that can effectively utilize petascale computational resources to quantify the interaction of the human body with nearby wireless devices. The investigators are developing two classes of advanced BIOEM solvers based on finite- and boundary-element algorithms to solve coupled electromagnetic and bio-heat transfer equations. The investigators are, also, deploying the resulting solvers on petascale computers for high-fidelity simulations and cross-validating and verifying the two classes of solvers during development to build confidence in the legitimacy of the new simulation results.<br\/><br\/>This project aims to significantly advance the state-of-the-art in BIOEM simulation, to accurately model wave interactions with the human body at resolutions never before attempted, to quantify the heating effect of wireless devices on the human body and the electromagnetic effect of the human body on device performance, and to demonstrate that results from these simulations can be used to design safer and more efficient devices. It is being executed by an interdisciplinary team of researchers at the University of Texas at Austin?s Institute for Computational Engineering and Sciences and the Texas Advanced Computing Center. The resulting petascale finite- and boundary-element solvers are expected to be useful for many other wave propagation\/absorption problems. The project is training students and postdoctoral researchers and establishing an interdisciplinary community of developers and users fluent in petascale computing. The investigators are introducing petascale algorithmic concepts, programming techniques, simulators, and applications into graduate and undergraduate courses. They are disseminating their findings and broadening participation of underrepresented groups through international conferences and peer-reviewed journals, through seminars at nearby universities in Texas, including those with significant underrepresented minority populations, and by releasing the resulting software via open source mechanisms.","title":"High-Fidelity Simulation of Bioelectromagnetic Effects on the Human Body with Petascale Computers","awardID":"0904907","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7691","name":"PetaApps"}}],"PIcoPI":[402077,"556801",402079,"501527",402081],"PO":["565247"]},"150848":{"abstract":"Abstract: Side-Channel-Proof Embedded Processors with Integrated Multi-Layer Protection<br\/>Embedded digital systems are ubiquitous and may contain sensitive information that could be used for malicious purposes if fallen into the wrong hands. Therefore, strong cryptographic algorithms have been incorporated inside these devices. However, attackers have switched their targets from the cryptographic algorithms themselves to the hardware\/software implementations of these algorithms, through ?side-channel? chip measurements. From a hardware perspective, such side-channel attacks can be implemented at both the circuit-level and architecture-level. Although much research has been performed in mitigating side-channel attacks, these solutions are inflexible, unsystematic, and have high overhead. The goal of this research is to develop a universal solution that synergistically combines both architecture-level and circuit-level countermeasures for mitigating all major categories of side-channel attacks, to yield an extremely secure, highly flexible, low overhead digital system design methodology. In this proof-of-concept project, preliminary research will be carried out at both levels. At the architecture-level, novel architectural support to mitigate architecture-level timing and access-driven attacks will be developed. At the circuit-level, Delay-Insensitive Ternary Logic will be utilized to design the new architectural support as well as other key components of a MIPS32 4K-compatible embedded microprocessor. The effectiveness and efficiency of side-channel attack resistance at both architecture-level and circuit-level will be evaluated. Educational modules of circuit-level and architecture-level attack mitigation will be developed. Graduate and undergraduate students, especially from underrepresented groups, will be involved in this project. The research outcome will be disseminated to the academic and industrial communities through journal articles, conference presentations, and appropriate websites.","title":"TC: Medium: Collaborative Research: Side-Channel-Proof Embedded Processors with Integrated Multi-Layer Protection","awardID":"0904943","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["562016","525965"],"PO":["497499"]},"152608":{"abstract":"This project develops a high-level notion of context that exploits the capabilities of next generation networks to enable applications that deliver better user experiences. In particular, it exploits mobile devices -- always with a user -- to capture key elements of context: the user's location and, through localization, characteristics of the user's environment. What matters for the user experience is the user's place: a location in conceptual terms such as \"at home,\" \"jogging,\" or \"grocery shopping\" -- descriptions that combine positions with activities, environmental properties, and the activities of other nearby people. Realizing this notion of place requires that information from devices and infrastructure flow in ways unanticipated in current network architectures. It presumes enabling opportunistic interactions while preserving the users' privacy and designing incentive mechanisms to promote cooperation without exploitation of any. The above architectural concerns lie far beyond traditional network topics such as routing.<br\/><br\/>This project will develop, demonstrate, and evaluate a novel network architecture that gives primacy to user experience. It will lead to theoretical advances in semantic context modeling, mobility tracking at multiple levels of abstraction, collaborative localization, and incentive mechanisms. Networked applications offering enhanced user experience will have significant payoffs for industry and the productivity and quality of life of citizens. A prototype system will implement and evaluate context-aware services in university settings with prospects of expansion to K-12 schools and public facilities.","title":"NetSE: Large: Collaborative Research: Platys: From Position to Place in Next Generation Networks","awardID":"0910838","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["563576","533183"],"PO":["565342"]},"153829":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Robotic Sensor Networks (RSNs) are finding increasing use in critical<br\/>applications such as surveillance, environmental monitoring, emergency<br\/>response and search-and-rescue. With recent advances in embedded<br\/>technologies, devices that can be used as RSN units are becoming available<br\/>for everyday use. <br\/><br\/>Intellectual Merit:<br\/>This project focuses on pursuit-evasion games where one or more<br\/>pursuers tries to \"capture\" an evader who, in turn, tries to avoid<br\/>capture. Robust, provably correct solutions to many RSN <br\/>tasks (such as coverage and connectivity) can be obtained by modeling them as pursuit-evasion games.<br\/><br\/>Existing solutions to pursuit-evasion games usually assume that<br\/>(i) all players can observe each other at all times and (ii) there is<br\/>a centralized authority that coordinates all pursuers. Hence, such<br\/>solutions are not applicable for modeling RSN applications where the<br\/>network faces severe sensing and communication limitations. The<br\/>primary goals of the proposed work are to understand the effect of these<br\/>limitations on the outcome of the game, and to design strategies to<br\/>overcome them. <br\/><br\/>Broader Impacts:<br\/>Sensing and actuation are expected to play significant roles in the<br\/>evolution of information technology and the Internet. This<br\/>research will contribute to this evolution in two major ways. First,<br\/>it will deliver algorithms, tools and techniques to address<br\/>communication, sensing and actuation issues simultaneously. Second,<br\/>it will help scientists and engineers participating in this development acquire a broad<br\/>range of skills in areas such as algorithms, perception, robotics and communications. This<br\/>will be achieved through outreach programs and by incorporating this research in PI's courses.","title":"NetSE: Small: Game Theoretic Coverage and Connectivity Services","awardID":"0916209","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["551321"],"PO":["564924"]},"152619":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Obtaining physiological\/behavioral data from human subjects in their natural environments is essential to conducting ecologically valid social and behavioral research. While several body area wireless sensor network (BAWSN) systems exist today for physiological data collection, their use has been restricted to controlled settings (laboratories, driving\/flying scenarios, etc.); significant noise, motion artifacts, and existence of other uncontrollable confounding factors are the often cited reasons for not using physiological measurements from natural environments. In order to provide scientifically valid data from natural environments, a BAWSN system must meet several unique requirements (1) Stringent data quality without sensing redundancy, (2) Personalization to account for wide between person differences in physiological measurements, and (3) Real-time inferencing to allow for subject confirmation and timely intervention.<br\/><br\/>Intellectual Merit: In this project, a multidisciplinary team of researchers spanning various computing disciplines and behavioral sciences are developing a general purpose framework called FieldStream that will make it possible for BAWSN systems to provide long term unattended collection of objective, continuous, and reliable physiological\/behavioral data from natural environments that can be used for conducting population based scientific studies. FieldStream is being incorporated in two real-life projects ? NIH sponsored AutoSense at Memphis and NSF sponsored Urban Sensing at UCLA, to help validate the assumptions, establish the feasibility of developed solutions, and to uncover new requirements. <br\/><br\/>Broader Impact: By making it possible to obtain scientifically valid objective data from the field, FieldStream promises to help solve several behavioral problems of critical importance to human society that have remained unanswered for lack of such data.","title":"NetSE: Large: Collaborative Research: FieldStream: Network Data Services for Exposure Biology Studies in Natural Environments","awardID":"0910878","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":[406620,"523520"],"PO":["565090"]},"153719":{"abstract":"The PI plans to develop a new and robust hierarchical multi-resolution framework that can be used for assessement of model uncertainty, especially that associated with prediction of protein structure. The approaches also enable respresentation of the structure in ways that enable rapid searching of structure space. It is important to establish quality estimation methods for predicted structures so that they can be used wisely by knowing the limitations of the model. Protein tertiary structure prediction has made steady progress in the past decade. However, current prediction methods are still not capable of producing highly accurate models on a regular basis. Practical use of prediction methods by biologists is limited not only the accuracy of current prediction methods but also the lack of error estimation of the models they produce. Moderately accurate models are still useful for many purposes, including design of site-directed mutagenesis experiments and structure-based function prediction, if the possible error range is understood. Resulting quality assessment methods will also contribute to improvement of protein structure prediction methods. In addition, structure models of proteomes of model organisms will be constructed with quality assessment data and will be made available to the public through the Internet. The proposed project leverages Purdue University's efforts in interdisciplinary computational life science and engineering by training graduate students and undergraduate students of different backgrounds through interdisciplinary coursework and direct involvement in the project.","title":"III: Small: Quality Assessment of Computational Protein Models","awardID":"0915801","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["550449"],"PO":["565136"]},"150904":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Concurrency-related vulnerabilities are pervasive in modern computing <br\/>systems. Concurrency exploits include time-of-check-to-time-of-use <br\/>(TOCTTOU) race conditions in file systems, attacks on signal handlers, <br\/>and evasive malware that uses concurrency to escape sandboxing <br\/>mechanisms. As processors feature ever more parallelism, and <br\/>computers process more of our sensitive data, defending against <br\/>concurrency attacks is a key challenge for the coming decade. <br\/><br\/>The first goal is to protect legitimate applications from concurrency <br\/>attacks when they access system resources (e.g., prevent TOCTTOU <br\/>attacks on file accesses and exploitable race conditions in signal <br\/>handlers). The objective is to provide application programmers with <br\/>mechanisms and policies for synchronizing access to system resources <br\/>so they can avoid unintentional vulnerabilities. <br\/><br\/>The second goal is to provide strong confinement of untrusted code in <br\/>the presence of concurrency, i.e., blocking intentionally malicious <br\/>behavior. Today's malware abuses concurrency mechanisms to bypass and <br\/>circumvent containment mechanisms like reference monitors and system <br\/>call wrappers. Providing robust system support for containing <br\/>malicious code is a critical challenge in intrusion detection and <br\/>prevention. <br\/><br\/>Modern computing systems fundamentally depend on concurrency for their <br\/>performance and functionality. Making sure that concurrency is used <br\/>securely is essential for building a trusted cyber infrastructure. <br\/>This research will have a significant impact on the practical <br\/>development of secure software, and enable security-critical <br\/>applications to realize the performance benefits of today's highly <br\/>parallel systems.","title":"TC: Medium: Collaborative Research: Securing Concurrency in Modern Systems","awardID":"0905177","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548106"],"PO":["565264"]},"150805":{"abstract":"Solving for the structure and reactions of the atomic nucleus<br\/><br\/>The discovery of nuclear fission revealed the tremendous amount of energy that can be released when the strong bonds between the neutrons and protons forming atomic nuclei are broken. Ever since that history-making discovery, theoretical nuclear physicists have sought a detailed explanation of the properties of the atomic nucleus based on knowledge of the strong force between these constituents. When this goal is achieved, we will be able to predict reactions that take place in extreme environments ? from the interiors of stars to the core of nuclear reactors. Improving our knowledge of nuclear structure and reactions will help us economically and safely harness nuclear phenomena in support of a broad spectrum of humanitarian needs. Future nuclear science and technology advances promise a growing line of medical, industrial and energy applications. Nuclear medicine and nuclear magnetic resonance imaging provide just two prominent medical applications that rely on elementary properties of atomic nuclei.<br\/><br\/>This project aims to expand dramatically the reach as well as the impact of nuclear theory by harnessing the vast computational power of NSF's leadership class computer facilities under construction. The goal is to develop and implement a symmetry-based extension of the ab initio no-core shell model. By effectively ferreting out important interactions at the fundamental quantum level, we can achieve accurate predictions of nuclear properties based upon a deep understanding of the underlying forces. All participating particles are treated on the same footing within a matrix (?shell model?) picture of the quantum many-particle system, the nucleus. We aim to predict the structure and reactions of light-nuclei important for stellar processes and, possibly, for fusion reactors within five years. As part of this PetaApps grant, future leaders ? primarily graduate students and postdocs, will be supported to conduct this research under the guidance of senior investigators.","title":"Collaborative Research: Taming the scale explosion in nuclear structure calculations","awardID":"0904782","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[402000,"466669"],"PO":["564022"]},"161948":{"abstract":"This award supports a Doctoral Colloquium (DC) at the 11th International Conference on Ubiquitous Computing (UbiComp 2009) to be held September 30 - October 3, 2009 in Orlando, FL. The International Conference on Ubiquitous Computing is the premier outlet for novel research contributions that advance the state of the art in the design, development, deployment, evaluation and understanding of ubiquitous computing (ubicomp) systems. The conference is a competitive and interdisciplinary venue for publishing and presenting research that spans and integrates pervasive, wireless, embedded, wearable and mobile technologies to bridge the gaps between the digital and physical worlds.<br\/><br\/>The DC will provide intellectual interaction with experts and peers that will improve the near term contribution of their doctoral dissertation research. The interaction will broaden the students' perspective about the future directions of research in a range of topics connected to Ubiquitous Computing. It will also enable the students to network with each other and with the experts. Finally, the focused attention and unique exposure given to the students will in and by itself draw and attract more students to work in the Ubiquitous Computing area. This should hopefully increase the number of graduates in this area, which should drive innovation and generate highly trained workforce working in field of Ubiquitous Computing.","title":"Ubiquitous Computing (Ubicomp) 2009 Doctoral Colloquium","awardID":"0954795","effectiveDate":"2009-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["561046"],"PO":["565342"]},"150816":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Though perhaps unfortunate, as a practical matter software is often<br\/>built with functionality as a primary goal, and security features are<br\/>only added later, often after vulnerabilities have been identified.<br\/>To reduce the cost and increase assurance in the process of security<br\/>retrofitting, the aim to develop a methodology involving automated and<br\/>semi-automated tools and techniques to add authorization policy<br\/>enforcement functionality to legacy software systems.<br\/><br\/>The main insight is that major portions of the tasks involved in<br\/>retrofitting code can be or already have been automated, so the design<br\/>process focuses on enabling further automation and aggregating these<br\/>tasks into a single, coherent approach.<br\/><br\/>More specifically, techniques and tools are being developed to: (1)<br\/>identify and label security-relevant objects and I\/O channels by<br\/>analyzing and instrumenting annotated application source code; (2)<br\/>insert code to mediate access to labeled entities; (3) abstract the<br\/>inserted checks into policy-relevant, security-sensitive operations<br\/>that are authorized (or denied) by the application's security policy;<br\/>(4) integrate the retrofitted legacy code with the site's specific<br\/>policy at deployment time to ensure, through advanced policy analysis,<br\/>that the application enforces that site's policy correctly, and (5)<br\/>verify correct enforcement of OS policy delegation by the retrofitted<br\/>application.<br\/><br\/>The techniques and tools being developed are useful not only<br\/>for retrofitting, but also for augmenting and verifying existing code<br\/>already outfitted with security functionality; hence improving the<br\/>state-of-the-art in creating more secure software.","title":"TC:Medium:Collaborative Research:Techniques to Retrofit Legacy Code with Security","awardID":"0904831","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521593"],"PO":["565264"]},"150948":{"abstract":"Different Internet users often access similar content resulting in identical data repeatedly traversing the network. Several systems have attempted to eliminate this redundant data from network links to improve network performance. However, these only apply to point-deployments, i.e. to specific applications, protocols, or links. Because of this, their benefits are limited. <br\/><br\/>This project develops an Internet architecture where redundancy elimination (RE) is inherently supported by the network. This architecture subsumes localized deployments and extends the benefits of RE to all end-to-end flows. Crucially, it improves the design of applications and protocols. It frees application designers from concerns about using network resources efficiently. Network protocols can leverage inherent RE to better meet application and network constraints. This work will consider the technical, algorithmic and economic issues in this new architecture, including supporting RE in networks and end-hosts, reconfiguring applications to optimally leverage RE, and incentives for ISPs and end-hosts to deploy RE. <br\/><br\/>Intellectual merit: The new architecture will improve end-to-end performance, enhance applications and protocols, and give rise to new applications. The research will consider technical, algorithmic, and economic issues in supporting RE and leveraging it optimally. It will advance various fields of Computer Science, including network hardware, protocols and applications, algorithms, game-theory and network economics. <br\/><br\/>Broader impact: This project will have a broad impact on future applications and protocols. It will improve network management and routing. It will also impact ISP pricing. The project has a substantial educational component involving the introduction of new courses and cross-site mentoring.","title":"NetSE: Medium: Collaborative Research: Foundational Issues in Network Redundancy Elimination","awardID":"0905277","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["458795"],"PO":["565090"]},"160529":{"abstract":"This workshop will provide leading figures in computer science and economics a chance to explore and further develop emerging research opportunities at the interface of the two disciplines. There is strong interest in both communities in pursuing a joint research agenda. The workshop will explore a range of issues where there is opportunity for research interaction. These include models of learning by computational agents in economic settings; research on the role of complex networks in economic systems; the welfare properties and stability of equilibria; the computational tractability of basic economic problems and the design of computationally feasible mechanisms; and the role of information, trust, and reputation in markets. The workshop will be structured to facilitate discussions among people working in different disciplines, who may have different perspectives that can be usefully synthesized in approaching these problems. The workshop will help frame the preparation of a subsequent report articulating significant research directions and applications.<br\/><br\/>The topics covered by the workshop have the potential to inform design and policy questions on topics of fundamental societal importance. One fundamental application will be to problems of trust, risk, and contagion in financial markets, offering insights into the interconnectedness and fragility of large financial systems. Other fundamental applications will be to problems in emerging online markets; to systems supporting innovation and knowledge creation, including social, economic, and technological aspects; and to markets in the developing world.","title":"Workshop Proposal: Research Issues at the Interface of Computer Science and Economics","awardID":"0946718","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1320","name":"ECONOMICS"}}],"PIcoPI":[429234,429235,"516907","450550"],"PO":["562944"]},"153907":{"abstract":"This project is developing a general solution to two new federated search problems. Massive web datasets are made more manageable by dividing them into topic-oriented \"shards,\" and then searching only a few shards per query, thus reducing computational costs dramatically. Integration of focused \"vertical search services\" into general-purpose search portals is made more manageable by a framework that uses multiple techniques to characterize the contents of each resource and track how its content and query traffic change over time. Introducing resource definition policies and diverse information into federated search requires solving a variety of new resource representation, resource selection, and result merging problems. This research is also addressing the requirements of dynamic resources, and looks beyond average case analysis to characterize the range of accuracy that a federated search service experiences. Reducing the computational costs of searching massive web corpora enables greater academic study of large web datasets, and lowers costs for web search companies. A comprehensive framework for integrating specialized information services in web portals makes it easier for commercial web search portals to deploy new search services.<br\/><br\/>New algorithms are being disseminated in the open-source Lemur Toolkit, thus making it very accessible. Datasets are being published in a form that enables them to be recreated precisely or closely by other researchers. Queries and relevance judgments are being published so that they may be used by other researchers. This project is an extension of research done in IIS-0841275, SGER: Multi-Tier Indexing for Web Search Engines.<br\/><br\/>Project URL: http:\/\/www.cs.cmu.edu\/~callan\/Projects\/IIS-0916553\/","title":"DC: Small: An Integrated Architecture for Federated Search","awardID":"0916553","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["541869"],"PO":["565136"]},"153918":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Deployment is a fundamental issue in Wireless Sensor Networks (WSNs). In many missions today, sensors are deployed deterministically in a planned manner. Instances include airport\/harbor monitoring, intruder tracking on government property, etc. This project studies optimal deployment patterns in WSNs, which are those patterns that achieve desired coverage and connectivity requirements with the fewest sensor nodes. Knowledge of these patterns can help avoid ad hoc deployment to save costs, minimize message collisions, improve network management, etc. However, exploration of these patterns is difficult and far from mature in WSNs. This project comprehensively studies them in both theoretical and practical settings for WSNs in 2- and 3-dimensional spaces. Three major research tasks are carried out: (1) exploring optimal deployment patterns for 1-coverage and k-connectivity in 2-dimensional space; (2) exploring such patterns for connected m-coverage (m > 1) in 2-dimensional space; (3) exploring such patterns for connected coverage in 3-dimensional space. If successful, this project will result in a set of optimal deployment patterns in theoretical and practical settings to achieve multi-coverage and multi-connectivity in 2-dimensional and 3-dimensional spaces with different ratios of sensor communication range to sensing range. The research can help establish theoretical foundations and practical guidelines for planned deployment not just for WSNs, but also for other wireless networks, such as mesh and cellular networks. In addition, the research results will broaden understanding of applications of computational geometry and topology in computer networks.","title":"NeTS: Small: Connected Coverage of Wireless Sensor Networks in Theoretical and Practical Settings","awardID":"0916584","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["523431",409563],"PO":["565303"]},"153929":{"abstract":"This project is aimed at developing a new framework of ensemble modeling of speech signals to address the long standing challenge of robust and accurate recognition of spontaneous speech. Toward this goal, random forests based allophonic clustering is used to construct ensemble models of allophones by random sampling the variables underpinning the allophonic variations; data sampling is used to enrich the diversity of the ensemble models by balancing within-set data sufficiency and between-sets data diversity; functional discriminative training is used to further optimize the efficiency and accuracy of the ensemble models. Experimental evaluations of these methods are performed on a standard speech recognition task to facilitate direct assessments of their efficacy by the speech research community. The ensemble modeling approach promises higher accuracy performance and lower computation costs than the current multiple system integration approach, owing to the improved likelihood scores contributed by the ensemble models in local steps of decoding search. The approach as advocated in this project opens up a new paradigm for investigating the many issues in speech acoustic modeling, it offers a new way for ensemble modeling of structured data generally, and therefore it has the potential of significantly impacting the fields of speech recognition and other machine learning applications. The research findings are disseminated via journal publication, conference presentation, and a website. The methods of this project have broad applications in speech recognition and structured data classification, and particularly they are employed to improve the accuracy performance of a telemedicine automatic captioning system.","title":"RI: Small: Ensemble Modeling of Speech Signals for Automatic Speech Recognition","awardID":"0916639","effectiveDate":"2009-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["518498"],"PO":["565215"]},"159090":{"abstract":"EAGER: Collaborative Research: Cross-domain Knowledge Transformation via Matrix Decompositions<br\/><br\/>Traditional data mining algorithms discover knowledge in new domains starting from the scratch, ignoring knowledge learned in other domains. Knowledge transformation is a transformative paradigm that utilizes previously acquired knowledge in other domains to guide knowledge discovery process in a new domain and is especially useful for large data sets. In particular, utilizing applicable knowledge in other domains helps to stabilize the unsupervised learning and generate results that we may have preliminary understanding. <br\/><br\/>The goal of this project is to design and develop cross-domain knowledge transformation mechanisms for knowledge discovery. The transformation mechanisms are based on matrix decompositions where the knowledge been transferred are represented directly and explicitly ? making them easy to comprehend and be utilized in practice. The proposed mechanisms provide a versatile knowledge transformation framework with solid theoretical foundation and enable a new paradigm of unsupervised learning with domain knowledge. <br\/><br\/>The usefulness of these knowledge transformation mechanisms\/systems will be demonstrated for effective information retrieval, consumer recommender systems, and product\/online opinion sentiment analysis. The versatility of this transformative metholody will be verified across many domains.","title":"EAGER: Collaborative Research: Cross-Domain Knowledge Transformation via Matrix Decompositions","awardID":"0939187","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["560636",425256],"PO":["550329"]},"150817":{"abstract":"The investigators will develop an approximate computational geometry that is algorithm independent, accurate, and fast. Geometric predicate evaluation and element construction will be performed approximately using floating point arithmetic. Degeneracy will be handled transparently. The evaluation and construction techniques will be encapsulated in a software library that will be free for nonprofit use.<br\/><br\/>The research challenge is robustness: the output of an approximate algorithm must be correct for a small perturbation of the given input. This definition extends the numerical analysis definition of a stable algorithm to cover combinatorial error. Robustness is a fundamental computer science problem that is a major challenge in computational geometry. The predominant strategy in computational geometry, exact computation using algebraic geometry, has high computational complexity and contradicts the standard scientific and engineering strategy of approximate computation with error bounds. The investigators will adapt approximate computation to the special needs of computational geometry, which is primarily combinatorial. This task involves core research at the interface between computational geometry and numerical computing.<br\/><br\/>Robust approximate computation will transform how computational geometry is taught, how algorithms are developed and implemented, and how the field interacts with the wider scientific and engineering community. Introductory courses will present a rigorous, practical robustness theory, instead of treating robustness in an ad hoc, incomplete way. Programmers will implement real RAM algorithms as stated, using our library to ensure robustness and to handle degeneracy, instead of addressing these problems anew for every algorithm, which is often a major research challenge. Computational geometry will be available to other disciplines in the form of high-quality software libraries, akin to modern applied mathematics libraries.","title":"AF: Medium: Collaborative Research: Approximate Computational Geometry via Controlled Linear Perturbation","awardID":"0904832","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":[402028],"PO":["565157"]},"160508":{"abstract":"In 2005, the NSF hosted ?Robots: An Exhibition of U.S. Automatons from the Leading Edge of Research?, which was the result of a 2-year comprehensive study assessing robotics programs in the U.S., Asia, and Europe. The subsequent report concluded that America is in danger of losing its leading position in robotics. Arguably, the U.S. remains the world leader in artificial intelligence (AI) and machine learning research. Such research is critical to advancing the cognition that robots need to interact with people and manipulate objects in unstructured environments. This need for machine cognition thus provides American roboticists with opportunities to fill critical gaps and both vertically advance and lead the field. The annual IJCAI event (International Joint Conference on Artificial Intelligence) is a venue that can bring American and International roboticists and AI experts together. For over a decade-and-a-half, the IJCAI has held the Robotics Workshop and Exhibition as part of the overall conference. Such a venue provides a unique opportunity for the community to formulate roadmaps that leverage and apply America?s strengths in artificial intelligence to robotics. Towards this, the 2009 IJCAI Robotics Exhibition and Workshop (Pasadena CA July 13-17, 2009) will emphasize the use of robotics outside of academia by creating a joint forum with the commercial and amateur sectors.<br\/><br\/>Intellectual Merit: The workshop ?Beyond Academia: Exploring the Lessons and Best Practices in Commercial and Amateur Robotics? focuses on sharing the needs and expectations of robotics from all communities. Speakers from Willow Garage, iRobot and the amateur robotics publication Make Magazine will offer unique perspectives and approaches to common challenges from the perspective of repeatability, measurement and situated deployment. The cross-pollination of these ideas and experiences is crucial to the successful integration of AI into robotics. The ultimate goal of the workshop is to generate a white paper describing joint research opportunities. This has intellectual merit because both the AI and robotics communities are at a crossroads regarding how to best move robotics forward toward algorithms and experimental approaches that produce repeatable results in unstructured environments. The exhibition consists of four themes that relate to subsequent robotics challenges: 1) multirobot teaming, 2) learning by demonstration, 3) manipulation, and 4) undergraduate robotics challenges. Each of these areas has been identified as focus areas for the integration of AI and robotics by previous NSF supported workshops.<br\/>Broader Impact: Complementing the workshop discussions and panel will be a significant number of hands-on exhibits. Here, research teams will showcase working demonstrations that support the challenge themes of learning, teaming and manipulation. Exhibits will be on display for 2 full days during the general IJCAI Conference, providing an excellent opportunity to engage a broad technical audience. The exhibits will also be open to the general public to raise awareness of the state-of-the-art. Students from local schools and summer camps will be invited to visit. In previous years, the exhibition attracted local school groups that attended via a day field trip. Access to the exhibits provides an opportunity for students and leaders to learn how robotics and AI play important roles in society.","title":"Travel Support for 2009 IJCAI Robotics Workshop and Exhibition","awardID":"0946632","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["558854"],"PO":[429182]},"150718":{"abstract":"A central task in understanding how neurons collectively process information is to map how neurons influence each other in local cortical networks. As defined here, local cortical networks will consist of tens to hundreds of neurons. Influence will be defined as how well knowledge of activity in one neuron will allow the activity in another neuron to be predicted. Three methods for measuring influence between neurons will be explored. To assess these methods, they will be used on data from simple, and then realistic, models of cortical networks where the underlying connectivity structure is known. After refinement, the methods will be applied to recordings from hundreds of cortical neurons in small slice cultures of brain tissue. Over 100 cortical neurons at a time will be recorded through the use of an advanced, 512 electrode array. In addition, measures of influence will be applied to data taken from 16 wire electrodes placed in behaving rats. These in vivo recordings will serve as a first step toward linking influence maps in cortical networks to behavior. This research is expected to provide new knowledge that could aid the design of brain-like computing devices. In addition, it could ultimately be used as a tool to identify differences in influence patterns between healthy and pathological brains. <br\/><br\/>The three methods for measuring influence will include directed information, transfer entropy, and Granger causality. Special care will be taken to identify situations where these measurements may produce false positive connections. These include cases where two neurons are driven by a common source at different delays, and cases where one neuron influences another neuron indirectly through an intercalated neuron. Such false positive connections will be identified and corrected, to the extent possible, by comparing raw pairwise measures of influence with conditional measures of influence. Simulations will also provide an estimate of how often neurons outside the recorded population can contribute to false positive connections. These estimates will be used to place confidence limits on the influence maps extracted from actual data. In neurons where influences converge, synergistic interactions between influences will be measured. The map of influence will serve to identify locations within the network where synergistic transformations of information, or computations, occur.","title":"Collaborative Research: Effective Connectivity and Computations in Local Cortical Networks","awardID":"0904413","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":["402087"],"PO":["564318"]},"153908":{"abstract":"The goal of this research is to develop new methods for improving the performance of optical character recognition (OCR) systems. In particular, the PI investigates \"iterative contextual modeling\", an approach to OCR in which high confidence recognitions of easier document portions are used to help in developing document specific models. These models can be related to appearance--for example a sample of correct words can be used to develop a model for the font in a particular document. In addition, the models can be based on language and vocabulary information. For example, after recognizing a portion of the words in a document, the general topic of the document may be detected, at which point the distribution over likely words in the document can be changed. The ability to modify character appearance distributions and language statistics and tune them specifically to the document at hand is expected to produce significant increases in the quality of OCR results.","title":"RI: Small: Coordinating Language Modeling, Computer Vision, and Machine Learning for Dramatic Advances in Optical Character Recognition","awardID":"0916555","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["460641","460642"],"PO":["564316"]},"159080":{"abstract":"This CPATH project revitalizes undergraduate computing education at Florida A&M University through integrating studio-based learning and active learning experiences into the early experiences of undergraduate computing students. Through collaboration with Auburn University, the project adapts the methodology of a successful CPATH project to the Florida A&M setting. The approach is inspired by a human-language learning metaphor in which humans learn their natural language by a series of active immersions before writing. Active learning should increase the engagement of students and develop a community of learners that provides the social and academic support for students to turn the challenges of computer science into learning experiences instead of barriers.<br\/><br\/>The intellectual merit of the project lies in the strong conceptual basis for the project and the collaborative team of investigators. The project includes significant evaluation and dissemination that should provide significant insights into the learning of computing to the discipline of computing education.<br\/><br\/>The broader impacts include the production of approaches and artifacts that can be used widely. The project impacts two communities, computer science majors and non-majors taking a software-centric literacy course. This should broaden the pool of students in the undergraduate computing pipeline and the resulting computing workforce within the nation.","title":"CPATH-1: Computational Thinking Evolution to Studio-Based Active Learning","awardID":"0939138","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["526253",425220,425221,425222],"PO":["564181"]},"150906":{"abstract":"Assuring deadlines of embedded tasks for contemporary multicore architectures is becoming increasingly difficult. Real-time scheduling relies on task migration to exploit multicores, yet migration actually reduces timing predictability due to cache warm-up overheads and increased interconnect traffic.<br\/><br\/>This work promotes a fundamentally new approach to increase the timing predictability of multicore architectures aimed at task migration in embedded environments making three major contributions:<br\/><br\/>1. The development of novel strategies to guide migration based on cost\/benefit tradeoffs exploiting both static and dynamic analyses.<br\/><br\/>2. The devising of mechanisms to increase timing predictability under task migration providing explicit support for proactive and reactive real-time data movement across cores and their caches.<br\/><br\/>3. The promotion of rate- and bandwidth-adaptive mechanisms as well as monitoring capabilities to increase predictability under task migration.<br\/><br\/>The work aims at initiating a novel research direction investigating the benefits of interactions between hardware and software for embedded multicores with respect to timing predictability. This project fundamentally contributes to the research and educational infrastructure for the design and development of safety- and mission-critical embedded systems.","title":"CSR: Medium: Collaborative Research: Providing Predictable Timing for Task Migration in Embedded Multi-Core Environments (TiME-ME)","awardID":"0905181","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553590"],"PO":["565255"]},"150939":{"abstract":"The research investigates a new method for detecting errors that occur at module boundaries involving complex application program interfaces. The method first dynamically observes running programs to obtain constraints that characterize successful interactions at module boundaries. It then uses symbolic dynamic taint tracing to obtain symbolic expressions that characterize how regions of the input map to specific values that appear at module boundaries. A constraint solver then generates new input regions that produce values at module boundaries that violate the observed constraints. The final step is to run the program on the resulting new inputs to see if the inputs expose errors involving interactions between modules.<br\/><br\/>The significance of the research is that many reusable modules present complex interfaces that are difficult for developers to understand.<br\/>Module boundaries therefore comprise a prime location for errors and security vulnerabilities in software systems. The research promises to develop new testing techniques for finding and eliminating these errors and vulnerabilities. Broader impacts include more reliable software infrastructure for our society and the education of a skilled workforce. Intellectual merit includes a better understanding of errors in software systems and new techniques for finding and eliminating these errors.","title":"SHF: Medium: Exposing and Eliminating Errors at Component Boundaries","awardID":"0905244","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[402363,"497068"],"PO":["565272"]},"150708":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The researchers are developing new theoretical models and technology to automatically convert descriptive text into 3D scenes representing the text?s meaning. They do this via the Scenario-Based Lexical Knowledge Resource (SBLR), a resource they are creating from existing sources (PropBank, WordNet, FrameNet) and from automated mining of Wikipedia and other un-annotated text. In addition to predicate-argument structure and semantic roles, the SBLR includes necessary roles, typical role fillers, contextual elements, and activity poses which enables analysis of input sentences at a deep level and assembly of appropriate elements from libraries of 3D objects to depict the fuller scene implied by a sentence. For example, ?Terry ate breakfast? does not tell us where (kitchen, dining room, restaurant) or what he ate (cereal, doughnut, or rice, umeboshi, and natto). These elements must be supplied from knowledge about typical role fillers appropriate for the information that is specified in the input. Note that the SBLR has a component that varies by cultural context.<br\/><br\/>Textually-generated 3D scenes will have a profound, paradigm-shifting effect in human computer interaction, giving people unskilled in graphical design the ability to directly express intentions and constraints in natural language -- bypassing standard low-level direct-manipulation techniques. This research will open up the world of 3D scene creation to a much larger group of people and a much wider set of applications. In particular, the research will target middle-school age students who need to improve their communicative skills, including those whose first language is not English or who have learning difficulties: a field study in a New York after-school program will test whether use of the system can improve literacy skills. The technology also has the potential for interesting a more diverse population in computer science at an early age, as interactions with K-12 teachers have indicated.","title":"RI: Medium: Collaborative Research: From Text to Pictures","awardID":"0904361","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["511614","507533"],"PO":["565215"]},"151929":{"abstract":"Research in machine translation of human languages has made substantial progress recently, and surface patterns gleaned automatically from online bilingual texts work remarkably well for some language pairs. However, for many language pairs, the output of even the best systems is garbled, ungrammatical, and difficult to interpret. Chinese-to-English systems need particular improvement, despite the importance of this language pair, while English-to-Chinese translation, equally important for communication between individuals, is rarely studied. This project develops methods for automatically learning correspondences between Chinese and English at a semantic rather than surface level, allowing machine translation to benefit from recent work in semantic analysis of text and natural language <br\/>generation. One part of this work determines what types of semantic <br\/>analysis of source language sentences can best inform a translation system, focusing on analyzing dropped arguments, co-reference links, and discourse relations between clauses. These linguistic phenomena must generally be made more explicit when translating from Chinese to English. A second part of the work integrates natural language generation into statistical machine translation, leveraging generation technology to determine sentence boundaries, ordering of constituents, and production of function words that translation systems tend to get wrong. A third part develops and compares algorithms for training and decoding machine translation models defined on semantic representations. All of this research exploits newly-developed linguistic resources for semantic analysis of both Chinese and English. <br\/><br\/>The ultimate benefits of improved machine translation technology are easier access to information and easier communication between individuals. This in turn leads to increased opportunities for trade, as well as better understanding between cultures. This project's systems for both Chinese-to-English and English-to-Chinese are developed with the expectation that the approaches will be applied to other language pairs in the future.","title":"RI: Large:Collaborative Research: Richer Representations for Machine Translation (REPS)","awardID":"0908532","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[404736],"PO":["565215"]},"159180":{"abstract":"Traditionally, computing systems have been designed to always compute correctly - i.e., they are designed for error avoidance under all system conditions; fault tolerance strategies are implemented primarily to ensure continued correct execution in face of unforeseen and infrequent faults in the system. This conservative, worst-case design philosophy often leads to very inefficient designs, especially in terms of power.<br\/><br\/>This project looks at the feasibility of developing a new class of computing systems, referred to as stochastic computer systems that perform best-effort fault avoidance in face of other objectives like latency and power. The primary benefit of a stochastic computer system will be allowing the use of very low-power, but unreliable technologies, as well as allowing aggressive low-power optimizations.","title":"An Early Stage Exploration of Stochastic Computer Systems","awardID":"0939948","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["535191"],"PO":["493916"]},"159070":{"abstract":"Free and open source software (FOSS) is software that can be freely shared, modified, and redistributed. FOSS is developed by collaborative communities and distributed under licenses that permit its sharing and redistribution. Humanitarian FOSS (H-FOSS) is FOSS that is developed specifically to benefit the local and global community. The key concepts underlying FOSS and H-FOSS are their collaborative development process and community ownership. These concepts provide the underpinnings for many remarkable software projects, such as free and open repositories of general knowledge (Wikipedia), standard DNA parts (The BioBricks Foundation), and scientific research (PLoS).<br\/><br\/>This project uses the H-FOSS model to help revitalize undergraduate computing education by getting students engaged in building free and open software that benefits the community. During the project's first three years, students from Trinity College, Wesleyan University, Connecticut College, and elsewhere have developed H-FOSS in traditional and video-conference courses, independent studies and capstone projects, and in sponsored summer internships. Working collaboratively with FOSS practitioners in real and virtual communities, students have developed software that directly supports a variety of global and local humanitarian efforts, ranging from disaster management to health care delivery to volunteer management to search and rescue operations. For more details about this work, see http:\/\/www.hfoss.org. <br\/><br\/>During the next two years, this project will have three major goals: (1) to extend the H-FOSS educational community by creating new H-FOSS Chapters at a wide range of undergraduate institutions, including community colleges, women's colleges, and traditionally black schools; (2) to create an H-FOSS Certificate Program that will recognize student achievement in the study and practice of H-FOSS development; and (3) to develop a sustainable infrastructure and funding model, along with industry and community partners, that will enable the H-FOSS effort to be expanded to a national scope. By getting computing students and faculty involved in building FOSS that serves the community, this project will thereby help transform the nature and enhance the attractiveness of undergraduate computing education itself.","title":"CPATH-2: Collaborative Research: Building a community to incorporate humanitarian free and open source software into undergraduate computing education","awardID":"0939097","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425175,"550122"],"PO":["565264"]},"159081":{"abstract":"Recent years have seen a diversity of curricula designed to attract students to computer science. Media, robots, games, and other contexts have brought the field to life for many students. Yet these and other innovative introductory courses are not designed to serve the distinct needs of students in the sciences, mathematics, and engineering disciplines. Although STEM students require increasingly sophisticated computational capabilities, their formal training in computation, if any, often focuses on a narrow range of applications to the exclusion of fundamental and widely transferable Computational Thinking (CT) concepts and skills. <br\/><br\/>This project's hypothesis is that the computational thinking curricula for all STEM students will benefit from the insights gained from contextual \"CS1\" courses. Harvey Mudd College (HMC) has recently designed, deployed, and evaluated a breadth first introductory CS1 curriculum with a STEM-themed context. This work seeks to turn that course inside-out, spawning a suite of computational thinking modules that can be flexibly composed into curricula for non-CS STEM students and pre-CS-majors alike. Instead of \"another CS1,\" the result will be resources that span STEM-serving computational-thinking courses and provide a compelling introduction to core CT ideas and skills for students with a broad range of science and engineering interests.<br\/><br\/>The objectives are to:<br\/>1. Design and assess rich and compelling course modules that can be assembled into introductory CT courses for a variety of audiences (high school, undergraduate, and graduate level) in different areas (e.g. computer science, biology, or engineering) and at different types of institutions (e.g. liberal-arts colleges and large universities). These modules will be problem-based, using STEM-motivated labs and assignments to develop and exercise major concepts.<br\/>2. Combine these modules to develop and deploy several prototype courses including introductory college computer science courses, an introductory college computation for biology course, a high school computation course, and a course for information technology graduate students.<br\/>3. Disseminate modules and courses through (1) a structured deployment process that guides other schools (not directly involved in this project) in choosing appropriate modules for their contexts and (2) structured workshops, visits to other schools, and publications and talks at a number of education conferences and symposia.<br\/><br\/>Intellectual Merit: This work is creating a flexible, retargetable CT curriculum, grounded in but not limited by core CS topics, and aimed at students with a broad range of scientific and engineering interests. The PIs have extensive experience developing novel and engaging CS1 curricula for students outside the CS major: HMC's CS for Scientists course has proven successful at exciting students across STEM disciplines about how they can leverage computation in their chosen fields. Adapting this course's materials to a broad range of institutions is an important step in understanding how to develop the computational capabilities of all STEM students.<br\/><br\/>Broader Impact: This work will directly create CT curricula for five very different institutions: two large public universities, one of which serves a large minority population, one liberal arts college, one public high school and one graduate school. All five curricula will draw material from a flexible and modular set of resources that will create or inform CT courses far beyond this initial set of schools. Most importantly, these five CT courses will enable a thorough and cross-cutting assessment of the impact and relevance of CT for students throughout STEM disciplines. The approach has already shown significant improvement in increasing interest in computation among young women at Harvey Mudd College; this project's much wider assessment will determine how much these local successes transfer across a diversity of populations and institutions.","title":"CPATH-2: Modular CS1 from the Inside Out: Computational Thinking for all STEM Students","awardID":"0939149","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["527996","543573","561152","558317"],"PO":["564181"]},"150918":{"abstract":"The growth of scientific data sets to petabyte sizes offers significant opportunities for important discoveries in fields such as combustion chemistry, nanoscience, astrophysics, climate prediction and biology as well as from data on the internet. However, the realization of new scientific insights from this data is limited by the difficulty of creating scalable applications due to the lack of easy-to-use programming models and tools. To address challenges in creating data intensive applications, the project will build an extensible language framework, backed by an expressive collection of high-performance libraries (I\/O and analytic), to provide a development environment in which multiple domain-specific language extensions allow programmers and scientists to more easily and directly specify solutions to data-intensive problems as programs written in domain-adapted languages. The project will build on recent attribute grammar research to build an extensible specification of C to host domain-specific language extensions which will also address the inadequate performance in storage, I\/O and analysis capabilities in low-level language such as C. <br\/><br\/><br\/><br\/>The proposed extensible language and library framework has the potential to be a transformative problem solving environment for programmers and scientists since it allows scalable and efficient solutions to data-intensive problems to be specified at a high-level of abstraction. The resulting language framework and libraries will be freely available to researchers writing applications for climate and other applications involving spatio-temporal data. This includes many applications in the physical sciences and engineering and thus it is expected that the framework will find use in other scientific domains as well.","title":"DC: Medium: Collaborative Research: ELLF: Extensible Language and Library Frameworks for Scalable and Efficient Data-Intensive Applications","awardID":"0905205","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["560392"],"PO":["560586"]},"150929":{"abstract":"It is often assumed that the use of robots to help people execute tasks will result in better performance than if the person or robot were operating alone. However, research in automated systems suggests that the performance of a human-machine system depends on the extent to which the person trusts the machine and the extent to which this trust (or distrust) is justified. As robots are being developed to aid people with complex tasks, it is critical not only that we build systems which people can trust, but that these systems also foster an appropriate level of trust based on the capabilities of the systems. A user who does not have an appropriate level of trust in the robot may misuse or abuse the robot's autonomous capabilities or expose people to danger. This project proposes to develop quantitative metrics to measure a user's trust in a robot as well as a model to estimate the user's level of trust in real time. Using this information, the robot will be able to adjust its interaction accordingly. <br\/><br\/>Promoting appropriate levels of trust will be particularly beneficial in safety-critical domains such as urban search and rescue and assistive robotics, in which users risk harm to themselves, the robot, or the environment if users do not trust the robot enough to rely on its autonomous capabilities. The research has the potential for a large impact on the field of human-robot interaction as few studies have explicitly examined issues involving trust of robots. Being able to model trust and foster appropriate levels of trust will result in more effective use of robotic automation, safer interactions, and better task performance.","title":"HCC: Medium: Collaborative Research: Development of Trust Models and Metrics for Human-Robot Interaction","awardID":"0905228","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["526078",402340],"PO":["565227"]},"150709":{"abstract":"Recent work has revealed how important it is to examine the<br\/>properties of programs after they have been translated to machine<br\/>code. For instance, many security exploits depend on<br\/>platform-specific features that are not visible at the source-code<br\/>level, such as memory-layout details (e.g., the offsets of variables<br\/>in activation records and padding between fields of a structure). The<br\/>expected contributions of the project include (i) a<br\/>language-independent tool generator that, from a formal specification<br\/>of a given instruction set's syntax and semantics, generates<br\/>implementations of dynamic-analysis, static-analysis, and<br\/>symbolic-evaluation components tailored to that instruction set, and<br\/>(ii) a variety of prototype language-specific applications (i.e.,<br\/>specific machine-code-analysis tools), including<br\/><br\/> o A tool to automate the detection of bugs and security<br\/> vulnerabilities in machine code. The aim is to identify definite<br\/> bugs and vulnerabilities, and information about what is required to<br\/> trigger them.<br\/> o A tool to check sequencing properties on machine code.<br\/> o A tool that can aid in detecting interoperability problems among<br\/> components by inferring input\/output and network-communication<br\/> formats, and by summarizing the behavior of a component's client.<br\/><br\/>The results will help programmers create correct, reliable, and secure<br\/>software systems by providing them with new kinds of tools to (a) verify<br\/>properties of a program?s behavior, and (b) find potential bugs and<br\/>security vulnerabilities.","title":"SHF: Medium: MACANTOK -- a MAchine-Code-ANalysis TOol Kit -- and its Applications","awardID":"0904371","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[401760],"PO":["564588"]},"159170":{"abstract":"The planned Workshop WOFE-09 is a sequel to WOFE-97 held January 1997 in Puerto de La Cruz, Tenerife, Spain, WOFE-99 held May 31 - June 4 in Villard de Lans, France, WOFE-2002 in St. Croix, Virgin Islands, and WOFE-04 held on December 18-22 in Aruba, and WOFE-07 held in Cozumel, Mexico<br\/><br\/>The objective of the workshop is to bring together leading scientists and engineers who are at the frontiers of electronic device and circuit research and development. Ultra low power digital electronics, microwave power circuits, and optoelectronics have become the foundation of today's electronics technology. Yet, they emerged from traditionally separated fields and are still largely pursued by specialists trained in different areas.<br\/><br\/>The intellectual merit of the proposed workshop will be in facilitating of ideas and information in cutting edge technologies at frontiers of research and in reviewing the most recent and exciting breakthroughs in the nanoelectronics and microelectronics fields, the underlying physical mechanisms that link recent and expected advancements, and in exchanging views on future trends and directions, the market pulls and the necessary policy and infrastructure changes. <br\/><br\/>The broader impacts will be in publishing Proceedings that will included best paper presented at the WOFE-09, peer-reviewed and edited with a detailed editorial Introduction and in promoting involving graduate students and younger scientists. In the past, some of the previous WOFE Proceedings were listed as Best Sellers by Word Scientific, Inc.","title":"Workshop on Frontiers in Electronics (WOFE-09) To be Held in Rincon, Puerto Rico on December 13-16, 2009","awardID":"0939894","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["561789"],"PO":["564357"]},"159082":{"abstract":"A paradigm shift has occurred in research in the natural and social sciences, but this change has not reached the classroom in a systematic way. Computational modeling has transformed the way science is done and is now a full partner to experimentation and theory in most disciplines. Despite its importance, students in the sciences do not know the basics of modeling, make fundamental errors in application, and are ill-prepared to solve complex, cross-disciplinary problems using modeling as a tool. Oberlin College proposes to change this and is well positioned to do so. By introducing dynamic systems modeling into introductory courses in 11 science disciplines, the College will expose the majority of its eventual science majors to these powerful techniques at least twice in their first two years of study. When coupled with follow-up efforts at the intermediate and advanced level, the College will transform the way that most science students view complex problem solving. Oberlin will be aided in this effort by faculty and graduate students from the Center for the Study of Complex Systems at the University of Michigan, building on a vibrant relationship between the institutions. Established connections with two nationally recognized modeling experts will help to anchor the effort and give it external perspective. More than a dozen Oberlin faculty have been active in this area in recent years, and they will be among the initial cohort through which this systemic change will be accomplished. The group of faculty engaged in computational modeling will expand through the wide range of grant activities. By using dynamic systems modeling, the College will achieve its five goals for this project: integrating computational thinking into the science curriculum; developing a cohort of faculty experienced in teaching and using modeling techniques; developing a new tool for teaching computational modeling; providing cross-disciplinary teaching and curriculum development opportunities for graduate students and a postdoctoral researcher; and assessing, revising, and disseminating the most successful components.<br\/><br\/>As the undergraduate institution that leads the nation in students who go on to get Ph.Ds, Oberlin?s project in modeling pedagogy will have a powerful multiplier effect as its graduates enter academia and other high-impact careers, carrying the new modeling paradigm with them. This cohort of young scientists will have an important effect since computational thinking is the key to complex problem solving in such diverse fields as public health, economics, climate change, and biotechnology. Students who have worked with models throughout their science education will be well equipped to tackle both societal and cutting edge scientific problems. This project will also produce a key piece of publicly available software for use in modeling pedagogy and research. Other products will include pedagogical modeling units across the 11 disciplines involved in this effort, and these will be disseminated through standard channel","title":"CPATH- 2: Teaching Computational Thinking through Integration of Dynamic Systems Modeling","awardID":"0939153","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425229,425230,425231,425232,"547506"],"PO":["565136"]},"149292":{"abstract":"This project addresses the current gap in research on creative design through personal fabrication and construction. At present, there is very little understanding of what enables (or prevents) users from making greater use of existing fabrication tools; there is even less exploration of how to expand the space of fabrication devices to accommodate both traditional and non-traditional crafting projects; and there is little discussion of how to build on the successes of web-based communities for \"intangible\" creations (videos, photographs, documents) to nurture communities for physical, tangible creations. This project expands the possibilities of accessible fabrication to develop prototypes of interfaces, personal devices, and infrastructure that will illustrate the power and potential of construction when placed in the hands of \"beginners\". The goal of this pilot project is to create a wide variety of small-scale innovations that can seed larger and longer-term projects in the near future. Work in interfaces will focus on the design of input devices and software tools; the goal here is to enable people (including children) to create objects using existing fabrication devices. Work in personal devices will focus on prototyping novel fabrication devices geared toward small-scale, individual craft projects. Work in infrastructure will focus on the creation of web-based software systems aimed at building self-supporting fabrication communities among children, students, and hobbyists. Through these multiple aims, this project seeks both to identify a (potentially wide) variety of topics for more ambitious research projects and to spark more widespread interest in these issues in the computer science and educational technology communities.","title":"PILOT: Construction Made Simple(r): Interfaces, Devices, and Infrastructure for Beginning Fabrication","awardID":"0856003","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["523483"],"PO":["562669"]},"160918":{"abstract":"A fast growing worldwide trend is to view computation as a commodity: Instead of maintaining their own computer systems, organizations or individuals may pay specialized providers to carry out the desired computation for them. This trend (often called \"Cloud Computing\") carries with it great promise in terms of overall computing efficiency, power consumption, and financial flexibility. However, it also opens the door to much more acute security threats than those we have encountered so far: Without additional protection, the client must completely trust the provider to perform the computation correctly, and at the same time keep the secrecy of the clients' most sensitive private data. <br\/><br\/>Allowing the client to benefit from this service without putting such an unreasonable amount of trust in the provider turns out to be an extremely complex and delicate task. In particular, traditional cryptographic techniques and concepts are of no help here. Indeed, the cryptographic community is recently abuzz with a set of new techniques that are aimed at dealing with such adversarial scenarios. These include exciting new techniques for: <br\/><br\/>- Computation on encrypted data (often called \"fully homomorphic encryption\")<br\/>- Verifiable Delegated Computation<br\/>- Program Obfuscation<br\/>- Leakage-Resilient Cryptography<br\/>- Circular Encryption<br\/>- Searchable and Conditionally Decryptable Encryption<br\/><br\/>The workshop will bring together researchers that work on different aspects of this problem, allowing for exchange of ideas and coming up with new research directions.","title":"Workshop: Cryptography in the Clouds","awardID":"0948699","effectiveDate":"2009-09-01","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["562010"],"PO":["565157"]},"150908":{"abstract":"TC: Medium: Collaborative Research: Wide-Aperture Traffic Analysis for Internet Security<br\/><br\/>Among emerging network threats, some of the most pernicious and elusive are stealthy attacks that take place at very low rates and in a targeted fashion. This project is developing methods for identifying malicious and unwanted activity in the Internet -- specifically, traffic that is low-volume and well \"hidden'' among normal traffic. The approach being taken is to develop new methods for direct analysis of Internet traffic of unprecedented scope and scale. In particular, the project is designing and implementing a system that leverages high-performance cluster computing to allow application of sophisticated pattern analysis and machine learning algorithms to network traffic at the packet and flow level.<br\/><br\/>An organizing principle of the system is its decomposition into data-parallel \"lenses'' and more computationally challenging \"pattern analysis'' components. The project is investigating the application of this architecture to dark address monitoring in traffic from core networks -- a capability that has not been possible to date.<br\/>The end result of this project will be a set of tools and a running system that may be used by researchers to enable new investigations into traffic analysis, and may be used by network operators on an ongoing basis to help protect their networks.","title":"TC: Medium: Collaborative Research: Wide-Aperture Traffic Analysis for Internet Security","awardID":"0905186","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[402290],"PO":["564223"]},"159292":{"abstract":"The Georgia Institute of Technology in collaboration with Columbus State University proposes an extension to the \"Georgia Computes!\" Alliance. Georgia Computes! has made dramatic strides in improving computing education throughout the state, at all levels of the pipeline. Its efforts start at 4th grade with summer camps, and continue through middle school with camps and outreach with the Girl Scouts, YWCA, and Cool Girls, extend to high school with camps and teacher professional development, and end in undergraduate education with faculty workshops. Georgia Computes! successes include exponential growth in the number of Girl Scouts taking their computing workshops, the creation of eight new regional summer computing camps, a doubling of the number of institutions offering Advanced Placement Computer Science (APCS), a doubling of the number of Hispanic students taking the APCS exam, and change at a quarter of the computing programs in the University System of Georgia. With this Extension, they propose to scale, and broaden their alliance interventions. Georgia Computes! will grow its teacher education efforts to include two regional centers of expertise, at Columbus State and at Armstrong Atlantic State University. In order to offer inservice workshops throughout the state, it will develop on-line materials, including courses that provide on-line access to Georgia's new computer science teaching endorsement. Georgia Computes! will grow its already successful K-12 outreach efforts to help students to develop a broader definition of computing. It will use more diverse student mentors, including high school students and disabled undergraduate students. Most importantly, this Extension will create infrastructure for careful measurement of individual university computing programs in the state and to track individuals from workshops and camps, through high school classes, to university degrees.","title":"BPC-AE: Collaborative Research: Extending \"Georgia Computes!\": A Statewide Vertical Alliance to Broaden Participation through Innovative, Inviting, and Relevant Computing Education","awardID":"0940495","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":[425832],"PO":["561855"]},"159050":{"abstract":"Free and open source software (FOSS) is software that can be freely shared, modified, and redistributed. FOSS is developed by collaborative communities and distributed under licenses that permit its sharing and redistribution. Humanitarian FOSS (H-FOSS) is FOSS that is developed specifically to benefit the local and global community. The key concepts underlying FOSS and H-FOSS are their collaborative development process and community ownership. These concepts provide the underpinnings for many remarkable software projects, such as free and open repositories of general knowledge (Wikipedia), standard DNA parts (The BioBricks Foundation), and scientific research (PLoS).<br\/><br\/>This project uses the H-FOSS model to help revitalize undergraduate computing education by getting students engaged in building free and open software that benefits the community. During the project's first three years, students from Trinity College, Wesleyan University, Connecticut College, and elsewhere have developed H-FOSS in traditional and video-conference courses, independent studies and capstone projects, and in sponsored summer internships. Working collaboratively with FOSS practitioners in real and virtual communities, students have developed software that directly supports a variety of global and local humanitarian efforts, ranging from disaster management to health care delivery to volunteer management to search and rescue operations. For more details about this work, see http:\/\/www.hfoss.org. <br\/><br\/>During the next two years, this project will have three major goals: (1) to extend the H-FOSS educational community by creating new H-FOSS Chapters at a wide range of undergraduate institutions, including community colleges, women's colleges, and traditionally black schools; (2) to create an H-FOSS Certificate Program that will recognize student achievement in the study and practice of H-FOSS development; and (3) to develop a sustainable infrastructure and funding model, along with industry and community partners, that will enable the H-FOSS effort to be expanded to a national scope. By getting computing students and faculty involved in building FOSS that serves the community, this project will thereby help transform the nature and enhance the attractiveness of undergraduate computing education itself.","title":"CPATH-2: Collaborative Research: Building a Community to Incorporate Humanitarian Free and Open Source Software into Undergraduate Computing Education","awardID":"0939002","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425111,"513893"],"PO":["565264"]},"159061":{"abstract":"This project, InspireCT, employs vertically integrated project teams to expose students to the excitement of computational thinking in action. This vertical integration results in a hands-on, active learning experience that can occur while students are still deciding what to study as undergraduates. InspireCT will revitalize undergraduate computing education by engaging students in team project applications of computing much earlier than is done today. The project includes participants at four levels of computing knowledge: pre-college students in grades 6-12, less experienced undergraduates, advanced undergraduates, and practicing professionals. <br\/><br\/>At the center of the project are advanced undergraduates and team projects typical of computing degree capstone experiences. The less experienced students are integrated into the excitement typical of capstone projects by activities appropriate to their experience level. The professionals provide projects and mentoring to ensure good connection with professional practice and actual applications of computational thinking.<br\/><br\/>InspireCT also makes use of mentoring - the project explores the impact of mentoring on student learning, and also examines the positive impact of the younger students seeing the successes of the more advanced students. This is expected to engender a positive attitude among less experienced students toward the study of computing. <br\/><br\/>Intellectual Merit - This project creates and disseminates a new approach to introducing and engaging students in computational thinking activities. This active learning approach is expected to improve student learning and to create a much more direct engagement with computing by \"doing\" rather than \"hearing about\" computational thinking. <br\/><br\/>The project focuses upon computational thinking concepts such as problem solving, abstraction, design, and thinking algorithmically. But the project also suggests that definitions of computational thinking need to include team level, collaborative efforts since this is how most professionals engage in computational thinking. Research indicates that understanding the collaborative and social aspects of computational thinking may be central to attracting more women students. <br\/><br\/>The project addresses significant challenges including shifts in instructional role, definition of appropriate activities for vertical integration, and changes in instructional role. At the same time, the project builds on a substantial base of theory and prior results in areas such as active learning, capstone projects, and gender equality in computing education. The theory and related work both indicate that the benefits could be very substantial if this project is successful in addressing the challenges and meeting the goals. <br\/><br\/>Broader Impact - InspireCT impacts students at both the pre-college and undergraduate levels. Sparking student interest at that earlier age and improving learning outcomes via active learning constitutes a potentially transformative impact on computing education. The social and applied aspects of this approach also provide key characteristics that research shows are effective in attracting women to computing. The community building aspect of the project includes both pre-college and undergraduate instructors. The InspireCT activities are organized to help identify and establish a series of collaborations between pre-college instructors and undergraduate faculty.","title":"CPATH-2: Collaborative Research: From Middle School to Industry: Vertical Integration to Inspire Interest in Computational Thinking","awardID":"0939059","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["520022"],"PO":["564181"]},"159072":{"abstract":"Computer science foundation-building courses at the freshman and sophomore levels pose the greatest stumbling blocks to undergraduate students' learning. CS student enrollment has declined over 60% nationwide, even though the demand for skilled professionals was increasing. There is an urgent need for a more effective CS learning model. <br\/><br\/>The main purpose of this research is to enrich the context of the CS learning process which is important from motivational and educational perspectives. This project investigates a verification-driven learning model that facilitates students' involvement in real-world computing tasks starting from their early computing courses and continuing throughout their entire studies in computing. This model can significantly reduce the prerequisites for students to study real-world problems in their early years. The students are tasked to validate the functionality of software, execute programs, test parts of systems (pre-decomposed subsystems and components), and locate possible errors. Such seemingly complex high-level tasks can be done by novice students because software verification does not require design and implementation, and can be turned into a learn-by-example process with adequate preparation. This kind of preparation is wrapped in a Verification-Driven Learning Case, which defines the configuration to support a verification-driven learning activity, and consists of elements such as the justification of the system's existence, the requirement specification, description of the functionality, a set of test cases, and the decomposition of the system. <br\/><br\/>The foundation of the verification-driven learning model lies in software testing theories and techniques. Frequent and progressive exercises on verification will prepare the students for formal specifications. To realize the learning model, this project will produce Learning Cases based on faculty research including computer security, bioinformatics, geographic information systems, database and data mining techniques, remote sensing, and fuzzy set techniques. The Learning Cases will expose the students to working software systems that serve a real-world purpose in scientific research, engineering development, or social networks. <br\/><br\/>This project will particularly advocate computer science education in under-represented minority and woman students. This learning approach will also help adult students who have rich experience in various areas but need to reposition themselves in the work force. The final goal of this project is to revitalize the CS programs and produce more competent graduates capable of computational thinking.","title":"CPATH-1: Collaborative Research: a Verification-Driven Learning Model that Enriches CS and Related Undergraduate Programs","awardID":"0939102","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425180,425181,"466202"],"PO":["565264"]},"150909":{"abstract":"Massive energy consumption is an escalating threat to the environment. Large-scale computational grids consume a substantial amount of energy, and <br\/>their energy requirements for powering and cooling are becoming comparable to the costs of acquisition. There is a lack of generally applicable methods for reducing energy consumption while ensuring good quality of service. This project will develop GridPac (Grid with Power-Aware Computing), a middleware environment that will allow grid managers and service providers to schedule multiple workflows across a distributed grid for system-wide optimization. GridPac will be based on a novel framework to support a variety of task-level workflows. The main features of this work are to develop: <br\/><br\/>(a) Novel static and dynamic algorithms for scheduling single and multiple workflows, which can be flexibly utilized by service providers in scalable grid environments. <br\/><br\/>(b) Control algorithms to account for dynamic adjustment of schedules using energy monitoring of the grid resources. <br\/><br\/>(c) Extensive benchmarking using a suite of commonly used grid workflows. <br\/><br\/>(d) A prototype middleware to assist IT organizations to better support their users while reducing energy costs. <br\/><br\/>The proposed work will lead to original scholarly contributions while harnessing the usage of computational grids. The project carries tremendous potential for economic, environmental, and societal impact. We will initiate new graduate and undergraduate level courses on related topics, and develop relevant tutorials, which will help to create awareness and educate a large audience on a critically important research topic.","title":"CSR: Medium: Collaborative Research: GridPac: A Resource Management System for Energy and Performance Optimization on Computational Grids","awardID":"0905187","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563791"],"PO":["564778"]},"158280":{"abstract":"This project seeks to create a framework for narrative-centered computing (NCC) that will help children reason more effectively about (a) the distributed chains of causation that mediate environmental change, and (b) how they can intervene effectively within those chains. The NCC framework begins with a new mechanism for computational storytelling called spatiotemporal anchoring. Spatiotemporally anchored stories consist not of a linear \"filmstrip,\" but instead of a network of story nodes. Each node depicts a small element of the overall plot, and is anchored to a specific location in space and time. To advance the story, users explore a rich geographical representation of the relevant spatiotemporal locale, discovering story nodes and the interconnections between them. Because nodes can be anchored at variable levels of spatiotemporal resolution and interlinked in non-linear ways, exploring these narratives will help children to develop more nuanced abilities for reasoning about distributed causation and variable scale. These abilities, in turn, will translate into more effective engagement with environmental issues. <br\/><br\/>While focusing on a particular topic in education, this project seeks to develop a new information technology method for enhancing human cognitive abilities in general. A striking feature of our global environmental predicament is the disparity between the breadth of the problem and the limited nature of humanity's current response. This disconnection may reflect underlying limitations on our intuitive cognitive and emotional processes. As organisms that are adapted to \"humansized\" scales of complexity and causation, we lack effective means for reasoning about the kinds of temporally, spatially, and socially distributed interactions that drive environmental phenomena. This innovative research seeks to address this problem and to overcome our difficulties in reasoning about distributed data by focusing instead upon our substantial ability to connect to stories.<br\/><br\/>The NCC framework also includes novel interaction mechanisms through which users can influence unfolding events in a story world via targeted behaviors in the real world. These mechanisms will allow children to see how their own environmentally relevant patterns of behavior, mediated by intuitively understandable causal mappings, could cause positive or negative changes in a story ecosystem. This feedback between user's actions and the unfolding story will have powerful implications for children's developing sense of environmental responsibility. The data that drives these interaction mechanisms will also provide a natural means of evaluating the effectiveness of this research. As a way of testing and refining the NCC framework, the research will include the creation of a testbed interactive narrative, to be deployed online and as a temporary science museum exhibit. This narrative will use spatiotemporal anchoring along with video and traditional cinematographic techniques to dramatize the interactions that take place within a representative California ecosystem, for example, a marine environment in which sea otters, kelp forests, and sea urchins all interact. The behavioral impact and educational effectiveness of this narrative will be evaluated both via the aforementioned data collection mechanisms as well as through interviews with users. <br\/><br\/>This research will make a significant contribution to Human-Centered Computing by developing a novel approach to embedding complex distributed phenomena in an interactive narrative format. The spatiotemporal anchoring technique developed here will be useful not just in the context of the present environmental system, but in a variety of other domains such as formal pedagogy (e.g., interactive narratives for understanding other STEM topics), social networking, games (e.g., massively multiplayer worlds in which players create story nodes to drive the plot), and personal information architecture (e.g., a geographically-anchored personal life history device). By focusing on children as the target audience, this research will also make substantial contributions to the emerging domain of child-centered computing. In particular, this work will lay the foundation for further investigation into how story and narrative can be used to create computational systems that even very young children can readily utilize. The environmental themes of the system will also conform to both national and California state guidelines for science education, thus giving it the potential to be broadly deployed in formal classroom settings as well as in informal learning contexts such as homes and science museums.","title":"Narrative-Centered Computing for Childhood Environmental Awareness","awardID":"0934672","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[422697],"PO":["564456"]},"159073":{"abstract":"Natural science has come to recognize and study phenomena that recur at multiple scales of space and time. This recognition has allowed fundamental principles to be exhibited in full universality and has helped energize cross-disciplinary work in the sciences. The team at Northern Kentucky University conjectures that a similar energizing of cross-disciplinary work in the informatics domain can be accomplished by likewise focusing on computational phenomenon occurring at multiple scales. They propose to develop, deploy, disseminate, and assess a curriculum model that is based on this notion. Seen from a computational perspective, the range of scales is vast. From elementary particles to the planet itself, computation occurs at many levels. This way of organizing computational phenomena across distinct scales is an alternative way of addressing the ?principles? approach to computing pedagogy. NKU will explore and assess the effectiveness of this alternative approach. Encouraging students to see computation operating on many scales can deepen their appreciation for computational thinking (CT) across wide variety of disciplines. This can help combat the insular pull of computer science pedagogy that can arise from a narrow focus on code and technology for its own sake. This project uses the College of Informatics at Northern Kentucky University to implement a model based on this vision. The College was formed in 2005, bringing together three departments: Communication, Computer Science, and Business Informatics (formerly Information Systems). The model deploys computational thinking in the curriculum at two levels of resolution. All students who have majors in the college (about 1100 students with majors ranging from Journalism to Information Technology) will enroll in a Principles of Informatics course that exposes them to computational thinking at many scales. Majors in Computer Science go beyond this to work through a full curriculum that has been reframed and extended to reference the multiple scales model. The dissemination of an accessible and appealing curriculum framework, one that motivates such students to apply computational thinking to a wide range of workplace situations, should provide a rich set of resources upon which other metropolitan universities, each with their distinctive sets of cross-disciplinary expertise, may build.","title":"CPATH-1: Informatics at Multiple Scales","awardID":"0939103","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["441347","425187","425188",425187,425188],"PO":["565136"]},"159084":{"abstract":"This program aims to revitalize undergraduate computing education through the development of a computational science minor targeted to undergraduate majors in science and engineering. These majors represent a broad community of learners for whom computation is an increasingly critical tool. Modern scientific and engineering applications of significant complexity require high-performance computing solutions, and scientists and engineers require computational thinking competencies to achieve such solutions.<br\/><br\/>The project introduces concurrent, parallel, and distributed computing concepts, techniques, and patterns early in the curriculum. The advent of multi-core processors at the commodity level, necessitated by the efforts to prolong Moore's law, have made understanding these topics a critical learning outcome. The overall effect of this project will thus be to teach computational thinking competencies, modern software design methods, high-performance computing, and scientific computing to a broad community of learners sorely in need of them. By renovating the curriculum with non-computer science majors in mind, computer science majors will also benefit significantly because concurrent, parallel, and distributed computational methods will be infused into the curriculum earlier than they are normally encountered. The computer science curriculum will also be revitalized by introducing real-world examples from science and engineering that have computational interest.<br\/><br\/>The demographics of science and engineering are different enough from traditional computer science that underrepresented groups in computing will receive significant exposure to core ideas of computational thinking and computing. The diffusion of computational techniques throughout a variety of disciplines will also change the way computational thinking and computation are perceived and taught within the core computer science discipline. A rigorous evaluation plan throughout all phases of the project will measure quantitatively the changes in the preparation of undergraduates for scientific computing by the proposed computational sciences minor, leading to a greater likelihood of being adopted or adapted by other institutions. By improving the computational skills of scientists and engineers, at Vanderbilt and elsewhere, the project will achieve the broader impact of improving science education in the United States, making students far better prepared for the work force and advanced graduate training.","title":"CPATH-1: Revitalizing Computing Education through Computational Science","awardID":"0939164","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425237,425238,"535919","486038"],"PO":["565264"]},"159260":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940358","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":[425746],"PO":["561855"]},"159052":{"abstract":"Computer science foundation-building courses at the freshman and sophomore levels pose the greatest stumbling blocks to undergraduate students' learning. CS student enrollment has declined over 60% nationwide, even though the demand for skilled professionals was increasing. There is an urgent need for a more effective CS learning model. <br\/><br\/>The main purpose of this research is to enrich the context of the CS learning process which is important from motivational and educational perspectives. This project investigates a verification-driven learning model that facilitates students' involvement in real-world computing tasks starting from their early computing courses and continuing throughout their entire studies in computing. This model can significantly reduce the prerequisites for students to study real-world problems in their early years. The students are tasked to validate the functionality of software, execute programs, test parts of systems (pre-decomposed subsystems and components), and locate possible errors. Such seemingly complex high-level tasks can be done by novice students because software verification does not require design and implementation, and can be turned into a learn-by-example process with adequate preparation. This kind of preparation is wrapped in a Verification-Driven Learning Case, which defines the configuration to support a verification-driven learning activity, and consists of elements such as the justification of the system's existence, the requirement specification, description of the functionality, a set of test cases, and the decomposition of the system. <br\/><br\/>The foundation of the verification-driven learning model lies in software testing theories and techniques. Frequent and progressive exercises on verification will prepare the students for formal specifications. To realize the learning model, this project will produce Learning Cases based on faculty research including computer security, bioinformatics, geographic information systems, database and data mining techniques, remote sensing, and fuzzy set techniques. The Learning Cases will expose the students to working software systems that serve a real-world purpose in scientific research, engineering development, or social networks. <br\/><br\/>This project will particularly advocate computer science education in under-represented minority and woman students. This learning approach will also help adult students who have rich experience in various areas but need to reposition themselves in the work force. The final goal of this project is to revitalize the CS programs and produce more competent graduates capable of computational thinking.","title":"CPATH-1: Collaborative Research: A Verification-Driven Learning Model that Enriches CS and Related Undergraduate Programs","awardID":"0939015","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["556350",425117],"PO":["565264"]},"159063":{"abstract":"Abstract<br\/><br\/>This CPATH award funds an extension of a CPATH community building project between Michigan State University (MSU), Lansing Community College (LCC), and the Corporation for Skilled Workforce (CSW) to prepare a globally competitive engineering workforce that is able to apply Computational Thinking (CT) to a broad range of societal challenges and opportunities. Broadly defined in the context of the engineering practice, computational thinking involves solving problems and designing systems by making use of fundamental computer science concepts. The goal is to redesign the role of computing within the engineering programs at MSU and LCC to develop CT competencies informed by industry needs by infusing CT learning opportunities into the undergraduate engineering curriculum. <br\/><br\/>The project has several major activities. A primary focus is on developing and implementing instructional modules in Chemical Engineering and Civil Engineering at MSU and the pre-engineering courses at LCC. The approach is to identify and implement authentic problems for curricular revision in two engineering disciplinary curricula at MSU and the engineering transfer curricula at LCC and to identify the computational principles for each disciplinary epitome and use these principles to help design the instructional modules. The team plans to develop appropriate materials to support the disciplinary faculty who will be teaching the modules. Comprehensive evaluation is to be conducted including the design and implementation of quasi-experimental evaluation and assessment components to document CT competencies in the engineering students. Finally, the group plans to improve information and knowledge exchange via the CPACE Engineering Talent Development Network and dissemination and communication efforts.<br\/><br\/>The intellectual merit lies with the strong interdisciplinary team that plans to redefine the role of computing within engineering programs and the collaborative network including industry partners that are involved. The project includes identification of computational thinking concepts and correlation with engineering competencies. The research results should inform future innovation in multiple engineering disciplines. <br\/><br\/>The broader impacts include the diverse group of students and stakeholders involved and engaged. Transfer from Lansing Community College into engineering programs is to be facilitated and students should be better prepared using the resources of this project. Dissemination of the resources and model is broad, thus allowing for replication and adaptation on a national scale.","title":"CPATH-2: CPACE II: Implementing Constituency-driven Curricular Change that Integrates Computational Thinking Across Engineering Disciplines","awardID":"0939065","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425147,425148,425149,"562208",425151],"PO":["564181"]},"154080":{"abstract":"This project focuses on the task of providing a consistent, semantic interpretation of all components of an image of an outdoor scene. The image is automatically segmented into large regions, each of which is a coherent scene component that is labeled with a rough geometric configuration (distance from the camera and surface normal), and with one of a subset of semantic classes, which include both background classes (such as water, grass, or road) and specific object classes (such as person, car, cow, or boat). The approach is based on the development of a holistic probabilistic model (a Markov random field) whose parameters are automatically learned from data. The model exploits both scene features and contextual relationships between scene components (e.g., cows are typically found on grass and boats on water). It also utilizes object shape and appearance models to identify specific object instances in the image. To address the complexities of reasoning using these richly structured models, new probabilistic inference algorithms are developed.<br\/><br\/>This project helps train graduate and undergraduate students within the PI's group, as well as students in an annual project class in this area. The project also develops significant infrastructure, including an extensive data set of labeled images and efficient inference algorithms, which are freely distributed to the research community. <br\/><br\/>The ability to provide a coherent interpretation of a scene composition is an important step towards automatic image annotation, with benefits both for image retrieval and for providing image summaries to visually impaired users.","title":"RI: Small: Region-based Probabilistic Models for Descriptive Scene Interpretation","awardID":"0917151","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[409972],"PO":["564316"]},"154091":{"abstract":"Electronic System Level ( ESL ) designs , specified behaviorally using<br\/>high-level languages such as SystemC , raise the level of hardware<br\/>design abstraction . This approach crucially depends on behavioral<br\/>synthesis , which compiles ESL designs to Register Transfer Level ( RTL )<br\/>designs . However , optimizations performed by synthesis tools make<br\/>their implementation error-prone , undermining the trustworthiness of<br\/>synthesized hardware . <br\/><br\/>This research develops a mechanized infrastructure for certifying<br\/>hardware designs generated by behavioral synthesis . It entails<br\/>developing a certified \" reference flow \" of synthesis transformations . <br\/>The reference flow is disentangled from the workings of a production<br\/>synthesis tool through new formal structure called \" clocked control<br\/>data flow graph \" ( CCDFG ) formalizing internal design representation . <br\/>Given an ESL design and its synthesized RTL , certification entails the<br\/>following automatic steps : ( 1 ) extracting initial CCDFG ; ( 2 ) applying<br\/>certified \" primitive transformations \" from the reference flow ,<br\/>following the application sequence by the synthesis tool , and ( 3 )<br\/>checking equivalence between the transformed CCDFG and RTL . Theorem<br\/>proving is used to certify primitive transformations off-line ;<br\/>equivalence checking accounts for low-level transformations and<br\/>manual tweaks . The correspondence between the transformed CCDFG and<br\/>the synthesized hardware makes equivalence checking efficient . <br\/><br\/>The project facilitates development of scalable and trustworthy<br\/>hardware : adoption of ESL approach expedites design cycle while formal<br\/>analysis guarantees trust in the synthesized hardware . The reference<br\/>flow makes explicit key design invariants implicitly assumed by<br\/>synthesis tools , facilitating development of more aggressive synthesis<br\/>tools . Finally , the tight integration of two complementary techniques<br\/>--- model checking and theorem proving --- in the certification is<br\/>applicable to other domains .","title":"TC: Small: Collaborative Research: Trustworthy Hardware from Certified Behavioral Synthesis","awardID":"0917188","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["559275"],"PO":["565327"]},"159360":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\" <br\/><br\/>GENI is a unique virtual laboratory for at-scale network experimentation on future internets. Dynamic and adaptive, GENI opens up new opportunities for significant socio-economic impact. GENI will support at-scale experimentation on a suite of shared, heterogeneous, highly instrumented infrastructure; enable deep programmability throughout the network, promoting innovations in network science, security, technologies, services, and applications; and provide collaborative and exploratory environments for academia, industry and the public to catalyze groundbreaking discoveries and innovation. <br\/><br\/>Spiral development is the core strategy for providing a concrete focal point for community debate and engagement moving forward. GENI Spiral 1 launched in October 2008 and is making rapid progress to create a set of end-to-end GENI prototypes by October 2009 with broad academic and industrial participation and strong competition in the design and implementation of GENI's control framework. Based on lessons learned in Spiral 1, the GPO issued a 2nd solicitation in 2008 to fill critical gaps in GENI's architecture, especially security requirements and architecture, experiment workflow tools and user interfaces, and prototypes for instrumentation and measurement. This award funds 33 new projects, which build upon the achievements of Spiral 1 and move the project into Spiral 2 with federation and shakedown experiments that will prove critical in guiding progress in GENI system design.","title":"GENI D&P Control Framework","awardID":"0940805","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["521729"],"PO":["564993"]},"159064":{"abstract":"This CPATH award supports a curriculum initiative to inject computational thinking capability into computer science and gerontology disciplines at the local and state levels with a plan to conduct, assess, and to analyze the outcomes to guide future nationwide efforts. The proposal consists of three major components: Developing a new interdisciplinary curriculum track in Gerotechnology culminating in an undergraduate certificate; Transforming the existing SmartHome Laboratory at Iowa State University into an open project platform, so that experiments and projects on the Smart Home can be run from remote locations; and Establishing an open source community on software based on service-oriented architecture to support collaborative projects. The new track is strongly supported by the latter two components to ensure that the proposed curriculum is supported by meaningful materials, examples, and projects and that enable community building between disciplines, stakeholders, and institutions.<br\/><br\/>Intellectual Merit: The proposed work introduces a new pedagogy that is interdisciplinary, incorporates the recent developments in multiple disciplines, and focuses on hands-on and practical experience. The SmartHome Laboratory allows students to make lasting contributions to real and meaningful applications and to collaborate with students from other colleges and backgrounds. Computer science students will be able to demonstrate their computational thinking competences through human-centered learning opportunities. Students from outside computer science should have opportunities to work in teams in order to fully utilize modern technologies that have begun to transform their professions. A competent team of experts in the fields and experienced practitioners has been assembled to ensure success of the project. The main national impact should be the creation a model of a program for a tightly focused application, gerontechnology, a new collaborative program model for the nation. <br\/><br\/>Broader Impact: In addition to the main goal of injecting computational thinking capabilities into the curriculum, the investigators plan proactive recruiting and support of a diverse group of students, including those with disabilities, females, and underrepresented minorities. The proposed curriculum provides stronger incentives and better accommodations to these groups while disseminating exciting, immediately applicable, cutting edge technologies. The results from learning and project activities can be disseminated immediately to the aging population and people with disabilities through service learning courses and family outreach extension.","title":"CPATH-1: Experimenting with an Open Platform for the New Interdisciplinary Study on Gerontechnology","awardID":"0939075","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425153,425154,425155,425156,425157],"PO":["564181"]},"159075":{"abstract":"Computer science foundation-building courses at the freshman and sophomore levels pose the greatest stumbling blocks to undergraduate students' learning. CS student enrollment has declined over 60% nationwide, even though the demand for skilled professionals was increasing. There is an urgent need for a more effective CS learning model. <br\/><br\/>The main purpose of this research is to enrich the context of the CS learning process which is important from motivational and educational perspectives. This project investigates a verification-driven learning model that facilitates students' involvement in real-world computing tasks starting from their early computing courses and continuing throughout their entire studies in computing. This model can significantly reduce the prerequisites for students to study real-world problems in their early years. The students are tasked to validate the functionality of software, execute programs, test parts of systems (pre-decomposed subsystems and components), and locate possible errors. Such seemingly complex high-level tasks can be done by novice students because software verification does not require design and implementation, and can be turned into a learn-by-example process with adequate preparation. This kind of preparation is wrapped in a Verification-Driven Learning Case, which defines the configuration to support a verification-driven learning activity, and consists of elements such as the justification of the system's existence, the requirement specification, description of the functionality, a set of test cases, and the decomposition of the system. <br\/><br\/>The foundation of the verification-driven learning model lies in software testing theories and techniques. Frequent and progressive exercises on verification will prepare the students for formal specifications. To realize the learning model, this project will produce Learning Cases based on faculty research including computer security, bioinformatics, geographic information systems, database and data mining techniques, remote sensing, and fuzzy set techniques. The Learning Cases will expose the students to working software systems that serve a real-world purpose in scientific research, engineering development, or social networks.<br\/><br\/>This project will particularly advocate computer science education in under-represented minority and woman students. This learning approach will also help adult students who have rich experience in various areas but need to reposition themselves in the work force. The final goal of this project is to revitalize the CS programs and produce more competent graduates capable of computational thinking.","title":"CPATH-1: Collaborative Research: a Verification-Driven Learning Model that Enriches CS and Related Undergraduate Programs","awardID":"0939108","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425195,"450955",425197,425198],"PO":["565264"]},"154092":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The goal of this proposal is to devise and implement a scalable virtual machine that includes scalable garbage collectors, profilers and just-in-time (JIT) compilers.<br\/><br\/>As hardware vendors deliver chip multiprocessors (CMPs) as the next-generation general-purpose computing substrate, programmers are increasingly choosing managed languages for their next generation applications. The virtual machine (VM) stands between the two, integrating them together. However, VMs are not yet capable of providing scalable performance to applications on parallel systems composed of CMPs. VMs are limited in part because key features, such as dynamic profiling, compilation, and garbage collection, are often not themselves scalable. This VM scalability bottleneck is an impediment to application scaling. For example, because VMs are oblivious to application data partitioning, they can introduce unnecessary communication such as false sharing. <br\/><br\/>This project seeks to solve this problem by designing and implementing scalable virtual machine (SVM) services. SVM includes novel dynamic profilers, just-in-time (JIT) compilers, and garbage collectors that are themselves scalable and support parallel applications. The project explores how to design and build a framework for parallel dynamic analysis, JIT compilation, and garbage collection that uses novel cost models of the application, analysis, JIT, and collector work to optimize for scalable high-performance. In particular, analysis, JIT, and garbage collector work is divided and scheduled in novel ways to mirror application partitions and threads.<br\/><br\/>SVM will be developed within a Java Virtual Machine, but the algorithms will apply to other managed languages such as C\\#, JavaScript, Python, and Ruby. The investigators will make both SVM and parallel applications publicly available, adding to the national research infrastructure.","title":"CSR: Small: Scalable Applications Start with Scalable Virtual Machine Services","awardID":"0917191","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["519591"],"PO":["561889"]},"159350":{"abstract":"Intelligence and Security Informatics (ISI) has been established as an interdisciplinary subject that focuses on the development and use of advanced information technologies, including methodologies, models and algorithms, infrastructure, systems, and tools, for local, national\/international, and global security related applications through an integrated technological, organizational, behavioral, and policy based approach. The international conference was first held in 2003; ISI 2009 will be held in Richardson Texas. This award will support student scholarships to attend the meeting, encouraging participation from a wide range of students.","title":"IEEE Intelligence and Security Informatics Conference","awardID":"0940743","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["551857","562519","558641"],"PO":["565136"]},"159020":{"abstract":"Computational concepts, techniques, and ideas have spread through many ?traditional? disciplines in recent decades, resulting in fields such as Computational Biology and Computational Linguistics that explicitly acknowledge their computational aspects. At the same time, however, most students in such disciplines receive a relatively narrow education that does not expose them to the wide range of computational concepts and techniques pertinent to their fields of study. The University of Arizona aims to address this situation via a campus-wide collaborative effort to train students in all fields in information science and computational thinking. This project develops, implements, and evaluates core components of the undergraduate curriculum for the School of Information Sciences, Technology, and Arts (SISTA) at the University of Arizona. The vision of SISTA is to identify how ideas in computational thinking, information sciences, and technology apply across a variety of disciplines; to provide a broad foundation in information science and computational thinking for students in many majors; and to foster students? awareness of interdisciplinary relationships starting with their first year at the university. Additionally, new relationships between departments across campus will be formed by engaging faculty in contributing to seminars on issues in computational thinking in their disciplines and in bringing together and supporting multi-disciplinary faculty teams to design, implement, and teach the new courses. The model is intended to be transferable to other institutions. Results and evaluations will be broadly disseminated.","title":"CPATH-2: Computational Thinking as a Foundation for Interdisciplinary Undergraduate Education","awardID":"0938763","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["524130",425015,"557891","550173","552111"],"PO":["565136"]},"159394":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Georgia Institute of Technology proposes an innovative program - Operation Reboot - that assists both unemployed IT workers who wish to make a career switch into high school teaching and existing high school teachers who wish to become more proficient in the computer science content area. The IT workers and existing teachers will be paired. Together, they will co-teach at least two computing classes over a year. During that year (and possibly the next), the IT worker will participate in the Georgia Teacher Alternative Preparation Program (GaTAPP) which provides teaching certification to individuals who hold a bachelor's degree but not a teacher education degree. GaTAPP serves unemployed workers, returning troops, and anyone else wishing to make a career switch. In Operation Reboot, the IT worker and the existing teacher will be mentored by an exemplary computing teacher, and they will participate in a successful Georgia Tech program that provides summer workshops and year-round professional development for computer science teachers. Operation Reboot participants will earn a computer science endorsement.<br\/><br\/>A teacher's motivation, self-efficacy, job satisfaction, and commitment to teaching are closely linked with their professional identity. Through co-teaching, the courses needed for GaTAPP, mentoring, and the teacher workshops at Georgia Tech, this program will transform the IT worker's identity into that of a computing teacher. Specific outcomes include (1) the transformation of 30 unemployed IT professionals into high school computing teachers, (2) improvements to the content knowledge and pedagogical content knowledge of at least an additional 30 existing high school computing teachers, (3) an increase in the number and quality of computing courses offered at the participating schools, and (4) an improvement in the computing education of thousands of students. Beyond its affect in Georgia, this program could provide a model for other states working to improve the quality of education in the face of a severe shortage of teachers with computer science content knowledge.","title":"Operation Reboot: Transforming Unemployed IT Workers into High School Computing Teachers","awardID":"0940932","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7967","name":"EDUCATION AND WORKFORCE"}}],"PIcoPI":["521278","521279"],"PO":["561855"]},"159284":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940475","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["494943"],"PO":["561855"]},"149253":{"abstract":"For researchers and developers of creativity support tools, online spaces of \"user-generated content\" (UGC) such as the video-sharing site Youtube.com and the photo-sharing site Flickr.com are of particular interest. These systems are massive, diverse spaces for creative production, interaction, collaboration and appropriation. This project investigates how specific UGC systems, those we call Creative Content Systems (CCS), are being used by literally millions of people to generate and disseminate their creative products. A better understanding of the dynamics of participation in such systems would allow us to both design more effective system support for creative activities in future UGC system, as well as providing us with a richer model of IT-enabled creativity. <br\/><br\/>The project's intellectual merit comes from three contributions. First, this work will generate enhanced models of creative practice in online communities. Amateur\/professional interactions have become increasingly prevalent in online communities and the differences between these populations in creative practice and intended audiences needs to be better understood and supported. Second, the research will generate and assess design recommendations for next generation creative support technology. Generating a better understanding of the common and distinct factors of amateur and professional creative practice is a necessary precondition for evolving the next generation of support tools for creative individuals and creative communities. Third, this work will generate enhanced knowledge of successful facilitation of amateur activity. Via the design recommendations for next generation CCS design, creative professionals will benefit from knowledge and technology to help them leverage amateur creativity and contribution. Leveraging the success of these systems will lead to broader impacts by encouraging innovation and creativity beyond this project's current participants and systems. Though this project is set in the context of creative cultural activity, the findings will be more broadly applicable to increasing participation in STEM-related projects that wish to enlist amateur contributions and volunteers. The results from this study will be disseminated broadly to academic communities including, but not limited to, Creativity and Cognition, CSCW, and CHI.","title":"CreativeIT Pilot: Learning from Creativity in the Wild: Leveraging the Success of Creative Content Systems","awardID":"0855865","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":[397790],"PO":["562669"]},"159076":{"abstract":"This conceptual development and planning project by the New York City College of Technology is creating a model of viable general education curriculum revision based on the tenets of Computational Thinking (CT), and defining changes in the College?s organizational and technological infrastructure needed to support such fundamental institutional transformation. This model is needed to be viable under current conditions of rapid and continuous changes in computer and information technologies and is applicable across different disciplines.<br\/><br\/>INTELLECTUAL MERIT. Computational thinking has become the essential competency for the workforce of the future. Today, the world of information technology is changing so fast that any isolated effort of computational curriculum update is likely to become obsolete almost as soon as it is completed. The intellectual merit of this Conceptual Development and Planning project in the redesign of City Tech?s curriculum and in the transformation of its organizational and technological infrastructure as:<br\/>? continuous instead of episodic and short-lived;<br\/>? systemic instead of local and isolated; and<br\/>? based on tenets of computational thinking.<br\/><br\/>To achieve this, the project team is taking a multi-level approach to ensure that no level of organizational infrastructure has been missed and that all of the participants (administration, faculty, staff, students, and wider community) are engaged and that all the elements of the system are mutually reinforcing. An important part of this process is be development of Key Indicators of computational thinking?the metrics that can be used to assess the progress of transformational effort, and course and program outcomes. These is also being used to serve as the basis for developing Computational Thinking Literacy in the college core. A set of the exemplary interdisciplinary case studies, instructional prototypes and curriculum units are being developed by the department groups and disseminated to the college and wider community.<br\/><br\/>BROADER IMPACTS: Because City Tech is a Hispanic Serving Institution and one of the most diverse institutions of higher education in the country, this program will have impact on an important urban community that is underrepresented in STEM. Due to advances of computer and information technology, for the first time in human history, any person, with or without scientific credentials, with or without special means, may have access to ongoing research activities. Discovering new ways of teaching and learning through interdisciplinary computational curricula and providing organizational and technological infrastructure for these activities will give the students and the broader community the ability to take advantage of these unique and endless possibilities, and will thereby fulfill the educational imperative of the college?s mission.<br\/>The web of interrelationships among departments and schools within this college that this project is creating will have far-reaching and long-lasting effect. Dissemination activities through the web will be continuous and systemic, reaching outward through internal and external advisory boards and the online community.","title":"CPATH-1: Planning for Institutional Transformation through Computational Thinking","awardID":"0939120","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425200,"425202",425202,425203,"530494",425205],"PO":["564181"]},"154071":{"abstract":"Recent advances in autonomous agents research are pushing our society closer to the brink of the widespread adoption of autonomous agents in everyday life. Applications that incorporate agents already exist or are quickly emerging, such as domestic robots, autonomous vehicles, and financial management agents. Reinforcement learning (RL) of sequential decision making is an important paradigm for enabling the widespread deployment of autonomous agents. However, a few notable successes notwithstanding, state-of-the-art reinforcement learning algorithms are not yet fully capable of addressing generic large-scale applications. <br\/><br\/>This project is advancing in four directions to scale-up application of RL systems. Specifically, the project is (1) developing algorithms to automatically structure the input, output, and policy representations for learning; (2) introducing parallelizable reinforcement learning algorithms so as to exploit modern parallel architectures; (3) unifying abstraction and hierarchical reasoning with model-based learning for the purpose of enabling intelligent exploration of large-scale environments; and (4) enabling reinforcement learning algorithms to benefit from low-bandwidth interactions with human users. Finally, we intend to unify the four research thrusts above into a single algorithm and conduct empirical evaluation on real-world\/large-scale applications, to include biped robot balancing and walking, robot soccer in simulation and with real robots, and a full-size autonomous vehicle capable of planning paths in an urban environment.<br\/><br\/>In addition to research advances and implications for improving national infrastructure, the project will contribute to undergraduate and graduate curriculum development.","title":"RI: Small: Efficient Reinforcement Learning for Generic Large-Scale Tasks","awardID":"0917122","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["553684"],"PO":["565035"]},"154082":{"abstract":"Freedom of speech is a founding principle of democratic society, and the Internet has become one of the most effective and common means of conveying expression that is likely to be controversial or suppressed. One threat to the freedom of speech online is the now widespread practice of Internet censorship by both private and state interests. These censors use a variety of social and technological means to limit availability or expression of information, stifling the democratic process.<br\/><br\/>This project is focused on developing overlay networks that promote freedom of speech by circumventing social and technological censorship measures. The project will develop new software and protocols for secure overlay networks that satisfy three distinct security goals: relationship privacy, membership hiding, and blocking resistance. A secondary focus of the project is on understanding these security goals and the relationships between them, and investigating the extent to which existing systems satisfy these properties.<br\/><br\/>The project will train undergraduate and graduate students to perform and apply research from a variety of disciplines (including cryptography, networking, algorithms, and coding theory). The project also develops new intellectual infrastructure by introducing the new notion of membership hiding as a security problem. Finally, the results of the project are expected to include the broad dissemination of free software that promotes freedom of expression on the Internet, against regimes that strongly oppose such expression.","title":"TC: Small: Scalable Censorship Resistant Overlay Networks","awardID":"0917154","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["422435","548224"],"PO":["565136"]},"154093":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/>Increasingly, computation and storage are moving into a planetary cloud accessible across ever-widening Internet pipes. Unfortunately, asynchrony, failures, and heterogeneity make it difficult to harness available computing power and storage, with inherent tradeoffs in performance, data consistency, and availability. The goal of this research is to raise the level of abstraction for building planetary-scale services, in particular to: i) make fault tolerant and high-performance storage a baseline abstraction for a variety of services, and ii) simplify the process of building extensible and distributed data structures that match the requirements of a range of services.<br\/>Taken together, this project has the potential to effect a qualitative shift in our ability to deploy next-generation high-performance and highly available network services. First, application developers will be able to leverage fault tolerant, locality-aware data storage as a given for their distributed applications. Second, the research will deliver primitives to ease the problem of deploying new distributed data structures. We will provide the abstractions to manage distribution, replications, and faults in these environments.<br\/>The broader impacts of this project will include leveraging our infrastructure to conduct studies of large-scale service architectures, first in advanced graduate courses and later in undergraduate courses, and a public release of the replication and extensible data structure software underlying our work for research and educational purposes.","title":"CSR: Small: System Support for Planetary Scale Services","awardID":"0917194","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485593","525660"],"PO":["565255"]},"158581":{"abstract":"This workshop aims to bring together leading scientists and practitioners in the domains of bibliometrics, informetrics, network and web science, digital libraries, academic policies, and open repositories for a public discussion on the quantitative evaluation of scholarly impact and value of publications. on scientific research. Quantitative evaluation of scholarly impact and value has historically been conducted on the basis of citation data. This approach is not always appropriate or accurate in the fast-paced, open, and interdisciplinary nature of scholarship which is, to a large degree, dependent upon digital data and sources. The workshop is meant to provide guidance and research agendas for further development of metrics for scientific impact and value. The workshop's intellectual merit is found in defining the scientific criteria and objectives that would lead to a more general community-acceptance of various impact metrics. The impact of science as traditionally measured is at the point of fundamental change as the digital research environment grows and attracts more participants. Novel impact metrics, that gain community acceptance, may lead to a more diverse and balanced scientific landscape in which the contributions of a larger and more diverse community are more equally recognized and valued.","title":"Workshop Proposal: Scholarly Evaluation Metrics: Opportunities and Challenges","awardID":"0936204","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[423773,"513429","478206"],"PO":["433760"]},"159043":{"abstract":"This CPATH project uses free open source libraries and tools for a student-centered,community-based video game development project called Mythic for the purpose of revitalizing interest in computing studies. The Mythic project is student centered in the sense that students define project goals, and it is community-based in the sense that students from different institutions, ranging from high school to community college to university, contribute to the development of a common project. The project promises to help revitalize computing education by engaging students in meaningful and enjoyable work activities that lead to greater mastery of computing concepts through the use of software development tools, the use of software libraries, and the use of computing concepts. Project investigators are also establishing internships with local game development companies to increase the relevance to students and assist faculty in aligning learning outcomes to meet the needs of industry.<br\/><br\/>The intellectual merit lies in the strong collaborative team with significant experience in game development and building real software in class settings. The project has an excellent conceptual foundation that could lead to new research findings in both video game development as well as in computing education.<br\/><br\/>The broader impacts involve the potential to attract a more diverse student population to computing fields. Students from the local community who go into the video game industry will serve as role models for younger students at the high school and college levels. Similarly, students going into computing jobs outside the video game industry will also demonstrate to younger students as well as their parents and teachers that focusing on video game development when young can result in the development of skills needed for rewarding careers later in life. Black and Hispanic students account for more than 50% of enrollments at the lead institution. Thus, the project helps to broaden the participation of these underrepresented groups in pursuing degrees in computing disciplines. The associated learning materials that are produced can serve as a resource for other institutions and as a foundation for collaborative research. This project activity should demonstrate to other departments and institutions the value of student-centered, community-based video game development projects to cultivate interest in and mastery of computational thinking in students from high school through university.","title":"CPATH-1: Revitalizing Computing Education through Community-Based Video Game Development Projects","awardID":"0938964","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425082,"548129",425084],"PO":["564181"]},"159055":{"abstract":"This project, InspireCT, employs vertically integrated project teams to expose students to the excitement of computational thinking in action. This vertical integration results in a hands-on, active learning experience that can occur while students are still deciding what to study as undergraduates. InspireCT will revitalize undergraduate computing education by engaging students in team project applications of computing much earlier than is done today. The project includes participants at four levels of computing knowledge: pre-college students in grades 6-12, less experienced undergraduates, advanced undergraduates, and practicing professionals. <br\/><br\/>At the center of the project are advanced undergraduates and team projects typical of computing degree capstone experiences. The less experienced students are integrated into the excitement typical of capstone projects by activities appropriate to their experience level. The professionals provide projects and mentoring to ensure good connection with professional practice and actual applications of computational thinking.<br\/><br\/>InspireCT also makes use of mentoring - the project explores the impact of mentoring on student learning, and also examines the positive impact of the younger students seeing the successes of the more advanced students. This is expected to engender a positive attitude among less experienced students toward the study of computing. <br\/><br\/>Intellectual Merit - This project creates and disseminates a new approach to introducing and engaging students in computational thinking activities. This active learning approach is expected to improve student learning and to create a much more direct engagement with computing by \"doing\" rather than \"hearing about\" computational thinking. <br\/><br\/>The project focuses upon computational thinking concepts such as problem solving, abstraction, design, and thinking algorithmically. But the project also suggests that definitions of computational thinking need to include team level, collaborative efforts since this is how most professionals engage in computational thinking. Research indicates that understanding the collaborative and social aspects of computational thinking may be central to attracting more women students. <br\/><br\/>The project addresses significant challenges including shifts in instructional role, definition of appropriate activities for vertical integration, and changes in instructional role. At the same time, the project builds on a substantial base of theory and prior results in areas such as active learning, capstone projects, and gender equality in computing education. The theory and related work both indicate that the benefits could be very substantial if this project is successful in addressing the challenges and meeting the goals. <br\/><br\/>Broader Impact - InspireCT impacts students at both the pre-college and undergraduate levels. Sparking student interest at that earlier age and improving learning outcomes via active learning constitutes a potentially transformative impact on computing education. The social and applied aspects of this approach also provide key characteristics that research shows are effective in attracting women to computing. The community building aspect of the project includes both pre-college and undergraduate instructors. The InspireCT activities are organized to help identify and establish a series of collaborations between pre-college instructors and undergraduate faculty.","title":"CPATH-2: Collaborative Research: From Middle School to Industry: Vertical Integration to Inspire Interest in Computational Thinking","awardID":"0939028","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["426637"],"PO":["564181"]},"154050":{"abstract":"Advancements in technology over the past decade are leading to a promising future for pervasive distributed computing (PDC), where access to information and services is provided anytime and anywhere around the world. The proliferation of Internet-scale applications poses new challenges for how future file systems are designed and managed to enable this future. The difficulty of these challenges grows with the number of users and the intensity of the data, and is further compounded by the need to support replication and consistency. However, previous file replication and consistency maintenance approaches are not efficient enough to be scalable for PDC. These two issues are typically addressed separately, despite the significant interdependencies between them. This research addresses this issue through the development of a file management system with Efficient and Reciprocal file Replication and Consistency maintenance (ERRC). The ERRC system will incorporate swarm intelligence based file replication and coordinated multi-factor-oriented file replication algorithms to achieve high efficiency in both file replication and consistency maintenance. The system also contains self-adaptive file replication and consistency maintenance mechanism that allows each node to determine the need of file replication and consistency maintenance in a decentralized manner. Understanding and insight gained as a result of this project will be disseminated through technology transfer to industry partners, in addition to publication and software release channels. The multi-disciplinary nature of this research also lends itself to cross-disciplinary education and well-rounded training of students.","title":"CSR: Small: Efficient and Reciprocal File Replication and Consistency Maintenance in Pervasive Distributed Computing","awardID":"0917056","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563519"],"PO":["565255"]},"157691":{"abstract":"The objective of this research is the transformation from static sensing into mobile, actuated sensing in dynamic environments, with a focus on sensing in tidally forced rivers. The approach is to develop inverse modeling techniques to sense the environment, coordination algorithms to distribute sensors spatially, and software that uses the sensed environmental data to enable these coordination algorithms to adapt to new sensed conditions. <br\/><br\/>This work relies on the concurrent sensing of the environment and actuation of those sensors based on sensed data. Sensing the environment is approached as a two-layer optimization problem. Since mobile sensors in dynamic environments may move even when not actuated, sensor coordination and actuation algorithms must maintain connectivity for the sensors while ensuring those sensors are appropriately located. The algorithms and software developed consider the time scales of the sensed environment, as well as the motion capabilities of the mobile sensors. This closes the loop from sensing of the environment to actuation of the devices that perform that sensing. <br\/><br\/>This work is addresses a challenging problem: the management of clean water resources. Tidally forced rivers are critical elements in the water supply for millions of Californians. By involving students from underrepresented groups, this research provides a valuable opportunity for students to develop an interest in engineering and to learn first hand about the role of science and engineering in addressing environmental issues.","title":"CPS: Medium: Collaborative Research: Physical Modeling and Software Synthesis for Self-Reconfigurable Sensors in River Environments","awardID":"0931348","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["526902"],"PO":["564728"]},"154072":{"abstract":"Stochastic inference problems arise naturally in many applications that interact with the world, such as natural language processing (NLP), robot control, analysis of social networks, and environmental engineering. Current real-world applications require inference mechanisms that can scale to thousands and more interactions. This project is scaling up and improving precision of automated inference and learning in dynamic partially observable domains, with later application to decision making, by combining the complementary computational strengths of logical and probabilistic methods. The inference and learning algorithms being developed are being assessed by theoretical and experimental means, with aims of improving question answering from text narratives and environment-state estimation for mobile robots. Examples of societal benefits are enabling people to access and examine details hidden in large amounts of textual information as well as enabling more helpful and autonomous mobile robots.","title":"RI: Small: Scaling Up Inference in Dynamic Systems with Logical Structure","awardID":"0917123","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["440709"],"PO":["562760"]},"154083":{"abstract":"Workload Shaping for Capacity and Power Provisioning in Storage Data Centers<br\/><br\/>Abstract<br\/><br\/>This award is funded under the American Recovery and Reinvestment<br\/>Act of 2009 (Public Law 111-5).<br\/><br\/>Tremendous growth in hosted services and data sharing are motivating a new generation of storage virtualization technologies that encompass the entire data center or ensembles of data centers. Accurate dynamic resource provisioning is critical to achieving cost-effective and environmentally-sensitive operation of these service centers in order to (i) reduce fixed costs for floor space, server hardware, and infrastructure for power distribution and cooling, (ii) lower the operational costs for management and electricity, and (iii) mitigate the hidden environmental and social costs of excessive energy use.<br\/><br\/>The goals of this project are to develop effective dynamic resource provisioning and scheduling schemes for storage servers using novel workload shaping techniques to improve cost and energy consumption. The research involves the design, analysis, implementation, and performance evaluation of new algorithms for workload shaping with superior performance characteristics. This will result in significant improvements in resource provisioning, capacity prediction, and admission control, as well as energy and power consumption. Unlike traditional server scheduling techniques in which the negative effects of workload bursts affect even well-behaved portions of the workload, the proposed workload shaping approach isolates the bursts and confines their effects to localized regions using online workload decomposition and recombination.<br\/><br\/>The project will support the education of graduate students in an emerging sector of Information Technology, and will also involve undergraduate engineering students in research in a topical technical area.","title":"CSR: Small: Workload Shaping for Capacity and Power Provisioning in Storage Data Centers","awardID":"0917157","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["410022"],"PO":["565255"]},"146493":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 <br\/>(Public Law 111-5).\"<br\/><br\/><br\/><br\/>This project strives for novel and transformative approaches to design automation guided by physical views of computation. A broad theme is the application of expertise from an established field, digital circuit design, to new fields, such as nanotechnology and synthetic biology. A specific theme that cuts across these domains is constructing and deconstructing probabilistic behavior. In the biological realm, the project will develop techniques for synthesizing biochemical systems that produce proteins according to specified probability distributions. This will provide robustness and flexibility ? akin to hedging with a portfolio of investments ? for applications in biochemical sensing and drug delivery. In the engineering realm, the project will develop techniques for designing digital circuits that process zeros and ones probabilistically. This will mitigate against the noise and glitches that occur as circuit components are scaled down in size to nanometers. <br\/>The circuit design community has unique expertise that can be brought to bear on the challenging design problems in synthetic biology. Applications in biology, in turn, offer a wealth of problems in algorithmic development. With its cross-disciplinary emphasis, this project will bring new perspectives to both fields. An important goal of the project is to communicate the goals and the impetus for interdisciplinary research to a wide audience. A new graduate-level course will be developed, titled \"Circuits, Computation, and Biology\". In parallel, a book with the same title will be written, to be published by Pan Stanford Publishing. Also public seminars will be given through the Caf\u00e9 Scientifique series hosted by the Bell Museum of Natural History in Minneapolis.","title":"CAREER: Computing with Things Small, Wet, and Random - Design Automation for Digital Computation with Nanoscale Technologies and Biological Processes","awardID":"0845650","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["528637"],"PO":["562984"]},"159275":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940445","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["542300"],"PO":["561855"]},"159067":{"abstract":"This project, InspireCT, employs vertically integrated project teams to expose students to the excitement of computational thinking in action. This vertical integration results in a hands-on, active learning experience that can occur while students are still deciding what to study as undergraduates. InspireCT will revitalize undergraduate computing education by engaging students in team project applications of computing much earlier than is done today. The project includes participants at four levels of computing knowledge: pre-college students in grades 6-12, less experienced undergraduates, advanced undergraduates, and practicing professionals. <br\/><br\/>At the center of the project are advanced undergraduates and team projects typical of computing degree capstone experiences. The less experienced students are integrated into the excitement typical of capstone projects by activities appropriate to their experience level. The professionals provide projects and mentoring to ensure good connection with professional practice and actual applications of computational thinking.<br\/><br\/>InspireCT also makes use of mentoring - the project explores the impact of mentoring on student learning, and also examines the positive impact of the younger students seeing the successes of the more advanced students. This is expected to engender a positive attitude among less experienced students toward the study of computing. <br\/><br\/>Intellectual Merit - This project creates and disseminates a new approach to introducing and engaging students in computational thinking activities. This active learning approach is expected to improve student learning and to create a much more direct engagement with computing by \"doing\" rather than \"hearing about\" computational thinking. <br\/><br\/>The project focuses upon computational thinking concepts such as problem solving, abstraction, design, and thinking algorithmically. But the project also suggests that definitions of computational thinking need to include team level, collaborative efforts since this is how most professionals engage in computational thinking. Research indicates that understanding the collaborative and social aspects of computational thinking may be central to attracting more women students. <br\/><br\/>The project addresses significant challenges including shifts in instructional role, definition of appropriate activities for vertical integration, and changes in instructional role. At the same time, the project builds on a substantial base of theory and prior results in areas such as active learning, capstone projects, and gender equality in computing education. The theory and related work both indicate that the benefits could be very substantial if this project is successful in addressing the challenges and meeting the goals. <br\/><br\/>Broader Impact - InspireCT impacts students at both the pre-college and undergraduate levels. Sparking student interest at that earlier age and improving learning outcomes via active learning constitutes a potentially transformative impact on computing education. The social and applied aspects of this approach also provide key characteristics that research shows are effective in attracting women to computing. The community building aspect of the project includes both pre-college and undergraduate instructors. The InspireCT activities are organized to help identify and establish a series of collaborations between pre-college instructors and undergraduate faculty.","title":"CPATH-2: Collaborative Research: From Middle School to Industry: Vertical Integration to Inspire Interest in Computational Thinking","awardID":"0939088","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[425164,425165,"539087"],"PO":["564181"]},"159089":{"abstract":"EAGER: Collaborative Research: Cross-domain Knowledge Transformation via Matrix Decompositions<br\/><br\/>Traditional data mining algorithms discover knowledge in new domains starting from the scratch, ignoring knowledge learned in other domains. Knowledge transformation is a transformative paradigm that utilizes previously acquired knowledge in other domains to guide knowledge discovery process in a new domain and is especially useful for large data sets. In particular, utilizing applicable knowledge in other domains helps to stabilize the unsupervised learning and generate results that we may have preliminary understanding. <br\/><br\/>The goal of this project is to design and develop cross-domain knowledge transformation mechanisms for knowledge discovery. The transformation mechanisms are based on matrix decompositions where the knowledge been transferred are represented directly and explicitly ? making them easy to comprehend and be utilized in practice. The proposed mechanisms provide a versatile knowledge transformation framework with solid theoretical foundation and enable a new paradigm of unsupervised learning with domain knowledge. <br\/><br\/>The usefulness of these knowledge transformation mechanisms\/systems will be demonstrated for effective information retrieval, consumer recommender systems, and product\/online opinion sentiment analysis. The versatility of this transformative metholody will be verified across many domains.","title":"EAGER: Collaborative Research: Cross-Domain Knowledge Transformation via Matrix Decompositions","awardID":"0939179","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["550720"],"PO":["565251"]},"153281":{"abstract":"The ultimate aim of this investigation is to develop computer systems capable of operating autonomously in dynamic and uncertain environments. The investigation comprises theoretical and experimental studies aiming at fusing causal and counterfactual relationships on top of probabilistic information to improve tasks of diagnosis, situation assessment and decision making in data-intensive applications. Specific research issues to investigate include developing algorithms and conceptual tools for diagnosis and situation assessment, using causal and counterfactual relationships, and developing novel methods of structure learning using propensity-score estimation and C-equivalence tests, with applications to epidemiology and molecular biology. <br\/><br\/>The theoretical part of this research touches on the core of human knowledge and scientific inquiry, and is having profound methodological ramifications in the fields of epidemiology, social science, economics, medicine and biology, where causal knowledge plays a major role. The practical part focuses on the development of new algorithms for causal and counterfactual reasoning, decision making and structure learning, with direct applications in areas that use graphical methods to encode knowledge.","title":"RI: Small: Probabilistic Networks for Automated Reasoning","awardID":"0914211","effectiveDate":"2009-09-15","expirationDate":"2012-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["541989"],"PO":["562760"]},"157780":{"abstract":"CPS:Small:Collaborative Research: Establishing Integrity in Dynamic Networks of Cyber Physical Devices<br\/><br\/><br\/>The objective of this research is to develop energy-efficient integrity<br\/>establishment techniques for dynamic networks of cyber physical devices. <br\/>In such dynamic networks, devices connect opportunistically and perform<br\/>general-purpose computations on behalf of other devices. However, some <br\/>devices may be malicious in intent and affect the integrity of computation. <br\/>The approach is to develop new trust establishment mechanisms for dynamic <br\/>networks. Existing trusted computing mechanisms are not directly applicable <br\/>to cyber physical devices because they are resource-intensive and require <br\/>devices to have special-purpose hardware.<br\/><br\/>This project is addressing these problems along three research prongs. <br\/>The first is a comprehensive study of the resource bottlenecks in current <br\/>trust establishment protocols. Second, the insights from this study are <br\/>being used to develop resource-aware attestation protocols for cyber <br\/>physical devices that are equipped with trusted hardware. Third, the<br\/>project is developing new trust establishment protocols for cyber physical<br\/>devices that may lack trusted hardware. A key outcome of the project is <br\/>an improved understanding of the tradeoffs needed to balance the concerns <br\/>of security and resource-awareness in dynamic networks.<br\/><br\/>Dynamic networks allow cyber physical devices to form a highly-distributed,<br\/>cloud-like infrastructure for computations involving the physical world. The<br\/>trust-establishment mechanisms developed in this project encourage devices to<br\/>participate in dynamic networks, thereby unleashing the full potential of<br\/>dynamic networks. This project includes development of dynamic networking<br\/>applications, such as distributed gaming and social networking, in<br\/>undergraduate curricula and course projects, thereby fostering the<br\/>participation of this key demographic.","title":"CPS: Small: Collaborative Research: Establishing Integrity in Dynamic Networks of Cyber Physical Devices","awardID":"0931992","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["486426",421129],"PO":["565239"]},"157791":{"abstract":"The objective of this research is to develop non-volatile computing devices, which allow the power source to be cut off at any time, and yet resume regular operation without loss of information when the power comes back. The approach is to replace all critical memory components with non-volatile units so that computing state is maintained over power interruptions. The advancement in new Flash memory devices makes this approach feasible by enabling low-voltage program\/erase (P\/E) around \u00b12V and a long (projected >1016) cycling endurance to be integrated into CMOS technology.<br\/><br\/>This research effort seeks to establish a new paradigm of computing where non-volatile memory units are used pervasively to enhance reliability against power source instability, energy-efficiency, and security. The non-volatile computing devices are especially useful for embedded cyber-physical systems enabling long running computations and data collection even with unreliable power sources. The technologies developed from this project can also benefit conventional architecture in its power optimization and internal security code generation. The project is a close collaboration between computer architecture and CMOS technology development groups, where all levels in the design hierarchy will be visited for system and technology evaluation.<br\/><br\/>This project integrates its research efforts with education by developing an undergraduate and Master curriculum that spans over the vertical design hierarchy in microprocessors. This vertical education will better prepare future work force in tackling tremendous design challenges spanning many layers of microprocessors. The results from this project will be made widely available to both industry and academia.","title":"CPS:Small:Non-Volatile Computing for Embedded Cyber-Physical Systems","awardID":"0932069","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["519714","519715"],"PO":["564778"]},"156581":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/><br\/><br\/>Customizable Domain-Specific Computing<br\/>To meet ever-increasing computing needs and overcome power density limitations, the computing industry has entered the era of parallelization, with tens to hundreds of computing cores integrated into a single processor; and hundreds to thousands of computing servers connected in warehouse-scale data centers. However, such highly parallel, general-purpose computing systems still face serious challenges in terms of performance, energy, heat dissipation, space, and cost. In this project we look beyond parallelization and focus on domain-specific customization as the next disruptive technology to bring orders-of-magnitude power-performance efficiency improvement to important application domains. <br\/>The intellectual merit of this project includes development of a general methodology for creating novel customizable architecture platforms and the associated compilation tools and runtime management environment to support domain-specific computing to: 1) achieve orders-of-magnitude computing efficiency improvement for applications in a specific domain; and 2) demon-strate that such improvement can be obtained with little or no impact on design productivity, so that it can be deployed in a wide range of application domains. Our proposed domain-specific customizable computing platform includes: 1) a wide range of customizable computing elements, from heterogeneous fixed cores to coarse-grain customizable cores, and to fine-grain field-programmable circuit fabrics; 2) customizable high-performance radio frequency interconnects; 3) highly automated compilation tools and runtime management software systems for application development; and 4) a general, reusable methodology for customizable computing applicable across different domains. By combining these critical capabilities, we shall deliver a super-computer-in-a-box that is customized to a particular application domain to enable disruptive innovations in that domain. This approach will be demonstrated in several important application domains in healthcare. <br\/>The broader impact of this project will be measured by the new digital revolution enabled by customized computing. We will demonstrate the feasibility and advantages of the proposed research in the domain of healthcare, given its significant impact on the national economy and quality of life issues. In particular, we focus our effort on revolutionizing the role of medical imaging and hemodynamic modeling in healthcare, providing much more cost-efficient, convenient solutions for preventative, diagnostic, and therapeutic procedures to dramatically improve healthcare quality, efficiency, and patient outcomes. The broader impact of this project also includes the integration of research and education, exposing graduate, undergraduate, and high school stu-dents to the new concepts and research from this project via several new courses jointly developed and shared by researchers in our newly established Center for Domain-Specific Computing (CSDC). Summer research fellowship programs to support high school and undergraduate students will be provided by CSDC. Our goal is to train a new generation of students who are prepared for customized parallelization and computing, and can effectively apply such techniques to many areas of our society, thus furthering the digital revolution. Special efforts are being made to attract underrepresented students at all levels via partnerships with campus organizations focused on diversity, such as the UCLA Center for Excellence in Engineering and Diversity.<br\/>This research will be carried out as a collaborative effort between four universities: UCLA (the lead institution), Rice, UC Santa Barbara, and Ohio State. The research team consists of a group of highly accomplished researchers with diversified backgrounds, including computer science and engineering, electrical engineering, medicine, and applied mathematics. For more information, please visit http:\/\/cdsc.cs.ucla.edu.","title":"Customizable Domain-Specific Computing","awardID":"0926127","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"6894","name":"ITR EXPEDITIONS"}}],"PIcoPI":["558485","558389",417551,"557772",417553],"PO":["562984"]},"158891":{"abstract":"Abstract<br\/>A major challenge for future High End Computing (HEC) systems built using many-core chips is the storage system since the available memory and bandwidth per processor core is starting to decline at an alarming rate, with the rapid increase in the number of cores per chip. Data-intensive applications that require large data sets and\/or high input-output bandwidth will be especially vulnerable to these trends. Historically, the storage architecture of an HEC system has been constrained to a large degree by the filesystem interfaces in the underlying Operating System (OS). The specific focus of this research is on exploring a new storage model based on write-once tree structures. This research will explore three programming models for users of the storage system, all of which can inter-operate through shared persistent data: 1) a declarative programming model in which any data structure can be directly made persistent in the storage system, with no programmer intervention, 2) a strongly-typed imperative programming model in which a type system extension will be used to enforce a separation between data structures that can be directly made persistent and those that cannot, and 3) a weakly-typed runtime interface that enables low-level C programs to access the storage system.","title":"Collaborative Research: Programming Models and Storage System for High Performance Computation with Many-Core Processors","awardID":"0937907","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["475422"],"PO":["565272"]},"157681":{"abstract":"CPS: Small: Dynamically Managing the Real-time Fabric of a Wireless Sensor-Actuator Network<br\/><br\/>The objective of this research is to develop algorithms for wireless sensor-actuator networks (WSAN) that allow control applications and network servers to work together in maximizing control application performance subject to hard real-time service constraints. The approach is a model-based approach in which the WSAN is unfolded into a real-time fabric that captures the interaction between the network's cyber-processes and the application's physical-processes. <br\/><br\/>The project's approach faces a number of challenges when they are applied to wireless control systems. This project addresses these challenges by 1) using network calculus concepts to pose a network utility maximization (NUM) problem that maximizes overall application performance subject to network capacity constraints, 2) using event-triggered message passing schemes to reduce communication overhead, 3) using nonlinear analysis methods to more precisely characterize the problem's utility functions, and 4) using anytime control concepts to assure robustness over wide variations in network connectivity.<br\/><br\/>The project's impact will be broadened through interactions with industrial partner, EmNet LLC. The company will use this project's algorithms on its CSOnet system. CSOnet is a WSAN controlling combined-sewer overflows (CSO), an environmental problem faced by nearly 800 cities in the United States. The project's impact will also be broadened through educational outreach activities that develop a graduate level course on formal methods in cyber-physical systems. The project's impact will be broadened further through collaborations with colleagues working on networked control systems under the European Union's WIDE project.","title":"CPS: Small: Dynamically Managing the Real-time Fabric of a Wireless Sensor-Actuator Network","awardID":"0931195","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["526924","550624"],"PO":["564778"]},"148980":{"abstract":"A recent shift from single-core to multi-core and many-core architectures and rising complexity of both hardware and software pose a number of challenges to computer systems industry. Computer architecture research is crucial in finding new approaches for designing, programming, debugging, and operating future computer systems based on multi-core processors.<br\/>Computer architecture research has predominantly relied on software simulations for quantitative evaluations of new architectural ideas and design space exploration in the last two decades. However, simulation-based research cannot keep pace with growing demands of new architectures and new benchmarks, suffering from extremely long simulation times, over-burdening complexity, and limited credibility. FPGA-based hardware emulators provide an attractive and cost-effective alternative to simulation: they address key weaknesses of software simulators - scalability, speed, and credibility, while offering similar levels of flexibility, observability, and reproducibility. Modern FPGAs can accommodate up to 16 processor cores running at clock speeds of over 200 MHz. At these speeds, they enable full-system emulation of complex multi-core architectures, run operating systems and real-world applications, and are several orders of magnitude faster than corresponding simulators.<br\/>This project will acquire new FPGA-based emulation hardware infrastructure at the University of Alabama in Huntsville. It will be used by researchers in the Laboratory for Advanced Computer Architectures and Systems (LaCASA), to help their ongoing research efforts targeting new architectures for increasing programmers? productivity and dependability in both single-core and multi-core computer systems. The infrastructure will also be used in several graduate and undergraduate computer engineering courses to improve academic training and learning experience, and help recruiting efforts.","title":"II-NEW: Acquisition of FPGA-Based Emulation Hardware for Research in Computer Systems Architecture","awardID":"0855237","effectiveDate":"2009-09-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["517808"],"PO":["535244"]},"154062":{"abstract":"The management of changes is a difficult and error-prone process in software maintenance and many other fields. Due to a lack of theory, there are few tools and methods available to systematically change objects while preserving important properties along with such changes. This problem is addressed by the theory of structured change. The overall research objective is to find principles for sound change management and to establish a theoretical foundation for the development of supporting tools. One particular goal is the development of domain-specific languages, which users can employ to effectively manage changes in all kinds of software applications.<br\/><br\/>The following technical approach is pursued. First, a flexible change representation is developed. Based on this representation, laws of a change algebra will be established to identify property-preserving transformations that can support sound change transitions. This work is accompanied by the development of algorithms for the incremental checking of property preservation. Ultimately, the theory will enable the development of tools that help users to effectively manage the evolution of objects. This goal is supported by the investigation of interaction principles that underly the editing and exploration of structured objects and their changes. Building on top of the theoretical foundation, the development of domain-specific languages will provide concrete help for users to express more sophisticated transformations and combinations than the simple one-step operations that are offered by the underlying formal model. Specifically, in the area of change representations for programs such a DSL will yield new, theoretically founded support for feature-oriented programming and software product lines. In the context of spreadsheets, web sites, etc. the development of such DSLs will empower millions of users to deal in a more systematic way with changes.","title":"SHF: Small: Change Theory for Variation-Aware Programming","awardID":"0917092","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["548134"],"PO":["564388"]},"159771":{"abstract":"Trust plays a key role in innovation, efficiency and thus effectiveness during collaborations, more so in virtual teams (VT) when members are unlikely to meet face-to-face. Establishing trust in virtual teams can increase effectiveness as team members will be less likely to spend time cross-checking others work. This research has three principle objectives: 1) develop a deeper understanding of trust in VT, 2) establish design rationale for automated monitoring and management of trust in VT, and 3) develop prototypes to monitor and manage trust in VT. <br\/><br\/>The results of this research will fill a gap in the literature by conducting a field study of trust in distributed software engineering teams. The prototype tool will provide insights into software support for trust in VT. Further, this study fits into a long-term successful program of research in analyzing and developing software support for collaborative software engineering in virtual organizations, giving a unique perspective and the opportunity to integrate findings with larger cross-cutting themes. The broader impacts include increasing the effectiveness of collaborations in teams, both for students enrolled in software engineering courses and ultimately practitioners working distributed software engineering. Moreover, enabling trust can encourage innovation, thus increasing the advantages of diverse teams by increasing confidence in collaboration while reducing transaction costs.","title":"VOSS: Enabling Trust in Virtual Teams for Increased Innovation and Effectiveness","awardID":"0943262","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["483634"],"PO":["564456"]},"158682":{"abstract":"Viruses are contagious agents and can cause epidemics and pandemics. The importance of the prevention and control of viral epidemics and pandemics to homeland security and daily life cannot be overemphasized. Viruses cannot grow and\/or reproduce outside host cells. Their infection starts with the attachment of a virus on the host cell surface, with possible fusion of viral capsid surface and the host cellular membrane, followed by virus penetration into the host cell. These processes involve mostly non-bonding interactions between the virus capsid surface and the aquatic environment, as well as the host surface membrane or receptor. It is imperative to understand the molecular mechanism of virus attachment on its host cell, the movement of virus fusion with cellular membrane, and the dynamics of virus penetration into its host cell. The prerequisites to these studies are efficient mathematical and computational techniques for virus surface construction, evolution and visualization, and analysis of the virus's non-bonding interactions with its host cell. Unfortunately, an average virus comprises millions of atoms, and virus dynamics involves an additional number of degrees of freedom due to its environment and host cell. The exceptionally massive data sets in virus systems pose severe challenges to full-atomic scale virus surface formation, visualization and virus interaction analysis. Therefore, the real time dynamic simulation of viral attachment, fusion and penetration of a host cell in the aquatic environment requires microsecond or millisecond simulation time and is technically intractable with full-atom models at present.<br\/><br\/>The proposed project addresses these challenges by developing a multiscale framework which reduces the problem dimensionality by a macroscopic continuum description of the aquatic environment, and a microscopic discrete description of virus atoms. To further reduce the size of virus data for excessively large viruses, a coarse-grain particle description based on amino acid residues is built into our multiscale framework. A total free energy functional is introduced to bring the macroscopic surface tension and microscopic potential interactions into the same footing. The differential geometry theory of surfaces raises naturally for the description of the interface between macroscopic and microscopic domains. Potential driven geometric flows are constructed to minimize the total free energy functional. A hybrid Eulerian-Lagrangian method is developed based on the geometric measure theory to accelerate the surface construction involving topological changes. In addition to promising preliminary results illustrating the power of this approach, extensive validation and applications are proposed to ensure that this methodology yields robust and powerful tools for virus surface construction, visualization, evolution, and dynamics.","title":"Differential geometry approach for virus surface formation, evolution and visualization","awardID":"0936830","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}}],"PIcoPI":[424067,"541932","524752","541934","541933"],"PO":["565286"]},"146472":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Malicious software is one of the most pressing security problems on<br\/>the Internet. The main reason for the apparent failure of current<br\/>defense approaches is that malware detection techniques are too<br\/>specific. This is most obvious with virus scanners, which rely on<br\/>signatures that are specific to individual malware instances. However,<br\/>also behavioral detection techniques typically target only specific<br\/>features of malicious code. Examples include the scanning behavior of<br\/>worms and the command and control channels of bots. Unfortunately,<br\/>such techniques become obsolete when malware evolves and the targeted<br\/>feature disappears.<br\/><br\/>In this project, we develop a novel malware defense system that<br\/>overcomes the shortcomings of current approaches. To this end, we<br\/>investigate techniques that specify and model program behavior at a<br\/>level of abstraction that captures general properties and features<br\/>that are fundamental to the execution of programs. In addition, we<br\/>develop a stealth and comprehensive analysis environment that<br\/>automatically extracts the characteristics of novel malware strains<br\/>when they appear, expressing these characteristics in terms of the<br\/>general, behavioral properties. These characteristics are then<br\/>automatically translated into efficient detection models. This allows<br\/>our system to quickly react to and eliminate novel malware variants.<br\/><br\/>The research on novel techniques to eliminate malware presents rich<br\/>opportunities for industrial and societal impact, and will have broad<br\/>impact though education and outreach. We will introduce a new course<br\/>on malware analysis at UC Santa Barbara, perform outreach activities<br\/>through a newly established diversity center, and cooperate with<br\/>well-known players in the anti-malware industry.","title":"CAREER: Toward eliminating malicious code","awardID":"0845559","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["535036"],"PO":["564388"]},"158572":{"abstract":"SIGCOMM is the flagship annual conference of the Special Interest Group on Data Communications, a special interest group of the Association for Computing Machinery. This award assists approximately 12 graduate students and 3 postdoctoral students from US institutions to attend this conference. Participation in conferences such as SIGCOMM is an extremely important part of the graduate school experience, provides students with an opportunity to interact with more senior researchers and exposes them to leading edge research in the field. The support requested in this proposal will enable people in the above categories to attend the main SIGCOMM 2009 conference, who would be otherwise unable to do so. The travel grant chairs are committed to encouraging the participation of women and under-represented minorities.<br\/><br\/>Intellectual Merit: This project proposes to provide travel support for US-based graduate and postdoctoral students to attend the main SIGCOMM 2009 conference. SIGCOMM is the flagship conference in the networking community and a highly competitive venue (with acceptance rate around 10%). Its rich program exposes participants to new ideas and cutting-edge research and allows for interaction between researchers from all over the world.<br\/><br\/>Broader Impact: First, this project integrates research and education of students through exposure to a premier technical meeting in computer networks and communications. Students will have the opportunity to observe high-quality presentations and interact with senior researchers in the field. The proposed student participation is expected to have a positive impact on the students? research interests and quality. Second, the project will promote diversity by encouraging and enabling women and other under-represented minorities to participate. Furthermore, the truly international flavor of SIGCOMM 2009 cultivates international research interactions and presents a tremendous opportunity to students to increase their breadth of ideas, research approaches, and technical perspectives.","title":"Student Travel Support for the Special Interest Group on Data Communication 2009 Conference","awardID":"0936144","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["536897"],"PO":["565090"]},"159793":{"abstract":"Understanding how organizations promote innovation is a key element of advancing the science of innovation, and hence the science of innovation policy. Data on innovation inputs, innovation processes, and innovation outputs are increasingly being captured and stored electronically. A number of fundamental bottlenecks to using these data to advance social science research exist due to unsolved issues of privacy, data integration, and data quality. The core scientific challenge is how to make such real-world, large-scale data available to researchers to nurture innovation and perform valid experimentation, while maintaining data privacy. Fortunately, computer scientists have been developing a variety of techniques and building new tools that manage large data sets in ways that can potentially help in supporting and measuring innovation activities. <br\/><br\/>This workshop brings together social scientists, the users of data on innovation, together with computer scientists, the creators of new tools for collecting data while protecting privacy concerns. The workshop includes leading computer scientists with specialties in data management, data mining, security\/privacy and social networks as well as social\/organizational scientists, such as economists, sociologists, psychologists and anthropologists. <br\/><br\/>The focus of the workshop is to identify emerging major challenges in this interdisciplinary area. Three different types of data critical to the study of innovation are the focus of study: third party data, such as U.S. Census data, patendt databases, NSF funding data or citation databases; detailed insider data such as internal communications, team video, or team documentation; and broader insider data such as cross-firm surveys.<br\/><br\/>The broader impact of the workshop is substantial. First, an enhanced empirical basis for studying innovation is necessary to guide policy decisions. Second, the workshop participants represent a broad variety of disciplines, which creates a broader interdisciplinary network of study. Finally, the attendance of graduate students advances the goal of training a new cohort of researchers in the field.","title":"Collaborative Research: Workshop on Confidential Data Collection for Innovation Analysis in Organizations to be held at Microsoft headquarters in September 2009 - Redmond, WA.","awardID":"0943337","effectiveDate":"2009-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0400","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7626","name":"SCIENCE OF SCIENCE POLICY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1320","name":"ECONOMICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7603","name":"SCIENCE, TECH & SOCIETY"}}],"PIcoPI":["558235"],"PO":["474859"]},"159320":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940591","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["460928"],"PO":["561855"]},"144074":{"abstract":"This research will explore interactions between cognition and emotion during the learning of scientific methods in the context of a computer tutoring environment. The primary focus will be on the relations between impasses, cognitive disequilibrium, and the affective-cognitive state of confusion. Confusion correlates with learning gains because it is diagnostic of cognitive disequilibrium, a state that occurs when learners face obstacles to goals, contradictions, incongruities, anomalies, conflicts, and system breakdowns. Cognitive equilibrium is normally restored after thought, reflection, problem solving and other effortful cognitive activities. Therefore, pedagogical tactics that challenge, perplex, and productively confuse learners are stimulating alternatives to the typical information delivery systems in education that promote shallow knowledge in the comfort zone of the learner, but rarely deep comprehension. This research will develop tutorial interventions that induce, track, and regulate confusion and cognitive disequilibrium in the minds of learners, as well as the cognitive and emotional mechanisms that restore cognitive equilibrium. The research has three specific objectives: (1) To promote deep learning by developing tutorial interventions that experimentally induce impasses, cognitive disequilibrium, and the resulting confusion; (2) to integrate sensing devices and signal processing algorithms that detect and track the associated confusion; and (3) to develop affect-sensitive pedagogical strategies to help learners regulate their confusion. The three objectives will be accomplished by augmenting an existing Intelligent Tutoring System (ARIES, Acquiring Research Investigative and Evaluative Skills) with technologies that automate assessment of emotion and cognition, as well as an intelligent handling of emotions. State-of-the-art sensing devices detect relevant emotions during learning (confusion, frustration, boredom, flow\/engagement, delight, surprise) on the basis of the dialogue history, facial expressions, and body posture. The ARIES system promotes scientific inquiry skills by presenting case studies that exhibit flawed scientific methods and that require learners to offer thoughtful critiques on the scientific merits of the studies. The critiques encourage (a) the general cognitive processes of drawing inferences, constructing causal models, identifying problems, and asking diagnostic questions and (b) skills that directly target scientific reasoning, such as stating hypotheses, identifying dependent and independent variables, isolating potential confounds in designs, interpreting trends in data, and determining whether data support predictions. Students interact with ARIES through conversational trialogues in natural language with two animated agents: a tutor agent and a peer agent. Cognitive disequilibrium is created when the agents produce messages with contradictions, conflicts, and clashes with what the student knows. Correct information eventually emerges in the trialogue, which restores cognitive equilibrium. <br\/> <br\/>The broader significance and importance of the project is to advance science education, intelligent learning environments, and human-computer interfaces. It is widely acknowledged that the level of science understanding among students and adults in the United States needs improvement and does not compare favorably with several other nations. The proposed research will help fill this gap by developing technological interventions to fortify citizens and aspiring scientists with the skills needed for critical thinking, complex reasoning, and problem solving in science. The project will develop intelligent learning environments targeted for deeper learning, which is needed for a technologically sophisticated workforce, and for a motivating learning experience, which is expected in recent generations of students. The project will develop advanced sensing devices for detecting emotions and cognition, a contribution that should impact the fields of human-computer interaction, cognitive science, and the learning sciences.","title":"Inducing, Tracking, and Regulating Confusion and Cognitive Disequilibrium during Complex Learning","awardID":"0834847","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["482198","558856"],"PO":["565227"]},"159485":{"abstract":"Crime scene investigation (CSI) is a highly visual and quantitative analysis characterized by a time-sensitive need to gather, organize, analyze, model, and visualize large, multi-scale, heterogeneous and context-rich data. CSI is also characterized by a fundamental need for rapid coordination and data translation across disciplines, agencies and levels of expertise as crime scenes are processed, reconstructed, solved and ultimately prosecuted over time, often critically in front of laypeople comprising a jury. The core intellectual contributions of this research include a shift to 3D virtual crime scene reconstruction and collaboration protocols for virtual CSI work. Embedded within the virtual scene will be all of the conventional evidence data, but will also include advanced data resulting from the development of non-invasive nano-scale methodologies and databases for advanced surface and cross-sectional materials chemistry analysis, especially fibers. The new data will lead to development of revolutionary high statistical significance when comparing similar materials commonly encountered in CSI. Further, collaboration protocols for dynamic virtual team assembly and interaction will be developed, assessed and optimized for contextual knowledge transfer.<br\/><br\/>The broader impacts of this research and education agenda include critical benefits to research and education infrastructure, public health and safety, and the justice system. The resulting system will be used as a novel research tool to increase the level of scientific rigor and advance the knowledge of forensic analysis. It provides a platform for integrating research with engaging science and engineering education opportunities for K-12, undergraduate and graduate students, including those from underrepresented groups and communities.","title":"CDI-Type II: IC-CRIME: Interdisciplinary Cyber-Enabled Crime Reconstruction through Innovative Methodology and Engagement","awardID":"0941421","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["550629","427311","427311","426417",426417],"PO":["564456"]},"159287":{"abstract":"North Carolina Agricultural and Technical State University, together with collaborating institutions Clemson University, Prairie View A&M University, the University of Colorado, the University of Wisconsin, Auburn University, the University of Indiana, Norfolk State University, Virginia Polytechnic Institute and State University, Fort Valley Sate University, and Jackson State University, proposes an extension of the successful Alliance for the Advancement of African-American Researchers in Computing (A4RC, pronounced \"A-Force\"). A4RC aims to increase the number of African-Americans obtaining advanced degrees in computing, particularly at the Ph.D. level. A4RC establishes and develops student pipelines from HBCUs to universities offering advanced degrees in Computing. A4RC has amassed a body of knowledge and experience with respect to what it takes to build effective HBCU\/R1 faculty collaborations, develop productive HBCU\/R1 research teams that include graduate and undergraduate students, and prepare undergraduate and master's students for research at the Ph.D. level. A4RC uses a \"research pod\" concept that is efficient, flexible, and effective in terms of HBCU\/R1 research collaborations. With this extension, A4RC plans to expand the alliance to include a greater number of HBCU\/R1 research collaborations, and to build new partnerships. A new category of partners -- Affiliate Partners -- will engage additional HBCUs and national labs and A4RC will become formal partners with the very effective BPC Demonstration Project, African-American Researchers in Computing Sciences (AARCS). A4RC will build collaborations with the BPC STARS and Empowering Leadership Alliances, and ADMI: The Symposium on Computing at Minority Institutions.","title":"BPC-AE: Collaborative Research: The Alliance for the Advancement of African-American Researcher in Computing (A4RC)","awardID":"0940480","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":["530190"],"PO":["560704"]},"159299":{"abstract":"DePauw University with the collaboration of the Anita Borg Institute (ABI) and the University of Virginia, and in partnership with the ACM Women's Council (ACM-W) and the National Center for Women and IT (NCWIT), proposes to create self-sustaining, regional communities of women in computing. National-level activities, such as the Grace Hopper Celebration of Women in Computing, have positively impacted thousands of women. They cannot, however, reach all women. In particular, national meetings have limited ability to recruit women from isolated areas of the country, to include women at institutions that cannot afford expensive and time-consuming travel to national meetings, to provide leadership roles, to encourage participation by high school students, and to support interactions that are frequent enough to spark and sustain collaborations among budding students and professionals. This project -- called WWW.2 for Wide Web of Women -- aims to overcome these impediments. The project will create twelve new and upgraded Regional Celebrations of Women in Computing that will bring students, faculty and indistry representatives together for biennial conferences. The conferences will increase women?s participation in computing through intentional role modeling, networking, group and indivudal career mentoring, providing career information, and oportunities for experiences in presenting their work. The attendees will be encouraged to continue their interactions between Celebrations, for example, by forming ACM-W student chapters, hosting multi-institutional get togethers, and maintaining connections through a wiki. Focusing on women (as well as regions) serves a population powerfully united by gender, yet diverse in experience, with personal stories varying by race, ethnicity, disability, and sexual orientation. This \"Web of Women\" will build momentum toward a tipping point of cultural change in stereotypes about gender and computing.","title":"BPC-A: Collaborative Research: WWW.2, a Wide Web of Women","awardID":"0940516","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["529248"],"PO":["561855"]},"159057":{"abstract":"Free and open source software (FOSS) is software that can be freely shared, modified, and redistributed. FOSS is developed by collaborative communities and distributed under licenses that permit its sharing and redistribution. Humanitarian FOSS (H-FOSS) is FOSS that is developed specifically to benefit the local and global community. The key concepts underlying FOSS and H-FOSS are their collaborative development process and community ownership. These concepts provide the underpinnings for many remarkable software projects, such as free and open repositories of general knowledge (Wikipedia), standard DNA parts (The BioBricks Foundation), and scientific research (PLoS).<br\/><br\/>This project uses the H-FOSS model to help revitalize undergraduate computing education by getting students engaged in building free and open software that benefits the community. During the project's first three years, students from Trinity College, Wesleyan University, Connecticut College, and elsewhere have developed H-FOSS in traditional and video-conference courses, independent studies and capstone projects, and in sponsored summer internships. Working collaboratively with FOSS practitioners in real and virtual communities, students have developed software that directly supports a variety of global and local humanitarian efforts, ranging from disaster management to health care delivery to volunteer management to search and rescue operations. For more details about this work, see http:\/\/www.hfoss.org. <br\/><br\/>During the next two years, this project will have three major goals: (1) to extend the H-FOSS educational community by creating new H-FOSS Chapters at a wide range of undergraduate institutions, including community colleges, women's colleges, and traditionally black schools; (2) to create an H-FOSS Certificate Program that will recognize student achievement in the study and practice of H-FOSS development; and (3) to develop a sustainable infrastructure and funding model, along with industry and community partners, that will enable the H-FOSS effort to be expanded to a national scope. By getting computing students and faculty involved in building FOSS that serves the community, this project will thereby help transform the nature and enhance the attractiveness of undergraduate computing education itself.","title":"CPATH-2: Collaborative Research: Building a Community to Incorporate Humanitarian Free and Open Source Software into Undergraduate Computing Education","awardID":"0939034","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["527969"],"PO":["565264"]},"159068":{"abstract":"This CPATH award brings together community colleges and universities in five regions including Bunker Hill Community College and University of Massachusetts Boston in Massachusetts, Northern Virginia Community College and George Mason University in Virginia, Ivy Tech Community College and Purdue University in Indiana, Cameron University in Oklahoma and City College of San Francisco and California State - Monterrey in California. The partners plan to revitalize undergraduate computing education through new research that correlates Computational Thinking (CT) with the new Information Technology Volume developed by the Special Interest Group for Information Technology Education of the Association for Computing Machinery to develop a CT framework for researching and building instructional elements. This resulting product identifies core computing concepts, methodologies, frameworks, and tools that may be applied across a variety of institutions and inform teaching and learning in undergraduate computing in a variety of environments. Each of the five partnerships consists of a paired team comprised of a university and a community college. The benefit of this arrangement is to ensure the focus is firmly set on undergraduate computing and that the outcomes and findings of this project develop core CT skills that improve matriculation and transfer from lower to upper division IT and computer science programs. <br\/><br\/>Intellectual Merit: This project develops innovative instructional scenarios and related assessments specifically aligned to develop and enhance CT outcomes for lower division computing students. The project partners will develop instructional elements and techniques that not only impart cognitive knowledge but that also pose authentic situations for students wherein CT attributes can be developed and demonstrated. In order to differentiate between cognitive knowledge gains and improvement in CT skills, faculty working with the treatment groups will develop enhanced student assessments using Principled Assessment Design for Inquiry which produces evidence-centered assessment design. An excellent team has been assembled to lead this project which has the potential to produce new disciplinary foundations and serve as a model for computing for the future.<br\/><br\/>Broader Impacts: In explicitly including lower division and community college IT courses in computational thinking frameworks, this proposal breaks new ground. The project is to be disseminated to a broad audience covering the spectrum of undergraduate computing education and broadening participation organization. Each regional partner has additional regional dissemination foci, and the team is particularly interested in national dissemination of the results obtained through the pedagogical approaches investigated in this work, particularly as they may inform others with an interest in improving matriculation and transfer from lower to upper division IT programs. The models and results from the project thus have the potential to reach a diverse set of institutions with different student populations and thus provide pathways for preparing computing students for the workforce of the future.","title":"CPATH-2: Advancing the Successful IT Student through Enhanced Computational Thinking (ASSECT)","awardID":"0939089","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["479529","558309",425170,425171],"PO":["564181"]},"162280":{"abstract":"Goedel's Incompleteness Theorem is essentially a 2-part result, whose<br\/>second facet establishes that all conventional axiom systems are unable to<br\/>prove a theorem corroborating their own consistency. This latter effect,<br\/>called the Second Incompleteness Theorem, is quite counter-intuitive<br\/>because human beings seem to implicitly believe that their cogitation<br\/>processes are consistent (in order for them to gain the needed motivational<br\/>energy for cogitation). Yet quite surprisingly, the Second Incompleteness<br\/>Theorem has demonstrated that conventional logics cannot corroborate such a<br\/>seemingly very natural consistency assumption.<br\/><br\/>The main goal of Willard's research project will be to explore to what<br\/>extent a logic formalism can wiggle around the Second Incompleteness<br\/>Theorem and formalize a type of at least partial instinctive faith in<br\/>its own consistency. Willard has already published several articles<br\/>exploring boundary-case exceptions to the Second Incompleteness<br\/>Theorem and generalizations of it, thus establishing the basic<br\/>foundational concepts for this quite unorthodox research approach<br\/><br\/>Willard's planned investigation will have an inter-disciplinary<br\/>emphasis, being germane to computer science, mathematics, the<br\/>cognitive and information sciences, philosophy and linguistics. It<br\/>will show that while self-justifying axiom systems have a very<br\/>unconventional outer shell, they do retain an ability to simulate most<br\/>of the practical computer-oriented knowledge of the data needed by any<br\/>arbitrary logically valid axiom system. It will also show how<br\/>computerized floating-point real number arithmetics behave very<br\/>differently from integer arithmetics and how self-justifying<br\/>formalisms retain an ability to expand their knowledge base by hopping<br\/>and skipping form one formal self-justifying axiom system to another<br\/>(via the use of Mind Change Theory and sundry trial-and-error<br\/>experimental methodologies).<br\/><br\/>The Second Incompleteness Theorem is sufficiently robust that its<br\/>evasion is feasible only in a limited context, where the specified<br\/>logic possesses a component that is unconventional in a nontrivial<br\/>way. The reason that such unconventional logics are of interest is<br\/>that human beings evidently possess some type of innate instinctive<br\/>understanding of their own self-consistencies (at least under some<br\/>formal definitions of consistency). It is therefore desirable to<br\/>understand what type of algorithmic processes and foundational<br\/>precepts from symbolic logic can simulate a Thinking Being's<br\/>conception of its own consistency (in either a full or partial sense).<br\/>The goal of this research project will be to investigate the nature of<br\/>and the potential uses and implications of logics that possess some<br\/>type of well-defined partial knowledge of their own consistency.","title":"EAGER: An Investigation of the Partial Degrees in Which Logics Can Recognize Their Own Consistency and the Potentially Broad Inter-Disciplinary Implications of These Effects","awardID":"0956495","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1268","name":"FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[433708],"PO":["565157"]},"162291":{"abstract":"The Warning, Alert, and Response Network (WARN) Act of 2006 established the Department of Homeland Security's Commercial Mobile Alert Service (CMAS) to enable a national capability to deliver alert messages to mobile devices for as much of the population as possible. This award funds a workshop to be hosted and managed by the National Academy of Sciences focused on understanding the state of the art for mobile emergency warning and to develop a research agenda to address intellectual gaps in the current understanding. Although alert and warning issues have been extensively studied for some time, relatively less is known about the opportunities and challenges associated with using cellular phones and other mobile communications devices, including the challenges of effectively communicating warning information using very brief text messages. Developing a fuller understanding of these issues and framing future research needs involves research, expertise, and practical knowledge from multiple disciplines. The proposed workshop would provide a forum for such a multidisciplinary exploration. <br\/><br\/>The discussions at the workshop and the material presented in the report will contribute to a better understanding of how the public will respond to alerts and warnings delivered over mobile devices. This understanding can inform the Department of Homeland Security?s implementation of the CMAS program and influence how messages are crafted (including what needs to be provided to the public in terms of education and training) and other facets of CMAS implementation and operation.","title":"Public Response to Alerts and Warnings on Mobile Devices: Current Knowledge and Research Needs","awardID":"0956543","effectiveDate":"2009-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"I334","name":"U.S. Department of Homeland Se"}}],"PIcoPI":["560890"],"PO":["565136"]},"153491":{"abstract":"Advances in digital microfluidics have led to the promise of biochips for applications such as point-of-care medical diagnostics. These devices enable the precise control of nanoliter droplets of biochemical samples and reagents. Therefore, integrated circuit (IC) technology can be used to transport and process \"biochemical payload\" in the form of nanoliter\/picoliter droplets. As a result, non-traditional biomedical applications and markets are opening up fundamentally new uses for ICs. <br\/><br\/>The goal of this project is to develop a design-automation infrastructure for reconfigurable microfluidic biochips. It envisions an automated design flow that will transform biochip research and their use, in the same way as design automation revolutionized IC design in the 80s and 90s. Design tools and optimization methods are being developed to ensure that biochips are as versatile as the macro-labs that they are intended to replace. The results from this research will enable a \"panel\" of concurrent immunoassay-based diagnostic tests on an integrated microfluidic processor biochip that can be \"user-programmed\", and which can provide results in real-time with picoliter sample\/reagent volumes. Specific research tasks include control-path synthesis and microcontroller\/microfluidics integration, chip optimization for multiplexed immunoassays, microfluidic logic gates for smart decision-making, and design for testability.<br\/><br\/>Miniaturized and low-cost biochips will revolutionize data analysis for air quality studies and clinical diagnostics, enabling a transformation in environmental monitoring, healthcare, exposure assessment, and emergency response. This project is especially aligned with the vision of functional diversification and \"More than Moore\", as articulated in the ITRS 2007, which highlights \"Medical\" as a \"System Driver\" for the future. The project bridges several research communities, e.g., microfluidics, electronic design automation, and biochemistry, and it provides interdisciplinary education to graduate and undergraduate students.","title":"SHF: Small:Design Tools and Optimization Methods for Digital Microfluidic Biochips","awardID":"0914895","effectiveDate":"2009-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["506171"],"PO":["565157"]},"157770":{"abstract":"The objectives of this research are to design a heterogeneous network of embedded systems so that faults can be quickly detected and isolated and to develop on-line and off-line fault diagnosis and prognosis methods. Our approach is to develop functional dependency models between the failure modes and the concomitant monitoring mechanisms, which form the basis for failure modes, effects and criticality analysis, design for testability, diagnostic inference, and the remaining useful life estimation of (hardware) components. <br\/><br\/>Over the last few years, the electronic explosion in automotive vehicles and other application domains has significantly increased the complexity, heterogeneity, and interconnectedness of embedded systems. To address the cross-subsystem malfunction phenomena in such networked systems, it is essential to develop a common methodology that: (i) identifies the potential failure modes associated with software, hardware, and hardware-software interfaces; (ii) generates functional dependencies between the failure modes and tests; (iii) provides an on-line\/off-line diagnosis system; (iv) computes the remaining useful life estimates of components based on the diagnosis; and (iv) validates the diagnostic and prognostic inference methods via fault injection prior to deployment in the field. The development of functional dependency models and diagnostic inference from these models to aid in online and remote diagnosis and prognosis of embedded systems is a potentially novel aspect of this effort.<br\/><br\/>This project seeks to improve the competitiveness of the U.S. automotive industry by enhancing vehicle reliability, performance and safety, and by improving customer satisfaction. Other representative applications include aerospace systems, electrification of transportation, medical equipment, and communication and power networks, to name a few.","title":"CPS: Small: Collaborative Research: Fault Diagnosis and Prognosis in a Network of Embedded Systems in Automotive Vehicles","awardID":"0931956","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["554506","465137","442464","541340"],"PO":["564728"]},"154140":{"abstract":"Many large-scale networked systems such as Online Social Networks (OSNs)are often represented as annotated graphs with various node or link attributes. Such a representation is usually derived from a snapshot that is obtained through measurements. These graph representations enable researchers to characterize the connectivity of these systems using graph analysis. However, captured snapshots of large networked systems are likely to be distorted. Furthermore, commonly-used graph analysis characterizes the connectivity of a graph in an indirect fashion and generally ignores graph dynamics.<br\/><br\/>This multi-disciplinary research program designs, develops and rigorously evaluates theoretically grounded techniques to accurately measure and properly characterize the connectivity structure of large-scale and dynamic networked systems. More specifically, the project examines various graph sampling techniques for collecting representative samples from large and evolving graphs. It also investigates how multiscale analysis can be used as a powerful technique to characterize the key features of the connectivity structure of large dynamic networked systems at different scales in space and time. The developed techniques will be used to characterize fundamental properties of the friendship and various interaction connectivity structures in different OSNs.<br\/><br\/>This project promises to identify the underlying technical and social factors that primarily drive the structural properties and dynamic nature of OSN-specific connectivity structures. It will produce new models for friendship and interactions in OSNs, a large archive of anonymized datasets and new tools for OSN measurement, simulation and analysis. The latter will be incorporated into newly-developed courses in Computer Science and Sociology, and will be freely distributed.","title":"NeTS: Small: Collaborative Research: Multi-Resolution Analysis & Measurement of Large-scale, Dynamic Networked Systems with Applications to Online Social Networks","awardID":"0917381","effectiveDate":"2009-09-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["551080"],"PO":["565342"]},"153062":{"abstract":"This project focuses on reducing the overhead and increasing throughput of network processing in multi-core platforms. In particular, packet processing functions are proposed to be balanced across the cores so as to facilitate virtualization in next-generation systems.<br\/><br\/>Low-cost multi-core architectures that put many CPU cores on the same chip are abundantly available in the market today. Researchers are developing a range of programming techniques for different applications to efficiently utilize the parallelism available in such multi-core architectures. However, research into how to alleviate the I\/O bottleneck, where protocol-processing overhead dominates the CPU execution time, is sparse.<br\/><br\/>Multicore has enabled broad interest in virtualization for diverse uses including server consolidation and sharing of various resources. Studies have shown that virtualization brings significant extra overhead to network I\/O. The objective of this project is to develop techniques to optimize the performance of virtualized I\/O with high-speed networks. In particular, the research team explores new software techniques in virtualized environments, that may reduce the network I\/O overhead in multi-core processors, through the following approaches: <br\/><br\/>1. Life of a Packet Analysis: this involves a measurement technique to trace the life of a packet in a virtualized environment with 10 Gigabit Ethernet. The study instruments the OS software, and should reveal potential bottleneck functions that contribute heavily to packet latency. <br\/><br\/>2. Mutithreading the protocol stack: Based on life-of-a-packet analysis, the TCP\/IP protocol stack in the guest O\/S and virtual machine monitor (VMM) will be divided into multiple threads that can execute in parallel on multiple cores and cut down the latency. Core scheduling techniques are developed to allocate these threads to different cores so as to exploit the cache locality of the multi-core architecture. <br\/><br\/>3. Pipeline Scheduling: Instead of splitting the protocol stack in terms of latency bottleneck, tasks are partitioned based on code size and multiple threads developed. Techniques are developed to schedule the threads appropriately so that the cache misses are reduced. <br\/><br\/>4. Combined Scheduling for Virtualized Environment: Although the parallel\/pipeline techniques are developed separately from the TCP\/IP stack and VMM, they are combined to create multiple threads in a virtualized environment and various code scheduling optimizations are applied to reduce latency and increase I\/O throughput. <br\/><br\/>A complimentary project to the one described here has been partly supported by grants from the Intel Corporation. Hence, the research results obtained from this project may have strong potential for technology transfer. The PI has mentored several Ph.D. graduates who later developed reputations for architecture research and he has mentored four female Ph.D. graduates during the last two years, contributing to increasing the representation of women in computing in the country. Such efforts continue under this NSF project. UCR is recognized as a minority serving institution. Hence, involving undergraduate students will enable minority participation in the project.","title":"CSR: Small: Core Scheduling to Improve Virtualized I\/O Performance on Multi-Core Systems","awardID":"0912850","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["516924"],"PO":["565255"]},"158881":{"abstract":"This project investigates optimization problems that arise while performing thermal management in very large data storage centers. To satisfy the growing data management needs, such storage centers contain possibly hundreds of thousands of hard disks and other components, and typically are consistently active. These generate a lot of heat, and hence the storage system must be cooled to maintain reliability, resulting in significant cooling costs. The cooling mechanism and the workload assignments in a storage center are intricately tied together.<br\/>This project is developing a general science of thermal management for large scale storage systems, by focusing on thermal modeling and management at different levels of the system hierarchy. Thermal aware techniques for allocating data access tasks to specific disks on which data is located, for controlling the schedules and speeds of thousands of tasks and disks to optimize quality of service, and for reorganizing data layouts on disks are being developed. This project will enable better thermal management in data storage centers, which can potentially result in significant reductions in the carbon footprint caused by those. The project will train several Ph.D. students in conducting research both at the University, and through internships at Industrial Research Labs.","title":"Optimization Algorithms for Large-scale, Thermal-aware Storage Systems","awardID":"0937865","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["541967","550401","538796"],"PO":["565272"]},"155251":{"abstract":"The Atlas of North American English, based on the study of cities over 50,000 population, shows that American regional dialects are becoming increasingly different as a result of ongoing changes in their vowel systems, leading to considerable miscomprehension across dialects. An understanding of this process calls for studies of many more communities and speakers. However, currently used methods of analysis require several days or weeks to accurately define the vowel system of a single speaker. This project is based on an accelerated method that produces ten times as much data in one hundredth of the time required, using automatic alignment of the sound wave and transcriptions. Methods will be developed for automatically measuring each vowel in the transcript with an error rate equal to or lower than that of manual measurement. These techniques will be tested on a very large database on change in the speech of a metropolitan community, a series of interviews recorded annually in Philadelphia neighborhoods from 1973 to 2008.<br\/><br\/>Dialect diversity is one of the major factors limiting the success of automatic speech recognition and provides a major challenge for our understanding of the causes of language change. The methods developed in this project will serve to accelerate sociolinguistic analysis across other communities and other languages. Findings from the analysis of the Philadelphia database will contribute to the understanding of gender differentiation in language change in progress, the reversal of the direction of change, and the diffusion of change across neighborhoods.","title":"Automatic Alignment and Analysis of Linguistic Change.","awardID":"0921643","effectiveDate":"2009-09-01","expirationDate":"2012-05-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["533436","467345"],"PO":["564500"]},"146550":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project develops WiFi-based Rural Extensions (WiRE), a new wireless architecture that can provide high bandwidth connectivity to rural regions at extremely low costs. WiRE is a comprehensive rural connectivity solution that can support a wide range of applications with performance, robustness and functionality guarantees. The design of WiRE addresses several research challenges across different protocol layers including: (1) an adaptive, high-performance unified Medium Access Control layer that seamlessly works across different network environments; (2) a secure and scalable naming and addressing solution to enable cellular access using mobile devices; (3) robust solutions for fault-tolerant network design, failure recovery, network management and unreliable power; (4) Quality of Service mechanisms to provide predictable end-to-end performance. The project enhances the understanding of networking and systems challenges in the developing world and can have enormous societal benefits to billions in rural regions. It makes fundamental advances in wireless networks including understanding complex interference interactions, protocol design and mobile applications. <br\/><br\/>The research activities in this program include cross-disciplinary collaborations in the areas of electrical engineering, economics, public health and sustainable development. The PI has organized several important workshops and conferences to increase the awareness of important computer science research challenges in the rural areas and the developing world. The education plan for this project includes new curricular development for this emerging area, inter-disciplinary education, mentoring students from various disciplines and training of underrepresented groups in rural regions.","title":"CAREER: A Low-Cost Efficient Wireless Architecture for Rural Network Connectivity","awardID":"0845842","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[390720],"PO":["565303"]},"159981":{"abstract":"","title":"Chipscale Nanofluidics for Chemical and Biological Separation and Sensing","awardID":"0944125","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I153","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I435","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}}],"PIcoPI":["511708",427971],"PO":["565136"]},"158892":{"abstract":"I\/O performance is often an issue for high-end computing (HEC) codes, due to their increasingly data-intensive nature and the ever-growing CPU-I\/O performance gap. Portable parallel I\/O benchmarks can help<br\/>(1) application developers to improve their codes' performance,<br\/>(2) HEC storage systems architects to improve their designs, and<br\/>(3) future and current owners of HEC platforms to reduce hardware cost and improve application performance through better system provisioning and configuration.<br\/><br\/>To keep up with the growing scale and complexity of HEC applications, this project develops automated generation of parallel I\/O benchmarks, analogous to the SPEC and NAS benchmarks for computation. Our approach will be embedded in BenchMaker, a prototype tool that takes a real-world, large-scale parallel application and automatically distills it into a compact, human-intelligible, I\/O-intensive, and parameterized benchmark. Such a benchmark accurately reflects the original application's I\/O characteristics and I\/O performance, yet with shorter execution time, reduced need for libraries, better portability, and easy scalability.<br\/><br\/>Benchmarks and tools that benefit the computational science community at large will be produced by this research. These benchmark prototypes will be used for parallel computing course projects and student research contests.","title":"Collaborative Research: Automatic Extraction of Parallel I\/O Benchmarks from HEC Applications","awardID":"0937908","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I159","name":"Defense Advanced Research Proj"}}],"PIcoPI":["549981","553590"],"PO":["565272"]},"156593":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/><br\/>Summary: Formal Analysis of Complex Systems<br\/><br\/>A Collaborative Proposal Involving CMU, CUNY, NYU, Stony Brook, UMD, Cornell, JPL<br\/><br\/><br\/>This Expedition, under the directorship of Lead PI Edmund M. Clarke, will develop new computational tools to help scientists and engineers analyze and understand the behavior of the complex models they develop for application domains ranging from systems biology to embedded control. Building on the success of model checking and abstract interpretation (MCAI), two well-established methods for automatically verifying properties of digital circuit designs and embedded software, this research project will extend the MCAI paradigm to systems with complex continuous dynamics and probabilistic behaviors. Challenge problems providing technology drivers and testbeds for the research include: understanding the precursors and course of pancreatic cancer; predicting the onset of atrial fibrillation; and obtaining deep design-time insights into the behavior of automotive and aerospace control systems. Ultimately, this Expedition is expected to provide vital tools that will enable health-care researchers to discover better treatments for disease and will allow engineers to build safer aircraft and other complex systems.<br\/><br\/>The world-class team of scientists and engineers assembled for this Expedition includes two Turing Award winners, a recipient of the National Medal of Science, and awardees of other prestigious research prizes. Outreach consists of the development of a new, highly ambitious and highly cross-discipline educational program called Complex Systems Science Engineering, an annual Minority-Focused Intersession Workshop for Undergraduates on Understanding and Analyzing Complex Embedded and Biological Systems to be hosted at member institution Lehman College, CUNY; substantial financial support for undergraduate research; student involvement in the NASA JPL Research Affiliates Program; and other research opportunities for undergraduate and graduate students and postdoctoral trainees.<br\/><br\/>More information: http:\/\/www.mcai2.org\/","title":"Collaborative Research: Next-Generation Model Checking and Abstract Interpretation with a Focus on Embedded Control and Systems Biology","awardID":"0926166","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"6894","name":"ITR EXPEDITIONS"}}],"PIcoPI":[417590,417591,417592],"PO":["565239"]},"154052":{"abstract":"Bullying among students at a school has become a serious social problem. In the project, researchers at University of California, Irvine and at KDDI Research and Development Laboratories study school bullying using digital communication media (such as cell phones, short messaging systems, emails, blogs) and create a sociological based network framework to help teachers and parents identify whether school bullying may exist among students. The project models interactions among students as a relationship network, constructs a relationship network from usage statistics of digital communication media, and identifies whether unique structural features exist in a relationship network that may indicate bullying among students. The framework is designed based on two key hypotheses: (1) school bullying imposes distinct structural features in a relationship network, and (2) a relationship network is constructed with some degree of accuracy from usage statistics of digital communication media without examining privacy-violating information. The framework only uses usage statistics that maintain privacy of communication, and it extracts such usage statistics from those publicly available, those collected by and traditionally made only available internally to a service provider, and those that the framework directly monitors. <br\/><br\/>The PIs collaborate with researchers in sociology and social psychology to empirically verify the hypotheses used in the framework, design the framework and empirically examine the framework. The intellectual merit of the project includes considering privacy of communication and applying sociology and social psychology knowledge in framework design. The broader impact of the project includes advancing understanding of school bullying, creating a framework that helps teachers and parents, and sharing of the project findings and artifacts with a large segment of the research community.","title":"NetSE: Small: A Framework to Identify Relationships Among Students in School Bullying Resulting from using Digital Communication Media","awardID":"0917059","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":[409909],"PO":["550147"]},"156120":{"abstract":"Collaborative Research: Recovery of 3D Shapes from Single Views<br\/><br\/>Zygmunt Pizlo, Purdue University<br\/>Longin Jan Latecki, Temple University<br\/><br\/>The human eye, like a camera, produces 2-dimensional images of a 3-dimensional world. How does the human brain succeed in interpreting these impoverished 2-dimensional images, allowing us to see the world as it actually is \"out there?\" This fundamental question, whose significance has been appreciated for 300 years, has not been answered despite the efforts of many scientists, engineers and mathematicians. Conventional approaches, which have not been successful, tried to recover the 3-dimensional shapes of objects and scenes from their 2-dimensional images by analyzing the depths of surfaces in multiple images (such as might be obtained from two eyes or from moving images) and by emphasizing the role of learning and familiarity. The approach taken by Zygmunt Pizlo at Purdue University and Longin Jan Latecki at Temple University is very different. It uses only a single 2-D image to recover the third dimension by applying a priori constraints (assumptions about the world built-in to the human visual system) that reflect important visual properties that are generally present in the physical world, properties such as the symmetry and compactness of 3D objects. <br\/><br\/>Pizlo and Latecki's research has the potential of encouraging theoretical changes in the study of human perception because it uses an entirely new approach to a classical unsolved problem in vision. It could support breakthroughs in machine vision because human beings are known to be much better than any machine confronted with recovering the 3D world from 2D information. Machine vision has important applications to many domains, including law enforcement and national security. Pizlo and Latecki's research attempts to solve the visual 3D shape problem by combining the results of experiments on human observers with state-of-the-art computational modeling. The project will provide an excellent opportunity for the interdisciplinary education of graduate and undergraduate students in psychology, computer science and engineering.","title":"Collaborative Research: Recovery of 3D Shapes from Single Views","awardID":"0924164","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["541851"],"PO":["564506"]},"156241":{"abstract":"Humans are unique in that they can learn and use language. However, we share many brain mechanisms for perception and action with our primate cousins, the monkeys and apes. The proposed research will chart how these shared brain mechanisms provide the basis for the uniquely human brain mechanisms that support the learning, perception, and production of language. The key idea is based on the mirror system, a system for controlling both the execution and observation of action, found for grasping in moneys. This idea was extended \"beyond the mirror\" in humans to encompass mechanisms for language. The approach to the research is computational: to develop computer programs that make explicit the implications of ape and monkey data and human data for analysis of the human language-ready brain. <br\/><br\/>The study of language within a more general understanding of action and perception may ground new approaches to language education and the treatment of language disorders. In particular, linguists have long debated what it is about language that is innate and what reflects the child's social learning. The assumptions of different schools of thought clearly influence approaches to language education. By laying bare underlying brain mechanisms that include an account of neural plasticity, the proposed research has the potential to transform the innateness debate in ways that can inform educators. To support this, the research will also develop a new information infrastructure, the Brain Operation Database, which will provide a repository of summaries of the empirical data used to test and develop models, descriptions of the models themselves together with summarized simulation results, and tools for comparing the success of different models in explaining known data and supporting predictions for new empirical research.<br\/><br\/><br\/>This work is co-funded by SBE\/BCS and CISE\/IIS\/RI.","title":"Beyond the Mirror: An Integrated Computational Framework for the Study of Action & Language","awardID":"0924674","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560350"],"PO":["563458"]},"154063":{"abstract":"Adaptive numerical algorithms are widely used to solve continuous problems in Computational Science and Engineering (CS & E). Unlike discrete combinatorial algorithms which predominate in Theoretical Computer Science, such algorithms for the continua are typically numerical in nature, iterative in form, and have adaptive complexity. The complexity analysis of such algorithms is a major challenge for theoretical computer science. In particular, it is necessary to properly account for the adaptivity that are inherent in such algorithms. Until now, all complexity analysis that accounts for adaptivity (for example, in linear programming) must invoke some probabilistic assumptions. The broader impact of this project lies in the push to extend the scope of theoretical algorithms into the realm of continuous computation. The project is seen as part of a research program to develop a computational model and complexity theory for real computation, one that can account for the vast majority of algorithms in CS & E.<br\/><br\/>This project develops a new non-probabilistic analysis technique called continuous amortization. It is able to quantify the complexity of an input instance as an integral, and reduce the problem to providing explicit bounds on the integral. The success in producing the first example of such adaptive bounds for the 1-dimensional case is now extended to higher dimensions. In order to bound these integrals, one needs another form of amortization called algebraic amortization. This generalizes the usual zero bounds by simultaneously bounding a product of individual bounds. These advances build upon the principal investigator's work in previous NSF projects on Exact Geometric Computation. The project also validates its algorithms by implementing them using the open-source Core Library software.","title":"AF: Small: Analysis Algorithms: Continuous and Algebraic Amortization","awardID":"0917093","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[409933],"PO":["565251"]},"154074":{"abstract":"In many scientific domains information is scattered across numerous interrelated and heterogeneous artifacts. In software engineering in particular, artifacts such as requirements, design documents, and code are often isolated by tools, development groups, and geographic locations. Current traceability approaches ? attempts to link related information ? fall short in tracing across heterogeneous artifacts and in supporting user-customized links. This project is aimed at crossing these information barriers, enabling the creation of traceability links between related artifacts, to support tasks such as impact analysis and software maintenance.<br\/><br\/>This project targets automated architecture-centric traceability which centers links on the architecture, enabling scalable and flexible link capture. Furthermore, stakeholders control link capture, enabling them to directly benefit from the links. The prevalent approach to automatic traceability is to recover links from existing artifacts. In contrast, this project pursues prospective generation of trace links which captures links in situ, while artifacts are generated or modified, enabling the capture of contextual relationships. Open hypermedia adapters enable the capture of links across heterogeneous artifacts and the rendering of resources at different levels of granularity. Users can determine the artifacts to trace and the link semantics to assign via externally customizable rules.<br\/><br\/>The approach is applicable to data provenance capture in e-Science. Prospective capture can aid in inferring experiment design and capturing links across heterogeneous artifacts like publications, data files, and plots. The results will also be valuable to the development of safety critical systems where satisfaction of all requirements is part of safety assurance.","title":"III: Small: Making and Tracing: Architecture-centric Information Integration","awardID":"0917129","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["533779"],"PO":["564388"]},"146462":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Policy-based computing is a critical component of many large-scale configurable systems because it enables dynamic adaptability of system behavior by changing policy configurations without reprogramming the systems. Policy evaluation, the process of checking whether a request satisfies a policy, is typically the performance bottleneck of policy-based systems. Most prior research has focused on the correctness (i.e., specification, design, and analysis) of policies. While correctness is an important issue, the adoption of policy-based computing may be limited if the resulting systems are not implemented efficiently and thus perform poorly. The high-level research objective of this project is to increase the effectiveness and adoption of policy-based computing by designing high performance policy evaluation algorithms and engines that can be adapted to support various policy languages. The primary focus of this project is the fast evaluation of security policies, which are most prevalent. To speed up policy evaluation, this research uses two unique approaches: policy normalization and canonical policy representation. The idea of policy normalization is to convert a policy with a complex logical structure to an equivalent policy with a simple logical structure. The idea of canonical policy representation is to convert a given policy to its canonical form. The techniques developed in this effort will be useful beyond this project. The results will greatly benefit society by increasing the adoption of policy-based computing. To promote education and learning, this effort actively involves high school, undergraduate, graduate students, especially students from under-represented minorities.","title":"CAREER: Towards High Performance Policy Evaluation","awardID":"0845513","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["562296"],"PO":["497499"]},"154085":{"abstract":"Virtualization is rapidly becoming a key technology for computing<br\/>systems, promising significant benefits in security, efficiency, and<br\/>dependability. Fully realizing these benefits depends upon the<br\/>reliability of virtual machine monitors (hypervisors). This research<br\/>aims toward developing a very high assurance, commercial quality<br\/>hypervisor by:<br\/><br\/>(1) designing practical tools and techniques to make reasoning about<br\/> hypervisors feasible;<br\/>(2) honing them through the formal verification of an existing simple<br\/> research hypervisor; and (3) applying them to develop and prove a graduated series of more and<br\/> more realistic hypervisor models, aiming toward a fully<br\/> functional, formally verified hypervisor.<br\/><br\/>The project proceeds along two tracks. In the first, an existing<br\/>research hypervisor is modeled and verified using the ACL2 formal<br\/>analysis tools. In the second track, tools and methodologies are<br\/>developed applicable to a wide variety of hypervisor implementations.<br\/>This work aims to advance the formal analysis of an important class of<br\/>software applications and to advance the state of the art in formal methods,<br\/>particularly management of large and complex formal proofs. This<br\/>research is a collaboration between the formal methods and systems<br\/>research groups at the University of Texas at Austin.","title":"TC: Small: V2M2: Towards a Verified Virtual Machine Monitor","awardID":"0917162","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["466839","542403"],"PO":["565327"]},"159332":{"abstract":"Predicting biodiversity, i.e., abundance of species, in response to climate change is a goal of environmental change research. Despite recent valuable advances in understanding biodiversity and climate, the current grasp is limited. There are two widely recognized obstacles: first, because of the complexity of the underlying processes, the existing models intended for understanding and prediction are not (computationally) scalable. Second, the coarse-scale environment models fail to capture interactions among species, which control biodiversity, and the models based on fine-scale, short-term observations are unable to make long-term predictions. This project aims to develop a prediction framework that coherently combines broad-scale pattern data with fine-scale data on species interactions and that is computationally scalable. It focuses on prediction at the geographic scale and in using geographic-scale data to better understanding at the scales where species interactions occur.<br\/><br\/>The goal is to develop a multiscale modeling framework and to design algorithms that make environmental models computationally scalable. The approach hinges upon strong interplay of algorithmic and statistical techniques. Statistical inference brings stochastic modeling sophistication in space and time, yielding improved characterization of the process and the possibility of full inference. Sophisticated algorithms make models and processes scalable and provide trade-offs between accuracy and efficiency. <br\/><br\/>The project draws on a wide range of topics in computer science and statistics, including geometric algorithms, approximation algorithms, hierarchical specifications within a Bayesian framework, and space-time process modeling. The problem areas address in the proposed prototypical example indicate more broadly applicable consequential challenges for both computer science and statistics. These include maintaining\/updating distributions and summaries, dynamic algorithms, data driven algorithms, stochastic optimization, and assessing uncertainty and multi-scale nonlinear interactions in inference. Techniques for obtaining trade-offs between conflicting goals are needed in order to optimize the overall performance of the model.","title":"CDI-Type II: Integrating Algorithmic and Stochastic Modeling Techniques for Environmental Prediction","awardID":"0940671","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["544491","496177","554177","563031","563031"],"PO":["565157"]},"146385":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/><br\/>As computing becomes embedded in the very fabric of our society, the<br\/>exponential growth and advances in cheap, high-speed communication<br\/>infrastructures allow for unprecedented levels of global information<br\/>exchange and interaction. As a result, new market forces emerge that propel<br\/>toward a fundamental, cost-efficient paradigm shift in the way computing is<br\/>deployed and delivered: computing outsourcing.<br\/><br\/>Outsourcing has the potential to minimize client-side management overheads<br\/>and benefit from a service provider's global expertise consolidation and<br\/>bulk pricing. Companies such as Google, Yahoo, Amazon, and Sun are rushing<br\/>to offer increasingly complex storage and computation outsourcing services<br\/>supported by globally distributed \"cloud\" infrastructures.<br\/><br\/>Yet significant challenges lie in the path to successful large-scale<br\/>adoption. In business, healthcare and government frameworks, clients are<br\/>reluctant to place sensitive data under the control of a remote, third-<br\/>party provider, without practical assurances of privacy and confidentiality.<br\/>Today's solutions however, do not offer such assurances, and are thus<br\/>fundamentally insecure and vulnerable to illicit behavior. Existing research<br\/>addresses several aspects of this problem, but advancing the state of the<br\/>art to practical realms will require a fundamental leap.<br\/><br\/>This project addresses these challenges by designing, implementing and<br\/>analyzing practical data outsourcing protocols with strong assurances of<br\/>privacy and confidentiality. It will also l initiate the exploration of the cost and energy<br\/>footprints of outsourcing mechanisms. This is essential as the main raison<br\/>d'etre of outsourcing paradigms lies in their assumed end-to-end cost<br\/>savings and expertise consolidation. Yet, research has yet to explore and<br\/>validate the magnitudes of these savings and their underlying assumptions.","title":"CAREER: Practical Privacy for Outsourcing Systems","awardID":"0845192","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553485"],"PO":["543481"]},"159266":{"abstract":"","title":"Tunable Infrared Lasers for Gas Phase Sensing","awardID":"0940380","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I153","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}}],"PIcoPI":["427971"],"PO":["565136"]},"153690":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>In programming languages research, there is a strong trend toward extremely<br\/>precise type systems, which can encode and verify extremely detailed<br\/>assertions about the behavior of programs and the structure of the data they<br\/>manipulate. However, precision is a two-edged sword. Combining precise<br\/>types with the other language features can lead to complex definitions that<br\/>are difficult to explain, implement, and reason about.<br\/><br\/>The goal of this project is to tame this complexity using contracts --<br\/>executable partial program specifications that are checked at run-time. The<br\/>project's primary contributions will be (1) to show how an improved theory<br\/>of contracts can be used to design and implement powerful, yet tractable,<br\/>precise type systems, (2) to develop a particular precise type system<br\/>extending regular expression types with security annotations, and (3) to use<br\/>the resulting system to demonstrate a useful form of ``updatable security<br\/>views'' in a multi-level Wiki allowing groups of users with different<br\/>clearance levels to collaboratively author structured documents.<br\/><br\/>This application is motivated by discussions with NSA researchers about the<br\/>need in the intelligence community for such tools. The project's software<br\/>deliverables will be distributed freely under an open-source license and<br\/>integrated with the popular Unison file synchronizer.","title":"TC: SMALL: Contracts for Precise Types","awardID":"0915671","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["563479"],"PO":["565264"]},"155890":{"abstract":"Proposal #: MRI 09-23481<br\/>PI(s): Chen, Yuhua<br\/>Institution: University of Houston<br\/> Houston, TX 77204-2015<br\/>Title: MRI\/Dev.: Reconfigurable DWDM Multi-Mode Switching Platform for Supporting Telesurgery Telemedicine and Heterogeneous Applications<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Project Proposed:<br\/>This project, developing a dense wavelength division multiplexing (DWDM) multi-mode switching platform instrument, supports telesurgery, telemedicine, and heterogeneous applications by allowing different types of messages within an application to choose from three switching modes: (electronic packet switching (EPS), optical burst switching (OBS), and optical circuit switching (OCS). While using the EPS mode to transfer short robotic control messages, applications such as telesurgery are expected to benefit from the approach by using the OBS mode or the OCS mode to transfer the ultra high bandwidth multi-view 3-D high definition (HD) video. The multi-mode switching platform will be developed using high performance reconfigurable field programmable gate array (FPGA) system along with optical switching nodes. The platform developed can be made available remotely to networking researchers and to the GENI infrastructure. The DWDM multi-mode switching platform enabled by the router architecture allows the three switching paradigms mentioned above (i.e., EPS, OBS, and OCS) to be supported on the same router platform, providing the greatest flexibility to applications. Each DWDM channel in an optical fiber can be individually reconfigured to a different switching mode based on the dynamic traffic load. Additionally, the approach allows individual application or individual type of messages within an application to be transported using the best-suited switching mode to achieve the best performance.<br\/><br\/>Broader Impacts: <br\/>This work can change the way quality medical services that can be delivered. Telesurgery and telemedicine allow medical experts and resources to be shared remotely by residents who do not have local access to such resources. While fostering research opportunities and collaborations in router designs, network management, and application designs, the platform instrument under development can provide research infrastructure to networking researchers and potentially unify the two often-divided research communities: the electronic packet switching and the optical switching. The female investigator serves as a mentor in WELCOME (Women for Engineering Learning Community for Maximizing Excellence), actively recruiting and retaining women in engineering. She is hosting two minority Harmony Science Academy students.","title":"MRI: Development of Reconfigurable DWDM Multi-Mode Switching Platform for Supporting Telesurgery Telemedicine and Heterogeneous Applications","awardID":"0923481","effectiveDate":"2009-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["486128"],"PO":["557609"]},"151061":{"abstract":"This project is developing and validating rigorous models of several central problems in the design of the Internet and its applications, which can be viewed as evolving distributed systems composed of software agents employing some algorithmic process. In these systems, one can predict the outcome of a particular task as a function of a set of input variables: the agent communication pattern, individual incentives, and algorithmic strategy---aspects that have previously been studied in isolation, but rarely in concert. The PIs are developing an analytic framework that explicitly accounts for both network structure and agent incentives. By considering simple tasks like information diffusion, search, and leader election, they will construct a theory that can be applied to practical problems such as Internet routing, congestion control, and reputation systems.<br\/><br\/>Intellectual Merit:<br\/>This project brings together a team of researchers with backgrounds spanning economics, algorithms, and networking to develop a unified approach to complex social networking that captures both network structure and agent incentives through a rigorous algorithmic framework. This project employs several research methodologies including human-subject experimentation, algorithm design, economic analysis, and large-scale simulation.<br\/><br\/>Broader Impact:<br\/>The multidisciplinary approach of this project promises to lead to a comprehensive understanding of the effect of network structure and agent incentives in networks. The project is training graduate and undergraduate students in the skills necessary to deal with social networks, which are emerging as a fundamental underpinning of many applications. The PIs are designing two new courses based upon the research conducted in the project.","title":"NetSe: Medium: Network Structure, Incentives, and Outcomes","awardID":"0905645","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["553090","515841","525661","548363",402714],"PO":["565251"]},"155681":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Proposal #: CNS 09-22996<br\/>PI(s): Lu, Kejie; Rodriguez, Domingo<br\/>Institution: University of Puerto Rico - Mayaguez<br\/>Title: MRI\/Dev.: Versatile Service-Oriented Wireless Mesh Network for Disaster Relief & Environmental Monitoring<br\/><br\/>Project Proposed:<br\/>This project, developing a versatile service-oriented wireless mesh network (WMN), VESO-MESH, that can be quickly built to respond to natural disaster, establishes a data intensive environmental monitoring application specifically addressing hurricanes and earthquakes. The VESO-MESH architecture aims to<br\/>- Integrate distributed processes and storage devices into the network so as to provide effective data process and access inside the network,<br\/>- Construct high-throughput backbone in WMN emphasizing the transmission of a larger volume of data, and<br\/>- Design and implement a set of service-oriented protocols to efficiently provide services to users inside the network and effectively utilize the network resources in terms of energy, processing, storage, etc.<br\/><br\/>Broader Impacts: The work promises to enable high-throughput data applications in disaster relief and environmental monitoring scenarios. It also plays a critical role in improving recruitment and retention of minorities at a large minority-serving institution with a high focus in engineering and a large enrollment of women. Curriculum materials will be developed and disseminated. The project provides educational and training opportunities for students at all levels in an EPSCoR jurisdiction.","title":"MRI: Development of A Versatile Service-Oriented Wireless Mesh Network for Disaster Relief And Environmental Monitoring in Puerto Rico","awardID":"0922996","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[414666,414667],"PO":["557609"]},"154130":{"abstract":"This project proposes to inform computer users of the privacy that they receive in practice. To do so, the project will record network and system measurements of laptop and desktop computers as they are used. It will then analyze those measurements to discover what personal information is exposed to whom and by which applications. This will be done as real users undertake real tasks to produce individual privacy assessments. The project will develop visual representations to convey measured information exposure to users as answers to specific privacy questions, e.g., \"What does Starbucks know about me?\" User studies will be run to evaluate whether representations of measured information exposure are an effective way to convey privacy risks and how they affect user behavior.<br\/><br\/>This research is motivated by the fact that people who use personal computers have little idea of how the applications they run spread their personal information over the Internet. Users must simply assume that reputable applications safeguard their privacy interests; they have no basis on which to make informed privacy decisions. The research seeks to provide users with the visibility that they lack. It will show them how their personal information is actually spread by measuring application behavior and reporting the results with simple representations. The intent is to provide non-technical users with a powerful tool to help them balance their privacy needs with the available applications. The long-term impact of this research is intended to encourage new privacy-enhancing technologies by highlighting real-world privacy problems and opportunities.","title":"TC:Small:Informing Users of Their Privacy in Practice","awardID":"0917341","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["483342","543394"],"PO":["565136"]},"158860":{"abstract":"This project will develop a job scheduling and resource allocation system for data-intensive high-performance computing (HPC) based on the congestion pricing of a systems' heterogeneous resources. This extends the concept of resource management beyond processing: it allocates memory, disk I\/O, and the network among jobs. The research will overcome the critical shortcomings of processor-centric resource management, which wastes huge portions of cluster and supercomputer resources for data-intensive workloads, e.g. I\/O bandwidth governs the performance of many modern HPC applications but, at present, it is neither allocated nor managed. The research will develop techniques that (1) recon&#64257;gure the degree of parallelism of HPC jobs to avoid congestion and wastage, (2) support lower-priority, allocation elastic jobs that can be scheduled on arbitrary numbers of nodes to consume unallocated resource fragments, and (3) co-schedule batch-processing workloads that use system resources that are unoccupied due to asymmetric utilization and temporal shifts in the foreground jobs. These techniques will be implemented and supported for free public use as extensions to an open-source resource-management framework. If used broadly, the software has the potential to provide much better utilization of the national investment in HPC facilities.","title":"CRAM: A Congestion-Aware Resource and Allocation Manager for Data-Intensive High-Performance Computing","awardID":"0937810","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I159","name":"Defense Advanced Research Proj"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7476","name":"ETF"}}],"PIcoPI":["551737",424531],"PO":["565272"]},"157782":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to develop a cyber-physical system composed of accelerometers and novel machine learning algorithms to analyze data in the context of a set of driving health care applications. The approach is to develop novel machine learning algorithms for temporal segmentation, classification, and detection of subtle elements of human motion. These techniques will allow quantification of human motion and improved full-time monitoring and assessment of medical conditions using a lightweight wearable system. The scientific contribution of this research is in advancing machine learning and human sensing in support of improved medical diagnoses and treatment monitoring by (i) modeling human activity and symptoms through sensor data analysis, (ii) integrating and fusing information from several accelerometers to monitor in real-time, (iii) validating the efficacy of the automated detection through assessments applying the state of the art in diagnostic evaluation, (iv) developing novel machine learning methods for temporal segmentation, classification, and discovery of multiple temporal patterns that discriminate between temporal signals, and (v) providing quality measures to characterize subtle human motion. These algorithms will advance machine learning in the area of unsupervised and semisupervised learning. The driving applications for this research are job coaching for people with cognitive disabilities, tele-rehabilitation for knee osteo-arthritis, assessing variability in balance and gait as an indicator of health of older adults, and measures for assessing Parkinson's patients. This research is highly interdisciplinary and will train graduate students for careers in developing technological innovations in health and monitoring systems.","title":"CPS: Medium: Collaborative Research: Monitoring Human Performance with Wearable Accelerometers","awardID":"0931999","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["438709","485815"],"PO":["565136"]},"154031":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/>As our reliance on online services continues to grow, the need for maintaining high availability of these services has become a pressing need as well as a challenge. The challenges include hardware failures, software bugs, operator error, malicious break-ins, and wide-area disasters such as power blackouts and natural catastrophes. This project is developing techniques to build data center services that remain highly available under such challenging conditions using virtualization.<br\/>The project makes two contributions. First, is a novel approach for Byzantine fault-tolerance (BFT) with a replication cost factor close to F+1 in order to tolerate up to F failures, thereby halving the cost of state-of-the-art BFT approaches. The savings in replication cost as well as commensurate gains in service throughput are realized using virtualization and are applicable to data centers hosting multiplexed services. Second, is a novel approach to seamlessly recover from wide-area disasters with negligible service replication cost during typical conditions. These gains are realized using virtual machine checkpointing, asynchronous replication, and semantics-aware storage techniques. The project demonstrates the feasibility of these approaches using theoretical analysis as well as prototype-driven experiments. The prototype implementations will be made available to other researchers and practitioners.","title":"CSR: Small: High Assurance at Low Cost in Data Centers Using Virtualization","awardID":"0916972","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["497218","558563"],"PO":["565255"]},"158882":{"abstract":"The objective of this research is to develop techniques that utilize solid-state memory technologies from device, circuit, architecture, and system perspectives across I\/O hierarchy in order to exploit their true potential for improving I\/O stack performance in high-performance computing systems. The PIs plan to develop I\/O friendly memory system architectures to enable hybrid processor-memory 3D integrations with largely reduced off-chip I\/O traffic. In addition, adaptive cache management and hotspot prediction methods are being developed to address the low random write performance of solid-state drives, and data processing techniques will be developed to enable run-time configurable trade-offs among solid-state drive performance characteristics. A comprehensive full-system simulation infrastructure is capable to evaluate and demonstrate the research under diverse high-performance computing workloads.<br\/>The research facilitates the high-performance computing systems to utilize existing\/emerging memory and processing technologies to tackle the grand I\/O stack design challenge. It can greatly contribute to enabling high-performance computing systems to stay on track of their historic scaling, and hence benefit numerous real-life applications such as biology, chemistry, earth science, health care, etc. This project contributse to the society through engaging under-represented groups, research infrastructure dissemination for education and training, and outreach to high school students.","title":"Collaborative Research: Cross-Layer Exploration of Non-Volatile Solid-State Memories to Achieve Effective I\/O Stack for High-Performance Computing Systems","awardID":"0937869","effectiveDate":"2009-09-15","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["550720"],"PO":["565272"]},"154042":{"abstract":"Technological advances in positioning, sensor and monitoring<br\/>technology drive data acquisition devices to generate massive streams<br\/>of data. The goal of this research is to develop a new class of<br\/>high-performance stream data management systems capable of coping with<br\/>scenarios with infinite data arriving in large volumes, and with<br\/>near-real time response requirements. <br\/><br\/>The proposed query processing paradigm, <br\/>termed the multi-route query mesh model (QM), overcomes a<br\/>major limitation in current query optimizers, both static and stream<br\/>ones alike, namely the assignment of a single `best' query execution<br\/>plan for all input data. This approach, being based on the strong<br\/>assumption of data uniformity, results in substandard performance for<br\/>possibly all data items. Instead, query mesh adopts a processing<br\/>structure composed of a data classifier and a multiple route plan<br\/>infrastructure. Different learning models can be plugged as<br\/>classifier logic into the QM model. Given the complexity of the QM<br\/>solution space, cost-based search heuristics are designed to<br\/>efficiently find high-quality query meshes. QM is adaptive supporting<br\/>the detection and incremental modification of the QM classifier and<br\/>its routes. <br\/><br\/>The intellectual merit of this project lies in the design, development and<br\/>evaluation of a novel multi-route paradigm for stream query<br\/>processing, -- a perfect middle ground between the two current<br\/>extremes of single-plan versus route-less solutions. Experimental<br\/>studies compare query mesh to state-of-the-art solutions. QM impacts<br\/>society by facilitating a wide range of stream-centric applications,<br\/>including medical out-patient monitoring, emergency management, and<br\/>business intelligence processing, and by integrating project<br\/>activities with education.<br\/><br\/>Further information on this project can be found at the project<br\/>web page: http:\/\/dsrgweb.cs.wpi.edu:8180\/DSRG\/","title":"III: Small: Query Mesh - A Novel Paradigm for Query Processing","awardID":"0917017","effectiveDate":"2009-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543520"],"PO":["563727"]},"159982":{"abstract":"The second workshop on Resource Discovery (RED) is co-located with<br\/>the 35th International Conference on Very Large Data Bases (VLDB)<br\/>on August 28, 2009, in Lyon, France. This project provides travel fellowships <br\/>to students enrolled in US universities in order to attend the workshop.<br\/><br\/>The workshop is concerned with the design and development of models and <br\/>prototypes that support the representation of resources, the discovery of <br\/>resources on the Web, the identification, localisation, and composition of <br\/>resources. A resource corresponds to an information source such as a data <br\/>repository or database management system (e.g., a query form or a textual <br\/>search engine), a link between resources (an index or hyperlink), or a service <br\/>such as an application or tool. Resources are characterized by core information <br\/>including a name, a description of its input and its output (parameters or format), <br\/>its address, and various additional properties expressed as metadata. Resource <br\/>discovery is the process of identifying and locating existing resources that have a <br\/>particular property. Machine-based resource discovery relies on crawling, clustering, <br\/>and classifying resources discovered on the Web automatically. Resources are <br\/>organized with respect to metadata that characterize their content (for data sources), <br\/>their semantics (in terms of ontological classes and relationships), their characteristics <br\/>(syntactical properties), their performance (with metrics and benchmarks), their quality <br\/>(curation, reliability, trust), etc. Resource discovery systems allow the expression of <br\/>queries to identify and locate resources that implement specific tasks. For further <br\/>information see the project web page at: http:\/\/bioinformatics.eas.asu.edu\/RED\/red2009.html","title":"Student Travel Fellowships to Attend the 2nd Workshop on Resource Discovery","awardID":"0944126","effectiveDate":"2009-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[427973],"PO":["560586"]},"154053":{"abstract":"Databases are typically used as a subsystem in a larger system that<br\/>contains Web servers, application servers, and network-attached<br\/>storage servers. Such complex systems experience some form of change<br\/>all the time, e.g., an update to a Java module in the application<br\/>server, a statistics update in the database, or a RAID rebuild in a<br\/>storage volume. Such changes in different subsystems can cause an<br\/>overall performance degradation whose cause is hard to diagnose. The<br\/>diagnosis task is all the more daunting because enterprise<br\/>environments have isolated administration teams and tools for each<br\/>subsystem.<br\/><br\/>This project is developing an integrated tool called DIADS that<br\/>automates complex administrative tasks like problem diagnosis, what-if<br\/>analysis, orchestrating disaster recovery, and online tuning when a<br\/>database is used as a subsystem in a larger system. DIADS contains two<br\/>technical innovations. Problem diagnosis involves reconstructing<br\/>system behavior at various points of time using historic and current<br\/>monitoring data collected from the system. However, the amount and<br\/>quality of monitoring data available from production systems is<br\/>constrained by the need to keep monitoring overhead low. DIADS uses an<br\/>abstraction called Annotated Plan Graph to represent and reason about<br\/>database behavior in the context of a larger system. Annotated Plan<br\/>Graphs are generated from light-weight monitoring data.<br\/><br\/>The other innovation in DIADS is a suite of workflows for<br\/>administrative tasks that combine machine-learning techniques with<br\/>domain knowledge from system experts. For example, for problem<br\/>diagnosis, the machine-learning part of the workflow provides core<br\/>techniques to handle large and noisy streams of monitoring data, while<br\/>the domain-knowledge part acts as checks-and-balances to guide the<br\/>diagnosis in the right direction. This unique design enables DIADS to<br\/>function effectively even in the presence of multiple concurrent<br\/>problems as well as noisy monitoring data prevalent in production<br\/>environments. DIADS is being prototyped for research and educational<br\/>purposes in a datacenter setting with PostgreSQL databases and an<br\/>enterprise-level storage area network. <br\/><br\/>For further information see the project web page at <br\/>http:\/\/www.cs.duke.edu\/~shivnath\/diads.html","title":"III:Small:Integrated Problem Diagnosis and Repair in Databases and Storage Area Networks","awardID":"0917062","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["550820"],"PO":["563727"]},"159630":{"abstract":"The 8th International Semantic Web Conference (ISWC), held October 25-29, 2009 in Northern Virginia is the major international forum where the latest research results and technical innovations on all aspects of the Semantic Web are presented. This student travel support enables students who want to become part of the Semantic Web research community to participate in ISWC 2009. In particular, the ISWC Doctoral Consortium creates an opportunity for doctoral students to test their research ideas, present their current progress and future plans, and to receive constructive criticism and insights related to their future work and career perspectives. This is expected to be a significant event in the graduate students' careers.<br\/><br\/>In selecting applications for the ISWC 2009 Travel Support, preference is given to students selected to participate in the Doctoral Consortium, followed by students who are first author on a paper accepted at the conference, followed by students who have other authorship on a conference or related workshop paper, with an additional aim to broaden participation in computer science among the underrepresented students. ISWC details, including the Doctoral Symposium and Travel Support, can be found at the conference website (http:\/\/iswc2009.semanticweb.org).","title":"Travel Support for U.S.-Based Students to Attend 8th International Semantic Web Conference 2009","awardID":"0942320","effectiveDate":"2009-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563576","563576","502435"],"PO":["563751"]},"146562":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law III-5).<br\/><br\/>With pervasive usage of embedded systems in our daily life and infrastructures, strengthening the security of embedded system in its design and implementation has become a critical priority for the research community. This project targets augmenting the processor architecture for run-time secure processing. Since the architectural support can be made transparent to upper-level software, it cannot be easily circumvented by new software security attacks. Meanwhile, in-processor changes offer great efficiency. We are pursuing three research objectives to address random memory corruption caused by software attacks. First, we explore effective architectural augmentations of embedded processors to monitor code integrity, and incorporate the monitor in a realistic application-specific instruction set processors (ASIPs) design flow. Second, we utilize the embedded speculative architectures of processors as a cache for legitimate behaviors to validate program control flow, protecting control data and decision-making data. The program execution validations are sampled at critical points to reduce the performance degradation. Third, we scale architectural support in a single-core environment up to more sophisticated and increasingly popular multi-core platforms. A suite of CAD design tools will be released to public for free use. Our approach will lead to a real impact on modern secure embedded processor design. The project will also facilitate the integration of research and education across multiple disciplines, and the PI is especially keen on promoting participation of traditionally underrepresented minorities and women in such domains.","title":"CAREER: Architectural Enhancement and Design Methodologies for Secure Processing in Embedded Systems","awardID":"0845871","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["557273",390745],"PO":["565264"]},"158662":{"abstract":"The NSF and other Federal agencies will require further understanding of concepts, methods, and means for Exascale computing systems before formulation of future programs in enabling technologies, architectures, and methodologies. NSF supports a targeted two-year program of investigation, The Exascale Point-design Study, to provide sufficient depth and detail of understanding of the interrelationships among possible enabling technologies, implementation architectures and operating system software, and programming interfaces and methodologies.<br\/><br\/>Working in consultation with LSU, USC, UIUC, UD, and Sandia National Laboratory (under DOE sponsorship), UT-Austin team focuses on energy efficiency as a key driver for Exascale systems. The PIs plan to investigate processor, memory system, and interconnect architectures that enable the exploitation of temporal and spatial locality, even when traditional memory hierarchies perform poorly. They plan to further investigate the use of hardware specialization as a means to accelerate critical components of applications in an energy-efficient fashion. UT-Austin plans to devise an Exascale architecture derived from prior research conducted under NSF, DOE, and DARPA sponsorship, reflecting some of the best-known principles and practices envisioned for hardware and software at the Exaflops scale.","title":"EAGER: An Energy-Driven Point Design Study for Exascale Computing","awardID":"0936700","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7684","name":"STRATEGIC TECHNOLOGIES FOR CI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[424003],"PO":["565272"]},"156484":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 <br\/>(Public Law 111-5).\" <br\/><br\/>RoboBees: A convergence of body, brain, and colony<br\/><br\/>J. Ayers, G. Barrows, D. Brooks, S. Combes, L. Mahadevan, G. Morrisett, <br\/>R. Nagpal, S. Ramanathan, G.-Y. Wei, M. Welsh, R.J. Wood, T. Zickler<br\/><br\/>This project entails the creation of a coordinated colony of robotic bees, RoboBees. Research topics are split between the ?body?, ?brain?, and ?colony?. Topics within the ?body? include all aspects of the flight apparatus, propulsion, and power systems. The ?brain? involves research on the electronic nervous system equivalent of a bee?s brain including circuits for sensing and decision-making. Finally, research within the ?colony? entails communication and control algorithms that will enable performance well beyond the capabilities of an individual. Each of these research areas is drawn together by the challenges of recreating various functionalities of natural bees. One such example is pollination: Bees coordinate to interact with complex natural systems by using a diversity of sensors, a hierarchy of task delegation, unique communication, and an effective flapping-wing propulsion system. Pollination and other agricultural tasks will serve as challenge thrusts throughout the life of this project. Such tasks require expertise across a broad spectrum of scientific topics. The research team includes experts in biology, computer science, electrical and mechanical engineering, and materials science, assembled to address fundamental challenges in developing RoboBees.<br\/><br\/>Beyond pollination and assisted agriculture, coordinated robotic insects will have substantial impact upon rescue workers for search and rescue and hazardous environment exploration applications. High fidelity environmental monitoring, traffic monitoring, and mobile sensor networks are just a few examples of the future impact of coordinated RoboBees. Since each RoboBee component must be developed from scratch, technological fallout will be prevalent throughout research on the body, brain, and colony. This new technology and the exciting and tangible nature of robotic bees present a tremendous opportunity to catalyze young minds and encourage their participation in science and engineering. An integral part of this program is the development of a museum exhibit, in partnership with the Museum of Science, Boston, which will explore the life of a bee and the technologies required to create RoboBees. <br\/>\u00ac<br\/>For more information, please visit: http:\/\/robobees.seas.harvard.edu","title":"Collaborative Research: RoboBees: A Convergence of Body, Brain and Colony","awardID":"0925751","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6894","name":"ITR EXPEDITIONS"}}],"PIcoPI":["437415"],"PO":["564318"]},"154075":{"abstract":"Our society, economy and national security are critically dependent on computers and computing devices. With a few hops, commodity computers and mobile phones can be connected to secret or sensitive information or to critical infrastructures. However, mainstream commodity computers have not been designed with security in mind, for the last three or more decades. Rather, they have been designed to improve performance, energy efficiency, cost or size, with security added on as an after-thought. While some specialized secure computers have been built, up to now, one had to sacrifice performance (or cost and convenience) for security. In this research, the PI plans to explore what is feasible if we allow ourselves a clean-slate design, where security is a first-class goal, on par with performance and other goals. The investigation will rethink computer architecture from first principles to significantly improve both the security and the performance of future computers.<br\/><br\/>The research has two thrusts: how to design computer architecture to enable more secure software and systems, and how to design computer hardware components that are themselves more trustworthy. The PI will develop a new threat-based design methodology for computer architecture, examining how to build security awareness into the design of each basic aspect of computing. New architectural foundations for secure processing, secure memories, secure caches, secure virtual memory translation, secure storage, and secure control flow will be developed. The research will focus on providing the cornerstones of security: Confidential and Integrity of critical information, and Availability, in the sense of resilient attestation and execution of security-critical tasks even when parts of the system may have been corrupted. The solutions will also consider hardware attacks, in addition to the software and network attacks considered by software security solutions and the current state-of-the-art hardware TPM (Trusted Platform Module) solution. <br\/><br\/>The intellectual contributions of this research will be new architectural foundations, and a new dimension of \"threat-based design\" in the research and development of all future computers. The broader impact of this research is to provide core security technology that can be built into commodity computing devices and their servers. These can be used in computer, communications, control, entertainment and embedded systems to build significantly more secure systems that will provide a leap forward in information and cyber security, benefiting our society.","title":"SHF: Small: Rethinking Computer Architecture for Secure and Resilient Systems","awardID":"0917134","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518483"],"PO":["366560"]},"159773":{"abstract":"The study of gene regulation is central to modern biology. A significant portion of the nascent field of synthetic biology has revolved around building synthetic gene networks to recapitulate regulatory mechanisms found in nature or to engineer novel biological functions. However, artificial gene networks have not approached the sophistication of their natural counterparts in either design or performance. There are several technical and scientific challenges that currently limit the engineering of large-scale integrated synthetic genetic networks. This research centers on developing a framework for automating the process of gene network design by a) obtaining various working \"parts\" of gene regulatory mechanisms from nature and b) by applying engineering sciences to learn how to compose them reliably into novel systems which have predictable behaviors. The value of this project will be demonstrated through the development of the ?Programmable Rhizosphere?, which is a framework for engineering mutualism between model plant and soil microbe species. The Programmable Rhizosphere will allow control of interactions between disparate organisms, and represents a significant step towards our ability to manipulate complex ecosystems.<br\/><br\/>Broader impact: This project brings together researchers from top US institutions as well as establishes a collaboration with major universities in the UK. Graduate students and postdoctoral researchers associated with this project will get an opportunity to participate in a multi-institution, multidisciplinary research project. They will have the opportunity to train on a wide variety of techniques in computational and molecular biology. The results of the project will be disseminated to the broader public including middle and high school students through the development of informational materials and hands-on demonstrations designed for educating the public on the technologies and potential impact of synthetic biology. In addition to the advances in the understanding of engineering synthetic regulatory systems, the Programmable Rhizosphere technology has broad implications for sustainability in agriculture. In particular, these technologies could be used to engineer beneficial phenomena such as nitrogen fixation in agricultural crops, which would displace petroleum-based fertilizers currently used in agricultural production.","title":"COLLABORATIVE RESEARCH: Programming the rhizosphere through highly integrated genetic, spatio-temporal control systems","awardID":"0943269","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7552","name":"COFFES"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7954","name":"SANDPIT"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}}],"PIcoPI":["475823"],"PO":["565223"]},"159663":{"abstract":"The Eastern Great Lakes (EaGL) Theory of Computation workshop provides an opportunity for interaction among the thriving collection of theory of computation (ToC) researchers living within a few hours driving distance to Buffalo. The community served by the workshop is large and growing: the region's colleges and universities have more than 90 ToC researchers, including at least 14 junior faculty hired since 2004, at institutions ranging from large research universities such as Carnegie Mellon to small colleges such as Oberlin. The presence of such a large concentration of ToC researchers presents a unique opportunity to gather locally and foster new research collaborations.<br\/><br\/>The main beneficiaries of the workshop are the graduate students in the area who get an opportunity to interact with leaders in ToC in the region (including three Turing award winners and a MacArthur fellow) in a small, relaxed setting. In addition to featuring six invited speaker talks, the workshop includes shorter talks by a few students who are nearing graduation.<br\/><br\/>The award will fund the workshop for the years of 2009 and 2010. This is expected to help it make the transition to an annual meeting. In 2009, the EaGL Workshop will feature technical talks by the following speakers: Allan Borodin (University of Toronto), Mark Braverman (Microsoft Research), Nick Harvey (University of Waterloo), Dexter Kozen (Cornell University), Katrina Ligett (Cornell University) and Adam Smith (Pennsylvania State University). Slides as well as video recordings from the talks will be provided freely on the workshop webpage.","title":"Eastern Great Lakes Theory of Computation Workshop","awardID":"0942511","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["550387"],"PO":["565251"]},"159784":{"abstract":"This award supports the Artemis project, a 5-week Summer program administered by Brown University's Department of Computer Science designed to encourage girls from local public schools to pursue careers in Computer Science, and more broadly in science and engineering. Participants are rising ninth graders and are exposed to the breadth of applications of Computer Science, and are introduced to a variety of the technologies underlying computing. An equally important goal of Artemis is to develop the leadership and entrepreneurial skills of undergraduate women who serve as coordinators each year. These coordinators serve the local community in their capacity as social entrepreneurs.","title":"The Artemis Project","awardID":"0943304","effectiveDate":"2009-09-01","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["517963"],"PO":["491702"]},"154097":{"abstract":"Power consumption is an increasingly important issue across society.<br\/>For communication, as the ranges of links in wireless networks<br\/>continue to shrink, the power consumed in the encoding and decoding<br\/>becomes a decidedly nontrivial factor in the choice of system<br\/>architecture. This is particularly important in settings such as<br\/>wireless patient monitoring, personal area networks, sensor networks,<br\/>etc. Shannon's classical information theory only established the<br\/>tradeoff between rate and transmit power as the probability of error<br\/>goes to zero and the block-length goes to infinity. This research is<br\/>about giving new conceptual tools for reasoning about the power<br\/>consumption in encoding and decoding as well. The core idea is that in<br\/>the age of billion transistor chips, the proper metric for complexity<br\/>is the power consumed by the implementation.<br\/><br\/>Just as simplified channel models have enabled sophisticated analysis<br\/>that has revealed deep insights into error correction and transmit<br\/>power, this research develops simplified implementation models that<br\/>are amenable to analysis. This reveals the fundamental tradeoffs<br\/>underlying the interplay between transmission and processing<br\/>powers. Crucially, the models developed are compatible with modern<br\/>approaches to iterative and \"turbo\" decoding by massively parallel<br\/>ASICs, while also not being limited to just the currently known<br\/>families of sparse-graph codes. By developing a unified mathematical<br\/>framework, this research allows us to understand the total power cost<br\/>of meeting performance objectives like high rate, low distortion, low<br\/>delay and low probability of error. This in turn leads to an<br\/>understanding of how to better engineer wireless systems as a whole:<br\/>opening up avenues for collaboration between circuit designers,<br\/>communication theorists, and networking researchers working at higher<br\/>layers.","title":"CIF: Small: Power Consumption in Communication","awardID":"0917212","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["560235"],"PO":["564924"]},"156286":{"abstract":"Collaborative Research: Recovery of 3D Shapes from Single Views<br\/><br\/>Zygmunt Pizlo, Purdue University<br\/>Longin Jan Latecki, Temple University<br\/><br\/>The human eye, like a camera, produces 2-dimensional images of a 3-dimensional world. How does the human brain succeed in interpreting these impoverished 2-dimensional images, allowing us to see the world as it actually is \"out there?\" This fundamental question, whose significance has been appreciated for 300 years, has not been answered despite the efforts of many scientists, engineers and mathematicians. Conventional approaches, which have not been successful, tried to recover the 3-dimensional shapes of objects and scenes from their 2-dimensional images by analyzing the depths of surfaces in multiple images (such as might be obtained from two eyes or from moving images) and by emphasizing the role of learning and familiarity. The approach taken by Zygmunt Pizlo at Purdue University and Longin Jan Latecki at Temple University is very different. It uses only a single 2-D image to recover the third dimension by applying a priori constraints (assumptions about the world built-in to the human visual system) that reflect important visual properties that are generally present in the physical world, properties such as the symmetry and compactness of 3D objects. <br\/><br\/>Pizlo and Latecki's research has the potential of encouraging theoretical changes in the study of human perception because it uses an entirely new approach to a classical unsolved problem in vision. It could support breakthroughs in machine vision because human beings are known to be much better than any machine confronted with recovering the 3D world from 2D information. Machine vision has important applications to many domains, including law enforcement and national security. Pizlo and Latecki's research attempts to solve the visual 3D shape problem by combining the results of experiments on human observers with state-of-the-art computational modeling. The project will provide an excellent opportunity for the interdisciplinary education of graduate and undergraduate students in psychology, computer science and engineering.","title":"Collaborative Research: Recovery of 3D Shapes From Single Views","awardID":"0924859","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[416761],"PO":["497399"]},"159322":{"abstract":"DePauw University with the collaboration of the Anita Borg Institute (ABI) and the University of Virginia, and in partnership with the ACM Women's Council (ACM-W) and the National Center for Women and IT (NCWIT), proposes to create self-sustaining, regional communities of women in computing. National-level activities, such as the Grace Hopper Celebration of Women in Computing, have positively impacted thousands of women. They cannot, however, reach all women. In particular, national meetings have limited ability to recruit women from isolated areas of the country, to include women at institutions that cannot afford expensive and time-consuming travel to national meetings, to provide leadership roles, to encourage participation by high school students, and to support interactions that are frequent enough to spark and sustain collaborations among budding students and professionals. This project -- called WWW.2 for Wide Web of Women -- aims to overcome these impediments. The project will create twelve new and upgraded Regional Celebrations of Women in Computing that will bring students, faculty and indistry representatives together for biennial conferences. The conferences will increase women?s participation in computing through intentional role modeling, networking, group and indivudal career mentoring, providing career information, and oportunities for experiences in presenting their work. The attendees will be encouraged to continue their interactions between Celebrations, for example, by forming ACM-W student chapters, hosting multi-institutional get togethers, and maintaining connections through a wiki. Focusing on women (as well as regions) serves a population powerfully united by gender, yet diverse in experience, with personal stories varying by race, ethnicity, disability, and sexual orientation. This \"Web of Women\" will build momentum toward a tipping point of cultural change in stereotypes about gender and computing.","title":"BPC-A: Collaborative Research: WWW.2, a Wide Web of Women","awardID":"0940595","effectiveDate":"2009-09-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":[425926],"PO":["560704"]},"153790":{"abstract":"Approaches to subjectivity and sentiment analysis often rely on<br\/>manually or automatically constructed lexicons. Most such lexicons are<br\/>compiled as lists of words, rather than word meanings (\"senses\").<br\/>However, many words have both subjective and objective senses as well<br\/>as senses of different polarities, which is a major source of<br\/>ambiguity in subjectivity and sentiment analysis. The proposed work<br\/>addresses this gap, by investigating novel methods for subjectivity<br\/>sense labeling, and exploiting the results in sense-aware subjectivity<br\/>and sentiment analysis. To achieve these goals, three research<br\/>objectives are targeted. The first is developing methods for assigning<br\/>subjectivity labels to word senses in a taxonomy. The second is<br\/>developing contextual subjectivity disambiguation techniques to<br\/>effectively make use of the word sense subjectivity annotations. The<br\/>third is applying these techniques to multiple languages, including<br\/>languages with fewer resources than English. The project will have<br\/>broader impacts in both research and education. First, it will make<br\/>subjectivity and sentiment resources and tools more widely available,<br\/>in multiple languages, to the research community, which will help<br\/>advance the state of the art in automatic subjectivity analysis, which<br\/>in turn will benefit end applications. Second, several educational<br\/>goals will be pursued: training graduate and undergraduate students in<br\/>computational linguistics; augmenting artificial intelligence courses<br\/>with projects based on the proposed research, which will offer<br\/>students hands-on experience with natural language processing<br\/>research; and reaching out to women and minorities to increase their<br\/>exposure to text processing technologies and access to research<br\/>opportunities.","title":"RI: Small: Collaborative Research: Word Sense and Multilingual Subjectivity Analysis","awardID":"0916046","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[409250],"PO":["565215"]},"152591":{"abstract":"Research in machine translation of human languages has made substantial progress recently, and surface patterns gleaned automatically from online bilingual texts work remarkably well for some language pairs. However, for many language pairs, the output of even the best systems is garbled, ungrammatical, and difficult to interpret. Chinese-to-English systems need particular improvement, despite the importance of this language pair, while English-to-Chinese translation, equally important for communication between individuals, is rarely studied. This project develops methods for automatically learning correspondences between Chinese and English at a semantic rather than surface level, allowing machine translation to benefit from recent work in semantic analysis of text and natural language <br\/>generation. One part of this work determines what types of semantic <br\/>analysis of source language sentences can best inform a translation system, focusing on analyzing dropped arguments, co-reference links, and discourse relations between clauses. These linguistic phenomena must generally be made more explicit when translating from Chinese to English. A second part of the work integrates natural language generation into statistical machine translation, leveraging generation technology to determine sentence boundaries, ordering of constituents, and production of function words that translation systems tend to get wrong. A third part develops and compares algorithms for training and decoding machine translation models defined on semantic representations. All of this research exploits newly-developed linguistic resources for semantic analysis of both Chinese and English. <br\/><br\/>The ultimate benefits of improved machine translation technology are easier access to information and easier communication between individuals. This in turn leads to increased opportunities for trade, as well as better understanding between cultures. This project's systems for both Chinese-to-English and English-to-Chinese are developed with the expectation that the approaches will be applied to other language pairs in the future.","title":"RI: Large: Collaborative Research: Richer Representations for Machine Translation","awardID":"0910778","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["423553"],"PO":["565215"]},"162282":{"abstract":"Theoretical and computational investigations will be launched to address fundamental issues associated with analysis, control, and design of networked physical systems forming an autonomously cooperative team in the presence of another team of adversaries. The goal of the present work is to expand the scope of the theory that was developed earlier for the specific applications scenarios to wider set of dynamic applications where game theory (and control) potentially has a role to play. The range of such potential applications is are very broad including robotics, modeling of economies, energy distribution and biomedicine.<br\/><br\/>As for the technical contributions of this exploratory work one can expect results from several different perspectives. The first point of departure from traditional game theory namely that of the study of dynamic processes rather than the study of equilibria has been already mentioned. Second point of departure is that while optimal control and system theory had indeed made use of game theoretic techniques in the past, this body of literature was largely limited to linear processes. The present investigation will be far more general to include nonlinear, as well as hybrid (i.e., mixed continuous, discrete), and asynchronous systems as well. Thus, while guided by applications, developing a general theory would be expected outcome of the proposed research. A third point of departure is while earlier theories focused on obtaining analytical solutions, the results from present investigation (since it involves nonlinear processes) will of necessity be computational or algorithmic in nature.<br\/><br\/>The potential societal implications of the proposed theoretical\/computational work is great ranging from economics, biomedicine to defense applications. Since the PIs are in close contact with application domains and the industry the potential for transfer of innovative methods and tools to applications is tremendous. The PIs also plan to educate graduate students as well as undergraduate students on related topics.","title":"EAGER: Game and Teaming Strategies for Networked Systems","awardID":"0956501","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["545317","545318"],"PO":["562984"]},"151051":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project determines the fundamental limits of network secrecy from a network coding perspective, and then applies this theory to improve security guarantees in peer-to-peer and wireless networks. As network coding gains prominence as an important strategy for both wired and wireless networks, the project identifies both the advantages and vulnerabilities from using network coding. Subsequently, the effort develops a design methodology that exploits the advantages while carefully compensating for the vulnerabilities. <br\/><br\/>This project analyzes networks under both outsider and insider attacks. Specifically, coding mechanisms are developed to combat an external eavesdropper. Also, a combination of cryptographic and information-theoretic tools are used to combat internal modification attacks on the network. The results are then used in two case studies: eavesdropper attacks on wireless mesh networks and pollution attacks on P2P content distribution systems. <br\/><br\/>Secure network coded systems, once well understood, can greatly impact how networks are designed and deployed. Nearly every network setting (wireless, wired or heterogeneous) can benefit in terms of improved resilience (in addition to other performance benefits such as throughput) in its design. Case studies in this effort are designed to help transition the theoretical principles developed into practical algorithms. <br\/><br\/>The research team includes an industry member which will aid in transitioning our research ideas from theory to practice. The team will disseminate its findings through traditional scholarly venues, through the web and to the local community at each partner institution.","title":"NeTS: Medium: Collaborative Research: Secure Networking Using Network Coding","awardID":"0905615","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[402681],"PO":["557315"]},"151073":{"abstract":"Collaborative Proposal 0905684 (UCI ? Franz) \/ 0905650 (UCSC ? Flanagan)<br\/><br\/>Next-Generation Infrastructure for Trustworthy Web Applications<br\/><br\/><br\/>Abstract<br\/><br\/>Many services traditionally performed by stand-alone programs running on desktop computers are being migrated to ?Web 2.0? applications, remote services that reside ?in the cloud? and are that accessed through a browser. This migration process offers a unique opportunity to re-engineer the way that software is constructed, adding some extra capabilities that reduce the vulnerability of the global information infrastructure to problems such as viruses, cyber-attacks, loss of privacy, and integrity violations. <br\/><br\/>With this goal in mind, this project designs and implements a next-generation infrastructure for trustworthy web applications. It evolves the existing Web 2.0 technologies into a more trustworthy ?Web 2.Sec? version by introducing information-labeling and strong information-flow controls pervasively at the service provider, at the user?s end, and on all paths in between.<br\/><br\/>A key feature of the new Web 2.Sec architecture is that all application programs are executed on top of a virtual machine (VM) rather than directly on physical hardware. Hence the VM retains full control over the data at all times, allowing it to enforce information-&#64258;ow policies that guarantee con&#64257;dentiality and integrity. Even a malicious or faulty program running on top of the Web 2.Sec VM cannot cause any action that would violate these policies.<br\/><br\/>A strong educational component involving both graduate and undergraduate students rounds off the project.","title":"TC: Medium: Collaborative Research:Next-Generation Infrastructure for Trustworthy Web Applications","awardID":"0905684","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486136"],"PO":["565327"]},"154120":{"abstract":"In a not too distant future, assistive robots will become a natural part of the human society, in hospitals, schools, elder care facilities, inner city urban areas, and eventually homes. While wheeled robots, e.g., a humanoid torso on a mobile platform, can cover a range of tasks that assistive robots will be needed for, eventually, legged robots will be the most suitable, as legs increase the effective workspace of a robot and allow maneuvering more complex terrains like steps, curbs, and cluttered and rough terrains in general.<br\/>This project investigates biped locomotion with a Sarcos humanoid robot. In contrast to most other projects in biped locomotion, it emphasizes walking over uneven and rough terrain, obstacle avoidance, recovery from unexpected perturbation, and learning methods for motor control, as these issues seem to be the most important for working in dynamic and partially unpredictable human environments. Another focus is on dexterous movement control, i.e., control with a maximal amount of compliance and minimal negative feedback gains, using advanced operational space controllers with internal model control. Dexterous, compliant control will increase safety of the robot when accidentally impacting with humans or obstacles, and it will also allow the robot to recover more easily from external perturbation simply by ?giving in?. Such a control approach requires departing from the traditional high-gain position controlled humanoid systems, and focuses on torque control, reactive instantaneous control instead of finite horizon optimization, as well as efficient motion planning and learning methods.","title":"RI: Small: Learning Biped Locomotion","awardID":"0917318","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["492859"],"PO":["564069"]},"154010":{"abstract":"CCF-0916893<br\/>SHF:Small: IMUnit: Improved Multithreaded Unit Testing<br\/>PIs: Darko Marinov and Grigore Rosu<br\/><br\/>Computing is going through a paradigm shift from a mostly sequential worldview to a mostly parallel worldview. The currently dominant programming model for parallel code is that of shared data, where multiple threads of computation communicate by accessing shared data objects. Unfortunately, developing and testing multithreaded code is very hard. To significantly improve testing of multithreaded code, this project develops a set of new techniques and tools for multithreaded tests. A multithreaded test is a piece of code that creates and executes two or more threads. Executing a test follows some schedule\/interleaving of the multiple threads. The key of the new approach is to allow the explicit specification of a set of relevant schedules for each test, while traditional tests implicitly specify all possible schedules. This project addresses three important challenges for multithreaded tests: (1) How to describe a set of schedules and which schedules from a given set to explore? (2) How to automatically generate multithreaded tests, especially schedules, for given code? (3) How to select and prioritize rerunning of the multithreaded tests when the code changes? Improved unit testing of multithreaded code has the potential to substantially increase the quality of developed code.","title":"SHF: Small: IMUnit: Improved Multithreaded Unit Testing","awardID":"0916893","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["549774","518574"],"PO":["551712"]},"154131":{"abstract":"This project aims to advance neural data analysis and image processing by exploiting the structure in multivariate phase representations. Combining insights from neural computation with advances in multivariate statistics, mathematical signal analysis, and machine learning, the project aims to build multivariate statistical models of angular variables that capture the dependencies between complex and hypercomplex phase variables. Recursive estimation techniques will be developed to allow for optimal estimation of distributions from noisy data and prediction of their temporal evolution. The models developed in this proposal will be applied to current problems in neuroscience and image processing.<br\/><br\/>As a foundation for the application domains, a recently developed method for estimating the parameters of stationary multivariate phase distributions will be generalized to situations in which the parameters are time-varying and the measurements are noisy, linear mixtures of the underlying sources. A recursive filtering model, similar to the classical Kalman filter, will be developed, that produces an optimal online estimate of latent phase variables in response to a sequence of noisy measurements.<br\/><br\/>In the first application domain, this model will be used to infer connectivity and temporal interactions among populations of neural oscillators from physiological measurements. The model will also be used to detect transient changes in connectivity by utilizing a mixture model of phase dynamics. These estimation techniques will be evaluated on simulated data and then applied to the analysis of neurophysiological recordings to better elucidate network dynamics.<br\/><br\/>In the application domain of natural image statistics, the model will be extended to handle hypercomplex phase variables in order to model the phase and orientation of edges in natural images, which contain rich information that may be exploited for image analysis and object recognition. The project aims to develop a model that describes the spatial dependencies among these variables as a nonlinear mixture of multivariate phase distributions.<br\/><br\/>https:\/\/redwood.berkeley.edu\/wiki\/NSF_Funded_Research","title":"Small: RI: Multivariate Phase Models for Image and Signal Processing","awardID":"0917342","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["483816",410105],"PO":["564318"]},"157772":{"abstract":"CPS: Small: Transforming a City's Transportation Infrastructure through an Embedded Pervasive Communication Network<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this inter-disciplinary research is to develop new technologies to transform the streets of a city into a hybrid transportation\/communication system, called the Intelligent Road (iRoad), where autonomous wireless devices are co-located with traffic signals to form a wireless network that fuses real-time transportation data from all over the city to make a wide range of new applications possible. The approach is to build new capacities of quantitative bandwidth distribution, rate\/delay assurance, and location-dependent security on a pervasive wireless platform through distributed queue management, adaptive rate control, and multi-layered trust. These new capacities lead to transformative changes in the way the transportation monitoring and control functions are designed and operated. <br\/><br\/>Many technical challenges faced by the iRoad system are open problems. New theories\/protocols developed in this project will support sophisticated bandwidth management, quality of service, multi-layered trust, and information fusion in a demanding environment where critical transportation functions are implemented. Solving these fundamental problems advances the state of the art in both wireless technologies and transportation engineering. The research outcome is likely to be broadly applicable in other wireless systems. <br\/><br\/>The economic and societal impact of the iRoad system is tremendous at a time when the country is modernizing its ailing transportation infrastructure. It provides a pervasive communication infrastructure and engineering framework to build new applications such as real-time traffic map, online best-route query, intelligent fuel-efficient vehicles, etc. The research results will be disseminated through course materials, academic publication, industry connection, and presentations at the local transportation department.","title":"CPS:Small: Transforming a City's Transportation Infrastructure through an Embedded Pervasive Communication Network","awardID":"0931969","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["485310","535333"],"PO":["564778"]},"154021":{"abstract":"Interactivity has become ubiquitous in the digital media landscape. From scrollbars in mobile texting devices to customization options in Web portals to chat functions on social-networking sites, there has been a proliferation of interactive tools affording enhanced user interaction with the system. While studies in the past have assessed the efficacy of individual tools, we have precious little generalizable knowledge about the larger concept of interactivity. How does interactivity affect user experience? Does it always ensure richer user engagement with the medium? The research will experimentally investigate three species of interactivity corresponding to the three central elements of communication -- source, medium, and message. Data will be used to articulate three ordinal levels of each type of interactivity, which will then be operationalized and used in further experiments to detect the combined effects of the three types of interactivity on user engagement as well as other outcomes of interest for both power users and regular users of Web interfaces. The research will assess the validity of conceptualizing interactivity in terms of multiple loci and more importantly, explore theoretical mechanisms by which interactivity is believed to affect user engagement.<br\/><br\/>A scientific understanding of the psychological effects of interactivity is quite critical for a society that is becoming saturated with interactive digital media. Dissemination of the proposed work will likely spawn a new wave of theoretically driven interactivity research. Research results will feed directly into design of interfaces for a variety of purposes, from learning systems to serious games. The proposed comparison between power users and regular users will shed light on interactivity's potential to bridge the digital divide. Equipment budgeted for lab studies will enhance infrastructure for research and education at Penn State's Media Effects Lab.","title":"HCC: Small: Interface Interactivity and User Engagement: A Communications Perspective","awardID":"0916944","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[409835],"PO":["565342"]},"154142":{"abstract":"In just a decade, dynamic invariant inference has emerged as one of the most promising directions in program analysis, with a variety of applications. An invariant inference system observes a program during test execution and filters a large number of candidate invariants (i.e., suspected relations between program data), finally reporting only those that hold with high confidence. However, inferred invariants are not always true (they depend on the quality of a test suite), and the few really useful invariants discovered are often accompanied by many more true but trivial and irrelevant facts. This work improves the quality of discovered invariants by ensuring their consistency with facts that are known statically. For instance, even though the invariants describing the behavior of two functions f1 and f2 may be unknown, we may know that any valid input for f1 is also valid for f2. This fact can be incorporated in the inference process to eliminate inconsistent invariants. More generally, the work explores techniques for expressing, discovering, and employing such consistency constraints to improve the quality of produced invariants, from type information and other sources including static analysis and user-supplied annotation.<br\/><br\/>The work will impact many aspects of software engineering, including scientific and industrial uses. Concrete benefits will be in the form of publications, usable software (released under an academic open-source license), software prototypes, and educational activities and resources (enhancement of a textbook and current courses, internships for high school students).","title":"SHF: Small: Collaborative Research: Dynamic Invariant Inference, Enhanced","awardID":"0917391","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["451330"],"PO":["565264"]},"148950":{"abstract":"With this instrumentation grant, the principal investigator will build a realistic access and home networking environment in Princeton's Networked End User Lab (NEULab) including a DSL access system, a cable modem access system, and a home network with triple screens: HDTV with set-top box, computer, and a variety of mobile devices. This testbed will be connected to national backbone testbed VINI via GigE links and a configurable router. <br\/><br\/>The PI will run a variety of experiments, based on theoretical foundation and in turn shaping the development of theory, on network architectures, protocols, algorithms supporting media-rich triple-play applications over constrained last hop and heterogeneous home networks. Through this proposal, several key parts of NEULab will be established, especially on DSL access network, cable modem access network, and triple-screen home network. The key equipments include DSLAM, CMTS, Spirent channel emulators, copper-farm, home gateways, two stages of switches, and consumer electronics with WLAN capabilities.<br\/><br\/>Intellectual Merit: Existing mathematical theories and algorithms developed in the following areas will be validated or falsified, and future ones inspired by the proposed testbeds: Broadband access fiber\/DSL networks, P2P content distribution, content-aware networking, distributed scheduling algorithms, joint power control and scheduling, stochastic network utility maximization, and green information technology. Open issues involving metrics that are difficult to be analytically characterized, such as delay, jitter, and rate of convergence, will also be addressed. A list of 9 challenging questions that can be answered in the testbed is provided under these 7 research areas. <br\/><br\/>Broader Impacts: This proposal represents a strategy built on top of the PI?s industry collabora- tions and technology transfers to accelerate the transfer of theory into practice, through a set of experimental platforms under the umbrella of NEULab within Princeton University. The PI will also actively involve undergrad students in the construction and running of the experimental facilities through their independent work and undergrad theses, and hold summer undergraduate program open to 10 undergrads outside Princeton every year.","title":"II-NEW: Advancing Access and Home Networking Research in NEULab","awardID":"0855144","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["561963"],"PO":["565090"]},"157783":{"abstract":"CPS: Small: Programming Environment and Architecture for Situational Awareness and Response<br\/><br\/>The objective of this research is to investigate and implement a software architecture to improve productivity in the development of rapidly deployable, robust, real-time situational awareness and response applications. The approach is based on a modular cross-layered architecture that combines a data-centric descriptive programming model with an overlay-based communication model. The cross-layer architecture will promote an efficient implementation. Simultaneously, the data-centric programming model and overlay-based communication model will promote a robust implementation that can take advantage of heterogeneous resources and respond to different failures.<br\/><br\/>There is currently no high-level software architecture that meets the stringent requirements of many situational awareness and response applications. The proposed project will fill this void by developing a novel data-centric programming model that spans devices with varying computational and communication capabilities. Similarly, the overlay communication model will extend existing work by integrating network resources with the programming model. This cross-layer design will promote the implementation of efficient and robust applications. <br\/><br\/>This research will benefit society by providing emergency responders with software tools that present key information in a timely fashion. This, in turn, will increase safety and reduce economic and human loss during emergencies. The productivity gains in deploying sensors and mobile devices will benefit other domains, such as field research using sensor networks. Software will be released under an open-source license to promote the use by government agencies, research institutions, and individuals. Products of this research, including the software, will be used in courses at the University<br\/>of North Carolina.","title":"CPS: Small: Programming Environment and Architecture for Situational Awareness and Response","awardID":"0932011","effectiveDate":"2009-09-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[421136],"PO":["565136"]},"154032":{"abstract":"This research addresses open questions on the interaction of aging, financial security in an information society, and elder perceptions of the risks of digital information technologies. The end technological goal is to improve the design of security and privacy technologies for older Americans. Note that security on the Internet is designed by younger, risk-seeking technologists who are primarily male. Those over 65 who require a secure Internet are by definition older, also risk-averse, rarely technologists, and more often than not female. It is not surprising that there is a mismatch between the mental models of secure system designers and this growing group of users. In terms of method, this research will include an examination of the value of multimedia combined with the scale enabled by traditional surveys. Specifically, the research will evaluate the inclusion of multimedia interactive technologies in terms of enabling inclusion of the nuance previously possible only in smaller scale qualitative work.<br\/><br\/>The implications of computer security being systematically ill-suited for elders are profound, and improving this mismatch is the broader implication of this work. Never has so much wealth been accessible with such ease by so many predators. Organized crime reaches out from remote jurisdictions, where American law enforcement cannot reach back. The combination of the concentration of wealth among Americans over age 65, the global unsecured network, availability of personally identifiable information used for authentication, increasingly organized online crime, and the disproportionate lack of technical expertise among elders can create a perfect digital storm. Yet this problem is profoundly under-studied. Without computer security technology built to serve elders, these risks cannot be effectively, systematically addressed.","title":"HCC: Small: View of Privacy in Older Adults","awardID":"0916993","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486499",409862,"537066"],"PO":["564456"]},"148961":{"abstract":"In this project, the PIs propose to construct and develop a shared infrastructure to support the collection and maintenance of realistic, large scale spam data sets, <br\/>referred as SPAM Commons.<br\/><br\/>Spam is a problem in many important communications media such as email and web. A sub-problem of spam, phishing (a form of online pretexting), caused an estimated $3.2B in damages in 2007. The broad impact of effective spam filtering methods can be estimated in billions of dollars in several communications media such as email and web.<br\/><br\/>Spam has also invaded other media, with concrete attack examples in social networks, blogosphere, Internet telephony (VoIP), instant messaging, and click fraud. <br\/><br\/>Unfortunately, spam research has been hampered by the lack of published real world data sets due to concerns with privacy and company intellectual property. This project team develops a shared infrastructure to support the collection and maintenance of realistic, large scale spam data sets, called Spam Processing, Archiving, and Monitoring Community Facility (SPAM Commons). <br\/><br\/>The main goals of SPAM Commons are: <br\/>(1) to facilitate remedial research that will stem the wastes and losses caused by spam, and <br\/>(2) enable revolutionary research that aim for stopping certain kinds of spam attacks altogether. <br\/><br\/>SPAM Commons is divided into a Public Partition and a Protected Partition.<br\/><br\/>The Public Partition is a direct analog of standard corpora for speech and image recognition research, consisting of a systematic and regular collection of both spam and legitimate data in the various communications media, starting from email and web spam, and expanding into other communications media as spam becomes a serious threat in each area and data become available. <br\/><br\/>The Protected Partition consists of a combined data and processing facility that makes private data or near real-time spam data available for experimental evaluation of spam defense mechanisms in a protected testbed. Access to such protected data will enable new spam research on real-time evolving spam and real world data sets that is infeasible today. <br\/><br\/>The intellectual challenges of the SPAM Commons project extend beyond the new research on various abovementioned spam areas enabled by the availability of data sets. The construction of both partitions of SPAM Commons includes significant intellectual challenges of their own. First, the isolation of Protected Partition addresses partially the concerns of privacy, which remains a general research problem. Second, useful spam and legitimate data sets require automated distinction of spam from legitimate documents with certainty, which remains an open research question in email, web, and other media. Third, the adversarial and mutual evolution of spam producers and defenders require continuous collection of fresh data for further study. Finally, the collection and streaming of near-real-time spam data represent research resources currently unavailable to spam researchers. Advances in these areas will spur the growth and evolution of SPAM Commons that will enable new research on the evolving and growing spam problem.<br\/><br\/>The impact of SPAM Commons data sets on experimental spam research may be similar to the impact of large corpora in disciplines such as speech\/image recognition and natural language processing, which achieved a level of scientific result reproducibility and comparativeness after the use of such corpora became standard requirements. The proposed data repository will be supported and used by 9 university partners (Clayton State, Emory, Georgia Tech, NC A&T, Northwestern, Texas A&M, UC Davis, U. Georgia, UNC Charlotte), and several industry partners (IBM, PureWire, Secure Computing).","title":"II-NEW: Collaborative Research: Spam Processing, Archiving, and Monitoring Community Facility (SPAM Commons)","awardID":"0855180","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["549757","532971"],"PO":["565327"]},"159972":{"abstract":"Divide-and-conquer and prune-and-search are two fundamental and ubiquitous paradigms in the design of algorithms. The first refers to the process of (i) splitting a given problem into smaller sub-problems, (ii) solving each of these subproblems, and then (iii) combining these solutions to obtain the solution to the original problem. The second is a way of searching among possible solutions to a given problem whereby (a) the possible solutions are split into several groups, then (b) all but one of the groups is somehow eliminated, and finally (c) the search continues, now confined to the one remaining group. It is noteworthy that in both approaches, sets are ``split'' into smaller ones - step (i) in divide-and conquer and step (a) in prune-and-search - and that in addition, many efficient and beautiful algorithms are based on one of these approaches. A main goal of this project is the development of some unusual, new, splitting tools that may be used in these paradigms. They will be sought from within an unexpected domain - geometric partitioning theorems. Topological methods have been applied to obtain facts like the ham-sandwich theorem, but there has not been much work on their algorithmic aspects, and what results we do have suggest that they would not be very useful as splitting tools for other algorithms. However some recent partitioning results of the investigator encourage the search for more tools of this kind.<br\/><br\/>Therefore this work will continue to seek new geometric partitioning results that can give novel, useful, splitting tools. Simultaneously the project will address a specific set of concrete, stubborn computational problems that arise frequently, and naturally, but have so far resisted efficient solutions. The goal is to better understand the complexity of these important and interesting problems, and to apply the new tools to obtain effective algorithms. Part of the intellectual merit of the project rests on the unusual approach to develop new algorithmic tools; in addition there is chance to make progress on a set of prevalent, hard, computational problems. Broader impacts reside in the potential to strengthen connections between geometry, combinatorics, and computation.","title":"AF:EAGER: Combinatorial Geometry, Partitioning, and Algorithms","awardID":"0944081","effectiveDate":"2009-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7939","name":"WIRELESS COMM & SIGNAL PROCESS"}}],"PIcoPI":[427946],"PO":["565157"]},"143274":{"abstract":"Many situations in society involve matchings. Workers are matched to jobs, students to schools, conference papers to reviewers, patients to organ donors, etc. Those involved have preferences which are often expressed as rankings of their potential partners. An important goal of a centralized match-maker is to produce a \"good\" matching that takes into account the preferences of all the participants. Perhaps the most important example of a matchings-with-preferences problem is the stable marriage problem. In some contexts, however, other kinds of matchings are more meaningful.<br\/><br\/>This research studies computational and structural issues that arise from matchings-with-preferences problems. The first part investigates various ways of choosing a fair matching -- an issue that comes up repeatedly as organizers of centralized matching schemes need to ensure that none of the participants have an advantage. Three criteria for fairness are considered. Let M consist of all valid matchings of an instance. A matching is fair if it is (i) a median element of M whose elements are ordered appropriately, if it is (ii) a winner of an election where participants vote which matching in M they prefer, or if it is (iii) chosen uniformly at random from M. In each case, the objective is to design provably good algorithms for finding or approximating a fair matching. In practice, participants' preferences are often allowed to contain ties and be incomplete. As a result, surprising complexities arise. For example, two stable matchings from the same instance do not necessarily have the same size. The second part of this research seeks to develop efficient algorithms for finding \"ideal\" stable matchings in these situations, and to analyze existing algorithms to determine the quality of the stable matchings they produce. In addition to impacting the way current centralized matching algorithms are designed, this research aims to make connections between the area of matchings-with-preferences and the fields of distributive lattices, voting theory and random sampling by viewing the problems in a broader context.","title":"Problems in Matchings with Preferences","awardID":"0830678","effectiveDate":"2009-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[381495],"PO":["565251"]},"154043":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The edge of the Internet continues to spread rapidly over the wireless medium. To cope with the escalating demand, every available opportunity in wireless networking will has to be maximally exploited, particularly at the border of physical and higher layers. One such opportunity is the capability of successfully capturing a frame even in the presence of an interfering frame, i.e., message-in-message (MIM). With MIM, two concurrent transmissions may be successful if they are activated in a specific order, but not the reverse. Towards harnessing MIM, this project aims to: i) Understand the intrinsic potential of MIM through theoretical analysis; ii) Draw on this understanding to design efficient higher layer protocols; iii) Develop a prototype testbed to validate\/evaluate the MIM-aware protocols.<br\/><br\/>This project offers obvious benefits to the broader community as it attempts to satiate the growing demand for bandwidth hungry applications over wireless networks by extracting the most from the scant spectral resources. Additionally, this project facilitates: i) Development and strengthening of the laboratory and curriculum for wireless networking at University of South Carolina and Duke University; ii) Involvement and mentoring of undergraduate students in wireless networking research; iii) Deployment of experimental wireless technologies within The Duke SmartHome.","title":"NeTS: Small: Collaborative Research: Transmission Reordering in Wireless Networks: Protocols and Practice","awardID":"0917020","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["451202"],"PO":["557315"]},"158531":{"abstract":"Proposal #: 09-35936<br\/>PI(s): von Thater-Braan, Rose<br\/>Institution: Silver Buffalo C.<br\/> Pt. Richmond, CA 94801-0000 <br\/>Title: SpProj.: Exploring the Foundations of Diversity: A Trans-Cultural Learning Lodge<br\/><br\/>Project Proposed:<br\/>This very non-traditional project for a relatively focused audience, aiming to teach, train, and learn, takes place across the larger academic environment, particularly within the Native American (NA) communities. To augment the more formal methodologies of conferences, papers, and lecture-based learning, the project intends to enhance understanding for the scientific community on a more personal network level. Using the Socratic method combined with the dialog processes should encourage a renewed focus on people-to-people, face-to-face learning beyond iPhone, Facebook, texting, and internet-based tools more commonly used in today's world. The work enables broader dissemination of results through selected workshops for the wider NA community, and even diverse groups across the university community and government agencies. The proposal states: 'Trans-cultural learning is rigorous primarily because it requires suspension of unexamined assumptions and reveals the cultural lens through which we view one another.' Thus, the work constitutes an educational policy effort, offering several 'convenings' focused on science, engineering, and educational policies and strategies. The basic concept of the 'convenings,' a Native American Concept, uses a forum, a lodge, or a wide-area discussion at which all aspects of the topic area are discussed and heard before any decisions or dissentions are admitted. Since this idea is used in places like Mongolia and Central Asia (e.g., the lawya jurga of Afghanistan), the concept may well be Asian in origin. The NA form of such meetings is couched in the form of 'lodges' in the project. The work has the potential for creating a broader understanding of a more informal technology known as 'talking circles' in 'Indian Country.' By its very nature, the proposed meetings are diverse and open to all subject areas within the umbrella of science, engineering, and education. Various events will be held to which NSF personnel and some PIs will be invited and at which Native scientists, scholars, educators, and traditional knowledge holders would attend with the purpose of exposing the attendees to the Native learning processes, culture, and knowledge, thus opening new ways of thinking and other cultures that approach knowledge and life in different ways. The project encourages diversity in science endeavors, both among the people involved in science and in the approaches to scientific research. The work enables understanding alternative sources of knowledge and generates 'shared perspectives from which radical new approaches may address commonly held goals.'<br\/><br\/>Broader Impacts: This project is all about broader impact. In the past three years the American Society of Engineering Education (www.asee.org) has focused on a similar 'year of dialog' approach with excellent results in increased informal networking among the members and has established several Special Interest Groups (SIGs) within the Corporate Member Council. The Learning Lodge exhibits the same potential for success via outreach encompassing diversity, K-12, and life-long learning forums.","title":"Exploring the Foundations of Diversity: A Trans-Cultural Learning Lodge for National Science Foundation Program Directors","awardID":"0935936","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7680","name":"ENG DIVERSITY ACTIVITIES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7607","name":"ENERGY,POWER,ADAPTIVE SYS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0706","name":"Division of DESIGN & MANUFACTURING INNOV","abbr":"DMI"},"pgm":{"id":"1468","name":"Manufacturing Machines & Equip"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"1402","name":"BIOCHEMICAL & BIOMASS ENG"}}],"PIcoPI":[423641],"PO":["557609"]},"148983":{"abstract":"Through Grid and Cloud computing, the importance of distributed computing has risen dramatically in recent years, increasing the computational power available to a widening audience of scientific and commercial users. Gains in computing power have caused a drastic increase in the volume of data produced by users, requiring new research on improved management and access to distributed data. These gains also drive the need for efficient scheduling and leasing of computational resources and for adapting current work in machine virtualization to a distributed context. These research directions require the development and evaluation of new models for computational, communication, and storage costs, but existing infrastructure makes model evaluation difficult or impossible, since they are in constant use by other researchers.<br\/>This project addresses these concerns by providing a diverse group of researchers with a Distributed Research Testbed (DiRT) on which to develop and evaluate new technologies. The clusters making up the testbed are located at the University of Chicago, the University of Florida, the University of Hawai?i, the University of Notre Dame, and the University of Mississippi. Unlike working grid environments, we have complete low-level control of the hardware and complete knowledge of where the data and computation are located. We will use the testbed to address problems faced today by the growing number of users of distributed computing. Because high performance computing is essential to the conduct of modern science, this project will have significant impact on research and education in a a wide variety of scientific disciplines.","title":"Collaborative Research: II-New: Distributed Research Testbed (DiRT)","awardID":"0855245","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[397101],"PO":["564778"]},"154065":{"abstract":"Energy-efficient wireless communication is critical for long-term sensor network applications, such as military surveillance, habitat monitoring and infrastructure protection. To reduce the energy costs of RF listening, a node has to reduce its duty-cycle by sampling wireless channels very briefly and shutting down for long periods. Consequently, the connectivity of low-duty-cycle networks becomes time-dependent. Previous research in this type of networks predominately focused on physical and link-layer designs. This project is positioned to provide significantly added value to these earlier successful research by conducting the first systematic research at the network layer for low-duty-cycle communication under a wide spectrum of network configurations covering a large design space. The key research challenge addressed by this project is to optimize networking performance (e.g., delay, reliability, and cost) in the presence of sleep latency and other practical considerations including (i) unreliable links, (ii) dynamic energy availability, and (iii) mobility. With a successful outcome from this project, long-term sensor applications can be supported by low-duty-cycle networking technologies, leading to significantly reduced costs in development, deployment, and maintenance. These applications, in turn, can improve the safety of transportation, the quality of education and learning, and the development of innovations in many scientific frontiers. <br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).","title":"NeTS: Small: Addressing Research Challenges in Low-Duty-Cycle Wireless Sensor Networks","awardID":"0917097","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["526936"],"PO":["565303"]},"148994":{"abstract":"The NetFPGA platform makes it easy for students and researchers to build and deploy high-performance networking systems using Field Programmable Gate Array (FPGA) hardware. FPGA logic is used to process packets at line-rate, while software running on an attached host computer implements control functions. <br\/><br\/>The principal investigators (PIs) began the beta program in January of 2008 and made the NetFPGA hardware available to any school by providing a copy of the source-source schematic and printed circuit board design to a low-cost 3rd party manufacturer. To keep the hardware cost low, they asked semiconductor companies to donate the components used on the NetFPGA. Today, every major component on the board is donated as a gift by Xilinx, Broadcom, Micron, and Cypress. The PIs also made the open-source software, gateware, courseware, and reference designs for the NetFPGA freely available on the NetFPGA.org website. <br\/><br\/>Broader Impact <br\/><br\/>The community is growing and contributing back feedback, creating new courses, and creating new applications for the NetFPGA. Going forward, the PIs want to continue their outreach program to include deployment of NetFPGA hardware in backbone networks, other research laboratories, and classrooms in EPSCoR states. Where possible, they have raised industrial funds so they can donate NetFPGA systems to under-funded schools.<br\/><br\/>Intellectual Merit <br\/><br\/>Through this award the PIs plan to do five things: (1) Pay for professional staff to continue the operation of the NetFPGA program, (2) Design and develop new reference designs and applications for the community, (3) Acquire and deploy the NetFPGA in many schools, particularly in EPSCoR states, and in national backbone networks, (4) Work with the community to create a self-supporting user-community within three years, and (5) Explore the design of a NetFPGA-10G ? a 10Gb\/s version of the platform.","title":"CI-ADDO-EN: NetFPGA Community Infrastructure Development and Operations of the NetFPGA","awardID":"0855268","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560546"],"PO":["564993"]},"154076":{"abstract":"CSR proposal #0917137<br\/><br\/>CSR:Small:Collaborative Research: FastStor: Data-Mining-Based<br\/>Multilayer Prefetching for Hybrid Storage Systems<br\/><br\/><br\/>Abstract<br\/><br\/>A large number of existing parallel storage systems consist of hybrid storage components, including solid-state drives (SSD), hard disks (HDD), and tapes. Compared with high-speed storage components (e.g. SSD and HDD), tapes inevitably become an I\/O performance bottleneck. Prefetching and caching are commonly employed techniques to boost I\/O performance by increasing the data hitting rate of high-end storage components. However, prefetching in the context of hybrid storage systems is technically challenging due to an interesting dilemma: aggressive prefetching schemes can efficiently reduce I\/O latency, whereas overaggressive schemes may waste I\/O bandwidth by transferring useless data from HDDs to SSDs or from tapes to HDDs. In this research project, called FastStor, we investigate new data-mining-based multilayer prefetching techniques to improve performance of hybrid storage systems. The goals of this research are to (1) design data-mining algorithms for multilayer prefetching; (2) develop predictive parallel prefetching mechanism for SSD-based storage systems; (3) implement parallel data transfer among SSDs, HDDs, and tapes; (4) develop meta-data management schemes; and (5) implement a simulation framework named FastStor-SIM. The developed toolkit can be used to improve the I\/O performance of data centers with hybrid storage systems. The research findings of this project are published in conferences or journals for public knowledge. Through the collaboration of Auburn University, South Dakota School of Mines and Technology, and the University of Southern Mississippi, PIs promote learning and training by exposing graduate and undergraduate students to technological underpinnings in the fields of storage systems.","title":"CSR: Small: Collaborative Research: FastStor: Data-Mining-Based Multilayer Prefetching for Hybrid Storage Systems","awardID":"0917137","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[409962,"559143",409964],"PO":["565255"]},"154087":{"abstract":"Ever since the first FORmula TRANslator, compilers have purported to<br\/>take an algorithm, formulated in human terms, and compile it to an<br\/>efficient executable. Practice clearly does not live up to this<br\/>ideal, as programming languages force execution-oriented design<br\/>decisions on the programmer, and compiler imperfections necessitate<br\/>further manual optimizations. While the ordinary programmer can<br\/>ignore this problem by using libraries, the library developer cannot.<br\/>The problem appears more desperate now than ever, since it is not<br\/>known what form future architectures will take, combined with a trend<br\/>towards pushing complexity away from the architecture (for example to<br\/>lower power consumption) and onto the program and compiler.<br\/><br\/>The FLAME project already allows linear algebra libraries to be<br\/>developed and coded at a high level of abstraction that better<br\/>captures the underlying algorithms. It has already been shown that<br\/>these technique greatly simplify the porting of libraries to different<br\/>platforms ranging from conventional sequential computers to exotic<br\/>multiGPU accelerators. However, the APIs for coding at a high level<br\/>of abstraction incur a considerable performance penalty for operations<br\/>that in each step perform relatively little computation (e.g., level-2<br\/>BLAS operations and ``unblocked'' algorithms). As a result, a<br\/>nontrivial part of libflame, the library that has resulted from the<br\/>project, still requires coding at a low level.<br\/><br\/>The project will develop a source-to-source translator will take<br\/>algorithms expressed at a high level of abstraction and will transform<br\/>these into a range of representations, including high-performance<br\/>low-level code. This will overcome the final legitimate objection to<br\/>the FLAME methodology since coding at a high level of abstraction will<br\/>no longer carry a performance penalty. The approach will be<br\/>generalized so that code transformations that an expert applies by<br\/>hand in order to target different platforms will be made mechanical.<br\/>Together, these represent a major departure from traditional<br\/>approaches to library development.","title":"SHF: Small:Transforming Linear Algebra Libraries","awardID":"0917167","effectiveDate":"2009-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["556801","501527"],"PO":["565272"]},"154098":{"abstract":"High-end routers and switches perform performance-critical lookups<br\/>into large data based on network packet content. Current designs rely<br\/>on specialized hardware modules for high performance. While mostly<br\/>sufficient, emerging new protocols create a problem; for these to be<br\/>deployed, expensive equipment upgrades are required. To support the rapid deployment of new data plane protocols, we need a flexible hardware\/software framework.<br\/><br\/>This project is developing such a unified framework for future<br\/>network devices with four components: a) an abstract execution model<br\/>to represent hardware, b) a toolchain to ease implementation, d)<br\/>quantitative performance evaluation of protocols, and d) programmable<br\/>hardware architectures specialized for the core operations in network<br\/>protocols. Leveraging trends in tiled architectures, the project is<br\/>developing a specialized tiled architecture that moves computation close<br\/>to storage and thus provide efficient lookups. The project is also<br\/>investigating how these design methodologies extend beyond protocol<br\/>processing to payload inspection as required by intrusion prevention,<br\/>application identification and other functionality.<br\/><br\/>Deploying and implementing new protocols is challenging. This project<br\/>will result in specification of flexible hardware for high-end<br\/>routers. This flexibility to support multiple protocols using a single<br\/>toolchain and architecture framework will reduce development costs of<br\/>future high-end routers and speedup the deployment of new<br\/>protocols. Another outcome will be the open-source release to<br\/>the academic community of the toolchain for developing high-speed<br\/>implementation of protocols, reference implementations of various<br\/>protocols, standard data sets, and a NetFPGA implementation of the<br\/>proposed hardware architecture.","title":"NeTS:Small:A Unified Lookup Framework to Enable the Rapid Deployment of New Protocols in High-Speed Routers","awardID":"0917213","effectiveDate":"2009-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[410016,"521594"],"PO":["564993"]},"159323":{"abstract":"DePauw University with the collaboration of the Anita Borg Institute (ABI) and the University of Virginia, and in partnership with the ACM Women's Council (ACM-W) and the National Center for Women and IT (NCWIT), proposes to create self-sustaining, regional communities of women in computing. National-level activities, such as the Grace Hopper Celebration of Women in Computing, have positively impacted thousands of women. They cannot, however, reach all women. In particular, national meetings have limited ability to recruit women from isolated areas of the country, to include women at institutions that cannot afford expensive and time-consuming travel to national meetings, to provide leadership roles, to encourage participation by high school students, and to support interactions that are frequent enough to spark and sustain collaborations among budding students and professionals. This project -- called WWW.2 for Wide Web of Women -- aims to overcome these impediments. The project will create twelve new and upgraded Regional Celebrations of Women in Computing that will bring students, faculty and indistry representatives together for biennial conferences. The conferences will increase women?s participation in computing through intentional role modeling, networking, group and indivudal career mentoring, providing career information, and oportunities for experiences in presenting their work. The attendees will be encouraged to continue their interactions between Celebrations, for example, by forming ACM-W student chapters, hosting multi-institutional get togethers, and maintaining connections through a wiki. Focusing on women (as well as regions) serves a population powerfully united by gender, yet diverse in experience, with personal stories varying by race, ethnicity, disability, and sexual orientation. This \"Web of Women\" will build momentum toward a tipping point of cultural change in stereotypes about gender and computing.","title":"BPC-A: Collaborative Research: WWW.2, a Wide Web of Women","awardID":"0940599","effectiveDate":"2009-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["513746"],"PO":["561855"]}}