{"176330":{"abstract":"The requirements for large-scale scientific visualization systems and large-scale scientific databases are converging. Visualization systems are being equipped with rudimentary query processing capabilities, observing that simply \"throwing datasets\" through the graphics pipeline ignores the scalable restructuring, manipulation, and filtering required by realistic applications. Further, there is increasing emphasis on in situ visualization --- execution of visualization and data processing on a single platform to avoid data transfer costs and afford new optimizations. In particular, the role of cloud computing as a large-scale visualizaton platform in addition to a large-scale data processing platform is underexplored.<br\/><br\/>In response to these pressures, the PI proposes a novel approach to the problem of scalable visualization, one informed by the algebraic query processing techniques developed by the database community coupled with recent advances in data-intensive scalable computing latforms such as MapReduce, Dryad, and their contemporaries. Specifically, the PI is developing an algebra of scalable visualization operators specialized for manipulating and visualizing mesh-structured datasets. The PI's previous work on an algebra for unstructured grid datasets found in finite element simulations provides a foundation, but does not support efficient parallel processing and cannot express certain common visualization tasks. Other existing systems favor depth over breadth, focusing on optimizations for specific visualization algorithms on specific hardware rather than a generic platform for visual analytics that can run on the shared-nothing clusters of commodity computers typically found in the cloud. The new approach, being developed and deployed on the Windows Azure platform, provides a core set of scalable primitives for manipulating mesh datasets using shared-nothing architectures, capable of expressing a variety of visualization algorithms, and amenable to algebraic reasoning and optimization.<br\/><br\/>For further information see the project web page: http:\/\/visdb.cs.washington.edu","title":"CIC: EAGER: Scalable Algebraic Visualization in the Cloud","awardID":"1060213","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8010","name":"Computing in the Cloud"}}],"PIcoPI":["531545"],"PO":["565136"]},"174010":{"abstract":"This project focuses on string theory, a leading candidate for unifying particle physics with gravity. The proposal aims to characterize features of the typical string compactification by applying algebraic geometry to study topological invariants of manifolds and to search for correlations between these data and structures relevant to model building, both in particle physics and cosmology. <br\/><br\/>This research is of interest to an interdisciplinary community of theoretical physicists, mathematicians and computer scientists. Researchers in this project are highly involved with the NSF-sponsored String Vacuum Project the results of this research are expected to cross-fertilize that endeavor. The software employed for computational algebraic geometry is publicly available, and the project involves several algorithmic improvements that can be incorporated into future versions of these codes. All computations are to be ported and developed for use in the Microsoft Azure platform.<br\/><br\/>This award corresponds to the Computing in the Cloud competition and is co-funded by the Office of Multidisciplinary Activities of the Directorate of Mathematical and Physical Sciences.","title":"EAGER: CiC: A String Cartography","awardID":"1048082","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8010","name":"Computing in the Cloud"}}],"PIcoPI":["548292"],"PO":["565272"]},"176067":{"abstract":"In High-End Computing (HEC), faults have become the norm rather than the exception for parallel computation on clusters with 10s\/100s of thousands of cores. As the core count increases, so does the overhead for fault-tolerant techniques relying on checkpoint\/restart(C\/R) mechanisms. At 50% overheads, redundancy is a viable alternative to fault recovery and actually scales, which makes the approach attractive for HEC.<br\/><br\/>The objective of this work to the develop a synergistic approach by combining C\/R-based fault tolerance with redundancy in HEC installations to achieve high levels of resilience.<br\/><br\/>This work alleviates scalability limitations of current fault tolerant practices. It contributes to fault modeling as well as fault detection and recovery in significantly advancing existing techniques by controlling levels of redundancy and checkpointing intervals in the presence of faults. It is transformative in providing a model where users select a target failure probability at the price of using additional resources.","title":"SHF: Small: RESYST: Resilience via Synergistic Redundancy and Fault Tolerance for High-End Computing","awardID":"1058779","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["553590"],"PO":["565272"]},"176078":{"abstract":"The 2010 Fall Workshop on Computational Geometry will be hosted at Stony Brook University, Stony Brook, NY, October 29-30, 2010.<br\/><br\/>The focus of this particular workshop is to highlight computational geometry methods and applications in sensor networks and network technologies, in line with the Network Technologies Division of the Center of Excellence in Wireless and Information Technology (CEWIT) at Stony Brook, which is providing partial support for the event. Computational geometry has played a significant role in network technology, particularly in ad-hoc sensor networks, data-driven mobility modeling, wireless mesh networks, network optimization, and transportation and communication systems.<br\/><br\/>The two-day workshop will take place during the fall semester of 2010 (October 29?30) on the campus of Stony Brook University, Stony Brook, NY. The proximity to many universities in the Northeast will facilitate student involvement; requested funding is targeted particularly at making the workshop accessible to students, both graduate and undergraduate.","title":"2010 Fall Workshop on Computational Geometry","awardID":"1058844","effectiveDate":"2010-10-01","expirationDate":"2011-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":[471875],"PO":["565157"]},"175892":{"abstract":"From Retroactivity to Modularity:<br\/>Design and Implementation of a Genetic Insulation Device in Yeast<br\/>Domitilla Del Vecchio and Ron Weiss<br\/><br\/>Modularity is an important property of engineered systems, yet it is debatable whether it is a general property of natural bio-molecular systems. Discovering the extent of modularity and understanding its mechanisms is one of the most important open research problems in systems biology. Furthermore, the long term success of synthetic biology critically depends on the ability to implement modular systems in such a way that the properties of individual components do not change unpredictably upon their interconnection. Our proposed research seeks to understand the mechanisms of modularity in regulatory networks using a combined theoretical\/experimental effort through the design, implementation, and analysis of a special genetic retroactivity insulation device in yeast. This novel device effectively decouples transcriptional components that would otherwise be highly interlocked by allowing propagation of a regulatory signal in the forward direction while minimizing the undesired phenomena of retroactivity in the reverse direction. Besides providing an important new circuit element for synthetic biologists, the mathematical analysis of an insulating device will lead to an improved understanding of the extent to which modularity is present in regulatory networks in biological systems. The first aim of our research is to show that retroactivity affects regulatory networks without insulation and therefore that modularity is not a natural property of bio-molecular signaling pathways. Second, we will demonstrate a novel insulation device that counteracts retroactivity and allows a circuit to transmit information reliably despite loading from downstream clients. This special circuit will be designed and placed between two connected components to insulate them from retroactivity effects. We will study the device?s performance, ability to regulate many copies of a downstream component, and requirements for correct operation. Third, we will study how well the insulation device is decoupled from the cellular environment. To this end, we will perform system-level analysis and investigate crosstalk between the device and various important cellular processes.<br\/> Intellectual Merit: Existing synthetic circuits lack an ability to insulate a driving input signal from retroactivity of the output load, precluding modular composition of complex biocircuits. To address this problem, we propose to construct and characterize a synthetic phosphorylation-based insulation device and instrumentation pathway that will demonstrate a general and modular technique for building sophisticated, large scale biological systems. Our novel technique leverages the integration of special rapid feedback mechanisms into biocircuits in order to create insulation devices, and hence has implications for the design and implementation of many other biological motifs and networks. Our research includes new theoretical and computational analysis of devices with feedback and retroactivity, and these new tools will also be applicable for the study of biological network problems other than retroactivity. This analysis is fundamentally important for tuning and characterizing desired insulation properties while minimizing interference with other cellular processes.<br\/> Broader Impact: In synthetic biology, this research will lead to a general understanding of the engineering principles of modularity for bio-molecular systems design. Likewise, in systems biology, this research will address a fundamental question ? To what extent is modularity an inherent property of biological systems? The product of our collaborative efforts will lead to the discovery in natural systems of motifs similar to our insulation device and to the explanation of how modularity is achieved, including insight into when and where natural systems implement modularity and for what purposes. Ultimately, the resulting capability of modular composition to achieve defined engineering goals in biological systems will have tremendous impact on human therapeutics, including regenerative medicine, diabetes, and cancer therapy, as well as in other diverse areas, including biofuel production, environmental remediation, pharmaceutical production, and biosensing applications. This research will contribute to new interdisciplinary courses and will be integrated into a ten week undergraduate synthetic biology Summer program that culminates in an international competition and has a track record of attracting women, under-represented groups, and high schools students to the field.","title":"CIF: Medium: Collaborative Research: From Retroactivity to Modularity: Design and Implementation of a Genetic Insulation Device in Yeast","awardID":"1058127","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":["526914"],"PO":["565223"]},"176222":{"abstract":"This project funds participation in the 2010 ACM Conference on Embedded Sensor Systems (SenSys 2010), held in November 2010, in Zurich, Switzerland. Now in its eight year SenSys 2010 presents novel sensor network and embedded systems research. A highly-selective, single-track venue, SenSys serves as the leading conference in this area highlighting experiences with real systems and experimentation with actual sensors, as opposed to simulations. Maximizing limited resources requires the sensor networking community interface with work done in related fields, and SenSys maintains a wide scope in order to incorporate advances from relevant areas. Supporting this intellectual diversity requires facilitating access for new participants. Applicants receiving funding from this project will be selected through a competitive application process and receive monies intended to cover travel and lodging. Preference will be given to applicants who would not be able to otherwise participate, as well as ones demonstrating that attending SenSys would have a significant impact on the trajectory of their research careers. Extra consideration will be given to increasing the diversity of SenSys through inclusion of women, minorities, and students from small or under-represented institutions. The intellectual merit of this project results from the exposure of selected applicants to the best research in the sensor networking field. Bringing applicants into the exciting, collaborative environment that SenSys 2010 creates will have a broad and immediate impact on the development of new and innovative solutions to the important problems being addressed by embedded sensor technology.","title":"Travel Support for SenSys 2010","awardID":"1059586","effectiveDate":"2010-10-01","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["511694"],"PO":["557315"]},"165475":{"abstract":"This project examines how artistic processes and forms of communication contribute to scientific and design problem-solving. By bringing together scientists, engineers and artists for a pilot study of interdisciplinary collaboration at Purdue University, the PIs aim to convey the significance of this new nature [next generation knowledge] in images and tangible artifacts, data visualization, engineered design prototypes, generative and kinetic installations for the public. The resulting case study and empirical evaluation of the social and collaborative process across disciplines will be an important step towards the successful development of a Center for Creative Collaboration (CCC) at Purdue University. The PIs envision the Center for Creative Collaboration as a variable network connecting science, engineering and the arts on Purdue's West Lafayette campus to enrich STEM education and provide a local model for STE(A)M (STEM disciplines plus Art) which emphasizes creativity and innovation; critical thinking and problem-solving; flexibility and adaptability; communication and collaboration.<br\/><br\/>Recent research in engineering, computer science and bioscience is revolutionizing our understanding of nature from the nano to the global. Rapidly changing knowledge about the natural environment in relationship to the 'new natures' presents new challenges for the development of strategies in computer science and engineering and in turn influence new generations of computational and engineering methods, technologies and materials. At the same time, contemporary artistic interventions are creating a critical public dialog about social, cultural and aesthetic affordances and implications of these 'new natures'. The proposed interdisciplinary educational framework for this project combines art, science and engineering strategies in the exploration of the natural environment and the 'new natures' in three interrelated project components: (1) a course titled \"Images of Nature\" that will bring together students from a range of disciplines at Purdue University, combining STEM disciplines with the Arts and Design; (2) a public exhibition of the devices, sculptures, computer graphics applications; photographs, etc. resulting from the course in an empty storefront in Downtown Lafayette, IN - the community surrounding Purdue University and; (3) a summer program exploring the theme of \"Images of Nature\" for Indiana area high school juniors from communities currently underrepresented at Purdue. By developing interdisciplinary approaches to image production guided by metaphorical thinking and polysensorial (i.e. engaging more than the sense of sight) technology, the experimental course and summer program will contribute to solving two larger problems: 1) scientists communicating their knowledge to the public and; 2) creating opportunities for artists to interpret contemporary understandings of nature created by new explorations in science and technology. These project goals will educate a new generation of scientist and artists who learn the benefits of cross-disciplinary inquiry.","title":"Pilot: Images of Nature - Technological Explorations of the Natural Environment Combining Art, Science and Engineering Strategies in an Educational Model for Collaborative Creation","awardID":"1002835","effectiveDate":"2010-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":[443277,443278],"PO":["562669"]},"171481":{"abstract":"The newly ratified IEEE 802.11n standard brings a number of new possibilities in the quest for attaining wire-like transmission speeds. The number of subchannels, the option for channel bonding, and the use of multiple antennas and MIMO technologies result in a vast variety of potential transmission strategies. Because of the number of variables, selecting the 'right combination' given the offered load, interference patterns and environmental noise is a complex undertaking. A na\u00efve channel assignment strategy will result in sub-optimal performance due to unnecessary channel contention. This work addresses a number of open questions in the quest to develop a channel assignment strategy for 802.11n that maximizes spatial reuse. In particular, the work seeks to answer to the following questions: (i) how should MIMO transmission schemes, channel bonding, and DFS considerations best be integrated into a channel management solution to maximize performance?; (ii) how can the gains achieved by MIMO systems best be utilized to influence the channel management system?; and (iii) how should metrics that influence these decisions be obtained and redefined for 802.11n systems? <br\/><br\/>The project will be facilitated through a partnership between UC Santa Barbara and HP Laboratories. Outcomes of the work will include a set of solutions for dynamically monitoring current channel state, and an integrated channel management solution that utilizes monitoring output to achieve high-speed, long transmission range communication in 802.11n systems.","title":"GOALI: Intelligent Channel Management in 802.11n Networks","awardID":"1032981","effectiveDate":"2010-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["552796","560332","552798"],"PO":["557315"]},"174364":{"abstract":"As the number of cores per chip scales to 1000s by the middle of the next decade, a fundamentally different set of constraints governs software design, including the operating system. However, recent research has demonstrated problems with scaling monolithic OS designs. In monolithic OSs, OS code executes in the kernel on the same core, which makes an OS service request. That has led to significant performance degradation and exhibits severe scalability problems. Efforts to improve scalability of these services have been difficult and marginally successful. The primary question facing OS research over the next decade is: How can the operating system services be designed such that they scale to hundreds or thousands of cores? To answer this question, the research community needs to rethink operating system design from the ground up in light of current and future multicore architectures.<br\/><br\/>One solution is to provide a factored operating system that scales over the increasing number of cores. A factored operating system (called \"fos\") factors out the system services of a monolithic OS into a set of individual services. fos further factors and parallelizes each system service into an Internet-style collection, or fleet, of cooperating servers that are distributed across the multicore chip and bound to specific cores. To maintain good performance and efficient utilization in the face of varying system resources and application demand, the fleets need to employ elasticity. The PIs propose an elastic version of fos (dubbed \"e-fos\") which provides technologies to allow system services to be scaled up or down at run-time. The primary goal of e-fos is to scale to a large numbers of cores while meeting the varying demand in resources and services, i.e., discover and evaluate how a factored operating system can leverage elasticity to maintain performance and efficiency. e-fos demonstrates elastic fleets and mechanisms to manage the elasticity for future multicores. These techniques replace the outdated \"static OS components\", which currently hinder contemporary monolithic OSs from scaling to hundreds or thousands of cores. For further information, see the project webpage: http:\/\/groups.csail.mit.edu\/carbon\/fos.","title":"EAGER: Technologies for Elastic OS Services in fos","awardID":"1049457","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":[467768],"PO":["565272"]},"174375":{"abstract":"Fake websites have emerged as a major source of online fraud, accounting for billions of dollars in fraudulent revenue at the expense of unsuspecting Internet users. Existing tools for combating fake websites are not very accurate, are limited in terms of the categories and genres of fake websites they detect, and lack adequate usability?often causing users to disregard their recommendations. Hence, there remains a need for intelligent detection systems capable of accurately detecting various types and genres of fake websites and displaying recommendations in a manner that is conducive to system use. In filling this gap, this research takes a novel user-centric approach that involves an assessment of user perceptions regarding detection-system design alternatives. The research method includes an extensive theory-based controlled lab experiment, which assesses the impacts of various design alternatives (such as website categories, genres, and accuracy\/time tradeoffs) on users? perceptions, behaviors, and skills (including security threat awareness, security threat appraisal, coping assessment, security behaviors, internet trust, and ability to identify fake websites). The research also develops a novel fake website detection system comprised of an intelligent hierarchical classification algorithm capable of promoting users? trust in the Internet. It utilizes a test bed of two thousand fake websites that include more than two million web pages. <br\/>This work uncovers new knowledge about factors influencing individuals? online security behaviors and skills, promotes Internet trust by developing enhanced systems for identifying fake websites, and develops advanced data and web mining techniques suitable for incorporating into information systems curricula.","title":"EAGER: A User-Centric Approach to the Design of Intelligent Fake Website Detection Systems","awardID":"1049497","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[467793,"525543"],"PO":["562974"]},"173055":{"abstract":"A Parallel Reconfigurable Observational Environment (PRObE) supports research on future supercomputing architectures. PRObE provides a needed and unique infrastructure to the low-level systems research community to study scaling (number of threads, nodes, and processors per node) and other challenges facing future supercomputing architectures. This infrastructure fills a well known significant long standing research facilities gap in the nations capabilities by creating a very large shared resource for systems and low-level research that allows fault injection, power control, controlling the entire resource down to the hardware, and providing direct hands on control of the resource. <br\/>The unique capabilities of PRObE open up new opportunities for research and hands-on experimentation that is was previously not feasible in the academic community. Using PRObE the low level systems research community is developing an improved understanding of the systems-level challenges for high-end computing, and the creating effective techniques to address them. PRObE creates new research opportunities for the academic community that has the significant potential to have a transformative impact on future supercomputing architectures. <br\/>PRObE provides an internship program and an annual summer school for hands-on training for visiting students on HEC systems using the Probe testbed. The proposed effort includes special attention to students from underrepresented groups, incorporating populations local to the New Mexico location.<br\/>The proposed infrastructure has the potential to facilitate the development of advances in basic knowledge required for the US to maintain its leadership positions in computing systems, data-intensive cloud computing, and data center automation.","title":"Collaborative Research: PRObE - The NSF Parallel Reconfigurable Observational Environment for Data Intensive Super-Computing and High End Computing","awardID":"1042537","effectiveDate":"2010-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7684","name":"STRATEGIC TECHNOLOGIES FOR CI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[464165,464166],"PO":["564993"]},"168776":{"abstract":"Project Abstract<br\/>HCC: Small: Depth Perception in Near- and Medium-Field Augmented Reality<br\/><br\/>Augmented reality (AR) is a technology where users see computer-generated, virtual objects superimposed on their view of the world. A large number of compelling AR applications have been proposed and developed in areas such as manufacturing, logistics, maintenance, situation awareness, heads-up maps, training, tourism, archeology, theater, choreography, architecture, and image-guided surgery. A common challenge for all of these AR applications is placing virtual objects at a specific depth in the real world. Because of inherent engineering limitations, AR displays do not show virtual objects with the same depth cues as real objects. Furthermore, some AR applications involve x-ray vision, which is the display of virtual objects that exist behind opaque surfaces. For these applications, the depth cues necessarily conflict, but still yield useful information. This leads to the scientific problems that this project is studying: (1) how depth perception operates with the conflicting depth cues of AR, and (2) new methods that can more effectively convey AR depth need to be developed and validated. <br\/><br\/>The investigators are addressing these problems through two major project tracks. The first track is empirically studying how the depth of computer-generated images is perceived for near-field distances within arm?s reach and medium-field distances of 1.5 to 30 meters. The second track is implementing and empirically testing several new eye tracker-based AR depth presentation methods. These include vergence depth rendering, where the vergence angle of the eyes controls which AR objects are visible, and simulated depth-of-field, where objects at different depths than the vergence angle are blurred. This simulates depth-of-field blurring in an AR display with a fixed focal depth. The project?s experiments adopt empirical methods from the long history of depth perception research and use control conditions that allow validation through comparison with this literature.","title":"HCC: Small: Depth Perception in Near- and Medium-Field Augmented Reality","awardID":"1018413","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["551043"],"PO":["565227"]},"172692":{"abstract":"A Platform for Internet Innovation<br\/><br\/>The architectural stability of the Internet was crucial in fostering the development of new applications and networking technologies by giving the former a stable base upon which to build and giving the latter a fixed set of requirements to support. However, in recent years this architectural stability has become a liability, as there are areas of increasing importance ? most notably inadequate support of security and availability, lack of adequate mechanisms for privacy, mobility, middleboxes, and data-oriented functionality ? where the original Internet architecture falls short. The persistence of the Internet's architectural deficiencies is not because they are intellectually intractable, but because they are beyond the reach of incrementally deployable changes. Based on this observation, the research team takes a different approach than recent clean-slate designs, focusing not on a new fixed architecture but instead on providing a platform to enable architectural innovation through incrementally deployable changes, without massive disruption in the infrastructure.<br\/><br\/>In this research project, the research team focuses on the ?hardware-defined functionality? challenge and proposes a ?platform for innovation? that allows the network infrastructure to support new architectures without changes to the underlying hardware. In particular, this approach will enable forwarding hardware to support a wide range of alternative designs. In addition, so that changes can be introduced alongside the current design, hardware will also be able to support multiple designs simultaneously. <br\/><br\/>The proposed platform will use a newly developed paradigm called Software-Defined Networks (SDN), currently embodied in the OpenFlow and NOX projects. OpenFlow is an open hardware forwarding interface. NOX is an open-source software platform that provides global abstractions to network management software and in turn communicates the decisions made by this software to the individual forwarding boxes. This effort will provide a solid foundation for more general SDN designs that are open, comprehensive and can meet long-term needs. <br\/><br\/>The research team will also explore and demonstrate applicability of the SDN approach including abstractions and programming model for different domains of network use. These include enterprise, WAN, home, and wireless. To demonstrate the ability of the proposed platform to support innovation in radically new network mechanisms, the research team will deploy prototype novel architectures on SDN. <br\/><br\/>If successful, the proposed approach would allow the use of known approaches and design proposals currently available in the literature to address many of the Internet's current problems, as these solutions would be incrementally deployable, without major disruption to the underlying infrastructure. Furthermore, current commercial efforts to address Internet?s deficiencies are disjointed, proprietary, and tailored for short-term needs. The next generation of SDN technology provides a solid basis for coordinated, long-term efforts to address critical needs in areas of security, mobility and support of content-centric application and services. More importantly, the proposed approach would allow the Internet to meet future requirements as they arise through incrementally deployable modifications, relieving network designers of the burden of predicting what these future requirements might be.","title":"FIA: Collaborative Research: Architecting for Innovation","awardID":"1040705","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["531675"],"PO":["565255"]},"175894":{"abstract":"This work proposes novel approaches to collaboratively visualize and interactively explore large interconnected high-dimensional data sets represented as large unstructured graphs. The proposed work builds upon scalable visualization methodology that is able to support interactive exploration of over a hundred thousand nodes on standard desktop computers, even without the use of hierarchical clustering. This research advances the state of the art in interactive network visualization in the following three research directions towards a visual tool set for collaborative interactive sense-making of social network data, represented as interconnected graphs: Web-based Scalability, Collaborative Graph Analysis, and New Visualization Paradigms, all together facilitating the visualization and collaborative comparison of large graphs from (and over) the semantic web. A specific focus of these novel visualization techniques is the visualization of uncertainty associated with the data sources or inferences.<br\/><br\/>The intellectual merit of this work is established by novel contributions to the fields of information and scientific visualization, as well as human-computer interaction: Interactive collaborative manipulation and analysis of very large graph structures is not currently possible with existing tools and techniques. Our proposed research provides a new collaborative and user-driven perspective on social network analysis which is interactive, flexible, scalable and extensible enough to keep pace with the rapid expansion of the social web. The intended results, a novel drag-and-drop approach for down-scaling, testing, comparing, and evaluating information networks, will establish and evaluate novel mechanisms to manage the onslaught of networked information in a collaborative manner. Results will be demonstrated through integration and evaluation of the novel visualization and interaction techniques within a semantic web-based analysis and interaction infrastructure.<br\/><br\/>The proposed work will enable significant broader impacts by making innovative scalable graph visualization methodologies available to broad audiences via open-source semantic web platforms. Web audiences will be enabled to access novel state-of-the-art graph analysis and visualization tools directly in their browsers without the need for downloading applets, plugins, or virtual machines of any kind. The PI will be using the proposed research as a case study and platform for projects supporting the teaching of human-computer interaction fundamentals. Interdisciplinarity is a cornerstone of successful user interface technology projects such as this one, and the investigator's research group has a demonstrated commitment to collaborations and partnerships with other departments on campus, as well as representatives from industry and the public community, targeting broad dissemination of the research results.","title":"EAGER: Collaborative Visualization for Knowledge Computing","awardID":"1058132","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J108","name":"National Security Agency"}}],"PIcoPI":["518684"],"PO":["565136"]},"176312":{"abstract":"Effective response and adaptation to the physical world, and rigorous management of such behaviors through programmable computational means, are mandatory features of cyber physical systems (CPS). However, achieving such capabilities across diverse application requirements surpasses the current state of the art in system platforms and tools. Current computational platforms and tools often treat physical properties individually and in isolation from other cyber and physical attributes. They do not adequately support the expression, integration, and enforcement of system properties that span cyber and physical domains. This results in inefficient use of both cyber and physical resources, and in lower system effectiveness overall. <br\/><br\/>This work investigates novel approaches to these important problems, based on modularizing and integrating diverse cyber-physical concerns that cross-cut physical, hardware, instruction set, kernel, library, and application abstractions. The three major thrusts of this research are 1) establishing foundational models for expressing, analyzing, enforcing, and measuring different conjoined cyber-physical properties, 2) conducting a fundamental re-examination of system development tools and platforms to identify how different application concerns that cut across them can be modularized as cyber-physical system aspects, and 3) developing prototype demonstrations of our results to evaluate further those advances in the state of the art in aspect-oriented techniques for CPS, to help assess the feasibility of broader application of the approach. The broader impact of this work will be through dissemination of academic papers, and open platforms and tools that afford unprecedented integration of cyber-physical properties.","title":"EAGER: Collaborative Research: Seamless Integration of Conjoined Cyber-Physical System Properties","awardID":"1060093","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["525751","556687"],"PO":["565239"]},"173056":{"abstract":"A Parallel Reconfigurable Observational Environment (PRObE) supports research on future supercomputing architectures. PRObE provides a needed and unique infrastructure to the low-level systems research community to study scaling (number of threads, nodes, and processors per node) and other challenges facing future supercomputing architectures. This infrastructure fills a well known significant long standing research facilities gap in the nation?s capabilities by creating a very large shared resource for systems and low-level research that allows fault injection, power control, controlling the entire resource down to the hardware, and providing direct hands on control of the resource. <br\/>The unique capabilities of PRObE open up new opportunities for research and hands-on experimentation that is was previously not feasible in the academic community. Using PRObE the low level systems research community is developing an improved understanding of the systems-level challenges for high-end computing, and the creating effective techniques to address them. PRObE creates new research opportunities for the academic community that has the significant potential to have a transformative impact on future supercomputing architectures. <br\/>PRObE provides an internship program and an annual summer school for hands-on training for visiting students on HEC systems using the Probe testbed. The proposed effort includes special attention to students from underrepresented groups, incorporating populations local to the New Mexico location.<br\/>The proposed infrastructure has the potential to facilitate the development of advances in basic knowledge required for the US to maintain its leadership positions in computing systems, data-intensive cloud computing, and data center automation.","title":"Collaborative Research: PRObE - The NSF Parallel Reconfigurable Observational Environment for Data Intensive Super-Computing and High End Computing","awardID":"1042543","effectiveDate":"2010-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["465808"],"PO":["564993"]},"168766":{"abstract":"In recent years, it has come to light that many signal estimation and detection problems in engineering, science, and statistics are significantly aided by modeling the signal as sparse in some basis.<br\/>By now, a relatively comprehensive theory has been constructed for such signal models, yielding algorithms that give provably good performance even when sampling far below the Nyquist rate.<br\/>The structure of real-world signals often goes beyond simple sparsity, though.<br\/>For example, the wavelet coefficients of natural scenes are not only sparse, but also show persistence across scales of the wavelet tree.<br\/>Recent investigations of structure within sparsity show that it can be exploited to yield gains in estimation performance, though existing results are somewhat limited.<br\/>For example, existing approaches strive to find only the single \"best\"<br\/>estimate, whereas many applications would like to know the set of all reasonable estimates along with relative confidence values, i.e., \"soft\" estimates.<br\/><br\/>This research investigates soft inference strategies leveraging a statistical modeling framework based on hidden state variables.<br\/>Here, e.g., using binary states would facilitate a sparse signal model, and using Markov structures on the binary states would facilitate structured sparsity.<br\/>In particular, this research investigates iterative and sequential Bayesian approaches to soft inference, building on state-of-the-art algorithms used in noncoherent communication receivers that go by the name of \"turbo equalization\" and \"sphere decoding.\"<br\/>This research also investigates fundamental issues in communication over sparse fading channels.<br\/>While existing approaches have focused on the problem of find the \"best\"<br\/>sparse channel estimate for subsequent use in a coherent decoding algorithm, communication theory instead prescribes a decoding metric based on model-averaging of soft sparse channel estimates.","title":"CIF: Small: Soft Inference under Structured Sparsity","awardID":"1018368","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["518451"],"PO":["564898"]},"167248":{"abstract":"The potential benefits from electronic medical records (EMRs), including lab tests, images, diagnoses, prescriptions, and medical histories are without precedent. Patients and insurers can avoid repeating studies that, for example, expose people to additional radiation and incur unnecessary costs. Providers can instantly access patient histories , and patients can take ownership of their medical records, with the potential for greater privacy, and better access to their records when they are needed. However, while the promises of EMRs are many, moving from paper-based systems to electronic ones is not without risk. For example, it is a lot easier for an attacker to sneak out of a hospital (or data center) with a USB stick in their pocket containing 8,000 patient records, than with the equivalent paper records. Moving electronic records online makes them particularly vulnerable to Internet-based attacks. These threats are getting worse, as attacks grow in sophistication. This project will focus on developing new security technologies to enable deployment of secure EMRs by utilizing new cryptographic techniques and building a pilot system to deploy within a major hospital. The pilot will enable storage of protected records across a distributed environment that includes untrusted outsourced databases and mobile devices. Patients will be able to interface with Public Healthcare Record (PHR) systems such as Google Health and Microsoft Health Vault or other cloud services. The project includes developing a key management scheme that is able to support the unique requirements of this model and algorithms, including auditing, key revocation, and traitor tracing.","title":"TC: Large:Self Protecting Electronic Medical Records","awardID":"1010928","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["544250",448024,"528234","553563",448027],"PO":["565264"]},"176665":{"abstract":"The National Science Foundation (NSF) is proud to announce the selection of New York University's Subhash Khot, an associate professor at the Courant Institute of Mathematical Sciences, to receive its 2010 Alan T. Waterman Award. Khot, a theoretical computer scientist, works in an area called \"Computational Complexity\" which seeks to understand the power and limits of efficient computation.<br\/><br\/>The annual Waterman award recognizes an outstanding young researcher in any field of science or engineering supported by NSF. Candidates may not be more than 35 years old, or seven years beyond receiving a doctorate, and must stand out for their individual achievements. In addition to a medal, the awardee receives a grant of $500,000 over a 3-year period for scientific research or advanced study in their field. <br\/><br\/>Khot is a brilliant theoretical computer scientist, and is most well known for his Unique Games Conjecture. He has made many unexpected and original contributions to computational complexity and his work draws connections among optimization, computer science and mathematics.<br\/><br\/>Khot has a long relationship with NSF, and an even longer history receiving awards. He received an NSF CAREER Award, a Sloan Foundation Fellowship, and a Microsoft New Faculty Fellowship. With his colleagues at New York University, Princeton, Rutgers University, and the Institute for Advanced Study, he is part of a $10 million NSF \"Expeditions in Computing\" grant under which the researchers are seeking to bridge fundamental gaps in our understanding of computational intractability.","title":"2010 Waterman Award","awardID":"1061938","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"10","name":"Office of OFFICE OF BUDGET, FINANCE, & AWARD MANAG","abbr":"BFA"},"div":{"id":"1001","name":"Division of BUDGET DIVISION","abbr":"DOB"},"pgm":{"id":"041P","name":"WATERMAN AWARD"}}],"PIcoPI":[473603],"PO":["565157"]},"169966":{"abstract":"As a consequence of advances in information technology and communication unprecedented quantities of information are available for use in making decisions and this information can be transmitted at unprecedented speed. At the same time, the process for integrating these vast quantities of data is daunting and particularly so given that much of the data available is incomplete and unreliable. Three events bringing together scholars in a variety of disciplines (e.g., computer science, economics, decision theory and mathematics) to explore possibilities for developing algorithmic methods for addressing the information aggregation \/ decision making problem engendered by the availability of vast quantities of noisy data and applied workshops to consider how such algorithms might be applied in specific domains (e.g., health care, ecology and port security) will be conducted. These are:<br\/>1) Sessions at the Second International Conference on Algorithmic Decision Theory aimed at identifying concrete research projects\/problems involving aggregation of vast quantities of noisy data and and small working group meetings following the conference to spell out those projects.<br\/>2) Two workshops, one on Algorithmic Decision Theory for the Smart Grid and one on Algorithmic Decision Theory for Robust Ports.<br\/><br\/>These activities are intended to spawn new networks among researchers in many fields and provide new methods and tools for addressing many important decision problems that confront policy makers.","title":"Workshops: Special Focus on Algorithmic Decision Theory","awardID":"1024722","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"1321","name":"DECISION RISK & MANAGEMENT SCI"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"1333","name":"METHOD, MEASURE & STATS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["264120"],"PO":["561884"]},"171495":{"abstract":"There has been growing recognition of scientists' and engineers' need for ethics education, including training requirements for many federal grant recipients, and the further need to incorporate macroethics education into responsible and ethical conduct in research education for social scientists, natural scientists, computer scientists, and engineers. This combination education and research project will develop, assess, and disseminate innovative introductory macroethical course modules. The major contribution of the project is the modules' content: an introduction to significant macroethics concepts from science and engineering ethics (SEE) and science and technology studies (STS). Macroethics examines the collective social responsibilities of scientists and engineers, as opposed to microethics, which emphasizes individual ethical dilemmas in research (for example, plagiarism). The project team will develop four modules, one for each of the following disciplinary ethics education courses: 1) biomedical sciences, 2) social and behavioral sciences, 3) physical sciences, and 4) engineering. The core concepts to be explored are drawn from STS theoretical frameworks and center on three ideas: (1) a critique of the idea of technology as progress, (2) engineering as a social experiment, and (3) the potential of conceptual and technical assumptions and decisions to have long-term impacts.<br\/><br\/><br\/>The project brings together an interdisciplinary team to develop module content and solicit further input from active scholars in SEE, STS, science, and engineering. The team will work with active scholars to identify and refine appropriate common core concepts for the modules by proposing roundtable discussions at a variety of professional association meetings. In addition, a network of nine disciplinary consultants will aid the leadership team. Before disseminating the final modules, the team will assess effectiveness and refine them as necessary. The assessment protocol will examine: 1) knowledge acquisition by the macroethics module users, 2) the effect of combining macroethical and microethical education on acquisition of knowledge in both areas, and 3) knowledge retention.","title":"Developing and Assessing Macroethics Modules for the Collaborative Institutional Training Initiative Responsible Conduct of Research Courses","awardID":"1033111","effectiveDate":"2010-10-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7603","name":"SCIENCE, TECH & SOCIETY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":[459141,"535952","563701",459144],"PO":["563704"]},"174587":{"abstract":"The most challenging problem facing creativity-based technology research stems from the multitude of hypotheses, concepts, descriptions, interpretations and definitions of what \"creativity\" means and how it can be described or modeled. It is understood and accepted that \"creativity\" holds the key to innovation, which can be defined as a qualitative jump from one level to another. It becomes obvious that research into \"creativity\" can only exist if it is seen as fundamental research and applied research at the same time. This is exactly the point where science, art and technology can intersect with the greatest benefit to all. This reciprocal interchange between science and technology and human creativity and innovation needs to be understood beyond discipline boundaries. To bring research and understanding of \"creativity\" to fruition for innovative approaches in science and technology and to reciprocally engage fundamental research in potentially non-scientific environments requires a truly open and cross-disciplinary framework. Initiatives supported so far in this area - drawing on research, development and production and spanning natural sciences, computer science and informatics, engineering and humanities including fine, performing and applied arts, educational science, psychology and philosophy - are promising and have yielded new insights. As these research projects by design and necessity have to cross academic and research boundaries, they need sustained support to enable, focus, coordinate and disseminate their activities and results within their own field as well as to other research outside of their more immediate scope. <br\/><br\/>The goal of this workshop is to define in concrete terms a platform that sustains cross-disciplinary and trans-disciplinary research, collaboration and exchange in the integration of quantifiable and qualitatively defined paradigms at the intersection of creativity, technology, research and innovation. This area of research can be subsumed under the heading of \"creativity-based technology research and technology-based creativity research\". In contrast to established platforms and network infrastructures to support the field in international arenas, there are few supported platforms - such as symposia, conferences, publications or internet-based resources - that are dedicated to establish communication and continuity in creativity-based technology research in the United States. Activities in this workshop will build upon results from prior NSF workshops in support of creativity-based technology research, and also upon research projects funded during the three-year tenure of the NSF CISE IIS CreativeIT program from 2007 to 2010. Objectives for this workshop are to: 1) Identify key issues in infrastructure needs to support creativity-based technology research; 2) Develop concrete plans toward the development, management and constituent involvement in a distributed network infrastructure for the sustained support of the field; and 3)Identify leading institutions that will move forward on proposals to possible supporting agencies and foundations. Based on these outcomes, the following actions may be defined: 1) Initial definition of a network structure of key institutions that can develop a proposal to the NSF and\/or other funding entities to support the network structure; 2) Collaborative research proposals as an extension of existing research projects, which are currently limited to one center or to one sub-field where other centers may have complementary research expertise and capacity; 3) Commitment, timeline and structure of future tasks required to consolidate the initiatives coming out of this workshop with the goal of developing a network of centers, researchers and creative practitioners.","title":"WORKSHOP: Infrastructure Needs to Support Creativity-based Technology Research","awardID":"1050249","effectiveDate":"2010-10-01","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["522219","550695"],"PO":["565136"]},"168416":{"abstract":"High resolution embryonic images, e.g., the data set BDGP (Berkley Drosophila Genome Project), have been introduced as an important tool for the discovery of gene-gene interaction. These images contain not only temporal information of a gene but also precise spatial information of expression regions of genes. So the biologic problem of the discovery of gene-gene interaction can be characterized as a computational problem of matching expression patterns of embryos at the same developmental stage. It is, however, very challenging to design a fully automatic computational system due to severe imaging and artificial variations in embryonic images. Current research on embryonic image processing involves significant manual manipulation or addresses only a small subset of variations. In this proposal, I propose a comprehensive automatic framework to achieve the three fundamental tasks: image standardization, stage determination, and expression pattern modeling. The proposed project will essentially advance the integration of biologic, image processing and pattern recognition, and machine learning. The PI will develop a series of analysis modules to standardize the variation across images, provide for inpainting, and provide estimates of the boundaries of embryos. The expression pattern modeling will develop discriminate features to address issues of distinguishing specific pixels in varied refraction circumstances. A key concept is to develop an imbalance point detection scheme that will minimize the occurrences of edge points and provide a measure of the imbalance degree.<br\/><br\/>These methods should be adaptable for analysis of images from other model species, e.g., mouse. The proposed work will directly facilitate basic and applied research on image processing crucial to biological image analysis. The challenges in analyzing developmental biological images as compared to natural images have created increasing demands on and opportunities for developing novel image processing techniques. The algorithms and tools developed in this project will have made available to the community. This project will also facilitate the development of new courses and laboratory infrastructure for knowledge discovery from biological data.","title":"III: Small: An Automatic Framework for Processing Drosophila Embryonic Images","awardID":"1016668","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["520803"],"PO":["565136"]},"168339":{"abstract":"Environmental degradation can lead to sustained natural and humanitarian disasters, which may foster political instability when societal demands exceed the capacity of local governments to cope. The influence of local land use changes on resiliency to droughts and on external food dependency is not very well understood. The effort will integrate environmental measurements and signatures, numerical climate models, and predictive statistical models with trends identified from large historical data sets, in order to provide valuable information and analyses for use in planning and understanding the impact of environment-based instabilities. The proposed methodology will allow evaluation of such effects and provide information to allow for mitigation. Mitigation of regional impacts is more tractable than global climate change impacts and could be effected through external aid. The focus is on regions of sub-Saharan Africa, where in the arid and semi-arid regions, the reduction in rainfall caused by land use change is likely to have significant implications for agriculture. The uniqueness of the proposed methodology is the coupled approach of examining the impact of population growth, land use change and climate feedback to food security in a relatively local area. By integrating current environmental measurements with current and historical data and a suite of proven modeling approaches, the project will enhance the ability to integrate and interpret these disparate information sources. The researchers will provide for the integration of students into research efforts at both the graduate and undergraduate levels.","title":"Environmental and Climate Impacts on National Security: A Coupled Human-Environment System Perspective","awardID":"1016302","effectiveDate":"2010-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}}],"PIcoPI":["527740","527741"],"PO":["565136"]},"170671":{"abstract":"Summary: Rapidly changing technologies of multi-modal communication, from the global reach of international satellite TV, the proliferation of Internet news outlets, to YouTube, are transforming the news industry. In parallel, ?citizen journalism? is on the rise, enabled by smart phones, social networks, and blogs. The Internet is becoming a vast information ecosystem driven by mediated events ? elections, social movements, natural disasters, disease epidemics ? with rich heterogeneous data: text, image, and video. Meanwhile, the tools and methodologies for users and researchers are not keeping pace: it remains prohibitively labor-intensive to systematically access and study the vast amount of emerging news data.<br\/><br\/>Leveraging UCLA's ongoing digital collection of 85,000 hours of news videos, including 8.1 billion image frames and 530 million words of closed captioning, the research team is developing a new computational paradigm for analyzing massive datasets of social and political news events: (i) Studying joint image-text parsing to categorize news by topics and events, and analyzing selection and presentation biases across networks and media spheres in a statistical and quantitative manner never before possible; (ii) Studying by joint image-text mining to reason the persuasion intents, and modeling the techniques of verbal and visual persuasions; (iii) Discovering spatio-temporal patterns in the interactions of multiple mediated events, and analyzing agenda setting patterns; and (iv) Developing an interactive multi-perspective news interface, vrNewsScape, for visualizing and interacting with our computational and statistical results.<br\/><br\/>Intellectual merit: This interdisciplinary project makes innovative contributions to three disciplines. Transforming social science research. The project develops a data-driven paradigm for transforming communication research in the social sciences. By enabling quantitative studies of massive visual datasets, the research team identifies and characterizes large-scale patterns of news mediation and persuasion currently inaccessible to researchers, due to the prohibitive cost of manual analysis. The research team goes beyond traditional object detection, segmentation, and recognition by studying framing and persuasion techniques in images, an untouched topic in computer vision. The team studies semantic associations and meanings for object and scene categories in their social context. Also, the team is studying image parsing to fill the semantic gap ? a long standing technical barrier in image retrieval, and will generate narrative text descriptions from the parse trees so that they can be fused with the input text and closed captioning for topic mining.<br\/><br\/>The research goes beyond conventional topic mining from text to perform integrative text-image mining, bias detection, and pattern discovery in the spatio-temporal evolution of mediated news events. The research detects and summarizes controversy and mine user-generated content for analyzing communicative intent and persuasive effects.<br\/><br\/>Broader impacts: vrNewsScape is being made publicly available to researchers and graduate students. Because the news media report on events in multiple different expert domains ? including congressional and presidential politics, international relations, war and public uprisings, natural disasters and humanitarian aid missions, disease epidemics and health initiatives, criminal activity and court cases, celebrities and cultural events ? the analytical tools in development are not limited to a particular research domain in social, political and computer sciences, but permit for the first time a systematic and quantitative examination of the massive datasets required to understand today?s mediated society.<br\/><br\/>In education, the project extends UCLA?s Digital Civic Learning initiative (dcl.sscnet.ucla.edu), a program involving college and high-school students in the analysis of news, thus delivering education benefits to potentially a huge number of students nationwide in Communication Studies (in 2004, 433,000 college students were enrolled in Communication and Journalism and 209,000 in Political Science[153]), exposing them to a new generation of high-level tools for handling multimodal data and inspiring them to pursue computational thinking, in line with the NSF?s objectives.","title":"CDI-Type II: Collaborative Research: Joint Image-Text Parsing and Reasoning for Analyzing Social and Political News Events","awardID":"1028381","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[456867,456868,456869],"PO":["564359"]},"172640":{"abstract":"A Platform for Internet Innovation<br\/><br\/>The architectural stability of the Internet was crucial in fostering the development of new applications and networking technologies by giving the former a stable base upon which to build and giving the latter a fixed set of requirements to support. However, in recent years this architectural stability has become a liability, as there are areas of increasing importance ? most notably inadequate support of security and availability, lack of adequate mechanisms for privacy, mobility, middleboxes, and data-oriented functionality ? where the original Internet architecture falls short. The persistence of the Internet's architectural deficiencies is not because they are intellectually intractable, but because they are beyond the reach of incrementally deployable changes. Based on this observation, the research team takes a different approach than recent clean-slate designs, focusing not on a new fixed architecture but instead on providing a platform to enable architectural innovation through incrementally deployable changes, without massive disruption in the infrastructure.<br\/><br\/>In this research project, the research team focuses on the ?hardware-defined functionality? challenge and proposes a ?platform for innovation? that allows the network infrastructure to support new architectures without changes to the underlying hardware. In particular, this approach will enable forwarding hardware to support a wide range of alternative designs. In addition, so that changes can be introduced alongside the current design, hardware will also be able to support multiple designs simultaneously. <br\/><br\/>The proposed platform will use a newly developed paradigm called Software-Defined Networks (SDN), currently embodied in the OpenFlow and NOX projects. OpenFlow is an open hardware forwarding interface. NOX is an open-source software platform that provides global abstractions to network management software and in turn communicates the decisions made by this software to the individual forwarding boxes. This effort will provide a solid foundation for more general SDN designs that are open, comprehensive and can meet long-term needs. <br\/><br\/>The research team will also explore and demonstrate applicability of the SDN approach including abstractions and programming model for different domains of network use. These include enterprise, WAN, home, and wireless. To demonstrate the ability of the proposed platform to support innovation in radically new network mechanisms, the research team will deploy prototype novel architectures on SDN. <br\/><br\/>If successful, the proposed approach would allow the use of known approaches and design proposals currently available in the literature to address many of the Internet's current problems, as these solutions would be incrementally deployable, without major disruption to the underlying infrastructure. Furthermore, current commercial efforts to address Internet?s deficiencies are disjointed, proprietary, and tailored for short-term needs. The next generation of SDN technology provides a solid basis for coordinated, long-term efforts to address critical needs in areas of security, mobility and support of content-centric application and services. More importantly, the proposed approach would allow the Internet to meet future requirements as they arise through incrementally deployable modifications, relieving network designers of the burden of predicting what these future requirements might be.","title":"FIA: Collaborative Research: Architecting for Innovation","awardID":"1040396","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["508065"],"PO":["565255"]},"173993":{"abstract":"Today, two trends conspire to slow down the pace of science, engineering, and academic research progress in general. First, researchers increasingly rely on computation to process ever larger data sets and to perform ever more computationally-intensive simulations. Second, individual processor speeds are no longer increasing with every computer chip generation as they once were. To compensate, processor manufacturers have moved to including more processors, or cores, on a chip with each generation. To obtain peak performance on these multicore chips, software must be implemented so that it can execute in parallel and thereby use the additional processor cores. Unfortunately, writing efficient, explicitly parallel software programs using today's software-development tools takes advanced training in computer science, and even with such training, the task remains extremely difficult, error-prone, and time consuming. This project will create a new high-level programming platform, called Implicit Parallel Programming (IPP), designed to bring the performance promises of modern multicore machines to scientists and engineers without the costs associated with having to teach these users how to write explicitly parallel programs. In the short term, this research will provide direct and immediate benefit to researchers in several areas of science as the PIs will pair computer science graduate students with non-computer science graduate students to study, analyze, and develop high-value scientific applications. In the long term, this research has the potential to fundamentally change the way scientists obtain performance from parallel machines, improve their productivity, and accelerate the overall pace of science. This work will also have major educational impact by developing courseware and tutorial materials, useable by all scientists and engineers, on the topics of explicit and implicit parallel computing.<br\/><br\/>IPP will operate by allowing users to write ordinary sequential programs and then to augment them with logical specifications that expand (or abstract) the set of sequential program behaviors. This capacity for abstraction will provide parallelizing compilers with the flexibility to more aggressively optimize programs than would otherwise be possible. In fact, it will enable effective parallelization techniques where they were impossible before. The language design and compiler implementation will be accompanied by formal semantic analysis that will be used to judge the correctness of compiler transformations, provide a foundation for about reasoning programs, and guide the creation of static analysis and program defect detection algorithms. Moreover since existing programs and languages can be viewed as (degenerately) implicitly parallel, decades of investment in human expertise, languages, compilers, methods, tools, and applications is preserved. In particular, it will be possible to upgrade old legacy programs or libraries from slow sequential versions without overhauling the entire system architecture, but merely by adding a few auxiliary specifications. Compiler technology will help guide scientists and engineers through this process, further simplifying the task. Conceptually, IPP restores an important layer of abstraction, freeing programmers to write high-level code, designed to be easy to understand, rather than low-level code, architected according to the specific demands of a particular parallel machine.","title":"SI2-SSI: Accelerating the Pace of Research through Implicitly Parallel Programming","awardID":"1047879","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["483683","511660"],"PO":["564388"]},"172673":{"abstract":"A Platform for Internet Innovation<br\/><br\/>The architectural stability of the Internet was crucial in fostering the development of new applications and networking technologies by giving the former a stable base upon which to build and giving the latter a fixed set of requirements to support. However, in recent years this architectural stability has become a liability, as there are areas of increasing importance ? most notably inadequate support of security and availability, lack of adequate mechanisms for privacy, mobility, middleboxes, and data-oriented functionality ? where the original Internet architecture falls short. The persistence of the Internet's architectural deficiencies is not because they are intellectually intractable, but because they are beyond the reach of incrementally deployable changes. Based on this observation, the research team takes a different approach than recent clean-slate designs, focusing not on a new fixed architecture but instead on providing a platform to enable architectural innovation through incrementally deployable changes, without massive disruption in the infrastructure.<br\/><br\/>In this research project, the research team focuses on the ?hardware-defined functionality? challenge and proposes a ?platform for innovation? that allows the network infrastructure to support new architectures without changes to the underlying hardware. In particular, this approach will enable forwarding hardware to support a wide range of alternative designs. In addition, so that changes can be introduced alongside the current design, hardware will also be able to support multiple designs simultaneously. <br\/><br\/>The proposed platform will use a newly developed paradigm called Software-Defined Networks (SDN), currently embodied in the OpenFlow and NOX projects. OpenFlow is an open hardware forwarding interface. NOX is an open-source software platform that provides global abstractions to network management software and in turn communicates the decisions made by this software to the individual forwarding boxes. This effort will provide a solid foundation for more general SDN designs that are open, comprehensive and can meet long-term needs. <br\/><br\/>The research team will also explore and demonstrate applicability of the SDN approach including abstractions and programming model for different domains of network use. These include enterprise, WAN, home, and wireless. To demonstrate the ability of the proposed platform to support innovation in radically new network mechanisms, the research team will deploy prototype novel architectures on SDN. <br\/><br\/>If successful, the proposed approach would allow the use of known approaches and design proposals currently available in the literature to address many of the Internet's current problems, as these solutions would be incrementally deployable, without major disruption to the underlying infrastructure. Furthermore, current commercial efforts to address Internet?s deficiencies are disjointed, proprietary, and tailored for short-term needs. The next generation of SDN technology provides a solid basis for coordinated, long-term efforts to address critical needs in areas of security, mobility and support of content-centric application and services. More importantly, the proposed approach would allow the Internet to meet future requirements as they arise through incrementally deployable modifications, relieving network designers of the burden of predicting what these future requirements might be.","title":"FIA: Collaborative Research: Architecting for Innovation","awardID":"1040593","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["560546"],"PO":["565255"]},"173674":{"abstract":"The underlying physics of the resonance ionization mass spectrometric technique in association with laser desorption measurements remains under-explored, and the application to isotopic measurements largely untested when compared with other approaches. When the technique was first implemented, lasers were expensive and balky to use, limiting the ultimate application of the method. Since that time, lasers have evolved significantly, resulting in lower cost, size, power, and increased ease of use, enabling measurements using laser desorption as the basis for the mass spectrometer. Because of these advances, secondary ionization approaches can approach 100% efficiency, enabling sub-parts per billion detection limits, and significantly increased measurement precision. This proposal expands the basic physical understanding of the underlying atomic processes, in addition to exploring methods that could enable real-time in-situ isotopic measurements of trace isotopic and elemental systems. Initial results show that the laser and mass spectrometer systems could be made portable for real-time field use, while maintaining sufficient precision and accuracy for enabling geo-chronology, geo-location, forensics, archeology, food tracking, and studying nuclear processes. The team will engage students in the geologic science, physics, and engineering of geo-chronology, resonance ionization, and mass spectrometry in order to support this effort.","title":"LDRIMS Geolocation and Nuclear Forensics Using a Real-Time Portable Charaterization Instrument","awardID":"1045679","effectiveDate":"2010-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J290","name":"Defense Intelligence Agency"}}],"PIcoPI":[465982,"510368"],"PO":["565136"]},"164512":{"abstract":"Leveraging crowdsourcing to collect data is becoming more common. Human Computation, in particular, has looked at how to use artificial intelligence on data collected from people playing games, to validate that useful data has been collected on a very large scale. This work will investigate a new form of artificial-intelligence based crowdsourced games called Computational Gaming, in which questions will be posed without knowing what the answers are beforehand. Questions that require human judgment will be posed in the context of a game, and machine learning will be used to determine what questions to pose to which players and how to determine whether the responses are valid.<br\/><br\/>Intellectual Merit. This project will demonstrate the validity of Computational Gaming through two examples in text and image labeling, delineating a set of guiding design principles for building and evaluating future Computational Gaming designs, and producing a toolkit that supports and encourages the use of these design principles for building Computational Gaming systems.<br\/><br\/>Potential Broader Impacts. The project will create, both more quickly and more cheaply, databases of human-labeled data; it will also do so for a wider variety of problems than currently exists. The framework and toolkit for Computational Gaming will be valuable for game designers, for researchers in many domains that need labeled data, and for the users for whom the research is being conducted.","title":"SoCS: Creation of a Framework for Computational Gaming","awardID":"0968566","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["532662"],"PO":["563324"]},"174225":{"abstract":"The objective of the workshop is to establish the fundamental research challenges for trustworthy biometric systems in identity management. The link between biological identity as we know it today and our digital persona is rapidly changing where transactions in the cyberspace rely on establishment of trust. The intersection between personal identity, biometrics (measured identity), and identity in cyberspace is the topic of this workshop. In cyberspace, there is opportunity to create multiple digital identities (or pseudonyms) to one human identity, where guarded anonymity and privacy preserving tools are needed which provide levels of trust and scale in the information content linked to true identity. Biometrics, based on physiologic or behavioral measurements, is a technology that fundamentally ties an individual to a transaction\/location and may be a tool to establish trust enabling identity management for a wide array of applications, including border control, information technology, e-commerce, and war-time environments. There is a need to develop methodologies that address privacy, acceptability, usability, and security of stored and transmitted biometric information. The proposed workshop will bring a team of interested individuals from academia, government, and industry to discuss fundamentals and future directions in identity science related to privacy, trust, and security.","title":"Fundamental Research Challenges for Trustworthy Biometrics Workshop","awardID":"1048975","effectiveDate":"2010-10-01","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560284"],"PO":["565327"]},"168813":{"abstract":"Building software is often a process of great complexity. In this day and age, safe and reliable software is a rare oddity and software failure is a norm rather than an exception. How can safe and reliable software be built in a manner that is practical and cost-effective? This project addresses the issue by focusing on building trustworthy low-level systems that is verifiably safe and reliable. Instead of solely relying on testing to ensure safety and reliability, the novel approach taken in the project provides the programmer with a formal means to construct proofs demonstrating correctness properties of actual implementation that can be verified independently. This is often referred to as combining programming with theorem-proving.<br\/><br\/>ATS is a programming language equipped with a highly expressive type system rooted in the framework Applied Type System. In particular, both dependent types and linear types are available in ATS. The development of ATS has now reached a point where advanced types can be effectively employed to support the construction of safe and efficient code. Continuing this progress naturally directs us to investigate how the paradigm of combining programming with theorem-proving as is advocated in ATS can be exploited to raise code quality in low-level systems programming. The project is expected to yield significant contributions to the understanding of type theory and its application to the design and implementation of low-level systems. In particular, advanced type theory (involving dependent types and linear types) is to be developed to facilitate the use of types in capturing programming invariants.","title":"ATS for Systems Programming with Theorem Proving","awardID":"1018601","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[451820],"PO":["565264"]},"163489":{"abstract":"MOBILIZE: Mobilizing for Innovative Computer Science Teaching and Learning is a Targeted Math and Science Partnership between the University of California Los Angeles (UCLA) as the lead and the Los Angeles Unified School District (LAUSD) as the Core Partner school district. The Computer Science Teachers Association (CSTA) and the Association for Computing Machinery, Inc. are Supporting Partners. The Partnership promotes computational thinking, with an overarching goal of fostering inventiveness and innovation among students and teachers through increasing the computer science instructional capacity of high schools, especially in a large urban school district. This project brings together the Center for Embedded Networked Sensing (CENS), an NSF Science and Technology Center (STC) in the Henry Samueli School of Engineering and Applied Sciences, and Center X in the Graduate School of Education & Information Studies at UCLA. MOBILIZE deploys challenging and engaging hands-on computer science projects and curricula using new participatory sensing technologies in high school mathematics and science courses. MOBILIZE prepares a large number of high school teachers to use inquiry teaching methods with the intent that technologies that are ubiquitous with students today, such as mobile phones, peak the interests of students and motivate them in ways that ultimately increases both students' achievement and their identities as \"doers\" of science, while enhancing the computer science knowledge and pedagogical acumen of teachers. <br\/><br\/>MOBILIZE:<br\/>--creates exciting, challenging, multi-disciplinary, real-life based, cutting-edge, hands-on inquiry projects, tools, and materials for teaching computer science concepts in high school computer science AND in standards-based mathematics and science classes. Piloting occurs locally with dissemination nationally, with the long term goal of increasing student engagement and achievement in computer science, mathematics, and the other sciences. High school teachers work with STEM and education faculty to develop new computer science materials that build on the CENS Participatory Sensing systems, which involve students in observing and analyzing environmental and social processes where they live, work, and play;<br\/>--develops an innovative model of professional development for current and future high school teachers around the implementation of these projects, to include multi-disciplinary teams of teachers organized into learning communities with STEM and Education faculty, coaching, and a new pre-service computer science methods course, in order to create a cadre of teachers with expertise in both computer science content and pedagogy; and<br\/>--informs state and national policy changes (including changing the academic status of computer science from vocational to academic and establishing a computer science teaching credential) necessary to improve the quality of high school computer science instruction.<br\/><br\/>The research hypotheses explored focus on: students as computer scientists, whether in mathematics, science or computer science courses; teachers as computer scientists, whether teaching mathematics, science or computer science; and impact on pre-service teachers in terms of their likelihood to utilize inquiry-based instructional strategies during their early years of teaching.","title":"MOBILIZE: Mobilizing for Innovative Computer Science Teaching and Learning","awardID":"0962919","effectiveDate":"2010-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1792","name":"MSP-TARGETED AWARDS"}}],"PIcoPI":["537785","528135","460071","528136","560926"],"PO":["564918"]},"169803":{"abstract":"Human languages use pitch to convey meaning in a bewildering variety of ways. In all languages, pitch (as one aspect of speech prosody) can express attitude or emotion. In some languages, like English, pitch patterns, usually called intonation contours, also express distinctions such as that between a question and a statement. In languages like Mandarin Chinese, pitch patterns usually called tones go still further to signal differences between words that are otherwise identical. Despite significant advances in recent decades, a unified theoretical account of such linguistic phenomena remains elusive. What is missing is a common acoustic or articulatory vocabulary for expressing the relevant distinctions---a single measurable dimension within which spoken pitch contours (rises and falls) can be reliably distinguished regardless of the language under investigation. In recent work, the research team developed a new mathematical approach to tone and intonation, based on the notion of Tonal Center of Gravity. TCoG is a gestalt or global approach to tone perception and production that reconciles seemingly contradictory results from different strands of the experimental literature, moving toward a model that incorporates the best aspects of past theories, while avoiding their characteristic weaknesses. That earlier work has established that the TCoG approach accounts well for production and perception data involving two contrasting English intonation contours. This project aims to expand the empirical range of the approach in three crucial ways: First it extends the model to additional English intonation patterns. Second, it moves beyond English to look at other intonation languages (e.g., German), as well as so-called \"tone languages\" (e.g., Serbian). Lastly, whereas the previous work concentrated primarily on the timing of tonal events in speech, this project goes further, to investigate the interaction of tonal timing patterns with the scaling of tonal events in the pitch domain. The experimental work will be of two primary kinds: automatic classification of pitch contours recorded from native speakers in an experimental setting, and direct manipulation (through speech synthesis) of pitch contours in perception studies designed to determine which aspects of the acoustic signal have the greatest effect on listeners' judgments of utterance meaning.<br\/><br\/>Given the central role of intonation patterns in speech communication, one major contribution of the Tonal Center of Gravity approach is its potential to transform methods for speech synthesis and speech understanding. Synthetic speech is typically described as repetitive, detached, and often unhelpfully neutral; listeners recognize that they are talking with a machine that 'doesn't get it'. By providing a more detailed understanding of how intonational patterns help to convey a message, TCoG could be used to devise algorithms for the synthesis of more natural and appropriate-sounding speech. Likewise, for automatic understanding of the aspects of meaning that depend on intonational patterns, TCoG could allow an automatic system to detect levels of nuance beyond simply whether a word is emphasized or not, or whether an utterance is a statement or a question. A final application of this work could be in the development of software tools for second language learning, in which automated instruction and feedback on the subtleties of second language intonation patterns could help learners master important aspects of communication that are typically ignored in current approaches to language pedagogy.","title":"Collaborative Research: Integrating Shape, Scaling, and Alignment in a Global Approach to F0 Events in Intonation Systems","awardID":"1023853","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["456055"],"PO":["564343"]},"172685":{"abstract":"Proposal #: 10-40666<br\/>PI(s): Ghose, Kanad; Gopala, Kardik; Murray, Brice T; Sammakia, Bahgat G; <br\/>Institution: SUNY - Binghamton <br\/>Title: MRI\/Dev.: Fully Instrumented Self-Sensing and Self-Regulating Data Center<br\/>Project Proposed:<br\/>The project, building an instrument for next generation data centers where energy consumption and management is treated as a first class resource (together with CPU, communications, etc) that needs to be scheduled and managed explicitly to maximize the overall energy-efficiency of the data center, takes a new approach for predicting local and global thermal conditions with new control paradigms. Studying the most energy-efficient use of the cooling resources, the proposed instrument specifically involves:<br\/>- Experimental, scaled down data center of Linux servers with dynamic cooling facilities, modified kernels. and scheduling components; <br\/>- Large number of temperature and airflow sensors and power meters, along with software instrumentation; <br\/>- Floor plenum based chilled air cooling system used to provide nominal cooling and remotely controlled computer room air conditioners (CRACs) that provide a quickly adjustable and directed cooling facility;<br\/>- Software components for the facility that permit research into the development of a wide variety of techniques, both traditional and innovative, for improving the data center energy efficiency; and <br\/>- Generation and recording live data on workload levels, power consumption, temperature, and airflow distributions. <br\/>Broader Impacts: <br\/>This unique facility primarily provides solutions for energy efficiency in data centers. The project intensively involves minority, women, and undergraduate students in their research. The instrument contributes to prepare all students for rewarding careers in the technology, management, and use of data centers.","title":"MRI: Development of a Fully Instrumented Self-Sensing and Self-Regulating Data Center","awardID":"1040666","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["494774","494775","494776","550962"],"PO":["557609"]},"172696":{"abstract":"A Platform for Internet Innovation<br\/><br\/>The architectural stability of the Internet was crucial in fostering the development of new applications and networking technologies by giving the former a stable base upon which to build and giving the latter a fixed set of requirements to support. However, in recent years this architectural stability has become a liability, as there are areas of increasing importance ? most notably inadequate support of security and availability, lack of adequate mechanisms for privacy, mobility, middleboxes, and data-oriented functionality ? where the original Internet architecture falls short. The persistence of the Internet's architectural deficiencies is not because they are intellectually intractable, but because they are beyond the reach of incrementally deployable changes. Based on this observation, the research team takes a different approach than recent clean-slate designs, focusing not on a new fixed architecture but instead on providing a platform to enable architectural innovation through incrementally deployable changes, without massive disruption in the infrastructure.<br\/><br\/>In this research project, the research team focuses on the ?hardware-defined functionality? challenge and proposes a ?platform for innovation? that allows the network infrastructure to support new architectures without changes to the underlying hardware. In particular, this approach will enable forwarding hardware to support a wide range of alternative designs. In addition, so that changes can be introduced alongside the current design, hardware will also be able to support multiple designs simultaneously. <br\/><br\/>The proposed platform will use a newly developed paradigm called Software-Defined Networks (SDN), currently embodied in the OpenFlow and NOX projects. OpenFlow is an open hardware forwarding interface. NOX is an open-source software platform that provides global abstractions to network management software and in turn communicates the decisions made by this software to the individual forwarding boxes. This effort will provide a solid foundation for more general SDN designs that are open, comprehensive and can meet long-term needs. <br\/><br\/>The research team will also explore and demonstrate applicability of the SDN approach including abstractions and programming model for different domains of network use. These include enterprise, WAN, home, and wireless. To demonstrate the ability of the proposed platform to support innovation in radically new network mechanisms, the research team will deploy prototype novel architectures on SDN. <br\/><br\/>If successful, the proposed approach would allow the use of known approaches and design proposals currently available in the literature to address many of the Internet's current problems, as these solutions would be incrementally deployable, without major disruption to the underlying infrastructure. Furthermore, current commercial efforts to address Internet?s deficiencies are disjointed, proprietary, and tailored for short-term needs. The next generation of SDN technology provides a solid basis for coordinated, long-term efforts to address critical needs in areas of security, mobility and support of content-centric application and services. More importantly, the proposed approach would allow the Internet to meet future requirements as they arise through incrementally deployable modifications, relieving network designers of the burden of predicting what these future requirements might be.","title":"FIA: Collaborative Research: Architecting for Innovation","awardID":"1040715","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561756"],"PO":["565255"]},"172586":{"abstract":"A Platform for Internet Innovation<br\/><br\/>The architectural stability of the Internet was crucial in fostering the development of new applications and networking technologies by giving the former a stable base upon which to build and giving the latter a fixed set of requirements to support. However, in recent years this architectural stability has become a liability, as there are areas of increasing importance ? most notably inadequate support of security and availability, lack of adequate mechanisms for privacy, mobility, middleboxes, and data-oriented functionality ? where the original Internet architecture falls short. The persistence of the Internet's architectural deficiencies is not because they are intellectually intractable, but because they are beyond the reach of incrementally deployable changes. Based on this observation, the research team takes a different approach than recent clean-slate designs, focusing not on a new fixed architecture but instead on providing a platform to enable architectural innovation through incrementally deployable changes, without massive disruption in the infrastructure.<br\/><br\/>In this research project, the research team focuses on the ?hardware-defined functionality? challenge and proposes a ?platform for innovation? that allows the network infrastructure to support new architectures without changes to the underlying hardware. In particular, this approach will enable forwarding hardware to support a wide range of alternative designs. In addition, so that changes can be introduced alongside the current design, hardware will also be able to support multiple designs simultaneously. <br\/><br\/>The proposed platform will use a newly developed paradigm called Software-Defined Networks (SDN), currently embodied in the OpenFlow and NOX projects. OpenFlow is an open hardware forwarding interface. NOX is an open-source software platform that provides global abstractions to network management software and in turn communicates the decisions made by this software to the individual forwarding boxes. This effort will provide a solid foundation for more general SDN designs that are open, comprehensive and can meet long-term needs. <br\/><br\/>The research team will also explore and demonstrate applicability of the SDN approach including abstractions and programming model for different domains of network use. These include enterprise, WAN, home, and wireless. To demonstrate the ability of the proposed platform to support innovation in radically new network mechanisms, the research team will deploy prototype novel architectures on SDN. <br\/><br\/>If successful, the proposed approach would allow the use of known approaches and design proposals currently available in the literature to address many of the Internet's current problems, as these solutions would be incrementally deployable, without major disruption to the underlying infrastructure. Furthermore, current commercial efforts to address Internet?s deficiencies are disjointed, proprietary, and tailored for short-term needs. The next generation of SDN technology provides a solid basis for coordinated, long-term efforts to address critical needs in areas of security, mobility and support of content-centric application and services. More importantly, the proposed approach would allow the Internet to meet future requirements as they arise through incrementally deployable modifications, relieving network designers of the burden of predicting what these future requirements might be.","title":"FIA: Collaborative Research: Architecting for Innovation","awardID":"1040072","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["508283"],"PO":["565255"]},"163896":{"abstract":"From Retroactivity to Modularity:<br\/>Design and Implementation of a Genetic Insulation Device in Yeast<br\/>Domitilla Del Vecchio and Ron Weiss<br\/><br\/>Modularity is an important property of engineered systems, yet it is debatable whether it is a general property of natural bio-molecular systems. Discovering the extent of modularity and understanding its mechanisms is one of the most important open research problems in systems biology. Furthermore, the long term success of synthetic biology critically depends on the ability to implement modular systems in such a way that the properties of individual components do not change unpredictably upon their interconnection. Our proposed research seeks to understand the mechanisms of modularity in regulatory networks using a combined theoretical\/experimental effort through the design, implementation, and analysis of a special genetic retroactivity insulation device in yeast. This novel device effectively decouples transcriptional components that would otherwise be highly interlocked by allowing propagation of a regulatory signal in the forward direction while minimizing the undesired phenomena of retroactivity in the reverse direction. Besides providing an important new circuit element for synthetic biologists, the mathematical analysis of an insulating device will lead to an improved understanding of the extent to which modularity is present in regulatory networks in biological systems. The first aim of our research is to show that retroactivity affects regulatory networks without insulation and therefore that modularity is not a natural property of bio-molecular signaling pathways. Second, we will demonstrate a novel insulation device that counteracts retroactivity and allows a circuit to transmit information reliably despite loading from downstream clients. This special circuit will be designed and placed between two connected components to insulate them from retroactivity effects. We will study the device?s performance, ability to regulate many copies of a downstream component, and requirements for correct operation. Third, we will study how well the insulation device is decoupled from the cellular environment. To this end, we will perform system-level analysis and investigate crosstalk between the device and various important cellular processes.<br\/> Intellectual Merit: Existing synthetic circuits lack an ability to insulate a driving input signal from retroactivity of the output load, precluding modular composition of complex biocircuits. To address this problem, we propose to construct and characterize a synthetic phosphorylation-based insulation device and instrumentation pathway that will demonstrate a general and modular technique for building sophisticated, large scale biological systems. Our novel technique leverages the integration of special rapid feedback mechanisms into biocircuits in order to create insulation devices, and hence has implications for the design and implementation of many other biological motifs and networks. Our research includes new theoretical and computational analysis of devices with feedback and retroactivity, and these new tools will also be applicable for the study of biological network problems other than retroactivity. This analysis is fundamentally important for tuning and characterizing desired insulation properties while minimizing interference with other cellular processes.<br\/> Broader Impact: In synthetic biology, this research will lead to a general understanding of the engineering principles of modularity for bio-molecular systems design. Likewise, in systems biology, this research will address a fundamental question ? To what extent is modularity an inherent property of biological systems? The product of our collaborative efforts will lead to the discovery in natural systems of motifs similar to our insulation device and to the explanation of how modularity is achieved, including insight into when and where natural systems implement modularity and for what purposes. Ultimately, the resulting capability of modular composition to achieve defined engineering goals in biological systems will have tremendous impact on human therapeutics, including regenerative medicine, diabetes, and cancer therapy, as well as in other diverse areas, including biofuel production, environmental remediation, pharmaceutical production, and biosensing applications. This research will contribute to new interdisciplinary courses and will be integrated into a ten week undergraduate synthetic biology Summer program that culminates in an international competition and has a track record of attracting women, under-represented groups, and high schools students to the field.","title":"CIF: Medium: Collaborative Research: From Retroactivity to Modularity: Design and Implementation of a Genetic Insulation Device in Yeast","awardID":"0964646","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":["496117"],"PO":["565223"]},"185138":{"abstract":"With the advent of increasing numbers of increasingly smart machines, there is a growing need to develop technologies that are not only smart, but sensitive to the people and the other machines around them, and sensitive to the context in which they are used. Such an understanding will permit the development of technologies that can coordinate their interactions with humans in a more natural, seamless and fluid fashion. To meet these goals, this research program focuses on three critical yet under-studied contexts of interaction, each of which represents a different constraint upon interpersonal communication: (1) the physical context of shared visual access, (2) the social context of rapport, and (3) the biological context of aging. While some research has been conducted on each of these contextual factors, none has addressed their interaction, nor gathered them into one broader conception of the role of context in interpersonal coordination. This research applies a theory-driven design approach that includes experimental studies, theory development, computational modeling, system implementation and evaluation. In particular, the research program proposes: a) A rigorous study of human-to-human communication using elicitation experiments to develop a more detailed understanding of interpersonal communication across a range of contexts; b) A formalization of the findings into computationally explicit forms that provide predictions of behavior and capture the observed behavioral patterns; c) Integration of the models into a dialogue manager that is implemented within a larger computational architecture; and, d) Evaluation of the implemented system by having untrained humans interact with the system in such a way as to evaluate its effectiveness and reveal gaps in the underlying models as well as in our theoretical understanding.<br\/><br\/>The outcome of this research will advance our theoretical understanding of the role various contextual factors play during interpersonal communication. The results will be useful to a variety of scientific communities including those that study basic human communication (e.g., psychologists, linguists and communication researchers) and those that study interactive computational systems (e.g., computer scientists, computational linguists, and interaction designers). The research will also provide practical design guidelines and a general computational model that describes how machines can make intelligent choices on the basis of these contextual factors during everyday interactions. At a practical level, the general computational model can be applied by technologists developing many different technologies, such as embodied agents, large-scale displays, ubiquitous computing, in-car navigation, and assistive technologies for the elderly and those with cognitive impairments.","title":"HCC: Coordinating Communication: Visual, Social & Biological Factors in Grounding for Humans and Agents","awardID":"1138299","effectiveDate":"2010-10-25","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[496760],"PO":["564456"]},"167637":{"abstract":"Providing an environment that offers both immersion and interaction is a tough research challenge. Ensuring a reasonable Quality of Experience (QoE) in using these environments installed in geographically distributed cities is even a tougher challenge. This project considers a collaborative, immersive, and interactive environment that not only supports 3D rendering of the participants? video but also other modalities such as Body Sensor Network (BSN) data that can offer highly precise data about a person?s physical movements (as well as physiological data). While creating this environment, one needs to consider the various bottlenecks that choke the data streams carrying the immersive and interactive information: reconstruction delay, ultra-high throughput needed, packet loss, and rendering delays. <br\/><br\/>The main aim of this project is to design and develop collaborative, multi-modal immersive environments with higher frame rates and frame quality by carrying out research tasks that can take advantage of information from other modalities and handle these bottlenecks.<br\/><br\/>In a typical tele-immersive environment, participants can see themselves in the locally rendered 3D view and see participants in the remote environments as well. Since the local rendering delays are much smaller, participants can see themselves earlier and in a more smooth fashion compared to the rendering of remote participants that suffers from communication delays and packet losses. This aspect of varying delays among the immersive participants can potentially cause problems during dynamic interactions and affect their QoE. Answers to questions such as what type of problems can be caused and how the participants handle them depend on the application domain of the immersive environments. To study the QoE and validate (with usability studies) the collaborative, immersive environment, a tele-rehabilitation application will be deployed in multiple cities: Berkeley, California; 2 sites in Dallas, Texas; and Urbana-Champaign, Illinois. <br\/><br\/>Intellectual Merits of this project are (i) The resource adaptation framework for streaming multi-source, multi-destination, multi-rate, multi-modal data incorporates supervisory hybrid control theory based fine-grained resource management, multi-modal coarse-grained management, and a multi-modal multicasting approach. (ii) Graphics Processing Unit (GPU)-based 3D reconstruction and compression algorithms. These algorithms facilitate reconstruction of 3D data points based on 3D camera array data and compress them at a faster pace than their CPU-based counterparts. (iii) GPU-based rendering algorithm of 3D data on the receiver side. This algorithm will handle potential data loss in 3D camera data streams using skeletal information from BSN data streams. (iv) Identification and measurement of Quality of Experience (QoE) metrics and using those metrics to derive Quality of Service (QoS) parameters. The derived QoS parameters will then help the resource adaptation framework to modify its decisions at run-time. This project aims to have transformative aspects in the new set of algorithms that exploits multi-modality while incorporating a feedback based on Quality of Experience for functions such as streaming, 3D reconstruction, and rendering.<br\/><br\/>Broader Impacts: This project promises significant impact in the fields of education and pervasive health care by providing augmented abilities to carry out intricate programs such as tele-rehabilitation with increased correctness and flexibility. This can also lead to improved productivity in the society considering the ability of health-care professionals to potentially handle a larger population (in remote places) as well as considering the possibility of the affected persons to become independent and productive faster. The project also ensures the results from the proposed research will be incorporated into the courses being taught. 3 women PhD students and 6 under-graduate students (2 are minority students) already working with the investigators of this project. Serious efforts will be undertaken to continue their involvement in this project. Apart from refereed conference and journal publications, the developed software, collected data, and research results will be shared with other researchers through a dedicated website (after ensuring satisfaction of HIPAA regulations).","title":"NetSE:Large:Collaborative Research: Exploiting Multi-modality for Tele-Immersion","awardID":"1012975","effectiveDate":"2010-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["502215","474699","558157",449102],"PO":["565090"]},"183675":{"abstract":"This project will implement and evaluate technological supports for African-American Vernacular English(AAVE)-speaking children to learn Standard American English while engaging in problem-based scientific inquiry. The technology consists of virtual peers that collaborate with children to solve a bridge-building problem, while scaffolding the notion that different kinds of language are appropriate for different conversational contexts. The work relies on the recognition that primary school education is based on a set of mainstream oral practices and literacy-preparation skills, and yet all children do not share the same cultural experiences typical of mainstream culture, nor come to school speaking the same dialect of English. Similarly, while traditional science classrooms have emphasized a particular style of scientific discourse, not all children come to school with the mastery of these discourse styles. Scientific inquiry is at the heart of the contemporary science classroom but it is usually defined according to a specific cultural tradition that privileges individual opinion, 'talking back' to the teacher, and criticism of others; a tradition that may not be shared by all students, and which may have ramifications for science achievement among diverse populations. A unique approach for integrating cultural authenticity into learning technology will be pursued: (1) carrying out an in-depth investigation into AAVE peer-oriented language and nonverbal communicative behaviors. The corpus of data obtained from this study will be shared with all interested researchers via the Penn Linguistic Data Consortium; (2) Two technological innovations will extend prior work on virtual peers so as to make possible the current work: (a) PIPER, a new platform for rapid prototyping and implementation of virtual peers so that each of the virtual peers does not require extensive re-implementation as it did in our Flash days; (b) AVP, an authoring system for virtual peers so that children themselves can program the virtual peer as a way of actively engaging with the technology, with code-switching and with collaborative science inquiry and then description of that inquiry to a teacher; (3) evaluating the technologies with respect to their role in improving children?s use of SAE, their educational self-efficacy, and their learning gains in second grade standardized science measures.<br\/><br\/>The broader significance and important of the work lies in: (1) the potential to substantially increase access to reading, writing, and science literacy for under-served, at-risk children, and to thereby decrease the Black-White achievement gap; (2) technological innovation that will allow other researchers to quickly prototype and implement virtual peers and pedagogical agents that speak different dialects and language, and that can be programmed by their designers, and by their users; (3) an innovative program of dissemination of results and research practices that involves publication and presentation of results, sharing the corpus of data via the Penn Linguistic Data Consortium, but also the involvement of local schools with high populations of African-Americans, local churches and community centers, and informal education institutions such as science centers and children's museums.","title":"Bridging the Achievement Gap with Authorable Virtual Peers","awardID":"1129360","effectiveDate":"2010-10-25","expirationDate":"2013-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["496760"],"PO":["564456"]},"172598":{"abstract":"Proposal #: 10-40123<br\/>PI(s): Peterson, Larry L.<br\/> Freedman, Michael J.; Pai, Vivek; Rexford, Jennifer<br\/>Institution: Princeton University <br\/>Title: MRI\/Dev: Development of a Virtual Cloud Computing Infrastructure <br\/>Project Proposed:<br\/>This project, building VICCI, a programmable cloud-computing research testbed, enables a broad research agenda in the design of network systems that requires both multiple point-of-presence and significant processing\/storage capabilities on the sites. VICCI, a distributed instrument with a point-of-presence at Princeton, GeorgiaTech, Stanford, and U Washington, along with international clusters in Europe and Japan, encompasses both a distributed set of virtualized compute clusters and networking hardware and the software that enables multiple researchers to innovate both at and above the infrastructure layer. It is designed to support research both into the design and deployment of large-scale distributed services that use an environment. VICCI enables research in<br\/>- Building block services (addressing issues of replication, consistency, fault-tolerance, scalable performance, object location, and migration) designed to be used by other cloud applications,<br\/>- Developing new cloud programming models designed for targeted application domains, and<br\/>- Studying cross-cutting issues at the foundation of the cloud?s design and how to build a trusted cloud platform that ensures confidentiality and integrity of computations that are outsourced to the cloud.<br\/>Plans include bootstrapping VICCI with working software from PlanetLab with an ultimate goal of folding the results into VICCI itself, thus creating an even more effective platform for research into scalable network systems.<br\/>Broader Impacts: <br\/>This project, strongly influenced by the experience with PlanetLab that has demonstrated the importance of deploying experimental network services on realistic platforms (i.e., platforms that are realistic enough to attract the real user community), provides a realistic environment to evaluate and deploy scalable new network services. VICCI supports deployment studies of prototype systems. Thus, it accelerates research and teaching processes by supporting seamless migration of scalable services and applications from early prototypes. Moreover, it offers a path to re-energize the innovative process that has led to new network services, widespread consumer adoption, and generation of new economic and social value. It also provides graduate students with extensive experience in building large-scale distributed systems and enables the design of more courses taking advantage of the instrument.","title":"MRI: Development of a Virtual Cloud Computing Infrastructure","awardID":"1040123","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["533299","560046","533300","531675"],"PO":["557609"]},"176218":{"abstract":"Artemis is a five-week summer program in which its participants (rising ninth-grade girls) are exposed to the breadth of Computer Science. The girls learn by undertaking a range of educational and confidence-building activities. Further, the girls hear lectures from women scientists and other potential role models from academia and industry. Artemis is also a networking opportunity: the girls who participate befriend other girls their age who have an interest in the sciences. A key goal of the program is that each Artemis student should be able to picture herself as a scientist by the end of the summer.<br\/><br\/>An equally important goal of Artemis is to develop the skills of the program's coordinators. Female Brown undergraduates serve as coordinators each year. While their primary responsibilities are to design a curriculum and teach Computer Science, the coordinators are also empowered to make many of the decisions that are critical to running the program. They advertise Artemis, review applications and select participants, budget the enterprise and eventually hire their own successors. Through their participation in Artemis, the coordinators develop strong leadership and entrepreneurial skills, and ultimately serve Brown's local community in their capacity as social entrepreneurs.<br\/><br\/>This award supports Artemis---its past activities and two additions. First, as Artemis is in its 15th year, this project is assessing the impact of the program. The project is undertaking a longitudinal study of Artemis, using expert evaluators, to determine if Artemis girls and coordinators go on to pursue careers in the sciences at a higher rate than non-Artemis girls and coordinators. This evaluation is crucial to the long-term sustainability of Artemis, because it will enable us to discover the dimensions along which the program is successful, which will guarantee continued institutional commitment and facilitate future fundraising efforts. Second, the award is funding tentative steps to expand Artemis beyond Brown, beginning with Boston University. The Boston University Artemis program will be administered by the Learning Resource Network (LERNet), a center dedicated to promoting science, mathematics, and engineering among the pre-college population by offering a wide range of programs that engage K-12 students in STEM activities, expose them to current scientific research, and stimulate their interest in STEM disciplines.","title":"EAGER: The Artemis Project: Evaluation and Expansion","awardID":"1059570","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["517963"],"PO":["565035"]},"172643":{"abstract":"Proposal #: 10-40422 Collaborative with Proposal #: 10-40429<br\/>PI(s): Prakash, Ravi & Rajan, Dinesh <br\/>Banerjee, Bhaskar; Mittal, Neeraj, Venkatesan,S. & Camp, Joseph, Chen, Jinghong, Gui, Ping<br\/>Institution(s): University of Texas-Dallas & Southern Methodist University<br\/>Title: MRI\/Dev Consortium: Dev. of Wireless Networking Testbed and Emulator (WiNeTestEr) <br\/>Project Proposed:<br\/>This project proposes to build a versatile wireless networking testbed called Wireless Networking Testbed and Emulator (WiNeTestEr). The main objectives and the novelty of this testbed is in its capability to <br\/>- Emulate the large-scale wireless networks in multiple licensed and unlicensed bands, <br\/>- Allow access to local and remote users to configure and control the same emulator, and provide repeatability,<br\/>- Support experiments related to node mobility, multi-antenna (MIMO) operation, and cognitive radios, and <br\/>- Provide an easy-to-use interface for remotely running wireless experiments over<br\/>The main intellectual challenge is in fundamental difficulties to emulate the analog nature of wireless channels and the related effects, such as attenuation, multipath fading and multi-user interference. To this end the proposal addresses methods to emulate the multipath effect, such as by converting the analog RF signal from a node into digital baseband, buffer it for a period of time using an FPGA, add scaled versions of the signals that have experienced different amounts of delay, and finally, convert the resulting signal back into the analog domain. To emulate multi-user interference, the proposal suggests that RF signals from different nodes are fed into an RF combiner and then into a receiving node?s antenna. Other channel effects are also addressed. It is planed to emulate different wireless environments with consideration of scalability up to hundreds of wireless nodes. The design of the WiNeTestEr is robust, as it will use coaxial cables to connect the wireless nodes to the emulator which mimics the over-the-air link between them. In this way, the network should be immune to interference from other devices in the laboratory and the environment. The usage of the instrument includes novel developments in both hardware and software, such as new wideband RF circuits and boards for emulation emulate a variety of channel effects, a new RF combiner that can simultaneously operate over multiple bands, and a software tool that includes algorithm design, control of parallel emulator processes, and network management.","title":"MRI Consortium: Development of Wireless Networking Testbed and Emulator (WiNeTestEr)","awardID":"1040422","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":[462891,462892,"485416",462894],"PO":["557609"]},"176955":{"abstract":"This project is to sponsor a workshop on ?Cooperative Autonomous Resilient Defenses in Cyberspace (CyberCARD)? which is to be held in the DC metro area over the two days of January 27-28, 2011.<br\/><br\/>The outcome of this workshop is a report that outlines new research directions in the area of Cooperative Autonomous Resilient Defenses in Cyberspace. This report will become available on the web within two weeks after the conclusion of the workshop.<br\/><br\/>The workshop consists of four tracks that span all areas of defenses in cyberspace:<br\/><br\/>1. Trustworthy cyber-physical systems and infrastructures: to provide robust control and communications.<br\/><br\/>2. Pervasive monitoring and analytics: to provide self-awareness and situational-awareness, particularly in real time<br\/><br\/>3. Attack-resilient system operation: to provide continuous services even under persistent attacks<br\/><br\/>4. Cooperative autonomous cyberspace defense: to enable systems to work together cooperatively with shared understanding","title":"Workshop on Cooperative Autonomous Resilient Defenses in Cyberspace (CyberCARD)","awardID":"1063152","effectiveDate":"2010-10-01","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[474437],"PO":["493916"]},"171841":{"abstract":"Body Area Sensor Networks: A Holistic Approach from Silicon to Users <br\/>The objective of this research is to develop new principles and techniques for adaptive operation in highly dynamic physical environments, using miniaturized, energy-constrained devices. The approach is to use holistic cross-layer solutions that simultaneously address all aspects of the system, from low-level hardware design to higher-level communication and data fusion algorithms to top-level applications. In particular, this work focuses on body area sensor networks as emerging cyber-physical systems.<br\/>The intellectual merit includes producing new principles regarding how cyber systems must be designed in order to continually adapt and respond to rapidly changing physical environments, sensed data, and application contexts in an energy-efficient manner. New cross-layer technologies will be created that use a holistic bottom-up and top-down design -- from silicon to user and back again. A novel system-on-a-chip hardware platform will be designed and fabricated using three cutting-edge technologies to reduce the cost of communication and computation by several orders of magnitude.<br\/>The broad impact of this project will enable the wide range of applications and societal benefits promised by body area networks, including improving the quality and reducing the costs of healthcare. The technology will have broad implications for any cyber physical system that uses energy constrained wireless devices. A new seminar series will bring together experts from many fields (including domain experts, such as physicians and healthcare professionals). The key aspects of this work that deal with healthcare have the potential to attract women and minorities to the computer field.","title":"CPS: Medium: Collaborative Research: Body Area Sensor Networks: A Holistic Approach from Silicon to Users","awardID":"1035303","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["534190"],"PO":["565274"]},"172710":{"abstract":"A Platform for Internet Innovation<br\/><br\/>The architectural stability of the Internet was crucial in fostering the development of new applications and networking technologies by giving the former a stable base upon which to build and giving the latter a fixed set of requirements to support. However, in recent years this architectural stability has become a liability, as there are areas of increasing importance ? most notably inadequate support of security and availability, lack of adequate mechanisms for privacy, mobility, middleboxes, and data-oriented functionality ? where the original Internet architecture falls short. The persistence of the Internet's architectural deficiencies is not because they are intellectually intractable, but because they are beyond the reach of incrementally deployable changes. Based on this observation, the research team takes a different approach than recent clean-slate designs, focusing not on a new fixed architecture but instead on providing a platform to enable architectural innovation through incrementally deployable changes, without massive disruption in the infrastructure.<br\/><br\/>In this research project, the research team focuses on the ?hardware-defined functionality? challenge and proposes a ?platform for innovation? that allows the network infrastructure to support new architectures without changes to the underlying hardware. In particular, this approach will enable forwarding hardware to support a wide range of alternative designs. In addition, so that changes can be introduced alongside the current design, hardware will also be able to support multiple designs simultaneously. <br\/><br\/>The proposed platform will use a newly developed paradigm called Software-Defined Networks (SDN), currently embodied in the OpenFlow and NOX projects. OpenFlow is an open hardware forwarding interface. NOX is an open-source software platform that provides global abstractions to network management software and in turn communicates the decisions made by this software to the individual forwarding boxes. This effort will provide a solid foundation for more general SDN designs that are open, comprehensive and can meet long-term needs. <br\/><br\/>The research team will also explore and demonstrate applicability of the SDN approach including abstractions and programming model for different domains of network use. These include enterprise, WAN, home, and wireless. To demonstrate the ability of the proposed platform to support innovation in radically new network mechanisms, the research team will deploy prototype novel architectures on SDN. <br\/><br\/>If successful, the proposed approach would allow the use of known approaches and design proposals currently available in the literature to address many of the Internet's current problems, as these solutions would be incrementally deployable, without major disruption to the underlying infrastructure. Furthermore, current commercial efforts to address Internet?s deficiencies are disjointed, proprietary, and tailored for short-term needs. The next generation of SDN technology provides a solid basis for coordinated, long-term efforts to address critical needs in areas of security, mobility and support of content-centric application and services. More importantly, the proposed approach would allow the Internet to meet future requirements as they arise through incrementally deployable modifications, relieving network designers of the burden of predicting what these future requirements might be.","title":"FIA: Collaborative Research: Architecting for Innovation","awardID":"1040838","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["560562"],"PO":["565255"]},"172523":{"abstract":"Abstract <br\/>Proposal #: 10-39741 <br\/>PI(s): Papanikolopoulos, Nikolaos; Lim, Kelvin; Guillermo Sapiro <br\/>Institution: University of Minnesota <br\/>Title: MRI\/Dev.: Video-Based Robotic Instrument for Behavioral Analysis and Diagnosis of At-Risk Children <br\/><br\/>Project Proposed: <br\/>The proposed set of tools constitutes a video-based robotic instrument which targets the domain of early diagnosis for children at risk of developing psychiatric disorders. As such, this proposal is at the disciplinary boundaries between computer science, psychology and psychiatry, and medicine. Proposed is the development of a robotic instrument that could observe and automatically analyze abnormalities in children, thus introducing a novel technology which can help identifying children at risk. Specific activities include: <br\/>- Development and clinical verification of instrumentation and clinical protocols to quantify mental disorders in children; <br\/>- Development and usage of computer vision and machine learning methodologies in the instrument; <br\/>- Development of statistical models to evaluate the available related data sets; <br\/>- Usage of a wide array of passive and active sensors and state-of-the-art 3D camera systems to collect and analyze the monitored data; <br\/>- Usage of robots and robot pets as a means to detect and treat mental disorders; and, <br\/>- Practical validation of the instrument at the Medical School. <br\/><br\/>Broader Impacts: <br\/>The recent usage of computer vision methodologies\/hardware and robotics for detection of mental disorders in children, in itself, constitutes strong broader impacts. Planned are also educational programs (workshops, tutorials, etc.) that will enable training gathering of physicians and psychologists to the aforementioned methods\/procedures, which would otherwise not be possible. Moreover, significant planned curriculum development at the participating institutions revolves around the instrument. In addition, outreach activities for middle-school students from underrepresented groups will take place, and so will outreach to various pertinent patient groups. This truly interdisciplinary project also plans to include international partners.","title":"MRI: Development of a Video-Based Robotic Instrument for Behavioral Analysis and Diagnosis of At-Risk Children","awardID":"1039741","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":["557449","549760","557451"],"PO":["557609"]},"172644":{"abstract":"Proposal #: 10-40422 Collaborative with Proposal #: 10-40429 <br\/>PI(s): Prakash, Ravi & Rajan, Dinesh <br\/>Banerjee, Bhaskar; Mittal, Neeraj, Venkatesan,S. & Camp, Joseph, Chen, Jinghong, Gui, Ping <br\/>Institution(s): University of Texas-Dallas & Southern Methodist University <br\/>Title: MRI\/Dev Consortium: Dev. of Wireless Networking Testbed and Emulator (WiNeTestEr) <br\/>Project Proposed: <br\/>This project proposes to build a versatile wireless networking testbed called Wireless Networking Testbed and Emulator (WiNeTestEr). The main objectives and the novelty of this testbed is in its capability to <br\/>- Emulate the large-scale wireless networks in multiple licensed and unlicensed bands, <br\/>- Allow access to local and remote users to configure and control the same emulator, and provide repeatability, <br\/>- Support experiments related to node mobility, multi-antenna (MIMO) operation, and cognitive radios, and <br\/>- Provide an easy-to-use interface for remotely running wireless experiments over <br\/>The main intellectual challenge is in fundamental difficulties to emulate the analog nature of wireless channels and the related effects, such as attenuation, multipath fading and multi-user interference. To this end the proposal addresses methods to emulate the multipath effect, such as by converting the analog RF signal from a node into digital baseband, buffer it for a period of time using an FPGA, add scaled versions of the signals that have experienced different amounts of delay, and finally, convert the resulting signal back into the analog domain. To emulate multi-user interference, the proposal suggests that RF signals from different nodes are fed into an RF combiner and then into a receiving node?s antenna. Other channel effects are also addressed. It is planed to emulate different wireless environments with consideration of scalability up to hundreds of wireless nodes. The design of the WiNeTestEr is robust, as it will use coaxial cables to connect the wireless nodes to the emulator which mimics the over-the-air link between them. In this way, the network should be immune to interference from other devices in the laboratory and the environment. The usage of the instrument includes novel developments in both hardware and software, such as new wideband RF circuits and boards for emulation emulate a variety of channel effects, a new RF combiner that can simultaneously operate over multiple bands, and a software tool that includes algorithm design, control of parallel emulator processes, and network management.","title":"MRI Consortium: Development of Wireless Networking Testbed and Emulator (WiNeTestEr)","awardID":"1040429","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["557493",462897,"550846",462899],"PO":["557609"]},"174954":{"abstract":"Abstract<br\/><br\/>This innovative project explores in a novel fashion an emerging phenomenon of significant importance to academic research. Public academic information resources on the social web are growing in size and number at a very rapid rate. The goal of this project is to develop a quality assessment and an association discovery framework for online academic information, and ultimately to establish a novel framework for supporting researchers in accessing, organizing, utilizing, and exchanging all types of academic information. The proposed assessment framework will utilize the rich behaviors expressed in social reference data to design quality assessment measures that are tightly connected to the new data. The framework will utilize publicly-available academic information on social reference sites, and examine association rules that connect two articles based on time periods, topics and social-network based measures. The dynamic information environment of the web adds considerably to the challenges associated with this research. However, if successful, the results will be of considerable value to many communities of domain researchers.","title":"EAGER: Tapping into Public Academic Information on the Social Web: Towards a Novel Academic Recommendation Framework","awardID":"1052773","effectiveDate":"2010-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[469267],"PO":["564456"]},"163745":{"abstract":"Modern society is increasingly relying on wireless networks. Spectrum is the most valuable resource in a wireless network. How to share this limited resource among different users is one of the main challenges. When different users share the same spectrum, their signals cause interference to each other. Therefore, the most distinctive feature of wireless networks is the phenomenon of interference. In this research, we place special emphasis on practical considerations to ultimately find new ? realistic ? methods to deal with interference.<br\/><br\/>A recent development is the idea of interference alignment which has shown that the capacity of wireless networks may be significantly higher than previously believed. Since higher rates invariably come at the cost of lower reliability, the emerging capacity results present only half the picture. This research is motivated by the need to complete this picture by evaluating the benefits of interference alignment schemes on the performance of wireless networks when both rate and reliability are of concern. The research follows three main thrusts. First, we examine the rate-reliability tradeoff of interference alignment schemes from the traditional coding perspective which places emphasis on low decoding complexity, usually at the cost of a restricted notion of optimality. Second, we examine the rate-reliability tradeoff of interference alignment schemes in the Shannon framework which allows strong definitions of optimality, usually at the cost of unbounded delay and complexity. These two thrusts are the stepping stones to the final thrust to reconcile the findings from the two distinct perspectives and use the collective insights to develop new physical layer schemes that can operate at the frontier of the rate-reliability tradeoff.","title":"CIF: Medium: Interference Alignment and the Rate-Reliability Tradeoff of Wireless Networks","awardID":"0963925","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["518462","550258"],"PO":["564924"]},"167508":{"abstract":"Providing an environment that offers both immersion and interaction is a tough research challenge. Ensuring a reasonable Quality of Experience (QoE) in using these environments installed in geographically distributed cities is even a tougher challenge. This project considers a collaborative, immersive, and interactive environment that not only supports 3D rendering of the participants? video but also other modalities such as Body Sensor Network (BSN) data that can offer highly precise data about a person?s physical movements (as well as physiological data). While creating this environment, one needs to consider the various bottlenecks that choke the data streams carrying the immersive and interactive information: reconstruction delay, ultra-high throughput needed, packet loss, and rendering delays. <br\/><br\/>The main aim of this project is to design and develop collaborative, multi-modal immersive environments with higher frame rates and frame quality by carrying out research tasks that can take advantage of information from other modalities and handle these bottlenecks.<br\/><br\/>In a typical tele-immersive environment, participants can see themselves in the locally rendered 3D view and see participants in the remote environments as well. Since the local rendering delays are much smaller, participants can see themselves earlier and in a more smooth fashion compared to the rendering of remote participants that suffers from communication delays and packet losses. This aspect of varying delays among the immersive participants can potentially cause problems during dynamic interactions and affect their QoE. Answers to questions such as what type of problems can be caused and how the participants handle them depend on the application domain of the immersive environments. To study the QoE and validate (with usability studies) the collaborative, immersive environment, a tele-rehabilitation application will be deployed in multiple cities: Berkeley, California; 2 sites in Dallas, Texas; and Urbana-Champaign, Illinois. <br\/><br\/>Intellectual Merits of this project are (i) The resource adaptation framework for streaming multi-source, multi-destination, multi-rate, multi-modal data incorporates supervisory hybrid control theory based fine-grained resource management, multi-modal coarse-grained management, and a multi-modal multicasting approach. (ii) Graphics Processing Unit (GPU)-based 3D reconstruction and compression algorithms. These algorithms facilitate reconstruction of 3D data points based on 3D camera array data and compress them at a faster pace than their CPU-based counterparts. (iii) GPU-based rendering algorithm of 3D data on the receiver side. This algorithm will handle potential data loss in 3D camera data streams using skeletal information from BSN data streams. (iv) Identification and measurement of Quality of Experience (QoE) metrics and using those metrics to derive Quality of Service (QoS) parameters. The derived QoS parameters will then help the resource adaptation framework to modify its decisions at run-time. This project aims to have transformative aspects in the new set of algorithms that exploits multi-modality while incorporating a feedback based on Quality of Experience for functions such as streaming, 3D reconstruction, and rendering.<br\/><br\/>Broader Impacts: This project promises significant impact in the fields of education and pervasive health care by providing augmented abilities to carry out intricate programs such as tele-rehabilitation with increased correctness and flexibility. This can also lead to improved productivity in the society considering the ability of health-care professionals to potentially handle a larger population (in remote places) as well as considering the possibility of the affected persons to become independent and productive faster. The project also ensures the results from the proposed research will be incorporated into the courses being taught. 3 women PhD students and 6 under-graduate students (2 are minority students) already working with the investigators of this project. Serious efforts will be undertaken to continue their involvement in this project. Apart from refereed conference and journal publications, the developed software, collected data, and research results will be shared with other researchers through a dedicated website (after ensuring satisfaction of HIPAA regulations).","title":"NetSE: Large: Collaborative Research: Exploiting Multi-Modality for Tele-Immersion","awardID":"1012194","effectiveDate":"2010-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["561784"],"PO":["565090"]},"168829":{"abstract":"This research investigates efficient and effective quantitative risk analytics methods for enterprise network security. The research uses attack graphs, a widely used and well-tested technique for enterprise network security analysis, as the foundation to build a metric model. It aims to produce a theoretically sound model with extensive empirical evaluation on continuous fresh data from production networks. The soundness ensures that the computed metrics have a clear meaning, which is useful since inputs to such metric models are inevitably imprecise probability estimates, but one still needs the computed metrics to be meaningful within a known error bound so that they can be further applied to estimate expected loss from possible cyber breaches. The research investigates methods that can calculate such metrics both efficiently, and with controlled accuracy. The metric model will be evaluated on continuous fresh data produced from the PI's departmental network at Kansas State University, as well as other available data sources.<br\/><br\/>This research will provide technology and tools for organizations to dramatically improve the efficiency in security administration of their enterprise networks. The metric models developed from the research will facilitate knowledge sharing among stake holders in cyber security, leading to standardized technologies that benefit our society. The PI's intend to widely disseminate the research result to security practitioners in the field, through tutorials and workshops. The researchers will collaborate with Idaho National Laboratory to apply the metric models to critical infrastructure protection. The research\/education activities also outreach to a larger community, including women and other under-represented groups in science and engineering, through the various programs already established at Kansas State University.<br\/><br\/>For further information see the project web site at the URL:<br\/>http:\/\/people.cis.ksu.edu\/~xou\/securitymetrics\/","title":"TC:Small:Collaborative Research:Models and Techniques for Enterprise Network Security Metrics","awardID":"1018703","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548367"],"PO":["565136"]},"173999":{"abstract":"As supercomputers become more powerful, they become more complex. In order to take advantage of the increased power, scientific applications that run on these supercomputers will have to become more complex and will have to take advantage of more processing cores. Even those who are expert at optimizing these applications are quickly being overwhelmed. The Workbench for HPC Applications (W-HPC) project is transforming the way these experts develop, debug, optimize, and run their applications. Using the Eclipse platform, W-HPC provides a robust and portable way to manage computational science and engineering code development for a range of research disciplines. W-HPC also includes a targeted education and outreach program including outreach to minority-serving institutions that will train new users, explain the advantages of using Eclipse-based tools, and encourage users participate in the development of new tools.<br\/><br\/>The next generation of petascale systems will give unprecedented power to the scientific community as they tackle grand challenge problems. However, in order to take advantage of the huge potential performance improvements, application size and complexity will increase substantially as projects become multi-institutional and multi-disciplinary. The Workbench for HPC Applications project is transforming the way the community develops, debugs, optimizes, and runs its applications. As part of the project, the Eclipse Parallel Tools Platform (Eclipse PTP) is being enhanced. Eclipse PTP provides an open source, robust, portable, and sustainable development environment suitable for use with a broad range of scientific codes. Targeted education and outreach activities are also part of the project. They will train new users, explain the advantages of using Eclipse-based tools, and encourage users participate in the development of new tools.","title":"SI2-SSI: A Productive and Accessible Development Workbench for HPC Applications Using the Eclipse Parallel Tools Platform","awardID":"1047956","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0708","name":"Division of EMERGING ENGINEERING TECHNOLOG","abbr":"EET"},"pgm":{"id":"1414","name":"INTERFAC PROCESSES & THERMODYN"}}],"PIcoPI":["556685","503795","540196",466745,"530888"],"PO":["558595"]},"171921":{"abstract":"Tens of thousands of the nation?s bridges are structurally deficient. This project proposes to design a self sustaining, wireless structural monitoring system. The novel low-power Flash FPGA-based hardware platform and the corresponding software architecture offer a radically new approach to CPS design. A soft multi-core platform where software modules that run in parallel will be guaranteed to have dedicated single-threaded soft processor cores enables flexible power management by running only the necessary cores at any given time at the slowest clock rate mandated by the observed\/controlled physical phenomena. As bridges tend to vibrate due to wind and dynamic load conditions, we are developing a novel vibration-based energy harvesting device that is capable of automatically adjusting its resonant response in order to capture much more energy than the current techniques can. Moreover, the PIs are developing structural health assessment techniques involving quantitative analysis of signals to determine crack type, location and size. <br\/><br\/>The technology will indicate structural problems before they become critical potentially saving human lives and averting late and extensive repairs. The impact of the vibration harvesting technique and the soft multi-core architecture will go beyond structural monitoring. A separate soft core dedicated to each software component that interacts with the physical world will make CPS more responsive while saving power at the same time. <br\/><br\/>The education plan focuses on outreach toward underrepresented minorities by recruiting such undergraduates to participate in the research. To facilitate the dissemination of our results, all hardware designs and software developed under this project will be open source.","title":"CPS: Medium: Self-Sustaining CPS for Structural Monitoring","awardID":"1035627","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[460491,"551714",460493,"527012"],"PO":["565274"]},"175705":{"abstract":"This NSF grant supports the First PI Meeting and Workshop on Cyber-Physical Systems (CPS), held at the Westin Arlington Gateway hotel, in Arlington, VA on Aug 10-12, 2010. The purpose of this meeting is to provide a forum for scientific interaction among a wide range of stakeholders in academia, industry and federal agencies; to review new developments in CPS foundations; to identify new, emerging applications; and to discuss technology gaps and barriers. The program of the meeting includes presentations from projects funded by NSF under the Cyber-Physical Systems program, government and industry panels, and topical discussion groups.","title":"CPS - Principal Investigator Meeting 2010","awardID":"1057390","effectiveDate":"2010-10-01","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["553600"],"PO":["561889"]},"163759":{"abstract":"The energy cost of operating large server farms is now a sizable portion of their total-cost-of-ownership. The focus of the ecoDB project is to design, develop and evaluate methods that improve the energy efficiency of such server farms for data-intensive applications. ecoDB will investigate a range of issues, including \"global\" issues that considers the entire server farm as a holistic single large computing system and uses energy-aware workload management and data placement strategies. These global techniques will be implemented in various existing distributed systems, including the Condor system. At the other end of the spectrum, this proposal plans to investigate \"local\" techniques that can be used to improve the energy efficiency of an individual server by synergistically exploiting the underlying hardware and\/or software characteristics. A crucial aspect of the ecoDB project is to focus on techniques that systematically trade performance for energy efficiency, essentially treating \"energy consumption\" as a first-class metric in data processing systems. The repercussions of this approach percolate through various aspects of a data processing systems ranging from query\/workload optimization and evaluation to replication management and job scheduling in large-scale parallel and distributed data processing systems.<br\/><br\/>This project will also facilitate the training of graduate students in the emerging area of energy-efficient data processing methods. The broader impacts of this proposal also include benefits to society by producing techniques that can potentially reduce the energy consumption of data centers, which in turn has beneficial environmental and economical effects. <br\/><br\/>This project is partially funded by the OCI CF21 Venture Fund for promoting the reuse of Cyberinfrastructure (CI) elements. <br\/><br\/>For further information, please see: http:\/\/pages.cs.wisc.edu\/~jignesh\/ecodb\/","title":"III: Medium: Energy-Efficient Data Processing","awardID":"0963993","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"6892","name":"CI REUSE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560467","533271"],"PO":["565136"]},"171933":{"abstract":"Abstract <br\/>The objective of this research is to develop advanced distributed monitoring and control systems for civil infrastructure. The approach uses a cyber-physical co-design of wireless sensor-actuator networks and structural monitoring and control algorithms. The unified cyber-physical system architecture and abstractions employ reusable middleware services to develop hierarchical structural monitoring and control systems. <br\/><br\/>The intellectual merit of this multi-disciplinary research includes (1) a unified middleware architecture and abstractions for hierarchical sensing and control; (2) a reusable middleware service library for hierarchical structural monitoring and control; (3) customizable time synchronization and synchronized sensing routines; (4) a holistic energy management scheme that maps structural monitoring and control onto a distributed wireless sensor-actuator architecture; (5) dynamic sensor and actuator activation strategies to optimize for the requirements of monitoring, computing, and control; and (6) deployment and empirical validation of structural health monitoring and control systems on representative lab structures and in-service multi-span bridges. While the system constitutes a case study, it will enable the development of general principles that would be applicable to a broad range of engineering cyber-physical systems. <br\/><br\/>This research will result in a reduction in the lifecycle costs and risks related to our civil infrastructure. The multi-disciplinary team will disseminate results throughout the international research community through open-source software and sensor board hardware. Education and outreach activities will be held in conjunction with the Asia-Pacific Summer School in Smart Structures Technology jointly hosted by the US, Japan, China, and Korea.","title":"CPS: Medium: Collaborative Research: Cyber-Physical Co-Design of Wireless Monitoring and Control for Civil Infrastructure","awardID":"1035748","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["501588"],"PO":["565274"]},"170613":{"abstract":"The ability to predict quantitatively how natural and engineered systems will behave is a critical element to the growth and advancement of technology. Such predictions are developed through the application of computers to mathematical models of the system of interest. All such systems are made of materials that are ultimately composed of countless molecules, but often it is not necessary to acknowledge this fact to make useful quantitative predictions. However, with the continued growth and sophistication of nanotechnology, the development of advanced materials, and the growing interest in extremes of application, recognition of the underlying role of molecules in producing physical behavior is indispensable for reliable and accurate predictions. The principles required to achieve this are well established in the laws of quantum mechanics, but the means to convert this understanding into predictions about macroscopic material behaviors is quite limited. Recent advances and trends in computer science and engineering present opportunities to remedy this situation. Two key developments are the advent of multicore processors and distributed computing in general and, apart from this, a focus on data-driven knowledge. Computationally-intensive methods must be reconsidered from the ground up to make real use of these advances in computer science. The promise of new computing technologies is not likely to be met without a more fundamental and radical reformulation of the basic computational approach. This project aims to contribute to these transformations. Future developments open up new avenues for experimental validation of first-principles computational chemistry methods (i.e., requiring no input from experiment), improving them and thereby technologies where they can be applied.<br\/><br\/>By supplying a route to fluid properties from first principles, this research provides an enabling technology across much of science and engineering while translating fundamental chemistry into applications via new cyber-approaches. Advances made in this project are expected to impact most directly chemical engineering, computational chemistry, and computer science, with a potentially broad array of secondary impacts in areas such as nanotechnology, materials science and engineering, geology, energy, atmospheric science and any other of the myriad fields that can benefit from the capability to predict and model material properties. The development of data-analysis schemes as part of this project can be extended and applied in unforeseen ways to other systems of discrete objects, and the computer-programming tools developed here aim to be sufficiently general to allow application to a diverse set of problems well beyond those that motivate this work. Additionally, education and outreach are promoted via a workshop for high-school students, and via distribution of new easy-to-use open-source software enabling others to apply the methods developed here in their own applications.<br\/><br\/>This is a Cyber-Enabled Discovery and Innovation Program award and is co-funded by the Division of Chemistry, the Office of Multidisciplinary Activities, the Directorate of Computer & Information Science and the Division of Chemical, Bioengineering, Environmental, and Transport Systems.","title":"CDI Type II: New cyber-enabled strategies to realize the promise of quantum chemistry as a far-reaching tool for engineering applications","awardID":"1027963","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"7751","name":"CDI TYPE II"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[456694,"510422","558152",456697],"PO":["563091"]},"170646":{"abstract":"This research creates an innovative method for visualizing and analyzing space-time dimensions of the spread of ideas through semantic webs represented in texts posted on the Internet and the Web pages. The project integrates geographic information systems (GIS), geographic information science (GIScience), computational linguistics (CL), and semantic web (computer-based ontology) technologies to track and analyze public-accessible websites for progressively more defined clusters of words and phrases that characterize actual and potentially developing networks of social processes. Human and natural crises (e.g., epidemics), and hostile social movements (e.g., militia and hate groups) are examined as illustrative exemplars of the utility of such an integrated system. Website pages and web contents with identified clusters of words or phrases will be mapped (by geo-referencing their web addresses, URL, place names, gazetteers, blogs, etc.) over a world map (using GIS tools) with time stamps. The resulting map provides a visual ?information landscape? consisting of hundreds of website locations (using real world coordinate systems) containing related keywords or similar ideas. When integrated with time-series analyses, this map allows the examination of the paths and speed of information dissemination, as well as the evolving varieties of various ideas and their relationships. By creating a Semantic Web Automatic Reasoning and Mapping System (SWARMS) prototype, researchers can visualize the spread of concepts, ideas and news over time and space. Clusters of keywords and phrases are identified and classified, and references to key ideas, provocative events, and important text sources are collected. This innovative methodology can be applied in multiple languages and other applications, such as cellular phone text messages and social network messages (such as twitter messages).<br\/><br\/>Intellectual Merit: This project forms a new multidisciplinary research framework in connecting social science and computer science for analyzing the dynamic information landscape on the Internet in which ideas spread quickly. By combining GIScience and geo-locating skills in a Web search mechanism, this project illustrates a new approach to information query, retrieval, and analysis methods. The creation of semantic knowledge bases upgrades traditional ?data mining? methods to advanced ?information mining? approaches. This research facilitates the development of space-time analysis methodology, a rapidly growing field in the context of the traditional separation between time series analysis and spatial analysis. The innovative semantic and spatiotemporal analysis framework provides a new direction for social science research to track the spread of ideas, to analyze where they go and how fast, and to analyze the ideological, social, and religious conditions that promote that spread. There are numerous current for- and non-profit organizations as well as government organizations that routinely monitor the web for various purposes. The unique aspect of this project, however, is that it brings together disparate academic disciplines not only to monitor the web, but also introduces a coherent methodological framework to analyze the spread of an idea and its impact through cyberspace.<br\/><br\/>Broader Impacts: This project helps to foster the integration of research and education in multiple disciplines, including geography, linguistics, political science, and communication. Four graduate students at SDSU are directly funded and trained through this project. Students across a variety of disciplines and curricula also directly benefit from this research project. This research provides an excellent opportunity to involve students from diverse backgrounds. San Diego State University is ranked number 8 in the nation for bachelor?s degrees awarded to Hispanics and number 11 for bachelor?s degrees awarded to all ethnic minorities, and was ranked number 22 in the nation for ethnic diversity by U. S. News and World Report in 2006. Given the makeup of the student body, this project features underrepresented groups in both graduate and undergraduate programs. The project website publicizes research findings to the general public and creates a discussion forum to involve multidiscipline researchers. Four Cyber-Discovery and Information Landscape workshops are planned to facilitate future multidisciplinary collaborations. This research improves understanding of the technical, psychological, and political mechanisms and conditions that facilitate the spread of certain ideas and provide a new direction for social science research.","title":"CDI-Type II: Mapping Cyberspace to Realspace: Visualizing and Understanding the Spatiotemporal Dynamics of Global Diffusion of Ideas and the Semantic Web","awardID":"1028177","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[456791,456792,456793,456794],"PO":["551712"]},"171912":{"abstract":"Abstract <br\/>The objective of this research is to develop advanced distributed monitoring and control systems for civil infrastructure. The approach uses a cyber-physical co-design of wireless sensor-actuator networks and structural monitoring and control algorithms. The unified cyber-physical system architecture and abstractions employ reusable middleware services to develop hierarchical structural monitoring and control systems. <br\/><br\/>The intellectual merit of this multi-disciplinary research includes (1) a unified middleware architecture and abstractions for hierarchical sensing and control; (2) a reusable middleware service library for hierarchical structural monitoring and control; (3) customizable time synchronization and synchronized sensing routines; (4) a holistic energy management scheme that maps structural monitoring and control onto a distributed wireless sensor-actuator architecture; (5) dynamic sensor and actuator activation strategies to optimize for the requirements of monitoring, computing, and control; and (6) deployment and empirical validation of structural health monitoring and control systems on representative lab structures and in-service multi-span bridges. While the system constitutes a case study, it will enable the development of general principles that would be applicable to a broad range of engineering cyber-physical systems. <br\/><br\/>This research will result in a reduction in the lifecycle costs and risks related to our civil infrastructure. The multi-disciplinary team will disseminate results throughout the international research community through open-source software and sensor board hardware. Education and outreach activities will be held in conjunction with the Asia-Pacific Summer School in Smart Structures Technology jointly hosted by the US, Japan, China, and Korea.","title":"CPS: Medium: Collaborative Research: Cyber-Physical Co-Design of Wireless Monitoring and Control for Civil Infrastructure","awardID":"1035562","effectiveDate":"2010-10-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["482862",460466],"PO":["565274"]},"171934":{"abstract":"Body Area Sensor Networks: A Holistic Approach from Silicon to Users <br\/>The objective of this research is to develop new principles and techniques for adaptive operation in highly dynamic physical environments, using miniaturized, energy-constrained devices. The approach is to use holistic cross-layer solutions that simultaneously address all aspects of the system, from low-level hardware design to higher-level communication and data fusion algorithms to top-level applications. In particular, this work focuses on body area sensor networks as emerging cyber-physical systems.<br\/>The intellectual merit includes producing new principles regarding how cyber systems must be designed in order to continually adapt and respond to rapidly changing physical environments, sensed data, and application contexts in an energy-efficient manner. New cross-layer technologies will be created that use a holistic bottom-up and top-down design -- from silicon to user and back again. A novel system-on-a-chip hardware platform will be designed and fabricated using three cutting-edge technologies to reduce the cost of communication and computation by several orders of magnitude.<br\/>The broad impact of this project will enable the wide range of applications and societal benefits promised by body area networks, including improving the quality and reducing the costs of healthcare. The technology will have broad implications for any cyber physical system that uses energy constrained wireless devices. A new seminar series will bring together experts from many fields (including domain experts, such as physicians and healthcare professionals). The key aspects of this work that deal with healthcare have the potential to attract women and minorities to the computer field.","title":"CPS: Medium: Collaborative Research: Body Area Sensor Networks: A Holistic Approach from Silicon to Users","awardID":"1035771","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550342","527785","485695","543576"],"PO":["565274"]},"170614":{"abstract":"Summary: Rapidly changing technologies of multi-modal communication, from the global reach of international satellite TV, the proliferation of Internet news outlets, to YouTube, are transforming the news industry. In parallel, ?citizen journalism? is on the rise, enabled by smart phones, social networks, and blogs. The Internet is becoming a vast information ecosystem driven by mediated events ? elections, social movements, natural disasters, disease epidemics ? with rich heterogeneous data: text, image, and video. Meanwhile, the tools and methodologies for users and researchers are not keeping pace: it remains prohibitively labor-intensive to systematically access and study the vast amount of emerging news data. <br\/><br\/>Leveraging UCLA's ongoing digital collection of 85,000 hours of news videos, including 8.1 billion image frames and 530 million words of closed captioning, the research team is developing a new computational paradigm for analyzing massive datasets of social and political news events: (i) Studying joint image-text parsing to categorize news by topics and events, and analyzing selection and presentation biases across networks and media spheres in a statistical and quantitative manner never before possible; (ii) Studying by joint image-text mining to reason the persuasion intents, and modeling the techniques of verbal and visual persuasions; (iii) Discovering spatio-temporal patterns in the interactions of multiple mediated events, and analyzing agenda setting patterns; and (iv) Developing an interactive multi-perspective news interface, vrNewsScape, for visualizing and interacting with our computational and statistical results. <br\/><br\/>Intellectual merit: This interdisciplinary project makes innovative contributions to three disciplines. Transforming social science research. The project develops a data-driven paradigm for transforming communication research in the social sciences. By enabling quantitative studies of massive visual datasets, the research team identifies and characterizes large-scale patterns of news mediation and persuasion currently inaccessible to researchers, due to the prohibitive cost of manual analysis. The research team goes beyond traditional object detection, segmentation, and recognition by studying framing and persuasion techniques in images, an untouched topic in computer vision. The team studies semantic associations and meanings for object and scene categories in their social context. Also, the team is studying image parsing to fill the semantic gap ? a long standing technical barrier in image retrieval, and will generate narrative text descriptions from the parse trees so that they can be fused with the input text and closed captioning for topic mining. <br\/><br\/>The research goes beyond conventional topic mining from text to perform integrative text-image mining, bias detection, and pattern discovery in the spatio-temporal evolution of mediated news events. The research detects and summarizes controversy and mine user-generated content for analyzing communicative intent and persuasive effects. <br\/><br\/>Broader impacts: vrNewsScape is being made publicly available to researchers and graduate students. Because the news media report on events in multiple different expert domains ? including congressional and presidential politics, international relations, war and public uprisings, natural disasters and humanitarian aid missions, disease epidemics and health initiatives, criminal activity and court cases, celebrities and cultural events ? the analytical tools in development are not limited to a particular research domain in social, political and computer sciences, but permit for the first time a systematic and quantitative examination of the massive datasets required to understand today?s mediated society. <br\/><br\/>In education, the project extends UCLA?s Digital Civic Learning initiative (dcl.sscnet.ucla.edu), a program involving college and high-school students in the analysis of news, thus delivering education benefits to potentially a huge number of students nationwide in Communication Studies (in 2004, 433,000 college students were enrolled in Communication and Journalism and 209,000 in Political Science[153]), exposing them to a new generation of high-level tools for handling multimodal data and inspiring them to pursue computational thinking, in line with the NSF?s objectives.","title":"CDI-Type II: Collaborative Research: Joint Image-Text Parsing and Reasoning for Analyzing Social and Political News Events","awardID":"1027965","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[456699],"PO":["564359"]},"171924":{"abstract":"The objective of this research is to develop new foundations of composition in heterogeneous systems, to apply these foundations in a new generation of tools for system integration, and to validate the results in experiments using automotive and avionics System-of-Systems experimental platforms. The approach is to exploit simplification strategies: to develop theories, methods, and tools to assist in inter-layer decoupling.<br\/>Intellectual merit. The research program has three focus areas: (1) theory of compositionality in heterogeneous systems, (2) tools and tool architectures for system integration, and (3) systems\/experimental research. The project develops and deploys theories and methods for inter-layer decoupling that prevent or decrease the formation of intractable system-wide interdependences and maintain compositionality at each layer for carefully selected, essential system properties. Compositionality in tools is sought by exploring semantic foundations for model-based design. Systems\/experimental research is conducted in collaboration with General Motors Global R&D (GM) and focuses on electric car platforms. <br\/>Broader impact. The project is contributing to the cost effective development and deployment of many safety and security-critical cyber-physical systems, ranging from medical devices to transportation, to defense and avionics. The participating institutions seek to complement the 30-year-old conventional curriculum in systems science with one that admits computation as a primary concept. The curriculum changes will be aggressively promoted through a process of workshops and textbook preparation.","title":"CPS: Large: Science of Integration for Cyber-Physical Systems","awardID":"1035655","effectiveDate":"2010-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[460500,460501,"553550","533198","564429"],"PO":["564778"]},"171935":{"abstract":"Abstract <br\/>The objective of this research is to develop advanced distributed monitoring and control systems for civil infrastructure. The approach uses a cyber-physical co-design of wireless sensor-actuator networks and structural monitoring and control algorithms. The unified cyber-physical system architecture and abstractions employ reusable middleware services to develop hierarchical structural monitoring and control systems. <br\/><br\/>The intellectual merit of this multi-disciplinary research includes (1) a unified middleware architecture and abstractions for hierarchical sensing and control; (2) a reusable middleware service library for hierarchical structural monitoring and control; (3) customizable time synchronization and synchronized sensing routines; (4) a holistic energy management scheme that maps structural monitoring and control onto a distributed wireless sensor-actuator architecture; (5) dynamic sensor and actuator activation strategies to optimize for the requirements of monitoring, computing, and control; and (6) deployment and empirical validation of structural health monitoring and control systems on representative lab structures and in-service multi-span bridges. While the system constitutes a case study, it will enable the development of general principles that would be applicable to a broad range of engineering cyber-physical systems. <br\/><br\/>This research will result in a reduction in the lifecycle costs and risks related to our civil infrastructure. The multi-disciplinary team will disseminate results throughout the international research community through open-source software and sensor board hardware. Education and outreach activities will be held in conjunction with the Asia-Pacific Summer School in Smart Structures Technology jointly hosted by the US, Japan, China, and Korea.","title":"CPS: Medium: Collaborative Research: Cyber-Physical Co-Design of Wireless Monitoring and Control for Civil Infrastructure","awardID":"1035773","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560533"],"PO":["565274"]},"170505":{"abstract":"Since early 1990s, with the advancement of machine learning methods and the availability of data resources such as treebanks and parallel corpora, data-driven approaches to Natural Language Processing (NLP) have made significant progress. The success of such data-driven approaches has cast doubt on the relevance of linguistics to NLP. Conversely, NLP techniques are rarely used to help linguistics studies. The goal of this NSF-sponsored workshop is to carefully examine the relationship between linguistics and NLP and determine how incorporating linguistic knowledge into NLP systems can advance the state of the art of NLP and how NLP can assist linguistic studies through automatic collection and analysis of linguistic data.<br\/><br\/> The workshop will bring together researchers from linguistics and NLP with diverse interests in and across both disciplines. The workshop is held in conjunction with ACL on July 16, 2010 in Sweden. This award provides financial support that allows the workshop to attract top researchers in the US to attend the workshop in Sweden, and the support is crucial especially for linguists who normally do not attend ACL.<br\/><br\/> This workshop is intended to begin collaboration between linguists and NLP researchers that will continue long after the workshop has finished. The ultimate goals of the workshop and follow-up events are to accelerate work in NLP by bringing in important knowledge and information from linguistics, and to open the eyes of NLP researchers to the challenges within the field of linguistics that could benefit from cutting-edge, state-of-the-art NLP.<br\/>The cross pollination between the disciplines can only push both forward and in directions that otherwise would come much later or not at all.","title":"Workshop on NLP and Linguistics: finding the common ground","awardID":"1027289","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}}],"PIcoPI":["507284"],"PO":["565215"]},"172817":{"abstract":"Participation in authentic research projects can be a powerful way to engage students in science and introduce them to the computational tools that are used in science research. However, finding an authentic project in which students can participate is time consuming for educators, both in terms of finding an appropriate project and preparing curriculum to support its use in the classroom. Citizen science ? the involvement of non-professionals in the research enterprise ? has been successfully adapted to the classroom by programs such as Cornell University?s Lab of Ornithology. Current efforts across citizen science projects tend to be focused on students reporting back fieldwork or stop at providing subject area lesson plans that relate to the topic of the research study. Thus, they do not have a strong connection to the subsequent analysis conducted by the researchers: there is no introduction to the significant computational tools that are used by scientists after students contribute data to arrive at research results. Additionally, the lesson plans are generally developed as part of the setup of the project, and have no sustainable way to continue expanding or be applied to new projects without additional influx of funding. In collaboration with the Adler, the Zooniverse Citizen Science Alliance has developed a framework called ZooTeach to support educators in the development and sharing of classroom curriculum, which can be easily implemented across Zooniverse research projects. The team in this demonstration project is first to refining the existing ZooTeach resource, seeding with pilot resources, expanding, and disseminating this framework with and to formal and informal educators. In doing so, the team is developing a set of best practices for how citizen science projects can be used in the classroom to encourage exploration of computing in an authentic science workforce context. <br\/><br\/><br\/>Intellectual Merit<br\/>The Adler team is led by Nancy Ross Dribin, director of interactive media, in collaboration with the Adler education department and Dr. Chris Lintott, director of citizen science initiatives and founding member of the Zooniverse. An advisory board of seven people, including a mix of leading figures in Chicago Public Schools, educational technology, and computational science instruction, inform the project. <br\/>With the successful completion of this project, the Adler will: <br\/>? Evaluate and refine the existing ZooTeach structure to ensure that it supports and encourages educator use. Expected outcomes include both visiting to find resources and contributing to resource development as direct authors as well as reviewers. Working with educators to provide such an environment will provide valuable information to projects looking to encourage educator-contributed materials. <br\/>? Create an interactive to support the use of the Zoos as an introduction to the use of computational tools in science research. By supporting non-project educators as the primary contributors of curriculum, this opens the possibility of using future funding to create more specific, complex resources that facilitate connecting the citizen science task completed by students and the computational tools and analysis conducted by the team scientists. <br\/><br\/>Broader Impacts<br\/>This project will:<br\/>? Promote use of Zoo Teach at appropriate formal and informal educator conferences and in professional development at the Adler. In addition to encouraging use of Zoo Teach by educators and in informal education professional development programs, this will also enable team members to disseminate project findings to peers. <br\/>? Evaluate the effectiveness of an open, contributory approach to lesson plan development in relation to citizen science projects. As noted above, this evaluation will be disseminated via conferences as well as via the Adler?s website and via electronic communications with peers. It will provide valuable information about the effectiveness of and best practices for following this approach.","title":"Citizen CI-TEAM Demonstration Project - Expanding the Zooniverse: Refining Resources to Support Educator Use of Citizen Science in the Classroom","awardID":"1041419","effectiveDate":"2010-10-01","expirationDate":"2014-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7477","name":"CI-TEAM"}}],"PIcoPI":[463460,463461,"494978"],"PO":["565272"]},"171938":{"abstract":"The objective of this research is to study, develop and implement a comprehensive set of techniques that will eventually enable automobiles to be driven autonomously. The approach taken is to (a) address cyber-physical challenges of reliable, safe and timely operations inside the automobile, (b) tackle a range of physical conditions and uncertainties in the external environment, (c) enable real-time communications to and from the automobile to other vehicles and the infrastructure, and (d) study verification and validation technologies to ensure correct implementations.<br\/><br\/>Intellectual Merits: The project seeks to make basic research contributions in the domains of safety-critical real-time fault-tolerant distributed cyber-physical platforms, end-to-end resource management, cooperative vehicular networks, cyber-physical system modeling and analysis tools, dynamic object detection\/recognition, hybrid systems verification, safe dynamic behaviors under constantly changing operating conditions, and real-time perception and planning algorithms. Multiple intermediate capabilities in the form of active safety features will also be enabled. <br\/><br\/>Broader Impacts: Automotive accidents result in about 40,000 fatalities and 3 million injuries every year in the USA. The global annual cost of road injuries is $518 billion. Many accidents are due to humans being distracted. Autonomous vehicles controlled by ever-vigilant cyber-physical systems can lead to significant declines in accidents, deaths and injuries. Autonomous vehicles can also offload driving chores from humans, and make time spent in automobiles more productive. Vehicular networks can help find the best possible routes to a destination in real-time. Broader impacts in this area are amplified by the project's partnerships with companies in the transportation and agricultural technology industries, and in information technology. Broader impacts are also sought through demonstrations and outreach to attract students into science and technology, and in particular to cyber-physical systems research.","title":"CPS: Large: Center for Autonomous Transportation Systems","awardID":"1035813","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["489879","513331",460554,460555,"461012"],"PO":["565274"]},"171949":{"abstract":"The objective of this research is to check correct functioning of cyber-physical systems during their operation. The approach is to continuously monitor the system and raise an alarm when the system seems to exhibit an erroneous behavior. Correct functioning of cyber-physical systems is of critical importance. This is more so in safety critical systems like medical, automotive and other applications.<br\/><br\/>The approach employs hybrid automata for specifying the property to be monitored and for modeling the system behavior. The system behavior is probabilistic in nature due to noise and other factors. Monitoring such systems is challenging since the monitor can only observe system outputs, but not it's state. Fundamental research, on defining and detecting whether a system is monitorable, is the focus of the work. The project proposes accuracy measures and cost based metrics for optimal monitoring. The project is developing efficient and effective monitoring techniques, based on product automata and Partially Observable Markov Decision Processes. The results of the project are expected to be transformative in ensuring correct operation of systems.<br\/><br\/>The results will have impact in many areas of societal importance and utility for daily life, such as health care, nursing\/rehabilitation, automotive systems, home appliances, and more. The benefits in nursing\/rehabilitation emanate from the deployment of advanced technologies to assist caregivers. This can lead to improved health and quality of life of older patients at reduced costs. The project includes education and outreach in the form of K-12 outreach and involvement of undergraduate and graduate students in research. The project is committed to involving women and minorities in education and research.","title":"CPS: Small: Monitoring Techniques for Safety Critical Cyber-Physical Systems","awardID":"1035914","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550555",460591],"PO":["564778"]},"171928":{"abstract":"The objective of this research is to establish a new development paradigm that enables the effective design, implementation, and certification of medical device cyber-physical systems. The approach is to pursue the following research directions: 1) to support medical device interconnectivity and interoperability with network-enabled control; 2) to apply coordination between medical devices to support emerging clinical scenarios; 3) to ?close the loop? and enable feedback about the condition of the patient to the devices delivering therapy; and 4) to assure safety and effectiveness of interoperating medical devices.<br\/>The intellectual merits of the project are 1) foundations for rigorous development, which include formalization of clinical scenarios, operational procedures, and architectures of medical device systems, as well as patient and caregiver modeling; 2) high-confidence software development for medical device systems that includes the safe and effective composition of clinical scenarios and devices into a dynamically assembled system; 3) validation and certification of medical device cyber-physical systems; and 4) education of the next-generation of medical device system developers who must be literate in both computational and physical aspects of devices.<br\/>The broader impacts of the project will be achieved in three ways. Novel design methods and certification techniques will significantly improve patient safety. The introduction of closed-loop scenarios into clinical practice will reduce the burden that caregivers are currently facing and will have the potential of reducing the overall costs of health care. Finally, the educational efforts and outreach activities will increase awareness of careers in the area of medical device systems and help attract women and under-represented minorities to the field.","title":"CPS: Large: Assuring the Safety, Security and Reliability of Medical Device Cyber Physical Systems","awardID":"1035715","effectiveDate":"2010-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[460517,"497082","526896","553656","553657"],"PO":["565274"]},"159192":{"abstract":"This project is a three-year effort to support participation in the 2010 and 2012 Copper Mountain Conferences on Iterative Methods and the 2011 Copper Mountain Conference on Multigrid Methods. The funding in this award is specifically intended to support the participation of students, women, and minority scientists. The Copper Mountain Conferences have graduate students forming a very large fraction of the attendees (typically 30%-40%), many of them full participants who co-author papers and give presentations. Women and minorities are growing fractions of the attendees (e.g., 27 of 49 students participating in 2008 were women); this award funding is targeted to further enhance their proportions. Support for the students, women, and minority scientists from this award is in the form of reduced registration fees, travel support, and subsidized meals and lodging. The funding also supports a \"Student Paper Competition\", which draws entries from a significant fraction of the student attendees and results in extraordinarily high-quality papers on scientific discovery from the students, working in tandem with and under the guidance of their faculty advisors. These results, like the conferences as a whole, span wideranging and important theoretical and applications areas, such as techniques of convergence analysis, implementation and development of mathematical software, and use of such ideas in novel settings, including advanced computer architectures and new applications such as uncertainty quantification.<br\/><br\/>The Copper Mountain Conference series form arguably the premier conferences in two closely related mathematical fields: iterative and multigrid methods. These two fields provide computational support for numerical simulation of a very wide host of endeavors, including environmental and energy research, medical and biological applications, and many other areas critical to the U. S. and international science and engineering community. This award supports the participation of students, women, and minority scientists at those Conferences. The Conferences? traditionally work to ensure the future vitality of the fields of iterative and multigrid methods by facilitating development and nurturing of a community of capable graduate students and entry-level scientists. Through their egalitarian structure, with no invited speakers and all talks of equal length, the Conferences provide mechanisms for young people to meet each other and all participants in a relaxed yet scientifically rigorous setting; these mechanisms include topical tutorials, themed evening workshops, and access to the broad representation of participants from academia, national laboratories, and industry. The Conferences have a tradition of a very high level of student participation (typically 30-40% of attendees), and will cultivate this through supporting students' local and travel expenses. An emphasis is placed on engendering diversity through support of women and minority scientists. These conferences bring together the world?s leading practitioners in these critical fields and result in high-level publications, effective applications codes, and the establishment of longterm collaborative research partnerships.","title":"Special Meeting at Copper Mountain on Multigrid and Iterative Methods","awardID":"0939995","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":[425580],"PO":["565027"]},"170908":{"abstract":"The world as we know it will be transformed by climate change with one-third of known species threatened with extinction, diseases projected to emerge in new areas, disruption of the ecosystems that provide our food and water, and urban environments at increased risk from rising sea levels. To diminish the negative impact of impending climate change, various strategies are being investigated, including societal ?adaptation? to increase eco-system tolerance. Climate change adaptation can include activities like managed relocation of species (like armadillos in Indiana), building habitat corridors to allow species to move into newly appropriate habitat, maintaining engendered species in zoos and botanic gardens, growing genetically modified drought-resist crops in newly dry regions, planting non-native trees to maximize carbon sequestration, or constructing large-scale levees to protect low-lying coastal areas like Manhattan. Relatively little is known about the conditions under which climate change adaptation activities can be successful or about their potentially disastrous side effects. Addressing this problem raises fundamental questions about the relationship of humans to natural systems that transcend disciplinary boundaries. <br\/><br\/>Increasingly, policymakers recognize that evaluation of adaptation strategies must be integrative and interdisciplinary, informed by expertise in environmental science, law, engineering, and other disciplines. Adaptation to climate change necessitates an unprecedented mobilization, coordination and integration of data, information, and knowledge, enabled by emerging technologies and cyberinfrastructure. This award creates a climate adaptation virtual organization linking people and shared resources to enable informed decision-making and novel research. The Collaboratory for Adaptation to Climate Change relies on cyber infrastructure, data management, and computational algorithms including tools to generate ecological projections, survey data on expert opinion, an information clearing house on regulation related to adaptation, interactive mapping with geographic information systems, mining of social media on the issue of climate change, and data mining algorithms that integrate these elements to create forecasts under uncertainty. The Collaboratory promises to be transformative in its inter-disciplinary integration and will lead the science of adaptation to climate change. The ultimate goal is to make the Collaboratory a onestop-shop that encompasses multiple dimensions of climate change adaptation.","title":"CDI-TYPE II: Building and studying a virtual organization for adaptation to climate change","awardID":"1029584","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[457539,"559182",457541,"537738","528568"],"PO":["565342"]},"167140":{"abstract":"The cortex consists of two major cell types: neurons and glia. Most research in cortical function has focused primarily on the role of neurons in signal processing. Glial cells, including astrocytes, have been considered as secondary actors in brain function, providing physical and metabolic support to neurons. In primary visual cortex (V1), precise neuronal responses and representations are considered to anchor visual processing. However, astrocytes contact synapses as well as blood vessels, and recent evidence suggests that astrocytes receive synaptic inputs and influence neuronal as well as vascular responses. The accumulated results of the past decade have led to the ?tripartite synapse? concept, in which excitatory synapses in cortex are composed of a presynaptic, a postsynaptic, and an astrocytic element. An over-arching and novel theme of this proposal is that astrocytes partner with neurons in synaptic transmission and plasticity. Any complete framework for understanding and modeling the network basis of cortical responses must account for both astrocytic and neuronal contributions. The goal of this proposal is to combine experimental and computational modeling approaches to understand the role astrocytes play in the generation, development and plasticity of neuronal responses in visual cortex.<br\/><br\/>Many aspects of astrocyte biology and physiology have been described in vitro, but little is known about the role of astrocytes in the context of intact functional circuits. This project will utilize novel experimental approaches, including specific cellular markers, optical probes of cellular function, and genetically engineered mice with optical reporters, that provide new ways to examine the cooperative roles of neurons and astrocytes in visual cortex responses and representations. The US laboratory of Mriganka Sur has pioneered the use of these approaches, in combination with in vivo two-photon calcium imaging of cells, optical imaging of intrinsic signals, and electrophysiological recording, to study the influence of astrocytes on visual processing. The modeling portion of this project will develop the first network models of visual cortex to include astrocyte influences on synaptic transmission, in addition to neuronal excitation and inhibition. The German laboratory of Klaus Obermayer has made seminal contributions to a computational understanding of how visual cortex networks generate, develop and alter emergent responses. Previous joint efforts of the Sur and Obermayer groups have been influential in revealing operating regimes of visual cortex networks, the influence of map structure on cortical network function, and the dynamics of feature-selective responses. In each instance, computational models influenced experiments, and vice versa.<br\/><br\/>This project is jointly funded by Collaborative Research in Computational Neuroscience and the Office of International Science and Engineering. A companion project is being funded by the German Ministry of Education and Research (BMBF).","title":"CRCNS: US-German Collaboration: Role of Astrocytes in Cortical Information Processing","awardID":"1010363","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[447681],"PO":["564318"]},"177030":{"abstract":"The goal of this project is to develop a semantic foundation, cross-layer system architecture and adaptation services to improve dependability in instrumented cyberphysical spaces (ICPS) based on the principles of \"computation reflection\". ICPSs integrate a variety of sensing devices to create a digital representation of the evolving physical world and its processes for use by applications such as critical infrastructure monitoring, surveillance and incident-site emergency response. This requires the underlying systems to be dependable despite disruptions caused by failures in sensing, communications, and computation. The digital state representation guides a range of adaptations at different layers of the ICPS (i.e. networking, sensing, applications, cross-layer) to achieve end-to-end dependability at both the infrastructure and information levels. Examples of techniques explored include mechanisms for reliable information delivery over multi-networks, quality aware data collection, semantic sensing and reconfiguration using overlapping capabilities of heterogeneous sensors. Such adaptations are driven by a formal-methods based runtime analysis of system components, resource availability and application dependability needs. Responsphere, a real-world ICPS infrastructure on the University of California at Irvine campus, will serve as a testbed for development and validation of the overall ?reflective? approach and the cross-layer adaptation techniques to achieve dependability. Students at different levels (graduate, undergraduate, K-12) will be given opportunities to gain experience with using and designing real-world applications in the Responsphere ICPS via courses, independent study projects and demonstration sessions. Students will benefit tremendously from exposure to new software development paradigms for the ICPSs that will be a part of the future living environments.","title":"CPS: Medium: Collaborative Research: Dependability Techniques for Instrumented Cyber-Physical Spaces","awardID":"1063596","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["541836","515756","499298"],"PO":["565239"]},"168582":{"abstract":"Interference is a fundamental feature of the wireless medium and a major performance bottleneck in the engineering of wireless networks. However, the broadcast nature of the wireless medium which manifests itself in the form of interference can also be a benefit in disguise. It allows multiple nodes to receive a common signal and generates the potential for cooperation. Much of the fundamental research effort on the broadcast aspect so far has addressed these two aspects (interference and cooperation) separately. This project studies interference management and cooperation in a common context and a holistic manner.<br\/><br\/>The research conducted in this effort (a) looks for novel communication strategies that harness the broadcast advantage while minimizing its interfering nature; (b) looks to identify engineering contexts where the novel communication strategies provide the most gain over traditional approaches; and (c) looks to characterize novel fundamental outer bounds (beyond the cut-set ones) to rates of reliable network communication where cooperation and interference coexist. These goals are addressed by starting out with simple (but canonical) models of wireless networks featuring two unicast traffic under three formulations that cover a wide range of issues in wireless networks: (i) cooperative networks such as cellular networks, (ii) competitive networks or networks with restricted cooperation such as Wi-Fi, and(iii) heterogenous networks involving cognitive radios.","title":"CIF: Small: Cooperative Interference Management-A Fundamental Study","awardID":"1017430","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["523699"],"PO":["564924"]},"177031":{"abstract":"The goal of this project is to develop a semantic foundation, cross-layer system architecture and adaptation services to improve dependability in instrumented cyberphysical spaces (ICPS) based on the principles of \"computation reflection\". ICPSs integrate a variety of sensing devices to create a digital representation of the evolving physical world and its processes for use by applications such as critical infrastructure monitoring, surveillance and incident-site emergency response. This requires the underlying systems to be dependable despite disruptions caused by failures in sensing, communications, and computation. The digital state representation guides a range of adaptations at different layers of the ICPS (i.e. networking, sensing, applications, cross-layer) to achieve end-to-end dependability at both the infrastructure and information levels. Examples of techniques explored include mechanisms for reliable information delivery over multi-networks, quality aware data collection, semantic sensing and reconfiguration using overlapping capabilities of heterogeneous sensors. Such adaptations are driven by a formal-methods based runtime analysis of system components, resource availability and application dependability needs. Responsphere, a real-world ICPS infrastructure on the University of California at Irvine campus, will serve as a testbed for development and validation of the overall ?reflective? approach and the cross-layer adaptation techniques to achieve dependability. Students at different levels (graduate, undergraduate, K-12) will be given opportunities to gain experience with using and designing real-world applications in the Responsphere ICPS via courses, independent study projects and demonstration sessions. Students will benefit tremendously from exposure to new software development paradigms for the ICPSs that will be a part of the future living environments.","title":"CPS: Medium: Collaborative Research: Dependability Techniques for Instrumented Cyber-Physical Spaces","awardID":"1063597","effectiveDate":"2010-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[474612,474613],"PO":["565239"]},"168760":{"abstract":"Systematic methodologies for the design of distributed and implementable routing and scheduling algorithms that enable one to design, provision and manage mobile wireless networks with predictable and controllable performance are lacking. The research project provides a new framework for modular cross-layer design of scheduling and routing algorithms for ad-hoc networks.<br\/><br\/>Clique based methods are used for scheduling, where cliques are defined in the interference graph. Clique based policies are developed to achieve optimal throughput and as basis for distributed implementable algorithms for scheduling. Clique based scheduling is easier and more flexible and provides a pathway to extend Network Calculus results, to provide deterministic performance bounds for wireless networks. For the routing, a component based design model is used that divides the routing protocol into components with separate design concerns. Stability, agility and flexibility are better achieved through a component based architecture. These solutions are still cross-layer, but they have well defined interfaces for signaling, control and information exchange between components and layers. Performance models provide a systematic methodology to study and quantify the relationship and sensitivity of the network performance to its components parameters. <br\/><br\/>The research will yield new principles and fundamental methodologies for the design, performance evaluation, and control of multi-hop wireless networks. Research results will be incorporated in communication, optimization and design courses at the graduate level. The results will be disseminated to industry and Government Labs. Validation and testing will be accomplished via emulation and real life wireless network testbeds in collaboration with industry and Government Labs.","title":"NeTS: Small: Component Based Routing and Clique Based Scheduling for Modular Cross-layer Design of Mobile Ad-hoc Networks","awardID":"1018346","effectiveDate":"2010-10-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["460501",451686],"PO":["557315"]},"168573":{"abstract":"Routing is one of the most important algorithmic problems in networking. Traditional routing is done by constructing routing tables via routing protocols. Such a solution is space inefficient and it requires considerable setup overhead, which makes it infeasible for some networks such as wireless sensor networks. Recently, geometric routing has been proposed as an alternative approach. Geometric routing often uses virtual coordinates of the nodes to compute routing paths. The virtual coordinates of the vertices are computed by running graph drawing algorithms on them. The simplest geometric routing is greedy routing, in which a vertex simply forwards messages to a neighbor that is closer to the destination. The first problem for greedy routing is its theoretical applicability. In order for greedy routing to always succeed, for every pair of vertices u and v in the network, there must be a distance-decreasing path from u to v. Unfortunately, not every graph can be drawn so that distance-decreasing paths exist between every pair of vertices. The second problem for greedy routing is its practical feasibility: the virtual coordinates in a greedy drawing have to be succinct. The combination of the two problems is a significant hurdle for the applicability of greedy routing. The aim of this project is to tackle these greedy routing problems by introducing and studying a new notion of graph drawing: k-geometric embedding, in which each node of a network can be mapped into up to k virtual locations in the target metric space. For two nodes u and v in the network, the smallest distance among all their virtual locations is defined as the distance of these two nodes. In particular, this project will study k-greedy drawing, which is defined to be a k-geometric embedding in which distance-decreasing paths always exist.<br\/><br\/>The intellectual merits of this research include the following: (i) the new concepts will open a new area of graph drawing and strengthen the connection between graph drawing and network routing; (ii) the theory developed will make greedy routing feasible for more kinds of networks. Consequently, greedy routing may become a truly practical alternative. The broader impacts of this research include the following: (i) the results obtained from this research will have impact on graph theory, graph drawing, and geometric routing, especially greedy routing; (ii) the research results will be incorporated into computer science education.","title":"AF: Smal: k-Greedy Drawing of Graphs and Their Applications","awardID":"1017366","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[451236],"PO":["565157"]},"168133":{"abstract":"Low-density parity-check (LDPC) codes are currently recognized as the most promising coding technique to achieve the ultimate limits of robust communications over noisy channels. LDPC codes devised by the PIs have been selected by NASA for various applications and adopted for the 10G Base-T Ethernet. However, there are many challenges before LDPC codes become universal in applications. In particular, there is a need for a mathematical framework to determine the properties of the constructed codes for easy encoder and decoder implementations. Furthermore, it has been observed that the dramatic improvement in code performance as the channel improves comes to a sudden halt at some point. This phenomenon, known as error-floor, may preclude LDPC codes from applications requiring very low error rates, such as high-speed satellite communication and high-density data storage systems. Another challenge is the computational complexity needed to retrieve the correct data after being corrupted with noise. This research addresses these three challenges.<br\/><br\/>The research develops methods to study the relevant properties of efficiently encodable and decodable LDPC codes that ensure good performance when decoding using iterative algorithms. The research also develops an efficient decoding algorithm using a backtracking technique to lower the error-floors of LDPC codes due to trapping sets. This decoding technique removes the obstacles for applications of LDPC codes in communication and storage systems where very low error rates are required. Furthermore, the research also proposes a novel and computationally efficient reliability-based iterative algorithm for decoding non-binary LDPC codes for correcting combinations of random and bursts of errors. This decoding technique requires only integer and finite field operations and offers an effective trade-off between performance and decoding complexity.","title":"CIF: Small: Theory and Structure of Quasi-Cyclic LDPC Codes and Algorithms to Lower the Error Floor and Decode Non-Binary LDPC Codes","awardID":"1015548","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[450215,450216],"PO":["564924"]},"176351":{"abstract":"Effective response and adaptation to the physical world, and rigorous management of such behaviors through programmable computational means, are mandatory features of cyber physical systems (CPS). However, achieving such capabilities across diverse application requirements surpasses the current state of the art in system platforms and tools. Current computational platforms and tools often treat physical properties individually and in isolation from other cyber and physical attributes. They do not adequately support the expression, integration, and enforcement of system properties that span cyber and physical domains. This results in inefficient use of both cyber and physical resources, and in lower system effectiveness overall. <br\/><br\/>This work investigates novel approaches to these important problems, based on modularizing and integrating diverse cyber-physical concerns that cross-cut physical, hardware, instruction set, kernel, library, and application abstractions. The three major thrusts of this research are 1) establishing foundational models for expressing, analyzing, enforcing, and measuring different conjoined cyber-physical properties, 2) conducting a fundamental re-examination of system development tools and platforms to identify how different application concerns that cut across them can be modularized as cyber-physical system aspects, and 3) developing prototype demonstrations of our results to evaluate further those advances in the state of the art in aspect-oriented techniques for CPS, to help assess the feasibility of broader application of the approach. The broader impact of this work will be through dissemination of academic papers, and open platforms and tools that afford unprecedented integration of cyber-physical properties.","title":"EAGER: Collaborative Research: Seamless Integration of Conjoined Cyber-Physical System Properties","awardID":"1060337","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["502125",472681],"PO":["565239"]},"168354":{"abstract":"This project is exploring how overlay networks can be designed and engineered to meet the demanding performance requirements of real-time distributed applications such as large-scale virtual worlds and distributed cyber-physical systems. These applications are characterized by sessions with large numbers of distributed endpoints that issue regular status reports that must be delivered to a dynamically changing set of recipients. They require non-stop data delivery, even as the communication pattern changes. We address this requirement using a novel communication primitive called a comtree that functions like a per-session private network that is provisioned to support continuous data delivery in the presence of rapidly changing traffic. Each comtree defines its own routing context, enabling simple and scalable routing for both unicast and multicast packets. Multicast groups can be highly dynamic with each endpoint subscribing to tens or hundreds of multicast groups and changing their subscriptions many times per second. Our provisioning methods ensure that each comtree has sufficient capacity to support its traffic, even in the presence of rapidly changing multicast groups. The methods developed in this project will enable large-scale, highly interactive virtual worlds that are better able to support social interaction and group collaboration applications in business and education.","title":"NeTS: Small:Performance-Engineered Overlay Networks for Real-time Distributed Applications","awardID":"1016356","effectiveDate":"2010-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["522381"],"PO":["564993"]},"177066":{"abstract":"In this EAGER project, the University of Arkansas at Pine Bluff is carrying out a preliminary investigation into automatic intrusion detection and response for cyberinfrastructure-oriented systems. The aim of the project is to develop an extendable framework to automatically evaluate, measure, and rate security threats, i.e. intrusions within complex network systems linked together via cyberspace using software and hardware. The cyberinfrastructure consists of computing systems, data storage systems, data repositories and advanced instruments, and visualization environments, linked together by software and advanced networks to improve scientific productivity and enable breakthroughs not otherwise possible. The framework will be designed to operate as an active\/programmable component of existing systems that will be automated, dynamic and adaptive. In addition, the project will use intrusion data from the University of Arkansas at Little Rock, Center for Excellence for Assurance, Security, and Software Usability, Research, and Education (ASSURE) to construct visual representations of intrusion behavior patterns and predictive models to forecast future attacks on such systems. The project is a targeted exploratory project that is novel, and has potentially significant value for the computer\/network security, and information assurance communities within five core areas as they relate to cyberinfrastructure resourcesSecurity: (1) developing a unifying quantitative system for intrusions within cyberinfrastructureoriented systems (2) developing mechanisms to automatically appraise intrusions within cyberinfrastructure-oriented systems (3) developing security visualization models to represent intrusions within cyberinfrastructure-oriented systems to allow for the classification, and categorization of intrusion types, (4) expanding the expertise of faculty members at teaching oriented universities within the domain of cyberinfrastructure security (5) expanding the community of students exposed to cyberinfrastructure security concepts, theories, practices, and principles.<br\/><br\/>Intellectual Merit<br\/>The intellectual merit of the proposed AIDR-COS project is to carve out a flexible security framework to examine intrusions within cyberinfrastructure-oriented systems. The project involves a number of unique interdisciplinary research issues such as identification of intrusion types within cyberinfrastructure-oriented systems, adaptive intrusion classification structures, dynamically generated solutions, and a unique quantitative measurement process. In addition, to the development of autonomous mechanisms based on automatic intrusion detection, response models to enable autonomous system adjustments depending on intrusion classes.<br\/><br\/>Broader Impacts<br\/>The broader impacts of this project include: (1) new collaborations to expand the research\/education community within the domain of cyberinfrastructure security, to include greater numbers of historically underrepresented minorities, and teaching-oriented universities, (2) expanding the ability of organizations to integrate in proven security solutions that harness<br\/> available resources, thus extending the return on investment of the existing computing infrastructure and easing the integration of evolving cyberinfrastructure systems, (3) improving the ability of security engineers to develop security solutions for non-monolithic<br\/>cyberinfrastructure systems, (4) developing avenues for sharing knowledge and resources as innovation takes place within the domain of cyberinfrastructure security as it relates to automatic intrusion detection and classification, and cyber security.","title":"Automatic Intrusion Detection and Response system for Cyberinfrastructure-Oriented Systems (AIDR-COS)","awardID":"1063831","effectiveDate":"2010-10-15","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[474701,474702],"PO":["564181"]}}