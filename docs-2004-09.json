{"94517":{"abstract":"This research aims at developing novel models and methodologies for designing high performance, low cost real-time control systems. Using a networked control system as the target application, the project emphasizes an integrated treatment of control and real-time system development. The main focus of this work is on scheduling approaches for dealing with uncertainty and flexibility presented in many real-time control applications. Research activities for dealing with uncertainty includes the design of adaptive scheduling strategies to enforce a Markov-Chain based constraint and the evaluation of different schedulers. To maximally exploit flexibility existing in real-time control systems, the project investigates the effect of quantization on closed-loop system performance, and devises adaptive scheduling strategies to achieve the desired system performance while reducing resource demands.<br\/><br\/>The collaborative effort by the team of control and real-time system researchers provides unique opportunities for introducing new concepts and perspectives in tackling many challenges that are inherently interdisciplinary. The goal of the project is to advance understanding of the interplay between control system design and real-time system design.<br\/><br\/>The broader impacts of this project can be felt in two main aspects. First, as an integrated part of the project, a new course is being developed at the graduate\/senior undergraduate level to expose students to both the theory and the practice of designing embedded real-time control systems. The project is expected also to have impact through a collaboration in real-time control and civil engineering, in conjunction with Notre Dame's Center for Environmental Science and Technology (CEST).","title":"Flexible Scheduling in Real-Time Control Systems with Uncertainty","awardID":"0410771","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526924","550624"],"PO":["561889"]},"94539":{"abstract":"Mark E. Campbell, Cornell University, Hybird Estimation and Control with Bounded Probabilities<br\/><br\/>This project is developing a novel approach for hybrid estimation for <br\/>applications envisioned in hybrid systems research. Three areas of hybrid estimation research are developed, with an integrated evaluation process using known examples and real time testbeds. First, a bounded probability hybrid estimator is developed, where multiple continuous estimators, each at a different level of probability, are implemented in parallel. The system (user or hybrid controller) can switch estimators to the level of probability desired. Level sets are used to define each probability level, and relate it back to the original probability density function. Second, connections between hybrid estimation and control and planning are made, with a specific focus on switching hybrid vehicle control, including transition of bounded model uncertainties. Third, a computational infrastructure for the hybrid estimators is developed, including real time implementations. Theoretical work is systematically validated using simple, known examples first, followed by more complex examples that can be numerically evaluated, to ultimately a real time, embedded hybrid systems evaluation on a Cornell testbed. The Cornell SeaScan UAV testbed is a suite of up to four small UAV's, and a similar lab-based, hardware-in-the-loop testbed. During the summers, undergraduate students are teamed with PhD students and post-docs in an effort to transition and verify the technologies experimentally.<br\/><br\/>This work is expected to advance hybrid systems theory by enabling a general class of hybrid theory (such as control and planning) to be implemented in a realistic setting. The hybrid estimator allows a level of probability (such as risk) to be \"dialed up.\" While vehicle control and planning are used as motivation, the hybrid estimator is developed to allow general implementation for hybrid systems, from biological to air traffic control systems.","title":"EHS: Hybrid Estimation and Control with Bounded Probabilities","awardID":"0410909","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["553705"],"PO":["561889"]},"97949":{"abstract":"The goal of this project is to design metrics of online reputation that are both robust to gaming agents and efficiently computable. This will be done through development of an axiomatic framework for reputation together with novel algorithms that make the framework useful. This work will be grounded in practical online reputation systems of contemporary interest, and issues arising in real systems will guide axiomatic and algorithmic developments.<br\/><br\/>To navigate the complex web of information and agents on the Internet, society has increasingly come to rely on automated systems that assess reputation. Some prominent examples of such reputation systems are the PageRank mechanism used by the Google search engine, the feedback based rating scheme for the online auction site eBay, and the incentive scheme used by the popular file sharing system KaZaA. All these reputation systems are vulnerable to gaming by selfish agents trying to improve their own rating. Fundamentally, these reputation systems suffer from a misalignment between economic incentives of individual users and aggregate value to society. This research program will have a significant impact on several important problem domains such as ranking of web pages and blogs, online marketplaces, and peer-to-peer systems.<br\/><br\/>Online services such as search engines and auction sites have become an important part of our national infrastructure and need to be protected against greedy or malicious tampering. This research will contribute to the robustness of such systems. Additionally, the purpose of reputation systems is to gather highly imperfect information from many sources, and to process it into a comprehensible prediction of outcomes (e.g., whether a vendor will be reliable). Certain national security needs could conceivably be met with variants of reputation systems. One of the great challenges of intelligence assessment is to determine what information is reliable and what is not. The proposed research should help in addressing this challenge.<br\/><br\/>Elements of the research will be integrated into undergraduate and graduate courses on optimization, game theory, Markov chains, public policy, and Internet technology.","title":"ITR: Axioms and Algorithms for Reputation","awardID":"0428868","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["440832","429621","560159"],"PO":["564456"]},"98928":{"abstract":"Proposal Number: 0435168<br\/>PI: Nicholas Maxemchuk <br\/>Institution: Columbia University <br\/>Title: Funneling Impulses in Sensor Networks<br\/><br\/>Abstract: <br\/><br\/>This grant's research targets sensor networks that must \"funnel\" a sudden impulse of data that is generated due to an anomalous event such as an earthquake, terrorist attack, flood, or fire. The objective is to understand, from a fundamental standpoint, how to design sensor networks to adequately handle these impulses of data.<br\/><br\/>The PIs explore four fundamental areas that must be addressed by these types of networks for this scenario:<br\/><br\/>* Topological layout (density) of sensors to optimize battery resources during funneling.<br\/><br\/>* Persistence of data waiting to be funneled as nodes fail<br\/><br\/>* Compression of data en-route to the collection points during funneling.<br\/><br\/>* Reliability of delivery of data en-route to the collection points during funneling<br\/><br\/>The research will produce fundamental, mathematical models that will be used to solve these problems in an analytical context. The results will be of use to more practically-oriented research that seeks to implement and experiment with actual hardware and software solutions.<br\/><br\/>The availability of dense sensor networks that are robust and can effectively funnel impulses will have great impact on demanding sensing application areas such as disaster response and recovery, fire fighting, and emergency response. In addition, the techniques that are developed within this research will play a crucial role in defining foundations for future dense sensor networks, providing the basis for a new class of sensing applications in these critically important areas.<br\/><br\/>Research results will be disseminated through technical and popular publications in top conferences.","title":"NeTS-NOSS: Funneling Impulses in Sensor Networks","awardID":"0435168","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["493395","497480","522280","553512"],"PO":["434241"]},"97729":{"abstract":"NSF ITR Proposal 0426904<br\/>Making Speech Recognition Pervasive by Migrating it Into Silicon<br\/>Rob A. Rutenbar (CMU), Tsuhan Chen (CMU), Robert W. Brodersen (U.C. Berkeley)<br\/><br\/>ABSTRACT<br\/><br\/>Whether running on a single cell phone or a conventional PC - all of today's state-of-the-art speech recognizers exist as complex software running on conventional computers. This is profoundly limiting for national and homeland security applications in which mobility or stealth are essential. Today's state-of-the-art speech recognizers fully occupy the resources of a modern desktop PC; but we cannot deploy such hardware in scenarios where size, covertness, long-life, and untethered operation are essential. Our cell phones last a week if we do not use them; they last a few hours when we actually speak to them. To remedy this, we must move the core of today's most successful speech recognition strategies directly into silicon. We propose to design a silicon speech recognition architecture that can offer at least 100 times better energy efficiency than today's software solutions. We will explore performance trade-offs by extending field programmable gate array (FPGA) emulation technology, so that proposed chip designs may be rapidly evaluated executing real-world problems involving hours of voice data. The Carnegie Mellon \/ Berkeley team brings decades of experience with silicon design, low-power design, and speech recognition to this effort. The goal of the project is to liberate speech recognition from the artificial constraints of its current software-only form, and to make it a reliable, pervasive technology for the field-oriented national and homeland security applications where it is today unsuitable.","title":"ITR-NHS-DMC: Making Speech Recognition Pervasive by Migrating it Into Silicon","awardID":"0426904","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["542045","309009"],"PO":["562984"]},"92933":{"abstract":"Over recent years, there have been two significant changes in the area of high-end computing: 1) an increasing focus on interactive data driven applications and 2) a shift from tightly coupled high-end computing systems to networked clusters of machines within an organization and across geographically dispersed organizations. A particular challenge in using networked clusters for an interactive and data-intensive computing task is that processing of data may not always be possible where data is resident. The principal investigators (PIs) envision that a configuration comprising a networked collection of storage cluster(s), compute cluster(s), memory cluster(s), wired\/wireless clients, and facilities for data visualization and collaboration, will be common and popular in modern organizations. Moreover, people within an organization will interact with existing compute and data resources over the Internet, as part of a grid environment.<br\/><br\/>Intellectual Merit: This project aims to design and develop such systems and their components including communication, networking, I\/O, QoS, programming models, compilers, scheduling, middleware, caching, and indexing. The system research will be closely integrated with research in algorithms for visualization and data mining and end data-intensive applications. The overall goal will be to enable collaborative, data-driven, and interactive applications involving multi-terabyte datasets to benefit from end-to-end QoS.<br\/><br\/>The research testbed will consist of a compute cluster and a memory cluster connected to an existing mass storage cluster with high-speed WAN links (20.0 Gbps and beyond). A wireless testbed with clients and graphics resources (adapters, haptic devices, and headmount displays) will also be connected to the compute cluster to study the end-to-end QoS and interactivity issues.<br\/><br\/>Broader Impact: This project will benefit 18 investigators, their students (including members of underrepresented groups) and research staff in the Department of Computer Science and Engineering (CSE) and Department of Biomedical Informatics (BMI) to carry out state-of-the research in systems, networking, middleware, data mining and visualization; disseminate the results through research forums; and disseminate the developed software through open-source avenues. Several team members of this project collaborate with faculty members and researchers inside and outside of the campus in designing and developing end-applications in the areas of engineering, science, and medicine. This project will facilitate developing state-of-the-art solutions for these end-applications in an inter-disciplinary manner. A numbers of initiatives are planned for integrating research and education: enhancing several graduate courses in CSE with hands-on projects on networked cluster environment, creating new courses on data mining and data and scientific visualization in CSE, and creating a new interdisciplinary course sequence in the area of application-driven grid computing (jointly to be done by the CSE and BMI). The outreach plan includes participation in K-12 programs, participation in summer training programs for underrepresented groups, and collaboration with minority institutions.","title":"High-End Computing and Networking Research Testbed for Next Generation Data Driven, Interactive Applications","awardID":"0403342","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["532951","561947","410444","558505","533228"],"PO":["565272"]},"105952":{"abstract":"This project, addressing heterogeneous and dynamic sensor technologies, facilitates experimental research, demonstrating and distributing scalable middleware services that support hybrid sensor technologies, including traditional scalar sensors such as the Berkeley motes, as well as newer sensors such as the OGI panoptes video-based sensors. The work focuses on the following tasks:<br\/> Adaptive Network Protocols,<br\/> Global Power Management, and<br\/> Programmable Architectures.<br\/>Dynamically inferring and exploiting the heterogeneity of network components, the 1st task investigates mechanisms to support a range of sensor networking technologies by designing adaptive protocols for network resource management and data recovery. The 2nd investigates techniques to help designers understand global power management in heterogeneous sensor networking applications. The 3rd task investigates middleware to support the programmability of hybrid signaling within video-based sensor networks. To validate and demonstrate the approach, three sample applications will be built. <br\/> Time-Elapsed Imaging for Coastal Monitoring (used to sense light),<br\/> Security Monitoring (used to sense movement in a room), and<br\/> Health-Care Monitoring (used to validate video and vice versa with scalars).<br\/>The difference between a custom-built application and a middleware version for various parameters will be measured in each case, as well as how much energy can be saved by having hybrid sensors working cooperatively (rather than autonomously) to manage power. This project explores the fundamental challenges in enabling such applications. Addressing the diversity in sensors should be critical in addressing the sensor networking applications of the future. These systems comprise the integration and interaction of diverse classes of sensor nodes, motivating approaches that require greater synergy among nodes than those previously explored in the traditional sensor networks. Augmenting the infrastructure through separate funds with a variety of additional sensing devices, will enable the creation of an extensive and flexible testbed to study scalable middleware services that support hybrid technologies. Hybrid sensor technologies can enrich the potential of sensor applications.<br\/><br\/>Broader Impact: The artifacts of this research will be useful to the broader community; the experiences with real applications can inform further research. Moreover, the experimental research will further enable scientists in the Environmental Science and Biomedical Engineering Departments. This work enhances the curriculum enabling students to partake in experimental sensor networks research for their course work.","title":"CISE RR: Infrastructure to Support Heterogeneous and Dynamic Sensor Networking Research","awardID":"0514818","effectiveDate":"2004-09-16","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["357733"],"PO":["557609"]},"104874":{"abstract":"Information systems for supporting the fluid organizations of the 21st century must be correspondingly open and agile, able to automatically configure themselves out of heterogeneous system components, accommodate the dynamic exit and entry of hitherto unknown participants and maintain system stability in the face of limited trust. The goal of this project is to develop technologies that enable the construction of such Contractual Agent Societies (CAS), open information systems where independently developed agents configure themselves automatically through a set of dynamically negotiated social contracts. Social contracts define the shared context of agent interactions, including ontologies, joint beliefs, joint goals, normative behaviors, etc. In addition, they specify classes of contract violations together with associated sanctions and enforcement mechanisms. The deliverables of this work include a language and ontology for representing social contracts, as well as the definition of agent architectures capable of negotiating social contracts and adapting their behavior accordingly. Significant attention will be given to the experimental evaluation of the proposed agent architecture by developing prototype CAS versions of at least two different electronic marketplaces and demonstrating how CAS buyer and seller agents can successfully move between marketplaces, adapting themselves according to the rules of each marketplace.","title":"CAREER: Contractual Agent Societies: Negotiated Shared Context and Social Control in Heterogeneous Multi-Agent Systems","awardID":"0509709","effectiveDate":"2004-09-01","expirationDate":"2006-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":[276877],"PO":["564456"]},"105864":{"abstract":"This project, developing an infrastructure for data intensive applications, aims at establishing a cluster and display-wall infrastructure to facilitate experimental research in systems that support retrieval, querying, modeling, and visualization of massive amounts of data in a broad range of scenarios. The infrastructure, consisting of a cluster of graphics-capable workstation with fast network infrastructure, a high-resolution display wall, and a dedicated file server, supports three research projects:<br\/> Exploiting the Hidden Web,<br\/> Large Scientific Visualization, and<br\/> Modeling and Rendering Large 3D Environments.<br\/>The first project searches, indexes, and queries the hidden Web data. Often crawlers, which visit pages by following hyperlinks, cannot find needed information without searching the individual sites. This project develops techniques to enable a crawler to navigate through hidden pages, building a search engine that allows these data to be queried. The second relates to the development of visualization technology that is suitable for very large scientific datasets. This research includes the development of out-of-core algorithms for scientific visualization, parallel graphics and scalable-display technology, novel rendering algorithms, and better visualization modeling primitives. The project expects to build visualization systems that effectively decouple the visualization requirements from the available hardware resources, allowing visualization of arbitrarily large datasets on any reasonable device. The third project looks into models of real-world objects and scenes from which applications such as entertaining, training and simulation, special effects, analysis of forensic records, telepresence, and remote walkthroughs can benefit. This work requires tackling expensive optimization problems related to registering and cleaning raw data, and high-resolution display for real-time rendering.<br\/><br\/>This infrastructure enables the establishing of a lab in Visualization and Geometric Computing and WebDB; which in turn will benefit many students. An outreach component is in place; the research currently supports several female and minorities. Moreover, two new related courses are under development","title":"A Cluster Infrastructure to Support Retrieval, Management and Visualization of Massive Amounts of Data","awardID":"0514485","effectiveDate":"2004-09-20","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["521992"],"PO":["557609"]},"102597":{"abstract":"PROPOSAL NO: 0403130<br\/>INSTITUTION: University of Akron<br\/>PRINCIPAL INVESTIGATOR: Dai , Liming<br\/>TITLE: NER: Conducting polymer nanocontainers and conducting polymer-carbon nanotube junctions<br\/><br\/>Abtsract:<br\/>The recent development of nanoscience and nanotechnology could revolutionize computers and electronics by miniaturizing transistors and developing novel integration methods. This proposal aims at performing a feasibility study on the synthesis of conducting polymer nanostructures and their junctions with aligned carbon nanotubes. The proposed research stemmed from our long-term interest in nano-\/micro-fabrication of conducting polymers and aligned carbon nanotubes. The main approach involves the use of nanobubbles generated on aligned carbon nanotube tips as the template for electrodeposition of conducting polymers, leading to the generation of novel conducting polymer nanostructures (e.g. polymer nanotubes) and conducting polymer-carbon nanotube junctions. Examples include the formation of novel multiple metal-semiconductor or semiconductor-semiconductor junctions by sequential electrodeposition of different conducting polymer nanostructures on the aligned carbon nanotube tips and novel switchable junctions by electrochemical and\/or chemical doping of the conducting polymer components. In conjunction with the proposed multi-scale modeling and simulation efforts for fundamental understanding of the conducting polymer nanostructures and their junctions with carbon nanotubes, results from the proposed studies could open up new possibilities for fabricating novel integrated circuits and electronics, for example, through 3-dimensional integration and\/or by chemically-induced switching memory devices. In addition, the use of conducting polymer nanostructures for sensing and controlled release applications will also be demonstrated.","title":"NER: Conducting Polymer Nanocontainers and Conducting Polymer-Carbon Nanotube Junctions","awardID":"0456394","effectiveDate":"2004-09-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1676","name":"NANOSCALE:  EXPLORATORY RSRCH"}}],"PIcoPI":["560171"],"PO":["562984"]},"97917":{"abstract":"Recent advances in Natural Language Processing, in particular the ability to use unstructured data to answer natural language questions, are very exciting from an educational perspective. They offer the promise of systems that can automatically respond to students' questions, thus supporting not only a guided but also an open ended, exploration based, approach to learning.<br\/><br\/>Developing software that supports students' learning is all about constructing the right kind of environment for students, one that facilitates rather than inhibits inquiry through a known knowledge space and provides a jumping-off space for trying to find or generate new knowledge.<br\/><br\/>The goal of this project is to apply research in Computer Science -- particularly Natural Language Processing -- and the Learning Sciences, to developing an intelligent tutor that can provide this needed environment. This tutor will inhabit a human-computer interactive environment in which the computer is able to detect and track the user's cognitive and academic state and act based on this knowledge to aid the student in identifying and accessing relevant knowledge, contribute relevant factual information the student may need and guide the student in selecting potentially relevant subtasks.<br\/><br\/>The testbed domain in this project involves high school and undergraduate level students studying concepts in Bioinformatics -- building on the enormous amounts of biological data and software made freely available on the Web by the Bioinformatics community, and specifically, making use of the Biology Workbench system developed at NCSA.<br\/><br\/>In the context of this project, researchers will (1) develop the necessary machine learning, natural language and inference methods that can robustly support a level of natural language understanding that is sufficient to ``understand'' students and their queries well enough to direct it to the right material, make relevant suggestions and develop a meaningful dialog in the context of the subject matter; (2) create a system that is able to accommodate different student backgrounds and goals and behave appropriately, and learn as it does so; and (3) study how students learn and how to support students' learning in a computer-aided context.<br\/><br\/>This project will contribute to the understanding of how students learn in a computer aided environment and use it to develop improved methods for supporting learning in these environments. This has the potential for large educational impact for large classes, distance education, and self-paced instruction. The project's computational results in areas such as natural language based human machine interaction, adaptive dialog management, user-sensitive information retrieval and extraction, and machine learning, would be widely applicable to many other domains, including intelligent information access and interactive support systems for senior citizens and other groups.","title":"ITR-(ASE+ECS)-(soc+sim+int)-Natural Language Processing Technology for Guided Study of Bioinformatics","awardID":"0428472","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["488661","549219","318715","477235","456699"],"PO":["564318"]},"98907":{"abstract":"Abstract: <br\/><br\/>Providing privacy for sensor networks is an important problem that is complicated by the fact that it is easy for adversaries to observe communications between sensor nodes. A first line of defense for protecting sensor communications is cryptography. However, these methods cannot address the complete spectrum of privacy issues in sensor systems. Specifically, security solutions are inadequate for protecting the privacy of contextual information surrounding a sensor application, such as the source's location, or the time at which a measurement was made, or even the size of sensor data packets.<br\/><br\/>This project investigates the development of a framework for providing three critical types of contextual privacy to sensor communications: source location privacy, temporal privacy, and traffic privacy. The project takes the viewpoint that the existing network stack can be modified to protect privacy while maintaining desirable levels of resource-efficiency. This investigation will enhance the privacy levels achieved through the development of new routing protocols involving the use of directed random walk techniques to obfuscate the data source, the modification of the structure of sensor messages to prevent traffic analysis attacks, the introduction of delay in the delivery of messages to reduce temporal correlation attacks, and the introduction of modifications to physical layer communications and the sensor topology to prevent the localization of a communication source. Through dissemination of the research results in both archival publications and new curricula, this project will advance the development of sensor applications by addressing critical privacy issues before sensor systems become a communal asset.","title":"NeTS-NOSS: PARIS: A Framework for Privacy Augmented Relaying of Information from Sensors","awardID":"0435043","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"V618","name":"NSA-SOW"}}],"PIcoPI":["564747","531726"],"PO":["543507"]},"97708":{"abstract":"The overall theme of this grant is to bring the tools and power of theoretical computer science to bear on the study of electoral systems (i.e., one-round social choice systems-ways of so reaching a decision from a collection of inputs). We will do so in a way that jumps far beyond the analyses of language-complexity-of-winner in specific electoral systems research done by the proposer and many others; rather, our core focus is on the following two themes: (a) understanding the reasons for and sources of complexity in electoral systems, and (b) providing ways of circumventing such complexity.<br\/><br\/>Let us speak of each of these two related themes in turn. Regarding (a), to get at not the what but the why of the high complexity levels that by now have been found in various specific electoral systems that are considered nice in terms of their fairness-type properties, we will study the extent to which fairness inherently requires high complexity. That is, we will obtain theorems of the form: Any system satisfying the following fairness axioms will have a winner-computation problem that is hard for the following complexity class. The goal of this part of the research is to fund what types of fairness property collections are inherently precluded, and what types are not-information that is very useful in the design and choice of electoral (decision) systems. That is, just as Arrow's Impossibility Theorem [Arr63] made clear that some natural fairness\/niceness property collections outright preclude the existence of systems having those properties, we wish to use not existence but (the more demanding standard of) tractability as a guide to what property collections can and cannot be achieved.<br\/><br\/>(We also will, via studying the complexity of the central score functions involved in electoral systems, determine whether the standard simplification to languages has obscured insights into electoral complexity, and we will also study the complexity of manipulating electoral systems, and their resistance to manipulation.)<br\/><br\/>Regarding (b), the core ideas explored will be: Since real elections typically have small numbers of candidates, for complex electoral systems (both specific ones and broad classes of systems), what is their complexity when viewed as parameterized by the number of candidates; and can the scoring functions underlying electoral systems having high complexity be well-approximated, or can it be proven that they cannot; and in informal everyday practice can they be well-attacked with heuristic methods?<br\/><br\/>Broader Impacts This proposal involves a wide range of broader impacts, including information dissemination, international collaboration, collaboration with a non-PhD-granting school, enrichment of local community, training of students and post-docs, and service to the theory community. <br\/><br\/>These activities are outlined in more detail throughout the proposal: in the Broader Impacts part of the Proj. Description, in the Human Resources and Service to the Community parts of the Prior Work section, in the Synergistic Activities part of the Biog. Sketch, and in the Grad. Student Justification part of the Budget Justification. Another broader impact is via the research itself. The research's most important goal is to determine which combinations of electoral fairness\/niceness conditions inherently do\/don't induce computational complexity. This goal is exceedingly natural, as it seeks to identify what types of electoral-system fairness goals don't crash into the wall of complexity-theoretic limitations (basically, an analog of Arrow's Impossibility Theorem, yet enforced not by mathematical impossibility but rather by the limitations of computation). As to other parts of the research, the study of power-fairness will research the issue of which apportionment algorithms amplify or shrink the power of small voting blocks within a society; the study of manipulation will seek to learn what makes a system easy to evaluate yet simultaneously hard to manipulate; the study of fixed-parameter complexity of seemingly computationally complex systems will seek to fund when even such systems can be feasible on \\reasonable\" numbers of candidates. (Regarding ECS\/ASE\/NHS, looking at the detailed descriptions of them in the program solicitation, it is clear that all three are deeply affected by the importance of the issue of coming fairly and efficiently to decisions based on the preferences of separate entities. NHS is additionally supported by the studies of manipulation and control. And the Technical Focus dmc is supported by decision-making, which is an explicit part of the description of the dmc focus area.)","title":"ITR - (ECS+ASE+NHS) - (dmc): Richer Understanding of the Complexity of Election Systems","awardID":"0426761","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["478022"],"PO":["562944"]},"96619":{"abstract":"This project, creating a new cluster computer design targeted at interactive exploration of datasets tens of terabytes in scale, supports analysis and visualization of massive datasets. Research efforts concentrate mainly on genomics and bioinformatics, cosmology and geophysics, and computational fluid dynamic (turbulence and stellar convections). For the purpose of rendering, in near real-time, datasets whose render information requires up to 2TB of simultaneously active storage, a large system consisting of 80 dual processor nodes with a massive amount of disk space will be used for the visualization task. The visualization system will allow slightly more leeway for exploratory viewing of interactions among multiple variables at multiple time slices. Motivated by the need to interactively explore voluminous datasets, the system supports interactive analysis and visualization that follows any interactively specified and\/or modified path through the 4 dimensions examining all the data along that path by streaming this data, potentially replicated at each of 80 network nodes, into the memories at a rate that matches the node's ability to perform significant analysis and\/or visualization operations on the data and to display the results for the user at high resolution on viewing screens as large as the LCSE's 13 Mpixels Power Wall. Volume visualization and various kinds of pattern matching and cross correlation target this data. The design goals require significant research in scientific visualization, data management, data storage and cluster data sharing, as well as prority-based job scheduling.<br\/><br\/>Broader Impacts: The development of this system involves many students and postdocs in the collaborating disciplines. The system will be used in instruction as well as in research leading to advance degrees. The computer science department at Fond du Lac Tribal and community College in Cloquet Minnesota will also benefit from this project due to the existing collaboration of the Laboratory for Computational Science and Engineering (LCSE) with this Native American serving college. LCSE has also shared its technology developments and software. Once again, the developed software will be made available over the Web in Open source format.","title":"MRI: Development of a System for Interactive Analysis and Visualization of Multi-Terabyte Datasets","awardID":"0421423","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["468762","543507","382574","455559"],"PO":["557609"]},"95409":{"abstract":"Entropy Compressed Data Structures<br\/><br\/>In this report, we highlight the intellectual challenges of the<br\/>proposal, both theoretically and in practice. The interplay between<br\/>theory and practice distinguishes this proposal from many in the<br\/>database searching area. The goal of an entropy-compressed technology<br\/>could have a major impact on data structure design and implementation.<br\/>We give a three-year research plan of desired and expected outcomes.<br\/><br\/>In this proposal, we introduce a new data structures model and<br\/>technology called Entropy-Compressed Data Structures that addresses<br\/>the importance of limiting the size of text databases and search<br\/>structures that index huge volumes of data. The main goal is to<br\/>achieve \"optimal\" space terms (with a leading coefficient of 1, with<br\/>provably smaller second-order terms) while not sacrificing optimal<br\/>lookup time. We measure our \"optimal\" space usage in a data-aware<br\/>manner, as a function of the inherent randomness (or entropy) in the<br\/>input data set. This model is an outgrowth of the recent<br\/>space-efficient discoveries made by the PI and coauthors in the area<br\/>of text indexing, which has caused a rebirth of research in text<br\/>indexing and has spawned considerable interest in space-efficient data<br\/>structures.<br\/><br\/>In order to analyze the space required, we need measures (or models)<br\/>to evaluate these succinct structures and quantify the<br\/>space-savings. The space required for a structure should relate in<br\/>some sense to the entropy of the data that the structure is built<br\/>upon. We formalize a variety of intuitive and meaningful models as a<br\/>foundation for a uniform and structured study in a number of<br\/>applications.<br\/><br\/>We plan a three-pronged approach in developing Entropy-Compressed Data<br\/>Structure technology:<br\/><br\/>First, we focus on the fundamental dictionary problem, <br\/>where the task is to represent a set S of t items out of a universe <br\/>U = {0, ..., n-1}. Dictionaries are critical in text indexing <br\/>and other database applications as a building block in designing<br\/>entropy-compressed data structures. For text-based applications,<br\/>dictionaries serve as a powerful black box that operates within some<br\/>entropy-aware partitioning of the data. Any improvement to a<br\/>dictionary structure would have tremendous impact on all such<br\/>dependent applications.<br\/><br\/>In the first year, we expect to devote our efforts in developing a<br\/>powerful and succinct fully indexable dictionary that operates in<br\/>near-optimal time. In particular, we hope to achieve bounds for a<br\/>dictionary supporting the operations of rank and select (and thus the<br\/>predecessor operation as well) in gap + o(log {n choose t}) bits<br\/>(where gap refers to the optimal space cost using a gap-encoding of<br\/>the items in the dictionary), while achieving time bounds of Anderson<br\/>and Thorup, namely O(min{{sqrt{log t\/loglog t}, <br\/>((loglog n)(loglog t))\/logloglog n, loglog t + log t\/loglog n }}) time.<br\/>In a similar vein, we wish to further push our structure to achieve<br\/>gap + o(gap) bits without sacrificing lookup time. These<br\/>contributions would be quite major theoretically, and their impact<br\/>could be considerable in practice.<br\/><br\/>As a further step, we would also like our dictionary to be dynamic, as<br\/>this development would be of immediate interest to the database<br\/>community. In practice, we want our structures to be simple, so that<br\/>they can be readily implemented. For instance, a good implementation<br\/>also becomes a potential solution to the IP lookup problem, since one<br\/>could abstract an IP lookup as nothing more than a query to find the<br\/>longest common prefix match (which is very similar to the predecessor<br\/>problem).<br\/><br\/>Second, once a powerful dictionary is developed to serve as a black<br\/>box, we can begin to focus on the technology of space-efficient<br\/>representations of the application data structures themselves. Text<br\/>indexing has received quite a bit of attention in recent years, and we<br\/>focus on improvements to these structures to motivate a similar<br\/>progression of work in other application areas. We will show very<br\/>clearly the relationship between text indexing and the dictionary<br\/>problems and how they can be used as a basic paradigm for making data<br\/>structures entropy-compressed.<br\/><br\/>A strong component of this proposal, in comparison with other projects<br\/>in the IDM program, is the marriage of theoretical analysis and<br\/>practical implementation. We have demonstrated rigorous mathematical<br\/>proofs of optimality in our earlier work, and moreover, the mathematical<br\/>elegance has translated to efficient implementations in practice. We<br\/>regard our strengths in theoretical design and analysis as a very<br\/>strong component of this project.<br\/><br\/>In the second year, we propose to improve the sta","title":"Entropy-Compressed Data Structures","awardID":"0415097","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["313394"],"PO":["563727"]},"97719":{"abstract":"ABSTRACT<br\/><br\/>ITR: Collaborative Research (NHS + ASE) (int + dmc):<br\/>Networks of Robots and Sensors for First Responders<br\/><br\/>PI: Daniela Rus, MIT<br\/>Co-PI: Vijay Kumar, U. Pennsylvania<br\/>Co-PI: Sanjiv Singh, CMU<br\/><br\/><br\/>This collaborative ITR project addresses the development of proactive networks of sensors and robots that perceive their environment and respond to it, anticipating information needs by the network and by users of the network, repositioning and organizing themselves to best acquire and deliver the information. Such networked systems combine the most advanced concepts in perception, communication, and control to create computational systems capable of interacting in meaningful ways with the physical environment, extending individual capabilities of each component and user to encompass a much wider area and range of<br\/>data. The PIs envision a physical analog to the Internet-- networks of computers that can actively sense, physically interact with, and reason about the world. While the Internet allows transparent access to information already online, this research will extend the paradigm by allowing users to \"google\" for physical information, setting into motion robots and sensors that team together to acquire information and act on it.<br\/><br\/>Intellectual Merit<br\/><br\/>The proposed research program will be make significant contributions to networked multi-agent systems: control, self-organization, adaptation, and perception. The work will focus on: (1) Control for communication and sensing: the control of robotic agents to maintain communication links or establish new ones, while obtaining the required sensory information and tracking sources; (2) Communication for sensing and perception: the fusion of information from heterogeneous sensors over the network, providing the required information for each agent to plan and control its mobility and providing remotely located human rescue workers with information through immersive displays; and (3) Communication networks for sensing and control: the grouping, scheduling and routing of nodes to adapt to changing, adverse conditions while maintaining guarantees for control of mobility and for sensor fusion and integration.<br\/><br\/>Broader Impact<br\/><br\/>The research will enhance national and homeland security by providing first responder with information about areas that are unsafe and hard to reach for humans in three ways. First, it will speed up the response time by helping in assessment, by augmenting human perception for command and control. Second, it will help in suppression and containment. Third, it will play a role in recovery, as in identification of victims and location of responding personnel. The collaboration with practitioners at the Allegheny Fire Training Academy will ensure that the research is grounded in the real world and has impact in the emergency response community.","title":"ITR: Collaborative Research: -\\(NHS+ASE)-\\(int+dmc\\): Networks of Robots and Sensors for First Responders","awardID":"0426838","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["527733"],"PO":["429182"]},"97609":{"abstract":"This project is constructing a modern infrastructure to support cross-disciplinary research and to serve as a catalyst for student training in the fields of applied information processing, neuroscience, and assistive technology research. By merging these fields, a foundation is set for (1) developing new methodologies destined to respond effectively to the issue of universal accessibility, and (2) establishing research strategies to meet impending needs in neuroscience as functional mappings and causality of key brain disorders are developed. The infrastructure includes a high performance computational cluster with an active display mural, a magnetic link for integrating electroencephalography to magnetic resonance imagery, an optical topography system for near-infrared spectroscopy, and an eye-gaze tracking system. The infrastructure extends the research capabilities of Florida International University (FIU) and enables long-range improvements in neuroscience and assistive technology. The infrastructure is envisioned to provide researchers with an environment that is conducive to cross training among disciplines, supported by experimental evaluations and feasibility studies, from which prototype designs are moved to the realm of practicality. New opportunities are made possible for consolidating a joint FIU-Miami children's Hospital neuroscience program worthy of national distinction. In assistive technology research, a primary objective is to design the next generation of human computer interfaces that are multimodal and adaptive as real-time assistive systems that extend the functional capabilities of persons with motor and visually disabilities. On the educational front, new curriculum is planned, with engineers, computer scientists, neuroscientists, and radiologists working together for an integrated approach to the teaching and training of students. Furthermore, this project strengthens FIU's outreach programs for recruiting outstanding Ph.D. students. This is coupled with sustained commitments to recruiting and retaining underrepresented minorities in CISE-related disciplines.","title":"MII: Hardware-Software Integration for the Design of Real-Time Prototypes Merging Assistive Technologies to Neuroscience","awardID":"0426125","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":["420405","558105",256830,"435839","435840"],"PO":["565272"]},"101564":{"abstract":"The purpose of this grant is to provide support for students from the United States to travel to Berlin, Germany to attend the 12th IEEE International Conference on Networking Protocols (ICNP '04). ICNP is a premier networking conference. The goal of the travel support is to largely defray the costs of student travel so that more students may attend the conference. These students will attend talks from top researchers in networking, participate in panel discussions, and meet members of the networking research community. This grant will enable students to attend the conference that would not otherwise be able due to financial constraints.","title":"Student International Travel Support for IEEE International Conference on Networking Protocols (ICNP '04); October 5-8, 2004; Berlin, Germany","awardID":"0451306","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518380"],"PO":["7594"]},"100365":{"abstract":"The goal of this project is to explore compilation technologies for high-levelscripting languages that make it possible to run the generated code on leading-edge parallel com-puters without sacri .cing application performance,programming clarity,or programming system responsiveness.The intellectual merit of the proposed research lies in research on the trade-o .sbetween di .erent compilation times .language generation time versus application compilation orinterpretation time .to achieve higher optimization levels without making compile times unaccept-ably long.","title":"Introducing Parallelism into Scripting Languages through Generalized Data Distributions and Library Preprocessing","awardID":"0444465","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"V549","name":"DARPA-HEC-URA"}}],"PIcoPI":["24590","309293","421136","179296","517356"],"PO":["565272"]},"100145":{"abstract":"The optical network is a promising high-speed backbone or transportation network that requires<br\/>an extremely caution in operations. The reconfiguration is one of the indispensable operations if a<br\/>virtual topology no longer serves a traffic demand which is changed over time.<br\/> We propose to develop an algorithm and a complete reconfiguration model for wavelengthrouted<br\/>optical networks which includes the reconfiguration process and the policy. The reconfiguration<br\/>process provides the choices of the reconfiguration operations (e.g., add, delete or re-route<br\/>lightpaths) to maintain the high performance of the network in any traffic demand volumes and<br\/>patterns while minimally disturbs the current virtual topology. The reconfiguration policy defines<br\/>which choice to be selected that returns the optimal expected outcome based on the cost of operation<br\/>and the performance reward. We have preliminary experimental results that show that selecting<br\/>the choice with the highest immediate outcome does not return the optimal expected outcome in<br\/>the long term.<br\/> Although the reconfiguration problem is an NP-hard problem and is a trade-off between performance<br\/>and number of changes in virtual topology, we can still find the solutions using a multiobjective<br\/>evolutionary algorithm with the concept of Pareto Optimal. The algorithm provides a set<br\/>of solutions in the Pareto front while the policy picks one of solutions in the Pareto front that gains<br\/>the optimal expected outcome. The policy depends on the pattern of traffic. If the future pattern<br\/>of traffic can be predicted or estimated, the Markov Decision Process (MDP) can define the policy.<br\/>However, the status of network or the MDP's state which effects the Pareto front needs an intensive<br\/>study.<br\/> Our goal is to develop the theory and algorithms in accordance with realistic traffic demand and<br\/>protocol. The model will be the centralized control over the network, which will not be designed<br\/>only for the specific performance objective or traffic type but be applicable for various objectives<br\/>and traffic types. The development of practical algorithms for solving these problems represent an<br\/>important step in allowing reasonable scale implementation of optical networks.<br\/> Intellectual Merit of the proposed research rests on the integration between the reconfiguration<br\/>process and the policy based on the Pareto optimal concept and MDP that has not yet happened in<br\/>the Optical network reconfiguration field. Reconfiguration problems are among the most difficult<br\/>in the areas of optical networks since such problems encompass the construction of algorithms<br\/>involving the extremely high-speed communication over an optical fiber. The consequence problem<br\/>is how or when to perform the reconfiguration process. From the practical application viewpoint,<br\/>we want to advance our model to the practical optical networks.<br\/> Broader Impacts of the proposed research is expected to be strong since we are proposing<br\/>to integrate two disciplines, the evolutionary computing and the stochastic process for the recon-<br\/>figuration in the optical networks. We expect that the work will have broad impact in industrial<br\/>practices on network provisioning, protection and restoration areas.","title":"SGER: Algorithm Design for Reconfiguration Problem in Optical Networks","awardID":"0443257","effectiveDate":"2004-09-01","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["381214","348204"],"PO":["499399"]},"94903":{"abstract":"This project seeks to develop adaptive techniques for high performance graph-based reasoning systems that allow users to control the tradeoffs between computational resources and solution quality. The main thrust of this project is to introduce adaptability and scalability in algorithms for constraint optimization, probabilistic inference, and decision making under uncertainty. The project is structured into subprojects that study: (1) iterative belief propagation for graphical models; (2) hybrids of stochastic local search and inference; (3) search guided by partition-based heuristics; and (4) mixed probabilistic and deterministic (constraint) networks. These subprojects are tied together by the PI's ongoing research on the unifying framework of \"parameterized bounded inference\" that combines the two paradigms of search and structure-based inference. Endowing graph-based algorithms with increased adaptability and scalability is important not only to progress in AI and computer science but also to application in many domains. An additional goal of this project is to package the developed algorithms in one software reasoning and evaluation shell (REES) to allow uniform empirical evaluation and to facilitate dissemination of the project's results by researchers, educators and application builders.","title":"Strategies for High Performance Graph-Based Reasoning","awardID":"0412854","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["475511"],"PO":["387198"]},"103456":{"abstract":"Determination of three-dimensional structures of proteins provides insight into their evolutionary origins, functions, and mechanisms. While determining atomic-detail structures by traditional methods can be expensive, time consuming, or even infeasible, coarser-grained structural characterization is often sufficient to provide significant insight. The multimodal approach to rapid, approximate protein structure integrates complementary experimental evidence from a number of sources in order to verify and discriminate among computationally predicted structures. Appropriate experiments, due to their speed, variety of information, and disjoint experimental limitations, include cross-linking, giving rough distance restraints; stability assays after mutagenesis, characterizing structural roles of residues in particular environments; and solution x-ray scattering, yielding global shape properties.<br\/><br\/>The multimodal approach is grounded in probabilistic models that evaluate consistency of data with structural features (distances, accessibilities, overall shapes). This approach takes advantage of the diversity and relative independence of the available methods, rather than seeking to integrate separate measurements into an overarching physical model. Inference algorithms then reason about posterior distributions of structures and features, avoiding false optimism in a single answer, measuring overall plausibility, assessing the available information content, and quantitating uncertainty in individual features. Associated experiment planning algorithms optimize multimodal experiments (e.g. selecting cross-linker length and specificity, and identifying optimal mutation sites) for a given analysis task, so as to efficiently utilize experimental resources while maximizing information gain. The multimodal integration mechanism is being developed, applied, and tested with published data from individual methods, and is being used to plan and interpret appropriate experiments for selected proteins of unknown structure. Active participation of graduate students expands educational activities and tools will be accessible.","title":"SEI(BIO): Integration of Multimodal Experiments for Protein Structure","awardID":"0502801","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["511584"],"PO":["565136"]},"94969":{"abstract":"Prop ID: 0413204<br\/> P I: Colgate, J. Edward Organization: Northwestern University<br\/> Title: Variable Compliance Haptic Field Displays<br\/><br\/> Abstract<br\/><br\/>This research will address a novel class of haptic devices: \"Haptic Field Displays\" (HFDs). HFDs are large scale arrays of moveable pins or \"tactels\" covered by a flexible graphical display. HFD pin arrays will be much like the \"tactile arrays\" that have been developed for displaying Braille or virtual environments, but with some key differences. For instance, HFDs will be full-screen enabling scanning with the fingertip or using multiple fingers. They will operate not by actively controlling the displacement or force of each tactel, but by controlling compliance. The intellectual merit of this research stems from two sets of studies. The first is a set of psychophysical studies that will provide quantitative specifications for HFDs including the necessary dynamic range of tactel compliance and the resolution (or just noticeable difference) of compliance. These studies will also lead to an initial set of HFD primitives that naturally encode affordances (such as pushing, sliding or rotating). Finally, these experiments will assess human operator performance in using HFDs, especially in spatial localization and analog level-setting tasks. The second set of studies will address the design and integration of electronically programmable HFD tactels, each a meso-scale mechatronic system including a variable compliance mechanism, actuation and sensing. These studies will focus on the meso-scale realization of two low power \"semi-active\" approaches: variable damping achieved by controlling an orifice, and variable compliance achieved by placing a continuously variable transmission (CVT) between the fingertip and compliant element. Broader impacts of this research include the potential to improve the usability of graphical interfaces for normally-abled populations, as well as increase the accessibility of interfaces for differently-abled populations such as the elderly, those with low vision, and those who are blind. In addition, it has the potential to increase safety and utility in situations where high demands are placed on vision. For instance, HFDs would allow automobile drivers to focus visual attention on the road while simultaneously taking advantage of the growing assortment of electronic devices that may be found in a vehicle. This research will also impact undergraduate and graduate education at Northwestern more generally: tactel design and control will be integrated into at least two project-based courses taught by the P.I.s.","title":"Variable Compliance Haptic Field Displays","awardID":"0413204","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["555783","541975","541976"],"PO":["403839"]},"98908":{"abstract":"Traditional wireless cellular networks support voice or other constant-bit-rate connections. Under these conditions, fixed bandwidth allocation schemes have been successfully used to multiplex multiple users in the same cell while providing protection from multi-user interference. However, future wireless networks will need to accommodate multimedia sources that are bursty in nature and generate variable-bit-rate traffic. The goal of this project is to develop ALLIANCES (ALLow Improved Access in the Network via Cooperation and Energy Savings), a high-throughput medium access scheme for wireless networks that is suitable for bursty sources. <br\/><br\/>The wireless network is viewed as a spatially distributed antenna, with antenna elements linked via the unreliable wireless channel. When there is a collision, the packets involved in the collision are saved in a buffer. In the slots following the collision, a set of nodes, designated as relays, form an alliance and bounce off the signal that they received during the collision slot. By processing the originally collided packets and the signals forwarded by the relays, the destination node can recover the original packets. The spatial diversity introduced via the cooperative relaying enables one to effectively deal with the wireless channel without any bandwidth expansion or additional antenna hardware. ALLIANCES maintains the benefits of ALOHA systems in the sense that all nodes share access to media resources efficiently and without extra scheduling overhead, and enables efficient use of network power. Due to the importance of wireless communication in today's society, any improvement in throughput and energy savings is a worthwhile endeavor.","title":"NeTS-NR: ALLow Improved Access in the Network via Cooperation and Energy Savings (ALLIANCES)","awardID":"0435052","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["526916"],"PO":["434241"]},"102401":{"abstract":"Proposal Number: 0455350<br\/><br\/>TITLE: : Support for Support for US Japanese Workshop on Critical Information Infrastructure Protection<br\/><br\/>PI: Julie Ryan<br\/><br\/>Abstract:<br\/><br\/>The proposed activities will facilitate and support a workshop to bring together US and Japanese expert researchers in areas concerning protection of critical information infrastructures. The workshop goal is to identify and initiate the development of future collaborations between U.S. and Japanese researchers in specific technical areas. The workshop will include technical presentations from researchers from both countries, mutual discussion related to these topics, informal discussions, and government-government discussions. Support will include simultaneous interpretation for the formal discussions during the workshop.","title":"Support for U.S. - Japanese Workshop on Critical Information Infrastructure Protection; September 28-29, 2004; Arlington, VA","awardID":"0455350","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V883","name":"HOMELAND SECURITY-WORKSHOP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["528370"],"PO":["521752"]},"107703":{"abstract":"This project is creating programming language technology and tools to <br\/>aid the development of performance-sensitive distributed streaming <br\/>applications, such as real-time sensor networks. The basic idea is to <br\/>design programming abstractions that are specific to the domain of <br\/>streaming applications, and to develop checking and compilation tools <br\/>for mapping them to the underlying operating system mechanisms and <br\/>network protocols.<br\/><br\/>The approach is based on the \"Infopipe\" programming model, a novel <br\/>approach to building streaming applications, currently under <br\/>development by the PIs. Experiments with an early prototype have <br\/>shown Infopipes to be very promising. However, language tools for <br\/>simplifying the programming task, checking correctness properties and <br\/>ensuring adequate performance of complex \"Infopipelines\" do not <br\/>currently exist. This proposal outlines the research involved in <br\/>creating these tools and presents some novel ideas on the language <br\/>primitives and tools for Infopipes, the kinds of Infopipe properties <br\/>that can be automatically checked, and the conceptual foundation that <br\/>enables this checking to be rigorous.","title":"ITR: A Domain-Specific Language for Infopipes","awardID":"0523474","effectiveDate":"2004-09-27","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5980","name":"WESTERN EUROPE PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[284472],"PO":["561889"]},"95828":{"abstract":"Incorporating Power-aware Computing Techniques into the Classroom<br\/>Abstract<br\/><br\/>Power-aware computing has become a significant area of research and development both in industry and academia. Various techniques for reducing the energy consumption have been developed. The techniques developed for achieving the reduced power and energy cover many phases of the computer system design including circuits, voltage scaling, micro-architectures, operating systems, and compilers.<br\/><br\/>The current curriculum and the available textbooks for the relevant computer engineering courses do not adequately address power-aware computing. Our overall aim is to incorporate power-aware techniques into both the graduate and undergraduate curricula. Funds derived from this project will be used to develop a proof-of-concept in this regard.<br\/><br\/>The proof-of-concept will consist of developing instructional modules covering the following topics: (i) Power simulators, (ii) Static and Dynamic sources of power consumption, (iii) Fetch throttling as a means of reducing power consumption in high-end processors, and (iv) Voltage-scaling techniques in real-time systems. We will develop detailed plans for a two-course sequence in power-aware computing. This course sequence will be suitable for students who have had some prior exposure to computer architecture, operating systems, and compilers. It will include special-purpose applications such as embedded systems. Finally, we will develop in detail, an evaluation framework by which the quality of our offerings can be measured and improved.","title":"CRCD\/EI: Incorporating Power-Aware Computing Techniques Into the Curriculum","awardID":"0417481","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["553614","553615","408968"],"PO":["521045"]},"97809":{"abstract":"Sequential and graph-structured data arise naturally in a wide variety of scientific, engineering, and intelligence problems, such as handwriting and speech recognition, text mining, gene finding, and network analysis. While researchers have recently made significant progress on machine learning methods for processing structured data, these methods are much less accessible to scientists, engineers, and analysts than the better understood statistical learning techniques of classification and regression.<br\/><br\/>This project is researching methods to advance the state of the art in machine learning for structured data, building on recent work in conditional random fields and weighted transducers. The project is also developing a software toolkit to make the results of these advances accessible to researchers working in a wide range of disciplines and application domains. The toolkit will enable users to define, train, and apply models for structured data without requiring advanced expertise in machine learning. The functionality of the toolkit will include methods for specifying features relevant to an application, automatically selecting the most relevant features, adjusting parameters to optimize suitable training objectives, and combining models that pertain to different facets of an application.<br\/><br\/>The software, which will be freely distributed, will be tested with selected users in several application domains, and be carefully documented. The project will thus provide the scientific and engineering community with the first generally usable tool for learning from structured data, serving a role that is parallel to that of the more standard tools for classification and regression that are already widely used.","title":"ITR: Collaborative Research: (ACS+NHS)-(dmc+soc): Machine Learning for Sequences and Structured Data: Tools for Non-Experts","awardID":"0427594","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T471","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["460641"],"PO":["565215"]},"101456":{"abstract":"Mark Gordon of Iowa State University and Teresa Head-Gordon of UC-Berkeley are supported by the Chemistry Division to support approximately 50 people at an October 2004 workshop. The purpose of the workshop is to discuss opportunities, challenges, and unmet needs in the emerging, overlapping areas of cyberinfrastructure and cyberscience, from the perspective of the chemistry community. In addition to the two co-organizers, a steering committee of seven additional persons will assist in the planning, implementation, and final report of the workshop. Participants will compose a diverse group of researchers and educators, from academic and industrial backgrounds, as well as representatives from federal labs and funding agencies. The workshop report will inform the Chemistry Division about key issues in cyber-enabled chemistry.","title":"A Workshop on Cyber-Enabled Chemistry","awardID":"0450822","effectiveDate":"2004-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1978","name":"PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7368","name":"SCI TESTBEDS"}}],"PIcoPI":["540364","521837"],"PO":["353291"]},"101698":{"abstract":"CNS-0452067 Gautam Biswas Title: SGER: Modeling, Analysis, and Diagnosis for Safety of Distributed Hybrid Systems<br\/><br\/>Distributed embedded systems are pervading all aspects of our daily lives, from home appliances to safety and mission critical systems, such as automobiles, aircraft, manufacturing processes, nuclear plants, and military systems. These engineered systems consist of multiple subsystems with software components tightly integrated into physical processes. Complete analysis of their behaviors at design time is computationally infeasible. Diagnosis of fault behavior and its potential propagation through highly-coupled complex systems lacks a comprehensive scientific foundation. Commonly used methods for fault and failure mode criticality analysis do not address the detailed interactions of these systems and do not scale. A key observation is that the coupled subsystems interact at the physical level through energy-related interactions and at the logical level, by information exchange typically facilitated by a communication fabric such as a local area network LAN or control network. <br\/><br\/>The objectives and primary thrust areas of this exploratory research effort are two-fold. <br\/>(i) Advance the scientific understanding of modeling and behavior analysis of complex, embedded systems that are made up of distributed, interacting subsystems. This will require developing modeling methodologies and languages that integrate heterogeneous paradigms, developing formal models and mechanisms to handle subsystem interactions, and parameterizing the models to facilitate fault analysis. <br\/>(ii) Develop practical technologies for safety analysis and online diagnosis of complex distributed systems. The significant challenge in building a systematic framework for distributed diagnosis is to specify the coupling between subsystems in a way that fault interactions are captured in sufficient detail and integrated into the hybrid modeling methodology. It is also important to combine the results of the subsystem diagnostic components in a computationally efficient manner.<br\/><br\/>The science and technology developed in this project will inform designers in how to build more effective, reliable, and verifiable systems. For rapid dissemination through graduating engineers, research results will also be introduced in undergraduate and graduate engineering classes and laboratories at Vanderbilt University. Besides regular publications, efforts will be made to run a focused workshop in this area.","title":"SGER: Modeling, Analysis, and Diagnosis for Safety of Distributed Hybrid Systems","awardID":"0452067","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["536406","491916","533198"],"PO":["561889"]},"101379":{"abstract":"The overwhelming acceptance of online groups is evidenced by the tremendous quantity of activity and the size of the archives of these groups (in the range of a terabyte or more). People are turning to newsgroups for emotional support, for information, for social engagement and for facilitation of task performance. The PI's long-term objective is to make that experience of the best quality possible. To that end, in this project the PI will carry out a preliminary study of a large database of newsgroups from NetScan in order to use a large population to verify her findings in a small pilot study previously conducted, whose goal was to discover some characteristics of online communities. Results of the pilot study indicate that new participants in newsgroups are more likely to participate a second time if they receive a response to their first posting, and they are also more likely to post multiple messages if they receive a response. Apparently, based on the findings of the small study, emotional quality of the first posting or its response bears no impact on future participation, but if the first posting requests something of the group, the poster of that message is more likely to post at least once more. This project will re-examine these findings, as well as endeavor to refine aspects of community formation and maintenance in online groups by running statistical analyses of these variables in the larger database.<br\/><br\/>Broader Impacts: Newsgroups are still a relatively new phenomenon, which is attracting research attention but only on a fairly small scale. An analysis of a large database of newsgroup features and activity may provide results that could change how online communities are perceived. This project will attempt to define online communities in ways that look for differences from and similarities with face-to-face ones. Doing so will permit the design of newsgroups to reflect more closely the needs of the group, as well as of individual participants, in order to enhance their experience and solidify community formation and maintenance.","title":"SGER: Stickiness: Predicting Continued Participation in Newsgroups","awardID":"0450515","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":[267283],"PO":["565227"]},"112941":{"abstract":"Behaviorally Situated Avatars for Tutoring: Beyond the Talking Head and Animated Icon<br\/>Abstract<br\/><br\/>One-on-one tutoring is a critical component of teaching and learning. This project investigates technology to deploy an anywhere-tutor anywhere-student system that permits a tutor to provide instruction via an animated avatar. Exploiting psycholinguistic information, the system translates time-situated pointing and communicative gestures performed on a LCD tablet in conjunction with speech into a stream of behaviorally correct, spatially situated 3D gestures performed by the avatar tutor. A camera tracks the student, facilitating socially aware behavior by the avatar. The system exploits the student's ability to use body motion cues in the embodied avatar to direct her attention to appropriate locations of projected graphics that serve as artifacts of instruction. The technology will potentially facilitate a tutoring program in which students may connect to a pool of tutors for help with a variety of topics. The approach essentially implements tutoring 'telephone handsets' at both ends of the interaction. Tutors may be distributed across multiple sites at their convenience and take calls as they are needed. Widespread access to such tutoring will facilitate the vision of universally available educational opportunities. The project will investigate the necessary artificial intelligence and interaction technologies and evaluate the efficacy of this tutoring methodology.","title":"ITR: Beyond the Talking Head and Animated Icon: Behaviorally Situated Avatars for Tutoring","awardID":"0553246","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["486496"],"PO":["565227"]},"100764":{"abstract":"The investigator proposes to explore the foundations for a new, full-fledged theory of stochastic estimation for tracking boundaries of phenomena or objects that are described as level sets. Stochastic estimation for contours has shown its power in the literature of active contours, and level set methods have been shown to be very effective for describing boundaries that change topology frequently, and shape very rapidly. <br\/><br\/>Part of the proposed activities are theoretical in nature: the theory must be formalized from scratch, and several mathematical and computational challenges are to be overcome, including the formulation of methods for perturbing boundaries in a stochastically controlled way; the interleaving of boundary shape estimation with contour motion analysis; the invention of new methods for resampling, Maximum Likelihood, and Maximum A Posteriori estimation in the context of level sets; and the development of numerically efficient methods for the update and propagation of boundary estimates. Another important component of this proposal is work on applications ranging from the tracking of oil spills or clouds of pollutants by a swarm of robots; the identification and interpretation of hand gestures in image sequences; and the analysis of growth of skin lesions for dermatological diagnosis. <br\/><br\/>The proposed applications are important in their own right: tracking the spread of oil spills, pollutants, forest fires and similar phenomena is of clear and immediate usefulness to society. Tracking techniques for video analysis are of urgent importance for surveillance of public sites, monitoring of activities, and aiding of the speech or hearing impaired. In addition, the marriage of stochastic estimation and level sets is fundamental enough to make possible advances also in fields beyond computer vision.","title":"SGER: Tracking Level Sets","awardID":"0447245","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7339","name":"COMPUTER VISION"}}],"PIcoPI":["513187"],"PO":["317663"]},"101446":{"abstract":"Artificial Intelligence research has made limited progress towards computational understanding of human reasoning: we have failed to emphasize the creation of programs with \"resourcefulness\" in the face of unfamiliar problems. In computing theory and applications the emphasis has largely been on specific algorithms and mathematical techniques; complex systems have rarely yielded reproducible results or fundamental insights into a theory of system construction. Resourceful programs will require the application of multiple reasoning techniques, a layered architecture for coordinating activity whereby higher-order, reflective processes can diagnose failures in lower-order, deliberative processes.<br\/><br\/>Scenarios requiring \"commonsense reasoning\" provide an anvil of sufficient scope that only highly-resourceful programs will meet the requirements. Two projects support these aims: Roboverse establishes a virtual world where humanoid characters engage in complex, multi-realm scenarios, applying common sense to physical, social and mental activities; Panalogy is a specification for interconnect among multiple representations, combining diverse reasoning techniques such as analogy, case-based reasoning, statistical analysis and logical inference. An early version of Panalogy instantiates a set of meta-management components, demonstrating different ways to coordinate and repair baseline reasoning processes.<br\/><br\/>These resources enable wider research-community involvement by providing motivating demonstrations of new theoretical principles and evaluation tools and methodologies for experimental reproduction and comparison. We aim, through workshops, publications and direct engagement to encourage broader support from corporate and governmental sources. This increased effort in resourceful computing research leads the way towards programs that engage readily with humans in the search for solutions to complex problems of importance to science and society.","title":"SGER: An Architecture of Diversity for Common Sense Reasoning","awardID":"0450770","effectiveDate":"2004-09-01","expirationDate":"2005-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":[267441],"PO":["564318"]},"100347":{"abstract":"This proposal seeks to address these two primary challenges by developing adaptive software tools to<br\/>co-manage quality-performance-power tradeoffs. First, we will develop combinatorial and statistical adaptive techniques to select methods dynamically, delivering the improved performance while producing a solution that meets application quality requirements. Next, using an annotated model of computation and communication costs and sparse data access patterns, we will develop techniques for power reduction without<br\/>performance impairment. For example, power savings can be significant even when relatively minor load<br\/>imbalances among processors are exploited. These imbalances can easily be on the order of trillions of<br\/>CPU cycles, and power consumption can be tuned through dynamic voltage scaling (DVS, where both the<br\/>clock frequency and the supply voltage are tuned) for lightly\/heavily loaded processors. More importantly,<br\/>resulting insights can lead to future systems where the power budget is directed effectively over processor-memory interconnect subsystems to improve application performance. We plan to implement our techniques by developing an adaptive component software system on high-end multiprocessors","title":"Adaptive Software for Extreme-Scale Scientific Computing: Co-Managing Quality-Performance-Power Tradeoffs","awardID":"0444345","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7417","name":"S AND T HIGH-END COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[264770,"521548","507752","550407"],"PO":["565272"]},"100358":{"abstract":"We propose to develop and empirically evaluate the software tools,analysis techniques,and compiler<br\/>optimizations necessary to generate automatically a customized Linux image,and to affect the necessary ap-<br\/>plication transformations that use it.Moreover,we will quantify the success of our techniques using scienti .c<br\/>applications and software prototypes executing on commodity cluster platforms.We will employ parallel and<br\/>.oating-point intensive codes as well as scientic database programs.We will focus on execution platforms<br\/>viable at the high-end .clusters of SMP,IA32 and IA64 systems .the latter allowing us to investigate<br\/>relevance to NSF's current TeraGrid [65 ]effort.The result,we believe,will be a software system that auto-<br\/>matically enables high-performance scientic computing on commodity systems through application-specific<br\/>customization and dynamic adaptation of a low-cost,popular,and familiar Linux operating system.","title":"Automatic Linux Customization and Optimization for High-Performance Scientific Applications","awardID":"0444412","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7417","name":"S AND T HIGH-END COMPUTING"}}],"PIcoPI":["402357","561463"],"PO":["565272"]},"101515":{"abstract":"This award will provide travel support for approximately twenty graduate students to attend the First Annual International Conference on Security for Mobile, Wireless and Ubiquitous Systems (MoWiSec) jointly supported by the European Commission (EC) and NSF. This new conference will provide a forum to exchange ideas, techniques, and applications, discuss best practices and future directions, raise awareness and share experiences among researchers, practitioners, standard developers and policy makers in the field of security for wireless\/mobile networking based systems including pervasive and ubiquitous systems. The conference will provide for interactive and fruitful discussions on the various topics among participants from the academic, governmental, and industrial sectors. The travel award will target graduate students, since attending conferences is an important part of their educational experience, and they often have limited funds. This travel support thus contributes to initiate, develop, and foster relationships with leading international groups undertaking research in the related technical areas.","title":"Travel Support for First Annual International Conference on Network Security for Mobile, Wireless and Ubiquitous Systems","awardID":"0451117","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[267628],"PO":["565090"]},"100316":{"abstract":"CCR-0306607<br\/>Matthew B. Dwyer<br\/>Kansas State University<br\/><br\/><br\/>Model checking is emerging as a popular technology for reasoning about behavior properties of a wide variety of software artifacts including: requirements models, architectural descriptions, designs, implementations, and process models. The complexity of model checking is well-known, yet cost-effective analyses have been achieved by exploiting semantic properties of specific software artifacts. Adapting a model checking tool to exploit this kind of \"domain knowledge\" often requires in-depth knowledge of the tool's implementation. We believe that with appropriate tool support, domain experts will be able to develop efficient model hecking-based analyses for a variety of software models.<br\/><br\/>To explore this hypothesis, our project is developing BOGOR, a model checking framework with an extensible input language for defining domain-specific constructs and a modular interface design to ease the optimization of domain-specific state-space encodings, reductions and search algorithms. We will use BOGOR to investigate the degree to which customization of model checking algorithms can yield improved<br\/>scalability. Specifically, we will adapt BOGOR to reason about event-driven component-based design models and to reason about multi-threaded Java programs. We will evaluate the ease with which<br\/>domain information can be incorporated into the framework and the space\/time improvements that can be achieved by exploiting that information.","title":"BOGOR : A Model Checking Framework for Dynamic Software","awardID":"0444167","effectiveDate":"2004-09-01","expirationDate":"2006-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["561782"],"PO":["564388"]},"101669":{"abstract":"CNS 0451865 MIT Eric M. Feron Title: SGER: Convex Optimization of Lyapunov Certificates for Software Behavior Systems<br\/><br\/>This exploratory research project is transferring innovative concepts and associated computational techniques from the control systems analysis arena to software engineering for embedded systems. The project seeks safer embedded systems by applying computational methods to obtain thoroughly tested software; better software certification methods (e.g. for aviation and medical applications); and new techniques for real-time applications. Specifically, the research brings concepts of Lyapunov invariance and associated computational procedures, widely applied in control theory, to the context of real-time, embedded software. The goal is to provide behavior certificates, in the form of numerical Lyapunov invariants, that the software will perform according to some desired specifications. The central idea of the research is to use techniques such as Lagrangian relaxation and convex optimization to produce certificates that (for example) all variables will remain within acceptable ranges and that, when so required, the program will finish in finite time. A considerable economic benefit is to be gained from partial automation of the software analysis process, in particular static analysis, and this research is expected to yield a broad new class of techniques for this purpose. Furthermore, the techniques being studied complement and extend emerging techniques for abstract interpretation of programs.<br\/> The research pursues several specific objectives: development of dynamical system representations of software systems that are suitable for analysis via Lyapunov invariants, development of methods to compile relevant programs expressed in commonly used languages (such as C) into these dynamical system models; identification of Lyapunov-like invariants via linear programming and\/or semidefinite programming to automatically establish key properties of software; definition and preliminary implementation of an automated software analysis tool, whose outputs are certificates of proper program behavior; adaptation of the above efforts to scale up to large computer programs; and finally implementation of the described methods on significant examples arising from the literature and from existing safety-critical software routinely used by MIT.","title":"SGER: Convex Optimization of Lyapunov Certificates for Software Behavior Systems","awardID":"0451865","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["384455","384455","495325"],"PO":["561889"]},"100801":{"abstract":"Proposal Number: 0447420<br\/><br\/>TITLE: Cyber Trust PI Meeting<br\/><br\/>PI: Donald J. McGillen<br\/><br\/>Abstract:<br\/><br\/>Carnegie Mellon University will host a meeting of Cyber Trust Principal Investigators and others interested in Cyber Trust research areas at a hotel located in Pittsburgh, Pennsylvania August 18, 2004 - August 20, 2004. The purpose of the meeting is to convene the set of Principal Investigators funded under the NSF to pursues research in the Cyber Trust emphasis area. The meeting will encourage synergy among the researchers and research projects by means of planned technical sessions and opportunities for informal discussion. A public website will provide information about the workshop and will archive the talks and papers presented at the workshop","title":"Workshop: Cybertrust PI Meeting; August 18-20, 2004; Pittsburgh, PA","awardID":"0447420","effectiveDate":"2004-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["344850"],"PO":["521752"]},"100207":{"abstract":"This Small Grant for Exploratory Research will take advantage of opportunities arising from an earlier grant from the Digital Govnernment program (9983468) and has two objectives: <br\/><br\/>1. Quickly, while government program managers who partnered on the earlier award are still in place, develop backend systems that allow data sharing among different agencies and the front-end interface system that will be visible to the citizens and businesses of the State of New Jersey. This effort will lead to technology transfer of the prototype system to the State of New Jersey. <br\/><br\/>2. Conduct a transnational comparison evaluation study of similar human-centered systems for government on-line services in European Union countries. This effort will provide critical knowledge for developing US\/EU digital government research collaborations and might lead to technology sharing among several countries. The study will concentrate on developing a methodology for comparative analysis and surveying of the European case literature, and will help establish common discussion areas between different projects and programs that aim to achieve the similar objectives.","title":"SGER: Technology Transfer of Inter-Agency Government Services and Their Transnational Feasibility Studies","awardID":"0443591","effectiveDate":"2004-09-01","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":[264401,"543481"],"PO":["371077"]},"99081":{"abstract":"This project will identify social and technical areas (and questions) where the <br\/>state of today.s technical knowledge is inadequate to provide reasonable <br\/>answers. A better understanding of these areas will be useful both to policy <br\/>makers, including elections officials, whose decision making should take note of <br\/>the limits of today.s technical understanding and where further research could <br\/>improve the voting process, and to researchers who would seek to remove those <br\/>limits in the future. <br\/> <br\/>The results will be useful in their own right, but this project is conceptually the first <br\/>phase of a more comprehensive project on electronic voting that would assess <br\/>evidence about a broader set of issues in the use of information technology in <br\/>the electoral process. That is, that larger project.should support be obtained.<br\/>would use the results of this project as a point of departure for an effort that <br\/>would enable a much deeper and more thorough exploration of the issues <br\/>raised in the report from this project.","title":"A Framework for Understanding Electronic Voting","awardID":"0436133","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["298189","298190","560890"],"PO":["371077"]},"98190":{"abstract":"Proposal: NSF-0430425<br\/><br\/>Title: Securing Untrusted Software with Interposition<br\/><br\/>PI: David Mazieres<br\/><br\/>Abstract<br\/><br\/>The principles for building secure computer systems have been known for decades. Yet violating them---by assuming elevated privilege, for example---makes application development so much easier on conventional operating systems that it's doubtful the principles will ever be broadly followed there. This research program investigates a new operating system design, Asbestos, that allows applications to be completely secured by third parties, such as system administrators, without help from application authors themselves. The fundamental Asbestos security primitive is interposition, whereby programs can easily interpose upon, monitor, and control any or all interactions between an application and the rest of the system. Unlike previous systems, this includes interactions with other applications as well as system services. Interposers correspond to security policies, or per-application firewalls. They can block or virtualize undesired accesses, so that legacy applications that demand inappropriately high privilege can run in a less-privileged setting. Design challenges include making system interactions easy for interposers to understand, and developing a convenient library of security policies built from interposition components. A successful Asbestos design has the potential to significantly improve the security of critical systems, even those running insecure applications. Source code will be released publicly under an open-source license.","title":"CT:Securing Untrusted Software with Interposition","awardID":"0430425","effectiveDate":"2004-09-15","expirationDate":"2006-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T221","name":"DARPA-ASBESTOS SECURING UNTRUS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V842","name":"DARPA-ASBESTOS SECURING UNTRUS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["562011","541752","462739","541961"],"PO":["521752"]},"87080":{"abstract":"Learning to Perform Moderation in Online Forums<br\/><br\/>Online discussion forums are a valuable resource for people looking to find information, discuss ideas, and get advice on the Internet. The number of forums continues to grow rapidly, covering such topics as politics, technical news and advice, medical issues, and product ratings and opinions. Unfortunately, many forums have too much activity, resulting in information overload. Moderation systems are implemented in some forums as a way to handle this problem, but due to sparsity issues, they are often not sufficient. This project is aimed at automating the moderation process, which currently relies entirely on humans. A framework for learning to perform machine moderation is developed by finding patterns in the moderations made by humans. Four fundamental research challenges are addressed: (1) Identify features that define a good or bad comment and develop methods to extract these features efficiently; (2) Develop classifiers that can be trained to moderate arbitrary comments with high accuracy; (3) Use the knowledge acquired in training on moderated forums in different, possibly unmoderated, forums; (4) Develop a system to combine human and machine moderation effectively. Millions of people already use online forums on a regular basis. This project will produce technology that will improve the quality of service provided to users of online forums and reduce the cost of operation by reducing substantially the amount of human moderation that is needed. The broader impact of the project includes training graduate and undergraduate students at the University of Massachusetts, traditional and non-traditional dissemination effort involving deployment of the resulting technology, and a newly formed alliance with an international research team at INRIA, France.<br\/><br\/>http:\/\/anytime.cs.umass.edu\/shlomo\/research\/MODERATE.html","title":"Learning to Perform Moderation in Online Forums","awardID":"0328601","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["485994"],"PO":["563751"]},"98091":{"abstract":"Some pictorial styles differ dramatically and can be distinguished without scrutinizing the picture, for example, Pointillist vs. Renaissance; or a photograph by a master vs. a casual snapshot. The investigators explore pictorial style using quantitative measurements, leading to a parametric characterization that captures coarse-grain pictorial style. The research has several applications in computer graphics and image analysis, with broad technological impact on society. It can be embedded in image classification and retrieval tools. For digital photography, it can transfer the style of master photographers to casual snapshots, leading to important quality enhancement. In addition, it will lead to novel and intuitive image manipulation tools that act directly on stylistic aspects. Finally, such statistical estimators might help in the future to understand what makes images photorealistic and lead to filters that increase realism. This research project is accompanied by an interdisciplinary course on the \"art and science of depiction,\" and by an inter-disciplinary workshop on image statistics. <br\/><br\/>The research studies marginal and joint statistics of oriented multiscale decompositions such as steerable pyramids. The investigators develop a new recursive pyramidal decomposition that captures the spatial variations of \"texturedness\" over an image. They also explore the statistics of edge features, and they devise new non-linear edge-preserving decompositions to prevent haloing artifacts at strong edges during style transfer. Finally, the research explores a new approach to color style characterization based on the notion of naming color category. The purity of a color is defined as its distance to a color prototype such as pure blue, and statistics of this purity are leveraged to assess and enhance color vividness. Success of the style characterization is evaluated by classification tasks (supervised learning) and by style transfer: the relevant statistics of a source image or set of images are enforced in a destination image. The visual modification of the destination image permits the assessment of which stylistic aspects are captured by the statistics, independently of content. The research builds on the synergy between visual perception, image analysis and computer graphics.","title":"Parametric Analysis and Transfer of Pictorial Style","awardID":"0429739","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["485699"],"PO":["532791"]},"98290":{"abstract":"The transmission, storage, and related processing of video are important technical problems in today's society. Progress related to the efficient representation of video is of increasing importance for personal mobile electronics and for Internet applications. Video coding algorithms are often based on motion-compensated predictive coding. The project involves an original approach for video representation that is based on recent developments in wavelet theory: recently developed transforms are designed<br\/>to overcome basic problems that degrade the performance of the wavelet transform when it is applied to multidimensional data using the standard separable implementation.<br\/><br\/> The standard separable 3-D wavelet transform is rarely used for video compression because it mixes 3-D orientations in its subbands; this artifact reduces the effectiveness of the separable transform for providing an efficient representation of video. However, the new 3-D wavelet transform is free of the mixing artifact and gives a meaningful multi-scale decomposition for video. With the new transform, it is more likely that the multiresolution frame work, which has proved very effective for image compression and efficient feature extraction, can also be effectively applied to video representation. The new transform isolates motion in different directions in separate subbands, so the direction of motion can be inferred to some degree from the wavelet coefficients.","title":"Video Coding using a 3-D Motion-Selective Wavelet Transform","awardID":"0431051","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["491898","451533"],"PO":["564898"]},"98180":{"abstract":"Proposal CNS-0430336<br\/><br\/>Title: New Complexity-Theoretic Techniques in Cryptography<br\/><br\/>PI: Salil P. Vadhan<br\/><br\/>The research focuses on several powerful techniques from computational complexity (the study of problems that are computationally intractable) that they may help in addressing important open problems in cryptography and security. These techniques include randomness extractors, Nisan-Wigderson-type pseudorandom generators, complete problems, diagonalization, and non-black-box use of an algorithm's code.<br\/>The efforts include both strengthening existing applications of these complexity-theoretic techniques, such as doing cryptography with human-memorizable passwords, mitigating the effect of key exposure, and biometrics; and seeking new applications, especially to problems that have remained beyond the scope of standard techniques in cryptography, such as proving the security of Fiat-Shamir-type digital signatures, doing public-key cryptography from one-way functions with no trapdoor, and understanding the extent to which obfuscation, watermarking, and homomorphic encryption are possible. The research is foundational in nature, yet it can impact a variety of problems of practical interest in trustworthy computing.<br\/>The research will be closely integrated with educational efforts, through new courses developed at Harvard and the involvement of both graduate and undergraduate students in the research.","title":"New Complexity-Theoretic Techniques in Cryptography","awardID":"0430336","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["525639"],"PO":["521752"]},"98070":{"abstract":"0429590\/0429595<br\/>Collaborative Research: Well-Founded Behavioral Software Contracts<br\/><br\/>Robert Bruce Findler<br\/>Matthias Felleisen<br\/><br\/>MacIlroy's vision of a marketplace of software components requires enforceable contracts. Such a contract describes the expectations and obligations of a contract; its enforcement system decides whose fault it is when a program breaks a contract. <br\/><br\/>The first goal of this project is to investigate the nature of behavioral contracts and mechanisms for monitoring contracts for all kinds of component mechanisms, including classes, mixins, aspects, modules, and related constructs. The second goal is to study how contracts can help improve static analyses and how static analyses can partially verify contracts. Finally, the project team will conduct an experiment with a component marketplace to test their software contracts and contract monitoring systems. <br\/><br\/>In the long term, this research may help establish a truly competitive marketplace of software components. In this marketplace, components will come with open-source contracts. Alternate suppliers can then produce components with near-equivalent contracts, and consumers can choose from an array of interchangeable components.","title":"Collaborative Research: Well-Founded Behavioral Software Contracts","awardID":"0429590","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["518591"],"PO":["564388"]},"98092":{"abstract":"PROPOSAL ID: 0429743<br\/>PI: Mike Bushnell (Rutgers U), Vishwani Agrawal (Auburn U)<br\/>TITLE: Spectral Built-In Self-Testing for Mixed-Signal Systems-in-a-Package <br\/><br\/> Abstract: <br\/>In this research the PIs propose a new application of the theory of signals and systems to testing digital systems-in-a-package (SIPs). Digital input signals are considered as a set of time-varying waveforms, characterized by a correlation matrix. The elements of this matrix are the auto-correlation and cross-correlation coefficients, determined from inputs that have known fault and error detection properties. The auto-correlation indicates how a signal resembles its own past, and the cross-correlation indicates how a signal resembles other signals.<br\/><br\/>The PIs propose a completely integrated built-in self-testing (BIST) system for huge digital hardware systems. Rather than inserting a full-scan chain and using combinational BIST, digital circuit spectral analysis techniques is used to determine which flip-flops (memory elements) to scan to simplify the testing. Subsequent topologically analysis of the digital part of the system is made to determine its necessary spectral testing frequencies in partial-scan mode at each primary input. Finally, one inserts low-overhead spectral BIST hardware to generate these frequencies and uses a novel response compacter for BIST, which calculates the cross-correlation between various primary outputs as a signature. Spectral BIST uses less hardware than the conventional BIST system, covers 8.4% more of the faults in sequential mode, but requires less than 10% of the patterns.<br\/> <br\/>The benefits of these concepts would be drastically shorter test pattern sequences, compared with present-day BIST, but high fault coverage. This leads to economic benefits of a large power reduction in test mode, and shorter test time. Other benefits are simplified testing hardware and lower hardware overhead. We will create a spectral analysis method to insert the testing hardware into the sequential circuit to raise its fault coverage. The PIs plan to topologically analyze sequential circuits to determine the predominant spectra of their input responses. This is expected to accelerate spectral analysis, since one can avoid analyzing parts of the spectrum that the circuit could never generate.","title":"Spectral Built-In Self-Testing for Mixed-Signal Systems-in-a-Package (SIP)","awardID":"0429743","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["485659","260890"],"PO":["562984"]},"100727":{"abstract":"Intellectual Merit<br\/><br\/>This proposal seeks to sponsor U.S. faculty and researchers to attend the first SINO-US<br\/>Workshop on Computer and Computational Sciences (WCCS) to be held in Beijing 2005. The<br\/>purpose of the workshop is to strengthen research exchange in computer sciences, and to<br\/>promote successful collaborations between experts in the field. WCCS provides a forum for<br\/>presenting the latest advances in computer and computational sciences, engineering, and<br\/>technologies. It also provides a platform for discussing the practical challenges<br\/>encountered and the solutions adopted thus far. <br\/><br\/>Broader Impact<br\/><br\/>A particular aim of WCCS is to bridge the gap between the research community and the<br\/>application domains, and to foster discussion and technology exchange between these two<br\/>communities within the two geographic regions (US and Asia). As such, we have invited<br\/>top-notch researchers in the computer science community to serve on the Technical<br\/>Program Committee. <br\/>We believe that by offering funding for selected U.S. scientists (who would not otherwise<br\/>be able to attend due to monetary obstacle), these individuals and the overall workshop <br\/>goals will benefit. Travel support for attendance will be advertised nationwide; women,<br\/>minorities and disabled faculty and researchers will be especially encouraged to apply for<br\/>sponsorship.<br\/><br\/>The foremost goal is to establish contacts for future collaborations and to allow for ideas<br\/>and solutions to be exchanged.","title":"WORKSHOP: Advances in Computers and Computational Sciences.","awardID":"0447079","effectiveDate":"2004-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["453727","292276"],"PO":["565272"]},"98192":{"abstract":"ForNet: Design and Implementation of a Network Forensics System<br\/><br\/>Nasir Memon, Polytechnic University of NY<br\/><br\/>Award 0430474<br\/><br\/>Abstract<br\/><br\/>This project proposes to address the lack of effective tools for aiding investigation of malicious activity on the Internet and other private IP based networks such as corporate and government networks. The broad goal of this project is to study and demonstrate the technical feasibility of building an appropriate network forensics system and establish the technical foundations for such an infrastructure. Although the vision and motivation behind a network forensics system may be compelling, the algorithms and techniques that will make it possible are challenging endeavors.<br\/><br\/>A proof of concept prototype network forensics system will be built. The prototype system will consist of forensics modules called SynApps that will create and store intelligent synopses of packet traffic entering and leaving a network. Multiple such forensics modules will be networked via a Forensics Server. The Forensics Servers are then networked across an intranet or the Internet to result in a Forensics Network (ForNet).<br\/><br\/>The activities of the project will be carried out in co-operation with experts in criminal justice, and a small prototype system networked between the communities will be built and deployed. The Information Systems and Internet Security (ISIS) Laboratory at Polytechnic University will be used as the vehicle for integration of the proposed research activity into class projects and undergraduate research projects done on the security testbed in ISIS.<br\/><br\/>The ForNet will be able use synopsized network traffic to answer questions in investigations of many varieties of attacks against networks and systems.","title":"ForNet: Design and Implementation of a Network Forensics System","awardID":"0430444","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["311538","512465","559652","280545","311540"],"PO":["565090"]},"98082":{"abstract":"The focus of this research proposal is to develop tool support to provide the ability for scientific programmers to inquire about scalability problems and correlate this information back to source code. Furthermore, we believe that tools should be able to suggest and evaluate optimizing transformations to alleviate these problems. This would constitute a significant improvement over current performance analysis practice.<br\/><br\/>The key intellectual merit is in providing an automatic framework for detecting scalability problems and<br\/>correlating them back to source code. We will experiment with our framework on the ASCI codes, which<br\/>is intended to stress high-performance clusters.<br\/><br\/>The broader impact of this work is in three main areas. First, both PIs are working to create an interdisciplinary educational and research program. Second, students will be educated in high-performance<br\/>computing. Finally, the proposed work allows for technology transfer to a wide arena of emerging fields,<br\/>such as cluster computing as well as the established areas of SMPs and massively parallel computing.<br\/>The developed framework and tools will be made generally available to the research community and high-performance computing labs.","title":"Collaborative Research: Effective Detection and Alleviation of Scalability Problems","awardID":"0429653","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["558579","553590"],"PO":["565272"]},"100948":{"abstract":"Recently, it has been recognized that power management to control temperature is vitally important. In fact, in May Intel abruptly announced that it had scrapped the development of two new computer chips (code named Tejas and Jayhawk) for desktops\/servers in order to rush to the marketplace a more efficient chip technology more than a year ahead of schedule. Analysts said the move showed how eager the world's largest chip maker was to cut back on the heat its chips generate. Intel's method of cranking up chip speed was beginning to require expensive and noisy cooling systems for computers.<br\/> There is an extensive literature on power management in computing devices, and there is an extensive literature on power management in ad-hoc and sensor networks. Yet almost all of this literature focuses on power management to conserve energy, and not on power management to reduce temperature. Temperature and energy are different physical entities with quite different properties. Bluntly, if the processor in your mobile device exceeds its energy bound, your battery is exhausted, but if your mobile device exceeds it thermal threshold, your processor dies.The need to manage power to reduce temperature will become increasingly important as device power consumption is growing exponentially, and as ad-hoc and sensor networks become more prevalent. We propose to reexamine power management problems from a temperature perspective to try to better understand the difference between managing power to conserve energy and managing power to minimize temperature. We plan to start with speed scaling problems within devices and with routing problems in ad-hoc networks. It is anticipated that this project will produce novel optimization techniques and analytical results that will be useful in the design of temperature-efficient protocols for large-scale ad-hoc and sensor networks. The work will be a joint inter-disciplinary effort, involving investigators with expertise in on-line algorithm design and in network protocol design and development. It is further anticipated that the project will provide students with a unique opportunity to investigate and experiment with new ways of thinking about important design parameters for this emerging class of networks.","title":"Algorithmic Support for Temperature Aware Computing and Networking","awardID":"0448196","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["534213"],"PO":["499399"]},"96290":{"abstract":"This project involves collaboration between the PI at the US Air Force Academy, and partners at SRI International, and the University of Colorado. The project involves building and testing a prototype of a platform that integrates shared work in educational domains. The platform facilitates opening of a series of new and instructionally potent interactive pathways: each student interacts with his or her personal agent in solving problems or acquiring new curricular concepts, the professor can also direct the agents, and all of them -- professor, student or agent -- have immediate access to the curriculum-tailored library of applets that provide clarifying visualizations, simulations, animations or fuller explanations of curriculum concepts. The agents communicate with each other and can aggregate instructionally specific data across the class for the professor. The professor also has a perceptive agent in his or her space to organize data but also to serve as an observer that can debrief with the instructor and with other agents. The three IT advances that are integrated in this project involve shared workspaces; digital libraries; and perceptive animated agents. The curriculum development research involves teams of upper level computer science students and educators who collaborate in the creation of applet libraries that are customized for individual curricula. The deliverables for this project include: Shared Workspaces, Applets, and Perceptive Agents. For the purposes of this project, a Shared Workspace involves a software application -- such as a programming editor or electronic sketchpad -- that is networked and shared by different users in a \"What You See Is What I See\" or WYSIWIS manner and that also permits teacher-to-class screen broadcasting. This project's foci lie with instructionally sophisticated WYSIWIS architectures whose interfaces feature authentic classroom metaphors. In the context of this project, Applets are portable \"mini-programs\" that produce text or video explanations, simulations, visualizations, animations, or graphical representations of course concepts. And, finally, the Perceptive Agents developed for ALASKA enable a form of personal tutoring, where the agent-tutor and student work closely together in a virtual one-on-one setting. Agents in this project engage in simple dialogs with students to help fulfill their goals; they have three possible classes of responses to student requests: 1) give an answer or invoke an applet; 2) engage in a clarification dialog with the student; or 3) pass the history of the interaction to the teacher or agent network for resolution. This project's framework is easily translated to classroom settings for many other disciplines with compatible curricula as well as to asynchronous learning environments. The proposal capitalizes on and extends substantial investments by NSF and others in animated agent technologies, digital library production, and participatory design models for crafting high quality and usable education objects, and collaborative lesson-studies.","title":"CRCD\/EI: ALASKA: Applet and Library Augmented Shared Knowledge Areas","awardID":"0420310","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["524324","551122",252458,"91250"],"PO":["563751"]},"97071":{"abstract":"This project, developing practical tools for more effective performance evaluation of networked applications and furthering work in adaptive streaming media repair, studies end-user performance perception in network applications through an integrated framework considering user, application, and network layers. The research considers diverse network applications, aiming at bridging the gap in understanding the increased diversity resulting from the rapid rise of these new applications. Often, precise information is lacking regarding how the network improvements benefit the network application. Thus, assessing the benefits of new network treatments becomes difficult, and so does designing the next generation networks that will effectively support QoS of emerging applications. An Application Performance Studies Laboratory will be developed addressing finely control network performance for a range of selected applications. As appropriate, each of the projects will share research resources in the new lab to measure performance for interactive applications, network games, and streaming media repair. Specifically, the infrastructure enables the following projects:<br\/> Integrating measures of network performance with user perception,<br\/> Quality of service for network games, and<br\/> Perceived quality of adaptive streaming media repair.<br\/>The methodology employed integrating network performance with end-user application performance allows targeting studies of new applications on emergent networks. The work should culminate in advancing tools measuring the impact of the network and application level treatments on the end-user performance. Novel mechanisms for adaptive streaming media repair are expected.<br\/><br\/>Broader Impact: The research involves strong integration of research and education, enriching education with exciting possibilities in CS research. Undergraduate senior projects will be instrumental in realizing the preparation of network applications for effective studies. Additionally, a new related undergraduate major will be developed.","title":"Research Resources for Network Application Studies","awardID":"0423362","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":[255325,"435447","435449"],"PO":["557609"]},"98171":{"abstract":"Proposal Number: CNS-0430254<br\/><br\/>TITLE: A Survivable Information Infrastructure for National Civilian BioDefense<br\/><br\/>PI: Rafail Ostrovsky <br\/><br\/>This project focuses on the theoretical foundation and the protocols that facilitate a survivable information infrastructure that meets the critical requirements of a national emergency response system. Specifically, the project will address the following challenges:<br\/>(1) expand the existing theoretical framework to analyze the behavior of malicious and colluding participants; (2) design and construct a scalable survivable messaging system that operates correctly under a strong adversarial model that includes insider threat and denial of service attacks; (3) design and construct information access protocols that protect against compromised database servers providing incorrect data or servers that deny access to legitimate users; and (4) prevent malicious users from learning unauthorized information. The domain of application for this work is the Clinicians' Biodefense Network (CBN), a nationwide Internet-based information exchange system designed to provide clinicians with critical information in the aftermath of a bioterrorist attack. The CBN is designed to mitigate benign Internet faults and to resist a physical attack on one location. However, it is not able to correctly operate under a stronger threat model that includes insider attacks. Solutions for this stronger threat model are not currently available and present a major research challenge. This project will construct a prototype survivable system based on the CBN, and from it draw general principles. It will develop a solid theoretical foundation and novel system tools to facilitate building national emergency networks that are resilient against cyber-attacks in crisis situations, when those networks are most urgently needed.","title":"Collaborative Research: A Survivable Information Infrastructure for National Civilian BioDefense","awardID":"0430254","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["533831"],"PO":["521752"]},"98061":{"abstract":"ABSTRACT<br\/><br\/>PI: John Lambris <br\/>Institution: University of Pennsylvania<br\/>Proposal Number: 0429534<br\/><br\/>Research: <br\/><br\/>A challenge in computational protein design is the discovery of novel proteins, which are compatible with either target template structures or arbitrarily three dimensional structures. This research is a dynamically data driven application systems, (DDDAS), effort through an integrative research framework, (i.e., computational, physicochemical, and biochemical approaches) for the in silico de novo design of peptides and proteins. The primary aims of the project are (i) in silico sequence selection and folding specificity calculations through a novel computational framework that is based on mixed-integer optimization and deterministic global optimization, (ii) in vitro and in silico characterization via NMR, structure determination, and molecular dynamics, (iii) protein expression, structural characterization and activity measurements of predicted sequences, and (iv) the development of a web-based WorkBench support system for de novo peptide\/protein design which will be freely available to all researchers. The biological systems for testing and validating the proposed framework include the C3a anaphylatoxin (aims (i)-(iv)), and human beta defensins (aims (i), molecular dynamics of (ii) and (iv)). <br\/><br\/>Intellectual Merit:<br\/><br\/>The planned effort involves an interdisciplinary team (Floudas, Lambris, Morikis) from three institutions (Princeton, U. Penn, U. California at Riverside). Their expertise spans the fields of complement biology, protein chemistry, structural biology, mathematical modeling and analysis, combinatorial and global optimization, scientific computing, and bioengineering, and the project is an integrative computational and experimental effort. These developments can expedite significantly the drug discovery process, address important tasks in the design of new drugs, and the proposed novel concept of a web-based WorkBench will be the first such service to the scientific community. <br\/><br\/>Broader Impacts: <br\/><br\/>Using IT and DDDAS techniques, in a uniquely symbiotic computational and experimental framework, this project will lay the groundwork for making significant advances in the discovery of new drugs. This framework for in silico prediction of new sequences which fold selectively to structural templates and their experimental validation will allow rapid screening of novel alternatives and will lead into better and faster drug discovery which has direct impact in our society. The proposed effort integrates participation of graduate students, postdoctoral students, and undergraduate students into the research, thereby providing multidisciplinary training opportunities. The co-PIs have records in research with undergraduate students as part of their junior independent work, as well as senior thesis work. All three institutions have policies for attracting students and employees from traditionally under-represented groups. The co-PIs are committed to working with these students and will work pro-actively to attract them to this research project, the seminar series, the journal club, and the graduate level course. The co-PIs have strong records of educating undergraduate and graduate students, and post-doctoral associates from under-represented groups. The results of the research will be disseminated to the entire scientific community through publications in archival journals, refereed proceedings, and via presentations at conferences. Furthermore, the development of the web-based WorkBench for the de novo design of peptide\/proteins will provide, for the first time, service to the scientific community.","title":"ITR: Collaborative Research: (ASE+NHS+EVS)-(sim+dmc+int): In Silico De Novo Protein Design: A Dynamically Data Driven, (DDDAS), Computational and Experimental Framework","awardID":"0429534","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7368","name":"SCI TESTBEDS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":[258239],"PO":["565229"]},"87061":{"abstract":"Music Information Retrieval (MIR) is a new and vibrant international, multidisciplinary research endeavor that strives to develop innovative content-based searching schemes, novel interfaces, and evolving networked delivery mechanisms in an effort to make the world's vast store of music accessible to all. Librarians, musicologists, psychologists, audio engineers, music teachers and students, computer scientists, legal experts, music rights-holders, and business executives are all involved. This project is designed enhance the efforts being made to establish a scientific evaluation paradigm within the MIR research community. Major issues addressed in this project include the comprehension of the complex nature of music information; adequately capturing the complex nature of music queries; and an in-depth examination of the \"relevance\" problem in the MIR context. To these ends, this project undertakes the creation of comprehensive set of data-rich query records that are both grounded in real-world requirements and neutral with respect to retrieval technique(s) being examined; the adoption, and subsequent validation, of a \"reasonable person\" approach to \"relevance\" assessment; the establishment of scientifically valid experimental protocols; and, the ongoing acquisition of music information (audio, symbolic and metadata) to enhance the development of a secure, yet accessible, research environment that allows researchers to remotely participate in the use of the large-scale testbed collection. Because this project significantly enhances the infrastructure of MIR research, it plays a pivotal role in improving access to the world's vast music resources. Thus, this project impacts the way music lovers, scholars, educators, students, industrial and commercial developers, and all other interested parties, will be interacting with music in the future. The project Web site (http:\/\/music-ir.org) provides access to the research materials, publications and updates.","title":"Toward the Scientific Evaluation of Music Information Retrieval Systems","awardID":"0328471","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["262170","559417"],"PO":["433760"]},"98072":{"abstract":"0429590\/0429595<br\/>Collaborative Research: Well-Founded Behavioral Software Contracts<br\/><br\/>Robert Bruce Findler<br\/>Matthias Felleisen<br\/><br\/>MacIlroy's vision of a marketplace of software components requires enforceable contracts. Such a contract describes the expectations and obligations of a contract; its enforcement system decides whose fault it is when a program breaks a contract. <br\/><br\/>The first goal of this project is to investigate the nature of behavioral contracts and mechanisms for monitoring contracts for all kinds of component mechanisms, including classes, mixins, aspects, modules, and related constructs. The second goal is to study how contracts can help improve static analyses and how static analyses can partially verify contracts. Finally, the project team will conduct an experiment with a component marketplace to test their software contracts and contract monitoring systems. <br\/><br\/>In the long term, this research may help establish a truly competitive marketplace of software components. In this marketplace, components will come with open-source contracts. Alternate suppliers can then produce components with near-equivalent contracts, and consumers can choose from an array of interchangeable components.","title":"Collaborative Research: Well-Founded Behavioral Software Contracts","awardID":"0429595","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["475166"],"PO":["564388"]},"98094":{"abstract":"NSF 0429753 Autostereoscopic Visualization and Geometric Computing for<br\/>Biological Macromolecules<br\/><br\/>The planned research seeks to develop tools and techniques for<br\/>visualization and geometric reasoning for large proteomics data. The<br\/>proposed research has three main components -- implicit-function-based<br\/>representations for proteins, faster computation of protein<br\/>electrostatics, and real-time auto-stereoscopic visualization. The<br\/>research will develop a unified framework of implicit functions that<br\/>can compactly and efficiently represent non-bonded protein properties<br\/>including protein electrostatics and accessibility. By tightly coupling<br\/>these properties, implicit-function-based representations will likely<br\/>result in synergistically favorable crossovers in the solutions to these<br\/>problems. Further, providing adaptive, progressive, and hierarchical<br\/>representations for implicit functions will allow them to be used in<br\/>multiresolution schemes for storage, transmission, and computational<br\/>steering. Protein electrostatic interactions are of central importance for<br\/>many biological processes. Autostereoscopic visualization of proteins<br\/>and their properties is important in understanding the 3D structure of<br\/>proteins. The proposed research will develop new methods for rendering<br\/>implicit surfaces and volumes using the recent advances in graphics<br\/>hardware as well as adapt efficient methods for autostereoscopic displays<br\/>with personalization.","title":"Autostereoscopic Visualization and Geometric Computing for Biological Macromolecules","awardID":"0429753","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["543581"],"PO":["532791"]},"96291":{"abstract":"Title: ITWF Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science<br\/><br\/>CNS 0420436, PI Horwitz, Univ. of Wisconsin-Madison<br\/>CNS 0419340, PI Huss-Lederman, Beloit College<br\/>CNS 0420312, PI Munson, Univ. of Wisconsin-Milwaukee<br\/>CNS 0420337, PI Dunsmore, Purdue University<br\/>CNS 0420343, PI Rodger, Duke University<br\/>CNS 0420358, PI Binkley, Loyola College of Maryland<br\/>CNS 0420368, PI Biggers, Georgia Institute of Technology<br\/>CNS 0420433, PI Ryder, Rutgers University<br\/><br\/><br\/>This collaborative ITWF project implements a new approach to introductory computer science with the goal of increasing the enrollment and retention of women and under-represented minorities in undergraduate computer science degree programs. The project adapts the Emerging Scholars Program and the Peer-led Team Learning approaches, which have been proven successful in mathematics and other sciences, to computer science. It is a collaborative project between the University of Wisconsin-Madison, Beloit College, Duke University, Georgia Institute of Technology, Loyola College of Maryland, Purdue University, Rutgers University, and the University of Wisconsin-Milwaukee. The project includes targeted recruitment of students with strong mathematics and science backgrounds to the new course. The course includes students working in small groups on challenging problems with group facilitation by outstanding undergraduates.<br\/> <br\/>The intellectual merit of this project lies in the strong basis on models that have been successful in other disciplines. The collaborative represents a team of investigators with significant expertise in educational reform and transformation. Implementation will take place at the diverse set of institutions represented by the collaborative partners, thus providing an excellent environment for evaluation of this innovative approach and illustrating the possibilities for replication and adoption by a wide range of institutions.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science. The method to be tested is relative low cost and straightforward to implement, thus it has a high potential for broad impact across the country.","title":"ITWF: Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science","awardID":"0420312","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["367915"],"PO":["361119"]},"98480":{"abstract":"The self-assembly process for bottom-up construction of nanostructures is of<br\/>fundamental importance to the emerging discipline of Nanoscience. For example,<br\/>the self-assembly of DNA tile nanostructures into 2D lattices can be used to<br\/>manufacture patterned nanostructures from smaller unit nanostructures<br\/>components known as DNA tiles on which other molecules such as metallic<br\/>particles and proteins can be affixed, and DNA tiling lattices can be used to<br\/>perform parallel universal computation. However, self-assemblies at the<br\/>molecular scale are prone to a quite high rate of error, ranging from<br\/>approximately between 0.5% to 5%, and the key barrier to large-scale<br\/>experimental implementation of DNA tiling is this significant error rate in the self-assembly<br\/>process. The problem of tiling errors is particularly critical for DNA<br\/>lattices that use computational tilings to produce complex patterns, The limitation<br\/>and\/or elimination of these errors in self-assembly is perhaps the single most<br\/>important major challenge to nanostructure self-assembly. The goals of the<br\/>proposed research are to develop methods for error-resilient self-assembly; to<br\/>analyze these by probabilistic, kinetic analysis and computer simulation; and to<br\/>demonstrate these error-resilient self-assembly methods by a series of laboratory<br\/>experiments. Research will be done in the context of DNA tiling assemblies. Prior<br\/>work by Winfree provided a method to decrease tiling self-assembly errors<br\/>without decreasing the intrinsic error rate of assembling a single tile, however, his<br\/>technique resulted in a final assembled structure that is four times the size of the<br\/>original one. This research team at Duke University has developed compact<br\/>error-resilient tiling methods that do not increase the size of the tiling assembly.<br\/>They will test their new error-resilient tiling methods that use overlay redundancy<br\/>such that a single pad mismatch between a tile and its immediate neighbor forces<br\/>one or more further pad mismatches between adjacent tiles in the neighborhood<br\/>of this tile. The research will use a combination of theoretical and experimental<br\/>methods. Theoretical probabilistic kinetic analysis and empirical studies of the<br\/>computer simulation of tilings will first be used to validate these error-resilient<br\/>overlay redundancy tiling methods; the analysis will allow prediction of the<br\/>reduced error rate and verify the speed of the assembly is not reduced. Following<br\/>this, actual experimental demonstrations will be made using DNA tiles, The<br\/>overall goal is to demonstrate the feasibility of error-free assemblies of thousands<br\/>of tiles.","title":"Nano: Error-Resilient DNA Tiling Assemblies","awardID":"0432038","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["550822","531216"],"PO":["521045"]},"98271":{"abstract":"Abstract:<br\/><br\/>The field of distributed networking and computation is on the verge of a technological revolution. Emerging applications in national security, transportation, communication, and commerce require distributed networks to be capable of multi-user communication and collaborative signal and information processing. One very important component of these networks is the underlying communication channel. These channels have memory, are often time-varying, and are often poorly modeled. Furthermore, in many of these networks, the nodes are power limited and only have modest computational resources. Feedback is a very important, though poorly understood, feature of modern communication systems. Feedback is useful because it can increase the capacity of a given channel with memory; it can increase the error exponent and hence decrease latency; it often leads to simpler coding schemes; and it allows the encoder to adapt to unknown channel variations.<br\/><br\/>This research involves: (1) determining the fundamental limits and tradeoffs between the quality of channel feedback and the resulting Shannon capacity of the channel; (2) developing the sequential rate distortion theory for joint-source channel coding; (3) analyzing the convergence and accuracy of message-passing algorithms in general; and (4) developing message-passing, error-correcting codes specialized for channels with memory and feedback. The investigators use tools from the study of graphical models to jointly treat communication complexity and computational complexity.","title":"Capacity and Coding Techniques for Channels with Memory and Feedback","awardID":"0430922","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["517534"],"PO":["348215"]},"98172":{"abstract":"Trustworthy photographs play an important role in many applications such as news reporting, intelligence information gathering, criminal investigation, security surveillance, as well as health care. However, with the advent of digital age, the trustworthiness of pictures could no longer be taken for granted. This project will develop a completely blind and passive system for detecting digital photograph tampering. No extra encryption, signature extraction, or information embedding processes are needed. Content tampering operations are detected at the point of checking by analyzing the natural signal\/scene characteristics in the image. <br\/>We take an innovative approach integrating techniques from signal processing and computer graphics. The signal processing method involves effective use of higher-order signal statistics, signal acquisition device modeling, image decomposition, and image structural analysis to identify tampering artifacts at the signal level. The computer graphics approach includes novel techniques of 3D geometry estimation, illumination field recovery, and scene reconstruction to detect inconsistency at the scene level like shadows, shading, and geometry. <br\/>We aim at a successful system that makes any attacking maneuver as difficult as possible. The system will also provide equal emphasis on robustness and informativeness - suspicions will be explained with locations and reasons. To achieve broader impacts, the proposed research will include deployment of a public image forgery detection engine, release of a large original data set, and definitions of evaluation benchmark.","title":"Cyber Trust - Restore the Trustworthiness of Digital Photographs: Blind Detection of Digital Photograph Tampering","awardID":"0430258","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["563299","485160"],"PO":["371077"]},"98293":{"abstract":"The proposed research touches on both theoretical computer science and artifcial intelligence (AI).<br\/>In particular, the techniques of theoretical computer science will be applied to two significant<br\/>problem areas in AI: knowledge representation and machine learning. Certain forms of knowledge<br\/>representation are extremely important for AI applications. Some, such as conjunctions of Horn<br\/>clauses, have been studied from AI's earliest days; others, such as decomposable negation normal<br\/>form (DNNF), are relatively new. This project will study the computational complexity aspects of<br\/>these and other forms of knowledge representation, and formal learnability results for them.<br\/>Knowledge representation is interesting because the choice of representation determines the ease<br\/>or difficulty of various tasks that an intelligent agent must perform, such as reasoning or planning.<br\/>The representations of interest for this research include various forms of propositional logic, ranging<br\/>from disjunctive normal form to DNNF, and various more powerful logics, such as modal logics,<br\/>some forms of predicate logic, and probabilistic description logic. This proposal includes a variety<br\/>of problems and approaches, unified by recurring themes drawn from combinatorics and logic.<br\/>One main goal of the proposed work is to advance the understanding of several aspects of im-<br\/>portant knowledge representation formalisms. This includes answering questions on expressiveness<br\/>for both basic formalisms such as disjunctive normal forms and decision trees, and also for recent<br\/>formalisms such as DNNFs. It also includes determining the complexity of handling exceptions in<br\/>different formalisms, which is both a practical problem and is also closely related to some questions<br\/>on the efficient learnability of the representations. The proposed work will include a probabilistic<br\/>analysis of the important reasoning technique of Horn approximations, in order to identify situ-<br\/>ations when the method can be expected to work efficiently in spite of examples demonstrating<br\/>its worst-case behavior, and an analysis of the possibilities for compiling a knowledge bases into a<br\/>more efficient form having short resolution proofs of its consequences.<br\/>Another goal of the project is to obtain a better integration of the learnability aspect of the<br\/>different knowledge representation formalisms into the emerging comparative theory of knowledge<br\/>representation. This line of research includes making new progress on old, well established problems,<br\/>such as learning Horn sentences, the further study of recently introduced problems, such as revising<br\/>Horn sentences, and the exploration of representations that have not been studied yet from the point<br\/>of view of learnability, such as modal logics. Work is also proposed on the exclusion dimension, a<br\/>promising recent notion, in both propositional and predicate logic.<br\/>Intellectual merit: The proposal addresses several key issues in knowledge representation<br\/>and learning: expressiveness, efficient manipulation, efficient reasoning, and efficient learning and<br\/>revision, in propositional, predicate, and modal logic. The proposal builds on the previous re-<br\/>search results of the proposers, which includes the development of new approaches to logic learning<br\/>and theory revision, and their technical expertise in computational learning theory, computational<br\/>complexity theory, combinatorics and logic, leading up to a comprehensive, in-depth study of core<br\/>problem areas of artificial intelligence, emphasizing the interactions between the different aspects.<br\/>The proposers have initial results in several of the suggested research directions.<br\/>Broader impact: The rapid increase in both the amount of, and the inherent complexity<br\/>of data greatly increases the importance of expressive knowledge representation formalisms that<br\/>are suitable for efficient manipulation, reasoning, automated acquisition and revision. Symbolic<br\/>knowledge representation formalisms based on propositional, predicate, modal and other logics<br\/>form an indispensable component in a large number of applications. Understanding the complexity<br\/>obstacles in these applications, and identifying possible avenues for circumventing them, is a crucial<br\/>component of further development.","title":"Complexity Aspects of Knowledge Representation and Learning","awardID":"0431059","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["528421","409637"],"PO":["499399"]},"98073":{"abstract":"Current wireless data networks, such as 802.11b\/g\/a (Wi-Fi) which are<br\/>based on single antenna transmission are inefficient in terms of<br\/>the number of users (capacity) that can be supported in a given area. <br\/>It is well known that multiple antenna elements (arrays) can be combined with<br\/>beamforming and space-time coding to greatly enhance the capacity of<br\/>cellular networks. However, the use of antenna arrays to enhance <br\/>capacity in Ad hoc networks (i.e. when a base station is not available)<br\/>is not well understood. The development of new beamforming <br\/>and space-time coding techniques that exploit antenna arrays in Ad hoc <br\/>networks will greatly increase the number of users and data rates that <br\/>can be supported in future Wi-Fi and Wi-Max type applications, and <br\/>reduce dependence on cellular and optical backbone infrastructures. <br\/><br\/>This project specifically develops and analyzes a class of <br\/>distributed array processing algorithms for increasing Ad hoc wireless <br\/>network capacity based on iterative minimum mean-square error <br\/>(IMMSE) beamforming. In IMMSE, the transmit beamformer at each <br\/>node is set to the conjugate of the conventional MMSE receive beamformer <br\/>computed using a training sequence. IMMSE is then studied using <br\/>noncooperative game theory in order to obtain convergence and efficiency <br\/>results. The IMMSE algorithm is extended to space-time coding to <br\/>yield approximate solutions to maximizing decoupled Shannon <br\/>capacities of Ad hoc networks. These IMMSE-Deflation (IMMSE-D)<br\/>algorithms attempt to balance desired link capacity with a tax on<br\/>interference to other links, and hence may offer better network<br\/>throughput than greedy capacity-maximization algorithms. Overall<br\/>network throughput is evaluated by embedding the IMMSE and IMMSE-D<br\/>algorithms in a network simulation software package.","title":"Noncooperative Beamforming for Ad hoc Networks","awardID":"0429596","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["355335"],"PO":["564898"]},"98194":{"abstract":"Proposal Number: NSF-0430450<br\/><br\/>TITLE: Cryptographic Foundations of Cyber Trust<br\/><br\/>Principal Investigator: Shafi Goldwasser<br\/><br\/>Protecting the electronic information world is paramount to the success and stability of modern society. This includes protecting the integrity and privacy of stored and communicated data, guaranteeing security of complex electronic transactions, and maintaining availability of the existing infrastructure. At the core of any trustworthy and resilient solution to these problems lies a set of cryptographic protocols that are guaranteed to preserve explicitly stated security requirements under some cryptographic hardness assumptions in the face of malicious attacks. The design of cryptographic protocols is a complex endeavor, which must be accompanied by a security analysis which rests on sound theoretical foundations. This research will address challenges that arise in the the design of cryptograhic protocols at multiple levels, from the mathematical underpinnings of computational difficulty, through modeling and analysis of protocols, to deployment and run-time issues. The following objectives will be pursued: diversifing cryptographic hardness assumptions; adequate modeling and analysis of cryptographic protocols in complex environments; analyzing the security of current practices; and designing new cryptographic protocols which achieve stronger levels of security. The diversity of the challenges addressed will have a significant impact on the design and practice of cryptographic protocols in the future.","title":"Cryptographic Foundations of Cyber Trust","awardID":"0430450","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["562010"],"PO":["521752"]},"98095":{"abstract":"Physically Aware Computer Architecture<br\/>Abstract<br\/><br\/>Technology scaling and low-level physical effects are straining the clean interfaces between abstraction levels necessary to make the design process manageable. This tension will increase as new physical phenomena are manifested in nanotechnology-based circuits. At the same time, microarchitecture is becoming increasingly important in managing the way physical phenomena impact key figures of merit such as performance, energy efficiency, cost, and expected lifetime. This proposal considers the interaction between the computer architecture domain and physical domain aspects such as thermal effects, aging processes, floorplanning, interconnect, process variations, and power-supply variation. We propose to model these phenomena using \"compact\" models. We will develop models for key physical phenomena and explore architecture techniques for managing their impact.<br\/><br\/>Unless microarchitecture can account for low-level physical phenomena like process, voltage, and temperature variability, increasing design margins will impose high and possibly prohibitive costs that drastically limit design possibilities. The discovery of similarities in the modeling and design approaches for such phenomena offers a solution. In terms of broader impact, the project will develop a flexible modeling infrastructure that will enable the architecture and computer systems design community to perform physically-aware design and analysis and compensate for these technology trends. Further impact will arise from educating a generation of students to consider low-level physical phenomena in higher-level abstract design domains.","title":"Physically Aware Computer Architecture","awardID":"0429765","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["560683","489873","527785"],"PO":["550859"]},"99195":{"abstract":"Manna<br\/>0437281<br\/><br\/>This one-year award supports the participation of 15 US researchers, including two postdoctoral fellows in a US-European cooperative workshop, \"Software Engineering Tools: Compatibility and Integration.\" The workshop is organized by Zohar Manna of Stanford University, Thomas Henzinger of the Ecole Polytechinque Federale of Lausanne, Switzerland, and Hermann Kopetz of the Technical University of Vienna, Austria. A lack of tool integration has been recognized as a major impediment to the construction of complex computer systems, especially in the development of embedded systems. Tool operability is an important prerequisite for increasing software productivity and reliability. The workshop will address these issues. <br\/><br\/>The workshop will bring together American and European scientists that share a common interest in seeing that software development research serves as a catalyst for practical advances in next-generation software intensive systems. It is expected to give rise to new collaborations that advance the field. To advance this purpose, the workshop will include a meeting of the working group of the China, US, and Europe initiative (CUE), a global initiative to integrate theoretical computer science with software engineering practice.","title":"US-Europe Cooperative Workshop: Compatability and Integration of Software Engineering Tools","awardID":"0437281","effectiveDate":"2004-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["309451"],"PO":["564152"]},"95291":{"abstract":"There is today a broad consensus among theoretical linguists (of all frameworks) and researchers in Natural Language Processing (NLP) about what the syntactic phenomena are that we encounter in natural languages. However, there are many different frameworks in which analyses of these phenomena have been implemented, and there is even disagreement about specific analyses within one single framework. As a result, linguistic resources such as annotated corpora or grammars cannot be easily reused across frameworks. This project will investigate the common categorization of syntax that underlies work in linguistics and NLP. This underlying categorization is called a ``metagrammar''. Given a metagrammar, a tool can be produced to automatically generate grammars in different frameworks. <br\/><br\/>This research contains three main activities. The first involves comparative work in several languages (including English) that will lead to coordinated metagrammars for these languages. These framework-independent specifications will catalog syntactic properties and detail their possible interaction; categories shared between languages will lead to shared portions of the metagrammar. The second concerns the development of specific grammar statements that relate metagrammatical categories to constructs in particular frameworks and for particular languages. It is these statements that, in their interaction, determine word order. The third involves annotating the Penn Treebank (PTB) corpus with the syntactic properties from the metagrammar, thus making the information implicitly encoded in the phrase structure of the PTB explicit and usable by other frameworks.<br\/><br\/>This project will enable the NLP and linguistics communities to better share insights on syntactic phenomena. Additionally, the work will enable the development of new NLP tools that are less dependent on a particular representation. It will enable linguists to rapidly develop grammars and test-suites for different frameworks and languages, thus allowing for both cross- and inter-framework evaluation of linguistic grammars. Upon completion of the project, the PTB re-annotated with the high-level categories of the metagrammar will be made available to the research community .","title":"Metagrammatical Knowledge for Grammars and Corpora","awardID":"0414409","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["472144","507533"],"PO":["565215"]},"98140":{"abstract":"Proposal Number 0430066<br\/><br\/>Principal Investigator: Richard N. Taylor<br\/><br\/>Self-Adaptive Software<br\/><br\/>Adaptive behavior is required of many classes of software systems in which untimely human responses to change are insufficient. Self-adaptive software systems address this requirement by continually observing themselves and their environment in order to effect autonomous modifications to their behavior. This research aims to develop a methodology for the development of self-adaptive software centered on ensuring a high-level of adaptation policy visibility, enforcing a strict decoupling of policy specification <br\/>from system implementation, and supporting the independent and dynamic runtime evolution of adaptation policies.<br\/><br\/>To achieve these objectives, the design of self-adaptive systems through the integration of architectural models and knowledge-based techniques is investigated. A specification of adaptation policies <br\/>based on architectural knowledge independent from system semantics is included in software architecture models; these artifacts are leveraged to implement knowledge-based reasoning to determine <br\/>necessary system modifications. Research results are evaluated in the context of space exploration systems, which provide a rich set of examples sorely needing self-adaptive capabilities.<br\/><br\/>This research enables the principled architecting of self-adaptive systems by elevating and specifying adaptation policies as first-class architectural elements supported by the novel integration <br\/>of knowledge-based techniques for reasoning over the space defined by architectural knowledge, adaptation policy, and system modifications.","title":"Self-Adaptive Software","awardID":"0430066","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["533779"],"PO":["564388"]},"97073":{"abstract":"This project, developing middleware for building highly heterogeneous wireless sensor networks (WSNs), proposes creation of mechanisms to help formulate, communicate, and coordinate complex tasks in WSN. Constructed with both resource-lean and resource-rich sensors\/actuators, the facility enables the following applications:<br\/> Environmental Monitoring for Countering Agro-Terrorism,<br\/> Surveillance for Homeland Security, and<br\/> Patient Monitoring for Improved Healthcare.<br\/>Since WSNs are highly heterogeneous in nature, the middleware will be developed in an integrated fashion, supporting the development, maintenance, and deployment, and execution of sensing-based applications. The work includes mechanisms for formulating complex sensing tasks, communicating tasks to individual sensor nodes, merging and processing low-level sensor readings from the individual sensors nodes to obtain desired high-level results, reporting results back to the user, designing energy-efficient distributed compression and transmission techniques, and developing network-friendly media security solutions. At present, two categories of sensing devices exist: one characterized as resource-lean (low-cost, low-power) sensing devices such as motes and smart dust developed in UC Berkeley, and the other represented by resource-rich multimedia sensors such as video camera and microphone. The infrastructure will allow the co-existence of various types of sensors and the use of multiple sensing modalities to achieve coordinates system capabilities and performance. The project includes the following activities:<br\/> Middleware Development for Wireless Sensor Networks,<br\/> Adaptive Optimization as Middleware Services for WSNs,<br\/> Optimizing Multimedia Delivery over WSNs,<br\/> Ultra-wideband (UWB) for Wireless Patient Monitoring (WPM), and<br\/> WSN Applications for Homeland Security and Healthcare.<br\/><br\/>Broader Impact: This work enhances collaborative research, development and educational capabilities. The platform should be able to support a broad range of WSN applications of potential importance to national security. Expected impact could be felt in US agriculture, economy, defense, homeland security, and healthcare.","title":"CISE-RR: Wireless Sensor Networks: Middleware and Applications","awardID":"0423386","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["498256","564156","478365","564155","327917"],"PO":["557609"]},"98173":{"abstract":"Proposal Number: CNS-0430271<br\/><br\/>TITLE: A Survivable Information Infrastructure for National Civilian BioDefense<br\/><br\/>PI: Yair Amir <br\/><br\/>This project focuses on the theoretical foundation and the protocols that facilitate a survivable information infrastructure that meets the critical requirements of a national emergency response system. Specifically, the project will address the following challenges:<br\/>(1) expand the existing theoretical framework to analyze the behavior of malicious and colluding participants; (2) design and construct a scalable survivable messaging system that operates correctly under a strong adversarial model that includes insider threat and denial of service attacks; (3) design and construct information access protocols that protect against compromised database servers providing incorrect data or servers that deny access to legitimate users; and (4) prevent malicious users from learning unauthorized information. The domain of application for this work is the Clinicians' Biodefense Network (CBN), a nationwide Internet-based information exchange system designed to provide clinicians with critical information in the aftermath of a bioterrorist attack. The CBN is designed to mitigate benign Internet faults and to resist a physical attack on one location. However, it is not able to correctly operate under a stronger threat model that includes insider attacks. Solutions for this stronger threat model are not currently available and present a major research challenge. This project will construct a prototype survivable system based on the CBN, and from it draw general principles. It will develop a solid theoretical foundation and novel system tools to facilitate building national emergency networks that are resilient against cyber-attacks in crisis situations, when those networks are most urgently needed.","title":"Collaborative: A Survivable Information Infrastructure for National Civilian BioDefense","awardID":"0430271","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["339946",258520],"PO":["521752"]},"98294":{"abstract":"NSF Proposal Number: 0431068<br\/><br\/>Title: Preconditioning techniques for linear systems of equations<br\/><br\/>PI: Vivek Sarin, Dept. of Computer Science, Texas A&M University<br\/><br\/>Abstract:<br\/><br\/>The solution of linear systems of equations is a fundamental problem that<br\/>must be tackled in various areas of science and engineering. Iterative<br\/>methods are used to solve large sparse systems from partial differential<br\/>equations as well as large dense systems from integral equations.<br\/>Preconditioning techniques are necessary to accelerate the rate of<br\/>convergence of these solvers. An ideal preconditioner should be robust,<br\/>effective, parallelizable, and inexpensive to compute and apply to the<br\/>linear system. When solving dense systems, the unavailability of the<br\/>coefficient matrix often limits the choice of preconditioners. The goal of<br\/>the project is to develop novel preconditioning techniques for sparse and<br\/>dense linear systems. These techniques will use a sequence of linear<br\/>transformations to obtain a preconditioned system from the original one.<br\/>Techniques will be developed to analyze the preconditioned system, and<br\/>schemes will be developed to improve the effectiveness of the<br\/>preconditioner. The resulting preconditioners will be robust, effective,<br\/>and inexpensive. These preconditioning techniques will be implemented,<br\/>analyzed, and tested on a variety of problems. These efforts will be<br\/>integrated with interdisciplinary collaborative research activities to<br\/>ensure a greater impact on application areas.","title":"Preconditioning Techniques for Linear Systems of Equations","awardID":"0431068","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[258835],"PO":["381214"]},"98074":{"abstract":"Control-Flow Processors<br\/>Abstract<br\/><br\/><br\/>An architecture is presented that unifies fine-grain control-flow and data-flow dependences in the context of contemporary superscalar processors, preserving highly streamlined mechanisms of superscalar processors while endowing them with dataflow properties. Future independent instructions are fetched, executed, and locally finalized, their results propagated and corresponding resources freed, and their cumulative effects sustained regardless of prior unresolved branch mispredictions. Branch mispredictions no longer serialize execution, leaving exceptions and finite resources as the only remaining serializing constraints in the system.<br\/><br\/>In the domain of high-performance microprocessors (which power supercomputers, personal computers, laptops, and even cell phones), there remain a few dogged bottlenecks that fundamentally constrain performance, making it difficult to translate the potential of additional transistors into effective performance gains. The project's broader significance is an approach that aims to overcome one of the remaining grand-challenge problems in scaling microprocessor performance.","title":"Collaborative Research: General-Purpose Memory Tagging for Reliable, Secure, and Fast Computing","awardID":"0429598","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["485790"],"PO":["325495"]},"97690":{"abstract":"Proposal ID: 0426608 <br\/>P I: Touba, Nur <br\/>Organization: University of Texas at Austin <br\/>Title: ITR - (ASE) - (int): CAD for Reducing Soft Error Failure Rates in Logic Circuits <br\/><br\/>Abstract:<br\/>Reducing the soft error failure rate for logic circuits is more expensive and difficult than for memories and is expected to emerge as a very important problem in the future for mainstream low-cost electronics as technology continues to scale. Currently, there is a lack of computer-aided design (CAD) tools and techniques for addressing this problem in a cost-effective manner. This research project involves developing a new paradigm for designing logic circuits with protection from soft errors to reduce the soft error failure rate. A fine-grain quantitative approach will be investigated where the susceptibility of the logic circuit to soft errors is estimated at each step of the design process and fault tolerance features are incorporated as needed in a cost effective way to satisfy soft error failure rate requirements. One of the key ideas in this research is to exploit the asymmetric soft error susceptibility of internal nodes in a logic circuit to direct the insertion of fault tolerance features. Unlike memories where the probability of a soft error in each cell is equally likely, in logic circuits upsets at some internal nodes can have orders of magnitude greater probability of being latched and causing a soft error than at other nodes. By focusing error detection and\/or error masking capability towards the nodes that are most susceptible to soft errors, the soft error failure rate in logic circuits can be significantly reduced at a fraction of the cost of existing techniques which try to guarantee coverage of all nodes. The objectives of this project include developing efficient procedures for estimating soft error susceptibility, developing CAD algorithms for cost-effective insertion of fault tolerance features, and developing soft error protection schemes that minimize impact on timing and power.","title":"ITR - (ASE) - (int): CAD for Reducing Soft Error Failure Rates in Logic Circuits","awardID":"0426608","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["517957"],"PO":["562984"]},"96293":{"abstract":"Abstract<br\/> <br\/>Title: ITWF Collaborative Research: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science<br\/><br\/>CNS 0420505, PI Kamin, Univ. of Illinois at Urbana-Champaign<br\/>CNS 0420000, PI Califf, Illinois State University<br\/>CNS 0420458, PI Lucht, Heartland Community College<br\/>CNS 0420468, PI Mobasseri, Parkland College<br\/>CNS 0420506, PI Uskov, Bradley University<br\/>CNS 0420321, PI Van Cleave, Eastern Illinois University<br\/><br\/><br\/><br\/>This collaborative ITWF project implements a set of activities designed to increase participation of women and under-represented minorities in undergraduate computer science programs in the state of Illinois. The project includes high school outreach, curriculum reform, mentoring, and other extracurricular activities. It is a collaborative project between the University of Illinois at Urbana-Champaign, Illinois State University, Heartland Community College, Parkland College, Bradley University, and Eastern Illinois University. The project involves building communities among various groups within the state to recruit, support, and retain students in computing courses and programs.<br\/> <br\/>The intellectual merit of this project lies in the strong research basis for the intervention models as well as the vertical integration of the models at a range of secondary and post-secondary institutions within the state. The project plan is clear and reasonable with well-defined roles for the partners. The project builds on existing programs and partnerships within the state and includes investigators with significant relevant experience.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science within one state. If successful, the project may provide a sound model for similar broad-based approaches in other states and geographical areas.","title":"Collaborative Research: ITWF: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science","awardID":"0420321","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[252465],"PO":["361119"]},"98251":{"abstract":"A stochastic information fusion methodology is developed to assimilate electrical resistivity tomography, high-frequency ground penetrating radar, mid-range-frequency radar, pneumatic\/gas tracer tomography, and hydraulic\/tracer tomography to image fractures, characterize hydrogeophysical properties, and monitor natural processes in the vadose zone. The information technology research will develop: (1) mechanisms and algorithms for fusion of large data volumes; (2) parallel adaptive computational engines supporting parallel adaptive algorithms and multi-physics\/multi-model computations; (3) adaptive runtime mechanisms for proactive and reactive runtime adaptation and optimization of geophysical and hydrological models of the subsurface; and (4) technologies and infrastructure for remote (pervasive) and collaborative access to computational capabilities for monitoring subsurface processes through interactive visualization tools.<br\/><br\/>The combination of the stochastic fusion approach and information technology can lead to a new level of capability for both hydrologists and geophysicists enabling them to \"see\" into the earth at greater depths and resolutions than is possible today. Furthermore, the new computing strategies will make high resolution and large-scale hydrological and geophysical modeling feasible for the private sector, scientists, and engineers who are unable to access supercomputers, i.e., it is an effective paradigm for technology transfer.","title":"Collaborative Research: SEI (EAR): Adaptive Fusion of Stochastic Information for Imaging Fractured Vadose Zones","awardID":"0430826","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["558205"],"PO":["565136"]},"99582":{"abstract":"ABSTRACT<br\/>NSF-0439955<br\/><br\/>Systems biology seeks to understand fundamental mechanisms of organismal biology in humans and other species at the level above individual reactions and structures. Large, complex data sets must be obtained at various levels of biological functions from transcription to end-phenotypes. This involves not only heterogeneous data but these studies must also include time-series and perturbations as they must assess homeostasis and genetic variation. Computer science, statistical and analytical methods must all be developed and applied for managing, distributing, representing, analyzing and modeling these large complex datasets. Networks and pathways must be determined and then annotated with genetic, molecular, biological and pharmacological attributes. Finally, networks and pathways must be engineered to test hypotheses about systems biology in complex organisms. <br\/><br\/>Because the field is inevitably interdisciplinary, many different kinds of effort are required. This is the second year of the conference, with an agenda based on identifying theoretical and experimental platforms for systems biology. Members of underrepresented groups are actively encouraged to attend and present, including students. Sponsors of the conference include the Center for Computational Genomics and Systems Biology (J. Nadeau, CWRU, Cleveland), the Institute for Systems Biology (L. Hood, Seattle), Systemscope (M. Roux and C. Auffray, Paris), Center for Bioinformatics and Systems Biology (S. Surbramaniam, San Diego), and the Keck Graduate Institute (D. Galas, Claremont).","title":"2nd International Conference on Pathways, Networks, and Systems: Theory and Experiments; October 15-20, 2004; Heraklion, Greece","awardID":"0439955","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["559061","415743","556513","498292",262645],"PO":["565136"]},"98141":{"abstract":"Collaborative Research: DefCOM - Distributed Defense against DDoS<br\/><br\/>Jelena Mirkovic, University of Delaware<br\/>Peter Reiher, UCLA<br\/><br\/>Award 0430228<br\/><br\/>Abstract<br\/><br\/>This project investigates a distributed cooperative solution to the problem of distributed denial-of-service attacks. The proposed defense system, DefCOM, combines the advantages of victim-end defenses (accurate attack detection) and source-end defenses (efficient response and precise separation of the legitimate traffic from the attack traffic). It also enlists the help of backbone routers to control attack traffic in partial deployment scenarios where many potential sources do not deploy a source-end defense.<br\/><br\/>DefCOM nodes will be deployed in source, victim and core networks, and will cooperate via an overlay to detect and stop attacks. Overlay communication will ensure effective operation even if DefCOM nodes are sparsely and non-contiguously deployed. DefCOM's response to attacks is twofold: defense nodes reduce the attack traffic, freeing the victim's resources; and they also cooperate to detect legitimate traffic within the suspicious stream and ensure its correct delivery to the victim. Because networks deploying defense nodes directly benefit from their operation, DefCOM has a workable economic model to spur its deployment. DefCOM further offers a framework for existing security systems to join the overlay and cooperate in the defense. These features create excellent motivation for wide deployment, and the possibility of a large impact on the DDoS threat.","title":"Collaborative Research: DefCOM: Distributed Defense Against DDoS Attacks","awardID":"0430073","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["485932"],"PO":["521752"]},"98262":{"abstract":"Synthetic aperture radar (SAR), geophysical and seismic imaging, ultrasound imaging, optical coherence tomography (OCT), and many forms of astronomical imaging are examples of coherent imaging systems. In practice, the acquired phase data are noisy due to imprecise knowledge of the motion of the sensor, or due to the properties of the medium. As a consequence, the produced imagery is improperly focused. Existing techniques for correcting the imagery, referred to as autofocus, are ill-equipped to handle the challenges of modern high-resolution systems. The availability of well-focused ultra-high-resolution SAR imagery is crucial for antiterrorism efforts. Improved focusing may also lead to breakthroughs in medical imaging, such as ultrasound imaging of the human breast.<br\/><br\/>The investigators develop a new generation of autofocus algorithms that will enable improved focusing in a variety of coherent imaging modalities. Primarily, the SAR autofocus problem is considered because of its national importance in all-weather surveillance, and also because the SAR field is highly developed. The research will focus on the following approaches: (i) optimization strategies that optimize image sharpness metrics, (ii) multiresolution vector space methods that exploit the structure of the phase error, and (iii) multichannel blind deconvolution techniques that exploit the redundancy of the blurring operation on each row of the image. These approaches motivate the development of a unified framework, in which all of the available assumptions are used in a robust restoration procedure. The implementation of the methodology in practical SAR systems will be emphasized. Finally, the developed autofocus methodology will be extended and applied to ultrasound, OCT, and passive radar imaging.","title":"Collaborative Research: A Modern Autofocus Methodology with Applications to Radar Imaging","awardID":"0430877","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["518402"],"PO":["564898"]},"98273":{"abstract":"The main goals and the intellectual merit of the proposed research are to advance our understanding and ability to deal with computationally hard optimization problems, to expand the scope of our methodologies to facilitate e.ective decision making in multifaceted situations where multiple criteria come into play, and to formalize problems from other areas and address them rigorously using the most suitable algorithmic tools.<br\/><br\/>One thrust of the proposed research concerns the development of a coherent algorithmic theory for multicriteria problems. Such problems are very common and have been mostly squeezed into an one-dimensional mold so far. Besides the general theory and algorithm that will be developed, several problems from databases involving resource and utility trade-o.s will be addressed in this light.<br\/><br\/>A second thrust concerns the further development of the theory of hard approximation problems. A major objective is to understand and characterize the degree to which hard problems can be approximated, in particular, which problems can be approximated within a constant factor, independent of the size of the instance.<br\/><br\/>The third thrust concerns issues in modeling and analysis of systems, and seeks to formulate<br\/>and bring the relevant problems within the realm of algorithmic analysis.<br\/><br\/>A broader impact of the proposed research is expected to be derived from the connections that<br\/>will be pursued between the methodologies and tools from theoretical computer science, and the<br\/>problems and issues that arise in other areas, eg. databases and system analysis. It is expected<br\/>that this will bene.t both sides.","title":"Research in Algorithms, Approximatiion and Applications","awardID":"0430946","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["550946"],"PO":["499399"]},"98284":{"abstract":"We propose to work on several areas of theory. The first concerns game<br\/><br\/>theoretic\/economic questions. The second concerns several questions about<br\/><br\/>polynomials: zero testing, MOD complexity, and learning.<br\/><br\/><br\/><br\/>The proposed research will examine a variety of open problems from<br\/><br\/>these areas. Some of the open problems are classic and well known;<br\/><br\/>others are new. The mix between known problems that are often<br\/><br\/>difficult and new problems is important. Both types of problems will,<br\/><br\/>we believe, advance our understanding of these important questions.<br\/><br\/><br\/><br\/>The first questions concern mainly non-cooperative games as well as<br\/><br\/>fair division problems. These problems have often been studied for<br\/><br\/>years, but only recently have researchers looked closely at their<br\/><br\/>computational complexity. It seems clear that the interface between<br\/><br\/>game theory and economic problems with complexity theory has<br\/><br\/>tremendous potential.<br\/><br\/><br\/><br\/>The second questions concern mainly classic problems from the<br\/><br\/>foundations of complexity theory. They include the power of polynomial<br\/><br\/>under various complexity restrictions and certain learning<br\/><br\/>problems. The problems are important for two reasons. They are<br\/><br\/>important for their own sake. Further, their solution or even partial<br\/><br\/>solution is likely to yield new insights and potentially new<br\/><br\/>techniques. These could then be used to further our understanding of<br\/><br\/>other problems in other parts of theory.<br\/><br\/><br\/><br\/>Intellectual Merit: Games and economic problems are extremely<br\/><br\/>challenging. This is especially true for non-zero sum games. Their<br\/><br\/>complex structure raises many important fundamental questions. We<br\/><br\/>expect to learn a great deal from the study of these important<br\/><br\/>problems. This is also true for the more classic questions concerning<br\/><br\/>polynomials. The questions of testing, mod behavior, and learning are<br\/><br\/>difficult problems. Some have been challenging open problems for<br\/><br\/>decades. We believe that any progress on these problems will require<br\/><br\/>us to use old methods in new ways and to invent new methods.<br\/><br\/><br\/><br\/>Broader Impact: The impact of the proposed research into games<br\/><br\/>and economic problems is clear. Progress on the computational aspects<br\/><br\/>of economic problems has a clear impact on society. As commerce<br\/><br\/>becomes more digital, it is clear that any better understanding of games<br\/><br\/>and economic problems will have impact on a very broad community.<br\/><br\/><br\/><br\/>The work on polynomials also will have a broad impact. Some of the<br\/><br\/>most fundamental theory questions would be effected by progress on any<br\/><br\/>of the proposed research. The impact would be far beyond the theory<br\/><br\/>community that studies these questions. It could effect other fields<br\/><br\/>like: cryptography, learning theory, and fundamental parts of<br\/><br\/>mathematics.","title":"Research Into the Complexity Theory of Games and Polynomials","awardID":"0431023","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["400310"],"PO":["499399"]},"98053":{"abstract":"This research examines broad issues of guaranteeing that the essential shape of an object is preserved during algorithms used in engineering design, animation and molecular modeling. While geometric characteristics such as surface area and volume can be objectively measured and compared for two objects, other shape characterizations, such as the distinction between a garden hose and the same hose tied into a knot, are more subtle and require the methods of this research. Surprisingly, these distinctions are not easy for present day algorithms and difficulties in detecting these differences has been estimated to cost billions of dollars annually in lost productivity in the aeronautical and automotive industries. This research is an interdisciplinary investigation between computer scientists and mathematicians with a corresponding educational emphasis upon introducing the next generation of scientists to a holistic perspective that combines theory with novel engineering and life science applications. The applications to molecular modeling are expected to be attractive to the many women in the biological sciences and thereby increase the participation of women in the computational and mathematical sciences.<br\/><br\/><br\/>This research integrates new topological constraints and numerical error bounds into geometric approximation algorithms, defining when a surface approximation is in the same topological equivalence class as the original surface. While surface approximation is a classical mathematical topic, the issue of topological equivalence has typically been left to human inspection. The novel approach of this research is the development of the theory and practice to create computationally tractable algorithms that ensure topological equivalence for a rich class of surface approximation techniques. The creation of appropriate applied mathematics to eliminate any direct algorithmic dependence upon computation of the medial axis significantly enriches the class of robust approximation algorithms delivering verifiable topology. Another major innovation is the comprehensive consideration of geometric models composed from bounded surface patches. This perspective eliminates a prevailing, but unrealistic theoretical hypothesis that geometric models have only a single bounding surface. The additional subtleties rely upon new numerical approximations along the boundaries of each constituent patch.","title":"Computational Topology for Surface Approximation","awardID":"0429477","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[258220,"482465","486281"],"PO":["565157"]},"98174":{"abstract":"Privacy is increasingly a major concern that prevents the exploitation of the Internet's full potential. Consumers are concerned about the trustworthiness of the websites to which they entrust their sensitive information. Although significant industry efforts are seeking to better protect sensitive information online, existing solutions are still fragmented and far from satisfactory. Specifically, existing languages for specifying privacy policies lack a formal and unambiguous semantics, are limited in expressive power and lack enforcement as well as auditing support. Moreover, existing privacy management tools aimed at increasing end-users' control over their privacy are limited in capability or difficult to use.<br\/>This project seeks to provide a comprehensive framework for protecting online privacy, covering the entire privacy policy life cycle. This cycle includes enterprise policy creation, enforcement, analysis and auditing, as well as end user agent presentation and privacy policy processing. The project integrates privacy-relevant human, legal and economic perspectives in the proposed framework. This project will develop an expressive, semantics-based formal language for specifying privacy policies, an access control and auditing language for enforcing privacy policies in applications, as well as theory and tools for verifying privacy policies. Additionally, experiments and surveys will be conducted to better understand the axes of users' privacy concerns and protection objectives. Results from this empirical work will be used to develop an effective paradigm for specifying privacy preferences and methods to present privacy policies to end users in an accurate and accessible way.","title":"Collaborative Research: A Comprehensive Policy-Driven Framework for Online Privacy Protection: Integrating IT, Human, Legal and Economic Perspectives","awardID":"0430274","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["527911","548253","529959","560877","548254"],"PO":["469867"]},"98295":{"abstract":"A stochastic information fusion methodology is developed to assimilate electrical resistivity tomography, high-frequency ground penetrating radar, mid-range-frequency radar, pneumatic\/gas tracer tomography, and hydraulic\/tracer tomography to image fractures, characterize hydrogeophysical properties, and monitor natural processes in the vadose zone. The information technology research will develop: (1) mechanisms and algorithms for fusion of large data volumes; (2) parallel adaptive computational engines supporting parallel adaptive algorithms and multi-physics\/multi-model computations; (3) adaptive runtime mechanisms for proactive and reactive runtime adaptation and optimization of geophysical and hydrological models of the subsurface; and (4) technologies and infrastructure for remote (pervasive) and collaborative access to computational capabilities for monitoring subsurface processes through interactive visualization tools.<br\/><br\/>The combination of the stochastic fusion approach and information technology can lead to a new level of capability for both hydrologists and geophysicists enabling them to \"see\" into the earth at greater depths and resolutions than is possible today. Furthermore, the new computing strategies will make high resolution and large-scale hydrological and geophysical modeling feasible for the private sector, scientists, and engineers who are unable to access supercomputers, i.e., it is an effective paradigm for technology transfer.","title":"Collaborative Research: SEI (EAR): Adaptive Fusion of Stochastic Information for Imaging Fractured Vadose Zones","awardID":"0431069","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["526291","267124"],"PO":["563727"]},"98064":{"abstract":"Abstract<br\/><br\/>Cooperative Hardware\/Software Designs for virtual Instruction Set Computers<br\/><br\/>Vikram S. Adve<br\/>U. of Illinois, Urbana<br\/>0429561<br\/><br\/>This work proposes a class of cooperative compiler\/microarchitecture techniques that can improve performance and reduce the complexity and power-consumption of general-purpose processors. The key feature of these proposed techniques is that they exploit a wide, implementation-specific instruction set interface between the compiler and the processor, enabled by the use of Virtual Instruction Set Computer (VISC) architecture.<br\/><br\/>A VISC architecture is characterized by having two instructions sets - one which is exposed to software (the virtual ISA or V-ISA) and another which is actually implemented by hardware (the implementation ISA or I-ISA)-and a translator that is used to transparently emulate the first with the second. Because the I-ISA is never exposed to software (other than an implementation-specific translator that is logically part of the processor design) it can freely expose implementation specific microarchitectural details and interfaces without concerns for binary compatibility across implementations. It is this opportunity to architect an implementation-specific ISA and use it for cooperative compiler\/microarchitecture techniques that is the central focus of this proposal.<br\/><br\/>Two aspects of the proposed work differentiate it from previous work on software-exposed architectures. First, we are translating from a rich V-ISA layer that retains much of the high-level information present in the program's source code. We hypothesize that the availability of this information is fundamental in the translator's ability to transform the code to exploit the proposed mechanisms, and we will evaluate this hypothesis for the proposed techniques. Second, the proposed techniques are truly cooperative, in that the compiler can have full knowledge of implementation-specific details of the microarchitecture, and the microarchitecture can rely on information from and code generation constraints on the complier. This gives our designs full freedom to exploit the distinct and complimentary strengths of compilers and hardware; neither system is the other's subordinate. Whereas hardware can efficiently observe and respond to dynamic events and can cheaply speculate and validate that speculation, the compiler can perform global analysis to reduce and simplify the decisions the hardware has to make and to eliminate unnecessary speculation.<br\/><br\/>Specifically, we proposed to develop cooperative compiler technology and microarchitectures that address critical challenges in modern general-purpose processors. For each of these challenges, we will explore one or two techniques (described in the proposal) that rely extensively on software interaction, and which would be impractical without the VISC approach.","title":"Cooperative Hardware\/Software Designs for Virtual Instruction Set Computers","awardID":"0429561","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["542046","322427","539055"],"PO":["550859"]},"98185":{"abstract":"Data Stream computation is emerging as one of the important models for analysis, monitoring and event detection in context of large networks, e.g., the internet, telephone networks, and sensor networks for observational sciences. In general, data streams model computations over massive data sets. Often, the size of the data is so large that it incurs too high a cost (in time or infrastructure) to allow efficient random access.<br\/><br\/>Thus in a data stream algorithm the space allowed to an algorithm is significantly smaller than the size of the input. In several scenarios, the input data is not even stored elsewhere, allowing only a single pass over the data.<br\/><br\/>Due to the space bounds, data stream computation typically cannot seek exact solutions and therefore consider approximation algorithms to find near optimal solutions. Furthermore, the applications of data streams, i.e., monitoring and analysis, often prefer a fast near optimal solution compared to an expensive polynomial time exact solution.<br\/><br\/>The goal of this proposal is to design approximation algorithms for several key problems in data streams. The proposal will also attempt to develop broad techniques and frameworks for stream algorithms. Along with our theoretical investigations, we will also explore problems related to practice. Given the relevance of the data streams to large networks the proposed algorithmic research in data streams will have a broad<br\/>impact.","title":"Approximation Algorithms for Data Streams","awardID":"0430376","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["486185"],"PO":["562944"]},"98196":{"abstract":"Experiments in CyberSpace<br\/><br\/>Roy Maxion, Carnegie-Mellon University<br\/><br\/>Award 0430474<br\/><br\/>Abstract<br\/><br\/>It is important to be able to place high confidence in a detection system of any kind, particularly one intended for detecting attacks against the nation's critical information infrastructure. One requirement for establishing such confidence is to have a complete understanding of a detector's \"sweet spots\" and operational limits, so as to calibrate the detector optimally for the conditions under which it performs best. Due to a lack of standard test data sets and measurement procedures, such calibrations have not previously been done.<br\/><br\/>The proposed research will address methods of achieving high confidence in intrusion and malicious-insider detectors by developing: (a) metrics for gauging the effectiveness of detection algorithms; (b) gold-standard reference data sets, with calibrated ground truth, to be shared among producers and consumers of detection technologies, particularly for replication of scientific experiments that determine detection efficacy for new algorithms across a range of data conditions; and (c) a data synthesizer for producing reference and calibrated data sets.<br\/><br\/>This work will put decision makers in a position to know the flaws, the strengths, and the weaknesses of detectors before deployment. Knowing the operational limitations of one detector provides the opportunity to design a companion detector whose strengths compensate for the weaknesses of the other, enabling accurate and efficient composition of detectors for the first time.<br\/><br\/><br\/>Experiments in CyberSpace<br\/><br\/>Roy Maxion, Carnegie-Mellon University<br\/><br\/>Award 0430474<br\/><br\/>Abstract<br\/><br\/>It is important to be able to place high confidence in a detection system of any kind, particularly one intended for detecting attacks against the nation's critical information infrastructure. One requirement for establishing such confidence is to have a complete understanding of a detector's \"sweet spots\" and operational limits, so as to calibrate the detector optimally for the conditions under which it performs best. Due to a lack of standard test data sets and measurement procedures, such calibrations have not previously been done.<br\/><br\/>The proposed research will address methods of achieving high confidence in intrusion and malicious-insider detectors by developing: (a) metrics for gauging the effectiveness of detection algorithms; (b) gold-standard reference data sets, with calibrated ground truth, to be shared among producers and consumers of detection technologies, particularly for replication of scientific experiments that determine detection efficacy for new algorithms across a range of data conditions; and (c) a data synthesizer for producing reference and calibrated data sets.<br\/><br\/>This work will put decision makers in a position to know the flaws, the strengths, and the weaknesses of detectors before deployment. Knowing the operational limitations of one detector provides the opportunity to design a companion detector whose strengths compensate for the weaknesses of the other, enabling accurate and efficient composition of detectors for the first time.","title":"Experiments in CyberSpace","awardID":"0430474","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["550270","492191"],"PO":["529429"]},"92180":{"abstract":"This collaborative research grant awarded to a multidisciplinary team aims to develop algorithmic tools and a corresponding cyberinfrastructure for the development, coordination, utilization, and dissemination of knowledge regarding the application of optimization-based inverse methods for radiation treatment planning. The PIs bring to this research cross-disciplinary proficiency in Industrial Engineering, Computer Sciences, and Radiation Oncology, building on their recent research in the areas of information technology, optimization, and treatment planning. The algorithm development is based on their newly developed methodologies including slicing approaches and the Nested Partitions framework. Along with the development of algorithms for Radiation Treatment Planning, the PIs also plan to develop a website that will provide an infrastructure to researchers worldwide for the development, coordination, utilization, and dissemination of optimization methods in Radiation Treatment Planning research. <br\/><br\/>Approximately one million new cases of cancer are reported each year in the United States, with many times that number occurring worldwide. It is reported that more than 40 percent of people diagnosed with cancer in the US will undergo treatment with radiation therapy. Given the aging population, these numbers are expected to increase rapidly in coming years. It is expected that research results developed in this project will accelerate the development and understanding of efficient and effective automated Radiation Treatment Planning methods and software, resulting in clinical treatments of significantly higher quality, thereby enhancing both the quality of life and the longevity of cancer patients treated with radiation.","title":"Collaborative Research: Interdisciplinary Center for Radiation Treatment Planning","awardID":"0355567","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7368","name":"SCI TESTBEDS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1787","name":"SERVICE ENTERPRISE SYSTEMS"}}],"PIcoPI":[241550],"PO":["523516"]},"98890":{"abstract":"National Science Foundation<br\/>NETS - Research in Network Technologies and Systems <br\/>CISE\/CNS<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Proposal Number: 0435490<br\/>Principal Investigator: Ramasubramanian, Srinivasan<br\/>Institution: University of Arizona<br\/><br\/>Proposal Number: 0434872<br\/>Principal Investigator: Somani, Arun<br\/>Institution: Iowa state University<br\/><br\/>Proposal Number: 0434956<br\/>Principal Investigator: Subramaniam, Suresh<br\/>Institution: George Washington University<br\/><br\/>Proposal Title: Collaborative Research: NeTS-NR: Evolutionary Architectures for Ultra-Broadband Access Networks<br\/><br\/>There is a significant mismatch between core and access network capacities currently prevalent. In order to stimulate viable large-scale fiber deployment in the last mile, an evolutionary approach to building high-capacity access net-works is called for. This project develops such an approach by providing solu-tions that can evolve starting from lower-cost wireless-based ones to the ulti-mate fiber-to-the-home (FTTH) solution. Architectural solutions for metro net-works and neighborhood access networks that allow high-speed packet switch-ing and provide efficient aggregation methods to multiplex bandwidth from vari-ous access points are developed. In particular, an evolutionary path from more cost-effective wireless and free-space optics-based solutions to FTTH for neighborhood networking is developed. Solutions ranging from high-speed elec-tronic packet-switching to all-optical WDM\/TDM for metro networking are also investigated. Analytical modeling and simulation tools to evaluate the perform-ance of the architectures are also provided. By targeting a critical area in future networking infrastructure research, the project's outcomes will have immediate and wide practical implications in network development. The results of the pro-ject will lead to a roadmap for the development of the next generation access network infrastructure.<br\/><br\/>Dr. Admela Jukan<br\/>Program Director, CISE\/CNS<br\/>Aug 19, 2004.","title":"Collaborative Research: NeTS-NR: Evolutionary Architectures for Ultra-Broadband Access Networks","awardID":"0434956","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564881"],"PO":["402055"]},"97680":{"abstract":"Field phenomena are ubiquitous in nature (e.g. temperature, wind speed, hydraulic head, ocean current velocity) and can be represented by physically based equations constrained by mathematical boundary conditions. Field data are usually stored in computer databases by gridding the solutions of these equations. This approach is inefficient with respect to computer memory and reduces the flexibility of the data with respect to spatial scale. The objective of this project is to create a new Geographic Information System (GIS) database paradigm in which fields are represented by storing three object data types that constitute a mathematical model of the field: (1) a physically-based system of equations; (2) boundary conditions for those equations; and (3) a solution engine for the equations. If the mathematical solution to the system of equations is unique, then solving for the field represented by the mathematical model is equivalent to storing the field itself.<br\/><br\/>The test application for this method is a GIS database for ground-water protection. Shallow ground-water flow is driven by hydraulic boundaries (lakes and streams) and guided by the Darcy Equation. A ground-water hydraulic potential field (head) can be represented by storing lake and stream features along with flow equations. The mathematically exact Analytic Element Method (AEM) is used to solve the flow equations, so that the potential field can be retrieved at high precision, at any resolution, over any area in the database domain. The result will be a suite of GIS tools coupled to a numerical ground-water flow model and an object-oriented GIS database.<br\/><br\/>This project will produce a new archetype for storing, manipulating, and conceptualizing spatially distributed earth science data. It encourages an object-oriented rather than grid-oriented approach to natural fields. To promote broader dissemination of this approach, a specialist meeting will be held and a graduate course will be offered to students in the existing NSF IGERT program at the University at Buffalo.","title":"ITR - (ASE+NHS) - (dmc): Fields as Objects in Geographic Information Systems, Applications to Ground Water","awardID":"0426557","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["500431",257022],"PO":["565136"]},"98670":{"abstract":"This project will explore how people construe the representational states of robots, and the cognitive and perceptual basis for this construal, particularly with respect to vision. Specifically, a series of experimental studies will explore people's beliefs about a highly anthropomorphic humanoid robot named ISAC. The most basic experiments will ask whether subjects overestimate ISAC's ability to see visual changes. Follow-ups will explore the degree to which these misunderstandings affect assumptions that might underlie on-line human-robot interactions, and this research will explore the perceptual basis for invoking an anthropomorphic model. <br\/><br\/>People make systematic mispredictions about visual experience, vastly overestimating their own and others' ability to see visual changes, and further, these overestimates also apply to mechanical representational systems such as computers when they are described as having anthropomorphic beliefs, goals, and intentions. Research has also begun to identify specific perceptual cues that may serve to bootstrap knowledge about representations. The focus of this project is both to understand intentional vision in the human users of robotic systems, and ultimately to use this understanding as the basis for improving the artificial intelligence (AI) underlying the robots' processing of human users' intentions.<br\/><br\/> The research represents a novel application of insights gained from cognitive development to understanding how adults construe mechanical representational systems. As such, it not only has the potential to advance our understanding of adults' models of representation and the perceptual basis of these models, but it also has the potential to guide the development of the AI underlying human-robot interaction. In particular, this research will isolate situations in which user models of humanoid robots may diverge from reality, and specify an ecologically valid basis for AI programming that can structure the coding of intentional human action. <br\/><br\/> This research will not only enrich the existing collaborations between the cognitive science and engineering communities at Vanderbilt University, but it will also have a broader educational impact. Testing these ideas in the context of a humanoid robot will also provide a compelling context for both graduate and undergraduate students to consider basic questions of representation and mind, and it is expected that Vanderbilt undergraduates will play a crucial role in assisting with this research. <br\/><br\/>Humanoid robots are currently being developed to fill real-world functions ranging from household chores to elder-care. Among the challenges these devices pose, perhaps the most difficult is the need for a two-way understanding between the robots and their human users. Not only do humans need to understand robot capabilities and representational states, but robots require the same understanding of humans. This is particularly true if robots are to have productive and flexible interactions with humans, a process that requires a careful alignment of understanding that is dynamic enough to coordinate a complex flow of changing circumstances, beliefs, desires, and intentions. This research will strengthen the scientific basis for efforts to improve human-robot interaction.","title":"Intentional Vision in Humans and Robots","awardID":"0433653","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7322","name":"HSD - DEC, RISK & UNCERTAINTY"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["270496",259953,"527440","379284"],"PO":["564456"]},"96492":{"abstract":"This project, creating learning environments where children can be fully immersed in and engaged with their learning materials, aims at acquiring high-end visualization and motion capture in the form of the Tangible Interfaces Collaborative Learning Environments (TICLE) project. The project centers around the development of learning environments; techniques for handling multi-sensory cues in user interfaces, and the use of visual technology in learning and adaptation in intelligent agents. While studying interfaces amenable for human computer interaction and learning, proposed is the acquisition of a CAVE-based immersive environment as well as a motion capture system that will be integrated with it. Exploring techniques such as virtual reality, full motion tracking, and sensor input devices, the work involves working on gesture tracking and recognition\/ interpretation, determining how to relate gestures to manipulation of objects. The proposal addresses the following research directions:<br\/><br\/>Tangible Interfaces for Collaborative Learning Environments<br\/>Interaction Paradigms<br\/>Tracking and Representing the Learning Environment<br\/>Rectifying and Resolving Conflicts among Data Sources<br\/>Multi-Parametric Interfaces and Complex Multi-Media Control Situations<br\/>Increasingly Multi-Parametric Real-Time Multi-Media Control Situations<br\/>User Feedback Strategies for Multi-Parametric Real-Time Multi-Media Control Situations<br\/>Training and Learning Multi-Parametric Real-Time Multi-Media Control<br\/>Learning and Adaptation in Intelligent Agents<br\/>Learning and Adaptation by Artificial Intelligent Agents<br\/>Learning and Adapting Human Agents<br\/>Learning and Adapting as a Programming Metaphor<br\/>Several subprojects extend previous work into a 3D cave environment, requiring a significant jump in complexity of the system including computer vision, graphics, and systems; as well as quite a bit of training. For the latter project, a motion tracking system monitors the robots and the CAVE to give feedback to the robots. In the area of human computer interfaces (HCI), strategies will be developed for tracking and representing what is going on in the learning environment, including algorithms for rectifying and resolving conflicts among disparate sources (such as multiple pairs of cameras and sensors). Experimentation with various paradigms determines how students may best interact with the objects and information. Ways of interacting with the space and the data in natural, expressive ways, affecting multiple parameters will be explored. In the area of artificial intelligence, the focus will be in determining what the users understand or intend. The investigation of adaptive agents will continue, allowing the system to fill in missing data and learn over time. All tracks focus on how the HCI can enhance collaborative educational environments. <br\/><br\/>Broader Impact: Supporting research at a minority institution, the work involves undergraduate and graduate students, including those from underrepresented groups. Exposing a wider audience into science, the work on TICLE exhibits high potential for broader impact in education. Moreover, outreach to K-12 is already under way.","title":"MRI: Acquisition of CAVE for Experiments in the Creation of Collaborative Learning Environments","awardID":"0420996","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["477225","505729","362946"],"PO":["557609"]},"97020":{"abstract":"Representation and Computation in Natural Vision<br\/><br\/>In natural environments, objects are viewed under a wide variety of lighting conditions, poses, backgrounds, and juxtapositions with other objects. Artificial vision systems that are sufficiently invariant to accommodate such variations are never sufficiently selective. The rich structure of real images offers a multitude of chance arrangements, many of which cause systems to falsely detect an object that is not there. On the other hand, systems that are highly selective are at the same time highly prone to missed detections in the face of natural variability. The visual systems of humans and animals, in contrast, are able to see accurately under a wide range of viewing conditions--how is it that biological systems are both selective and invariant?<br\/><br\/>The pursuit of this question leads to an analogous question about complex cells and other invariant cell types that are ubiquitous in the ventral visual pathway. Their strength would appear to be their weakness: How is it possible for the visual system to build selectivity out of invariance? Models of complex cells suggest an explanation. Complex and other invariant cell types, by virtue of their nonlinear response characteristics, necessarily possess a functional connectivity whereby these cells become functionally connected to a generally small subset of their inputs. This commitment is circumstantial, inasmuch as it depends on the particular pattern in the receptive field. Functional connectivity is a demonstrable mathematical property of virtually all of the non-linear models put forward to date for complex-cell receptive-field properties. What is more, these observations lead to the conclusion that pairs of such cells that possess overlapping receptive fields will demonstrate a functional common input. This too is circumstantial, and in fact functional common input is high exactly when the patterns in the respective receptive fields \"fit together\"---correspond to pieces of a larger whole. <br\/><br\/>These observations suggest a solution to the dilemma of invariance versus selectivity: pieces that fit properly together generate a high degree of functional common input, which manifests itself by a statistical dependence between otherwise invariant representations, most likely in the form of partial synchrony, thereby signaling a composition of parts to cells deeper in the visual pathway. <br\/><br\/>In search of experimental confirmation of this proposed answer to the selectivity\/invariance dilemma, the investigators employ new statistical and methodological techniques to study new questions about the receptive-field properties of invariant cells, and to measure new variables in the joint statistics of invariant cells with overlapping receptive fields.","title":"CRCNS: Representation and Computation in Natural Vision","awardID":"0423031","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1699","name":"COGNEURO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T469","name":"NGIA-COMP NEUOSCIENCE GRANT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V586","name":"NGIA-CRCNS REP & COMP IN NATUR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V917","name":"NGIA-REPRES & COMP IN NAT VISI"}}],"PIcoPI":["446347","538086","379746","422017"],"PO":["564318"]},"98472":{"abstract":"Recent years have seen the advent of DNA-based computation, as well as the development of a<br\/>DNA nanotechnology that produces objects, robust devices and periodic arrays. We propose to<br\/>combine these areas, by using a robust 2-state DNA device and DNA array assembly techniques<br\/>to prototype a programmable finite state machine capable of performing simple computations.<br\/>The goal is to produce a system that is programmable, produces an output and is reusable.<br\/>We exploit connections between Wang tiles, finite state machines (transducers) and com-<br\/>putable functions. The main idea uses DNA TX molecules to represent transducer transitions<br\/>and a sequence of 2-state DNA devices to program the input. Once the input is programmed,<br\/>the computation of the transducer is obtained solely by DNA self-assembly. Further more, iter-<br\/>ations and composition of transducers is also possible and hence all computable functions can<br\/>be obtained.<br\/>The project is composed of two major tasks,<br\/>1. To simulate computation by a finite state machine with output by a single assembly of<br\/>input molecules and TX transition molecules.<br\/>2. To obtain transducer computation with a programmale input by DNA 2-state devices and<br\/>TX molecules.<br\/>Intelectual Merit. The project prototypes a nanomachine that is potentially programmable<br\/>and produces an output that can serve as an input in a new device or as a template for orga-<br\/>nization and growth of nanostructures used in nanoelectronics. The proposed machine has a<br\/>potential for an algorithmic control of this growth. Theoretically, the design of the machine and<br\/>the need for encoding (locally and globally) that is error correcting will lead to development of<br\/>new techniques in algorithmic pattern design.<br\/>Broader Impact. Research in DNA-based computation relies on many disciplines, such as<br\/>computer science, DNA chemistry, nucleic acid enzymology, thermodynamics and molecular<br\/>physics. Few individuals enter in to it with adequate preparation. We will attempt to provide<br\/>some remedy for this problem during the course of this project. The graduate, undergraduate<br\/>and high school students who participate in this work will be uniquely trained and will be<br\/>prepared as unique interdisciplinary research scientists. Three graduate students (two at New<br\/>York University and one at the University of South Florida) will receive graduate training<br\/>through this award. They will meet with each other, and become familiar with the thinking and<br\/>methodologies of their opposite colleagues in the other university. In addition, we will include<br\/>an undergraduate in the project, to gain experience in combining computer science with DNA<br\/>nanotechnology. We aim to include a high school student in the parts of the work for which<br\/>they are eligible (e.g., computation and experiments not entailing the use of radiation).<br\/>Besides their own nanotechnological and mathematical disciplines, the PI and the co-PI are<br\/>prominent members of the DNA-based computation community. Both facets of this commu-<br\/>nity recognize that it is converging with structural DNA nanotechnology. In recognition of<br\/>this interdisciplinary phenomenon, the PI and the co-PI are involved in founding (as president<br\/>and treasurer, respectively) the \\International Society for Nanoscale Science, Computation and<br\/>Engineering\" with a goal to facilitate communication among the members of the participating<br\/>communities, and to recognize and promote the careers of the younger members, by offering<br\/>them recognition and a forum for their ideas.","title":"Nano: Programmable Finite State Machines Achieved by DNA Self-Assembly","awardID":"0432009","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}}],"PIcoPI":["554823","506031"],"PO":["521045"]},"99462":{"abstract":"This is a collaborative grant with two PIs; Javed Mostafa of Indiana, and David Stark of Columbia. <br\/><br\/>Intellectual Merit<br\/>With a grant from the NSF Digital Government Program, David Stark has been studying the role of information technologies in the public debate surrounding the rebuilding of Lower Manhattan in the wake of the September 11 attacks on the World Trade Center. In the process of conducting that research Stark's team has assembled an extensive digital archive containing 5,000 participant oral statements from one town hall meeting and an additional 19,000 oral statements collected at 240 different venues around New York City in the 'Imagine New York Envisioning Workshops'. These gathered statements provide a rich opportunity for testing various strategies of computer-assisted interpretation because they provide an opportunity to compare the conceptual patterns discerned by human intelligence with findings reached through the analytical methods of artificial intelligence. Supporting the initial explotation of that archive is the purpose of this grant.<br\/><br\/>The technical component of this grant arises from work Javed Mostafa has done under an NSF ITR grant. Data mining research concentrating on spontaneous human conversations is at an early stage of development. Mostafa's approach to data mining can offer different ways to analyze the same data. The project has three specific goals: 1) to detect emergent concepts by applying techniques that do not impose any a priori conditions; 2) to use techniques for analyzing known concepts by applying constraints on the mining process, and 3) to develop visualization of the results to facilitate interpretation by social scientists and support direct validation by citizen participants. <br\/><br\/>Broad Impact <br\/>Computer mediated communication offers new channels for citizens to express their views to elected officials and government agencies. Often, the resulting deluge of comments poses a technical and political challenge. How can officials\/agencies make sense of large-scale citizen input? How can meaningful patterns be efficiently and effectively identified? This project will contribute to advancing understanding of the opportunities and the limitations of computer-assisted interpretation. Its findings will be of considerable interest to scholars as well as to government managers responsible for the rebuilding of lower Manhattan. <br\/><br\/>Summary <br\/>Many challenges involved in creating new data mining tools demands an interdisciplinary collaboration for access to new data; this project offers such an opportunity. This time-critical testing of artificial intelligence methods will be important in understanding the public input to rebuilding lower Manhattan.","title":"Collaborative Research: SGER: Computer-Assisted Interpretation of Citizen Input in Rebuilding Lower Manhattan","awardID":"0439096","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["525526"],"PO":["371077"]},"98252":{"abstract":"This project is investigating and developing information modeling for comparative visualizations and analyses of complex chemical separations produced by comprehensive two-dimensional gas chromatography (GCxGC). GCxGC is a powerful new technology that provides an order-of-magnitude increase in separation capacity over traditional GC. A few advanced laboratories are pioneering GCxGC for a variety of applications, such as environmental monitoring and health-care, but researchers lack advanced information technologies for analyzing and interpreting the large, complex data generated by GCxGC.<br\/><br\/>The models being developed in this project abstract essential analytical information for comparative visualization and analyses. Analytical methods are being developed to extract model components from the structural characteristics of both GCxGC intensity data and data from GCxGC with mass spectrometry (GCxGC-MS). The models support calibration for varying chemical concentrations and measurements of the quality of fit to the data. Comparative visualizations of the GCxGC information models employ multiple viewing strategies with colorization and animation to provide users with multiple avenues for interactive analyses. Interactive analyses support comparisons with view navigation and controls, queries and edits of model-based information and metadata, and structured reporting.<br\/><br\/>The model-based information technologies facilitate advanced chemical analyses in a broad range of problems. The project is demonstrating their value for two applications of GCxGC. One application analyzes changes of complex mixtures of petroleum hydrocarbons in the environment following an oil spill. The other application uses GCxGC to fingerprint fragrances for classification and identification.","title":"Collaborative Research: SEI: Information Modeling for Comparative Visualizations and Analyses - Informatics for Comprehensive Two-Dimensional Gas Chromatography","awardID":"0430835","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["555165"],"PO":["565136"]},"98263":{"abstract":"A stochastic information fusion methodology is developed to assimilate electrical resistivity tomography, high-frequency ground penetrating radar, mid-range-frequency radar, pneumatic\/gas tracer tomography, and hydraulic\/tracer tomography to image fractures, characterize hydrogeophysical properties, and monitor natural processes in the vadose zone. The information technology research will develop: (1) mechanisms and algorithms for fusion of large data volumes; (2) parallel adaptive computational engines supporting parallel adaptive algorithms and multi-physics\/multi-model computations; (3) adaptive runtime mechanisms for proactive and reactive runtime adaptation and optimization of geophysical and hydrological models of the subsurface; and (4) technologies and infrastructure for remote (pervasive) and collaborative access to computational capabilities for monitoring subsurface processes through interactive visualization tools.<br\/><br\/>The combination of the stochastic fusion approach and information technology can lead to a new level of capability for both hydrologists and geophysicists enabling them to \"see\" into the earth at greater depths and resolutions than is possible today. Furthermore, the new computing strategies will make high resolution and large-scale hydrological and geophysical modeling feasible for the private sector, scientists, and engineers who are unable to access supercomputers, i.e., it is an effective paradigm for technology transfer.","title":"Collaborative Research: SEI (EAR): Adaptive Fusion of Stochastic Information for Imaging Fractured Vadose Zones","awardID":"0430884","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":[258755],"PO":["563727"]},"98153":{"abstract":"This collaborative Industry\/University Cooperative Research Center will perform research in three critical, overlapping areas. Cooperative Communications and Networking research will examine wireless networks build out of nodes that cooperate at the physical and network layers. Cooperative networks offer enhanced capacity, reliability and efficiency relative to infrastructure and ad hoc networks. The second area of research focuses on extending the battery life of portable terminals thereby removing a major enhancing the convenience and value of wireless terminals and sensors. The third research area is Wireless Applications and associated Information Delivery mechanisms. Wireless Applications under investigation include content distribution, applications that leverage the ubiquity of wireless infrastructure with location awareness, and applications that adapt to the capacity limitations of the wireless vis-a'-vis the wired network. Each project focuses on a specific mode of wireless connectivity of the Internet to portable mobile information devices. In addition to developing and evaluating protocols and applications, Information Delivery research addresses security and robustness.","title":"Collaborative Research: Industry University Cooperative Research Center for Wireless Internet","awardID":"0430145","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"H430","name":"ARMY"}}],"PIcoPI":[258464,"421979","525973","525973","528387",258469],"PO":["565057"]},"98285":{"abstract":"Fluorescence optical diffusion tomography (FODT) uses diffusely scattered light to image deep into tissue. This new biomedical imaging modality has tremendous potential in the early diagnosis of cancer and the development of new pharmaceuticals because: <br\/><br\/>1) it offers the chemical and molecular specificity of spectroscopy; <br\/><br\/>2) it can also be coupled to fluorescent molecular imaging agents to target specific cancers or biological processes of interest; <br\/><br\/>3) it is minimally invasive since it only requires exposure to light; <br\/><br\/>4) it has the potential to be low cost since it does not require coherent optical sources and demodulation. <br\/><br\/>However, a critical barrier to this technology is the creation of algorithms which can reconstruct images from light that has been diffusely scattered by seemingly opaque tissue. This research creates the foundation for FODT technology by developing the algorithms that can accurately reconstruct FODT images from this diffusely scattered light. <br\/><br\/>The algorithms are based on Bayesian inverse methods and multigrid optimization of the resulting cost functionals. Critical goals of the research are to reconstruct accurate fluorescence yield volume renderings, <br\/>to directly estimate pharmaco-kinetic parameters, to form reconstructions which use modulation and wavelength diversity to improve specificity, and to develop novel polarization-sensitive imaging methods. <br\/><br\/>2. A level of effort statement: <br\/><br\/>The PIs will make every attempt to meet to the original scope and level of effort of the project.","title":"Parametric Optical Diffusion Tomography","awardID":"0431024","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["518523",258813],"PO":["564898"]},"98054":{"abstract":"The proposed research considers computational models for multisensor, multiframe superresolution.<br\/>The underlying mathematical model is a Fredholm integral equation of the first kind. For the<br\/>superresolution problem, not only is the input data contaminated by noise, but the parameters <br\/>defining the linear operator are uncertain because of uncertainty in sensor alignment. <br\/><br\/>The noisy input makes the problem a candidate for Tikhanov regularized least squares. The uncertainty in <br\/>the operator make it a candidate for regularized total least squares. Moreover, the uncertainty in <br\/>the linear operator is structured, thus structured total least squares models are appropriate.<br\/>This project considers these least squares and total least squares models and appropriate methods for<br\/>regularizing them. The merits of this activity according to NSF criteria are given below.<br\/><br\/>Intellectual Merit<br\/><br\/>1. The deployment of space variant regularization to the recently proposed least squares <br\/>and total least squares models.<br\/><br\/>2. The application of total least squares algorithms and space variant regularization to the solution<br\/>of blind deconvolution problems using images acquired by multisensor arrays.<br\/><br\/>3. The extension of structured total least squares algorithms to red--green--blue (RGB) color imaging.<br\/><br\/>4. The application of wavelet superresolution algorithms to multisensor array acquired low resolution<br\/>degraded imaging.<br\/><br\/><br\/>Broader Impact<br\/><br\/>1. The superresolution problem has impact upon military, commercial, and health care<br\/>applications in diverse disciplines such as bioengineering,satellite imaging, and electrical <br\/>and computer engineering. Other intriguing possibilities include substituting expensive high resolution <br\/>instruments such asscanning electron microscopes by their cruder, cheaper counterparts and then applying <br\/>technical methods for increasing the resolution to that derivable with much more costly equipment.<br\/><br\/>2. Survey articles will be prepared to provided tutorial information on our computational methods.<br\/>This is in addition to publishing the project's results in appropriate refereed journals and conferences.<br\/><br\/>3. The PI and co-PI intend to recruit 4 REUs per year from Penn State's University Scholars program.<br\/><br\/>4. Penn State graduate students will be collaborators with the expectation of producing<br\/> Ph.D. theses related to the project.","title":"Efficient Computational Methods for Robust Multispectral Multiframe Superresolution","awardID":"0429481","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[258224,"485393"],"PO":["399214"]},"98175":{"abstract":"Proposal Number: CNS-0430276<br\/><br\/>TITLE: A Survivable Information Infrastructure for National Civilian BioDefense<br\/><br\/>PI: Cristina Nita-Rotaru <br\/><br\/>This project focuses on the theoretical foundation and the protocols that facilitate a survivable information infrastructure that meets the critical requirements of a national emergency response system. Specifically, the project will address the following challenges:<br\/>(1) expand the existing theoretical framework to analyze the behavior of malicious and colluding participants; (2) design and construct a scalable survivable messaging system that operates correctly under a strong adversarial model that includes insider threat and denial of service attacks; (3) design and construct information access protocols that protect against compromised database servers providing incorrect data or servers that deny access to legitimate users; and (4) prevent malicious users from learning unauthorized information. The domain of application for this work is the Clinicians' Biodefense Network (CBN), a nationwide Internet-based information exchange system designed to provide clinicians with critical information in the aftermath of a bioterrorist attack. The CBN is designed to mitigate benign Internet faults and to resist a physical attack on one location. However, it is not able to correctly operate under a stronger threat model that includes insider attacks. Solutions for this stronger threat model are not currently available and present a major research challenge. This project will construct a prototype survivable system based on the CBN, and from it draw general principles. It will develop a solid theoretical foundation and novel system tools to facilitate building national emergency networks that are resilient against cyber-attacks in crisis situations, when those networks are most urgently needed.","title":"Collaboration: A Survivable Information Infrastructure for National Civilian BioDefense","awardID":"0430276","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["519699"],"PO":["521752"]},"97086":{"abstract":"This project, evaluating protocols for wireless networks and developing scaling techniques for physical environments, aims at deploying an anechoic chamber for interference control, forming a testbed, referred to as the Wireless Wind Tunnel. The uses of the testbed focus on:<br\/> Evaluation of wireless protocols (WP) in controlled environments,<br\/> Development of channel models suitable for simulation-based evaluation of WPs, and<br\/> Evaluation of techniques for scaling the physical environment to facilitate realistic wireless experiments.<br\/>The Wireless Wind Tunnel (WWT) addresses some of the limitations based on computer evaluations resulting from the present insufficient understanding of channel and system models for wireless networks. These are not well understood and brute force accurate simulation of the wireless environment are at present too complex. Existing hardware testbeds suffer from one or both of the following shortcomings: <br\/> Experiments often cannot be repeated due to interference by other wireless devices operating in the same frequency range and <br\/> The parameters of the experiment (such as the mobility patterns of the mobiles and scatterers in the environment) are not fully controllable.<br\/><br\/>Broader Impact: This work impacts the education mission, including course work, laboratories, student projects. The testbed will serve as a demonstration tool. New educational opportunities will open involving experimental research providing better training and motivation. Facilities will be made available to a larger pool of researchers. Additional impact is expected on communications systems in practice.","title":"RR: Wireless Wind Tunnel: A Testbed for Experimental Evaluation of Wireless Networks","awardID":"0423431","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["541861","557160","553537","223414","460382"],"PO":["557609"]},"98186":{"abstract":"0430378<br\/>PI Alex Aiken<br\/>Collaborative Research: Type Qualifiers for Software Security<br\/>0430118 Foster, Jeffrey 0430585 Wagner, David<br\/><br\/>This research aims to develop tools and techniques to find and eliminate security vulnerabilities in software. The approach is based on static analysis, which by analyzing source code can model all possible executions of a program. The distinguishing feature of the project is to show that very large applications are free from classes of security vulnerabilities. Thus, the focus is not just in finding security holes in software, but in verifying their absence. Previous experience has shown that simple, approximate tools do not find all or<br\/>even nearly all security vulnerabilities; the higher assurance given by verification is needed. The experimental goal is to apply these techniques to the Linux kernel, a security-critical application with<br\/>millions of lines of code.<br\/><br\/>The main technical approach being investigated is based on user-defined type qualifiers that refine the standard types of the programming language. Previous work has shown that type qualifiers are a natural and useful way to explicitly specify desired security properties that are normally only implicit in a program. In much the same way that a correctly typed program cannot have run-time type errors, having consistent type qualifiers throughout a program implies that the property expressed by those qualifiers must hold in every<br\/>execution. The significance of this work is that, if successful, it will improve the understanding of how to perform sophisticated static analysis of very large programs. The broader impact will be in discovering and<br\/>repairing new security vulnerabilities in widely-used software infrastructure and in verifying that some of that infrastructure is free from at least some security flaws.","title":"Collaborative Reseach: Type Qualifiers for Software Security","awardID":"0430378","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T470","name":"DARPA-NSF CYBER TRUST PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T951","name":"DARPA - CYBER TRUST PHASE III"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V901","name":"DARPA-NSF CYBER TRUST PROGRAM"}}],"PIcoPI":["507674"],"PO":["564388"]},"98076":{"abstract":"Exploring Network-on-Chip (NoC) Architecture Design Space<br\/>Abstract<br\/><br\/><br\/>Design of scalable, high performance, area and energy efficient network-on-chip (NoC) architectures has emerged as a critical issue for orchestrating the system-on-chip (SoC) design paradigm. However, unlike the traditional multiprocessor interconnects, design of NoC architectures poses a whole set of new challenges in terms of on-chip area budget, energy efficiency, and reliability. The motivation of this research is to explore the NoC design space considering four closely intertwined issues. These are area constraint design and analysis of NoC architectures, developing detailed energy models for on-chip interconnects, designing suitable fault-tolerant techniques and reliability models, and developing a comprehensive testbed for conducting performance, energy and reliability tradeoffs in designing NoCs.<br\/><br\/>Since on-chip interconnects are predicted to be the performance bottlenecks for SoC architectures, the success of this research is likely to have a significant impact on the design of future SoCs, which are increasingly used in a wide range of applications. The simulation\/analytic tools and techniques developed in this research will be used for training undergraduate and graduate students. The tools will be available through our Web site for use by other researchers, and we envision direct transfer of our ideas to industry.","title":"Exploring Network-on-Chip (NoC) Architecture Design Space","awardID":"0429631","effectiveDate":"2004-09-15","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["550859","549542"],"PO":["562984"]},"98197":{"abstract":"Proposal Number: 0430477<br\/><br\/>TItle: OS Support for Application Installation, Execution, and Management in<br\/>an Untrustworthy World<br\/><br\/>PI: Steven Gribble <br\/><br\/>Modern computer users face many security threats and manageability obstacles. Today's software is increasingly complex, buggy, and prone to vulnerability. In addition to familiar threats such as worms and viruses, users must contend with new, more subtle attacks, such as the spread of spyware. Unfortunately, operating systems do little to help users address the security and vulnerability challenges of the networked environment. For example, it is difficult to determine what programs are running on a system, or what code is responsible for generating visible activity (such as network traffic, file system activity, or windowing activity). <br\/>This research focuses on the construction of a new application and operating system architecture based on lightweight virtual machines, with each application being both installed and isolated in its own VM. Installing and removing applications becomes simple, as a VM provides a clean container in which all of the application dependencies and resources can be embedded. Tracking an application and associating activity with its source becomes possible, since activity is easily observable through and traceable to the narrow VM interface. This architecture provides stronger security properties, since malicious applications are isolated from benign programs and data, and a vulnerability within an application no longer puts other applications at risk. The impact of this work will be to provide users with trustworthy infrastructure that they can depend on, and to mitigate damage to users in the case of successful attacks.","title":"OS Support for Application Installation, Execution, and Management in an Untrustworthy World","awardID":"0430477","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7228","name":"DATA AND APPLICATIONS SECURITY"}}],"PIcoPI":["450764","532591"],"PO":["521752"]},"98087":{"abstract":"The potential and promise of multiple antenna techniques has now resulted in widespread considerations for the use of these in a variety of contexts: for wide area wideband wireless transmission in next generation cellular systems; for local area hot-spot data service overlays in cellular systems; for emerging short-range wireless LAN networks; for promoting efficient spectrum sharing in the unlicensed bands; and a variety of collaborative techniques in wireless adhoc networks. A key attribute required of any multiple antenna technique to be successful, in any of the above contexts, is the need for reliable and efficient channel state information (CSI). Delay requirements imposed by wireless applications and the time variations in the channel, require not only reliability in CSI information, but also that the feedback of such information be fast and frequent. This project studies the fundamental limits of CSI feedback schemes that can be used in multiple antenna multiuser wireless communication systems. <br\/><br\/>A fundamental issue studied is if it is necessary for reliable CSI feedback to be optimally quantized and encoded in a Shannon theoretic sense? Specifically, unquantized and uncoded (UQ-UC) CSI feedback schemes are studied, that have the attractive feature of avoiding the delays due to quantization and coding, while still being optimal in certain situations relating to the uplink and downlink of wireless channels. In cases where such \"zero-delay\" schemes are sub-optimal, enhancements that can substantially improve performance are studied via (a) performance bounds for UQ-UC CSI feedback in FDD and TDD systems, (b) CSI feedback receivers, (c) information capacity of transmitter optimization in multiple antenna multiuser systems, and (d) comparative evaluation of UQ-UC CSI feedback with practical coded transmission.","title":"Unquantized and Uncoded Channel State Information Feedback in Multiple Antenna Multiuser Wireless Systems","awardID":"0429724","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["475434"],"PO":["564898"]},"98098":{"abstract":"This project addresses the growing gap between nominal and exceptional peak operating conditions in modern microprocessor designs with particular emphasis on thermal and power delivery systems. In this project, we will develop and evaluate an adaptive, multi-disciplinary approach to the problem. We propose to characterize the prevalence of voltage and thermal emergency conditions and explore methods to sense and detect these emergencies at runtime. We also propose to develop flexible and extensible architectural interfaces to pass alarm information to a novel binary translation layer, where the alarm information is processed and the execution stream modified to avoid recurrences of the original emergencies.<br\/><br\/><br\/>This project seeks to address a key problem in the design of future computer systems; particularly in application domains where energy efficiency and the ratio of price-to-performance are more important design principles than peak performance. The proposed project aims to realign the design of microprocessors given this emerging trend and allow a greater number of applications in high-volume web services like web searches, computational genomics\/biology, and massively multi-player role-playing games (e.g., military simulations) to achieve substantial price\/performance gains.","title":"An adaptive alarm-based approach to high-performance\/low-cost computing","awardID":"0429782","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7368","name":"SCI TESTBEDS"}}],"PIcoPI":["255915","518228","518229"],"PO":["550859"]},"95580":{"abstract":"TRACKING MULTIMODAL COMMUNICATION IN HUMANS AND AGENTS<br\/><br\/>This project investigates multimodal communication in humans and agents, focusing on two linguistic modalities - prosody and dialog structure, which reflect major communicative events, and three non-linguistic modalities - eye gaze, facial expressions, and body posture. It aims to determine<br\/>1. which of the non-linguistic modalities align with events marked by prosody and dialogue structure, and with one another;<br\/>2. whether, and if so when, these modalities are observed by the interlocutor;<br\/>3. whether the correct use of these channels actually aids the interlocutor's comprehension.<br\/>Answers to these questions should provide a better understanding of the use of communicative resources in discourse and can subsequently aid the development of more effective animated conversational agents.<br\/><br\/>The outcomes of our observations will be modeled on controlled elicited dialog. To assure robust information on the interplay of modalities, we control the base conditions, genre, topic, and goals of unscripted dialogs. An ideal task for this is the Map Task, where dialog participants work together to reproduce on one player's map a route preprinted on the other's. The two maps, however, are slightly different, so that each player holds information important to the other. This scenario triggers a highly interactive, incremental and multimodal conversation.<br\/><br\/>In the proposed project a basic corpus of Map Task dialogues will be collected while recording spoken language, posture, facial expressions, and eye gaze. Hand gestures, discouraged by the task, will be recorded where they occur. These findings will be used in the Behavior Expression Animation Toolkit (BEAT) in order to augment the current intelligent system AutoTutor. AutoTutor has been developed for a broad range of tutoring environments that coach the student in following an expected set of descriptions or explanations. The coach-follower roles in the Map Task scenario make it possible to easily change the scenario for AutoTutor. In a series of usability experiments interactions of dialog participants with AutoTutor will be recorded. These experiments allow us to record not only the participant's impressions, but also his or her efficiency (the time to complete map, latency to find named objects, deviation of the instruction follower's drawn route from the instruction giver's model), and communicative behavior (discourse structure, gaze, facial expressions, etc.).<br\/><br\/>The research resulting from this project will benefit a large variety of fields, including cognitive science, computational linguistics, artificial intelligence, and computer science. In addition, the integration of the modalities into a working model will advance the development and use of intelligent conversational systems.","title":"Tracking Multimodal Communication in Humans and Agents","awardID":"0416128","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7180","name":"EDUCATIONAL RESEARCH INITIATIV"}}],"PIcoPI":["482198",250637,"309902",250639,250640],"PO":["564318"]},"98990":{"abstract":"As human-induced environmental change continues, society is facing an increasing array of pressing environmental challenges. Answers to these complex challenges must be informed by coordinated, long-term, interdisciplinary research. Following a very successful two decades of science, training and outreach, the Long-Term Ecological Research (LTER) Network is poised to address a set of new initiatives to be pursued in response to these environmental \"Grand Challenges.\" It is this background that sets the stage for intensive Network-wide planning activities that started at the last LTER All-Scientists Meeting (September 2003), and that would continue under this proposal for another 24 months. This planning effort has three specific objectives: (1) Develop a plan for LTER network-level science, technology, and training, (2) Explore alternative governance, planning and evaluation structures for managing LTER Network science, and (3) Envision and plan for education, training, outreach, and knowledge exchange activities to link LTER science with application needs.<br\/><br\/>Broader Impacts: This planning activity will create the framework necessary for the<br\/>LTER Network to (1) increase the scale and scope of activity needed to address a number of ecological Grand Research Challenges, (2) achieve a higher level of coordination and complementarity among the research sites, (3) incorporate new, enabling technologies into LTER research, (4) broadly train the next generation of ecologists, and (5) improve and increase the exchange of knowledge between science, managers and policy makers. In doing so, the LTER Network will actively pursue a new level of collaboration, synthesis and integration to address challenging ecological questions now and in the future.","title":"Preparing the LTER Network for Collaborative Science, Education and Synthesis: A Planning Proposal","awardID":"0435546","effectiveDate":"2004-09-15","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7368","name":"SCI TESTBEDS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1195","name":"LONG TERM ECOLOGICAL RESEARCH"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"5209","name":"ENVIR SOCIAL & BEHAVIOR SCIENC"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7381","name":"ECOSYSTEM SCIENCE CLUSTER"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0807","name":"Division of MOLECULAR AND CELLULAR BIOSCIE","abbr":"MCB"},"pgm":{"id":"1089","name":"MICRO OBS & MICRO INTER & PRO"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1650","name":"BIOLOGICAL OCEANOGRAPHY"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7355","name":"INSTRUCTIONAL MATERIALS DEVELP"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1402","name":"Division of ANTARCTIC INFRASTRUCTURE & LOG","abbr":"AIL"},"pgm":{"id":"5205","name":"ARCTIC RESRCH SUPPRT & LOGISTI"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1403","name":"Division of ANTARCTIC SCIENCES DIVISION","abbr":"ANT"},"pgm":{"id":"5111","name":"ANTARCTIC ORGANISMS & ECOSYST"}}],"PIcoPI":["528613","430485","331916","159244","159244","360936"],"PO":["561879"]},"96471":{"abstract":"This proposal, acquiring a high-end scanner device for high-precision mapping and visualization applications, supports research in various projects in civil engineering and architecture ((re-)engineering in as-built environments), computer graphics (body motion), robotics (humanoid robotics locomotion), and haptics (force-based manipulation) among others. The research constitutes a substantial change in approaching disciplines where the loss of information (due to current-generation site) and equipment form major barriers. Improving the accuracy and quantity of information capture for direct applications in construction management, for object recognition and classification, and for model building more broadly, the work addresses the following projects:<br\/>Information technology enabled construction management with research on early detection and management of defects at construction sites, and utilization of advanced technologies in dynamic service networks,<br\/>Computational building evaluation in architecture with simulation of building designs and visualization of as-built environments,<br\/>Computer graphics and humanoid robotics with specific research on high fidelity animation, perception\/performance experiments in virtual environments, humanoid locomotion among obstacles and force-based manipulation, and<br\/>3D perception with specific on-going and future research on model building, object recognition, and classification.<br\/>Broader Impact: The infrastructure, supporting research across multiple departments, includes improvement on 3D scanning technology and 3D content acquisition, and offers education and training in the use of the new scanning technology and its applications. The involvement of undergraduates appears particularly suitable due to the promise of new engineering approaches.","title":"MRI: Acquisition of a High-Performance Laser Scanner for Research and Education in Civil Engineering, Architecture, Robotics and Computer Graphics","awardID":"0420933","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["301377","438709","520920","560865","553300"],"PO":["557609"]},"99562":{"abstract":"Proposal Number: 0439886<br\/>PI: Jonathan Turner <br\/>Institution: Washington University <br\/><br\/>Proposal Number: 0440940<br\/>PI: Scott Shenker <br\/>Institution: University of California, Berkeley <br\/><br\/>Proposal Number: 0439642<br\/>PI: Thomas E. Anderson <br\/>Institution: University of Washington, Seattle<br\/><br\/>Proposal Number: 0439842<br\/>PI: Larry Peterson <br\/>Institution: Princeton University <br\/><br\/><br\/>Title: Collaborative Research: Virtual Networking - Enabling Innovation in Networks and Services <br\/><br\/>Abstract: <br\/><br\/>The Internet is one of the great technology success stories of the twentieth century, enabling greater access to information and providing new modes of communication among people and organizations. Unfortunately, the Internet's very success is now creating obstacles to innovation in the networking technology that lies at its core. In order<br\/>to free the global communications infrastructure from stagnation, the nation must find ways to enable its continuing renewal. This planning grant is developing a case for network virtualization as a means to enable innovation in networks and services. Virtualization allows multiple logically independent virtual networks to share a common physical infrastructure or substrate. This program is developing a plan for a major new research initiative in network virtualization that includes both basic research, the development of key technology components and the creation of an experimental testbed, to establish feasibility and provide a context in which networking researchers can develop innovative new network architectures and services. The program is articulating the case for network virtualization, soliciting input from the network research community and working with the community to develop recommendations to NSF for a major initiative in this area.","title":"Collaborative Research: Virtual Networking--Enabling Innovation in Networks and Services","awardID":"0439842","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560046"],"PO":["292741"]},"98253":{"abstract":"Exact Geometric Computation (EGC) is one of the most successful approaches to nonrobust numerical computation. The basis of EGC is {\\em guaranteed accuracy computation}, a computational mode in which each numerical quantity can be computed to any user-specified accuracy. In the last 10 years, major software libraries and many robust algorithms and applications have been implemented based on EGC principles. <br\/>What is lacking is a model of computation to capture this mode. <br\/><br\/>The PI introduces a {\\em theory of real approximation} which fills this gap. The approach postulates a suitable countable set $\\mathbb{F}$ $\\mathbb{Z}\\ib\\mathbb{F}\\ib\\mathbb{R}$) of {\\em representable reals}, with the property that all numerical input and output come from $\\mathbb{F}$. Two current theories directly address the specific nature of real computation: the TTE School of Weihrauch and others, and the Algebraic School from Blum, Shub and Smale (BSS). The PI's approach is distinct from both schools, but complements them. The PI further introduces a {\\em Numerical Computational Model}, seen as an intermediate model between the Turing model and the BSS model. The development is informed by classical complexity theory, yet directly motivated by current development of EGC software.<br\/><br\/>Research topics include:<br\/><br\/>* The computability and complexity of real approximation. Connections are made to standard complexity theory via such topics as $NP$-completeness, and also to the algebraic theory of Blum, Shub and Smale.<br\/><br\/>* Fundamental questions motivated by the implementation of EGC software: dynamic constructive zero bounds, geometric separation bounds, complexity of approximate evaluation, and precision-sensitive complexity.<br\/><br\/>Some of these questions (e.g., zero bounds) involve a combination of experimental validation with theoretical studies. Implementation is done using the Core Library, the PI's ongoing open-source library project.<br\/><br\/>INTELLECTUAL MERIT.<br\/>One addresses a topic of long-standing interest, namely, providing a foundation for real computation and its complexity. The PI's approach to real approximation is concise, provably distinct from current approaches, unexpected, yet firmly grounded in computing practice. The new theory is, by design, a theory for EGC. But it can also serve as a foundation for numerical computation, something which Smale and others have called for. <br\/><br\/>BROADER IMPACT. <br\/>Through the applications of EGC to robustness issues, this work is expected impact many areas of omputational science and engineering. The practical work in this research is distributed freely as part of the Core Library software. This library, with its unique interface model, is widely applicable because any C++program can invoke it to achieve guaranteed accuracy. Guaranteed accuracy computation has applications beyond nonrobustness, from verifying conjectures to testing software. The PI, as in the past, is actively engaged in various outreach efforts to related fields, and to the larger computing community.","title":"A Theory of Real Approximations, with Applications","awardID":"0430836","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["409933"],"PO":["499399"]},"98495":{"abstract":"Abstract<br\/>The nascent field of synthetic biology is focused on creating small synthetic genetic networks<br\/>inserting them into living cells in order to \"program\" cellular behavior. Recent prototypes include<br\/>a toggle switch, an oscillator, logic gates, concentration band detectors, and even a pulse<br\/>generator. Synthetic gene networks are foreseen to have tremendous applications in<br\/>biotechnology, medicine, and defense related areas. Such engineered biological devices will<br\/>engage in simple computations and cell-cell communications to diagnose diseases, repair tissues,<br\/>detect and clean up environmental pollutants, and manufacture biomaterials.<br\/>The main challenge in synthetic biology is creating and tuning gene networks to desired<br\/>specifications. There is currently no formal mechanism to guarantee the behavior of these systems<br\/>and to tune their parameters a-priori to satisfy desired performances. The existing tools for formal<br\/>analysis cannot handle genetic networks successfully due to nonlinearities, uncertainties, scarce<br\/>knowledge of kinetic and regulatory parameters, and measurements corrupted by noise. However,<br\/>the adoption of synthetic gene networks in critical applications such as tissue engineering requires<br\/>that these systems meet strict safety guarantees.<br\/>In this project, we propose a hybrid systems approach to forward engineer and analyze synthetic<br\/>genetic networks. In this framework, interval-based specifications translate to reachability<br\/>analysis and safety verification, which are the central problems of formal analysis. By exploiting<br\/>the particular nonlinearities induced by chemical reactions and cooperative regulations, we first<br\/>reduce these infinite dimensional problems to finite searches on graphs by constructing discrete<br\/>abstractions, and then map them to parameter value intervals. This procedure will allow for<br\/>analysis under parameter uncertainty and will provide a provably correct methodology to tune the<br\/>parameters to achieve desired interval-based properties. We will validate our approach with two<br\/>experimental systems. We will improve the steady state digital response of a transcriptional<br\/>cascade and use the optimized cascades to build more robust toggle switches. We will also use<br\/>formal analysis to fine-tune the dynamic behavior of a pulse generator that incorporates cell-cell<br\/>communication and a feed-forward motif.","title":"BIC: Collaborative Research: Rational Design of Synthetic Gene Networks using Formal Analysis of Hybrid Systems","awardID":"0432094","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["496117"],"PO":["521045"]},"97285":{"abstract":"This project is developing a new conceptual framework for the automated processing of information arriving from physical sensors in a generalized wide-area, large-scale distributed network infrastructure. The project is focusing on water-related ecological and environmental applications, and it is addressing issues such as scalability, modularity, signal representation, data coherence, data integration, distributed query processing, scheduling, computer performance, network performance, and usability. This new framework treats signals as elements in prescribed sets and their associated structures. The project is constructing a computing and information processing (CIP) environment to deal with the algorithmic treatment of signal-based large scale content in order to extract information relevant and important to a user. It is also developing new theories and algorithms for computational signal processing to gather, process, and represent data obtained from physical sensors, at one end, as well as the development of new, non-traditional, concepts in software applications for reconfigurable, multimode human-computer interfaces to render information important to a user, at the other end. The project is also developing new concepts in middleware integration, distributed query optimization, distributed query processing, and distributed scheduling algorithms to adapt to an ever changing network infrastructure and provide a pathway between a physical world sensory reality with its associated physical sensors, and a user with network and database infrastructure applications. This project is tailoring its work for strategic environmental and ecological applications in the identification, monitoring, assessment, and management of hydrological events in tropical areas. The project will further expand the department's already strong efforts to increase the number of Hispanic and female scientists and engineers.","title":"MII: An Infrastructure for Wide-Area Large Scale Automated Information Processing","awardID":"0424546","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":[255932,"414667","444649","323153","266269"],"PO":["557609"]},"98143":{"abstract":"PROPOSAL NO: 0430077<br\/>INSTITUTION: University of California-Los Angeles<br\/>PRINCIPAL INVESTIGATOR: Cong, Jason<br\/>TITLE: CPA: Closing the Gap in VLSI Physical Design<br\/><br\/><br\/>Abstract:<br\/>Gordon Moore's famous observation that the number of transistors per integrated circuit doubles every two years has held true for the last four decades. The impact of this explosive increase has already transformed practically all areas of society, making possible all the recent revolutions in information technology: personal computing, telecommunications, bioinformatics, digital imaging, electronic commerce, etc. As the final economic and physical barriers to continued increases in silicon-based circuit densities begin to take shape, automated design tools play an ever more important role in determining system performance. Recent studies showed that existing circuit-placement tools are surprisingly far from optimal (70-150% excess wirelength) on simplified circuit benchmarks adapted from real industrial test cases. If this quality gap can be closed, the resulting benefit will be equivalent to advancing several generations in fabrication process technology, the cost of which, when feasible, is normally measured in billions of US dollars. The goal of this research is to develop new, scalable algorithms for VLSI physical design to enable multiple Moore's-Law generations of performance improvement through 3-D design optimization in the presence of complex timing and temperature constraints. <br\/><br\/> The focus in this project will be primarily on circuit placement, as it is the step that most constrains the layout of the interconnect wiring which dominates system performance. The core placement problem is to arrange all circuit elements within a given rectangle such that no two of them overlap and such that a standard estimate of total wirelength is minimized. A broader and deeper analysis of existing algorithms' deviation from optimality and how that deviation changes as design sizes increase will be used to develop a highly efficient and optimized placement engine for the core placement model problem. Scalability of the engine will derive from a multiscale framework, in which objectives and constraints are simultaneously represented and manipulated across a hierarchy of resolution scales. This engine will then be and augmented to handle various complex constraints in both the 2-D and 3-D settings, e.g., signal propagation times, maximum wiring density, maximum temperature, and circuit elements of widely varying sizes.<br\/><br\/>The broader impact of advancing the equivalent of an entire technology generation at almost negligible cost would be considerable. A large jump in raw computing power ultimately translates into new qualitative understanding, as previously intractable problems gradually become solvable. Of potentially even greater impact, moreover, are the possible advances in basic science to be obtained by incorporating detailed physical modeling into a scalable program for optimization over millions of interconnected elements. Ultimately, the vast size and complexity of nanoscale design problems can realistically be approached only by scalable algorithms yet to be developed. The successful formulation of a truly scalable methodology for physically realistic VLSI designs can be expected to have lasting and far-reaching impact on future design paradigms.","title":"CPA: Closing the Gap in VLSI Physical Design","awardID":"0430077","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["306467","558485"],"PO":["562984"]},"98264":{"abstract":"Cooperative Source and Channel Coding<br\/><br\/><br\/><br\/>Current and next generations of wireless devices and services are substantially different than the original cellular phones which could only carry voice signals. Third\/fourth generation cellular and wireless local area networks are designed to support data services, image and video communications as well as voice. Multimedia signals require higher data rates and larger bandwidths than their voice counterparts. This necessitates a more efficient use of already scarce radio resources. Furthermore, guaranteeing a desired level of signal quality for image and video, measured in terms of overall distortion, is especially difficult given that the wireless channel is unreliable and most efficient compression algorithms involve error propagation.<br\/><br\/>In order to provide robust wireless multimedia communications, this research uses cooperative communication techniques along with jointly optimized source compression and channel coding strategies. Cooperation of wireless terminals is achieved by overhearing other terminal's signals and retransmitting towards the desired destination. This provides signal diversity and enables robust source-to-destination routes which can adapt to changes in the wireless environment. In order to establish the theory and practice of cooperative source and channel coding, the research plan consists of three interrelated components: Information theory of source channel cooperation; design of cooperative source and channel coding techniques with numerical\/simulation studies to jointly optimize the parameters; and application of these techniques to wireless video transmission.","title":"Cooperative Source and Channel Coding","awardID":"0430885","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["491898","559524"],"PO":["564898"]},"98033":{"abstract":"This proposal presents research, development, deployment and testing of data-mining and machine learning-based technology for email and instant messaging data, including attached documents and files, and allowing for a broad range of applications for criminal investigation (both evidence gathering and evidence analysis) by law enforcement agencies. This tool can be applied to email and\/or account misuse, user behavior-based analyses such as detecting criminal groups using email and Instant Messaging accounts <br\/>that communicate with one another, and for the purpose of detecting various roles of the individuals that communicate with each other, as well as the subject matter discussed and exchanged between parties or groups of corresponding parties. Such investigative activities are routinely performed today by law enforcement agencies for criminal intelligence gathering, evidence processing of subpoenaed electronic records and in the detection of stegonographic communications between suspect groups of criminals and terrorists. If successful, this research will substantially improve the productivity of forensic analysis personnel, and support evidence gathering and tracking.","title":"Email Mining Toolkit Supporting Law Enforcement Forensic Analyses","awardID":"0429323","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["431190"],"PO":["371077"]},"98165":{"abstract":"The goal of this project is to design and develop a statistical-learning tool (STL) for classification and characterization of topographical features on Mars. Major tools for studying the Martian surface are geomorphic mapping and geologic mapping. The standard approach to perform these mappings is through a manual interpretation of images. This laborious approach severely limits the number of Martian sites amenable to study. The STL automates geomorphic mapping and expedites geologic mapping. Thus, it enables fast and quantitative characterization of large sections of the Martian surface. <br\/><br\/>The SLT uses digital topography instead of images to characterize Martian sites. Different topographical variables are fused into a multi-layer data structure. Each pixel in a site carries an array of local and regional topographic information. The automatic recognition and classification of topographic features is performed at the pixel level. This enables the quantitative characterization and comparison of different topographic formations based on statistics of their constituent pixels. The results can be conveniently visualized by means of thematic maps of topography. The capacity of the SLT can be extended by adding other data types (multispectral images) and by applying it to other planetary surfaces. <br\/><br\/>This methodology has a potential to become a powerful investigative tool with a wide range of applications. To facilitate its adoption by the research community the code that implements the SLT and its documentation will be put in the public domain. The results of this work will be disseminated through new courses, seminar talks, and collaborations with other institutes.","title":"Collaborative Research: A Statistical Learning Tool for the Analysis and Characterization of Mars Topography","awardID":"0430208","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["501341"],"PO":["563727"]},"98055":{"abstract":"ABSTRACT<br\/>0429492<br\/>Shriram Krishnamurthi<br\/>Brown University<br\/><br\/>As programs evolve, their code becomes increasingly tangled by the addition of both programmers and requirements. This mosaic quality complicates program comprehension and maintenance. The lack of<br\/>quality documentation in most systems further complicates this process. <br\/><br\/>A new developer is likely to approach a system with the same mindset as a user, viewing the system as a collection of features, not in terms of its internal structure. The proposed research thus describes<br\/>program fragments in terms of the features they impact, so developers can assess the effect their changes are likely to have and, in particular, be alerted to unexpected consequences. It will do this by exploiting information provided in the program's test suites.<br\/><br\/>The proposal should result in tools to help programmers such as a better, ``semantic'' code browser; an assistant to generate better version-control documentation; and an analysis of test suite dependencies. It will also study questions that facilitate future programming language design. Broader impact will include introducing new, related ideas into software engineering education and training undergraduates to conduct research.","title":"Lightweight Analysis of Program Evolution Using Feature Signatures","awardID":"0429492","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["519555"],"PO":["564388"]},"98297":{"abstract":"Technical abstraction boundaries, such as the layers of the OSI model, have been instrumental in the evolution of high performance\/power hungry information networks in the past. However, they are currently representing a bottleneck to the development of the large distributed networks such as networks of embedded systems, unmanned vehicles, robots and sensor networks. These networks could have tremendous impact on our society, making it easier to manage and safer. Deploying existing wireless and processor technology in these applications can be dangerous because of the cost of keeping them operative, because of the difficulties in managing them on large scales and because of their vulnerability of the systems to power outages. This research is motivated by the need of a solid scientific framework and a practical set of algorithms that surpass the limiting architectural models used in the present technology and provide working solutions for these new emerging applications.<br\/> To address this problem this research uses the concept of cooperation at the physical layer as the guiding principle for removing some traditional design boundaries that limit networks scalability and also as a systematic methodology to develop cross-layer solutions. The main partition removed is the network abstraction of \"point to point communications\", where the information from every source is encoded and transmitted independently and it is received and processed independently. The cooperative networking reference model studied in this research changes all this by allowing the nodes to collaborate in compressing\/elaborating the data and in transmitting them. Cooperation seems appropriate in networking sensors, unmanned robots, embedded systems since all the nodes of these networks naturally complement each other activities and information. The study addresses the cooperative modulation, channel acquisition and data compression problems.<br\/> Level of effort<br\/>To compress the projects tasks in one year of activity and encompass the main research objectives of our project we will dedicate our focused effort to solve the key issues of channel acquisition, link control and decentralized multiple access in the physical layer cooperative channel model. The aim is to build a new reference model for cooperative networks that clarifies the structure of the communication architecture. A more detailed description of the issues we are going to address is expressed in our original \"Statement<br\/>of Work\" [c.f. Section 2.2 in the proposal] and specifically in the first three research tasks described therein. By addressing them we will set the solid framework for the development of fully cooperative and decentralized network architectures. Other research items will be left for future projects.","title":"Cooperative Networks: A Framework to Derive Scalable Cross-Layer Designs","awardID":"0431077","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["550699"],"PO":["564898"]},"98066":{"abstract":"Proposals 0429894\/Naumann 0429567\/Leavens<br\/><br\/>Collaborative Research:<br\/>Formal Methods for Behavioral Subclassing and Callbacks<br\/><br\/>David A. Naumann and Gary T. Leavens<br\/><br\/>For evolvability, scalability, and productivity, software systems must be composed of extensible components. Features of object-oriented programming languages such as inheritance and dynamic dispatch, and<br\/>techniques like callbacks and downcalls, are crucial but they invert the usual layering of abstractions. Aliasing among objects is crucial for efficiency but can breach encapsulation boundaries. Yet abstraction<br\/>and encapsulation are necessary to separately validate individual components.<br\/><br\/>This project will advance the theory of specification, development, and verification for object-oriented software, focusing on behavioral subclassing, alias confinement, and callbacks. Core features of the<br\/>Java Modeling Language (JML) for behavioral interface specification will be studied, using a confinement discipline to control aliasing and model programs to specify callbacks. The ideas will be presented<br\/>in a cogent, simple, and robust theory, to facilitate applications by tools, comparison between alternative proposals for specification notations and proof rules, and teaching. The theory will be encoded<br\/>in a theorem prover and key results machine-checked.<br\/><br\/>This project will provide theoretical guidance for the designers of programming and specification languages. The results will also help clarify and improve techniques used in practice. Direct application is expected in projects based on JML and in work by our Brazilian collaborators.","title":"Collaborative Research: Formal Methods for Behavioral Subclassing and Callbacks","awardID":"0429567","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["521544"],"PO":["564388"]},"98077":{"abstract":"Proposal Number: 0429639<br\/><br\/>TITLE: Monitoring and Checking of Distributed Systems with Respect to<br\/> Formal Specifications<br\/><br\/>PI: Mahesh Viswanathan<br\/><br\/>Our increasing reliance on computer and digital systems, necessitates the critical need for the reliability of the underlying software. However, the task of developing correct software is particularly difficult since modern software systems need to address complicated problems. Hence there is an increasing need for automated techniques to analyze software continually. Traditional methods for analyzing the correctness of programs, namely, formal verification and testing are inadequate in several respects. In particular,<br\/>verification is performed on the formal design of a system and not its implementation, while testing is often ad hoc and fails to provide formal guarantees. Monitoring and checking systems at run-time attempts to address these concerns. Although great strides have been made in developing monitoring tools, there is one fundamental challenge that limits their widespread applicability. Most of the monitoring systems only analyze uni-processor systems or systems that have a synchronized global clock. In this project, the PI plans to<br\/>develop tools and algorithms to automatically monitor distributed systems with respect to formal specifications. In order to overcome the state space explosion problem encountered in distributed<br\/>debugging, the PI plans to partial-order techniques in centralized monitoring and game-theoretic ideas to construct local decentralized monitors from global specifications.","title":"Monitoring and Checking of Distributed Systems with respect to Formal Specifications","awardID":"0429639","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["553664"],"PO":["564388"]},"99188":{"abstract":"This proposal consists of two tasks<br\/><br\/>Decision making under the suspicion of deception<br\/>Decision making under social and hierarchical pressure<br\/><br\/>As stated in the proposal, cognitive scientists and social psychologists have studied decision making under uncertainty a great deal. However there are few studies analyzing faulty information. The project will attempt to study such situations by creating potential deceptions and studying how humans react and make decisions.","title":"Problems for Investigation for the Analyst of the Future Program","awardID":"0437238","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V577","name":"CIA-ANTENNE ARRAY PROCESSING"}}],"PIcoPI":[261535],"PO":["387198"]},"97880":{"abstract":"Sequential and graph-structured data arise naturally in a wide variety of scientific, engineering, and intelligence problems, such as handwriting and speech recognition, text mining, gene finding, and network analysis. While researchers have recently made significant progress on machine learning methods for processing structured data, these methods are much less accessible to scientists, engineers, and analysts than the better understood statistical learning techniques of classification and regression.<br\/><br\/>This project is researching methods to advance the state of the art in machine learning for structured data, building on recent work in conditional random fields and weighted transducers. The project is also developing a software toolkit to make the results of these advances accessible to researchers working in a wide range of disciplines and application domains. The toolkit will enable users to define, train, and apply models for structured data without requiring advanced expertise in machine learning. The functionality of the toolkit will include methods for specifying features relevant to an application, automatically selecting the most relevant features, adjusting parameters to optimize suitable training objectives, and combining models that pertain to different facets of an application.<br\/><br\/>The software, which will be freely distributed, will be tested with selected users in several application domains, and be carefully documented. The project will thus provide the scientific and engineering community with the first generally usable tool for learning from structured data, serving a role that is parallel to that of the more standard tools for classification and regression that are already widely used.-","title":"ITR: Collaborative Research: (ACS+NHS)-(dmc+soc): Machine Learning for Sequences and Structured Data: Tools for Non-Experts","awardID":"0428193","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["365960"],"PO":["565215"]},"98980":{"abstract":"National Science Foundation<br\/>Network Technologies and Systems (NeTS)<br\/>CISE\/CNS<br\/><br\/>Form 7 Review Analysis and Recommendation<br\/><br\/>Proposal Number: 0435497<br\/>PI: Edward Kohler <br\/>Institution: University of California, Los Angeles<br\/>Title: High-level and Efficient Sensor-Network Programs <br\/><br\/>Abstract: <br\/><br\/>Applications for embedded networked sensors must run well on resource-poor, unmaintained, environmentally exposed, and unreliable hardware. These hardware constraints rule out many traditional approaches for improving programmability, since they impose high runtime cost. As a result, system specialists must be involved in every stage of application development and deployment, and scientists cannot construct sensor applications on their own. This limits how well sensor networks can solve real scientific problems, since deployment is gated on the involvement of a few systems experts. This research program uses programming language technology to make efficient sensor network applications easy to deploy and tune. A set of new sensor components and a higher-level programming language for component configurations combine to form smart, efficient libraries of application-level services. Using these services, scientists can define an optimized application in just two or three lines of code, enabling quicker application deployment and tuning for different field conditions and, thus, more responsive science. The project will produce a new TinyOS component library, a sensor network programming language (SNACK) and compiler, a set of SNACK services designed for different application types, and several sample applications, including some designed for classroom use. All of the code will be freely and widely distributed.","title":"NeTS - NOSS: High-Level and Efficient Sensor Network Programs","awardID":"0435497","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["541961"],"PO":["434241"]},"96560":{"abstract":"This project, adding high performance interconnections and true data-intensive storage facilities, involves a high performance communication and storage backbone, named CASTOR. With the interconnections, this backbone enables achievement of the full benefits of the grid strategy to support data-intensive research in diverse disciplines. Major campus facilities will be linked by a 10Gigabit\/s network and supported by 24 Terabyte storage systems. CASTOR's high performance links are well matched to those of Florida Lambda Rail and National Lambda Rail. Serving the following research domains, High Energy Physics, Chemical Physics and Material Science, Coastal and Estuarine Modeling, Medical Physics, and Computational Biology, the new infrastructure will also serve Computer Science and Engineering on data-intensive, high-performance grids. CASTOR is expected to strengthen the collaboration between multidisciplinary teams across the institution and provide a unique resource for the projects in which the researchers participate. The infrastructure provides a unique resource for applications that require storing, processing, and communicating very large-scale data sets at very high speeds. Reflecting real-world scenarios, the work involves the following technologies:<br\/>* Grid Computing,<br\/>* Distributed Storage, and<br\/>* Advanced Networking.<br\/>The first involves the development innovative middleware techniques that complement and extend virtualization of physical information resources to hide infrastructure heterogeneity and allow applications to execute on grid-enabled resources with user control and interaction from various web-based interfaces. The second provides a trial version of the grid environment to operate queries, providing a proof-of-concept for deployment in larger systems. CASTOR serves as an \"ideal sandbox\" to develop and test algorithms suitable for a distributed data pipeline. The last enables experiments in a research network operating at ultra-high speeds and multiple domains, hence contributes to enrich projects.","title":"MRI: Acquisition of CASTOR: A High-Performance Communication and Storage Backbone for Data-Intensive Science and Engineering Computing","awardID":"0421200","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["338295",253558,"530692","530024","523144"],"PO":["557609"]},"82282":{"abstract":"The XStreamCast project addresses the efficient processing of XQueries over continuous streams in which a server broadcasts XML data to multiple clients concurrently and a client may tune-in to multiple streams at the same time. The goal of this project is to develop a framework that improves query throughput and response time on all clients, taking full advantage of their limited resources. Under this framework, the unit of transmission in an XML stream is an XML fragment, which corresponds to one or a few XML elements from the transmitted document. A server may choose to disseminate XML fragments from multiple documents in the same stream, can repeat some fragments when they are critical or in high demand, can replace them by sending delta changes, and can delete invalid ones. The client architecture is based on an optimization framework for XQuery that utilizes many efficient evaluation algorithms for processing XML data streams under memory and processing power constraints. The end goal is the construction of a complete prototype system based on the theoretical framework, which is expected to drastically improve performance when compared with other stream processing systems. The algorithms and the software resulting from this project will have a broader impact on a wide range of applications, especially in electronic commerce, since they will improve the way services are provided to clients. They will also reduce network traffic between servers and clients and will give the ability to small service providers and businesses to serve a larger number of clients using less powerful server computers and lower cost networking. The project Web site (http:\/\/lambda.uta.edu\/XStreamCast\/) will provide access research results and to a public interface to allow other researchers to test-drive the XQuery engine.","title":"XStreamCast: Broadcasting and Query Processing of Streamed XML Data","awardID":"0307460","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["553595","516651"],"PO":["563727"]},"96340":{"abstract":"Abstract<br\/> <br\/>Title: ITWF Collaborative Research: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science<br\/><br\/>CNS 0420505, PI Kamin, Univ. of Illinois at Urbana-Champaign<br\/>CNS 0420000, PI Califf, Illinois State University<br\/>CNS 0420458, PI Lucht, Heartland Community College<br\/>CNS 0420468, PI Mobasseri, Parkland College<br\/>CNS 0420506, PI Uskov, Bradley University<br\/>CNS 0420321, PI Van Cleave, Eastern Illinois University<br\/><br\/><br\/><br\/>This collaborative ITWF project implements a set of activities designed to increase participation of women and under-represented minorities in undergraduate computer science programs in the state of Illinois. The project includes high school outreach, curriculum reform, mentoring, and other extracurricular activities. It is a collaborative project between the University of Illinois at Urbana-Champaign, Illinois State University, Heartland Community College, Parkland College, Bradley University, and Eastern Illinois University. The project involves building communities among various groups within the state to recruit, support, and retain students in computing courses and programs.<br\/> <br\/>The intellectual merit of this project lies in the strong research basis for the intervention models as well as the vertical integration of the models at a range of secondary and post-secondary institutions within the state. The project plan is clear and reasonable with well-defined roles for the partners. The project builds on existing programs and partnerships within the state and includes investigators with significant relevant experience.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science within one state. If successful, the project may provide a sound model for similar broad-based approaches in other states and geographical areas.","title":"Collaborative Research: ITWF: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science","awardID":"0420458","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[252622],"PO":["361119"]},"98892":{"abstract":"Current trends in network deployment show that there is high asymmetry in fiber infrastructure and in available wireless spectrum. In particular, indoor business and educational environments, as well as dense urban areas, are generally richly endowed with heavily underutilized fiber, but their wireless resources are challenged by limited energy, by interference and by severe wireless propagation issues. The current ad-hoc deployment of wireless routers, commonly termed \"hot spots\", is a means of exploiting this asymmetry by placing wireless traffic onto the wireline infrastructure in a very localized fashion. This project seeks to extend radically the concept of hotspots by providing aggressive harvesting of the signals in the wireless domain through the existing, underutilized, fiber infrastructure. The technical rationale is to reduce the range of wireless transmissions by making use of the fact that wireless devices in fiber-rich areas are physically close to fiber. Currently, this proximity to fiber is not exploited, since there are very few access points, such as base stations or wireless routers, for translating wireless signals onto the fiber. The project will consider the use of a large number of small, inexpensive points of access to the fiber. In particular, our project will investigate using fiber infrastructure in buildings to allow us, for the first time, to use effectively wireless spectrum at very high frequencies, such as 60 GHz, where propagation effects allow only very short ranges. The main outcomes of this effort will be to alleviate significantly issues of wireless resource contention and energy use, by reducing the range needed for wireless transmission in densely populated environments, and allowing wireless signals to be captured ubiquitously by the fiber plant. This research will help establishing new means providing cheap and simple access onto fiber for wireless energy harvesting.","title":"NeTS-NR: Spectrum Teleportation: A Fiber-Aided Wireless Architecture","awardID":"0434974","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550597","316455","530080"],"PO":["565090"]},"96351":{"abstract":"Abstract<br\/><br\/>Title: ITWF Collaborative Research: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science<br\/><br\/>CNS 0420505, PI Kamin, Univ. of Illinois at Urbana-Champaign<br\/>CNS 0420000, PI Califf, Illinois State University<br\/>CNS 0420458, PI Lucht, Heartland Community College<br\/>CNS 0420468, PI Mobasseri, Parkland College<br\/>CNS 0420506, PI Uskov, Bradley University<br\/>CNS 0420321, PI Van Cleave, Eastern Illinois University<br\/><br\/><br\/><br\/>This collaborative ITWF project implements a set of activities designed to increase participation of women and under-represented minorities in undergraduate computer science programs in the state of Illinois. The project includes high school outreach, curriculum reform, mentoring, and other extracurricular activities. It is a collaborative project between the University of Illinois at Urbana-Champaign, Illinois State University, Heartland Community College, Parkland College, Bradley University, and Eastern Illinois University. The project involves building communities among various groups within the state to recruit, support, and retain students in computing courses and programs.<br\/><br\/>The intellectual merit of this project lies in the strong research basis for the intervention models as well as the vertical integration of the models at a range of secondary and post-secondary institutions within the state. The project plan is clear and reasonable with well-defined roles for the partners. The project builds on existing programs and partnerships within the state and includes investigators with significant relevant experience.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science within one state. If successful, the project may provide a sound model for similar broad-based approaches in other states and geographical areas.","title":"Collaborative Research: ITWF: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science","awardID":"0420505","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["451105",252671],"PO":["361119"]},"98782":{"abstract":"ABSTRACT<br\/>Special Projects Program - FY04<br\/><br\/>CNS 0434310, PI's Carla S. Ellis (Duke University), Andrew Bernat (CRA) and Mary J. Harrold (Georgia Tech.), submitted by the Computing Research Association (CRA)<br\/>Title: CRA's Committee on the Status of Women in Computing Research<br\/><br\/><br\/>This Special Project award to the Computing Research Association's Committee on the status of women (CRA-W) will provide support to CRA-W to expand and enhance its activities. Funding is provided to maintain the CRA-W committee and to support new initiative's such as the long-term tracking of graduate student cohorts, career mentoring mini-workshops, a reunion of former participants of CRA-W's programs for undergraduate research mentoring, new projects for women researchers in industrial labs, joint efforts with the Coalition to Diversifying Computing, a service called Friends of CRA-W to help principal investigators implement meaningful diversity plans, and a leadership summit for senior women.<br\/><br\/>The Computing Research Association's Committee on the status of women (CRA-W) has been a national leader since 1991 in positive efforts to increase the number and success of women in Computer Science and Engineering (CS&E) research. It is an action-based committee, implementing projects aimed at eliminating barriers to the full participation of women at all stages of the research pipeline. CRA-W has had a significant impact on the Computer Science & Engineering (CS&E) community, directly impacting over 2000 women and indirectly influencing thousands of others.<br\/><br\/>The intellectual merit of this project lies in CRA-W facilitating a broad range of research activities in CS&E. CRA-W's commitment to program evaluation will provides important data on what works and what doesn't work for others interested in starting similar programs.<br\/><br\/>The broader impact of this effort lies in CRA-W providing mentoring opportunities and community building to encourage women in CS&E research, and to increase the awareness of gender issues across the CS&E discipline. CRA-W programs address every rung of the ladder of higher education in CS&E. The networks of women mentoring women that CRA-W builds across institutions serve an essential function in ameliorating their isolation. CRA-W programs have a significant impact on institutions and their approach to including women in the research enterprise.","title":"CRA's Committee on the Status of Women in Computing Research","awardID":"0434310","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["353750","530729","209556"],"PO":["564181"]},"97693":{"abstract":"Proposal Number CNS-0426623<br\/><br\/>TITLE: ITR: Secure Remote Computing Services<br\/><br\/>PI: Jason Nieh<br\/><br\/>ABSTRACT<br\/><br\/>Secure remote computing services (SRCS) will be developed as a critical information technology (IT) infrastructure. SRCS will move all application logic and data from insecure end-user devices, which attackers can easily corrupt, steal and destroy, to autonomic server farms in physically secure, remote data centers that can rapidly adapt to computing demands especially in times of crisis. Users can then access their computing state from anywhere, anytime, using simple, stateless Internet-enabled devices. SRCS builds on the hypothesis that a combination of lightweight process migration, remote display technology, overlay-based security and trust-management access control mechanisms, driven by an autonomic management utility, can result in a significant improvement in overall system reliability and security. The results of this effort will enable SRCS implementations to provide many benefits, including persistence and continuity of business logic, minimizing the cost of localized computing failures, robust protection against attacks, and transparent user mobility with global computing access. SRCS in time of crisis specifically addresses a major concern of national and homeland security. The substantially lowered total cost of ownership of applications running on SRCS is anticipated to dramatically reduce the gap between IT haves and have nots.","title":"ITR - (NHS) - (int\/dmc): Secure Remote Computing Services","awardID":"0426623","effectiveDate":"2004-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["541922","508477","564223"],"PO":["529429"]},"98793":{"abstract":"Pattern classification problems that arise in natural language processing applications, such as parsing, machine translation, and speech recognition, are more complex than those commonly addressed with statistical learning methods. The broad goal of this research project is the design and analysis of statistical learning algorithms that are suitable for these problems. The research is focused on the following questions, which are motivated by characteristic properties of complex pattern classification problems in natural language processing: methods for multiclass classification with desirable statistical and computational properties; methods for structured classification, where the predicted variables come from a large set with a rich structure (for example, predicting the parse tree of a sentence); the extension of these methods to problems with hidden variables, that is, where some relevant data is not observed; and complex nonparametric models for these problems, in particular, computationally efficient nonparametric Bayesian methods based on hierarchical Dirichlet processes. The methods developed will be validated empirically on parsing, machine translation, and speech recognition problems.<br\/><br\/>The research project is aimed at the development and analysis of statistical learning methods for complex decision problems, such as those that arise in natural language processing. A key goal of research in natural language processing is the development of automated systems, such as translation systems and dialogue systems. The most successful approaches involve the use of statistical methods to exploit language data, such as a text corpus. However, the decision problems that arise are very complex. A good example is the problem of parsing, or recovering the syntactic structure underlying sentences in a language. For such problems, the set of candidate decisions is very large, and possesses considerable structure. This research project is aimed at developing computational and statistical methods that are suitable for complex decision problems of this kind. Successful methods are also likely to have a significant impact in other areas of computer science, including computer vision and bioinformatics, because similar complex decision problems also arise in these areas.","title":"MSPA-MCS: Collaborative Research: Statistical Learning Methods for Complex Decision Problems in Natural Language Processing","awardID":"0434383","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["497161","485442"],"PO":["565211"]},"97000":{"abstract":"Optimization problems pervade all areas of human endeavor. Such problems generally include an objective function to be minimized or maximized (cost, profit, accuracy, weight, time, fuel, durability, etc.) subject to satisfaction of certain constraints. In all but the simplest cases, effectively tackling these problems requires the use of \"numerical\" optimization tools. The present grant provides funding for developing, analyzing, implementing, and testing numerical algorithms for the solution of constrained optimization problems with a large number of inequality constraints. Such problems are common in engineering applications. Algorithms are sought that exhibit strong theoretical convergence properties as well as high practical efficiency. Attention is focused on algorithms that enjoy feasibility\" and \"monotone descent\"; i.e., that construct a sequence of iterates (increasingly better estimates of the solution) with the property that (i) all iterates satisfy the inequality constraints, and (ii) the objective function value improves monotonically from iteration to iteration.<br\/><br\/>Feasibility and monotone descent are of value in a broad range of application areas. In particular, in the context of the PI's previous work on developing and implementing algorithms, such properties have been acclaimed by users in areas ranging from cancer research to chemical engineering, to design of integrated circuits, to radiology, to mention but a few. Further, problems with a very large number of inequality constraints are common in many applications ranging over engineering and the sciences. Accordingly, it is anticipated that, as has been the case with previous algorithms and software developed by the PI's group, the algorithms and software that will come out of the proposed research if it is successful, will have a significant impact in a wide range of application areas.","title":"Feasible Point Optimization Methods for Design and Other Engineering Applications","awardID":"0422931","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":["544499"],"PO":["423737"]},"97132":{"abstract":"This project, addressing heterogeneous and dynamic sensor technologies, facilitates experimental research, demonstrating and distributing scalable middleware services that support hybrid sensor technologies, including traditional scalar sensors such as the Berkeley motes, as well as newer sensors such as the OGI panoptes video-based sensors. The work focuses on the following tasks:<br\/> Adaptive Network Protocols,<br\/> Global Power Management, and<br\/> Programmable Architectures.<br\/>Dynamically inferring and exploiting the heterogeneity of network components, the 1st task investigates mechanisms to support a range of sensor networking technologies by designing adaptive protocols for network resource management and data recovery. The 2nd investigates techniques to help designers understand global power management in heterogeneous sensor networking applications. The 3rd task investigates middleware to support the programmability of hybrid signaling within video-based sensor networks. To validate and demonstrate the approach, three sample applications will be built. <br\/> Time-Elapsed Imaging for Coastal Monitoring (used to sense light),<br\/> Security Monitoring (used to sense movement in a room), and<br\/> Health-Care Monitoring (used to validate video and vice versa with scalars).<br\/>The difference between a custom-built application and a middleware version for various parameters will be measured in each case, as well as how much energy can be saved by having hybrid sensors working cooperatively (rather than autonomously) to manage power. This project explores the fundamental challenges in enabling such applications. Addressing the diversity in sensors should be critical in addressing the sensor networking applications of the future. These systems comprise the integration and interaction of diverse classes of sensor nodes, motivating approaches that require greater synergy among nodes than those previously explored in the traditional sensor networks. Augmenting the infrastructure through separate funds with a variety of additional sensing devices, will enable the creation of an extensive and flexible testbed to study scalable middleware services that support hybrid technologies. Hybrid sensor technologies can enrich the potential of sensor applications.<br\/><br\/>Broader Impact: The artifacts of this research will be useful to the broader community; the experiences with real applications can inform further research. Moreover, the experimental research will further enable scientists in the Environmental Science and Biomedical Engineering Departments. This work enhances the curriculum enabling students to partake in experimental sensor networks research for their course work.","title":"CISE RR: Infrastructure to Support Heterogeneous and Dynamic Sensor Networking Research","awardID":"0423728","effectiveDate":"2004-09-01","expirationDate":"2005-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["518376","451080","357733"],"PO":["557609"]},"98111":{"abstract":"Voice is the method of choice for real time communications. Voice is so important to human communications that we have constructed entire networks centered around voice, namely, the public switched telephone network (PSTN) and the analog\/digital cellular networks. With the emergence of voice over the Internet Protocol (VoIP) and voice over wireless local area networks (Wi-Fi), a future voice call might consist of a digital cellular user communicating through a VoIP backbone network with a voice over Wi-Fi user, resulting in the connection of a digital cellular network through a VoIP network into a Wi-Fi link. Although the digital cellular networks utilize relatively sophisticated error detection and correction, unequal error protection, and error concealment, the error control, packet loss mechanisms, and packet loss concealment methods for VoIP and voice over Wi-Fi are relatively primitive. Furthermore, since each of these networks has different channel behaviors and may use different voice codecs and different network protocols, acceptable, bandwidth efficient voice service may not be achievable over such a connection. <br\/> This research involves voice communications over tandem heterogeneous networks and voice over Wi-Fi links. We examine (1) improved voice codec tandem performance, by developing speech-mode-adaptive postfilters and perceptual distortion measures, by removing the postfilter and inserting additional filtering within the analysis-by-synthesis loop, and by shaping the excitation within the analysis-by-synthesis loop; and (2) improved packet loss concealment and reduced latency, by jointly designing packet loss concealment methods and protocols for wireless LANs and by developing packet loss smoothing algorithms to use \"late\" packets to improve later reconstruction. The evaluation of the end-to-end network performance for voice communications uses the NS2 network simulator and voice quality metrics.","title":"Voice Communications over Tandem Heterogeneous Networks","awardID":"0429884","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["410030"],"PO":["564898"]},"98232":{"abstract":"The understanding of geometric shapes in everyday life combines visual impressions, tactile sensation, and their unification in the process of seeing something and reaching out to touch it to determine its physical properties, which may convey new information. Interactive computer graphics systems can be combined with 3D-touch-responsive (haptic) interfaces to permit not only the simulation of our familiar 3D world, but also the extension of our available sensations to additional dimensions and unfamiliar geometric objects by using the abstract power of computer modeling.<br\/><br\/>This research focuses on exploiting interactive graphics combined with haptics to develop new methods for investigating geometric structures whose understanding is beyond the normal capabilities of the unaided human. Results will be made available in the form of pedagogical animations as well as the software environments used to create them. Typical problems include the direct manipulation and study of deformable volumes resulting when a 3D knot is removed from the solid block of space it lives in, leaving the knot complement, and the exploration of the intricate collision-free deformations of surfaces in 4D space that are essential for studying the properties of functions of two complex variables.<br\/><br\/>The anticipated outcome of pursuing such approaches will be to enhance human capabilities and intuition pertaining to specific challenging geometric visualization problems, to provide methods enabling the discovery of scientific questions related to complex geometric structures that might not otherwise have been asked, and ultimately to advance the entire concept of empowering human understanding using computer-based technology.","title":"Exploring New Geometry by Touching, Seeing, and Feeling","awardID":"0430730","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["503797"],"PO":["565136"]},"97022":{"abstract":"Optimal computation of flow field variables from natural visual signals.<br\/><br\/>R.R. de Ruyter van Steveninck, W. Bialek<br\/><br\/><br\/>Many animals use visual information to navigate their environment, and in this context it is important for them to estimate how they move through space. Visual input, gathered by the eye, contains information that is related to self motion, but the connection between what we see and how we are moving is indirect and sometimes ambiguous. Moreover, light is carried by photons, and because these arrive at random the visual input forms a noisy representation of the surroundings. To make optimal estimates of self motion from visual input, the brain must therefore use an algorithm that takes into account the statistics of the visual input signals and the probabilistic relation between visual input and self motion.<br\/>This project will study motion estimation in the natural world as a statistical estimation problem, and compare the predictions of statistically optimal processing to measurements in a biological system. There are fundamental as well as practical reasons for studying the problem, but there is an additional motivation. That is to investigate if, and to what extent, neural computations in biological systems can be understood as being optimized for their specific tasks in the natural environment. This is a hard issue to solve in general, since the answer depends on poorly known statistical properties of natural sensory signals. The present case provides an example where one can measure and quantify both the signals that need to be estimated (rotations) and the data on which this estimate is based (raw visual input). Moreover, a level of statistical sampling can be achieved that allows a direct application of statistical inference to data that are representative for natural sensory signals. <br\/>The investigators will construct a precise high speed camera, with spatial sampling characteristics representative for the fly visual system, and with associated gyrosensors to measure camera rotation along three axes (yaw, pitch and roll). With this camera they will make precise simultaneous measurements of rotational camera motion and visual input in a natural environment. This simultaneous sampling makes it possible to effectively measure the probability distributions that describe the relation between motion and visual input. From this distribution, the characteristics of the optimal statistical motion estimator can be derived. These predictions for the computational structure of the optimal estimator will be compared to the behavior of motion sensitive neurons recorded from the visual brain of the blowfly. That comparison will allow quantitative assessement of the extent to which biological motion processing in the blowfly approaches optimal performance. Preliminary experiments have shown that both the blowfly and the optimal estimator show specific biases in their output, depending on the statistics of the input signals. There are strong indications that other animals, including humans, share similar biases, suggesting that these biases are an inevitable and universal consequence of the optimal processing of natural sensory signals.","title":"Optimal computation of flow field variables from natural visual signals","awardID":"0423039","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":["383901","543673"],"PO":["564318"]},"98474":{"abstract":"Increasingly, many aspects of biology can be viewed as involving the processing of information. Modern<br\/>information and computer science have played an important rolein such major biological accomplishments<br\/>as the sequencing of the human genome. On the other hand, biological ideas can inspire new concepts and<br\/>methods in information science. This project is motivated by these two observations. Progress in the field<br\/>of biological information processing will require interdisciplinary collaborations among computer scientists,<br\/>mathematicians, physicists, chemists, and biologists. The project is built around a series of workshops that<br\/>will enhance the interdisciplinary collaborations beginning to form and introduce outstanding junior people<br\/>to problems and topics at the forefront of research.<br\/>Intellectual Merit<br\/>The project will be organized around a series of workshops with four themes: (1) Algorithmic Approaches<br\/>to Biological Information Processing; (2) Computer Science, Engineering and Biology: Applications and<br\/>Analogies; (3) Biological Circuits and Cellular Signaling; (4) Proteomics. Two of these themes represent<br\/>approaches and two represent areas of application of these approaches. Under theme 1, planned workshops<br\/>are on Detecting and Processing Regularities in High Throughput Biological Data; Machine Learning Ap-<br\/>proaches for Understanding Gene Regulation; and Computational Tumor Modeling. Theme 2 workshops will<br\/>cover Nanotechnology and Biology; Control, Communication, and Computing in Biology; and The Mecha-<br\/>nism and Applications of the RNA Interference Process. For Theme 3, there will be workshops on Strategies<br\/>for Reverse Engineering Biological Circuits; Cell Communication and Information Processing in Developing<br\/>Tissues; Dynamics of Biological Networks; and Evolution of Gene Regulatory Networks. Theme 4 work-<br\/>shops will be on Information Processing by Protein Structures in Molecular Recognition; Proteome Network<br\/>Evolution; Functional Proteomics of Neurodegenerative Diseases; and Implications of Mathematical Models<br\/>of Infection and Molecular Modeling of Hepatitis B Virus. We expect that the workshops, scientific papers<br\/>and books coming out of the project will help to develop the long-term focus of the field, carefully define<br\/>problems and directions in computer science, mathematics, chemistry, andphysics of specific interest to and<br\/>designed in collaboration with biologists, and lead to new biological concepts that will in uence biological<br\/>and information science research in the future. In short, we expect the project to in uence the study of<br\/>biological information processing for years to come.<br\/>Broader Impacts<br\/>The ideas developed in this project will have impact on a myriad of fields and create cross-disciplinary<br\/>connections. A visitor program will encourage senior and junior researchers, including students, to participate<br\/>in collaborative research spawned by the workshops. Each workshop will have a fund for support of graduate<br\/>students and postdocs amd workshops will have a substantial educational component through talks of a<br\/>tutorial\/expository nature. The topic lends itself well to undergraduate research and participating faculty<br\/>will coordinate topics with an undergraduate research program (REU program) already in existence. To give<br\/>the project widespread dissemination, each workshop will have awebsite with relevant references, problems,<br\/>and copies of presentations that can make it a resource for a large community. The project should significantly<br\/>in uence the careers of a large number of outstanding junior researchers and it should play an important<br\/>role in the training and development of scientists who are well-prepared to become leaders in the field of<br\/>biological information processing. The project is expected to have a long-term impact well beyond its four<br\/>year duration since the workshop, visitor, and dissemination components of the project will allow the ideas<br\/>developed to reach hundreds of people nationwide and worldwide.","title":"CompBio: Special Focus on Information Processing in Biology","awardID":"0432013","effectiveDate":"2004-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T220","name":"NIH-NCI CVIT-DIMACS COMPUT TUM"}}],"PIcoPI":["308882",259414,"490024","264120"],"PO":["565223"]},"98122":{"abstract":"0429948<br\/>Insup Lee<br\/>University of Pennsylvania<br\/>Extracting Traceable Formal Models from Natural Language Policy Documents Insup Lee, Aravind Joshi<br\/><br\/>Policy plays an important role in our lives and affects us in many ways, e.g., the Food and Drug Administration's Code of Federal Regulations govern how to test blood for communicable diseases.<br\/>Ambiguities, conflicts, and incompleteness in such policy documents could lead to situations that are undesirable and unsafe.<br\/><br\/>The proposed research is to develop NLP (Natural Language Processing) based techniques and methods for extracting formal models from policy documents. These models are then analyzed for correctness and<br\/>consistency and also to used for conformance testing of implementations of the policy. This is a collaborative effort between researchers in NLP and Formal Methods and aims at producing an environment in which policy can co-exist in natural and formal languages. For success and usefulness of this approach, it is<br\/>important to maintain correspondence and traceability between these two representations of policy. Furthermore, the large size of the policy bases and the complexity of the documents warrant modularized<br\/>extraction of models and then the merging of these models. Existing NLP techniques need to be extended and tailored to aid in the modular extraction of formal models. The merging of extracted models also<br\/>requires extensions and refinements to formal method techniques. As our society relies more on computer-based systems, and on medical devices in particular, the proposed research will help to improve the reliability of such systems.","title":"Extracting Traceable Formal Models from Natural Language Policy Documents","awardID":"0429948","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["472144","553656"],"PO":["564388"]},"98012":{"abstract":"Visions of Digital Government see people easily accessing government information while <br\/>simultaneously encouraging a more efficient, transparent, and accountable government. The <br\/>implementation of these visions requires government to carefully consider the design information <br\/>technologies or\" code\", i.e., the physical hardware, software and architecture of information technologies. This research seeks to provide an understanding of how choices in code can govern or regulate society. <br\/>Initially a theoretical framework on how code operates as a regulatory mechanism will be developed. Additionally there will be a comparative analysis of code versus other regulatory mechanisms, such as law and social norms. Finally, there will be an attempt to understand the interrelationships between regulatory mechanisms, such as laws, social norms, and code. The theoretical framework will be informed by a series of historical case studies, allowing a systematic understanding of code. The foremost criterion for the case studies is to consider fundamental societal values that are of concern to society, such as free speech, privacy, and intellectual property rights.","title":"Governing With Information Technologies","awardID":"0429217","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["542485"],"PO":["371077"]},"98133":{"abstract":"Architectural Support for Effective User-Level Data Transport<br\/>Abstract<br\/><br\/>The objective of this project is to enable microprocessors to better utilize recent performance advances in I\/O and networking. It seeks to enable next-generation I\/O and networking services on general-purpose microprocessors by the addition of a subsystem consisting of multiple clusters of simple processors, and appropriate interconnects, to handle network and I\/O traffic without making the central processor unit (CPU) core, or its operating system, an artificial bottleneck. The research activities will prototype, demonstrate and evaluate our proposed system though a combination hardware prototypes, software simulation and application development.<br\/><br\/>The research directly addresses a critical problem common to all modern information technology systems: while commodity CPU and network performance have each independently seen dramatic performance improvements over the last decade, their combined use results in an inefficient system. In other workloads, modem CPUs achieve their promise on traditional computing workloads, and modern networking systems do the same for traditional communications tasks, but a combined system is unable to support emerging services (such as large-scale storage systems, content scanning systems and on-demand media) at the performance levels expected for such otherwise high-performance systems. The central problem lies in the hardware and software interfaces between the CPU and the network. Our proposed research aims to re-organize the CPU to better support high-performance networks and I\/O and enable a proliferation of advanced network and I\/O services on general-purpose commodity systems.","title":"Architectural Support for Effective User-Level Data Transport","awardID":"0430012","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["522382"],"PO":["550859"]},"98144":{"abstract":"Architecture, Algorithms, and Circuits for an Energy-Efficient Single-Chip Tera-Op\/sec Digital Signal Processor<br\/>Abstract<br\/><br\/><br\/>Digital Signal Processing (DSP) workloads are typically numerically intensive, parallelizable, and increasingly required in a number of applications. The project will develop the architecture, algorithms, circuit, chip layout, and software for a single-chip processing system that is capable of calculating DSP workloads with high performance and high energy efficiency. Processing chips contain a very large number of small asynchronously clocked programmable processors connected by a reconfigurable 2-dimensional grid network. The research will result in the design, fabrication, test, and characterization of a prototype processing chip, including the development of software for a small number of complex multi-algorithm applications. The project will evaluate the merits of the proposed architecture for these types of DSP workloads. <br\/><br\/>The research may lead to new capabilities that were previously constrained by maximum levels of power dissipation or throughput, in numerous applications such as life-extending medical devices, high volume consumer products, and very high throughput radar and image processors.","title":"Architecture, Algorithms, and Circuits for an Energy-Efficient Single-Chip Tera-Op\/sec Digital Signal Processor","awardID":"0430090","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["551167"],"PO":["550859"]},"98155":{"abstract":"Proposal Number: NSF-0430161<br\/><br\/>TITLE: Integrating Security and Fault Tolerance in Distributed Systems<br\/><br\/>PI: Andrew C. Myers, Ken Birman, Fred B. Schneider<br\/><br\/>Trustworthy distributed systems should tolerate both malicious attacks and benign faults while preserving data integrity and confidentiality. This research aims to produce methods for constructing distributed systems that are trustworthy in the aggregate, even when some nodes in the system have been compromised by malicious attackers. The security and fault-tolerance communities have developed their own solutions to aspects of these problems, but the solutions are incompatible. The goal of this project is to reconcile that incompatibility. One key idea is to use automatic compile-time transformations to rewrite programs to run securely, even when some host machines are untrustworthy. Code and data are transformed to synthesize distributed systems that, by construction, provide confidentiality, integrity, and availability. The planned research also includes new distributed computation techniques needed to make these transformations effective. These techniques include proactive recovery, proactive obfuscation, and threshold cryptography, which can help systems survive malicious intrusions and denial of service attacks while offering data integrity, high availability, and cryptographic protection for secrets. Gossip-based and epidemic communication algorithms can provide robust, scalable, and efficient information aggregration over a large distributed system. In summary, the plan is to combine new compile-time and run-time techniques to make distributed systems more trustworthy.","title":"Integrating Security and Fault Tolerance in Distributed Systems","awardID":"0430161","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["495285","166043","555502"],"PO":["529429"]},"98276":{"abstract":"The rapid development of a myriad of networked devices for computing and telecommunications presents challenging and exciting new issues for coding. Communication system designers always have to deal with trade-offs among reliability, efficient use of available bandwidth, data throughput and cost. Error-correction coding is one of the most powerful tools available to address these trade-offs. A small improvement in error-correction can yield large savings in the overall cost of systems. Low-Density Parity-Check (LDPC) codes promise to be the ultimate answer to the questions of coding specialists. Although a great amount of research has gone into LDPC codes, the investigators believe that the potency of LDPC codes in resolving many practically relevant coding issues such as rate-compatible coding, improved decoding and coding for error detection has yet to be discovered. <br\/><br\/>Today, theoretical limits on rates at which reliable transmission or storage of data is possible are known for many<br\/>telecommunications challenges. Today's and tomorrow's challenges are to employ LDPC codes in networked, distributed computing and communications applications. This work first investigates finite and infinite length punctured LDPC codes over MBIOS channels. Bounds on the performance degradation of punctured LDPC ensembles as a function of puncturing fraction are derived. Using which, the investigators plan to arrive at criteria for good puncturing patterns and degree distributions. Then, the research expands on improved decoding algorithms that<br\/>outperform standard iterative decoding by orders of magnitude over MBIOS channels. The intention is to derive conditions on the choice of guessed bits and bounds (on the number of them) for the improved decoding to successfully complete decoding. Finally, the research investigates the error detection capability of LDPC codes and analyzes the tradeoff between computational complexity and average performance of ensembles.","title":"Low Density Parity Check Coding: Applications and New Challenges","awardID":"0430964","effectiveDate":"2004-09-01","expirationDate":"2008-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["485126"],"PO":["432103"]},"98056":{"abstract":"Control-Flow Processors<br\/>Abstract<br\/><br\/><br\/>An architecture is presented that unifies fine-grain control-flow and data-flow dependences in the context of contemporary superscalar processors, preserving highly streamlined mechanisms of superscalar processors while endowing them with dataflow properties. Future independent instructions are fetched, executed, and locally finalized, their results propagated and corresponding resources freed, and their cumulative effects sustained regardless of prior unresolved branch mispredictions. Branch mispredictions no longer serialize execution, leaving exceptions and finite resources as the only remaining serializing constraints in the system.<br\/><br\/>In the domain of high-performance microprocessors (which power supercomputers, personal computers, laptops, and even cell phones), there remain a few dogged bottlenecks that fundamentally constrain performance, making it difficult to translate the potential of additional transistors into effective performance gains. The project's broader significance is an approach that aims to overcome one of the remaining grand-challenge problems in scaling microprocessor performance.","title":"Tools and Techniques for Integrated Power Management of Server Disks","awardID":"0429500","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["542015"],"PO":["562984"]},"98177":{"abstract":"The purpose of this research is to explore the vulnerabilities of recommendation and personalization systems in the face of malicious attacks, explore techniques for enhancing their robustness, and examine methods by which attacks can be recognized and possibly defeated. Most research in computer security focuses on protecting assets inside an organization's security perimeter from unauthorized access and modification. This project examines the problem of security for systems that are designed to be accessed and modified by the general public. How do we protect such a system from the legal but biased inputs of an attacker trying to subvert its functionality? The project will advance our understanding of the trustworthiness of recommender systems, now a crucial component in many areas from e-commerce and e-learning to content management systems. We will explore the spectrum of possible attacks against recommendation systems, and develop formal models characterizing these attacks and their impacts. We will investigate different metrics for assessing the robustness of recommendation algorithms including accuracy, stability and expected payoff to the attacker. In tandem with this theoretical work, we will conduct empirical investigations using data from a variety of domains. We will test a range of recommendation algorithms including user-based, item-based and model-based collaborative recommenders, and also explore hybrid recommendation by combining collaborative recommendation techniques with content-based and knowledge-based ones. Finally, informed by these results, we will consider how recommender systems can be secured, through improved algorithms but also by detecting attacks and responding appropriately. Our research will have significant implications for a variety of adaptive information systems that rely on users' input for learning user or group profiles. Many such systems have open components through which a malicious user or an automated agent can affect the overall system behavior.","title":"Secure Personalization: Building Trustworthy Recommender Systems","awardID":"0430303","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7228","name":"DATA AND APPLICATIONS SECURITY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":[258532,"525682"],"PO":["355797"]},"98298":{"abstract":"A stochastic information fusion methodology is developed to assimilate electrical resistivity tomography, high-frequency ground penetrating radar, mid-range-frequency radar, pneumatic\/gas tracer tomography, and hydraulic\/tracer tomography to image fractures, characterize hydrogeophysical properties, and monitor natural processes in the vadose zone. The information technology research will develop: (1) mechanisms and algorithms for fusion of large data volumes; (2) parallel adaptive computational engines supporting parallel adaptive algorithms and multi-physics\/multi-model computations; (3) adaptive runtime mechanisms for proactive and reactive runtime adaptation and optimization of geophysical and hydrological models of the subsurface; and (4) technologies and infrastructure for remote (pervasive) and collaborative access to computational capabilities for monitoring subsurface processes through interactive visualization tools.<br\/><br\/>The combination of the stochastic fusion approach and information technology can lead to a new level of capability for both hydrologists and geophysicists enabling them to \"see\" into the earth at greater depths and resolutions than is possible today. Furthermore, the new computing strategies will make high resolution and large-scale hydrological and geophysical modeling feasible for the private sector, scientists, and engineers who are unable to access supercomputers, i.e., it is an effective paradigm for technology transfer.","title":"Collaborative Research: SEI (EAR): Adaptive Fusion of Stochastic Information for Imaging Fractured Vadose Zones","awardID":"0431079","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["524966","449735","561892"],"PO":["563727"]},"98067":{"abstract":"PROPOSAL NUMBER: CPA 0429572<br\/>TITLE: Supporting Higher-Order Approaches to Symbolic Computation<br\/>PI: Gopalan Nadathur<br\/><br\/>ABSTRACT:<br\/>Emerging trends in software authentication and use indicate a growing importance for the explicit treatment of objects such as specifications, programs and proofs in programming contexts. Elegant methods have been developed that employ lambda calculi for representing and manipulating such structures in logically certifiable ways. This research concerns the flexible and efficient utilization within computational settings of the resulting higher-order approach to dealing with symbolic structures. One focus is that of understanding and reaping the efficiency benefits of using a controlled but versatile operation for decomposing the lambda terms that are central to the approach. New algorithms for deploying this operation, methods for exploiting explicit treatments of substitution within them and appropriate compilation techniques will be developed. In another direction, choices in the machine representation of lambda terms will be evaluated and machinery for realizing optimized reduction strategies over them will be designed. The research results<br\/>will be applied to a system that is currently being exploited in several verification and program manipulation projects. This system will be used in a hands-on exposure of formal methods in the classroom setting. The training of graduate and undergraduate students in the broad area of formal techniques in software development is also envisaged.","title":"Supporting Higher-Order Approaches to Symbolic Computation","awardID":"0429572","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["499410"],"PO":["564388"]},"98078":{"abstract":"0429640<br\/>Mats Per Erik Heimdahl<br\/>University of Minnesota-Twin Cities<br\/> A Catalytic Infrastructure For the Design, Development, and Deployment of Formal Modeling Tools<br\/><br\/>Modeling is crucial in software development. Unfortunately, modeling languages and tools are currently static and cannot accommodate evolving needs. This project will develop the foundation for extensible and flexible<br\/>modeling-language processing tools that will allow: easy extension and modification of formal modeling notations, easy construction of high-quality translations from modeling notations to analysis tools, and controlled reuse of trustworthy tool fragments. The research hypothesis is that extensible languages defined using attribute grammars with forwarding hold the key to hyper-flexible, catalytic tools infrastructures. The hypothesis will be tested by evaluating the tools and techniques with multiple diverse modeling-languages on realistic systems.<br\/><br\/>The project is innovative: it provides a radically new way of thinking about modeling-language design, execution environments, and translation as an extensible and flexible abstract syntax tree defined through attribute grammars. The results are significant; they provide an extensible infrastructure for the development, use, and evaluation of new languages and analysis tools. The impact is broad; it provides technology commercial tool vendors can use to design tools for flexibility, a common and open tools<br\/>infrastructure for various research groups, and tools for teaching software engineering, formal methods, programming languages, and compilers at all levels.","title":"A Catalytic Infrastructure for the Design, Development, and Deployment of Formal Modeling Tools","awardID":"0429640","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["544438","421080"],"PO":["564388"]},"97870":{"abstract":"Proposal 0428078<br\/>TITLE More Modular Reasoning for Aspect-Oriented Programs<br\/>Gary T. Leavens<br\/><br\/>This project will advance the theory and practice of aspect-oriented software development. Aspect-oriented languages allow modularization of code for requirements that do not align with a program's architecture, reducing scattering and tangling of code for these cross-cutting requirements.<br\/><br\/>The problem addressed by this project is how to recover static, modular reasoning in aspect-oriented programs. The technical approach is to create the design discipline, based on an analogy to behavioral subtyping, and a small aspect-oriented programming language to support it. By producing prototype tools and<br\/>applying them in case studies, the researchers will experimentally validate the utility of the language and design discipline. A formal study of specification and verification techniques will demonstrate<br\/>soundness of static, modular reasoning in the language and design discipline.<br\/><br\/>The discipline developed through the project will benefit software engineers and programmers by providing guidance for thinking about and applying aspect-oriented programming techniques. The discipline may<br\/>also improve software correctness and maintainability. By showing how a language can support the discipline, the project will contribute to the design of programming and specification languages. Like the<br\/>notion of behavioral subtyping, a disciplined approach to thinking about aspect-oriented abstraction will help educators convey the key ideas of the paradigm.","title":"More Modular Reasoning for Aspect-Oriented Programs","awardID":"0428078","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["521544"],"PO":["564388"]},"97991":{"abstract":"Long-lived, autonomous software systems require ongoing self-<br\/>assessment, which implies a comparison between expected and actual<br\/>stimuli, as a prerequisite to self-diagnosis and repair. <br\/>This project addresses the use of dynamic analysis and machine<br\/>learning techniques for behavior classification. The proposed <br\/>work will<br\/>- address fundamental research and education issues in dependable<br\/> software-based computing systems by exploring how machine<br\/> learning techniques can most effectively be applied to improve the<br\/> self-assessment process;<br\/>- develop research products in the form of prototype tools or<br\/> methodologies, applying Markov models and cluster analysis to <br\/> the assessment of program behavior data;<br\/>- provide dependability attributes that are suitable for measuring <br\/> the impact of the research products, such as <br\/> the extent to which a set of Markov models successfully<br\/> describes the behavior of a software system;<br\/>- provide empirical evaluation\/validation of the<br\/> research products together with associated test data <br\/> to validate the effectiveness of the approach<br\/>The proposed research will provide empirical data on the use of <br\/>Markov models to encode behavioral models, and methodologies<br\/>and infrastructure for use in performing further experimentation.<br\/>The resulting techniques for provisioning software with behavior <br\/>models to aid in self-awareness will promote research <br\/>on development of real-time systems.","title":"HDCCSR: Software Self-Awareness Using Dynamic Analysis and Markov Models","awardID":"0429117","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}}],"PIcoPI":["530729","397849","550806"],"PO":["564388"]},"98970":{"abstract":"This project is designing new application and network transport protocols as well as improved workload characterizations and models for evaluating the protocols. In the domain of workload characterization, the project is evaluating and extending a new method for network traffic characterization called Bayesian Block (BB) analysis that is significantly more accurate than previous methods for estimating the time-varying rate of bursty event processes, such as packet losses in a network flow, packet or flow arrivals to a gateway or end host in the network, or requests arriving to a network service. Anticipated results include (a) more precise and accurate characterizations of these network event processes, (b) more precise and realistic synthetic workload models for network flows, and (c) extensions to the BB analysis method to improve its accuracy. The project is also investigating more precise and accurate peer-to-peer workload characterizations that can be used in the design of improved peer-to-peer applications. In the domain of protocol design, the project is investigating (a) new near-optimal download protocols from multiple (peer-to-peer) servers, and (b) exploratory design of new transport protocols. The new transport protocols employ forward error correction to recover from packet loss as well as BB analysis at the receiver to determine when to send feedback to the sender regarding observed packet loss rate for use in regulating the rate the packets are sent to the receiver.","title":"NeTS-NR: Next Generation Protocol Design Using Quantitative Methods","awardID":"0435437","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["410040"],"PO":["565090"]},"97760":{"abstract":"Abstract<br\/>Proposal 0427202<br\/>U of Cal Los Angeles<br\/><br\/>PIs: Jens Palsberg, Eddie Kohler, Rupak Majumdar, Todd Millstein<br\/>Event-Driven Software Quality<br\/><br\/>Event-driven programming, where tasks are divided into cooperatively-scheduled \"handlers\" that react to external events, has found pervasive acceptance from high-performance servers to embedded systems <br\/>as an efficient method for interacting with the world. Unfortunately, the loose coupling of handlers obscures program control flow and interdependencies, making programs hard to debug, maintain, and validate.<br\/>This research program investigates a new generation of programming language and tool support for event-driven programs constructed out of modular components. As representative test systems, it focuses on Click, a performance-constrained modular software router, and TinyOS, a resource-constrained operating system for embedded wireless sensors. All phases of the programming process are addressed, from the languages used to write event-driven programs, through automated verifiers and analyses that<br\/>ensure safety properties (such as bounding the latency required to handle an event), to optimizers that reduce code size, optimize system structures, and meet global resource constraints. Next-generation language and tool support will lead to increased confidence in a wide variety of event-driven systems, including Web servers, sensor networks, medical implants, engine control, and fly-by-wire\/drive-by-wire systems, and will make this important methodology easier to teach. New compilers and analysis tools will be made publicly available.","title":"ITR - ASE - int: Event Driven Software Quality","awardID":"0427202","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["558389","541961","460594","515836"],"PO":["564388"]},"98981":{"abstract":"Abstract: <br\/><br\/>Large scale sensor networks can often be viewed as distributed databases in which information querying is a fundamental operation.<br\/><br\/>This project aims to research a framework for efficient information discovery in sensor networks, based on a new paradigm called \"active query forwarding\". The basic principle of this approach is to consider queries as active entities which move efficiently through the network in search of desired information.<br\/><br\/>A multi-part methodology is employed in the project. Algorithms are designed for query guidance, semantics, adaptation, and optimization; these are then evaluated through both mathematical analysis and computational simulations. Important elements of the active querying framework are further validated on real experimental platforms.<br\/><br\/>The expected results consist of: (1) a scalable querying framework, (2) its constituent mechanisms, and (3) the related evaluation and validation studies. Together, these provide a fundamental building block for information management in next-generation sensor networks. Utilizing such building blocks efficiently can potentially improve sensor network lifetimes by orders-of-magnitude over existing approaches, without sacrificing information quality. The techniques developed in this project are useful for a wide range of large-scale sensor network applications, from industrial process control to structural health monitoring.<br\/><br\/>The results of the project are to be disseminated widely and in a timely manner through high quality publications, talks, and interactions with several industrial teams. The project is also closely integrated with the undergraduate and graduate networks curriculum at the University of Southern California, including new courses on sensor and ad-hoc networks and the training of several M.S.\/Ph.D. students.","title":"NeTS-NOSS: Data-Centric Active Querying in Sensor Networks","awardID":"0435505","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550970","531832"],"PO":["434241"]},"96451":{"abstract":"This work, constructing laboratory-scale Flexible AC Transmission System (FACTS) devices and interconnecting them via a simulation engine, studies and reduces potential deleterious effects, such as congestion or insecure operation, that may quickly propagate across the grid in complex and dramatic ways resulting in wide-spread blackouts. The FACTS device family of switched power electronics-based controllers, presently constitutes one of the most promising new sets of power controllers. These devices control the power flow through the lines of the network by rapidly injecting independent current and voltages into the system. This FACTS network provides a testbed for simultaneously testing both the FACTS hardware and the distributed fault-tolerant and secure software. The FACTS device laboratory studies reliability of the power grid, allowing experimental verification for the dynamics and control of multiple FACTS devices within the system. The controllers, built to regulate and manage the flow of electricity in high power energy grids, form an essential part of the constructed scaleable network of FACTS. Thus, various failure propagation effects in the power grid are under study to manage and control the flow of energy. A laboratory-scale FACTS testbed studies how devices behave under different scenarios. While validating various algorithms using actual devices, researchers conduct emulation experiments on real hardware to test the correctness of control algorithms under development. FACT devices provide the necessary capabilities to build an adaptive power grid. Presently, there is little deployment of such devices; hence, insufficient experience with them. This project is expected to provide such experience to the industry. Additionally, the network provides a unique testbed with which to develop distributed embedded control software.<br\/><br\/>Broader Impact: The lab facilitates exploration of new power control technologies that might result in better use of transmission facilities, thus having long-term effects for the entire community. It also provides a physical testbed for advanced courseware, enriching the environment for both students and their advisors. The equipment will also be used, as part of the institutions minority program, to encourage under-represented groups to participate in the project research and will be made available to other research collaborators at minimal cost. Visualization of the power grid control on the web makes the work accessible to scientists and engineers, policy decision makers, and the general public. <br\/><br\/>The funds requested include the equipment listed below and associated expenses.<br\/> UPFC, Test equipment, Xeon 4 processor, maintenance<br\/> Some students involved in the development","title":"MRI: Construction of a Laboratory to Study FACTS Device Interactions","awardID":"0420869","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["388044","544620",253087],"PO":["557609"]},"96462":{"abstract":"This proposal, developing a networked system to allow safe and rapid analysis of network security and vulnerabilities with respect to worms, viruses, and other malicious conduct, creates a reconfigurable facility, named ReASSURE, for efficient reproducible, controlled, and safely contained experiments in computer science and technology with emphasis on information assurance and security. The new instrument will integrate functionalities in a manner that will enable high levels of safety and efficiency in manipulating, testing, and developing potentially dangerous experimental networking and virtual machine software while providing computational power to remote users. Advancing the study of virtual machine technology, the activity offers settings where potentially dangerous experimentation with networking and VM technologies can be performed safely. Providing as testbed networking facility, the infrastructure supports projects that require \"self-contained\" computing environments in computer science (including security), computer technology, forensics, and information warfares.<br\/><br\/>Broader Impact: Undergraduate classes will make use of the instrument, and both graduate and undergraduate students will be involved in its making. Attention will be given to women and underrepresented groups. The testbed impacts 15 projects of 8 faculty members at Purdue and at the CERIAS affiliates, Syracuse University, and the US Air Force Institute of Technology.","title":"Development of a Safe, Virtual Imaging Instrument for Logically Destructive Experiments","awardID":"0420906","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["549800",253133],"PO":["557609"]},"96583":{"abstract":"This project, constructing an advanced security detection system portal that integrates many individual functions of current systems, focuses on the physical security aspects integrating a variety of detection mechanisms, such as chemical and biological sensors. The work supports research in fundamental areas related to security detection, monitoring, prototyping, prevention, and recovery. Investigating fundamental research issues in security detection, the project involves prototyping a walk-through security portal that uses a variety of sensors (visible, infrared and millimeter wave images, metal and air detection data) along with X-ray baggage scanning information and other information about the individual to determine the threat level. The analysis of the fusion of all such data from heterogeneous devices is expected to yield more accurate assessment than any one of more sensors analyzed individually. The equipment supports research and development of advanced detection systems for secured entry through the use of multiple, network-integrated sensors. The approach encompasses several interdisciplinary research areas including <br\/><br\/>Smart sensors, <br\/>Wireless sensor and data networks, <br\/>Sensor fusion, <br\/>Pervasive computing,<br\/>Image processing, and<br\/>Databases and data mining.<br\/><br\/>Research in smart sensors improves the ability to distribute sensors in a secured-entry portal and develop techniques for sensing at a distance (e.g., gases and materials). Image sensors (visible, infrared and millimeter wave) support research in image processing and concealed weapon detection. Biometric sensors and RFID tag technologies also provide a rich source of information for controlling access to high security areas. Micromechanical systems (MEMS) research develops wireless microsensors for detection of toxins. Sensor networking and fusion coupled with database research develop new methods for collecting, exchanging, processing, and understanding large amounts of real-time sensory information. Higher-level data integration and data mining research contribute new techniques for learning and assessing threat levels, and more efficient personnel and baggage screening. This instrumentation complements current research on Pervasively Secure Infrastructures (PSI) by integrating secure-entry capabilities into a more general approach to securing an environment, such as mass transit and shopping malls.<br\/><br\/>Broader Impact: The instrumentation provides resources for the Institute for Research In Security (IRIS). This institute facilitates multidisciplinary, collaborative research to improve the ability to maintain secure and usable environments. IRIS collaborates with several public safety and law enforcement agencies in developing and deploying leading-edge technologies in existing and future environments. The work will be disseminated through open houses, public demonstrations, publications, multi-disciplinary course and the web-site. Public demonstrations will target K-12 students.<br\/><br\/>The funds requested include the equipment listed below and associated expenses.<br\/><br\/>MEMS Wireless Sensor Networking Testbed, Millivision Vela125 Scanning Booth, <br\/>PowerView Stereoscopic PIV systems, Smith Detection X-Ray Baggage scanner, etc.","title":"Acquisition of Instrumentation for Engineering Research in Advanced Security Detection Systems","awardID":"0421282","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[253668,"564777","513339","559680","550149"],"PO":["557609"]},"98893":{"abstract":"The goal of this project is to develop traffic quantization techniques for addressing the scalability challenges in packet-switched networks, as well as prototype implementations of protocols and algorithms for quantized networks. Traffic quantization is a new method for supporting per-flow functionality, which can alleviate the complexity associated with per-flow QoS. A quantized network offers only a small number of service levels. Rather than receiving the service requested, each flow is mapped to one of the levels offered by the network; this mapping is performed in a way that guarantees a QoS at least as good as that requested by the flow. The directional p-median problem has been introduced as a formal framework for reasoning about the bandwidth quantization problem, but there is a new set of research avenues to pursue. Specific objectives include the study of stochastic quantization and quantization for a vector of traffic parameters, and the implementation of efficient algorithms (scheduling, bandwidth-guaranteed routing) for quantized networks. Furthermore, this project will investigate quantization as a technology enabling scalability in a range of applications and problem domains (multiprocessor scheduling and Grid computing). The end-result will be a collection of traffic quantization techniques with formally verified properties, and a suite of scalable control and data plane protocols and algorithms to support QoS guarantees in quantized networks. It is expected that the results of this work will address the QoS and scalability problems facing the Internet, and will lead to the development of novel network architectures with the ability to cater to very large sets of heterogeneous users by offering and guaranteeing a menu of optimized services.","title":"NeTS-NR: Traffic Quantization: A Formal Framework for QoS and Scalability in Packet-Switched Networks","awardID":"0434975","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["484227"],"PO":["565090"]},"96352":{"abstract":"Abstract<br\/><br\/>Title: ITWF Collaborative Research: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science<br\/><br\/>CNS 0420505, PI Kamin, Univ. of Illinois at Urbana-Champaign<br\/>CNS 0420000, PI Califf, Illinois State University<br\/>CNS 0420458, PI Lucht, Heartland Community College<br\/>CNS 0420468, PI Mobasseri, Parkland College<br\/>CNS 0420506, PI Uskov, Bradley University<br\/>CNS 0420321, PI Van Cleave, Eastern Illinois University<br\/><br\/><br\/><br\/>This collaborative ITWF project implements a set of activities designed to increase participation of women and under-represented minorities in undergraduate computer science programs in the state of Illinois. The project includes high school outreach, curriculum reform, mentoring, and other extracurricular activities. It is a collaborative project between the University of Illinois at Urbana-Champaign, Illinois State University, Heartland Community College, Parkland College, Bradley University, and Eastern Illinois University. The project involves building communities among various groups within the state to recruit, support, and retain students in computing courses and programs.<br\/><br\/>The intellectual merit of this project lies in the strong research basis for the intervention models as well as the vertical integration of the models at a range of secondary and post-secondary institutions within the state. The project plan is clear and reasonable with well-defined roles for the partners. The project builds on existing programs and partnerships within the state and includes investigators with significant relevant experience.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science within one state. If successful, the project may provide a sound model for similar broad-based approaches in other states and geographical areas.","title":"Collaborative Research: ITWF: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science","awardID":"0420506","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[252673],"PO":["361119"]},"97694":{"abstract":"Abstract <br\/>0426627<br\/>Huang, Thomas<br\/>U of Ill<br\/><br\/>Audiovisual Scene Analysis<br\/><br\/>In many applications such as Homeland Security, video surveillance is a crucial component. An important task is to extract moving objects (vehicles, people) and to separate the individual sounds (car noise, speech). But this is done usually separately, the former from the image sequences alone, and the latter from the audio (of the sound mixture). However, the two are closely coupled. We aim to do the two jointly, and term the task: Audiovisual Scene Analysis. The tool we shall use is Probabilistic Graphical Models, esp. Generative Models. A generative model includes hidden variables which affect the observed data (in this case, video with the associated audio).<br\/>Using the Expectation-Maximization algorithms, these parameters can be estimated. The challenge is to come up with appropriate models such that the parameter estimation will lead to audiovisual object separation. Once the audiovisual objects in a video are separated, then techniques such as face recognition and speech analysis could be used to detect objects and events of importance to specific applications.","title":"ITR: (NHS) - (dmc+sim): Computational Audio-Visual Scene Analysis (CAVSA)","awardID":"0426627","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":[257066,"550184"],"PO":["562984"]},"97584":{"abstract":"The purpose of this grant is to provide support for student travel to the 29th IEEE Local Computer Networks (LCN) conference, being held in Tampa, Florida on November 16 to 18, 2004. The LCN conference is a longstanding conference covering all aspects of computer networking, with participants from the USA, Europe, and Asia. This grant offers support for not only student paper authors, but also for student attendees from a state university serving under-represented populations. This conference travel support insures that deserving students will be able to participate in the conference, thereby nurturing the next generation of researchers.","title":"Student Travel Support for 29th IEEE Local Computer Networks Conference (LCN); November 16-18, 2004; Tampa, FL","awardID":"0425963","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["528187"],"PO":["292741"]},"96396":{"abstract":"This project, acquiring equipment to form the core of the Rensselaer Grid, a research testbed consistent with the capabilities of the future national cyberinfrastructure, supports research programs in Information Technology, Biotechnology, nanotechnology, and Homeland Security. Projects focused on the development of grid middleware and multiscale computing technologies, and the application of these technologies to science and engineering, advance and use the grid. The RPI core grid consists of 3 clusters having a total of 374 processors, and a 4th cluster with 162 processors connected via dedicated 10Gbit links. The resulting grid provides a research testbed of heterogeneous clusters with heterogeneous connections that can provide substantial processing power to applications. Placing emphasis on the development of middleware and simulation technologies needed to make effective use, the planned cyberinfrastructure, consisting of distributed heterogeneous computing clusters, provides computing power to industry, medicine, and business. The grid computing technologies research consists of a set of projects including the development of distributed programming technologies, grid networking simulation and security, data flow, extraction and control; dynamic load balancing, and support of real time applications and devices. The multiscale computation applications include adaptive multiscale computation tools (supporting adaptive dynamic simulation models); multiscale methods for biomolecular structure; simulation based medical planning for cardiovascular disease; multifunction polymeric nanocomposites; dynamic contact tasks planning with application to disaster recovery; and the evolution of social groups in communication networks. Encouraging collaborative efforts with existing cyberinfrastructure investments, including NSF PACI centers and the ETF, this campus level effort engages 38 PI faculty from 11 academic departments in science and engineering and involves 99 students. The underlying research project, supported by scores of grants from 7 federal agencies, NY state, and 7 companies\/foundations, include 13 collaborative universities, 6 national labs, and a state agency. <br\/>Broader Impacts involve: <br\/> Making the advances widely available through open standards and open source interoperable tools,<br\/> Training and involvement of over 130 on-campus researchers, along with collaborating colleagues in other universities, labs, and industry,<br\/> Transferring direct technology to industry, including start-ups, through well established technology transfer programs,<br\/> Expanding the educational programs, including new courses related to cyberinfrastructure and multiscale systems techniques, and inclusion of relevant projects in existing courses, and<br\/> Demonstrating grid-based simulations to precollege students of diverse background.","title":"MRI: Acquisition of Infrastructure for Research in Grid Computing and Multiscale Systems Computation","awardID":"0420703","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["534411","525821","541895","512760","307820"],"PO":["557609"]},"99421":{"abstract":"The science of ecology is crucial to our understanding of the evolution of life on earth as well as environmental problems such as climate change and reduced biodiversity. At present, ecology is a small, underfunded discipline. There is a self-identified need among ecologists that their science must grow in order to address timely large-scale ecological questions. To this end, software tools must be developed to handle data, to enhance remote collaborations, and to perform more sophisticated analyses of ecological data. Such tools are part of the emerging field of ecoinformatics. To develop good tools, interdisciplinary efforts are required, since many ecological problems involve other sciences such as physics and chemistry. This workshop will bring together ecologists, social scientists, computer scientists and librarians to discuss the work practices and information needs of ecologists and to inform the design of the new ecoinformatics tools. Topics of interest will include computational tools for handling large datasets, and issues related to collaboration over distance and working across disciplines.<br\/> <br\/>Broader Impacts: The workshop will enable scientists from varied disciplines to form relationships and networks for future interaction, so that ecoinformatics can be truly interdisciplinary. The outcomes will have implications for scaling up other field sciences such as geology, oceanography, and paleontology.","title":"Collaboration in Ecology: A Workshop Proposal","awardID":"0438848","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["483548","386299"],"PO":["564456"]},"98211":{"abstract":"While tremendous progresses have been made in theory and algorithms, certain numerical propoerties of the RLS problem such as sensitivity of the solution and its condition number are not well understood, and solving large-scale problems remains a challenging task.<br\/><br\/>This propposal will further efforts to establish the eigenvalue reformulation as a numerically stable and efficient method for solving large-scale RLS problems and to develop robust Krylov subspace type methods for solving the related quadratic eigenvalue problem. It is also proposed to investigate eigenvalue formulations of other related constrained quadratic optimization problems to which this research may be applicable.<br\/><br\/>The proposed work would advance theoretical understanding and develop efficient algorithms for RLS problems. This approach via an eigenvalue problem would lead to algorithms that could better exploit future developments of eigenvalue algorithms. Another potentially important implication of this research is the establishment of a framework for justifying the use of a direct eigenvalue formulation for an optimization problem.","title":"Collaborative Research: Large Scale Regularized Least Squares Problems via Quadratic Eigenvalue Problems","awardID":"0430617","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["320271"],"PO":["499399"]},"98101":{"abstract":"Control-Flow Processors<br\/>Abstract<br\/><br\/><br\/>An architecture is presented that unifies fine-grain control-flow and data-flow dependences in the context of contemporary superscalar processors, preserving highly streamlined mechanisms of superscalar processors while endowing them with dataflow properties. Future independent instructions are fetched, executed, and locally finalized, their results propagated and corresponding resources freed, and their cumulative effects sustained regardless of prior unresolved branch mispredictions. Branch mispredictions no longer serialize execution, leaving exceptions and finite resources as the only remaining serializing constraints in the system.<br\/><br\/>In the domain of high-performance microprocessors (which power supercomputers, personal computers, laptops, and even cell phones), there remain a few dogged bottlenecks that fundamentally constrain performance, making it difficult to translate the potential of additional transistors into effective performance gains. The project's broader significance is an approach that aims to overcome one of the remaining grand-challenge problems in scaling microprocessor performance.","title":"Collaborative Research: General-Purpose Memory Tagging for Reliable, Secure, and Fast Computing","awardID":"0429802","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["550974"],"PO":["550859"]},"98112":{"abstract":"Proposals 0429894\/Naumann 0429567\/Leavens<br\/><br\/>Collaborative Research:<br\/>Formal Methods for Behavioral Subclassing and Callbacks<br\/><br\/>David A. Naumann and Gary T. Leavens<br\/><br\/>For evolvability, scalability, and productivity, software systems must be composed of extensible components. Features of object-oriented programming languages such as inheritance and dynamic dispatch, and<br\/>techniques like callbacks and downcalls, are crucial but they invert the usual layering of abstractions. Aliasing among objects is crucial for efficiency but can breach encapsulation boundaries. Yet abstraction<br\/>and encapsulation are necessary to separately validate individual components.<br\/><br\/>This project will advance the theory of specification, development, and verification for object-oriented software, focusing on behavioral subclassing, alias confinement, and callbacks. Core features of the<br\/>Java Modeling Language (JML) for behavioral interface specification will be studied, using a confinement discipline to control aliasing and model programs to specify callbacks. The ideas will be presented<br\/>in a cogent, simple, and robust theory, to facilitate applications by tools, comparison between alternative proposals for specification notations and proof rules, and teaching. The theory will be encoded<br\/>in a theorem prover and key results machine-checked.<br\/><br\/>This project will provide theoretical guidance for the designers of programming and specification languages. The results will also help clarify and improve techniques used in practice.<br\/>Direct application is expected in projects based on JML and in work by our Brazilian collaborators.","title":"Collaborative Research: Formal Methods for Behavioral Subclassing and Callbacks","awardID":"0429894","effectiveDate":"2004-09-01","expirationDate":"2008-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["521696"],"PO":["564388"]},"98233":{"abstract":"Intellectual Merit:<br\/>Numerous applications in science and engineering require meshing a surface or a volume into a triangulation. The problem arises at the micro-level in molecular modeling and at the macro-level in automotive designs, in the scientific study of natural phenomena and in the engineering of man-made machine tools and appliances. As varied the applications are, so are the types of their inputs. Almost no provable algorithm exists for many of these input domains. As a result, many of the commercial products catering to the huge needs for quality meshing rely on heuristics which often produce poor meshes. <br\/><br\/>This research will fill the gap between the need for quality meshing of a variety of input domains and the algorithm and software that can achieve it with guaranteed correctness. To this end, this research will consider inputs as varied as implicit, parametric, point-sampled, polyhedral, piecewise smooth surfaces as well as volumes enclosed by them. Each of these inputs poses difficulties that are unique to its kind. The project will focus on the design and analysis of the provable meshing algorithms and software systems based on them for these input domains.<br\/><br\/>Broader Impact:<br\/>The developed tools in this project will enable meshing complicated geometry with guarantees and enhance further analysis using them. This will impact a variety of areas in science and engineering including physics, biology, environmental science, computer aided designs, manufacturing, health care, entertainment and so on.<br\/><br\/>The development will influence the research in the areas of computational geometry, computational topology, geometric modeling, computer graphics and visualization. Course notes, seminars and software systems developed through the project will enable educators and students to attack meshing problems in a formal setting with guaranteed correctness.","title":"Implementation-friendly Geometric Algorithms for Provable Surface and Volume Meshing","awardID":"0430735","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["549998"],"PO":["565157"]},"98244":{"abstract":"Abstract<br\/>NSF-0430779<br\/><br\/><br\/>Consequences of global change for land cover, carbon cycles, and biodiversity loss involve complex interactions at fine scales, such as resource availability in forest understories, to regional land-cover, climate, and CO2. Global change research requires models developed through careful study of local phenomena that can be extended to landscape, regional, and global scales. Unfortunately, environmental scientists have been limited in their ability to determine how factors that operate at different scales impact landscapes.<br\/><br\/>The primary long-term goal of the research is to enhance the ability of biology and geoscience research programs to acquire, analyze, and distribute high-resolution GIS databases of important environmental attributes. In support of this goal the computer science team will develop new techniques to extract forest attributes in the form of GIS databases from remotely sensed data. The computer science team will build an aerial remote sensing platform and a suite of analysis tools for creating GIS databases of environmental attributes with sub-meter geo-registration and elevation accuracies.<br\/><br\/>The image acquisition, analysis and GIS tools developed by UMass and MHC <br\/>provide the critical broad-scale, yet high-resolution, data needed to parameterize and validate models used to study global change. The products of these analyses will be integrated within a modeling framework at Duke University that includes extensive field data, application of new statistical computation methods, and development of a stand simulator. The combined effort will be used to determine how diversity is maintained in forest stands based on a comprehensive accounting of environmental impacts and uncertainties.","title":"Collaborative Research: SEI(BIO)--Automated Methods for Generating High-Resolution GIS Databases from Remotely Sensed Data for Biodiversity Predictions","awardID":"0430779","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":[258710],"PO":["565136"]},"87123":{"abstract":"Location-based Information Access in Pervasive Computing Environments<br\/><br\/>Location-based spatial queries (LBSQs) refer to a set of spatial queries that retrieve information based on the current locations of the users. Due to the unrestricted mobility of users in the pervasive computing environments, the LBSQs is distinct from the traditional spatial queries. For example, a traveller may issue a query \"find me the three nearest restaurants\". The answer to this query is dependent on the location where the traveller receives the query results. <br\/><br\/>The goal of this research project is to investigate new ways of indexing and caching spatial data to support processing of LBSQs in pervasive computing and to validate the methods obtained from this project via analysis, implementation, and simulations. The emphasis of the project is on methods that are particularly suitable for wireless data broadcast. A list of LBSQs, including point query, window query, nearest neighbor (NN) search, k nearest neighbor (KNN) search, continuous nearest neighbor (CNN) search, spatial join, and complex queries is studied in this project. Fundamental issues faced by all the spatial indexes and caching schemes (such as large index search space, large index size, linear streaming property of wireless data broadcast, continuous movement and requests of mobile users, and cache replacement\/invalidation) are tackled. This research result will have significant impacts on advancing the fields of spatial databases and pervasive computing. The proposed research activities will be closely integrated with the PI's educational goals and activities at both of the undergraduate and graduate levels. The developed techniques and experimental data will be made available in a timely manner by means of a website and publication in multi- and interdisciplinary conferences, workshops, and journals. In addition, scientific and engineering presentations will be given to the broader community, including the public or industry, where possible. Finally, the results and experiences obtained in this research have many possible applications in location-based services, e.g., those based on the recently announced SPOT technology and directband network. Publication, technical reports, software and experimental data can be accessed at the project web site http:\/\/www.cse.psu.edu\/pda\/LBSQ","title":"Location-based Information Access in Pervasive Computing Environments","awardID":"0328881","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["316300"],"PO":["433760"]},"99465":{"abstract":"This is a collaborative grant with two PIs; Javed Mostafa of Indiana, and David Stark of Columbia. <br\/><br\/>Intellectual Merit<br\/>With a grant from the NSF Digital Government Program, David Stark has been studying the role of information technologies in the public debate surrounding the rebuilding of Lower Manhattan in the wake of the September 11 attacks on the World Trade Center. In the process of conducting that research Stark's team has assembled an extensive digital archive containing 5,000 participant oral statements from one town hall meeting and an additional 19,000 oral statements collected at 240 different venues around New York City in the 'Imagine New York Envisioning Workshops'. These gathered statements provide a rich opportunity for testing various strategies of computer-assisted interpretation because they provide an opportunity to compare the conceptual patterns discerned by human intelligence with findings reached through the analytical methods of artificial intelligence. Supporting the initial explotation of that archive is the purpose of this grant.<br\/><br\/>The technical component of this grant arises from work Javed Mostafa has done under an NSF ITR grant. Data mining research concentrating on spontaneous human conversations is at an early stage of development. Mostafa's approach to data mining can offer different ways to analyze the same data. The project has three specific goals: 1) to detect emergent concepts by applying techniques that do not impose any a priori conditions; 2) to use techniques for analyzing known concepts by applying constraints on the mining process, and 3) to develop visualization of the results to facilitate interpretation by social scientists and support direct validation by citizen participants. <br\/><br\/>Broad Impact <br\/>Computer mediated communication offers new channels for citizens to express their views to elected officials and government agencies. Often, the resulting deluge of comments poses a technical and political challenge. How can officials\/agencies make sense of large-scale citizen input? How can meaningful patterns be efficiently and effectively identified? This project will contribute to advancing understanding of the opportunities and the limitations of computer-assisted interpretation. Its findings will be of considerable interest to scholars as well as to government managers responsible for the rebuilding of lower Manhattan. <br\/><br\/>Summary <br\/>Many challenges involved in creating new data mining tools demands an interdisciplinary collaboration for access to new data; this project offers such an opportunity. This time-critical testing of artificial intelligence methods will be important in understanding the public input to rebuilding lower Manhattan.","title":"Collaborative Research: SGER: Computer-Assisted Interpretation of Citizen Input in Rebuilding Lower Manhattan","awardID":"0439105","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["486226"],"PO":["371077"]},"89433":{"abstract":"Job Scheduling for Data Centers with Multi-Level Storage Systems<br\/><br\/>Abstract<br\/><br\/>In many fields of science, engineering, and medicine, data is being collected and generated at an increasing rate, due to high-resolution measurements made possible by advanced sensor technologies and large scale simulations enabled by inexpensive, high-performance computing through commodity PC clusters. In order to support the data management and processing requirements of data driven science, research institutions and supercomputing centers will not only host, manage, and provide access to computing resources but also will deploy high-end, Grid-enabled data centers.<br\/>The objective of this project is to develop the scheduling technologies to provide efficient access to shared resources on large scale storage systems with multi-level storage hierarchies. We plan to design, implement and evaluate scheduling approaches for job schedulers that will control the access to and sharing of resources and that will support high throughput and interactive responses for many simultaneous data analysis and computing jobs on large storage systems.","title":"SOFTWARE: Job Scheduling for Data Centers with Multi-level Storage Systems","awardID":"0342615","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["532951","410444","530803","256888","452272"],"PO":["565272"]},"98024":{"abstract":"In localities with established community computer networks, interested citizens have been using a variety of online tools to interact with government. Citizens download local government information and use the Internet to stay informed on local issues. Town and county government officials and staff regularly update their web sites, post meeting agendas, budgets and minutes, background documentation, and exchange email on a one-to-one basis with residents. A new pattern of Internet use is emerging in which small groups of interested citizens - typically from established local formal and informal associations - distribute information on issues of interest among themselves and use online tools to deliberate on public policy. <br\/>Increased citizen-to-citizen discussion and deliberation is an important outcome of digital government initiatives. It is occurring predominantly through discussion lists, multiple recipient email exchanges, listserv forwarding, and most recently, even blogs. But citizen deliberation across the community has a limited linkage back to government decision-making. What strategies and tools might help local government better integrate this citizen deliberation into the local governing process? By examining government and citizen interactions and the deployment of innovative tools in a stable, mature community network research can extend beyond primary effects (government posting information online and answering email) to secondary effects, specifically, the impact of online government on deliberative democracy. <br\/><br\/>The research team will use a mature community computer network environment, the Blacksburg Electronic <br\/>Village in Blacksburg, Virginia, as a comprehensive test bed and case study. Of particular interest are the<br\/>differences between activists and underrepresented citizen on factors such as motivation for online use, role of weak social ties across diverse groups, collective efficacy and civic participation. Primary research objectives are: <br\/><br\/>- To model community use of network technology for deliberation with special focus on use by local organizations and by people with lower socioeconomic or ethnic minority status.<br\/>- To model local government use of network technology and the integration of citizen feedback into decision-making processes.<br\/>- To deploy and evaluate a suite of modified innovative tools for incorporating citizen deliberation into local government decision-making.<br\/>. <br\/>The intellectual merit of this project is based on re-focusing the digital government discussion around elements that make for an effective democracy rather than for effective government and in the participatory design and testing of innovative tools for lay citizens. The broader impacts are both conceptual and practical as well as policy related. A model of democratic deliberation that includes concrete tools could substantially modify future efforts to deploy this technology effectively by local government, particularly in small towns and rural areas where technical expertise is scarce and infrastructure is sub-optimal.","title":"Modeling Online Participation in Local Governance","awardID":"0429274","effectiveDate":"2004-09-01","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["550464","531150",258131,258132],"PO":["371077"]},"98266":{"abstract":"Superior shape and surface quality have a visible impact on new product design and industrial competitiveness. Decreasing the need for human, heuristic intervention when modeling surfaces is a precondition for accurate engineering simulation and high-quality geometry processing and it reduces effort, time, cost and variability. Characterizing and creating surfaces that withstand scrutiny in the detail is a fundamental unresolved challenge to applied differential geometry and geometric design.<br\/><br\/>This research will characterize high-quality surfaces and develop tools for their creation. The effort centers on surfacing schemes that are computationally efficient, finite and affine invariant, and generate fair, curvature-continuous, parametric surfaces that are representable in a standard rational or polynomial form. The starting hypothesis is that a blend between multiple primary surfaces is good if it does not create curvature features that were not present in the defining data.<br\/><br\/>The research will analyze why the existing techniques fail to generate satisfactory curvature distributions, develop a practical notion of surface quality, repair existing techniques or declare why they are fundamentally flawed and develop new approaches to be tested against a carefully chosen obstacle course of joins of multiple primary surfaces.","title":"High-quality Spline and Subdivision Surfaces","awardID":"0430891","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["486405"],"PO":["321058"]},"98299":{"abstract":"This project is developing novel statistical data mining methods that will help scientists to explore and understand large observational data sets. A specific focus of this research is on developing algorithms that can extract, from large data sets, models of dynamic behavior of objects over time, with an emphasis on selected data-driven problems in biology and geoscience. Examples include automated discovery of genetic regulatory mechanisms from expression measurements over time, and clustering and prediction of cyclone behavior over time. Statistical learning principles are being used to guide algorithm development and to produce publicly-available software tools. An educational component of this project is leading to an increased awareness among students of the important role of computer science and statistics in data-driven science.<br\/><br\/>The results from this project have the potential for significant and broad impact in the primary focus areas of geoscience and biology, as well as in other scientific and engineering areas involving large observational data sets from dynamic processes. In the geosciences, the new algorithms can yield improved modeling and prediction of extra-tropical and tropical cyclones, reducing the socio-economic risks associated with cyclonic events and potentially provide valuable clues about possible climate change. In the biosciences, improved understanding of gene regulatory mechanisms (obtained via new network discovery algorithms) can provide the basis for significant advances in systems biology and medicine, such as the identification of the regulatory mechanisms for cancer-related genes and resultant development of gene-specific medical treatments.","title":"Statistical Data Mining of Time-Dependent Data with Applications in Geoscience and Biology","awardID":"0431085","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["550872"],"PO":["565136"]},"94560":{"abstract":"National Science Foundation<br\/>Distributed Systems Research <br\/>CISE\/CNS<br\/><br\/><br\/>ABSTRACT<br\/>PROPOSAL NUMBER: 0411047<br\/>PRINCIPAL INVESTIGATOR: Rubenstein, Dan<br\/>INSTITUTION: Columbia University<br\/>PROPOSAL TITLE: Distributed, Self-Stabilizing Tasking for Emerging Network Environments<br\/><br\/>This proposal explores distributed algorithms and protocols to perform tasking in emerging networking environments. Tasking is easily described informally as assigning to each network node a job, rsource, or configuration drawn from a relatively small set of<br\/>possibilities, where the same task may be assigned to multiple ndes. Tasking examples include channel assignment for 802.11 ad-hoc networks, distributing computations in GRID networks, and placing content replicas in P2P networks.<br\/><br\/>This project contains a significant theoretical component that formalizes the distributed algorithms and protocols, proves self-stability, and formally quantifies bounds on the performance of the tasking result over general network topologies. The distributed protocols are designed for practical implementation, i.e., simplicity of design is preferred over additional optimality. We plan to demonstrate this facet via simulation and prototyping the results from the theoretical work within several emerging network environments including ad-hoc networks and distributed gaming networks. We anticipate dissemination via publication of results in leading conferences and journals, plus public release of software prototypes and simulation packages.<br\/><br\/>Several short-term goals are tackled under this proposal, including the reduction of messaging overhead, performance of the protocols in which underlying nodes join and leave the network, and variants on optimal configuration such as content popularity and nodes whose tasks are hard-wired. The research is also investigating the application of tasking in two novel environments: channel allocation in multi-hop ad-hoc wireless networks to minimize interference among neighboring nodes, and assignment of tasks to gaming servers to minimize latency in distributed gaming infrastructures.<br\/><br\/>Dr. Brett D. Fleisch<br\/>Program Director, CISE\/CNS<br\/>May 26, 2004.<br\/>.","title":"Distributed, Self-Stabilizing Tasking for Emerging Network Environments","awardID":"0411047","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["522280"],"PO":["543507"]},"94472":{"abstract":"Lach - Abstract<br\/><br\/>A challenging aspect of embedded system design is hardware\/software partitioning. Many system tasks may be performance-sensitive, but hardware implementation of all such tasks may be prohibitively expensive. In addition, hardware implementation of tasks that are performance-sensitive but rarely executed results in low resource utilization. Multi-mode systems have emerged as an area-efficient solution to this problem, implementing multiple time-wise mutually exclusive performance-sensitive tasks in a single hardware space. To execute a particular task, the hardware is configured to the appropriate mode. However, existing multi-mode techniques have limited reconfigurability, as only the datapath interconnect can be changed and only from mode-to-mode.<br\/><br\/>This project is developing a highly flexible multi-mode embedded system design technique that enables inter- and intra-mode reconfiguration of datapath components and control structures as well as interconnect. This added flexibility results in significant area and power savings over existing multi-mode techniques. The hardware flexibility is efficiently obtained via a new small-scale reconfigurability (SSR) design technique, which integrates small amounts of reconfigurable logic and interconnect into primarily fixed logic circuits, thus avoiding the area, delay, and power penalties associated with general-purpose reconfigurable fabric The design paradigm provided by these techniques requires a reevaluation of hardware\/software partitioning in embedded systems, as the cost model associated with hardware implementation changes significantly.<br\/><br\/>This project contains three primary components. First is the development of multi-mode system synthesis techniques that leverage the extra hardware flexibility provided by reconfigurable datapath components and controllers and intra-mode reconfigurability. The goal is a generic system synthesis algorithmic framework (including scheduling, allocation, and binding algorithms) that is applicable to a variety of embedded system applications. Second is the development of SSR as a hardware implementation technique for flexible datapath components and controllers. Third is exploring the effect this new design paradigm has on hardware\/software partitioning in embedded system desig","title":"EHS: Highly Flexible Multi-Mode Embedded Systems","awardID":"0410526","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["527785"],"PO":["561889"]},"98960":{"abstract":"NeTS-NR: Implementation Techniques for Last-Mile Wireless Mesh Networks<br\/><br\/>Tzi-Cker Chiueh, SUNY at Stony Brook<br\/><br\/>Award 0435373<br\/><br\/>Abstract<br\/><br\/>The explosive growth of IEEE 802.11 wireless LAN (WLAN) technology has prompted a rethinking of how metropolitan-area mobile wireless network services should be designed and implemented. Specifically the cost-effectiveness of 3G cellular networks is being called into question owing to their gargantuan initial licensing cost. In contrast, wireless mesh networks (WMN) that leverage 802.11-based WLAN hardware or the emerging 802.16 wireless broadband access standard (WiMAX) do not incur any licensing fees because they operate in the unlicensed spectrum. Moreover, the hardware\/software components of wireless mesh networks are relatively inexpensive since their success in consumer and enterprise market segments creates economies of scale and significantly brings down the manufacturing and development cost. This project is developing, implementing, and evaluating a novel wireless mesh network architecture called Hyacinth that is specifically designed to support last-mile broadband Internet access. Hyacinth features several unique innovations that are not present in other WMNs. First, Hyacinth significantly increases the aggregate throughput of a WMN by supporting multiple WLAN interfaces per WMN node, each operating at a distinct radio channel. Second, Hyacinth supports a host-transparent network-layer handoff scheme that preserves continuity of network applications as end hosts move across different subnets, without requiring any modifications to end hosts. Third, Hyacinth improves the aggregate throughput of each WMN node by equipping each WMN node with an array of access points and dynamically balancing their load. Fourth, Hyacinth's routing protocol has built sufficient redundancy into route updates such that compromised nodes that lie can be detected and isolated.","title":"NeTS-ProWiN: Implementation Techniques for Last-Mile Wireless Mesh Networks","awardID":"0435373","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["359707"],"PO":["564777"]},"94483":{"abstract":"Freudenberg-Krogh (collaborative) - Abstract<br\/><br\/>The goal of this project is to develop concepts and tools for model-based development of embedded control systems for automotive x-by-wire systems. X-by-wire systems replace mechanical connections between the driver and the vehicle with embedded computers and actuators (e.g., motors) to control the automobile and provide physical responses to the driver. These systems are characterized by multiple, highly integrated and interacting feedback loops. This project is creating new methods for designing these embedded control systems to improve performance while enhancing safety and reliability and reducing development cost. The research draws on control theory to deal with physical dynamics and synthesis of the feedback loops and with formalisms and techniques from computer science to deal with the logical aspects of the embedded software. Using a laboratory implementation of a steer-by-wire system as a test bed, models of the dynamics, including driver behavior, are being analyzed using new compositional methods that make it possible to design elements of the embedded control systems with guaranteed performance characteristics. The theory of fundamental design limitations is being extended and applied to these models to evaluate the tradeoffs between dynamic performance and robustness. Verification methods for hybrid systems (systems with continuous and discrete state variables) are being developed to demonstrate the safety of the system, even when there are failures in sensors and other system components. Tractable verification problems are being developed based on model decompositions reflecting the model structure, time-scale separation, and novel representations of the interaction dynamics. The embedded software design is being implemented and evaluated on the laboratory test bed in cooperation with an industrial partner.","title":"Collaborative Research: Embedded Control Systems for X-by-Wire Applications","awardID":"0410568","effectiveDate":"2004-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["460548"],"PO":["561889"]},"98971":{"abstract":"National Science Foundation<br\/>NETS - Research in Network Technologies and Systems <br\/>CISE\/CNS<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Proposal Number: 0435444<br\/>Principal Investigator: Zhang, Zhi-Li<br\/>Institution: University of Minnesota-Twin Cities<br\/>Proposal Title: NeTS-NR: Towards a Service-Oriented Internet<br\/><br\/><br\/>This project develops a novel service-oriented Internet (SOI) architecture that circumvents the inherent limitations of the current IP infrastructure. The new architecture provides a unified substrate for enabling and supporting new Internet services, while leveraging existing IP networks for data delivery. In the SOI architecture three key abstractions are advanced: 1) the notion of service cloud which is an abstract representation of a collection of service entities that an application or information service provider deploys over the Internet to fur-nish its services; 2) a new two-level, location-independent addressing scheme consisting of a globally defined, fixed-length service id which uniquely identifies each service cloud, and a variable-length, service-specific object id which speci-fies an object within a service cloud; 3) a new service layer that resides between the IP network layer and end-system layers for flexible support of service rout-ing and delivery. The SOI architecture can potentially facilitate and enable the deployment of value-added services that will spur the further development of the Internet, and produce great benefits to the society in general. Furthermore, the understanding and insights to be gained as a result of this research will lead to the establishment of design principles, mechanisms, and guidelines for building and evolving the future Internet. <br\/><br\/><br\/>Dr. Admela Jukan<br\/>Program Director, CISE\/CNS<br\/>Aug 5, 2004.<br\/>.","title":"NeTS-NR: Towards a Service-Oriented Internet","awardID":"0435444","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543509"],"PO":["565090"]},"97761":{"abstract":"Sequential and graph-structured data arise naturally in a wide variety of scientific, engineering, and intelligence problems, such as handwriting and speech recognition, text mining, gene finding, and network analysis. While researchers have recently made significant progress on machine learning methods for processing structured data, these methods are much less accessible to scientists, engineers, and analysts than the better understood statistical learning techniques of classification and regression.<br\/><br\/>This project is researching methods to advance the state of the art in machine learning for structured data, building on recent work in conditional random fields and weighted transducers. The project is also developing a software toolkit to make the results of these advances accessible to researchers working in a wide range of disciplines and application domains. The toolkit will enable users to define, train, and apply models for structured data without requiring advanced expertise in machine learning. The functionality of the toolkit will include methods for specifying features relevant to an application, automatically selecting the most relevant features, adjusting parameters to optimize suitable training objectives, and combining models that pertain to different facets of an application.<br\/><br\/>The software, which will be freely distributed, will be tested with selected users in several application domains, and be carefully documented. The project will thus provide the scientific and engineering community with the first generally usable tool for learning from structured data, serving a role that is parallel to that of the more standard tools for classification and regression that are already widely used.","title":"ITR: Collaborative Research: (ACS+NHS)-(dmc+soc): Machine Learning for Sequences and Structured Data: Tools for Non-Experts","awardID":"0427206","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["485891"],"PO":["565215"]},"96441":{"abstract":"This project, developing an instrument designed to test new network protocols and data services for long haul, high performance network called the Teraflow Testbed (TFT), integrates distributed clusters of workstation at four locations (Amsterdam, Geneva, Chicago-StarLight, and Chicago-UIC) using advanced 10 Gbs photonic networks and relying on both layer 2 optical switching and layer 3 routers. The project aims at supporting development of key network technologies important for the next step in high performance, data intensive computing. Research ranges from both low-level network protocol to offering high level data services. TFT will consist of distributed nodes over two continents that can transmit, process, and mine very high volume data flows (teraflows). The testbed will enable the development of new network protocols and innovative data integration and data mining services for teraflows. The work involves the design of a new class of applications that move not only the queries and computation, but the data when required. Subsequently, testing of the protocols and services for traditional routed networks as well as lambda grids will take place. The following three specific research activities in the general area of lambda-grids (posits collections of plentiful computing and storage resources richly interconnected by dedicated dense wavelengths division multiplexing (DWDM) optical paths) will be conducted:<br\/> High Performance Network Transport Protocols for Teraflows,<br\/> High End-to-End Performance for Teraflows, and<br\/> High Performance Data Services for Teraflows.<br\/>The first supports the development of new network protocols to provide higher bandwidth utilization and good transport performance for networks with high bandwidth-delay product optical network links. Based on previous work on SABUL, a rate based reliable transport protocol with high bandwidth delay, based on UDP (for data) and TCP (for control flow), a UDT protocol is proposed to achieve high effective throughput and still provide fairness for competing teraflows. The second supports the integration of local input-output systems with the very high data rate network protocols. Proposing the integration of an experimental system of intelligent high-speed disks connected to a cluster with the TFT, methods for relaying control information directly from the parallel I\/O system to the rate control algorithm in the new protocol will be investigated to maximize overall performance between remote parallel disks. The third develops high performance data services for mining teraflows that use a SOAP\/XML based control channel and a separate data channel. This activity builds a distributed peer-to-peer storage system for the data which teraflows can easily access and identifies data mining primitives to filter and process the teraflow. <br\/><br\/>Broader Impacts: TFT is expected to impact homeland defense, business continuity, and disaster recovery technologies. Post docs, graduate and undergraduate students will partake in the research. Tutorials on high performance data transport will be given at technical conferences.","title":"MRI: International Data Mining Grid Testbed for Research in High Performance Data Transport, Data Integration, and Data Exploration -- Instrument Development Proposal","awardID":"0420847","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["533353","532978",253047],"PO":["557609"]},"98630":{"abstract":"The PIs will undertake an experimental study and computational modeling of the internal representations and associated processes that underlie action perception and understanding by observers, and action planning and execution by actors. To facilitate both careful experimentation and formal theory, the PIs will approach the behavior representation problem primarily through the visual system, asking how do we understand the actions of others using our vision? That is, how do we perform mappings from image sequences depicting simple actions to the corresponding internal representations that allow action recognition, imitation, etc? The PIs will further explore higher-level cognitive representations and mechanisms used to categorize, reason about, and judge the movements and actions of others. The approach is based on a novel formal theory of the mental representations and processes subserving action understanding and planning, which the PIs believe provides a compact but powerful and extensible computational approach to the analysis and synthesis of complex actions (and action sequences) based on a very small set of atomic postural elements (\"key frames\" or \"anchors\") and the corresponding probabilistic, grammatical rules for their combination. This probabilistic \"pose grammar\" approach to action representation is similar to state of the art techniques used for speech recognition (e.g., hidden Markov models), but with key postural silhouettes taking the place of phonemes; such augmented transition grammars also nicely reflect sophisticated new control-theoretic techniques in robotics for robust anthropomorphic movement. The action representational system is not monolithic, but rather occupies a spectrum of informational structures at hierarchical levels corresponding to different behavior \"spaces\": mechatronic space, used in movement planning and production; cognitive space, involving representations for action recognition, analysis, and evaluation; visual motion space, which encodes and organizes visual motion caused by human action; and linguistic motion space, comprised of conceptual\/symbolic action encoding. Excluding here the latter space, the PIs' theoretic, computational, and experimental efforts seek to clarify and formally describe both the nature of the representations in these spaces and, crucially, the mapping of representations across spaces. Notably, they explore a candidate action representation, referred to as a visuo-motor representation, which, in facilitating the understanding of observed actions, may recapitulate and resonate with the actual motor representations used to generate movement. Moreover, they present a promising approach for obtaining this representation from discrete action elements or anchors.<br\/><br\/>Broader Impacts: This project will lead to significant advancements in both research and applications in psychology (e.g., robust social judgments given degraded biological motion), kinesiology (e.g., analysis\/modeling\/training of movement profiles, as in athletics or pathology\/rehabilitation), robotics (e.g., control of anthropomorphic robots), human and computer vision (e.g., automated action recognition in digital video), and other fields concerned with the interpretation and production of human\/humanoid action.","title":"Collaborative Proposal: HSD-DHB-MOD The Grammars of Human Behavior","awardID":"0433226","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7319","name":"HSD - DYNAMICS OF HUMAN BEHAVI"}}],"PIcoPI":["455781"],"PO":["565227"]},"98751":{"abstract":"The goal of this project is to build and calibrate two new mass spectrometer (MS) prototypes: 1) A small, high-impact tolerant rotating field MS (RFMS) that can measure gases and fluids in a small, hand-held package, allowing this device to be used for real-time analyses in the field, and 2) An extremely high-resolution multi-bounce time of flight (MBTOF) MS of moderate size, but with the<br\/>capability of measuring a wide range of light isotopes in addition to specific heavy<br\/>isotopes. For the first (RFMS) prototype, this existing design suffers from signal to noise (SNR) issues associated with the ionizer or the momentum filter. The team will use off-the-shelf (OTS) ionizers to track down the issue and correct the problem. For the second system, the existing design will be calibrated against a wide range of chemical compounds, to illustrate readiness for measurements. Specific tasks for the second (MBTOF) prototype will include: integration of a higher speed and sensitivity ETP Hybrid MCP-discrete dynode detector appropriate for isotope measurements, and calibration and sensitivity testing against a suite of chemical compounds. <br\/><br\/>The project investigates the fundamental ion physics associated with new implementations of sophisticated mass spectrometers that could be used in a wide range of scientific and commercial disciplines, in a wide range of environments, from ice boreholes that reveal the history of climate to effluent gas monitoring stations.","title":"New Mass Spectrometers for NBC & Environmental Characterization","awardID":"0434157","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V579","name":"DEFENSE-NATL MASINT CONSORTIUM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V918","name":"DIA-SOW"}}],"PIcoPI":["465982",260236,260237],"PO":["565136"]},"96342":{"abstract":"Abstract<br\/><br\/>Title: ITWF Collaborative Research: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science<br\/><br\/>CNS 0420505, PI Kamin, Univ. of Illinois at Urbana-Champaign<br\/>CNS 0420000, PI Califf, Illinois State University<br\/>CNS 0420458, PI Lucht, Heartland Community College<br\/>CNS 0420468, PI Mobasseri, Parkland College<br\/>CNS 0420506, PI Uskov, Bradley University<br\/>CNS 0420321, PI Van Cleave, Eastern Illinois University<br\/><br\/><br\/><br\/>This collaborative ITWF project implements a set of activities designed to increase participation of women and under-represented minorities in undergraduate computer science programs in the state of Illinois. The project includes high school outreach, curriculum reform, mentoring, and other extracurricular activities. It is a collaborative project between the University of Illinois at Urbana-Champaign, Illinois State University, Heartland Community College, Parkland College, Bradley University, and Eastern Illinois University. The project involves building communities among various groups within the state to recruit, support, and retain students in computing courses and programs.<br\/><br\/>The intellectual merit of this project lies in the strong research basis for the intervention models as well as the vertical integration of the models at a range of secondary and post-secondary institutions within the state. The project plan is clear and reasonable with well-defined roles for the partners. The project builds on existing programs and partnerships within the state and includes investigators with significant relevant experience.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science within one state. If successful, the project may provide a sound model for similar broad-based approaches in other states and geographical areas.","title":"Collaborative Research: ITWF: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science","awardID":"0420468","effectiveDate":"2004-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[252627],"PO":["361119"]},"98894":{"abstract":"Radio frequency identification (RFID) is expected to become an important and ubiquitous infrastructure technology. Based on the science and engineering of RFID technology, a new form of space \"Animated Space\" is envisioned to bridge the gap between physical and digital world in which real-world objects can communicate with users in order to convey their purpose, function, and history. Animated Space allows interaction of people in the space and provides timely and additional information which will enhance human activities and help in developing interest and discussion groups by associating information with objects and places. The designed network-based middleware for animated spaces, ASPEN, empowers the network infrastructure to deliver the information stored in the animated space to mobile users. Some of the unique features of ASPEN include: 1) the innovative mechanism for creating smart objects, 2) protocol for interaction with smart objects and smart devices, 3) sharing of information with other users using synchronous and asynchronous peer-to-peer communication, 4) object-oriented component model for content delivery depending upon user and device profile, 5) dynamic and intelligent content adaptation techniques and 6) efficient information storage in various formats, and reading levels and its retrieval. The animated space can lead to potentially very effective type of information evolution that can complement other information models and can reach a wide variety of people across a spectrum of settings. The work will have enormous potential to benefit society in areas such as education (e.g., informal learning, professional and technical learning, and special education such as delivery of content to people with disabilities) and safety (e.g. in emergency relief cases where multiple devices are used and interoperability of these devices would be beneficial).","title":"NeTS: Animated Spaces for the Digital Society: The ASPEN Architecture","awardID":"0434985","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["443993"],"PO":["565090"]},"98300":{"abstract":"The goal of the wireless revolution is to provide ubiquitous tetherless connectivity and access to information.<br\/>The last decade has seen great progress towards this goal with cellular phones and wireless LAN cards<br\/>now being commonplace. In particular, space-time processing, spurred by the use of multiple antenna<br\/>arrays, has emerged as a key enabler of wireless technology. Notwithstanding recent advances in wireless<br\/>communications research and technology, the state-of-the-art is far from realizing the capacity of wireless<br\/>networks because of significant gaps in our fundamental understanding of the shared physical wireless<br\/>channel. The key challenges posed by the wireless channel are due to its dispersive nature in time, frequency<br\/>and space resulting from physical signal propagation over multiple spatially distributed paths. This motivates<br\/>the central questions at the heart of this project:<br\/>What are the key factors that govern reliable communication over dispersive wireless channels?<br\/>What are the fundamental limits on communication over dispersive wireless channels?<br\/>What are the key principles that guide practical system design?<br\/>We will leverage a novel framework based on a virtual representation of physical wireless channels to<br\/>address these multi-faceted questions. The virtual representation is a powerful deconstructing tool for unraveling<br\/>the rich structure underlying dispersive wireless channels. As we demonstrate in this proposal,<br\/>the insights afforded by the virtual representation framework have deep and wide ranging implications in<br\/>the design and analysis of wireless communication systems. Within this framework, our proposed research<br\/>program has three broad integrated thrusts:","title":"Communication over Dispersive Wireless Channels: Theory and Methods Based on Physical Principles","awardID":"0431088","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["223414","531613"],"PO":["564898"]},"97101":{"abstract":"This project, investigating human grasping and manipulation strategies to gain insight into synergies employed by human subjects in grasping and manipulation tasks, aims to explore how best to use these findings to create better control algorithms for robot hands. Of particular importance are techniques to make autonomous robot behavior robust to uncertainties and to make algorithms with a human in the loop, such as teleoperation and control of prosthetic devices, more intuitive and effective for fine manipulation tasks. Although a high degree of freedom (DOF) device may be required to manipulate a wide variety of objects and perform a wide variety of tasks, in any given task situation, only a small number of independently controlled DOF may be necessary. To make significant progress towards dexterous grasping and manipulation, we must: <br\/> Make the best possible use of available sensing technology (specially for force sensing), and<br\/> Understand how to analyze, plan, and control hand motion in a reduced degree of freedom space (take advantage of task-based coordination rules and synergies that may make real time grasp optimization and planning tractable).<br\/>The infrastructure should contribute in answering the following questions:<br\/> What is an optimal grasp, and how does it depend on the kinematic and dynamic properties of the device doing the grasping?<br\/> What is the relationship between critical signals, muscle activation levels, hand shape, and force production during task performance?<br\/> Does analysis of data collected along the pipeline from cortical signals to force production allow easy organization into grasp primitives or result in \"control handles\" that a human operator of a robot hand would find intuitive?<br\/> How can human demonstrations of grasping and manipulation tasks be employed as the wonderful resource they seem to be, i.e., how can individual examples be converted into control algorithms that will function on a robot and be robust to variations and uncertainties?<br\/><br\/>Broader Impact: The results will improve the understanding of human hand motion and force production, the use of force information in teleoperation and control of prosthetic devices, and the ability to coach robot behavior through task demonstration. Teams of undergraduate students will use the facility and data collected will be made available on the web.","title":"RR:Collaborative Research Resources: Learning from Human Hands to Control Dexterous Robot Hands","awardID":"0423546","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["560865","457024"],"PO":["557609"]},"98432":{"abstract":"The establishment of this program, coincident with the creation of a new College of Engineering at the University of North Texas, is resulting in the development of a model curriculum representing a significant change in the manner Electrical Engineering (EE) students are educated. <br\/><br\/>This innovative curriculum is engaging students in enhanced cognitive self-realization in a learning-to-learn (L2L) process integrated with project-oriented industrial experiences at the freshman level, with additional project-oriented courses added each semester. Instructors recruited from nearby industries are helping team-teach the project-oriented courses. Such industry-university collaborations are helping students integrate theory, practice and business sense, ensuring that the engineering curriculum continues to be relevant, competitive, global and directed toward future technological developments. While traditional programs in electrical engineering emphasize modular structures and specialty disciplines, the approach of this project combines insights from cognitive science and learning\/teaching styles with an appreciation of the practical challenges raised by focusing the attention of students on project design issues in a class. Thus, the project is integrating project-based learning and L2L throughout the curriculum. <br\/><br\/>The benefits of this approach include increased student participation in the learning process (active learning and self-learning), enhanced communication skills, adaptation of pedagogies to a wider set of learning styles, and promotion of critical thinking and problem-solving techniques. Major features of the approach include industry-university partnerships, the focus on active learning, the emphasis on team-building, business and entrepreneurship education, lifelong learning and the importance of relevant engineering activities applied to real-world problems.","title":"A Project- and Design-Oriented Innovative Electrical Engineering Program","awardID":"0431818","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1340","name":"ENGINEERING EDUCATION"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"7218","name":"RET SUPPLEMENTS"}}],"PIcoPI":["494074","494074","295407","295407","287808","334005","460836"],"PO":["384581"]},"98201":{"abstract":"Proposal number: 0430510<br\/><br\/>TITLE: Byzantine Replication for Trustworthy Services<br\/><br\/>Principal Investigator: Lorenzo Alvisi<br\/><br\/><br\/>In a world where economics dictates that few components be rigorously tested or verified, methods for building trustworthy systems from untrustworthy components are essential. An attractive approach toward managing the complexity inherent in building trustworthy distributed systems consists in modeling a compromised component as faulty according to the Byzantine failure model---the weakest of all failure models, which allows faulty components to deviate arbitrarily and maliciously from their correct specification. This research explores the feasibility of this approach, both with respect to its fundamental assumptions and to its engineering viability. On the first front, the focus is on (1) the challenge of conjugating fault-tolerance and privacy by developing a firewall with formally verifiable privacy guarantees and (2) the establishment of a solid, quantitative basis for measuring failure independence of replicas against security attacks in Byzantine fault-tolerant architectures. On the second front, the emphasis is on exploring novel ways to implement Byzantine services that provide low latency, high throughput, and can be quickly and unobtrusively reconfigured to improve their performance in response to changes in the environment in which they operate. Addressing these issues successfully will enable a strategy for assembling untrustworthy components to obtain trustworthy systems. More broadly, the proposed research will impact both graduate and undergraduate curriculum at UT Austin and will contribute towards creating a UT Center for Information Security.","title":"Byzantine Replication for Trustworthy Systems","awardID":"0430510","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["466839","466840"],"PO":["521752"]},"87795":{"abstract":"This project will develop user-oriented image management of distribution technologies for digital libraries. An interdisciplinary team of computer and information scientists from US, China, and Taiwan will investigate efficient ways to search digital collections of images using an integrated approach. The US team of researchers consists of faculty members and students of Simmons College, University of Pennsylvania, and The Pennsylvania State University. Several technology areas will be studied: (1) ontology-based image retrieval, (2) machine learning based image retrieval including object-based partial image search, (3) automatic image annotation, and (4) intellectual property (IP) protection techniques. The team will use real-world digital library datasets to develop user-oriented technologies suitable for practical deployment. Notably, the research will utilize an existing collection consisting of a large quantity of images associated with the first Emperor of China of all types of resolution and with enormous cultural significance as well as the existing rich descriptive information.<br\/><br\/>This project will advance understanding of digital imagery management and distribution technologies. It is likely to result in more efficient and effective methods for retrieving images from large collections. It will provide means to decrease labor-intensive activities by providing automatic image annotations. It will enable more willing networking of quality image collections in distributed locations with the access model and IP techniques to be developed by the project. The project has significance for addressing the issue of user-oriented image-related technologies in a general way. The resulting techniques can be applied to other subject contents as well as technology-driven domains, such as computer vision.<br\/><br\/>Among the positive broader impacts will be enhancement of the international infrastructure for digital library research, providing larger-scale universal access to culture and heritages than what is possible now, and expanding the participation of the global digital library research community. This project will also address the national need for scientists by training interdisciplinary graduate students and by offering new interdisciplinary courses for undergraduate students. This international partnership will promote the involvement of small college and minority students in this type of advanced multidisciplinary research.","title":"IDLP: International Collaboration to Advance User-oriented Technologies for Managing and Distributing Images in Digital Libraries","awardID":"0333036","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["230874","426074","503706"],"PO":["563751"]},"98212":{"abstract":"Collection and monitoring of personal and business data will help government agencies detect crime, fraud, terrorism, natural disasters, and other emergencies. On the other hand, government collection and monitoring of massive mounts of data would create tremendous threats to people's privacy and an unnecessary potential for abuse. While low-tech collection of information by government agencies has been an accepted practice, the increased connectivity and transaction speed enabled by the Internet make centralized oversight of various transactional activities both more desirable and potentially more dangerous. For example, banks and individuals were for a long time required to report transactions involving more than $10,000 in cash. After 9\/11, the Patriot Act asked each bank to report more patterns of suspicious activities, including for example series of smaller cash transactions or international transfers adding up to $10,000. However, since Internet banking makes it easier to conduct transactions via multiple financial institutions, what the crime fighters would really like is an ability to collect data from all financial institutions, and moreover, an ability to mine this data at will. Of course, this would be a nightmare to citizens' privacy. Indeed, the availability of all this data at the hands of a government agency is in fact bound to create new threats to the security of the banking system, possibly more serious than the threats the centralized monitoring attempted to solve. And yet, from the standpoint of cryptography, the conflict between the needs for data monitoring and the need for data privacy is not irreconcilable!<br\/><br\/>Our research objective is to create mechanisms that limit the privacy threats posed by the data collection and monitoring applications, while still enabling their efficient operation. We believe that new cryptographic techniques can help resolve the conflicts between the benefits and threats posed by various data collection and monitoring scenarios. Fundamentally, we have no hope of resolving this conflict if the task of monitoring some activity for suspicious patters requires an unconstrained access to all the generated data. However, if the monitoring agency can be restricted in its access to the data, for example it can access only the data that satisfies some pre-defined suspicious patterns, then we can hope to enforce, using cryptographic mechanisms, (1) the correctness of the accessed data, and (2) the secrecy and anonymity of the data that does not meet the searched-for patterns. In other words, if conditions under which the agency should learn the data can be spelled out, then we can design data escrow protocols that allow the agency to do its monitoring work with no more intrusion on citizens' privacy then is absolutely necessary.<br\/><br\/>In the financial monitoring example, the research question is to find an efficient encryption-like escrow scheme with the property that all escrowed transactions remain anonymous and undecipherable by default, except of, for example, transactions which form a pattern of international money transfers originating from the same person and adding up to $10,000.<br\/><br\/>Our approach addresses a general problem of minimizing the threats posed by centralized collection and monitoring of sensitive private data. This is a novel but natural scenario for cryptography. It is also open-ended: Since different monitoring applications have different types of searched-for data patterns, this task will require a variety of approaches which are likely to produce privacy and\/or correctness-enforcing mechanisms useful in other cryptographic applications. Our preliminary investigations identified the link between quite simple privacy-protected data escrow applications and deterministic encryptions, unlinkable signatures on ciphertexts, and fair two-party computation of probabilistic functionalities.<br\/><br\/>This project establishes a new area of research on cryptographic tools and applications. While it's clear that centralized monitoring of various distributed activities might bring societal benefits, our research will help determine under what conditions and in what settings such monitoring can be done in a secure and maximally private manner. This research has a strong potential to impact the technical and political feasibility of data escrow and monitoring, strong PKI infrastructures (e.g. electronic IDs), and fault-tolerant cryptographic services.","title":"Privacy-Protecting Mechanisms for Data Escrow and Transaction Monitoring","awardID":"0430622","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7228","name":"DATA AND APPLICATIONS SECURITY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["357777"],"PO":["355797"]},"98102":{"abstract":"Statistical Techniques for Computer Performance Evaluation<br\/>Abstract<br\/><br\/>The proposed research seeks to investigate mathematical and formal methods for evaluating new computer system architectures. It involves adapting fundamental techniques from existing statistical and mathematical theory to permit the use of simulation-based evaluation in exploratory design. Specific issues to be studied deal with workload compression using sampling, and benchmark synthesis based on workload and parameterized models. <br\/><br\/>Detailed full-system simulation with real-world workloads is the preferred method of performance analysis in the microprocessor and computer system design community today, in preference to analytic modeling or the use of synthetic benchmarks. However, the very large simulation times taken by this methodology prohibits good design space exploration needed for increasingly complex designs. In addition, the project will address the training of computer architecture students in neglected areas of statistical or analytical modeling techniques.","title":"Statistical Techniques for Computer Performance Evaluation","awardID":"0429806","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["556800"],"PO":["550859"]},"98223":{"abstract":"Most logistics problems, ranging from the design of large-scale networks, the management of inventory, the coordination of the supply-chain for a manufacturing enterprise, to the scheduling of production in a chemical processing facility, are NP-hard, and hence, unlikely to have algorithms that are guaranteed to find optimal solutions quickly. Nonetheless, these problems must be tackled in an automated way, and so one tries to design algorithms that produces good solutions, if not optimal ones. In many cases, this is done in an ad hoc way, and one has little assurance that the solutions found are really close to the best one can do. <br\/><br\/>The goal of the theory of algorithms is to study simplified models, so as to extract certain algorithmic paradigms that can then be applied to more realistic settings. By studying theoretical models, one has the aim that the insight needed to prove strong theorems about the quality of the solutions found, translates into algorithmic principles that lead to algorithms that work well on the problems that industry needs to solve.<br\/><br\/>The intellectual merit of this proposal is based on outlining a number of specific logistics problems, focusing primarily on problems from scheduling inventory management and network design, and giving details of specific algorithmic approaches that should lead to improved approximation algorithms: algorithms for which one can prove that the solutions found are guaranteed to deviate from the optimal by a small amount. Specifically, we consider the joint replenishment problem, the one-warehouse, multi-retailer distribution problem, the capacitated facility location problem, the bin-packing problem, the asymmetric traveling salesman problem, and the no-wait flow-shop scheduling problem. <br\/><br\/>Finding good approaches to gain new efficiencies in logistical planning is an issue that is important for the overall US economy, and this is one of the significant broader impacts of this proposal. Furthermore, it is important that the US workforce has sufficient expertise to meet the technological challenges of the coming century. This proposal seeks funds that will aid in the training of doctoral students, in this very important area for the economic competitiveness of the US, who will become the next generation of faculty teaching our college population. Finally, current undergraduate courses need to reflect the current understanding of the basic principles of algorithms in optimizing logistics, so that our graduates, tomorrow's workforce, are prepared to meet the challenges ahead.","title":"Approximation Algorithms for Scheduling, Packing, and Related Logistics Problems","awardID":"0430682","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["562312"],"PO":["499399"]},"98113":{"abstract":"Abstract for proposal 0429901\/0430065<br\/><br\/>Modern technology enables the creation of digital 3D polygon meshes with incredible detail. Current mesh formats, which were designed when models and meshes were orders of magnitude smaller, complicate the processing of large, detailed data. This project will fully develop a new streaming mesh representation, and use it as a framework for algorithms that produce and\/or consume large polygonal and polyhedral meshes. At its core are several simple, new ideas that get around current limitations in computer memory hierarchies. The immediate benefit of compressed storage, faster loading, and better memory use appeal to any application creating large models, including scientific and engineering visualization for data exploration, scanned artifacts for artistic and museum displays, landscape modeling for flood or fire control, mesh generation for scientific computing, virtual environments for collaboration and education, and 3D models for e-commerce. <br\/><br\/>This project identifies the parameters that characterize a streaming mesh, then designs and implements algorithms whose behavior can be analyzed in terms of these parameters. Initial algorithms include surface simplification, compression, and transmission for geometric models for computer graphics, and extend to include 2D and 3D stream-based Delaunay triangulators. The key ideas grew out of work on geometric models in computer graphics; the project's investigators will apply them in more general contexts. The result will be useful software, embodying a computation paradigm that can process arbitrarily large meshes while avoiding geometric artifacts, degradation of quality, and other difficulties of approaches that cut meshes into pieces to fit into available memory. This project will ensure its broader impact though distribution of software (both source code and executables) for streaming and compressing meshes, and stream-based 2D and 3D Delaunay triangulation. The project will impact education of undergraduate and graduate students, and reach out to high school and elementary students through demonstration days. The principle investigators use several means to reach groups that are underrepresented in computer science.","title":"Collaborative Research: Fundamentals and Algorithms for Streaming Meshes","awardID":"0429901","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["554471"],"PO":["532791"]},"98476":{"abstract":"Collaborative Research: Intrinsically Motivated Learning in Artificial Agents<br\/><br\/>Project Summary<br\/><br\/>Humans are unendingly curious; we spontaneously explore and manipulate our surroundings to see what we can make them do; we obtain enjoyment from making discoveries and for making things happen. We often engage in these activities for their own sakes rather than as steps toward solving practical problems. Psychologists call these intrinsically motivated behaviors because rewards are intrinsic in these activities instead of being due to the satisfaction of more primary biological needs. But what we learn during intrinsically motivated behavior is essential for our development as competent autonomous entities able to efficiently solve a wide range of practical problems as they arise. This project's objective is to develop a computational model of intrinsically motivated learning that will allow artificial agents to construct and extend hierarchies of reusable skills that are needed for competent autonomy. This project builds on existing <br\/>research in machine learning, recent advances in the neuroscience of brain reward systems, and classical and contemporary psychological theories of motivation. At the core of the model are recent theoretical and algorithmic advances in computational reinforcement learning, specifically, new concepts related to skills and new learning algorithms for learning with skill hierarchies. The project develops a mathematical framework, implements the model in a series of simulated agents, and demonstrates the advances this will make possible in a series of increasingly complex environments.<br\/>Intellectual Merit-Machine learning methods have become much more powerful in recent years. Despite these advances and their utility, today's learning algorithms fall far short of the possibilities for machine learning. They are typically applied to single, isolated problems for each of which they have to be hand-tuned and for which training data sets have to be carefully prepared. They do not have the generative capacity required to significantly extend their abilities beyond initially built-in representations. They do not address many of the reasons that learning is so useful in allowing animals to cope with new problems as they arise over extended periods of time. Success in this project will provide a fundamental advance in machine learning and move the field in a new direction. Although computational study related to intrinsic motivation is not entirely new, it is currently underdeveloped and does not take advantage of the highly relevant recent advances in the field of computational reinforcement learning and in the neuroscience of brain reward and motivation systems. Furthermore, computational studies do not take advantage of psychological theories of play, curiosity, surprise, and other factors involved in intrinsically motivated learning. This project addresses these shortcoming by taking an explicitly interdisciplinary approach.<br\/>Broader Impacts-The new methods promise to improve our ability to control the behavior of complex systems in ways that will benefit society. Machine learning algorithms have been instrumental in a wide variety of applications in such areas as bioinformatics, manufacturing, communications, robotics, and security systems. It is important strategically, economically, and intellectually to increase the power of machine learning technologies as rapidly as possible. This project attempts to address some of these challenges. This project will strengthen interdisciplinary ties between the machine learning community of computer science and various disciplines devoted to the study of human cognitive development and education. The specific methods of concern in the proposed research have not yet been integrated. There has been very<br\/>little cross-fertilization between the psychological study of intrinsic motivation and machine learning. The proposed research will remedy this situation, thereby helping to create an avenue of communication that can foster future developments in both fields. The project has the potential to contribute to our understanding of general principles underlying human cognitive development, with implications for education, where enhancing intrinsic motivation is a key factor.<br\/>The educational component of the project focuses on graduate education through its training of graduate students. This includes the offering interdisciplinary graduate-level seminars at both U. of Massachusetts and U. of Michigan, to be taught by the PIs on the topic of intrinsically motivated learning. In its recruitment of graduate students, the project will take advantage of the role that U. Massachusetts plays as the lead institution in the NSF funded Northeast Alliance, which supports and mentors underrepresented minority students interested in academic careers in a science, mathematics, or engineering discipline. At U. of Michigan special effort w","title":"Collaborative Research: Intrinsically Motivated Learning in Artificial Agents","awardID":"0432027","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}}],"PIcoPI":["550371"],"PO":["565223"]},"98245":{"abstract":"Synthetic aperture radar (SAR), geophysical and seismic imaging, ultrasound imaging, optical coherence tomography (OCT), and many forms of astronomical imaging are examples of coherent imaging systems. In practice, the acquired phase data are noisy due to imprecise knowledge of the motion of the sensor, or due to the properties of the medium. As a consequence, the produced imagery is improperly focused. Existing techniques for correcting the imagery, referred to as autofocus, are ill-equipped to handle the challenges of modern high-resolution systems. The availability of well-focused ultra-high-resolution SAR imagery is crucial for antiterrorism efforts. Improved focusing may also lead to breakthroughs in medical imaging, such as ultrasound imaging of the human breast.<br\/><br\/>The investigators develop a new generation of autofocus algorithms that will enable improved focusing in a variety of coherent imaging modalities. Primarily, the SAR autofocus problem is considered because of its national importance in all-weather surveillance, and also because the SAR field is highly developed. The research will focus on the following approaches: (i) optimization strategies that optimize image sharpness metrics, (ii) multiresolution vector space methods that exploit the structure of the phase error, and (iii) multichannel blind deconvolution techniques that exploit the redundancy of the blurring operation on each row of the image. These approaches motivate the development of a unified framework, in which all of the available assumptions are used in a robust restoration procedure. The implementation of the methodology in practical SAR systems will be emphasized. Finally, the developed autofocus methodology will be extended and applied to ultrasound, OCT, and passive radar imaging.","title":"Collaborative Research: A Modern Autofocus Methodology with Applications to Radar Imaging","awardID":"0430780","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":[258712],"PO":["564898"]},"98487":{"abstract":"The extensive interactivity among genes that is now being revealed suggests that there is considerable flexibility in the genome's capacity for responding effectively to diverse conditions. In a model gene network, centering on a temperature-sensitive mutation in the Syntaxin1A gene affecting synaptic transmission in Drosophila, a high degree of flexibility has been observed and the interactions underlying the various states of the network will now be analyzed. The phenotypic space of the network's functionality will be explored and the patterns of gene expression associated with various different genotypes and system outputs assayed. Functional clustering analysis, a measure based on the mutual information in the system, will be applied to these data to construct testable models and predictions of gene interaction. The outcome of this research offers possibilities for new kinds of network strategies and architectures.<br\/> The overall goal of the work is to test the idea that gene networks operate by the same fundamental principles as neuronal networks, of which degeneracy is one of the key characteristics. The gene network surrounding Syntaxin will be analyzed by synthesizing various allele combinations, dividing them into groups with quantitatively similar phenotypes, and comparing the gene expression patterns within and between groups. A particular focus will be those genotypes that produce similar scores, as a window into the various network configurations that are capable of producing similar outputs (i.e., system degeneracy). From this analysis, models will be generated and predictions made of which (and how many) gene combinations stabilize the phenotype, and these will be tested by constructing and analyzing further mutant combinations.<br\/><br\/> Aim 1: Perform bi-directional selection on a population of flies in which all of these alleles (Syx1A3-69and EPs) are randomly segregating to derive strains with extreme sensitivity or resistance to paralysis. <br\/><br\/> Aim 2: Perform array analyses on a subset of phenotypic groups of genotypes from EP and Df analyses, as well as on the selected and control strains.<br\/><br\/> Aim 3: Apply functional clustering based on phenotype and array results, and make predictions on phenotypes of novel combinations. Test novel combinations phenotypically, and molecularly. <br\/><br\/>Gene networks are likely to share common organizational and operational principles with neuronal networks, and with biological networks in general, despite their very different modes and kinetics of internal communication and connection. This proposal addresses the issue directly, by taking a representative gene network and analyzing it with tools developed and validated for neuronal networks. <br\/>The experiments outlined above constitute a new approach to the question of whether there are fundamental underlying principles of biological network operation which, if discerned, would have wide-ranging implications for the design and implementation of artifical networks constructed for applications as diverse as computing, engineered adaptive devices, and communications.","title":"CompBio: Gene Interactions as a Model for Network Architectures","awardID":"0432063","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}}],"PIcoPI":["515695","487370"],"PO":["565223"]},"98135":{"abstract":"Proposal Number: 0430026<br\/>TITLE: Better Science Through Benchmarking: Theory Validation and <br\/>Application to Software Engineering<br\/>PI: Susan Elliott Sim<br\/><br\/>The research seeks to refine a preliminary theory of benchmarking and use the theory to guide development of benchmarks for research results in software engineering. Benchmarks have been used in elsewhere in <br\/>computer science to compare the performance of computer systems, information retrieval algorithms, databases, and many other technologies. The creation and widespread use of a benchmark within a <br\/>research area is frequently accompanied by rapid technical progress and community building. According to the theory of benchmarking, these effects appear because a benchmark is closely tied to the discipline's <br\/>scientific paradigm (as described by Thomas Kuhn.) Both benchmarks and paradigms emerge through a consensus on technical results and cultural expectations for conduct. Based on a successful preliminary study <br\/>applying this theory to reverse engineering, this research develops additional benchmarks in software engineering and collect data to validate the theory. This work will have benefits for the field through <br\/>the specific benchmarks being developed, empirical evaluation of research results, and an improved understanding of how research is conducted. In terms of broader impact, the benchmarks enable <br\/>geographically under-represented groups to participate in top tier research, because they can be downloaded from a web site and completed in reasonable time.","title":"Better Science Through Benchmarking: Theory Validation and Application to Software Engineering","awardID":"0430026","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["457014"],"PO":["564388"]},"98146":{"abstract":"Abstract<br\/>0430102<br\/>Stanford University<br\/><br\/>The objective of this project is to develop a unified theory of event correlation. Event correlation is a very powerful technique in publish-subscribe systems, an increasingly popular architectural design choice for embedded systems. Event correlation allows components to subscribe with the middleware with complex temporal patterns of events rather than with single events as in event filtering. This has several advantages: it improves performance by reducing network traffic and unnecessary component activations and by<br\/>enabling more accurate component scheduling; it simplifies system development by transferring functionality from components to a standard service in the middleware; and finally, it increases analyzability by making component dependencies explicit, and hence can make systems more reliable. Despite these advantages event<br\/>correlation is hardly being used. The reason is that system developers do not trust existing implementations: theoretical foundations that guarantee that all relevant events are indeed delivered are lacking.<br\/><br\/>The investigators are developing a theoretical framework for event correlation that addresses the following fundamental problems: <br\/>* the expressiveness of different event correlation languages and the relations among their operational models; <br\/>* the datatypes and algorithms for their run-time evaluation; <br\/>* the complexity of associated algorithmic analysis problems; <br\/>* the development of formal testing and verification tools.<br\/><br\/>This research is a new direction in the application of formal methods. Its starting point was the development of an event-correlation language by the investigators for the Boeing Bold Stroke platform under the DARPA PCES program. The current project develops the theoretical foundations for that language, and extends it<br\/>with memory and real-time facilities to accommodate more sophisticated event forwarding strategies and systems with real-time constraints. Efficient analysis algorithms, based on automata theory,<br\/>are being developed to enable system verification and optimization. These languages, models, and algorithms are evaluated on actual complex embedded systems.<br\/><br\/>The results of this research will benefit embedded systems development at many levels: <br\/>* a formal semantics will give system developers the confidence to use complex correlation patterns, which provides a concise and easily comprehensible way to express event dependencies;<br\/>* a hierarchy of operational models will allow compilers to generate efficient implementations, appropriately choosing the best space\/time\/parallelism tradeoffs according to the target platform; <br\/>* solutions to the underlying decision problems will lead to the development of practical reasoning tools, such as compilers implementing complex optimizations of correlators, static analysis tools, and run-time monitors.","title":"Foundations of Event Correlation","awardID":"0430102","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["309451"],"PO":["564388"]},"98267":{"abstract":"This research involves the development, installation, and <br\/>verification of a collection of error control codes that <br\/>are employed across base stations to vastly improve the <br\/>performance of public safety radio systems (i.e. those <br\/>used by police officers and firefighters). In particular, <br\/>recent events have demonstrated the stringent demands placed <br\/>on public safety radio systems in times of extreme crisis. <br\/>Such systems must handle high-priority delay-sensitive voice <br\/>transmissions that often need to be broadcast to a large number <br\/>of receivers over the challenging wireless communications channel. <br\/>The wireless channel can introduce significant signal fading, and <br\/>the narrowband frequency allocations and current collection of <br\/>single-antenna base stations in public safety radio systems <br\/>make it difficult to combat the effects of such fading using <br\/>previously considered techniques. Employing a single error <br\/>control code across multiple base stations can improve the <br\/>broadcast to a group of system users in the area, but there <br\/>are a number of technical barriers to such an approach. <br\/><br\/>The fundamental problem is that, because of the large geographical <br\/>area covered by the transmitting base stations, the relative time <br\/>of arrival at the receiver of signals from different base stations <br\/>can vary greatly, and, since the application is partial broadcast, <br\/>no amount of relative transmission timing can remedy such. The <br\/>research team has demonstrated that many standard space-time <br\/>schemes lose diversity versus signal fading in such a situation; <br\/>however, the team is developing families of codes that are robust <br\/>to this offset, thus preserving diversity against fading across the <br\/>coverage area. These codes are termed \"macroscopic space-time <br\/>codes,\" which, in addition to being developed, are being verified <br\/>on the OpenSky testbed of partner M\/A-COM, Inc.","title":"Macroscopic Space-Time Codes for Homeland Security","awardID":"0430892","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":[258765,"545656"],"PO":["348215"]},"99246":{"abstract":"ALSM represents a major new stage in a research program in Logistical Computing and Internetworking, (LoCI), for distributed state management. The IP model is too limited for distributed computing because it does not include the possibility of managing application state between end systems (i.e. at intermediate nodes). The unique contribution of the LoCI approach is that it not only models this possibility, it does so without sacrificing the scalability essential to networking.<br\/><br\/>While not viewing the IP model as sufficient for distributed systems, the project's strategy is to reapply the end-to-end design principles that underlie that model to storage and processor resources. The first target was storage. Following the end-to-end paradigm, the PIs created the Internet Backplane Protocol (IBP), which is a primitive mechanism for managing distributed storage. With IBP-based intermediate nodes, called depots, the network itself can be infused with storage resources that can be shared, scaled up, and exposed for external scheduling, much like IP service is. A testbed provisioned with more than 22TB of storage, spread among 250 depots in 20 countries has been deployed, and a variety of application groups are currently using the testbed to explore the technology.<br\/><br\/>Following the LoCI design philosophy, ALSM.s guiding hypothesis is this: If, by adhering to end-to-end principles, a generic, best effort computing service can be integrated into ascalable logistical network, then a programmable network resource fabric can be created that is capable of providing the kind of active state management that grid applications require.<br\/><br\/>The work will encompass the following main activities:<br\/><br\/>o Design Active Depots and ALSM middleware: will optimize active depot architecture to efficiently support data transformation; middleware will be created to map a high level network view onto the weak semantics of IBP and the NFU, using sophisticated end-to-end techniques to generate reliability, performance, etc.<br\/>o Enable GridSolve-L application environment: NetSolve will be adapted to use ALSM middleware so that NetSolve applications can issue logistical directives to exploit data locality patterns and offload state processing to active depots in the ALSM infrastructure. The result of this integration is GridSolve-L.<br\/>o Validate ALSM in a grid visualization application: We will investigate the use of ALSM to implement a remote visualization pipeline, using a real-world medical imaging application under GridSolve-L; operations will separate as appropriate onto active depots for state management and GridSolve-L for major computation.","title":"Active Logistical State Management for Distributed and Grid Application Environments","awardID":"0437508","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["558550","530745","450864","513541"],"PO":["551712"]},"98036":{"abstract":"Dramatic increases in computing power and storage capacity have allowed scientists and engineers to model nature in more detail than ever. However, such models often require massive input and output datasets, and the size of these datasets is outpacing our ability to manipulate and use them. In response, the project is developing a novel approach (Computational Database Systems) for exploring and understanding massive scientific datasets. The basic idea is to integrate scientific datasets stored as spatial databases with specialized, tightly-coupled, and highly-optimized functions that query and manipulate these databases. In particular, the project is developing computational database systems for building and querying the massive datasets produced by unstructured finite element simulations. The project expects to make the following major contributions that span scientific computing, database systems, and storage systems: (1) New algorithms for balancing linear octrees based on new techniques known as \"balance by parts\" and \"prioritized ripple propagation\". (2) Efficient new sorting-based techniques for extracting mesh structure from linear octrees. (3) Minimizing output data volume through compression of \"near zero\" simulation outputs. (4) New techniques for indexing compressed spatio-temporal datasets. (5) Storage management techniques that automatically determine the best layout for data at each level of the system's memory hierarchy.","title":"Computational Database Systems for Massive Scientific Datasets","awardID":"0429334","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["342331","358529","486331"],"PO":["565136"]},"98157":{"abstract":"Privacy is increasingly a major concern that prevents the exploitation of the Internet's full potential. Consumers are concerned about the trustworthiness of the websites to which they entrust their sensitive information. Although significant industry efforts are seeking to better protect sensitive information online, existing solutions are still fragmented and far from satisfactory. Specifically, existing languages for specifying privacy policies lack a formal and unambiguous semantics, are limited in expressive power and lack enforcement as well as auditing support. Moreover, existing privacy management tools aimed at increasing end-users' control over their privacy are limited in capability or difficult to use.<br\/>This project seeks to provide a comprehensive framework for protecting online privacy, covering the entire privacy policy life cycle. This cycle includes enterprise policy creation, enforcement, analysis and auditing, as well as end user agent presentation and privacy policy processing. The project integrates privacy-relevant human, legal and economic perspectives in the proposed framework. This project will develop an expressive, semantics-based formal language for specifying privacy policies, an access control and auditing language for enforcing privacy policies in applications, as well as theory and tools for verifying privacy policies. Additionally, experiments and surveys will be conducted to better understand the axes of users' privacy concerns and protection objectives. Results from this empirical work will be used to develop an effective paradigm for specifying privacy preferences and methods to present privacy policies to end users in an accurate and accessible way.","title":"Collaborative Research: A Comprehensive Policy-Driven Framework for Online Privacy Protection: Integrating IT, Human, Legal and Economic Perspectives","awardID":"0430166","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["517936","548078"],"PO":["565136"]},"98278":{"abstract":"Despite the recent dramatic growth of computational capability, our ability to model complex, 3D groundwater systems is still severely limited because of a number of tough computational and conceptual challenges including: the machine bottleneck; the algorithmic bottleneck; and the data assimilation problem. This research addresses systematically these fundamental difficulties in large-scale groundwater modeling using an interdisciplinary approach. In particular, the research takes advantage of hierarchy theory and develops: a hierarchical and patch dynamic framework for modeling complex groundwater systems across multiple scales; and a new modeling paradigm that resolves a significant computer science problem - a barrier to the practical implementation of hierarchical modeling. Specifically, the new, IT-enabled, and hierarchical patch dynamic framework will: (a) allow modeling complex groundwater systems without having to solve large, ill-conditioned matrix systems and thus eliminate or substantially alleviate the infamous \"curse of dimensionality\" and the associated computational bottlenecks in 3D groundwater modeling; (b) provide a systematic \"scaling ladder\" to link data and models across multiple scales and assimilate information from disparate sources; and (c) provide on the fly integration of hierarchical computations and visualizations, free users from having to interact with each subscale modeling patches, and eliminate the associated human bottlenecks. <br\/><br\/>The proposed hierarchical modeling environment may potentially change the way computational modeling is done in groundwater hydrology and substantially improve our ability to understand subsurface systems, processes, and scale interactions and to develop model-based tools for integrated water resources management and environmental cleanup.","title":"SEI+II (GEO): An IT-Enabled, Hierarchical and Patch Dynamic Environment for Modeling Complex, 3D Groundwater Systems Across Multiple Spatial Scales","awardID":"0430987","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["284315","541933","559170"],"PO":["565136"]},"98047":{"abstract":"This award will support a partnership among the University of California San Diego, the State of California Governor's Office of Emergency Services (OES), and the Public Safety Network (PSN) company. The goal is to perform spatiotemporal analysis of 9-1-1 call stream data and correlate these data to external events, in order to provide more effective and efficient response during emergencies. A wide variety of existing and emerging data sources are of potential value in helping the OES determine the location and magnitude of incipient disasters, and timely access to these data is critical for OES to manage State-level resources and to assist local governments in providing aid to disaster victims. PSN has been contracted by California to collect 9-1-1 call stream data across the State. PSN collects data from several hundred distinct Public Safety Answering Points (PSAP's) for about 60-80,000 emergency calls per day. Researchers from UC San Diego's San Diego Supercomputer Center and Scripps Institution of Oceanography will work with PSN and OES to provide expertise in advanced data management, data analysis, data mining, and statistical techniques, with the objective of performing spatiotemporal analysis of 9-1-1 emergency call stream data across the State of California and correlating these data with external information, such as earthquakes and fires.<br\/><br\/>PSN will provide an archival dataset of 9-1-1 call stream data for the 4-year period preceding the start of the project. The analysis will include correlation of this information with external event information, such as earthquakes and wildfires, to determine spatiotemporal signature of such events. This information will then be used to establish alarm thresholds to provide advance warning to first responders and other emergency service personnel, concerning the spatial extent and temporal evolution of an emergency event. The long-term<br\/>goal is also to enable the use of this information for real-time detection of emergency events in order to provide rapid response at the local level and facilitate decision support for resource allocation and planning at the State level.<br\/><br\/>Intellectual Merit - Analysis of 9-1-1 call stream data will provide a better understanding of the spatiotemporal patterns of emergency calls and their correlation to external events. Predictive models built with this data can lead to real-time decision support and better overall planning to enable more efficient and effective response to emergencies. While 9-1-1 data is currently being collected across the nation, it is being used primarily for administrative purposes, not for real-time assessment and prediction of emergency response situations. This project will provide that linkage between the data and the spatiotemporal analysis techniques required to mine the data and develop predictive models. <br\/><br\/>Impact - The project will involve first responders and emergency services personnel from State and<br\/>local agencies, as well as representative personnel from border law enforcement information agencies,<br\/>e.g. the Automated Regional Justice Information Systems (ARJIS), San Diego. Although the focus of this<br\/>project is on California, PSN also has access to 9-1-1 call stream data across much of the U.S. Indeed, the<br\/>methodologies developed in this research will be applicable immediately to other states and regions.","title":"Spatiotemporal Analysis of 9-1-1 Call Stream Data","awardID":"0429448","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["559496",258204,"518814"],"PO":["371077"]},"98168":{"abstract":"Collaborative Research: DefCOM - Distributed Defense against DDoS<br\/> <br\/>Jelena Mirkovic, University of Delaware<br\/>Peter Reiher, UCLA<br\/><br\/>Award 0430228<br\/><br\/>Abstract<br\/><br\/>This project investigates a distributed cooperative solution to the problem of distributed denial-of-service attacks. The proposed defense system, DefCOM, combines the advantages of victim-end defenses (accurate attack detection) and source-end defenses (efficient response and precise separation of the legitimate traffic from the attack traffic). It also enlists the help of backbone routers to control attack traffic in partial deployment scenarios where many potential sources do not deploy a source-end defense.<br\/><br\/>DefCOM nodes will be deployed in source, victim and core networks, and will cooperate via an overlay to detect and stop attacks. Overlay communication will ensure effective operation even if DefCOM nodes are sparsely and non-contiguously deployed. DefCOM's response to attacks is twofold: defense nodes reduce the attack traffic, freeing the victim's resources; and they also cooperate to detect legitimate traffic within the suspicious stream and ensure its correct delivery to the victim. Because networks deploying defense nodes directly benefit from their operation, DefCOM has a workable economic model to spur its deployment. DefCOM further offers a framework for existing security systems to join the overlay and cooperate in the defense. These features create excellent motivation for wide deployment, and the possibility of a large impact on the DDoS threat.","title":"Collaborative Research: DefCOM - Distributed Defense against DDoS Attacks","awardID":"0430228","effectiveDate":"2004-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["451563","550312"],"PO":["529429"]},"98289":{"abstract":"In 1960, Jane Goodall began the first long-term field study of the closest living relatives of humans, chimpanzees (Pan troglodytes), in Gombe National Park, Tanzania to describe their behavior by making extensive observations in their natural habitat. This study, which continues today, has made many contributions to understand chimpanzee behavior and human evolution, and has also inspired people around the world to study science and work toward wildlife conservation. Analysis of the complete observational dataset from Gombe and other field studies, such as the Kanyawara chimpanzee project, has the potential of providing new insights into many unanswered behavioral ecology questions, e.g. the influence of social relationships within the group on territorial behavior.<br\/><br\/>However, this observational paradigm is extremely labor-intensive and only a small part of the Gombe dataset has been analyzed so far. The goal of this project is to begin developing data analysis tools and techniques to reduce the time and effort required to analyze observation datasets. Expected results include a cartridge for mining concept patterns, a computationally efficient execution environment for concept pattern mining, and spatial semi-supervised learning algorithms to improve classification performance in creating maps. Expected results will not only benefit behavioral ecologists, but also contribute to research in many other spatio-temporal application domains, including location based services, transportation and epidemiology. Dissemination plans include development of instructional tools based on the Gombe data to motivate younger students to learn science and information technology as well as a workshop to increase collaboration between Computer Scientists and Behavioral Ecologists.","title":"Collaborative Research: SEI: Spatio-temporal Data Analysis Techniques for Behavioural Ecology","awardID":"0431044","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["436891"],"PO":["565136"]},"87168":{"abstract":"This research project is concerned with the problem of efficient, interactive and approximate similarity search in high-dimensional data sets. Large repositories of high dimensional data are central to a vast array of disciplines and applications, and the degree to which they can be exploited depends critically on the availability of efficient and smart tools for search and retrieval, analysis, and mining. The methodology involves approaches whose origins lie in several disciplines beside classical data management, including optimization, information theory, pattern recognition and signal compression. One line of attack hinges on the concept of approximate (rather than exact nearest neighbor) search which enables explicit search complexity-accuracy tradeoff analysis and includes: (a) the derivation of new accuracy criteria for effective tradeoff calculation; and (b) joint optimization techniques to design combined clustering and compression in the feature space as a framework for direct optimization of the search complexity-accuracy tradeoff. A second line of attack is concerned with interactive search involving relevance feedback from the users. It develops reduced complexity search techniques for relevance feedback mechanisms. The final phase of the project merges the two main thrusts to develop an efficient interactive approximate search system that optimizes the complexity-accuracy tradeoff. The project is inherently interdisciplinary and the advances made in it are expected to impact numerous disciplines where high-dimensional databases are of importance, as well as various areas of human endeavor -- scientific, medical, social, arts, entertainment, security, and more. The project Web site (http:\/\/www.scl.ece.ucsb.edu\/html\/prmdb_1.htm) is be used to provide access to the project's results.","title":"Fast Approximate Search and Retrieval of High-Dimensional Data","awardID":"0329267","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["550914","426604"],"PO":["563751"]},"95441":{"abstract":"Approximately one in ten blind persons are confined to wheelchairs, and independent travel is currently next to impossible for this population. Conventional blind wayfinding techniques - cane or guide dog - become extremely difficult or impractical in a wheelchair, requiring great physical dexterity and coordination. The traveler's loss of direct contact with the ground also removes vital feedback. It is easy to miss hazards such as obstacles and drop-offs ahead of or alongside the chair. While some technologies have been developed to aid in wheelchair navigation, they are either restricted to controlled environments or detect only a limited range of obstacles very close to the chair. As a result, independent travel is so difficult that few attempt it, resulting in a widespread lack of awareness of this severely disadvantaged population. The PI's long-term goal is to make independent travel feasible for blind wheelchair users. In this project, he will tackle the problem of sensing terrain features that are relevant to wayfinding in a wheelchair using computer vision technology. Computer vision algorithms for interpreting visual scenes will be developed to infer important visual information, in real time, about nearby terrain, obtained from images collected by cameras mounted to the wheelchair. This information will include the detection of hazards such as obstacles and drop-offs ahead of or alongside the chair, as well as detecting veer, finding curb cuts, finding a clear path, and maintaining a straight course. It will be communicated to the traveler using synthesized speech, audible tones and\/or tactile feedback, and is meant to augment rather than replace the information from existing wayfinding skills. The traveler will use this information to control the wheelchair himself\/herself (rather than relying on robotic control of the chair). The outcome will be a prototype system that helps prevent veering off the sidewalk by performing the following functions: detect and locate drop-offs and other obstacles; detect and locate curbs and curb cuts; and detect and locate the shoreline (i.e., edge of the sidewalk bordering grass or other terrain, or adjoining a wall), as well as sideslopes.<br\/><br\/>Broader Impact: Beyond the tremendous benefits that the technology resulting from this research may impart to the population of blind wheelchair users, the research will also advance the understanding of computer vision algorithms applied to terrain analysis and interpretation. The unique research environment at Smith-Kettlewell will draw upon the expertise of in-house blind engineers (one of whom is a post-doctoral fellow), who will assist in the design and assessment of the proposed system. In addition, the study will provide an opportunity for minorities and blind persons to gain exposure to science while participating in the gathering of data as research subjects. Finally, the results of the research will be disseminated in several public forums, including demonstrations of the system at local high schools and at the Exploratorium Science Museum of San Francisco.","title":"Computer Vision-Based Terrain Sensors for Blind Wheelchair Users","awardID":"0415310","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":[250277],"PO":["565227"]},"98961":{"abstract":"Traditional wireless cellular networks support voice or other constant-bit-rate connections. Under these conditions, fixed bandwidth allocation schemes have been successfully used to multiplex multiple users in the same cell while providing protection from multi-user interference. However, future wireless networks will need to accommodate multimedia sources that are bursty in nature and generate variable-bit-rate traffic. The goal of this project is to develop ALLIANCES (ALLow Improved Access in the Network via Cooperation and Energy Savings), a high-throughput medium access scheme for wireless networks that is suitable for bursty sources. <br\/><br\/>The wireless network is viewed as a spatially distributed antenna, with antenna elements linked via the unreliable wireless channel. When there is a collision, the packets involved in the collision are saved in a buffer. In the slots following the collision, a set of nodes, designated as relays, form an alliance and bounce off the signal that they received during the collision slot. By processing the originally collided packets and the signals forwarded by the relays, the destination node can recover the original packets. The spatial diversity introduced via the cooperative relaying enables one to effectively deal with the wireless channel without any bandwidth expansion or additional antenna hardware. ALLIANCES maintains the benefits of ALOHA systems in the sense that all nodes share access to media resources efficiently and without extra scheduling overhead, and enables efficient use of network power. Due to the importance of wireless communication in today's society, any improvement in throughput and energy savings is a worthwhile endeavor.","title":"NeTS-NR: ALLow Improved Access in the Network via Cooperation and Energy Savings (ALLIANCES)","awardID":"0435376","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["546219"],"PO":["434241"]},"95210":{"abstract":"WordNet is an important lexical resource for research in areas including NLP and AI. This project initiates the development of a radically enhanced version of WordNet. Constructing WordNet+ involves a novel combination of empirical methods: human annotation, corpus analysis, and machine learning. WordNet+ specifically addresses some of WordNet's limited ability to identify word senses, stemming from the sparsity of Boolean arcs among sets of synonymous words (\"synsets\"). First, quantified, oriented arcs are to be added among a core set of 5,000 synsets. These arcs reflect evocation--the extent to which the meaning of one synset brings to mind another. Following the selection of the core synsets, a random subset of 250,000 arcs are to be elicited from annotators. The annotators, trained and tested for inter- and intra-reliability, record the strength of their mental associations using a specially designed and tested interface. The remaining arcs are to be extrapolated from the manually obtained arcs using machine learning algorithms.<br\/><br\/>All results will be made available to the research community: the core concepts, the indirect co-occurrence matrices, and all available ratings. Given WordNet's past contributions to a number of diverse disciplines, the initial stages of the construction of this research tool should stimulate great interest and have a significant impact on related work.","title":"Constructing an Enhanced Version of WordNet","awardID":"0414072","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["542007","450503",249657,"511536"],"PO":["565215"]},"96310":{"abstract":"ABSTRACT<br\/>ITWF Program - FY04<br\/><br\/>CNS 0420365, PI's Donald Davis, Debra Major, Janis Sanchez-Hucles, Old Dominion U.<br\/>Title: Creating an Inclusive Learning Environment: Enhancing Retention of Women and Minorities in Computer Science<br\/><br\/>Collaborative Projects:<br\/>CNS 0420365, PI's Donald Davis, Debra Major, Janis Sanchez-Hucles, Old Dominion U.<br\/>CNS 0420371, PI Sandra DeLoatch, Norfolk State U.<br\/><br\/>Old Dominion University and Norfolk State University have been awarded an ITWF grant to conduct a collaborative four-year implementation project designed to create an inclusive learning environment in computer science (CS) and thereby increase retention of women and minority undergraduate students. The two institutions will create an inclusive learning environment through (a) strengthening faculty-student and student-peer relationships using collaborative and multicultural teaching and learning practices and (b) strengthening student self-efficacy, optimism, career management, and collaboration and coping skills. All beginning CS students will participate in a required, semester-long class that presents a realistic preview of the challenges of being a computer science major, techniques and skills for coping with such challenges, training in attitudes and beliefs that foster persistence, and use of role models to describe the career rewards that are possible in computer science. Faculty will be trained in \"wise schooling\" techniques to foster inclusiveness. Faculty will also include pair programming and collaborative learning in programming classes.","title":"Collaborative Research: ITWF - Creating an Inclusive Learning Environment: Enhancing Retention of Women and Minorities in Computer Science","awardID":"0420365","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"1397","name":"CROSS-DIRECTORATE  ACTIV PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["553186",252524,"523782"],"PO":["361119"]},"98862":{"abstract":"NeTS-ProWIN: Viral Radio<br\/><br\/>Andrew Lippman, MIT<br\/><br\/>Award 0434816<br\/><br\/>Abstract<br\/><br\/>This project is the initial stage of research intended to explore the feasibility of an approach to wireless networking called Viral Radio by assembling and evaluating a research prototype system with a small number of software-controlled radio nodes. The premise of Viral Radio is that it is possible to make energy- and spectrum-efficient radio communications networks that scale (almost) without bound. An adaptive distributed set of nodes treats RF signal relaying in a given space as a distributed optimization process whereby each radio uses the presence of other radios to assist and cooperate in messages delivery. Relaying is done without demodulation or buffering; thus eliminating delays normally associated with multi-hop ad hoc networks. A distributed routing algorithm controls the relays, and the ultimate destination nodes use the combination of original signal and relayed signals, plus the variability of propagation between source and destination to allocate signal energy in space to maximize throughput while minimizing interference between concurrent messages. This research path eventually leads to highly scalable and highly efficient real-time telecommunications and broadcast systems that rely on no central radiator or suite of cell towers. By showing how spectrum capacity can be increased by the presence of other, cooperating elements, Viral Radio suggests a new paradigm for spectrum management that allows the most communicating elements in a region without mutual interference rather than the least. This research can add additional practical weight to this argument, and can be used by those who are weighing new policy alternatives.","title":"NeTS-ProWIN: Viral Radio","awardID":"0434816","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[260549,"546254"],"PO":["7594"]},"98983":{"abstract":"Abstract: <br\/><br\/>Sensor networks are today being deployed in scientific applications in fields and buildings, but their use underwater has been quite limited. Undersea sensor networks are either based on expensive wired devices or a small number of relatively large nodes with long-range acoustic communications. The Sensor Networks For Undersea Seismic Experimentation (SNUSE) project is developing fundamental tools to support small, low-cost, wireless undersea sensor nodes. With laboratory and testbed experimentation and simulation, the project investigates:<br\/><br\/>- Hardware for small, low-power, moderate-range acoustic telemetry for underwater sensor nodes;<br\/>- Time synchronization, localization, and energy-efficient MAC protocols for environments with high-delay, acoustic communication;<br\/>- Applications protocols for ultra-low duty cycle operation, including long-duration sleep and wakeup and efficient application-level data caching and forwarding.<br\/><br\/>This work is directly applicable to applications in undersea sensing, including contaminant and pollution monitoring undersea micro- and macro-organism -life tracking, and seismic monitoring of undersea oil fields. Although focused on undersea applications, a large portion of the research is also applicable to traditional sensor networks. <br\/><br\/>This work supports undergraduate and graduate research at USC, both directly and through sensor networking laboratory classes and the developing CiSoft Masters Degree in Smart Oil-field technology. The results of this work will be disseminated via technical papers, freely available hardware designs and software on the project web site.","title":"NeTS-NOSS: Sensor Networks for Undersea Seismic Experimentation (SNUSE)","awardID":"0435517","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["377594","376299"],"PO":["564777"]},"97773":{"abstract":"ABSTRACT<br\/><br\/>ITR: Collaborative Research (NHS + ASE) (int + dmc):<br\/>Networks of Robots and Sensors for First Responders<br\/><br\/>PI: Daniela Rus, MIT<br\/>Co-PI: Vijay Kumar, U. Pennsylvania<br\/>Co-PI: Sanjiv Singh, CMU<br\/><br\/><br\/>This collaborative ITR project addresses the development of proactive networks of sensors and robots that perceive their environment and respond to it, anticipating information needs by the network and by users of the network, repositioning and organizing themselves to best acquire and deliver the information. Such networked systems combine the most advanced concepts in perception, communication, and control to create computational systems capable of interacting in meaningful ways with the physical environment, extending individual capabilities of each component and user to encompass a much wider area and range of<br\/>data. The PIs envision a physical analog to the Internet-- networks of computers that can actively sense, physically interact with, and reason about the world. While the Internet allows transparent access to information already online, this research will extend the paradigm by allowing users to \"google\" for physical information, setting into motion robots and sensors that team together to acquire information and act on it.<br\/> <br\/>Intellectual Merit<br\/><br\/>The proposed research program will be make significant contributions to networked multi-agent systems: control, self-organization, adaptation, and perception. The work will focus on: (1) Control for communication and sensing: the control of robotic agents to maintain communication links or establish new ones, while obtaining the required sensory information and tracking sources; (2) Communication for sensing and perception: the fusion of information from heterogeneous sensors over the network, providing the required information for each agent to plan and control its mobility and providing remotely located human rescue workers with information through immersive displays; and (3) Communication networks for sensing and control: the grouping, scheduling and routing of nodes to adapt to changing, adverse conditions while maintaining guarantees for control of mobility and for sensor fusion and integration.<br\/><br\/>Broader Impact<br\/><br\/>The research will enhance national and homeland security by providing first responder with information about areas that are unsafe and hard to reach for humans in three ways. First, it will speed up the response time by helping in assessment, by augmenting human perception for command and control. Second, it will help in suppression and containment. Third, it will play a role in recovery, as in identification of victims and location of responding personnel. The collaboration with practitioners at the Allegheny Fire Training Academy will ensure that the research is grounded in the real world and has impact in the emergency response community.","title":"ITR: Collaborative Research: -\\(NHS+ASE)-\\(int+dmc\\): Networks of Robots and Sensors for First Responders","awardID":"0427313","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["553286"],"PO":["429182"]},"98873":{"abstract":"National Science Foundation<br\/>NETS - Research in Network Technologies and Systems <br\/>CISE\/CNS<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Proposal Number: 0435490<br\/>Principal Investigator: Ramasubramanian, Srinivasan<br\/>Institution: University of Arizona<br\/><br\/>Proposal Number: 0434872<br\/>Principal Investigator: Somani, Arun<br\/>Institution: Iowa state University<br\/><br\/>Proposal Number: 0434956<br\/>Principal Investigator: Subramaniam, Suresh<br\/>Institution: George Washington University<br\/><br\/>Proposal Title: Collaborative Research: NeTS-NR: Evolutionary Architectures for Ultra-Broadband Access Networks<br\/><br\/>There is a significant mismatch between core and access network capacities currently prevalent. In order to stimulate viable large-scale fiber deployment in the last mile, an evolutionary approach to building high-capacity access net-works is called for. This project develops such an approach by providing solu-tions that can evolve starting from lower-cost wireless-based ones to the ulti-mate fiber-to-the-home (FTTH) solution. Architectural solutions for metro net-works and neighborhood access networks that allow high-speed packet switch-ing and provide efficient aggregation methods to multiplex bandwidth from vari-ous access points are developed. In particular, an evolutionary path from more cost-effective wireless and free-space optics-based solutions to FTTH for neighborhood networking is developed. Solutions ranging from high-speed elec-tronic packet-switching to all-optical WDM\/TDM for metro networking are also investigated. Analytical modeling and simulation tools to evaluate the perform-ance of the architectures are also provided. By targeting a critical area in future networking infrastructure research, the project's outcomes will have immediate and wide practical implications in network development. The results of the pro-ject will lead to a roadmap for the development of the next generation access network infrastructure.<br\/><br\/>Dr. Admela Jukan<br\/>Program Director, CISE\/CNS<br\/>Aug 19, 2004.","title":"Collaborative Research: NeTS-NR: Evolutionary Architectures for Ultra-Broadband Access Networks","awardID":"0434872","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["521840"],"PO":["565090"]},"98994":{"abstract":"This grant will support a symposium on the risks of voting and vote-counting in the United States. Technologists, election officials, political scientists and other experts will attend and will develop consensus on best practices and open questions based on a comprehensive review of voting and voting technology.<br\/>Elections, and enfranchisement of citizens, are a fundamental part of democracy, yet the nature of how elections are to be fairly conducted differs widely between (and even within) countries. New voting technologies appear to offer ease of access with the removal of barriers to voting for those who can not read a printed ballot, or who are physically disabled, home-bound or at remote locations. Other benefits may include near-immediate results, ability to perform more complex balloting schemes (such as instant runoff voting), and immunity from certain types of election fraud. Such promises have on occasion proven not to match actual performance, and the risks of undetectable election fraud and equipment failure may result in disillusionment of voters and disenfranchisement of citizens.<br\/><br\/>This topic combines issues involving design for development as well as design for democracy. The results of the symposium will include a set of organizational and technical recommendations to ensure the reliability of the systems implemented in each domain, considering the cost and need for reliability in different environments. The discourse will provide perspective on the interaction between democratic systems and adoption of voting equipment. Specific immediate design questions will address how the systems can be most effectively constructed and deployed.<br\/><br\/>The symposium will provide: i) concrete recommendations for evaluation of secure and reliable voting technology, and ii) theoretical contributions to the understanding of the interaction of technology adoption and governance. The results of this examination will be disseminated in multiple channels.","title":"Voting, Voting Risk and Vote Counting","awardID":"0435575","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["537066"],"PO":["371077"]},"97784":{"abstract":"ABSTRACT<br\/>0427382<br\/>Blanton, Ronald<br\/>CMU<br\/><br\/>Significant yield degradation is expected from design-fabrication interactions that are also known as systematic defects. Because our ability to see these defects is quickly diminishing, test will become the<br\/>main source of insight into these failures. In other words, in addition to its normal sorting function, test<br\/>will be the essential feedback loop for understanding the failure mechanisms inherent in complex fabrication<br\/>processes. Specifically, test will be the key enabler for characterizing defects, unacceptable parametric<br\/>variations, and design-process interactions essential for yielding reliable, working products in both a<br\/>timely and cost-effective manner.<br\/>To meet this challenge, new efficient approaches to test, testability analysis, design-for-test, built-in self<br\/>test, and diagnosis must be developed that can cope with the variety of failure types expected in futuregeneration products. Research in this area is restricted however since current test tools (i.e. fault simulators and test generators) are limited in the variety of failures that they can directly analyze. To remedy this situation, a fault tuple based infrastructure will be developed and disseminated that will enable researchers in the field of design, test and manufacturing to develop new and efficient approaches to test. The fault tuple mechanism is a general and effective methodology for analyzing failures in digital integrated circuits. Its key characteristic is its ability to precisely model the effects of any arbitrary failure mechanism on the logical behavior of a digital circuit. The proposed infrastructure includes the development, implementation and dissemination of (i) a fault tuple simulator, (ii) a fault tuple test generator, (iii) a set of fault generators (i.e. software modules that extract fault tuple models of a given defect type from the chip<br\/>design), and (iv) accompanying documentation that details capabilities and limitations of the test tools.<br\/>We believe creation of the proposed infrastructure will not only allow researchers to effectively evaluate<br\/>their approaches to test but enable them to develop totally new, innovative test methodologies that are<br\/>impossible within the current infrastructure.","title":"ITR (ASE + NHS) - (sim + dmc): Infrastructure Creation for Future Generation Test, Diagnosis and Yield Learning","awardID":"0427382","effectiveDate":"2004-09-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["548338"],"PO":["562984"]},"98884":{"abstract":"NeTS-ProWiN: Programmable\/Versatile Radio Platform for the Wireless Networking Research Community<br\/><br\/>Award 0434930<br\/><br\/>Babak Daneshrad, UCLA<br\/>Abstract<br\/><br\/>This effort brings together experimental PHY researchers from UCLA, networking research from UCI, and engineering expertise from Umachines to develop a highly flexible radio platform for the networking community. The availability of such a platform will spawn innovative and groundbreaking networking research for years to come.<br\/>The main thrusts of this proposal are two fold: (1) Specification, design, and development of a versatile radio platform with a fully defined API and a user friendly GUI. Two classes of radio nodes will be developed. The first is an inexpensive platform built entirely on DSP processors. This platform can handle bandwidths of a few MHz and can accommodate one or two antennas. The second node leverages FPGA technology and will provide real time operation in 25 MHz of bandwidth and can support up to 4 antenna elements. (2) Networking research carried out by UCI culminating in the implementation of the resulting algorithms on the developed nodes. The work will investigate MAC enhancements for both SISO and MIMO enabled nodes such that the physical layer parameters are controlled through the MAC layer for higher overall performance (cross-layer design). In addition to providing research results of great interest to the community, this work will push the nodes to their limits of flexibility and drives the definition and implementation of the MAC\/PHY interface.","title":"Collaborative Research: NeTS - ProWiN: Programmable\/Versatile Radio Platform for the Wireless Networking Research Community","awardID":"0434928","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"V818","name":"DEFENSE-NETS PROGRAM"}}],"PIcoPI":["544661"],"PO":["565090"]},"96343":{"abstract":"ABSTRACT<br\/>ITWF Program - FY04<br\/><br\/>CNS 0420473: PI's Sharad K. Maheshwari, Judith M. Davis, Edward Hill, and Anne L. Pierce, Hampton University<br\/>Title: BRACE: Bridging Research and Curriculum Experience<br\/><br\/><br\/>Hampton University has been awarded a planning grant to work with Norfolk State University and Virginia State University to examine why minority students at their three institutions do not pursue graduate study in information technology (IT). Preliminary graduation and alumni data of the computer science (CS) and computer information systems (CIS) majors from the three participating institutions show that there is a substantial gap in the number of students pursuing graduate study in these disciplines. Planning activities will include the identification of interventions addressing specific critical needs, and the creation of a repository of best practices. <br\/><br\/>The intellectual merit of this project lies in the development of a comprehensive plan for minority recruitment and retention in IT by incorporating new and known best practices into a program to prepare, mentor and track African-American IT students throughout college, graduate school, and initial job placement. The broader impacts of the project lie in its potential to generate information on how to increase the number of African-Americans pursuing IT majors and IT careers.","title":"ITWF: BRACE: Bridging Research and Curriculum Experience","awardID":"0420473","effectiveDate":"2004-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["468391",252630,252631,252632],"PO":["564181"]},"97795":{"abstract":"Abstract for Collaboration<br\/>0427985, 0427464, 0427094,0427912,0427695<br\/><br\/>A multidisciplinary team of researchers from Argonne National<br\/>Laboratory, Carnegie Mellon University, Columbia University,<br\/>University of Chicago, Emory University, and University of<br\/>Pennsylvania, with collaborators from the Universities of Graz and<br\/>Lubek, will initiate a long term research project on image-driven,<br\/>inversion-based biophysical modeling. The team includes expertise in<br\/>numerical algorithms and scientific computing, fluid and solid<br\/>biomechanics, PDE optimization, inverse problems, medical image<br\/>analysis and processing, and distributed and grid computing necessary<br\/>to tackle this class of problems.<br\/><br\/>This project aims to create a framework for assimilating multimodal<br\/>dynamic medical image data to produce highly-resolved,<br\/>physically-realistic, patient-specific biomechanics models. While the<br\/>computational and algorithmic aspects of the project are widely<br\/>applicable, the target application will be the construction of<br\/>patient-specific cardiac biomechanics models from 4D image datasets of<br\/>heart motion. Such models are useful for medical diagnosis and<br\/>surgical planning. This places a premium on quick turnaround of the<br\/>computations, which mean they must be fast, scalable, and capable of<br\/>exploiting grid-based computing.<br\/><br\/>Research will focus on three key areas that undergird the project's<br\/>overall goals: registration, inversion, and distributed computing. The<br\/>registration research component will create multilevel algorithms to<br\/>extract cardiac deformation histories from time-varying medical image<br\/>datasets via the solution of sequences of 3D image registration<br\/>problems. The inversion research component will develop multilevel<br\/>algorithms that use these deformation field histories as virtual<br\/>observations to solve inverse problems for cardiac biomechanical<br\/>parameters. The distributed computing research component will create<br\/>tools for performance prediction and resource scheduling that support<br\/>simulations across distributed computational resources.<br\/><br\/>Dovetailing with the research components, the project will undertake<br\/>an educational program designed to communicate the fruits of its work<br\/>and of the wider benefits of the integration of the biomedical<br\/>sciences, computing sciences, and computational sciences, to a more<br\/>general audience of students, disciplinary researchers, and the lay<br\/>public. The professional activities of the team members in the<br\/>inversion, image registration, grid computing, and computational<br\/>science communities will be parlayed to organize workshops and<br\/>international meetings, edit volumes, teach summer schools, develop<br\/>university and short courses, and engage in outreach activities---as<br\/>they have done in the past---but with greater emphasis on the field of<br\/>computational biomedicine. The proposed image-based cardiac<br\/>biomechanics modeling application will provide an excellent<br\/>opportunity to demonstrate the benefits to health and welfare that<br\/>advances in optimization-based registration and inversion algorithms<br\/>and Grid computing can provide.","title":"ITR: Collaborative Research - ASE - (sim+dmc): Image-based Biophysical Modeling: Scalable Registration and Inversion Algorithms and Distributed Computing","awardID":"0427464","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["369299"],"PO":["565272"]},"97685":{"abstract":"In the rapidly growing world of Internet infrastructures, we face many challenging new problems. These arise in part because the usual assumptions made in problems of this general type may no longer hold. For example, many typical questions dealing with massive data sets often involve networks or graphs of prohibitively large sizes. Only partial information can be obtained and in addition, this information is changing dynamically. There is an increasing need to develop the theoretical foundation for these myriad complex processes. In particular, there are many unresolved fundamental issues regarding the computational and informational-theoretic complexity of interactive computing, both in the classical setting as well as other emerging computational paradigms. In this proposal, we will investigate several<br\/>inter-related areas :<br\/>- Major open problems in communication complexity.<br\/>- Two information-theoretic identification problems Guessing secrets and Finding favorites.<br\/>- Two directions in quantum information processing quantum decision tree model and quantum communication complexity.<br\/>- Using techniques in the study of the so-called \"power law model\" for realistic networks<br\/>to develop new methods in the analysis of on-line algorithms. Impact Interactive computing is prevalent in almost all areas of computing and communcations with applications in numerous areas of science and engineering, such as security, finance, information retrieval, bioinformatics and beyond. However, the current state of the theoretical foundation for interactive computation is quite primitive and far from satisfactory. The proposed study on the computational complexity of interactive computation is meant to strengthen our understanding and provide insight that is crucial for the design and analysis of interactive algorithms. Because of the fundamental and far-reaching nature of the proposed work, this study will help bring together different areas and crossfertilization typically occur.","title":"ITR Collaborative Research: ASE-DMC Computational Complexity of Interactive Computation","awardID":"0426582","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["382705","542007",257042],"PO":["499399"]},"98312":{"abstract":"In 1960, Jane Goodall began the first long-term field study of the closest living relatives of humans, chimpanzees (Pan troglodytes), in Gombe National Park, Tanzania to describe their behavior by making extensive observations in their natural habitat. This study, which continues today, has made many contributions to understand chimpanzee behavior and human evolution, and has also inspired people around the world to study science and work toward wildlife conservation. Analysis of the complete observational dataset from Gombe and other field studies, such as the Kanyawara chimpanzee project, has the potential of providing new insights into many unanswered behavioral ecology questions, e.g. the influence of social relationships within the group on territorial behavior.<br\/><br\/>However, this observational paradigm is extremely labor-intensive and only a small part of the Gombe dataset has been analyzed so far. The goal of this project is to begin developing data analysis tools and techniques to reduce the time and effort required to analyze observation datasets. Expected results include a cartridge for mining concept patterns, a computationally efficient execution environment for concept pattern mining, and spatial semi-supervised learning algorithms to improve classification performance in creating maps. Expected results will not only benefit behavioral ecologists, but also contribute to research in many other spatio-temporal application domains, including location based services, transportation and epidemiology. Dissemination plans include development of instructional tools based on the Gombe data to motivate younger students to learn science and information technology as well as a workshop to increase collaboration between Computer Scientists and Behavioral Ecologists.","title":"Collaborative Research: SEI: Spatio-temporal Data Analysis Techniques for Behavioural Ecology","awardID":"0431141","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["550903","532009","469210"],"PO":["565136"]},"98213":{"abstract":"ABSTRACT<br\/><br\/>Distributed source coding (DSC), also known as distributed compression or the Slepian-Wolf problem, refers to the compression of two or more physically separated but statistically correlated information sources, where the sources send the (compressed) data to a common destination without communicating to each other. Having a close relation to a wealth of network information theory problems, distributed source coding is particularly appealing to sensor networks due to its ability to compress out the inter-source redundancy without explicit inter-sensor communication. Of specific interest to this research is the algorithmic design of practical and efficient DSC solutions using powerful channel codes. In view of the fairly mature status of the advanced channel coding technologies in a theoretical context and the very pervasive scope of their well-proven practical applications, exploring what cutting-edge channel codes can offer in this new field is particularly exciting. <br\/><br\/>This research focuses on the theoretic and algorithmic study of lossless and lossy DSC for symmetric and asymmetric memoryless sources. The goal is to exploit the code binning idea in capacity-approaching linear channel codes, including turbo codes and low-density parity-check (LDPC) codes, to achieve compression rates that are close to the theoretical limit. Specific attention is paid to sources that have non-uniform distributions and\/or source-dependent correlations, which are common in practical applications like sensor networks and multimedia streaming. Techniques including source decomposition, code splitting, rate combining and post-processing are used to design efficient coding strategies to match to the sources. In addition to analysis and simulations, practical issues are also addressed and a hardware sensor testbed is built to verify and demonstrate the true performance of these DSC prototypes.","title":"Exploring Capacity-Approaching Channel Codes In Distributed Source Coding","awardID":"0430634","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["545094"],"PO":["348215"]},"98334":{"abstract":"This project is investigating and developing information modeling for comparative visualizations and analyses of complex chemical separations produced by comprehensive two-dimensional gas chromatography (GCxGC). GCxGC is a powerful new technology that provides an order-of-magnitude increase in separation capacity over traditional GC. A few advanced laboratories are pioneering GCxGC for a variety of applications, such as environmental monitoring and health-care, but researchers lack advanced information technologies for analyzing and interpreting the large, complex data generated by GCxGC.<br\/><br\/>The models being developed in this project abstract essential analytical information for comparative visualization and analyses. Analytical methods are being developed to extract model components from the structural characteristics of both GCxGC intensity data and data from GCxGC with mass spectrometry (GCxGC-MS). The models support calibration for varying chemical concentrations and measurements of the quality of fit to the data. Comparative visualizations of the GCxGC information models employ multiple viewing strategies with colorization and animation to provide users with multiple avenues for interactive analyses. Interactive analyses support comparisons with view navigation and controls, queries and edits of model-based information and metadata, and structured reporting.<br\/><br\/>The model-based information technologies facilitate advanced chemical analyses in a broad range of problems. The project is demonstrating their value for two applications of GCxGC. One application analyzes changes of complex mixtures of petroleum hydrocarbons in the environment following an oil spill. The other application uses GCxGC to fingerprint fragrances for classification and identification.","title":"Collaborative Research: SEI: Information Modeling for Comparative Visualizations and Analyses - Informatics for Comprehensive Two-Dimensional Gas Chromatography","awardID":"0431252","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["415247"],"PO":["565136"]},"98224":{"abstract":"Many well-known NP-hard problems can be solved by straightforward enumeration algorithms of running time O(nk). For example, the clique problem (determine if a given graph of n vertices has a clique of k vertices) can be solved in time O(nk) by simply enumerating all subsets of k vertices in the graph. Based on the widely accepted assumptions in parameterized complexity theory, this proposed research will develop powerful new lower bound techniques to prove that the above enumeration algorithms are essentially the best possible solutions for a large group of well-known NP-hard problems. For example, it will be proved that the clique problem requires time n(k) even if one restricts the parameter values k to be of the order of any fixed function (n) < n\/ log n. The lower bound techniques will also provide new methods for the study of the trade-off between approximation ratio and running time of approximation algorithms, and for deriving computational lower bounds on polynomial time approximation schemes for certain NP-hard problems, in particular for some problems arising in computational biology. New design and analysis techniques for the development of improved algorithms will also be investigated for well-known parameterized problems with important applications in the real-world of computing.<br\/> The intellectual merit of the proposed activity. Computational lower bounds have been one of the most difficult topics in the study in theoretical computer science. The proposed research will tackle this difficult problem by introducing a new methodology based on parameterized complexity theory, by which computational lower bounds on well-known NP-hard problems can be effectively derived. The research will also study new design and analysis techniques for the development of improved algorithms for important parameterized problems in practical applications. Our research agenda is motivated by, and will build on, the success we have already achieved recently in our current study on parameterized computation and complexity. The proposed research will significantly advance the understanding on the concepts of computational tractability and computational intractability, from both theoretical and practical points of view.<br\/> The broader impacts resulting from the proposed activity. Progress made in this proposed research will have significant impact in education, science, and computational technology. First of all, the proposed research will be expected to strongly interact on other research fields in science and engineering, leading to collaborations of interdisciplinary research in Texas A&M University. The project will establish an excellent environment to broaden students' knowledge and research experience, benefit the undergraduate and graduate students from all areas involved in the research, and encourage underrepresented minorities and women to participate in advanced research. The results produced by the proposed research will enhance the undergraduate and graduate curriculum in computer science education.","title":"Computational Upper and Lower Bounds via Parameterized Complexity","awardID":"0430683","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["410068"],"PO":["499399"]},"96299":{"abstract":"Title: ITWF Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science<br\/><br\/>CNS 0420436, PI Horwitz, Univ. of Wisconsin-Madison<br\/>CNS 0419340, PI Huss-Lederman, Beloit College<br\/>CNS 0420312, PI Munson, Univ. of Wisconsin-Milwaukee<br\/>CNS 0420337, PI Dunsmore, Purdue University<br\/>CNS 0420343, PI Rodger, Duke University<br\/>CNS 0420358, PI Binkley, Loyola College of Maryland<br\/>CNS 0420368, PI Biggers, Georgia Institute of Technology<br\/>CNS 0420433, PI Ryder, Rutgers University<br\/><br\/><br\/>This collaborative ITWF project implements a new approach to introductory computer science with the goal of increasing the enrollment and retention of women and under-represented minorities in undergraduate computer science degree programs. The project adapts the Emerging Scholars Program and the Peer-led Team Learning approaches, which have been proven successful in mathematics and other sciences, to computer science. It is a collaborative project between the University of Wisconsin-Madison, Beloit College, Duke University, Georgia Institute of Technology, Loyola College of Maryland, Purdue University, Rutgers University, and the University of Wisconsin-Milwaukee. The project includes targeted recruitment of students with strong mathematics and science backgrounds to the new course. The course includes students working in small groups on challenging problems with group facilitation by outstanding undergraduates.<br\/> <br\/>The intellectual merit of this project lies in the strong basis on models that have been successful in other disciplines. The collaborative represents a team of investigators with significant expertise in educational reform and transformation. Implementation will take place at the diverse set of institutions represented by the collaborative partners, thus providing an excellent environment for evaluation of this innovative approach and illustrating the possibilities for replication and adoption by a wide range of institutions.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science. The method to be tested is relative low cost and straightforward to implement, thus it has a high potential for broad impact across the country.","title":"ITWF: Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science","awardID":"0420337","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["453383","425109"],"PO":["361119"]},"98235":{"abstract":"Abstract<br\/>NSF-0430742<br\/><br\/><br\/>Consequences of global change for land cover, carbon cycles, and biodiversity loss involve complex interactions at fine scales, such as resource availability in forest understories, to regional land-cover, climate, and CO2. Global change research requires models developed through careful study of local phenomena that can be extended to landscape, regional, and global scales. Unfortunately, environmental scientists have been limited in their ability to determine how factors that operate at different scales impact landscapes.<br\/><br\/>The primary long-term goal of the research is to enhance the ability of biology and geoscience research programs to acquire, analyze, and distribute high-resolution GIS databases of important environmental attributes. In support of this goal the computer science team will develop new techniques to extract forest attributes in the form of GIS databases from remotely sensed data. The computer science team will build an aerial remote sensing platform and a suite of analysis tools for creating GIS databases of environmental attributes with sub-meter geo-registration and elevation accuracies.<br\/><br\/>The image acquisition, analysis and GIS tools developed by UMass and MHC <br\/>provide the critical broad-scale, yet high-resolution, data needed to parameterize and validate models used to study global change. The products of these analyses will be integrated within a modeling framework at Duke University that includes extensive field data, application of new statistical computation methods, and development of a stand simulator. The combined effort will be used to determine how diversity is maintained in forest stands based on a comprehensive accounting of environmental impacts and uncertainties.","title":"Collaborative Research: SEI(BIO)--Automated Methods for Generating High-Resolution GIS Databases from Remotely Sensed Data for Biodiversity Predictions","awardID":"0430742","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":[258685,"290022"],"PO":["565136"]},"98136":{"abstract":"Some Coding Techniques for Computer Applications<br\/>Abstract<br\/><br\/>This research investigates the design of new coding techniques for balanced codes and Gray codes applicable to computer and VLSI systems. In particular the research will improve the performance of balanced codes by studying fast encoding\/decoding schemes, and investigate some simple mathematical functions which generate disjoint Hamiltonian circuits, to find good properties of Gray codes and generalized Gray codes in mixed radix systems, <br\/><br\/>The research in this proposal has potential applications in many areas such as reducing noise in VLSI systems, fault masking in data lines, maintaining data integrity in write-once memories, obtaining delay sensitivity in asynchronous systems, data encoding in some crypto-systems, A\/D converters, data compression, resource placement in <br\/>parallel systems, and efficient combinatorial algorithm design.","title":"Some Coding Techniques for Computer Applications","awardID":"0430033","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["486183"],"PO":["550859"]},"98268":{"abstract":"ABSTRACT<br\/><br\/>Scientific research is embracing highly collaborative, network-based, and data-intensive standards of practice. As scientific research transforms itself, the need for a natively digital, network-based scholarly communication system that is able to capture the digital scholarly record, make it accessible, and preserve it over time becomes evident. The ubiquity of the Internet provides the foundation for a new publication paradigm that is inclusive, responsive, and adaptive, one that resembles the scientific process that it intends to document. The Pathways project will investigate and prototype new infrastructure to address the following requirements. First, the unit of scholarly communication (traditionally a publication.) must be redefined to resemble the reality of science itself by integrating text, data simulations, images, audio, and other rich media. Second, the process of science is as important as the product. Networked infrastructure permits the decoupling and reimplementation of functions that have been vertically-integrated in traditional publishing systems. New information flows, or pathways, must be enabled to support a broad spectrum of functions including data sharing, dissemination of results, peer-review, and digital preservation. Third, information about the dynamics of scholarship is currently lost. The scholarly communication infrastructure should facilitate an archival view of scientific progress, whereby final results are but one record in the documentation of process. A graph-based information model will provide a layer of abstraction over heterogeneous resources (data, content, and services). A service-oriented process model will enable the expression and invocation of multi-stage compositional, computational, and transformational information flows.<br\/><br\/>An interoperable, network-based system will assist in breaking the constraining shackles of the traditional scholarly publishing paradigm, allowing for flexible and efficient mechanisms to create, disseminate, certify, register, transform, and archive scientific results. The models and protocols developed in this work will facilitate the creation of new types of information entities and the evolution of distributed workflows that better match underlying scientific processes. Just as the Web created a tool for all,scholars, teachers, lay citizens and school children, a better connected scholarly communication system will enable the wide dissemination of scientific results as rich, multi-dimensional, dynamic online resources.","title":"II: Pathways","awardID":"0430906","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["541699","423773",258770,258771],"PO":["565136"]},"97058":{"abstract":"This project, enhancing and facilitating the establishment and operation of a network testbed, provides a wired and wireless network infrastructure to support ongoing and future research. The institution will acquire integrative research instrumentation consisting of a traffic generator\/analyzer and wireless equipment, for the completion of an experimental state-of-the-art testbed. The high end traffic generator\/ analyzer services the analysis and measurement of results of applied methods in the network, under traffic conditions that highly approximate the scenarios in actual realistic core networks, providing the capability of enhancing models by comparing them against real-life experimental data. The wireless access points and the mobile computers\/devices supporting different wireless access technologies will not only support research efforts in the area of wireless networking, but enable the study of the user's end-to-end performance in a realistic hybrid networking environment as well. The current research projects place emphasis on the implementation of novel schemes for QoS networks, switch architectures, and network processing units needed to cope with current and future demands of the Internet evolution. The work addresses feasibility and deployability issues of network protocols, schemes, and applications in the next generation Internet, offering seamless integrated services and emulating the future hybrid network environments where wireless access and networking technologies take significant roles. Developed mechanisms are then tested for inter-operation of wireline and wireless solutions. The infrastructure supports the following research projects:<br\/> Dynamic Network Anomaly\/Attack Detection and Management,<br\/> Deployment and Implementation of Explicit Endpoint Admission Control Schemes,<br\/> Scalable Internet Routers, and<br\/> Wireless Access Networks.<br\/><br\/>Broader Impact: The infrastructure contributes to provide education and training in next generation Internet technologies.","title":"Research Resources: Integrative Instrumentation for Network Research","awardID":"0423305","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["269272","260819"],"PO":["557609"]},"98037":{"abstract":"Emergency Medical Systems (EMS) agencies, as first responders in medical emergency scenarios, are uniquely positioned to provide valuable data for surveillance and early warning systems. In most states, all patients who enter the EMS are tracked through their pre-hospital care to the emergency room using the Pre-Hospital Care Report. The PCR is used to gather vital patient information that is used by health care administrators as a resource to identify trends through macro analysis. Currently, the PCR data exists mostly on paper forms and the process of keying this data into a database that can be processed and mined for information can take up to several years as there is no automated means to extract this data from hospitals and transmit them to a central location for collating and analysis. The goal of this research is to attach this deficiency by using document image understanding and handwriting analysis.<br\/> <br\/>Intellectual Merit <br\/>The research team work toward solutions to extraction and recognition of handwritten text data from medical forms with loosely constrained layout structure, large medical vocabulary, and abundance of abbreviations and non-standard writing styles. If successful, this work will advance the state-of-the-art in handwriting recognition limited to applications with small 'pristine' vocabularies of less than a thousand words. The proposed task of machine recognition of PCR data from scanned forms requires recognition with vocabularies of tens of thousands of words which must also allow for non-standard abbreviations and medical jargon. <br\/>The research challenge in this case will be to use cues from fields on the form that can be recognized <br\/>accurately and efficiently, such as check box data, to constrain the size of the vocabulary of the words in the narrative fields. <br\/> <br\/>Broader Impact <br\/>Despite the publicity surrounding the issue of preparedness to guard against possible bioterrorist attacks, there have not been many short to middle-term practical technological solutions proposed to address the problem. The proposed project will greatly improve the speed of collecting PCR data to populate a national EMS database, thereby providing emergency medical service providers and health care administrators a wealth of data that can be used in trend analysis for the early detection of outbreak of diseases as well as allocation of public resources for emergency services.","title":"Emergency Medicine, Disease Surveillance, and Informatics","awardID":"0429358","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["454627","548306","540676",258173,258174],"PO":["371077"]},"98158":{"abstract":"PROPOSAL NO: 0430175<br\/>PROPOSAL NO: 0429292<br\/><br\/>PI: A. Jeffrey<br\/>PI: G. Bruns<br\/>co-PI: R. Jagadeesan, J.Riely<br\/><br\/>The objective of this proposal is a means of updating the functionality and security policies of high-confidence computer systems in a way that is both dynamic (can be accomplished while the system runs) and safe (does not compromise the trustworthiness of the system).<br\/><br\/>This proposal investigates the use of aspect-oriented techniques in the dynamic configuration of high-confidence software systems. The specification and implementation and verification of secured components will be studied in an aspect-oriented style. The addition of new software components, both for additional functionality and for security, will be modeled as dynamic aspects, which can modify software during its execution.<br\/><br\/>Dynamic aspects may allow for flexibility in the dynamic configuration of software, but they also introduce the possibility for subtle bugs to be introduced in the interaction between conflicting aspects. A similar problem (known as the Feature Interaction Problem) has been studied in the telecommunications field. The experience and techniques from that area will be brought to bear on security features modeled as aspects.<br\/><br\/>A class-based, object-oriented language with dynamic advice loading will be defined. Temporal logic will be used to specify both security properties and the conditions under which cutpoints apply. Static and dynamic analysis methods will be developed to identify interactions between aspects. Finally, tools will be developed to support these methods, and they will be applied in case studies.","title":"Collaborative Research: Temporal Aspects","awardID":"0430175","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["409674","409674",258485,"409672","409673"],"PO":["564388"]},"98279":{"abstract":"This is a continuation of the NSF grant 0105507 (2001-2004), for the exploration of how the underlying oriented matroid structure of points and lines affects properties of a variety of partially embedded combinatorial structures arising from motion planning and visibility problems in Computational Geometry. The ultimate goal is the design of efficient algorithmic solutions for a rich collection of geometric problems, some of which do not display an a priori discrete nature and could otherwise be attacked only using techniques from continuous geometry (real algebraic geometry). The focus of this research continues to be on fundamental mathematical properties and algorithms. These problems transcend application domains, but may lead to developing models and techniques for solving problems that arise in areas of science and engineering such as graphics (visibility computations with moving objects), robotics (collision detection and motion planning among obstacles) and molecular biology (protein folding). Female undergraduate students will be engaged in all aspects of the research, as well as graduate students. <br\/>The combinatorial structures being studied include pseudo triangulations, visibility graphs, floodlight illumination structures and other types of embedded graphs, with or without edge length, slope or other algebraic or semi-algebraic constraints. The pointed pseudo triangulations, which I introduced in work supported by a previous grant, led to very efficient solutions for certain motion planning questions in Computational Geometry. Significant advances have been made in the last few years on understanding their properties and applying them to other algorithmic questions. Two of the most challenging remaining questions are to extend them to three dimensions and higher, and to define them for non-generic point configurations in a way that would preserve desired rigidity theoretical properties. Equally important is to develop an understanding of their kinematic properties in ways that may lead to solutions to other folding and unfolding problems in computational geometry. New problems that emerged meanwhile address fundamental properties of points in motion subject to certain controlled motion laws, and of graphs drawn on such point sets. The emphasis is on the prediction of collisions and crossings. The plan is to employ some newly discovered properties of pseudo triangulations in the parallel redrawing model of rigidity which stand a good chance for 3d and higher dimensional generalizations. Potential applications include the design of test cases for kinetic structures and shape morphing.","title":"Oriented Matroids and Rigidity Theory in Computational Geometry","awardID":"0430990","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["550373"],"PO":["565157"]},"94760":{"abstract":"Optimization problems involving eigenvalues arise in many<br\/>applications. In recent years, attention has focused on<br\/>semidefinite programs, which are linear optimization problems in<br\/>the space of real symmetric matrices, with positive semidefinite<br\/>constraints. This project focuses on optimization problems in the<br\/>larger space of square matrices, not generally symmetric. In this<br\/>context, it is well known that eigenvalues, which provide<br\/>information about asymptotic behavior of dynamical systems, are<br\/>not as useful as pseudospectra, which provide a more robust<br\/>measure of system behavior. This project focuses on the<br\/>computation, analysis and, especially, numerical optimization of<br\/>pseudospectral functions. A secondary goal is to advance the<br\/>development of algorithms for general nonsmooth, nonconvex<br\/>optimization problems.<br\/><br\/>Applications of this work arise in many contexts. A good example<br\/>that we have used is a model of a Boeing 767 at a flutter condition.<br\/>Flutter occurs when the plane flies so fast that the interaction<br\/>of the aerodynamic (wind) forces with the structural forces in<br\/>the airplane combine to generate an instability which could be<br\/>catastrophic. Normally, a plane like this does not fly so fast but<br\/>it is important to know what would happen if it did, and whether a<br\/>simple controller could bring the plane under control. Eigenvalues <br\/>tell us about stability in the long term, but pseudospectra are far <br\/>more informative, telling us about stability in the short term. <br\/>Optimizing the pseudospectra over the parameters of the <br\/>controller may result in the design of a controller that is simple <br\/>yet effective in avoiding the instability and preventing catastrophe.","title":"Optimization of Pseudospectra","awardID":"0412049","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["549376"],"PO":["565027"]},"98940":{"abstract":"The objective of this project is to investigate the combined use of adaptation and preemption mechanisms in the context of best-effort networks, such as the Internet, as complementary tools for reacting to the onset of congestion or link failure. In particular, adaptation is seen as a means of reacting to light congestion, while preemption is useful for heavy congestion or link failure. With adaptation, the link bandwidth is dynamically allocated among competing flows so as to maximize specified QoS metrics, where each stream maintains its current route. With preemption, however, flows are selected to be re-routed based on their assigned priority levels. While preliminary adaptation and preemption policies have each been studied independently, this research project includes a novel combination of these mechanisms into a robust congestion control mechanism capable of handling traffic changes of varying magnitude. In practice, adaptation is essentially a distribution of the excess bandwidth left over after each stream's minimum bandwidth requirements have been satisfied. Preemption is appropriate when the congestion level is too great for adaptation to be viable. Preemption, however, carries a potentially greater impact on network stability and can cause service disruption for the flows selected for rerouting. The goal of this research is to study the tradeoffs between adaptation and preemption both analytically, in simulation, and on a physical testbed. The conclusion will be a recommendation regarding the optimal congestion mechanism for various congestion regimes.","title":"NeTS-NR: Preemption and Adaptation for Next Generation Multiservice Networks","awardID":"0435247","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["533238","520246"],"PO":["565090"]},"98951":{"abstract":"Proposal Number: 0435312<br\/>PI: David Starobinski <br\/>Institution: Boston University <br\/>Title: SensorNet Architectures of Indoor Location Detection: From Resolution to Robustness<br\/><br\/>Abstract: <br\/><br\/>The ability to accurately and robustly determine the location of sensors or targets is fundamental to the operation of sensor networks. In open outdoor settings, this can be performed with trilateration techniques used by the Global Positioning System (GPS). However, in indoor or dense urban environments, such techniques face a wide variety of debilitating complications, including signal reflections, occlusions, and unpredictable dependencies (e.g., doors opening and closing). This project is investigating fundamental performance limits of indoor location detection systems and aims at prototyping sensor network architectures that approach these limits. The work focuses on tradeoffs between robustness and resolution of such systems, drawing on the literature in coding theory, large deviations, and mathematical programming. Paralleling the development of GPS, the results of this project could serve as a cornerstone technology for a wide variety of applications, including tracking of shared equipment, victim disaster rescue, or indoor navigation for the blind","title":"NeTS-NOSS: SensorNet Architectures for Indoor Location Detection: From Resolution to Robustness","awardID":"0435312","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["526820","486132","449083"],"PO":["564777"]},"97862":{"abstract":"Many recent advances in natural language processing (e.g., speech recognition and information extraction) are due to widespread use of finite-state automata. These automata probabilistically transform input strings into output strings, and they can be quickly assembled to tackle new jobs via generic mathematical operations like composition and forward application. However, these automata are a bad fit for many important problems that require syntax-sensitive transformations and large-scale re-ordering (such as language translation and summarization).<br\/><br\/>We are investigating tree automata as an alternative building block for new natural language systems. These automata walk over input trees and produce output trees. Fortunately, there is an extensive mathematical theory associated with these devices. These automata also fit many of the ad hoc models recently proposed in natural language research. However, there are several critical missing pieces: (1) how to design efficient computer science algorithms for generic tree operations, (2) how to design efficient machine learning algorithms for inducing tree automata and probabilities from linguistic data, and (3) how to use automata to accurately model problems in automatic language translation.<br\/><br\/>We expect this research to yield several benefits. Many researchers who currently use finite-state tools will switch to more powerful tree-based automata and obtain more accurate language processing systems. Also, tree automata will enable better understanding of how to model language translation more deeply and accurately, and -- importantly -- in such a way that syntactic and lexical translation knowledge can still be acquired fully automatically by the machine from text corpora.","title":"ITR-(NHS)-(dmc)-TREEWORLD: Probabilistic Tree Transducers for Machine Translation and Natural Language Processing","awardID":"0428020","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["404736",257577,"518197"],"PO":["565215"]},"97752":{"abstract":"The goal of the proposed research is to extend the reach of machine learning technology so that it can enable computers to perform a broader span of tasks than currently. In particular the goal is to enable machines to extract knowledge from data into a form such that robust reasoning can be done on it. Currently representations on which reasoning can be done on a large scale are typically programmed and the results suffer from brittleness - they do not behave well in unforeseen situations. In the proposed approach, which is called knowledge infusion, the goal is to acquire the rules on which reasoning will be <br\/>done by a combination of programming and learning, and to have a continuous process of learning and checking against an environment to ensure that the rules are reliable. The goal is to handle unaxiomatized or commonsense knowledge, which encompasses the bulk of knowledge that humans handle everyday, as embodied in speech or text, replete as these often are with inconsistencies, ambiguities and errors. This can be distinguished from knowledge that is known to be axiomatizable, such as most knowledge of a mathematical nature. Axiomatized knowledge, in general, can be easily programmed, and computers can usually fully exploit such knowledge up to any inherent computational complexity limitations of the problem at hand. <br\/><br\/>The most central aims of the research are the development of algorithms that realize knowledge infusion and are computationally efficient and effective even for very large datasets. Also central is the identification of what the fundamental limits of the phenomenon are. The techniques used will be from theoretical computer science, and experimentation on large datasets will be carried out as needed. <br\/><br\/>The goal is to be able to infuse into machines commonsense knowledge about the world on a large scale and in a way such that the machines will be able to reason with it with a controlled level of robustness. Success in this endeavor can be expected to have applications in almost all areas of computing that involve either human interaction with a computer, or computation on data that was generated by or has reference to humans. Hence there are numerous connections with the national priority areas EVS and NHS, and with the technical focus areas int and dmc. <br\/><br\/>Broader Impact: <br\/><br\/>If successful the results of the research will help enhance the effectiveness of computers to handle commonsense or unaxiomatized information about the world. This would extend the usefulness of computers to new areas and contribute to prosperity (EVS). It would also enable large datasets to be analyzed automatically with greater functionality than hitherto (NHS).","title":"ITR - (EVS+NHS) - (dmc + int): Knowledge Infusion","awardID":"0427129","effectiveDate":"2004-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["438597"],"PO":["565251"]},"97873":{"abstract":"Title: ITR: COLLABORATIVE RESEARCH - (ASE+NHS) - (int): BFT-LS: Byzantine Fault Tolerance for Large-Scale, High-Performance Distributed Storage Systems<br\/><br\/>Reliance on information available over the Internet is increasing every day. At the same time, the number of malicious attacks is growing. Nevertheless, it is critical that online information be stored reliably: information must not be lost, must be accessible when needed, and what a user sees must be what is actually stored. These requirements must be satisfied in spite of malicious attacks on the network or the storage nodes. This project concerns research on a new storage system, BFT-LS (Byzantine Fault Tolerance - Large Scale), that satisfies these requirements. <br\/><br\/>BFT-LS is designed to support five main goals: (1) Reliability. BFT-LS provides extremely reliable storage: stored objects are not lost, are available when needed, and are uncorrupted, in spite of malicious attacks and Byzantine failures in which a node behaves arbitrarily badly. (2) Automatic Reconfiguration. BFT-LS is a dynamic system that reconfigures itself automatically, thus enhancing reliability by reducing reliance on operators. BFT-LS also allows nodes to be added to replace failed nodes and to improve service under increasing load. (3) Application Independence. BFT-LS provides a flexible interface that meets the needs of many applications, including file systems and databases. (4) Extended Semantics. BFT-LS supports atomic transactions that can read and write many objects. In addition, read-only transactions can run in the recent past yet are guaranteed to see a consistent state. (5) Efficient access at large scale. BFT-LS is intended to run efficiently at very large scale: it must store a vast quantity of state that is accessed by huge numbers of users who are physically located all over the world. It provides an infrastructure that allows clients to us data cached nearby, rather than communicating with far-away storage nodes. Nearby nodes aren't trusted, however; instead a new reliable stream mechanism ensures data validity.<br\/><br\/>BFT-LS is expected to provide greater functionality than earlier work while also providing outstanding performance. Its extended functionality not only requires innovative new solutions in many areas, but also makes the system more generally useful because it can support a wide range of applications.","title":"ITR: Collaborative Research: (ASE+NHS) - (int): BFT-LS: Byzantine Fault Tolerance for Large-Scale, High-Performance Distributed Storage Systems","awardID":"0428107","effectiveDate":"2004-09-15","expirationDate":"2010-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["383836"],"PO":["561889"]},"98973":{"abstract":"Abstract: <br\/><br\/>Wireless Sensor Networks (WSNs) will benefit society by accelerating scientific research, increasing productivity, and enhancing security. Candidate solutions to particular scientific challenges, ranging from device design to distributed algorithms, exist with various assumed requirements, constraints, and relationships between the components. However, there is no consensus on an overall sensor network architecture. Deployments take a narrow vertical slice to achieve a operational network. The objective of this project is to formulate and evaluate a comprehensive WSN systems architecture, encompassing general design principles, broad functional decompositions, and detailed interfaces by which pieces fit together. <br\/>The approach recognizes that the ``narrow waist\" of this architecture -- playing the role of IP in the Internet architecture -- is a best-effort single-hop broadcast. The primary method for articulating the essential abstractions is iterative cycles of (candidate collection, design, integration, evaluation) with the outcome presented to the community for analysis to establish the right compromises between generality and performance. This process will articulate consistent programming interfaces that encompass collection, aggregation, dissemination, neighborhoods, data centric storage, and attribute-based routing over multiple link layers. The architecture will be tested on cross-cutting aspects of efficiency, coordination, power, management, and security. It should embrace heterogeneity and allow for application-specific optimization within a consistent framework. <br\/>Creating a successful architecture for WSNs will reduce development effort, allow greater synergy and interoperability, enable more rapid innovation, and greatly broaden the sphere of applications from national security to scientific research and ecosystem management.","title":"NeTS-NR: Creating a Wirelss Sensor Net Architecture","awardID":"0435454","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["527079","560562","560562","508219"],"PO":["564777"]},"97884":{"abstract":"Engineering the Unexpected: Socio-technical Issues in the Design of Management Systems for Biohazardous Emergencies <br\/> <br\/>An interdisciplinary team of anthropologists, computer scientists, medical doctors, and technology specialists proposes to create a socio-technical model of information systems used in disaster management. This model will be constructed from interviews, first-person observations, public reports, and other sources of data on actual emergencies in the Detroit\/Windsor international metropolitan area over the past five years. The model will focus on the information systems that public and private agencies in the United States and Canada use to coordinate their preparation and response. The model will be used (a) to evaluate specific hypotheses regarding the effective integration of socio-technical issues into the design of disaster management systems, and (b) to provide guidance for the effective design and use of emergency management IT. <br\/> <br\/>The proposed model will be a hybrid of functional and agent-based models: In preparation for, response to, and consequence management of disasters, functional imperatives and self-organizing dynamics play differing roles. The model will incorporate representations of the cultures of the different groups, public authorities, medical professionals, first responders, families, communities, and even the media, insofar as these cultural differences have consequences for communication and the use of information. <br\/> <br\/>The research proposed here builds on a unique collaboration among multiple disciplines and capabilities at Wayne State University, and an international partnership with the Police, Fire, EMS, and other practitioners. This partnership has identified a critical issue in our Nations ability to respond to future threats: the coordination of multiple agencies in a jurisdictionally complex environment, and the development of systems appropriate to that complexity.","title":"Engineering the Unexpected: Sociotechnical Issues in the Design of Management Systems for Biohazardous Emergencies","awardID":"0428216","effectiveDate":"2004-09-15","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["354231","354232",257651,257652,257653],"PO":["469867"]},"94254":{"abstract":"CNS 0409382 Stephen M. Goddard University of Nebraska-Lincoln<br\/><br\/>Title: Energy-Aware CPU and I\/O Scheduling for Embedded, Real-Time Systems<br\/><br\/>Embedded real-time systems often have severe power constraints that require aggressive energy conservation techniques in both the processor and the Input\/Output (I\/O) devices. This project is investigating energy-aware processor and I\/O scheduling for embedded, hard real-time systems with flexible task models. The results will provide the opportunity for increased energy savings in reactive, embedded, real-time systems that execute in unpredictable environments, such as mobile robots. The project focuses on two central problems: processor energy conservation for sporadic tasks, and energy conservation for I\/O devices with periodic tasks.<br\/><br\/>Processor Energy Conservation: Processor energy conservation for the periodic task model has been extensively researched in the context of dynamic power consumption for embedded, real-time systems. However, energy conservation with more flexible real-time task models, such as the sporadic task model, remains an open problem. The project is investigating processor energy conservation for sporadic tasks that have deadlines not equal to their respective periods, non-preemptive earliest-deadline-first (EDF) scheduling, shared resources under EDF scheduling, and generalized versions of the sporadic task model. <br\/><br\/>Energy Conservation in I\/O Devices with Periodic Tasks: This research is investigating methods that dynamically re-order job executions to conserve energy in I\/O devices under the periodic task model. Though the focus of this aspect of the project is energy conservation in I\/O devices, the method minimizes processor dynamic power dissipation when only frequency scaling is supported (and not voltage scaling). It also reduces leakage power consumption by grouping short idle periods into longer intervals of time in which the processor can be made idle without jeopardizing temporal correctness.","title":"EHS: Energy-Aware CPU and I\/O Scheduling for Embedded, Real-Time Systems","awardID":"0409382","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["486378"],"PO":["561889"]},"98863":{"abstract":"NeTS-NR: Using Signal Propagation Emulation to Understand and Improve<br\/>Wireless Networks<br\/><br\/>Peter Steenkiste, CMU<br\/><br\/>Award 0434824<br\/><br\/>Abstract<br\/><br\/>Wireless networking has become a part of everyday life, but research aimed at evaluating and improving wireless protocols is hindered by the inability to perform repeatable and realistic experiments. Techniques used in wired networks are inadequate for analyzing wireless networks since the wireless physical layer affects operation at all protocol layers; moreover, wireless links are variable, error-prone, and affected by external uncontrolled sources.<br\/><br\/>This project is developing a system that accurately emulates wireless signal propagation in a physical space. The project is also developing realistic signal propagation models, and conducting experiments to see how diverse technologies such as WiFi, Bluetooth, and software defined radios are affected by the physical layer.<br\/><br\/>By combining many benefits of simulation and real world experimentation, the emulator can have a dramatic research impact. Since the emulator can be shared over the network, it can be integrated into existing testbeds. It can also enable remote groups to compare realistic results. Moreover, the emulator can aid education by supporting hands-on wireless course projects in a realistic, \"safe\" isolated environment. Emulator-based experiments will significantly improve understanding of how signal propagation affects medium access control layer performance, and enable the development of improved protocols. This project will also result in a set of realistic models of signal propagation. Finally, this project will quantify the relative strengths and weaknesses of competing wireless protocols in diverse, realistically emulated physical environments. Project results will be disseminated through publications, through allowing remote researchers emulator access, and through educational activities such as course projects.","title":"NeTS-NR: Using Signal Propagation Emulation to Understand and Improve Wireless Networks","awardID":"0434824","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["396979","463128"],"PO":["402055"]},"96333":{"abstract":"Title: ITWF Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science<br\/><br\/>CNS 0420436, PI Horwitz, Univ. of Wisconsin-Madison<br\/>CNS 0419340, PI Huss-Lederman, Beloit College<br\/>CNS 0420312, PI Munson, Univ. of Wisconsin-Milwaukee<br\/>CNS 0420337, PI Dunsmore, Purdue University<br\/>CNS 0420343, PI Rodger, Duke University<br\/>CNS 0420358, PI Binkley, Loyola College of Maryland<br\/>CNS 0420368, PI Biggers, Georgia Institute of Technology<br\/>CNS 0420433, PI Ryder, Rutgers University<br\/><br\/><br\/>This collaborative ITWF project implements a new approach to introductory computer science with the goal of increasing the enrollment and retention of women and under-represented minorities in undergraduate computer science degree programs. The project adapts the Emerging Scholars Program and the Peer-led Team Learning approaches, which have been proven successful in mathematics and other sciences, to computer science. It is a collaborative project between the University of Wisconsin-Madison, Beloit College, Duke University, Georgia Institute of Technology, Loyola College of Maryland, Purdue University, Rutgers University, and the University of Wisconsin-Milwaukee. The project includes targeted recruitment of students with strong mathematics and science backgrounds to the new course. The course includes students working in small groups on challenging problems with group facilitation by outstanding undergraduates.<br\/> <br\/>The intellectual merit of this project lies in the strong basis on models that have been successful in other disciplines. The collaborative represents a team of investigators with significant expertise in educational reform and transformation. Implementation will take place at the diverse set of institutions represented by the collaborative partners, thus providing an excellent environment for evaluation of this innovative approach and illustrating the possibilities for replication and adoption by a wide range of institutions.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science. The method to be tested is relative low cost and straightforward to implement, thus it has a high potential for broad impact across the country.","title":"ITWF: Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science","awardID":"0420433","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["438877"],"PO":["361119"]},"97785":{"abstract":"In wireless communication systems, users with heterogeneous information content such as data, voice, and multimedia constrain the network by having different reliability requirements. In this project a framework which can provide heterogeneous reliability guarantees for the users is considered.<br\/>This adds a completely new dimension to the trade-off of performance in a wireless network, and is unique to multiterminal communication systems. It is as if the network has some amount of reliability that can be allocated among the users. This is a very general concept and can be applied in any multiterminal<br\/>communication problem.<br\/><br\/>This is accomplished by defining individual probabilities of errors for the users in the network. Hence for a fixed vector of rates of the users, a system can provide a trade-off of reliabilities among the users. <br\/>This set of achievable reliabilities is referred to as the multiuser reliability profile of a multiuser network. This profile is a function of the vector of transmission rates inside the capacity region.<br\/>For a wireless system employing multiple antennas, this profile is referred to as multiuser diversity gain<br\/>profile. Further, these guarantees are directly manifested in the physical layer and can be translated into QoS guarantees in the higher layers in the network architecture. This is a marked shift from conventional approaches that relegate this task to the higher network layers. Hence in a heterogeneous wireless networks,<br\/>heterogeneous QoS guarantees can be more efficiently realized using the techniques considered in this project. This project is expected to have a significant impact on the design of the next generation of wireless networks.","title":"ITR - (ASE+ECS) - (dmc+soc): A Framework for Heterogenious Quality-of-Service Guarantees in Wireless Networks: A Communication-theoretic Approach","awardID":"0427385","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["483402","485560"],"PO":["564898"]},"99974":{"abstract":"This award supports participants in a two-day symposium on machine learning for anomaly detection to be held at Stanford University on May 22-23, 2004. The purpose of the symposium is to bring together researchers, students, and industrial practitioners from different application areas and let them report their recent results and discuss common concerns. A central aspect of the symposium are eleven invited talks given by established researchers whose work provides a good sampling of research using machine learning methods to detect anomalies across a variety of domains. The symposium fosters improved research in anomaly detection by exposing attendees to ideas from other fields, encouraging interaction and collaboration, and helping to identify common open problems. Dissemination plans include developing a website (http:\/\/cll.stanford.edu\/symposia\/anomaly\/) with the speakers talks and relevant papers available for download, preparing a workshop report, and organizing a special journal issue devoted to machine learning approaches to anomaly detection. Finally, the symposium will contribute to increased understanding of methods for anomaly detection, which is becoming important in many areas such as public health monitoring, computer network security, and accounting fraud detection.","title":"Symposium on Machine Learning for Anomaly Detection","awardID":"0442128","effectiveDate":"2004-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["559662",263679],"PO":["563751"]},"98885":{"abstract":"This effort brings together experimental PHY researchers from UCLA, networking research from UCI, and engineering expertise from Umachines to develop a highly flexible radio platform for the networking community. The availability of such a platform will spawn innovative and groundbreaking networking research for years to come.<br\/>The main thrusts of this proposal are two fold: (1) Specification, design, and development of a versatile radio platform with a fully defined API and a user friendly GUI. Two classes of radio nodes will be developed. The first is an inexpensive platform built entirely on DSP processors. This platform can handle bandwidths of a few MHz and can accommodate one or two antennas. The second node leverages FPGA technology and will provide real time operation in 25 MHz of bandwidth and can support up to 4 antenna elements. (2) Networking research carried out by UCI culminating in the implementation of the resulting algorithms on the developed nodes. The work will investigate MAC enhancements for both SISO and MIMO enabled nodes such that the physical layer parameters are controlled through the MAC layer for higher overall performance (cross-layer design). In addition to providing research results of great interest to the community, this work will push the nodes to their limits of flexibility and drives the definition and implementation of the MAC\/PHY interface.","title":"Collaborative Research: NeTS-ProWIN: Programmable\/Versatile Radio Platform for the Wireless Networking Research Community","awardID":"0434930","effectiveDate":"2004-09-15","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"V818","name":"DEFENSE-NETS PROGRAM"}}],"PIcoPI":["508494"],"PO":["557315"]},"96344":{"abstract":"This project, supporting collaboration among co-located and remote experts requiring interactive ultra-high-resolution imagery, aims at developing a high-end visualization \"LambdaVision\" multipanel display as a means to advance both scientific research and public safety as validated by users in various disciplines and training exercises in disaster response. LambdaVision will target applications requiring extremely high data rates and very large, high-resolution images, such as earth surface imagery. Applications include scientific simulations and disaster response. Plans included the development of smaller versions for use in the classroom and in the field. The following research applications will use the system:<br\/>Geoscience Research ,The US Geological Survey, Integrated Ocean Drilling Program<br\/>US National Lacustrine Core Repository, Computer Science Research in Visualization, Advanced Networking Middleware, and Multi-User Collaboration ,Scalable Adaptive Graphics,Advanced Networking Middleware,Collaborative Methods for Display-Rich Environments<br\/>Research Instrumentation Development, LambdaVision and Lambda Table Architecture LambdaVision and Lambda Tabel Seamless Display Technology ,LambdaTable Tracking System<br\/><br\/>Broader Impact: PIs have a history of developing technology that domain scientists use. The work includes designing systems suitable for use in the field, classroom, and lab.","title":"MRI: Development of Instrumentation for Lambda Vision","awardID":"0420477","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["557607","552897","495168","558518","558519"],"PO":["557609"]},"97697":{"abstract":"Over the past decade we have witnessed an astounding surge in computing devices and interfaces off the desktop and into the multi-tasking environments of the real world. In this project, the PI will develop a rigorous computational architecture, the Task-Integrated-Modeling (TIM) architecture, and an associated methodology for evaluating user interfaces in complex multitasking environments. The TIM architecture centers on integrating cognitive models of behavior with the interface in the context of the multitasking environment, using \"cognitive architectures\" to represent and simulate user cognition and behavior. Based on these models, the architecture allows a designer to rapidly evaluate new interfaces through stages of rapid prototyping, task demonstration, integrated model creation, and computational simulation. The theory behind the architecture and the system itself will account not only for various aspects of human multitasking but also of individual differences, facilitating robust modeling of a range of user populations. As a test domain for the architecture, the project will focus on the domain of driving, particularly the use of device interfaces in the vehicle and the study of different driver populations (e.g., younger vs. older drivers). The PI will implement a rapid development and evaluation system for new in-vehicle interfaces that attempts to minimize potential driver distraction from these interfaces. In addition, shared Internet libraries of software applications, toolkits, and cognitive models will be created, for dissemination to and use by academic researchers as well as industry designers and developers.<br\/><br\/>Broader Impacts: Through collaborations with academic researchers and industry experts, the PI will rigorously address the problem of driver distraction (currently the leading cause of crashes in the United States), helping to explore the sources of distraction and helping to devise rigorous methods of improving the safety of our vehicles and roadways. The computational infrastructure developed will not only advance our theoretical understanding of human cognition, but also realize these theories in real-world practical systems. The project will involve diverse populations, directly by including under-represented groups in research work and summer workshops, and indirectly by exploring how individual differences may affect interface use and multi-tasking. Locally, the related education plan will result in new courses in human-computer interaction, cognitive systems, and off-the-desktop computing at Drexel University, providing a unified HCI curriculum for roughly 40-50 students per year in the HCI track and even more across the Computer Science Department and the University as a whole. The PI will also initiate an annual educational and hands-on HCI workshop for high-school students in West Philadelphia, focusing on the under-represented minority populations in these neighborhoods, in the hope of exciting and inspiring these students to pursue further education and careers in fields related to people and technology.","title":"ITR - (EVS+ASE) - (int+sim): Rapid Evaluation of User Interfaces in Multitasking Environments","awardID":"0426674","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["444122","415194"],"PO":["565227"]},"96487":{"abstract":"This project, impacting genome analysis, structural proteomics, and macromolecular imaging by linking massive and exponentially growing data in each of these fields to the molecular basis of biological functions, aims at acquiring a 220-CPU Opteron distributed memory computing cluster. The Structural and Computational Biology and Molecular Biophysics (SCBMB) Program using the cluster encompasses six institutions: Baylor College of Medicine, Rice University, the University of Houston, the University of Texas MD Anderson, the University of Texas Health Sciences Center-Houston, and the University of Texas Medical Branch-Galveston. The infrastructure will service the following research activities:<br\/>Electron Cryo-Microscopic Reconstruction of Biological Assemblies at the National Center for Macromolecular Imaging (NCMI) (mainly Electronic Cryomicroscopy and Image Reconstruction), Characterization of Functional Surfaces for Structural Proteomics (involving the Evolutionary Trace Method (ET) and utilizing High-Throughput Identification and Geometric Matching of Functional Surfaces), Comparative Genomics (including Parallel Comparison of DNA sequences via Positional Hashing (Pash) and Comparative Sequence Assembly and Mapping)<br\/>Micro-RNA (miRNA) (binding target complementary mRNS by regulating gene expressions)<br\/>Each research project has high computational demands that will be met with the proposed parallel environments. The derivation of meaningful inferences from raw biological data requires intensive computation involving data sets. For example, to reconstruct 3-D images of macromolecular machines, the labs need to transform and auto-correlate gigabytes of voxels from electron cryomicroscope data; to identify functional sites in protein structures, the lab requires all-against-all comparisons of thousands of protein structures; and to identify mammalian genes and detect novel micro-RNAs, the labs require cross-comparisons of billions of basepairs of DNA sequence. These applications all share the common feature of repeated but relatively independent computations that can be split among many CPUs with modest need of communication through a common file server. These shared characteristics can be serviced well by the requested cluster.<br\/><br\/>Broader Impact: The infrastructure enhances the educational experience at participating institutions. Students in the SCBMB graduate program (encompassing 6 institutions) will use the system, significantly enhancing their research opportunities. Baylor has outreach programs for undergraduates and for high school. Workshops, software tool development, and technology transfer will serve to disseminate the results.","title":"MRI: Acquisition of a Cluster Computer for Digital Biology","awardID":"0420984","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["334007","473954",253235,253236,"430331"],"PO":["557609"]},"98203":{"abstract":"Collaborative pervasive computing applications can greatly improve the investigative capabilities and productivity of scientists and engineers in many fields. Users of such applications usually form groups to collaboratively perform their tasks, supported by their computing devices, including desktop computers, pocket PCs, and\/or smart phones, over Mobile Ad hoc Networks (MANET), LAN and Internet. Users of collaborative pervasive computing applications usually need to share various types of data, including experimental data, sensitive documents, multimedia data, etc. In data sharing and management, a very important issue is trustworthiness. To support trustworthy data sharing and management among groups of users for collaborative pervasive computing applications, secure group communication, trustworthy shared data discovery, flexible access control mechanisms, effective data replication, data quality assurance mechanisms, and intrusion detection mechanisms are needed. So far, little research has been done in trustworthy shared data discovery and flexible access control mechanisms for collaborative pervasive computing environments.<br\/><br\/>In this proposal, an innovative approach is proposed to trustworthy shared data service management to provide users of collaborative pervasive computing applications with the capabilities of sharing, discovering and accessing shared data with high confidence. Our approach will be based on Web Services architecture, emerging OWL technology and our Reconfigurable Context-Sensitive Middleware (RCSM) and Secure Group Communication Service (SGCS). In our proposed approach, shared data services are used to provide access interfaces to shared data. Our proposed trustworthy shared data service management will include trustworthy shared data service specification and generation, shared data service discovery, and secure access to shared data services. The proposed research will generate a new trustworthy shared data service management technique, including an OWL-based trustworthy shared data service specification language, an automated service generation technique, a trustworthy shared data service discovery protocol and a lightweight situation-aware access control framework. The expected results will be implemented as a set of middleware components and services to support the development of trustworthy data sharing and management capability in collaborative pervasive computing applications. We will develop a demonstration application to demonstrate and evaluate our expected results. <br\/><br\/>The intellectual merits of the proposed research includes (a) using automatically generated web services as the unified interface for accessing shared data to overcome organizational barriers, (b) integrating access control policies with OWL-based data description and access interface specification to enhance semantic interoperability and enable intelligent service discovery, (c) incorporating situation-awareness in access control to enforce flexible high-grained access control policies based on the situation and different local access control models in various security domains, and (d) developing a lightweight, secure and fault-tolerant service discovery protocol.<br\/><br\/>The proposed research will have the following broader impacts: <br\/>(1) The results of the proposed research can greatly improve the user confidence in collaborative pervasive computing applications and increase the effectiveness of collaborative research or development among scientists, engineers and\/or businessmen in pervasive computing environments. <br\/>(2) Since the proposed research is based on the widely accepted Web Services architecture and the Resource Description Framework (RDF) standards of the World Wide Web Consortium (W3C), the results of the proposed research can be extended to general applications using Internet, Grid and Semantic Web, with increased trustworthiness.<br\/>(3) The results of the proposed research will be included as a part of the senior\/graduate level course on information assurance and a new graduate-level course on data and application security at Arizona State University. The new material in these courses should attract high-quality students to participate in research on cyber trust.","title":"Trustworthy Data Sharing and Management for Collaborative Pervasive Computing Applications","awardID":"0430565","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["487903"],"PO":["433760"]},"98324":{"abstract":"Over the past several years, there has been a great deal of research to <br\/>improve performance of wireless communications in fading environments by exploiting <br\/>transmitter and\/or receiver diversity and spatial multiplexing. The pioneering work by Telatar, <br\/>Foschini and Gans showed that multiple antenna radios (MAR) in a wireless communication system <br\/>can greatly improve the performance. The major roadblock to MAR being a financially viable <br\/>option for wireless communications is the cost of the analog portions of the radio. <br\/>Point--to--point MAR systems employing complex signaling and signal processing algorithms have been <br\/>designed and built and have achieved performance very close to the outage capacity. <br\/>The remaining gains that are achievable in MAR will only be exploited by considering the cost <br\/>and complexity of analog circuitry in MAR signalling and signal processing, by considering more <br\/>complex models for wireless propagation, and by putting MAR in networking context. The <br\/>focus of this effort is to push MAR technology by exploiting the structure in these more <br\/>complex models and networking scenarios.<br\/><br\/>The objectives of the effort can be succinctly stated as:<br\/>1) Communication theory is often interested in normalizing performance <br\/>for a fixed average power but in wireless implementations the peak <br\/>power is a more critical driver than the average power. The research <br\/>is examining optimization of performance and throughput with a peak <br\/>power constraint in multiple antenna radio.<br\/>2) Feedback communication is likely going to enable a significant <br\/>improvement in throughput and demodulator complexity in a networked <br\/>scenario especially in environments with low mobility (e.g., wireless <br\/>computer networks). This research is approaching feedback <br\/>communication with a classic scientific method of iterating between <br\/>experimentation on real channels and more realistic theoretical problem <br\/>formulations based on the results derived in experimentation.<br\/>3) The cost driver in wireless communication currently is the analog <br\/>circuitry. This research is examining techniques that would minimize <br\/>the complexity of the analog systems in a multiple antenna radio. The <br\/>objectives are to being met by the following research tasks<br\/>a) Improved channel parameterization for long range prediction for <br\/>multiple antenna radio,<br\/>b) Design and field testing of a variety of MAR automatic repeat <br\/>request algorithms,<br\/>c) Experimentation with the proposed feedback algorithms for MAR,<br\/>d) Feedback algorithms for MAR with constant envelop modulations,<br\/>e) Feedback algorithms for MAR with limited analog capabilities,","title":"Working Toward Capacity in Multiple Antenna Radio","awardID":"0431196","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["282307"],"PO":["564924"]},"96168":{"abstract":"Title: ITWF Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science<br\/><br\/>CNS 0420436, PI Horwitz, Univ. of Wisconsin-Madison<br\/>CNS 0419340, PI Huss-Lederman, Beloit College<br\/>CNS 0420312, PI Munson, Univ. of Wisconsin-Milwaukee<br\/>CNS 0420337, PI Dunsmore, Purdue University<br\/>CNS 0420343, PI Rodger, Duke University<br\/>CNS 0420358, PI Binkley, Loyola College of Maryland<br\/>CNS 0420368, PI Biggers, Georgia Institute of Technology<br\/>CNS 0420433, PI Ryder, Rutgers University<br\/><br\/><br\/>This collaborative ITWF project implements a new approach to introductory computer science with the goal of increasing the enrollment and retention of women and under-represented minorities in undergraduate computer science degree programs. The project adapts the Emerging Scholars Program and the Peer-led Team Learning approaches, which have been proven successful in mathematics and other sciences, to computer science. It is a collaborative project between the University of Wisconsin-Madison, Beloit College, Duke University, Georgia Institute of Technology, Loyola College of Maryland, Purdue University, Rutgers University, and the University of Wisconsin-Milwaukee. The project includes targeted recruitment of students with strong mathematics and science backgrounds to the new course. The course includes students working in small groups on challenging problems with group facilitation by outstanding undergraduates.<br\/> <br\/>The intellectual merit of this project lies in the strong basis on models that have been successful in other disciplines. The collaborative represents a team of investigators with significant expertise in educational reform and transformation. Implementation will take place at the diverse set of institutions represented by the collaborative partners, thus providing an excellent environment for evaluation of this innovative approach and illustrating the possibilities for replication and adoption by a wide range of institutions.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science. The method to be tested is relative low cost and straightforward to implement, thus it has a high potential for broad impact across the country.","title":"ITWF: Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science","awardID":"0419340","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[252159],"PO":["361119"]},"98588":{"abstract":"The Householder Symposium gathers the world's most active researchers in numerical linear algebra once every three years to review advances in the field, present recent theoretical and practical results, assess where the field is headed in the near future, and to provide an intimate atmosphere to foster close personal interaction and exchange of ideas. Key subjects that will be emphasized at the symposium include the solution of large systems of linear equations, eigenvalue problems, preconditioning, perturbation theory, least squares, integral equations, and applications in many different aspects of scientific and engineering computation, including control, systems and signal processing, data-mining, data compression, and bio-engineering. Many reseachers in numerical linear algebra consider the Householder Symposium to be the most important and influential meeting in the field.<br\/><br\/>This project supports the travel of junior U.S. researchers to the 16th Householder Symposium on Numerical Linear Algebra to be held May 23--27, 2005 in Champion, Pennsylvania. The funds are for travel expenses for U.S. graduate students and recent Ph.D.s who would otherwise be unable to attend. The NSF funds will permit full participation by the most promising junior members of the U.S. numerical linear algebra community. As the Householder Symposium is traditionally a gateway conference into the field, participation of junior scientists is essential. U.S. participation in the Symposium will have a positive impact on the continued strong competitiveness of the U.S. in the crucial discipline of numerical linear algebra. Advances in numerical linear algebra have had an enormous impact on a number of scientific fields that are important in maintaining U.S. competitiveness in science and technology. Some recent examples include the development of web search engines such as those for Google and Yahoo, algorithms used in the development of the global positioning system, eigenvalue based algorithms for face recognition that can be used in airport security, and the development of algorithms for high speed supercomputers.","title":"16th Householder Symposium on Numerical Linear Algebra; Champion, PA; May 23-27, 2005","awardID":"0432634","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["549456","450672","549376","485393","485287"],"PO":["565027"]},"98236":{"abstract":"As the pace of biological research increases, computers are being used to manage the explosive amount of biological information. Much of information relevant to biological research is recorded either as coded data in biological databases or as free text in journal articles and in annotation fields of biological databases. Natural language processing tools have shown to have the potential to decrease the difficulty of managing information in biomedical free text.<br\/>This project aims to use online resources (e.g., genetic databases, free-text corpora or machine readable dictionaries) and machine learning techniques for the construction of a biological entity tagging system that associates terms mentioned in text with entries in databases. Biological entity tagging is extremely challenging because of novelty, synonymy and ambiguity associated with terms representing biological entities in text. The project includes the construction of a biological entity dictionary and the acquisition of disambiguation knowledge using online resources. It also includes the development of dictionary lookup method and the employment of machine learning techniques for resolving ambiguity, discovering novelty, and recognizing synonymy. The research will generate several deliverables and the enriched information on gene\/protein names, bibliography, and other annotation fields will be integrated into UniProt\/PIR databases, which is an ongoing international effort on protein databases.<br\/>The project provides an opportunity of furthering the collaborations among Columbia University, Georgetown University Medical Center and University of Maryland at Baltimore County. The project also integrates educational and research activities by having graduate and undergraduate students involved in the overall project.","title":"SEI+II(BIO): BioTagger - Biological Entity Tagging Using Online Resources and Machine Learning","awardID":"0430743","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["529169","516887","390544"],"PO":["565136"]},"98247":{"abstract":"Determination of three-dimensional structures of proteins provides insight into their evolutionary origins, functions, and mechanisms. While determining atomic-detail structures by traditional methods can be expensive, time consuming, or even infeasible, coarser-grained structural characterization is often sufficient to provide significant insight. The multimodal approach to rapid, approximate protein structure integrates complementary experimental evidence from a number of sources in order to verify and discriminate among computationally predicted structures. Appropriate experiments, due to their speed, variety of information, and disjoint experimental limitations, include cross-linking, giving rough distance restraints; stability assays after mutagenesis, characterizing structural roles of residues in particular environments; and solution x-ray scattering, yielding global shape properties.<br\/><br\/>The multimodal approach is grounded in probabilistic models that evaluate consistency of data with structural features (distances, accessibilities, overall shapes). This approach takes advantage of the diversity and relative independence of the available methods, rather than seeking to integrate separate measurements into an overarching physical model. Inference algorithms then reason about posterior distributions of structures and features, avoiding false optimism in a single answer, measuring overall plausibility, assessing the available information content, and quantitating uncertainty in individual features. Associated experiment planning algorithms optimize multimodal experiments (e.g. selecting cross-linker length and specificity, and identifying optimal mutation sites) for a given analysis task, so as to efficiently utilize experimental resources while maximizing information gain. The multimodal integration mechanism is being developed, applied, and tested with published data from individual methods, and is being used to plan and interpret appropriate experiments for selected proteins of unknown structure. Active participation of graduate students expands educational activities and tools will be accessible.","title":"SEI(BIO): Integration of Multimodal Experiments for Protein Structure","awardID":"0430788","effectiveDate":"2004-09-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":[258717,"461949","511584"],"PO":["355797"]},"98016":{"abstract":"A fundamental problem in communications is that of detecting an information-carrying signal which has been transmitted over a channel subject to interference, noise and other impairments. This project studies this problem, with a special focus on the case when the structure of the transmission channel and the noise\/interference is unknown to the receiver. One typical instance of this situation is suppression of interference that consists of signals from an unknown number of other transmitters who utilize the same frequency band. This is relevant to several practical problems: multiuser detection for the third generation spread spectrum (CDMA) system, and antijamming for the Global Positioning System (GPS) or wireless communications systems, for example. In summary, the outcome of the research will help improve the quality of wireless links and enable a more efficient use of the radio spectrum. The project takes a systematic, decision-theoretic approach to the problem under study. A new paradigm is developed, where the key idea is to use mixture models (a.k.a. ``mixture of experts'') for the received data. Specific topics addressed include: 1) Formulation of a general model\/framework for communications signals via mixture densities. 2) Development of statistically sound methods for the mixture model parameter estimation. 3) Design of demodulation algorithms that utilize the mixture model formulation of the received data, and that can be integrated with soft-decision decodable GF(2) codes. 4) Algorithm design for practical problems including: suppression of interference with unknown structure; methods that can trade off between ``noise-prewhitening'' interference suppression and multiuser (joint) detection; diversity combination with an unknown number of ``significant'' paths (e.g., for CDMA or UWB); demodulation of signals with unknown modulation formats; suppression of non-Gaussian noise.","title":"Multiple Model Framework for Noncoherent Detection in Communications","awardID":"0429228","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":[258107,258108],"PO":["348215"]},"99347":{"abstract":"ABSTRACT<br\/>NSF-0438921<br\/><br\/>RZHETSKY, ANDREY<br\/><br\/>Analysis of complex subjects, such as human psychiatric disorders, is currently fragmented into multiple scientific communities, which often have little or none interactions. It is quite possible, even likely, that powerful cues to finding remedies to numerous human maladies can be found right now provided that disparate pieces of the knowledge puzzle are combined in one head. It would be even more desirable to have the unordered collection of facts substituted with a quantitative probabilistic model allowing for formal evaluations of model predictions, analysis of <br\/>discrepancies between data points, and hypothesis testing. The long-term research plan would address many issues, such as compiling the data, converting interactions into beliefs and amplifying the data associated with each node.<br\/><br\/>The test of the feasibility of this vision begins with a well-known system, cell-cycle <br\/>network in the baker.s yeast to reproduce with belief network formalism the known phenotypic effects for yeast. The goals in this analysis would be (1) define applicability boundaries of the belief network methodology as applied to pathway data, (2) demonstrate feasibility of the approach, and (3) use the resulting model as a proof-of-principle for a larger study. The next step would include modeling with belief networks the knowledge that has been compiled over a few years on autism in humans, with a focus on automated conversion of molecular interaction data into belief networks, computation of probabilities for individual interactions, incorporation of expert inputs and experiments with reasoning over the network. The PI and a graduate student will be engaged in this project.","title":"SGER: Belief Networks for Human Pathways","awardID":"0438291","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["506707"],"PO":["565136"]},"98258":{"abstract":"ABSTRACT<br\/><br\/>Storage of biomolecular sequences, and accessing them to determine sequence homologies is central to the current revolution in bioinformatics and computational biology. Besides search tools, the large size of biological data used by some important applications underscores the need for developing efficient out-of-core algorithms. The goal of the project is to design storage structures, algorithmic techniques, and software for disk-resident sequence data, and apply it to important applications in computational biology. To achieve this<br\/>goal, a three-pronged strategy is used: Firstly, application requirements identified in collaboration with domain experts are being used to design fundamental storage structures for sequence data. This research spans the development of efficient out-of-core algorithms for well-known in-core data structures and also the design of new data structures suitable for targeted applications. Secondly, efficient algorithms for queries on disk-resident sequence data are being developed. Finally, the out-of-core techniques developed are integrated with application software in computational genomics such as EST clustering and fragment assembly. The goal is to develop faster algorithms, reduce the exorbitant main-memory requirements, or enable solution of larger problem instances, as appropriate.<br\/><br\/>The results of the research will be made accessible to computer scientists<br\/>in the form of software libraries and molecular biologists in the form of application software. Efforts are being made to integrate the results of this research into popular tools used by molecular biologists. The interdisciplinary nature of the project is providing unique training opportunities for graduate students.","title":"Efficient Representation and Manipulation of Large-Scale Biological Sequence Data","awardID":"0430853","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["531658","565135"],"PO":["565136"]},"98027":{"abstract":"The focus of this research proposal is to develop tool support to provide the ability for scientific programmers to inquire about scalability problems and correlate this information back to source code. Furthermore, we believe that tools should be able to suggest and evaluate optimizing transformations to alleviate these problems. This would constitute a significant improvement over current performance analysis practice.<br\/>The key intellectual merit is in providing an automatic framework for detecting scalability problems and<br\/>correlating them back to source code. We will experiment with our framework on the ASCI codes, which<br\/>is intended to stress high-performance clusters.<br\/>The broader impact of this work is in three main areas. First, both PIs are working to create an interdisciplinary educational and research program. Second, students will be educated in high-performance<br\/>computing. Finally, the proposed work allows for technology transfer to a wide arena of emerging fields,<br\/>such as cluster computing as well as the established areas of SMPs and massively parallel computing.<br\/>The developed framework and tools will be made generally available to the research community and high-performance computing labs.","title":"Collaborative Research: Efficient Detection and Alleviation of Scalability Problems","awardID":"0429285","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["517411"],"PO":["565272"]},"98269":{"abstract":"As multimedia processing and networking technologies, products and<br\/>services evolve, the number of people communicating interactively<br\/>is growing rapidly. Consequently, multimedia communication<br\/>services are starting to consume a considerable share of the<br\/>backbone traffic. This highlights the problem of transmitting<br\/>real-time media efficiently. Effective multimedia communication<br\/>demands appropriate media-aware and application-specific<br\/>solutions, without which the full benefits of such services will<br\/>not be realized. Poor approaches often lead to such system<br\/>performance degradations as unacceptable presentation quality<br\/>perceived by the clients, possible network collapse due to the<br\/>high-bandwidth nature of multimedia applications, and poor<br\/>performance observed by other network flows due to the<br\/>unresponsiveness of such applications.<br\/><br\/>Given the fact that existing protocol suites are unable to provide<br\/>the desired features, the study of media-aware transport protocols<br\/>is overdue. The focus of this research is on the design and<br\/>evaluation of end-to-end solutions for reliable multimedia<br\/>services. Nonetheless, it is a challenging task to develop a<br\/>generic solution that can satisfy the needs of the broad range of<br\/>multimedia applications available today. Such an approach would<br\/>result either in an unnecessarily complicated protocol that is far<br\/>beyond real implementation or in a very high-level one that cannot<br\/>exploit the specific features of the media. The investigators' aim<br\/>is to develop a suite of Multimedia Transport Protocols (MMTP)<br\/>that integrate media properties, application requirements, and<br\/>network characteristics in such a way that the presentation<br\/>quality is optimal in the rate-distortion sense.","title":"Enhancing the Multimedia Experience in Emerging Networks: Rate-Distortion Optimization in Multimedia Networking","awardID":"0430907","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["347935"],"PO":["348215"]},"87049":{"abstract":"Online Data Migration<br\/><br\/>Current demand for scalability in databases leads to an architecture of loosely-coupled computer nodes which can be expanded or contracted at will. Demand for 24\/7 availability leads to requirements for online reorganization. To satisfy these demands, this project develops algorithms for migrating data from one node to another in a distributed system while still allowing users to access the data. First, several schemes for deciding which data to move are considered. While the goal is load balancing, performance of the migration algorithm itself is also a consideration. Algorithms must move only a small amount of the data, not reassign everything to a new node. Experiments are run to measure the \"goodness\" (coefficient of variance) of load balancing as well as the cost of migration. Second, index maintenance during migration is considered. When only a relatively small amount of data is moved, creating new indexes is more expensive than merging indexes or index entries of moved data into already existing indexes at destination nodes. This merging process must also be online so that users have access to all the data almost all of the time. Experiments measure both efficiency and concurrency for index merging algorithms. Broader impacts of this research include (1) educating the future educators of our technological workforce, (2) enabling efficient online reorganization of massive databases, such as occurs when government agencies are combined and (3) aiding the database industry in satisfying customer demand for scalability and 24\/7 availability. More information about this project is available at http:\/\/www.ccs.neu.edu\/research\/dblab\/","title":"Online Data Migration","awardID":"0328393","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["289452"],"PO":["469867"]},"90360":{"abstract":"The central thesis of this project is that the area of Internet measurements has matured to the point that it can advance from a descriptive to an operational role. Measurements, collected passively or actively at end-hosts, routers, or edge devices and proxies, can be fed back and used in applications, transport protocols, packet forwarding engines, and routing mechanisms. The project aims at the design and evaluation of important network mechanisms driven by measurements. Three such mechanisms are the following.<br\/><br\/> Techniques for the auto-configuration of major router processes, such as buffer management, based on passive measurements in router interfaces<br\/><br\/> Dynamic route selection, driven by active edge-to-edge performance measurements and congestion prediction <br\/><br\/> Transport optimizations for high-bandwidth long-distance networks, using recently developed bandwidth estimation techniques.<br\/><br\/>The focus on measurements is integrated in the project's research and education aspects. A major educational objective is to bring network measurements into the classroom as a learning and visualization tool. The PI is going to create an Internet measurements graduate course, lso covering \"network statistics\", i.e., a collection of statistical tools for the analysis of network measurements. <br\/><br\/>The project can have a significant technological, economic, and social impact. A wide-scale deployment of network measurements as an operational tool can improve the Internet's performance, resilience, and robustness, and enable new services and applications. The tools, prototypes, and learning material being developed are made publicly available. Finally, the integration of measurements in the curriculum changes radically the way in which computer networking is being taught.","title":"CAREER: Putting Network Measurements to Work - Design & Evaluation of Measurement-Driven Network Mechanisms","awardID":"0347374","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["550447"],"PO":["402055"]},"93540":{"abstract":"This project proposes to develop a framework for hardware-assisted speculative program optimization (H-SPOT). H-SPOT optimizes programs aggressively based on actually observed program properties by speculatively performing optimizations that are profitable but cannot be guaranteed to be safe at static compile time. The project develops a transactional processor model that provides architectural support to ensure the correctness of optimizations at run time. <br\/><br\/>The project's technical contributions are: (1) The H-SPOT compiler that provides a <br\/>reformulation of compiler optimizations to apply them even in cases when traditional static compilers would not be able to perform them. It implements dynamic program analysis to obtain information about program properties and uses a cost-benefit model to apply the most promising optimizations. The compiler also develops a static recovery and fix-up code analysis to determine the run-time actions required to ensure the correctness of optimized programs.","title":"NGS: Collaborative Research: Transactional Execution: Making Unsafe Compiler Optimizations Work at Run Time","awardID":"0406265","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["342332"],"PO":["301532"]},"102071":{"abstract":"EIA-0218359<br\/>Hao Yan <br\/>Duke University<br\/><br\/>Molecular Robotics for DNA Nanostructures<br\/><br\/>The objective of this project is to develop molecular motors that are incorporated into self-assembled DNA lattices. The main goal of this project will be to develop experimental proof-of concept demonstrations of the construction of novel DNA motors such as a DNA motor that is designed to have both translational and rotational motion. Incorporation of molecular motors into DNA arrays has many applications: It can selectively manipulate molecules using molecular motor devices arranged on DNA tiling arrays; A DNA array of motors may offer a mechanism to do DNA computation of arrays whose elements (the tiles) hold state; Parallel cellular automata computation may be executed from arrays of finite state automata each of which hold state. This project is also developing DNA nanostructures containing motors that operate autonomously without environmental changes. Methods are being tested to use \"fuel DNA\" to provide energy to drive the motion of DNA nanostructures. As an alternative approach, experiments are conducted to incorporate protein motors such as Kinesin into DNA lattices. In particular, the use of selective aptamer binding to link protein motors to periodic sites of a DNA lattice will be tested. The resulting arrays of protein motors have many applications to nanorobotics, e.g., they are potentially very useful for sorting and transport of nanoparticles.","title":"QuBIC: Molecular Robotics for DNA Nanostructures","awardID":"0453686","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["555498"],"PO":["521045"]},"92484":{"abstract":"In this project, Avigad and Friedman propose to develop a theoretical base<br\/>in mathematical logic to support the development of mechanized proof<br\/>assistants for mathematics. They propose to study the definitional structure<br\/>of mathematics, and characterize the ways that definitions are used in<br\/>practice; to study the methods of inference commonly used in elementary<br\/>reasoning in number theory, real analysis, and set theory, and to develop of<br\/>algorithms that can mirror these forms of inference; and to develop an<br\/>enriched theory of mathematical proof to characterize and classify the<br\/>various ``indirect'' methods that are used in mathematical reasoning. A<br\/>novel aspect of the proposal is the attention Avigad and Friedman will give<br\/>to actual data, i.e. specific formal developments. In particular, Avigad<br\/>will complete a mechanically verified proof of the prime number theorem, and<br\/>is developing a broad number theory library, using a proof system called<br\/>Isabelle; and Friedman has begun a fully formal development of set theory<br\/>using in a notational framework of his own devising, with an emphasis on<br\/>readability, for a broad audience.<br\/><br\/>This research is intended to contribute to the general goal of devising<br\/>better computer support for the development, manipulation, storage, and<br\/>communication of mathematical knowledge. In particular, formal mathematical<br\/>libraries and means of handling them are important to verify the behavior of<br\/>hardware and software systems, for example, and to support scientific<br\/>computing and cryptography. It is well understood that the development of<br\/>useable proof assistants will have to combine pure logical considerations<br\/>with pragmatic engineering concerns. However, in today's specialized<br\/>academic environments, the relevant communities have become largely<br\/>disjoint. Avigad and Friedman are committed to bridging the gap, by<br\/>developing powerful theory that is guided by, and designed to support, sound<br\/>practice.","title":"Collaborative Research: Theoretical Support for Mechanized Proof Assistants","awardID":"0401265","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1268","name":"FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["508444"],"PO":["565280"]},"97962":{"abstract":"Abstract<br\/>ITR-(ASE+NHS)-(int): A Digital System Paradigm For Yield Enhancement and Graceful Degradation Via Error Acceptance<br\/><br\/>Despite extensive research into improving fabrication processes, continued VLSI scaling will be inhibited by high variations in process parameters, higher defect densities, and higher susceptibility to external noise. We propose two notions, namely error-tolerance and acceptable operation, to facilitate imprecise computation: these notions systematically capture the fact that an increasingly large class of digital systems can be useful even if they do not perfectly conform to a rigid design specification. We propose to develop a systematic methodology for design and test of this class of digital systems that will exploit the notion of error tolerance, to enable dramatic improvements in scale, speed, and cost. In the proposed methodology, system specification will include a description of the types of errors at system outputs, and the thresholds on their severities, that are tolerable. The design methodology will exploit this information to obtain designs that provide higher performance and\/or lower costs.<br\/><br\/>Over the next 15 years, the proposed approach will provide dramatic improvements in scale, speed, and cost for a wide class of digital systems, including many integral to NHS. This will enable development and wider deployment of devices with advanced capabilities in areas such as speech processing, real-time translation of spoken natural languages, and biometrics.","title":"ITR-(ASE+NHS)-(int): A Digital System Paradigm For Yield Enhancement and Graceful Degradation Via Error Acceptance","awardID":"0428940","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["451942","535238","451991",257944],"PO":["562984"]},"98820":{"abstract":"NeTS-NR: Efficient and Localized Broadcasting in Ad Hoc Wireless Networks<br\/><br\/>Jie Wu, Florida Atlantic University<br\/><br\/>Award 0434533<br\/><br\/>Abstract<br\/><br\/>Collective communication represents a set of important communication functions that involve multiple senders and receivers. Broadcasting is one of the fundamental operations and has extensive applications, including the route discovery process in reactive routing protocols, naming and addressing, and dense mode multicasting. Due to the broadcast nature of wireless communication, blind flooding of the broadcast message may cause serious contention and collision, resulting in the broadcast storm problem. This project studies the challenge of efficient and localized broadcasting in ad hoc wireless networks by offering a generic framework that can capture many existing localized broadcast algorithms and, in addition, some efficient solutions can be derived from this framework. This research has six thrusts: (1) Provide a more generic framework for deterministic and localized broadcasting in ad hoc networks, including constructing consistent views. (2) Derive cost-effective broadcast schemes from the framework. (3) Reduce excessive broadcast redundancy through energy-efficient design,. (4) Explore the use of broadcasting as a basic building block to support other types of collective communication. (5) Ensure broadcast coverage with controlled redundant transmission without solely relying on ACK\/NACK. (6) Integrate different components and fine tune the system through an empirical study based on a set of well-defined quantitative performance metrics. The new framework can easily integrate other objectives such as energy-efficiency and reliability. The results of this research will provide guidelines for efficient and localized algorithms for a wide range of applications. This research will also exploit and contribute to theoretical studies in graph theory and distributed algorithms.","title":"NeTS: Efficient and Localized Broadcasting in Ad Hoc Wireless Networks","awardID":"0434533","effectiveDate":"2004-09-01","expirationDate":"2009-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["366922","7594"],"PO":["564777"]},"98941":{"abstract":"In addition to the traffic growth in the Internet, new applications and services are imposing a large variety of requirements. At the same time, the emergence of network applications on video, audio, business services, and other data ser-vices is creating an imminent demand for integration of most traffic with de-fined quality of service (QoS) guarantees. Examples of emerging network re-quirements are directly related to reliability, recoverability, and security. Al-though most of these requirements have kindled research interests in recent years, it is still unclear how to integrate them for next generation networks. To manage the increasing variety of QoS requirements, this research project pro-poses a new service model concept, called service vector, as a solution for pro-viding QoS support for a large variety of traffic classes. This concept is expected to help achieving the following objectives: a) robust differentiated service model capable of supporting fine QoS granularity; b) scalability; c) satisfaction of the users' customized end-to-end requirements; d) improved network operator revenue; e) higher utilization of the current Diffserv network model. The com-plexity and feasibility of service vectors for the next generation networks is in-vestigated, and the impact on router architectures and deployment issues are considered for the implementation of service vectors in new-generation and de-ployed routers.","title":"NeTS-NR: Networks with Extended Quality of Service using Service Vectors","awardID":"0435250","effectiveDate":"2004-09-15","expirationDate":"2008-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550852",260816,"348215","269272",260819,260820,"416405"],"PO":["565090"]},"98952":{"abstract":"NeTS - NR: Ad hoc Congestion Control for Mobile Ad Hoc Networks<br\/><br\/>Saad Biaz, Auburn University<br\/><br\/>Award 0435320<br\/><br\/>Abstract<br\/><br\/>This project is developing ad hoc end-to-end congestion control techniques particularly adapted to mobile ad hoc networks (MANETs). In mobile ad hoc networks, frequent link failures and other random losses unrelated to congestion disqualify packet loss as a reliable congestion indicator and require ad hoc congestion control algorithms that must (1) accurately diagnose the real cause of a loss and (2) appropriately react to each type of loss. The research team is investigating an innovative direction to develop an accurate loss discriminator and an implicit continuous congestion measure that is based on packet loss and yields better performance. The key to solving these problems is to \"de-randomize\" congestion losses. This is achieved by marking packets with different discard priorities and enabling biased queue management at all intermediate nodes so that they may target and drop packets with the highest discard priority when congestion occurs. A judicious marking allows senders to implicitly estimate congestion. This project attacks theoretical and systems challenges and will enable the practical deployment of MANETs. In addition, such challenges will help attract and educate talented graduate students and retain the brightest undergraduate students.","title":"NeTS - NR: Ad hoc Congestion Control for Mobile Ad Hoc Networks","awardID":"0435320","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["505916"],"PO":["434241"]},"96301":{"abstract":"Title: ITWF Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science<br\/><br\/>CNS 0420436, PI Horwitz, Univ. of Wisconsin-Madison<br\/>CNS 0419340, PI Huss-Lederman, Beloit College<br\/>CNS 0420312, PI Munson, Univ. of Wisconsin-Milwaukee<br\/>CNS 0420337, PI Dunsmore, Purdue University<br\/>CNS 0420343, PI Rodger, Duke University<br\/>CNS 0420358, PI Binkley, Loyola College of Maryland<br\/>CNS 0420368, PI Biggers, Georgia Institute of Technology<br\/>CNS 0420433, PI Ryder, Rutgers University<br\/><br\/><br\/>This collaborative ITWF project implements a new approach to introductory computer science with the goal of increasing the enrollment and retention of women and under-represented minorities in undergraduate computer science degree programs. The project adapts the Emerging Scholars Program and the Peer-led Team Learning approaches, which have been proven successful in mathematics and other sciences, to computer science. It is a collaborative project between the University of Wisconsin-Madison, Beloit College, Duke University, Georgia Institute of Technology, Loyola College of Maryland, Purdue University, Rutgers University, and the University of Wisconsin-Milwaukee. The project includes targeted recruitment of students with strong mathematics and science backgrounds to the new course. The course includes students working in small groups on challenging problems with group facilitation by outstanding undergraduates.<br\/><br\/>The intellectual merit of this project lies in the strong basis on models that have been successful in other disciplines. The collaborative represents a team of investigators with significant expertise in educational reform and transformation. Implementation will take place at the diverse set of institutions represented by the collaborative partners, thus providing an excellent environment for evaluation of this innovative approach and illustrating the possibilities for replication and adoption by a wide range of institutions.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science. The method to be tested is relative low cost and straightforward to implement, thus it has a high potential for broad impact across the country.","title":"ITWF: Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science","awardID":"0420343","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["465198"],"PO":["361119"]},"98963":{"abstract":"Proposal Number: 0435382<br\/>PI: Bruce Maggs<br\/>Institution: Carnegie Mellon University <br\/>Title: A Measurement-Driven Approach to Internet Protocol and System Design<br\/><br\/>Abstract: <br\/><br\/>The sheer size and complexity of the Internet today has made it difficult for network researchers to evaluate the impact that protocol changes may have on its operation. The basic problem is that it is difficult to deploy new protocols widely enough for testing purposes. In response, this project uses a novel approach (Measurement-Driven Protocol Design) that combines large-scale measurements of the Internet with the design of new protocols. Large-scale measurements enable accurate emulation- and simulation-based evaluation of protocol behavior and, thus, are the key to doing the \"what if\" analysis for many protocol designs. This measure-to-evaluate approach enables the project to make significant contributions to the areas of protocol and system design. <br\/><br\/>This project develops this new methodology as part a number of specific research thrusts that, in combination, push the state-of-the-art in both standard IP and overlay routing. Specifically, the project expects to make the following major contributions: 1) novel designs for wide-area IP routing incorporating techniques for diagnosing inter-domain routing problems and inter-domain traffic engineering, 2) significant improvements to overlay routing through new streaming multimedia overlay designs and reflector networks optimizations, and 3) optimization of access networks' performance and availability using a novel combination of overlay and IP routing techniques.<br\/><br\/>In addition to the methodology and protocols developed, a significant fraction of the measurements made as part of this research will be made available for research and education. In order to make them available, this project also explores anonymization techniques for network measurements.","title":"NeTS-NR: A Measurement-Driven Approach to Internet Protocol and Systems Design","awardID":"0435382","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"I266","name":"National Security Agency"}}],"PIcoPI":["551078","458795","435983"],"PO":["565090"]},"96312":{"abstract":"Title: ITWF Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science<br\/><br\/>CNS 0420436, PI Horwitz, Univ. of Wisconsin-Madison<br\/>CNS 0419340, PI Huss-Lederman, Beloit College<br\/>CNS 0420312, PI Munson, Univ. of Wisconsin-Milwaukee<br\/>CNS 0420337, PI Dunsmore, Purdue University<br\/>CNS 0420343, PI Rodger, Duke University<br\/>CNS 0420358, PI Binkley, Loyola College of Maryland<br\/>CNS 0420368, PI Biggers, Georgia Institute of Technology<br\/>CNS 0420433, PI Ryder, Rutgers University<br\/><br\/><br\/>This collaborative ITWF project implements a new approach to introductory computer science with the goal of increasing the enrollment and retention of women and under-represented minorities in undergraduate computer science degree programs. The project adapts the Emerging Scholars Program and the Peer-led Team Learning approaches, which have been proven successful in mathematics and other sciences, to computer science. It is a collaborative project between the University of Wisconsin-Madison, Beloit College, Duke University, Georgia Institute of Technology, Loyola College of Maryland, Purdue University, Rutgers University, and the University of Wisconsin-Milwaukee. The project includes targeted recruitment of students with strong mathematics and science backgrounds to the new course. The course includes students working in small groups on challenging problems with group facilitation by outstanding undergraduates.<br\/> <br\/>The intellectual merit of this project lies in the strong basis on models that have been successful in other disciplines. The collaborative represents a team of investigators with significant expertise in educational reform and transformation. Implementation will take place at the diverse set of institutions represented by the collaborative partners, thus providing an excellent environment for evaluation of this innovative approach and illustrating the possibilities for replication and adoption by a wide range of institutions.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science. The method to be tested is relative low cost and straightforward to implement, thus it has a high potential for broad impact across the country.","title":"ITWF: Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science","awardID":"0420368","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["425936"],"PO":["361119"]},"93045":{"abstract":"Abstract<br\/><br\/>This proposal was received in response to Nanoscale Science and Engineering initiative, NSF 03-043, category NIRT. The project will explore biological nanoarchitecture and apply this knowledge to create ordered arrays of quantum dots and semiconductor nanowires. The focus of the research is on S-layers, self-assembling protein arrays found in bacteria. Learning from self-assembling biological nanostructures such as S-layers will provide a framework for novel approaches to fabricating nanometer features over a large-scale area, which remains a major challenge in nanotechnology. Moreover, the successful fabrication of nanostructuresbio-templated using S-layers will provide a unique opportunity to study collective quantum effects.<br\/><br\/>The future of nanoscale devices will depend upon the discovery of an increasing array of novel materials which have robust properties and can be vast number of materials and along with a systems engineering approach these materials can be vastly improved. Bioinspired nanoarchitecture will find utility in existing devices and also spawn a new generation of devices with functionalities that have yet to be fully realized with existing materials.","title":"NIRT: Bioinspired Nanoarchitecture","awardID":"0403990","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["480057","529834","503138","520332","553959"],"PO":["550859"]},"98985":{"abstract":"NeTS-ProWiN: Spectrum-Agile Wireless Available Networking (SWAN)<br\/><br\/>Jose Garcia-Luna-Aceves, University of California-Santa Cruz<br\/><br\/>Award 0435522<br\/><br\/>Abstract<br\/><br\/>Ad hoc networks demonstrated to date operate on pre-assigned portions of the spectrum, which limits their connectivity and the efficiency with which the available spectrum is used. Ad hoc networks are assumed to work independently of the Internet and attach to it only through a few access points. Furthermore, wireless routers are considered to be different from Internet routers, and routing in ad hoc networks today is independent of spectrum management or the availability of wired links.<br\/><br\/>The SWAN (Spectrum-Agile Wireless Available Networking) project addresses the above limitations by enabling wireless spectrum utilization in far more efficient ways than it is possible today, and by making wireless links an integral part of the Internet. The expected results in SWAN include:<br\/><br\/>(a) Wireless Available Networking: SWAN will develop an architecture and protocols that transform the concept of ad hoc networking into wireless available networking, such that Internet routers use radio links opportunistically, in much the same way as wired links are used today by routers.<br\/><br\/>(b) SMASH (Statistical Multiplexing of Available Spectrum Heuristics): SWAN will develop algorithms, protocols, and etiquettes for the dynamic sharing of the available spectrum based on the statistics of information flows. This way, routers determine in a distributed fashion which portion of the spectrum they can use.<br\/><br\/>(c) Policy-based Routing: SWAN will develop the first policy-based routing protocols for wireless enabled networks, with which routers manage the topology and paths of wired and wireless portions of the Internet based on administrative, quality-of-service, and spectrum-utilization policies.","title":"NeTS-ProWiN: Spectrum-Agile Wireless Available Networking (SWAN)","awardID":"0435522","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["348220","286112","535214"],"PO":["557315"]},"97786":{"abstract":"Title: ITR: COLLABORATIVE RESEARCH - (ASE+NHS) - (int): BFT-LS: Byzantine Fault Tolerance for Large-Scale, High-Performance Distributed Storage Systems<br\/><br\/>Reliance on information available over the Internet is increasing every day. At the same time, the number of malicious attacks is growing. Nevertheless, it is critical that online information be stored reliably: information must not be lost, must be accessible when needed, and what a user sees must be what is actually stored. These requirements must be satisfied in spite of malicious attacks on the network or the storage nodes. This project concerns research on a new storage system, BFT-LS (Byzantine Fault Tolerance - Large Scale), that satisfies these requirements. <br\/><br\/>BFT-LS is designed to support five main goals: (1) Reliability. BFT-LS provides extremely reliable storage: stored objects are not lost, are available when needed, and are uncorrupted, in spite of malicious attacks and Byzantine failures in which a node behaves arbitrarily badly. (2) Automatic Reconfiguration. BFT-LS is a dynamic system that reconfigures itself automatically, thus enhancing reliability by reducing reliance on operators. BFT-LS also allows nodes to be added to replace failed nodes and to improve service under increasing load. (3) Application Independence. BFT-LS provides a flexible interface that meets the needs of many applications, including file systems and databases. (4) Extended Semantics. BFT-LS supports atomic transactions that can read and write many objects. In addition, read-only transactions can run in the recent past yet are guaranteed to see a consistent state. (5) Efficient access at large scale. BFT-LS is intended to run efficiently at very large scale: it must store a vast quantity of state that is accessed by huge numbers of users who are physically located all over the world. It provides an infrastructure that allows clients to us data cached nearby, rather than communicating with far-away storage nodes. Nearby nodes aren't trusted, however; instead a new reliable stream mechanism ensures data validity.<br\/><br\/>BFT-LS is expected to provide greater functionality than earlier work while also providing outstanding performance. Its extended functionality not only requires innovative new solutions in many areas, but also makes the system more generally useful because it can support a wide range of applications.","title":"ITR: Collaborative Research: (ASE+NHS) - (int): BFT-LS: Byzantine Fault Tolerance for Large-Scale, High-Performance Distributed Storage Systems","awardID":"0427408","effectiveDate":"2004-09-15","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["550086"],"PO":["561889"]},"98765":{"abstract":"Pattern classification problems that arise in natural language processing applications, such as parsing, machine translation, and speech recognition, are more complex than those commonly addressed with statistical learning methods. The broad goal of this research project is the design and analysis of statistical learning algorithms that are suitable for these problems. The research is focused on the following questions, which are motivated by characteristic properties of complex pattern classification problems in natural language processing: methods for multiclass classification with desirable statistical and computational properties; methods for structured classification, where the predicted variables come from a large set with a rich structure (for example, predicting the parse tree of a sentence); the extension of these methods to problems with hidden variables, that is, where some relevant data is not observed; and complex nonparametric models for these problems, in particular, computationally efficient nonparametric Bayesian methods based on hierarchical Dirichlet processes. The methods developed will be validated empirically on parsing, machine translation, and speech recognition problems.<br\/><br\/><br\/>The research project is aimed at the development and analysis of statistical learning methods for complex decision problems, such as those that arise in natural language processing. A key goal of research in natural language processing is the development of automated systems, such as translation systems and dialogue systems. The most successful approaches involve the use of statistical methods to exploit language data, such as a text corpus. However, the decision problems that arise are very complex. A good example is the problem of parsing, or recovering the syntactic structure underlying sentences in a language. For such problems, the set of candidate decisions is very large, and possesses considerable structure. This research project is aimed at developing computational and statistical methods that are suitable for complex decision problems of this kind. Successful methods are also likely to have a significant impact in other areas of computer science, including computer vision and bioinformatics, because similar complex decision problems also arise in these areas.","title":"MSPA-MCS: collaborative research: Statistical Learning Methods for Complex Decision Problems in Natural Language Processing","awardID":"0434222","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["508222"],"PO":["336837"]},"97797":{"abstract":"Award Abstract<br\/><br\/>Environmental problems related to natural resource management span a wide variety of spatial, temporal and biotic hierarchy levels. Resource managers are charged with local, short-term decisions regarding controlling access and types of use for sub-areas within larger natural areas, as well as much longer-term planning for entire areas as large as many thousands of hectares. Similarly, regional-scale planning for water flows, hunting regulations, preserve allocation, and forest harvesting requires stakeholders to provide input to the process, and such planning has led to numerous contentious public debates throughout the US. The main objective of this project is the development of computational tools, utilizing grid-computing, to assist natural resource managers in assessing the impacts of alternative management plans. The central theme of this proposal is that evaluating the impacts of human actions to manage natural systems requires the use of computational models utilizing the best available science to analyze potential effects. To be effective, such models must be defensible scientifically, readily available to various stakeholders and extensible to allow new users to evaluate alternative plans, assumptions and choices of criteria to prioritize management actions. This requires the use of computational ecology to develop models, visualize these models, consider alternative human controls within these models and analyze from an optimization perspective the various controls, based upon social choice criteria that may vary from stakeholder to stakeholder.<br\/><br\/>Due to the variety of scales involved in natural resource management, the use of a multimodeling<br\/>approach is appropriate. In this, different models with potentially different mathematical and<br\/>computational forms are chosen for different components of the system, based upon the necessary levels of detail and available data for different components. These models are linked into a multimodel to evaluate the interactions of biotic and abiotic components. Grid computing provides a natural framework to develop toolsets for ecological multimodels due to the dispersed nature of datasets, software and computational resources, in addition to the general lack of appropriate hardware at many natural resource agencies. The challenges go well beyond the current state-of-the-art in geographic information systems, requiring spatially-explicit dynamic models linked to spatio\/temporal optimization schemes. Courses for managers and the engagement of underrepresented groups are planned.","title":"ITR: Grid Computing for Ecological Modeling and Spatial Control","awardID":"0427471","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["541004","557696","398611"],"PO":["565136"]},"98897":{"abstract":"Abstract: <br\/><br\/>Programming wireless sensor networks is notoriously difficult because of severe resource constraints for sensors, unstable and low-bandwidth communication links, unreliable nodes, inaccessible and hostile deployment environments for certain applications, and potentially a large number of nodes. To ease the building of sensor network applications, the objective of this research is to develop a high-level programming abstraction that facilitates resource-efficient, data-centric, and trustworthy computing for large-scale sensor networks, and is applicable to a wide range of sensor network applications.<br\/><br\/>This approach involves designing a sensor coordination model called active dataspace (ADS), an active data repository that provides associative operations for data access, and developing techniques to implement the ADS model in a resource-efficient, robust, and trustworthy fashion. This research extends previous work on the tuple space coordination model to address the challenges for sensor networks.<br\/>Specifically, the ADS model presents a novel construct called virtual tuple that supports a data-on-demand strategy to conserve the resources of data producers when their services are not needed, and presents constructs that facilitate in-network aggregation and exploiting locality.<br\/><br\/>This research is expected to provide an effective means to develop sensor network applications for a wide range of problem domains and to impact education through student participation. The results will be disseminated through papers and the Web.","title":"NeTS-NOSS: Sensor Coordination using Active Dataspaces","awardID":"0434997","effectiveDate":"2004-09-01","expirationDate":"2007-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[260667],"PO":["543507"]},"99414":{"abstract":"The project will investigate how the media, especially digital media, help define the boundaries between private and public life. The main focus of the project is a four month study, to be conducted Sept.-Dec. of 2004, of how 30 carefully selected subjects actually use various media to satisfy their private consumption desires, engage public issues, and construct the boundaries between the two. A second component of the project involves content analysis of a broad range of popular internet sites to map the ways in which the connections between public and private life are drawn. The study is timed to take advantage of the increased societal concern with public issues associated with the 2004 U.S. Presidential election, as well as the months immediately following when people typically pay less attention to public life. The project will employ a combination of qualitative ethnographic methods, as well as interpretive and more formal content analyses of internet sites and subjects' media diaries. <br\/><br\/>Broader Impacts: There is a general perception within the research community that the internet has yet to live up to its supposed potential for invigorating democratic life. Voter turnout remains low; citizen engagement seems largely unchanged. This project will provide information useful to policymakers as they seek to develop ways of employing digital technologies for enhancing American democratic life. It will shed light on how various technologies are likely to actually be used by a wide range of citizens. The results will be of use to those (including socially minded corporations conducting e-commerce) interested in furthering civic engagement, by providing insights into how to better design web sites and take advantage of the ways in which citizens use different types of media to pursue public concerns. The project involves collaboration with scholars from other disciplines in other countries that will cross-train student researchers in political science, sociology, public policy, business, computer science, and communication.","title":"Sger: Connecting The Private To The Public: New Information Technologies And The Future Of Public Life","awardID":"0438803","effectiveDate":"2004-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":[262216,262217],"PO":["564456"]},"98325":{"abstract":"Many geophysical simulations and nearly all climate models archive their results in hundreds to thousands of files spanning gigabytes to terabytes of storage. Before the geophysicist can interpret these data, it must be reduced to a manageable size (e.g., by averaging it) and\/or transported to a specified location (e.g., the desktop computer). Currently researchers often copy raw data over the Internet from multiple locations to commence their data analysis. This project is developing the Scientific Data Operators (SDO): efficient software that lets researchers perform typical data reduction and analysis in parallel, remotely, without wasting time and network bandwidth.<br\/><br\/>The SDO software combines distributed and shared memory programming, client-server architecture, and Open Source development techniques. As proof-of-concept, a distributed analysis of multiple NCAR CCSM IPCC climate assessment simulations (each is about a terabyte) within and across national boundaries will be performed. This project also provides support for a graduate student to carry out dissertation research in distributed climate analysis. Outside climate modeling and analysis, SDO will have three main impacts: (1) increase the value of large geophysical datasets by decreasing the time to analyze, discover, and publish new results; (2) reveal any critical bandwidth, I\/O, and client\/server bottlenecks in processing distributed geophysical data; and (3) improve analysis of growing bioinformatics data sets, especially gene expression data, in ways similar to the geophysics domain. SDO is free software based on the internationally successful netCDF Operator (NCO) software. The project results including this software will be accessible via the project web site.","title":"SEI(GEO): Scientific Data Operators Optimized for Efficient Distributed Interactive and Batch Analysis of Tera-Scale Geophysical Data","awardID":"0431203","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["338406"],"PO":["563727"]},"98215":{"abstract":"Abstract:<br\/>--------<br\/><br\/>In a semidefinite programming (SDP) problem, a linear function of<br\/>a symmetric matrix variable $X$ is minimized subject to linear<br\/>equality constraints on $X$ and the essential constraint that $X$<br\/>be positive semidefinite. Many mathematical optimization problems<br\/>can be cast as SDP problems including linear programming (LP) problems,<br\/>convex quadratic problems with convex quadratic inequality constraints,<br\/>matrix norm minimization problems, and a variety of maximum and<br\/>minimum eigenvalue problems. In addition, SDP has many<br\/>applications in combinatorial optimization, engineering,<br\/>statistics, and robust optimization.<br\/><br\/>Today, there are numerous algorithms and codes available for<br\/>solving LPs, SDPs, and other cone programs,<br\/>and these methods can be loosely grouped into three types:<br\/>second-order interior-point (IP) methods based on exact linear solvers,<br\/>second-order IP methods based on iterative linear solvers, and first-order<br\/>nonlinear programming (NLP) methods. The choice of which type to<br\/>use for a particular application is determined primarily by<br\/>problem size --- second-order IP methods based on exact linear solvers<br\/>are more efficient on small- to medium-scale problems while<br\/>first-order NLP methods and second-order IP methods based on iterative<br\/>linear solvers are better for large-scale problems.<br\/><br\/>Second-order IP algorithms for SDP are derived from similar<br\/>algorithms for LP and, in<br\/>particular, inherit the polynomial-time complexity of IP methods<br\/>for LP. In addition, as in LP, the subclass of primal-dual methods<br\/>and their higher-order variants are very effective for solving SDP<br\/>problems practically. In contrast to LP, however, there are many<br\/>ways one can compute the Newton search directions used in<br\/>primal-dual algorithms for SDP. For this reason, the theory and<br\/>implementation of primal-dual methods for SDP is substantially<br\/>more difficult than that for LP.<br\/><br\/>First-order NLP algorithms have been developed as an alternative<br\/>to second-order IP methods (based on exact linear solvers)<br\/>for solving large-scale SDPs that arise<br\/>in certain applications, e.g., in combinatorial optimization.<br\/>These methods reformulate the SDP problem into a NLP problem that<br\/>can be solved using standard NLP techniques --- in particular,<br\/>first-order techniques that do not require as much computation as<br\/>second-order techniques. The exclusion of second-order<br\/>information, however, makes it difficult (perhaps impossible) to<br\/>establish the polynomial complexity of such algorithms.<br\/><br\/>Polynomial convergence analysis of second-order IP methods based on<br\/>iterative linear solvers is still a topic which is not well-understood.<br\/>Since these methods have the potential to outperform first-order<br\/>methods in the solution of large-scale SDP problems, it is of<br\/>paramount importance to study the theoretical and practical behavior of these<br\/>methods. This proposal will address this topic in depth first in<br\/>the context of the basic LP problem and then in the context of<br\/>other cone programming problems such as quadratic programming (QP),<br\/>second-order cone programming and SDP.<br\/><br\/>This proposal addresses the development of the theory and<br\/>implementation of algorithms for SDP and also investigates the applications<br\/>of SDP. The objectives of this research project consist of:<br\/>1) advancing the knowledge of the theory and implementation of<br\/>second-order primal-dual methods for LP, SDP and other cone<br\/>programming problems;<br\/>2) developing and implementing second-order IP algorithms based on iterative<br\/>linear solvers for LP and more general cone programs;<br\/>3) developing new and\/or improving existing algorithms and implementations for<br\/>first-order smooth and non-smooth methods for SDP;<br\/>4) enhancing the variety, applicability, usefulness, and robustness<br\/>of first-order NLP methods for SDP;<br\/>5) developing SDP heuristics for combinatorial problems based on low-rank<br\/>restricted SDP problems; and<br\/>6) develop new insights of the geometry of the central path and its<br\/>consequences into the polynomial solvability of IP methods.<br\/><br\/>This research will lead to new and improved algorithms and codes<br\/>to find exact or approximate solutions to optimization problems<br\/>arising in diverse applications in industry, finance, science, and<br\/>engineering.","title":"Cone programming: Theory, Implementation and Applications","awardID":"0430644","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["540935"],"PO":["381214"]},"99315":{"abstract":"The objective of this workshop is to bring together the PIs and Co-PIs currently funded by the Information and Data Management Program of the National Science Foundation to discuss and exchange ideas on the focus topics of their field, as well as to identify and elaborate on emerging themes and particular emphases for future activities. <br\/><br\/>More specifically, the researchers, along with selected industry and government invitees, cooperatively focused on: <br\/><br\/>(1) analyzing research and development issues fundamental in making progress towards new challenges imposed by such diverse data sources as the Internet, embedded and distributed sensors, and satellites; <br\/><br\/>(2) specifying areas where major breakthroughs appear possible and needed; and <br\/><br\/>(3) identifying collaborations (e.g., inter-disciplinary, academic-industry) and research initiatives and facilities needed to meet current and future challenges. <br\/><br\/>In addition, workshop participants shared their current research activities and accomplishments, provided demonstrations, and in general, interacted with each other and explored potential fruitful collaborations and innovative synergisms. As a result, the workshop findings are expected to influence not only the research agenda and future directions of the Information and Data Management Program of the National Science Foundation but also the technology to be developed for the next decade or so in the ways data and information are used and managed by the community at large. The workshop web site (http:\/\/csr.bu.edu\/idm2004) will provide access to reports of projects supported by the Information and Data Management Program, workshop presentations and workshop findings.","title":"Information and Data Management Program's PI Workshop","awardID":"0438087","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["391834"],"PO":["563751"]},"98105":{"abstract":"0429836<br\/>Harmony: The Art of Reconciliation<br\/>Benjamin C. Pierce<br\/><br\/>This project aims to build a generic tool for reconciling disconnected<br\/>updates to heterogeneous, structured, replicated data -- usable, for<br\/>instance, to synchronize bookmark files from different web browsers<br\/>running on multiple machines.<br\/><br\/>A central theme is bringing ideas from programming languages to bear on<br\/>problems more commonly regarded as belonging to the purview of databases<br\/>or distributed systems. In particular, a major focus concerns<br\/>developing the foundations of \"bi-directional programming languages,\" in<br\/>which every program denotes a pair of functions -- one for extracting a<br\/>view of some complex data structure, and another for putting back an<br\/>updated view into the original structure. Similarly, the issue of<br\/>alignment of information during reconciliation will be addressed by<br\/>focusing on the type structure of the data being reconciled. This<br\/>linguistic perspective may offer new insights into classical problems in<br\/>these areas, such as the well known \"view update problem\" in databases.<br\/>At the same time, reconciling complex abstract formats, such as ordered<br\/>lists and trees, brings to fore a number of algorithmic issues<br\/>concerning how to meaningfully weave together disconnected changes in<br\/>replicas.","title":"Harmony: The Art of Reconciliation","awardID":"0429836","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["563479","497006"],"PO":["564388"]},"98226":{"abstract":"Abstract<br\/>NSF-0430693<br\/><br\/><br\/>Consequences of global change for land cover, carbon cycles, and biodiversity loss involve complex interactions at fine scales, such as resource availability in forest understories, to regional land-cover, climate, and CO2. Global change research requires models developed through careful study of local phenomena that can be extended to landscape, regional, and global scales. Unfortunately, environmental scientists have been limited in their ability to determine how factors that operate at different scales impact landscapes.<br\/><br\/>The primary long-term goal of the research is to enhance the ability of biology and geoscience research programs to acquire, analyze, and distribute high-resolution GIS databases of important environmental attributes. In support of this goal the computer science team will develop new techniques to extract forest attributes in the form of GIS databases from remotely sensed data. The computer science team will build an aerial remote sensing platform and a suite of analysis tools for creating GIS databases of environmental attributes with sub-meter geo-registration and elevation accuracies.<br\/><br\/>The image acquisition, analysis and GIS tools developed by UMass and MHC <br\/>provide the critical broad-scale, yet high-resolution, data needed to parameterize and validate models used to study global change. The products of these analyses will be integrated within a modeling framework at Duke University that includes extensive field data, application of new statistical computation methods, and development of a stand simulator. The combined effort will be used to determine how diversity is maintained in forest stands based on a comprehensive accounting of environmental impacts and uncertainties.","title":"Collaborative Research: SEI(BIO)--Automated Methods for Generating High-Resolution GIS Databases from Remotely Sensed Data for Biodiversity Predictions","awardID":"0430693","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["544491"],"PO":["565136"]},"99799":{"abstract":"Proposal Number: 0439886<br\/>PI: Jonathan Turner <br\/>Institution: Washington University <br\/><br\/>Proposal Number: 0440940<br\/>PI: Scott Shenker <br\/>Institution: University of California, Berkeley <br\/><br\/>Proposal Number: 0439642<br\/>PI: Thomas E. Anderson <br\/>Institution: University of Washington, Seattle<br\/><br\/>Proposal Number: 0439842<br\/>PI: Larry Peterson <br\/>Institution: Princeton University <br\/><br\/><br\/>Title: Collaborative Research: Virtual Networking - Enabling Innovation in Networks and Services <br\/><br\/>Abstract: <br\/><br\/>The Internet is one of the great technology success stories of the twentieth century, enabling greater access to information and providing new modes of communication among people and organizations. Unfortunately, the Internet's very success is now creating obstacles to innovation in the networking technology that lies at its core. In order<br\/>to free the global communications infrastructure from stagnation, the nation must find ways to enable its continuing renewal. This planning grant is developing a case for network virtualization as a means to enable innovation in networks and services. Virtualization allows multiple logically independent virtual networks to share a common physical infrastructure or substrate. This program is developing a plan for a major new research initiative in network virtualization that includes both basic research, the development of key technology components and the creation of an experimental testbed, to establish feasibility and provide a context in which networking researchers can develop innovative new network architectures and services. The program is articulating the case for network virtualization, soliciting input from the network research community and working with the community to develop recommendations to NSF for a major initiative in this area.","title":"Collaborative Research: Virtual Networking - - Enabling Innovation in Networks and Services","awardID":"0440940","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560562"],"PO":["292741"]},"98116":{"abstract":"ABSTRACT<br\/>0429921<br\/>Hassoun, Soha<br\/>Tufts University<br\/><br\/>The scaling of CMOS technologies has delivered astronomical increases in transistor density and performance,<br\/>leading to more chip functionality at higher speeds. Several problems are expected to plague nanometer designs:<br\/>robustness to process and operating variations; long-term reliability due to electromigration and soft errors; and power density, with static power density approaching or exceeding the dynamic one. Novel solutions spanning materials, devices, circuits, microarchitectures and Computer-Aided Design (CAD) tools are required to overcome these problems.<br\/>We focus in this proposal on CAD tools for double-gate devices, novel transistor structures with more than one gate terminal to control the transistor channel. Compared to MOSFETs, double-gate devices promise substantial improved control over leakage current and short channel effects while delivering high drive currents.","title":"CAD Tools for Double-Gate FETS","awardID":"0429921","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["539728"],"PO":["562984"]},"98237":{"abstract":"This proposal seeks continued funding for the PI's work in his principal research area of Approximation Algorithms. Previous NSF-funded work by the PI's research group has successfully formulated and solved several interesting problems for approximation including the Buy-at-Bulk Network Design, $k$-Minimum Spanning Tree, Group Steiner Tree, and the Degree-bounded Minimum Spanning Tree problems. Our contributions to this area include mathematical programming relaxations of hard problems and novel ways to round such relaxations using deterministic and randomized rounding techniques, as well as new problem formulations.<br\/><br\/>The focus of this proposal is to address the solution of computationally hard problems in the vein of approximation algorithms by moving closer to more real-world constraints.<br\/>Specifically, we propose work in directions involving incorporating integration, heterogeneity, competition, uncertainty, and hybrid input models into classical problems. The proposal reports on preliminary successes and ongoing investigation in each of these directions, and formulates specific new problems and approaches. The intellectual merit of the proposal is to push the frontiers of approximation algorithms in terms of expanding its scope and applicability, as well as the potential for discovery of new underlying techniques.<br\/><br\/>The proposal is complemented with an educational and outreach plan that continues the PI's involvement in broader educational goals such as participation in surveys, tutorials and teaching workshops, as well as new course and lecture note development. The<br\/>broader impact of the proposal include graduate student training and placement in this research area as well as an extensive education plan aimed at increased dissemination of the PI's research to a broader audience including four-year college lecturers.","title":"New Directions in Approximation Algorithms","awardID":"0430751","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["561985"],"PO":["499399"]},"99568":{"abstract":"Proposal Number: 0439886<br\/>PI: Jonathan Turner <br\/>Institution: Washington University <br\/><br\/>Proposal Number: 0440940<br\/>PI: Scott Shenker <br\/>Institution: University of California, Berkeley <br\/><br\/>Proposal Number: 0439642<br\/>PI: Thomas E. Anderson <br\/>Institution: University of Washington, Seattle<br\/><br\/>Proposal Number: 0439842<br\/>PI: Larry Peterson <br\/>Institution: Princeton University <br\/><br\/><br\/>Title: Collaborative Research: Virtual Networking - Enabling Innovation in Networks and Services <br\/><br\/>Abstract: <br\/><br\/>The Internet is one of the great technology success stories of the twentieth century, enabling greater access to information and providing new modes of communication among people and organizations. Unfortunately, the Internet's very success is now creating obstacles to innovation in the networking technology that lies at its core. In order<br\/>to free the global communications infrastructure from stagnation, the nation must find ways to enable its continuing renewal. This planning grant is developing a case for network virtualization as a means to enable innovation in networks and services. Virtualization allows multiple logically independent virtual networks to share a common physical infrastructure or substrate. This program is developing a plan for a major new research initiative in network virtualization that includes both basic research, the development of key technology components and the creation of an experimental testbed, to establish feasibility and provide a context in which networking researchers can develop innovative new network architectures and services. The program is articulating the case for network virtualization, soliciting input from the network research community and working with the community to develop recommendations to NSF for a major initiative in this area.","title":"Collaborative Research: Virtual Networking -- Enabling Innovation in Networks and Services","awardID":"0439886","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["522381"],"PO":["292741"]},"98127":{"abstract":"PROPOSAL NO: 0429979<br\/>INSTITUTION: University of Minnesota-Twin Cities<br\/>PRINCIPAL INVESTIGATOR: Parhi, Keshab<br\/>TITLE: Design of High-Speed DSPTransceivers for Ethernet over Copper<br\/><br\/>Abstract:<br\/>The server speed should always be an order of magnitude higher than the desktop speed. Growing use of gigabit ethernet on desktops and laptops requires availability of 10-gigabit over copper in data centers. These must exploit use of existing or new copper cables, and must be cheaper than their fiber based competitors. This project will address architectural design aspects and VLSI implementation aspects of the digital signal processing components of a 10-gigabit per second ethernet transceiver over copper. The challenges in design of these systems are many. At the system level, to achieve the required speed, what should be the baud rate and modulation scheme? Should one use precoding at the transmitter or equalization at the receiver? Should one use low-density parity check codes? How can one implement a 7000-tap based receiver, necessary for cancelling near end cross talk and echo for the cables, with lower power consumption? What receiver architectures are more suitable for meeting the speed requirements? What are the best solutions for implementing low-density parity check codes at 10 gigabits per second? Answers to these questions will be sought. Novel modulation schemes will be studied by hardware codesign techniques and the best architecture of a system with least area and power consumption will be sought. Availability of 10-gigabit per second data at data centers and desktops will significantly reduce the cost of deployment and increase the speed of internet access.","title":"Design of High-Speed DSPTransceivers for Ethernet over Copper","awardID":"0429979","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["550262"],"PO":["562984"]},"98248":{"abstract":"Understanding the power of nondeterminism is one of the most fundamental problems in theoretical Computer Science. Many problems that arise in practice fall into the nondeterministic class NP. A lot of effort has been put, by many researchers, in understanding various aspects and properties the class NP. The goal of this project is to enhance our current understanding of the class NP.<br\/><br\/>Intellectual Merit: This project studies the structure of NP in the average-case world and seeks to develop new techniques to understand relations among NP and related classes in the average-case realm. This would bring out new connections between average-case and worst-case complexities of NP. The nonuniform complexity of NP and related classes will be investigated. This work attempts to understand the intrinsic properties of NP-complete sets. All these investigations will help us gain more insight into the nature of nondeterminism.<br\/><br\/>Broader Impact: A goal of the project is to unearth connections among several hypotheses that have been previously used in different contexts. This effort could help in unifying some of the underlying concepts of these hypotheses. This might pave way to make progress on some basic problems. The results of the research will be integrated into advanced courses. The course materials, in the form of lecture notes, will be made available on the web. The informal seminars will form collaborative efforts among students and faculty from two different universities. All results of the research will be broadly distributed to the scientific community, and will be posted on line at ECCC. Results will be submitted to major scientific conferences.","title":"Study of Nondeterminism","awardID":"0430807","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["409713"],"PO":["499399"]},"97049":{"abstract":"This project, investigating medical robotics and human-machine interfaces, aims to acquire infrastructure to support the following research projects:<br\/> Development of intelligent robotic tools to perform off-pump (beating heart) coronary artery bypass graft surgery,<br\/> Identification of human strategies in constrained manipulation, especially mechanical assembly, and<br\/> Investigation of command interface alternatives for rehabilitation robotics.<br\/>The 1st project replaces conventional surgical tools with robotics instruments that are under direct control of the surgeon through teleoperation. The intelligent telerobotic tools proposed in this project will actively track and cancel the relative motion between the surgical instruments and the heart by Active Relative Motion Canceling (ARMC) algorithms, allowing the surgeries to be performed on a beating heart with technical perfection equal to traditional on-pump procedures. This research focuses on: development of control algorithms for model based ARMC, developing of sensing systems, and modeling of heart behavior. The 2nd more controversial project, modeling human limb control, assumes the existence of a virtual trajectory as a mental representation of intention. The work instruments human manipulation tasks, analyzing the data to infer consistent virtual trajectories. The analysis is then extended to direct transfer of human skills to robots through demonstration. The 3rd project constructs alternative interfaces for robot control from some sources to objectively measure efficacy of competing approaches in a timed robotic target acquisition task. Paralyzed individuals often benefit from being able to command computers, robots, and even their own stimulated limbs using eye, face, and head motions.<br\/><br\/>Broader Impact: If successful, the three projects should have a significant impact on society. The technology developed in the first will facilitate improvement in surgical treatment of coronary artery disease by reducing the rate of complications, risk, and operational cost, saving direct healthcare costs. The second project could impact manufacturing (force-responsive assembly). The third commands interfaces for tetraplegics.","title":"CISE-RR Equipment Proposal for Medical Robotics and Human-Machine Interfacing Research at the Case Western Reserve University","awardID":"0423253","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["554067","460484"],"PO":["403839"]},"99117":{"abstract":"The goal of the Third Workshop on Hot Topics in Networks (HotNets-III), being held in San Diego, California on 15-16 October 2004, is to bring together researchers in the networking and distributed systems community to debate emerging research directions. This workshop promotes community-wide discussion of ideas that are not yet mature, with the expectations that (1) this will influence and foster ongoing research in the community, and (2) many of the HotNets position papers will grow into papers accepted at SIGCOMM or other quality conferences. This grant provides funding to assist 10 US-based graduate students in attending this meeting. Participation in workshops like this is an extremely important part of the graduate school experience, providing the opportunity to interact with more senior researchers and to be exposed to leading edge work in the field. The support provided enables the participation of students who would otherwise be unable to attend HotNets-III.","title":"Student Travel Support for ACM HotNets-III Workshop; October 15-16, 2004; San Diego, CA","awardID":"0436331","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548363"],"PO":["7594"]},"98028":{"abstract":"PROPOSAL NO: 0430175<br\/>PROPOSAL NO: 0429292<br\/><br\/>PI: A. Jeffrey<br\/>PI: G. Bruns<br\/>co-PI: R. Jagadeesan, J.Riely<br\/><br\/>The objective of this proposal is a means of updating the functionality and security policies of high-confidence computer systems in a way that is both dynamic (can be accomplished while the system runs) and safe (does not compromise the trustworthiness of the system).<br\/><br\/>This proposal investigates the use of aspect-oriented techniques in the dynamic configuration of high-confidence software systems. The specification and implementation and verification of secured components will be studied in an aspect-oriented style. The addition of new software components, both for additional functionality and for security, will be modeled as dynamic aspects, which can modify software during its execution.<br\/><br\/>Dynamic aspects may allow for flexibility in the dynamic configuration of software, but they also introduce the possibility for subtle bugs to be introduced in the interaction between conflicting aspects. A similar problem (known as the Feature Interaction Problem) has been studied in the telecommunications field. The experience and techniques from that area will be brought to bear on security features modeled as aspects.<br\/><br\/>A class-based, object-oriented language with dynamic advice loading will be defined. Temporal logic will be used to specify both security properties and the conditions under which cutpoints apply. Static and dynamic analysis methods will be developed to identify interactions between aspects. Finally, tools will be developed to support these methods, and they will be applied in case studies.","title":"Collaborative Research: Temporal Aspects","awardID":"0429292","effectiveDate":"2004-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":[258143],"PO":["564388"]},"98149":{"abstract":"0430118 <br\/>PI Foster, Jeffrey <br\/>Collaborative Research: Type Qualifiers for Software Security<br\/>0430585 Wagner, David 0430378 Alex Aiken<br\/><br\/>This research aims to develop tools and techniques to find and eliminate security vulnerabilities in software. The approach is based on static analysis, which by analyzing source code can model all possible executions of a program. The distinguishing feature of the project is to show that very large applications are free from classes of security vulnerabilities. Thus, the focus is not just in finding security holes in software, but in verifying their absence. Previous experience has shown that simple, approximate tools do not find all or even nearly all security vulnerabilities; the higher assurance given by verification is needed. The experimental goal is to apply these techniques to the Linux kernel, a security-critical application with millions of lines of code.<br\/><br\/>The main technical approach being investigated is based on user-defined type qualifiers that refine the standard types of the programming language. Previous work has shown that type qualifiers are a natural and useful way to explicitly specify desired security properties that are normally only implicit in a program. In much the same way that a correctly typed program cannot have run-time type errors, having consistent type qualifiers throughout a program implies that the property expressed by those qualifiers must hold in every execution. The significance of this work is that, if successful, it will improve the understanding of how to perform sophisticated static analysis of very large programs. The broader impact will be in discovering and repairing new security vulnerabilities in widely-used software infrastructure and in verifying that some of that infrastructure is free from at least some security flaws.","title":"Collaborative Research: Type Qualifiers for Software Security","awardID":"0430118","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T468","name":"DARPA-CYBER TRUST PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T470","name":"DARPA-NSF CYBER TRUST PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T951","name":"DARPA - CYBER TRUST PHASE III"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V901","name":"DARPA-NSF CYBER TRUST PROGRAM"}}],"PIcoPI":["556281"],"PO":["564388"]},"98039":{"abstract":"Collaborative Research: Language Processing Technology for Electronic Rulemaking <br\/><br\/>Many people today, including news analysts, opinion pollsters, advertisers, and government regulation writers need to interpret, structure, and rapidly master large quantities of opinion-based text. New research is needed to develop text-processing tools that can perform advanced analysis of large text collections. This research will build on current text processing technologies, such as text clustering, text searching using information retrieval, and extractive summaries, to build and test tools tailored to the specific needs of government personnel working in an electronic rulemaking environment. <br\/><br\/>This project's focus is the federal government's several-thousand regulation writers, employed in some 200 agencies, who formulate, in a tightly scripted procedure, the rules and regulations that define the details of our laws. This project will attempt to solve several novel problems central to language processing research. In turn, it will deploy and evaluate a Rule-Writer's Workbench; a set of language tools that enables regulation writers, singly or jointly, to obtain a detailed and multidimensional overview of the material. <br\/>. <br\/>This research has the potential to impact far beyond IT and social science academia. It will explore such novel issues as author typing, opinion\/affect determination, and near-duplicate detection. If even just a handful of the new technologies are effective, they eventually may help thousands of regulation writers more effectively communicate with and understand the comments of millions of citizens in our increasingly digitized society, and produce better regulatory rules for all of us.","title":"Collaborative Research: Language Processing Technology for Electronic Rulemaking","awardID":"0429360","effectiveDate":"2004-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T384","name":"NSA-LEXICON-TO-ONTOLOGY SUPP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543277"],"PO":["565136"]},"94520":{"abstract":"Sass - Abstract<br\/><br\/>Advantages in Information Technology continue to play a vital role in our nation's ability to innovate and compete in theglobal market. Advancements in computing performance, especially in the embedded computing systems domain, are enabling these advantages. This project combines commercially available, hybrid devices (that is, single integrated circuits with processors, memory, and configurable hardware) and a novel run-time system with the goal of building systems with better performance and fewer resources. To accomplish this, the project is investigating and developing technology in two steps. First, every subroutine in the embedded systems application is processed to find those suitable for acceleration by configurable hardware and a new hardware feature is synthesized. Then, as the application executes, the run-time system continually reconfigures the hardware to keep the most profitable features resident. By carefully managing the overhead introduced, the aim of this work is to provide the performance advantages of custom hardware with fewer physical resources. The advantage of the particular system under investigation is that it automates reconfiguration -- which presently is an engineering-intensive, manual process. To test the effectiveness of this approach, the University of Kansas has teamed with Grand Valley State University to judge the performance of the system on applications developed by senior undergraduate students.","title":"EHS: Dynamic Hardware Reconfiguration to Accelerate Java-Based Embedded Systems","awardID":"0410790","effectiveDate":"2004-09-01","expirationDate":"2007-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["434381","329570"],"PO":["561889"]},"94410":{"abstract":"Many emerging applications rely on asynchronous data distribution, where several embedded computing notes act as sensors that feed data to other parts of the system. An important class of these systems is distributed real-time embedded (DRE) systems where the applications have timing constraints that must be correct, and the data have temporal intervals during which they are valid. This project addresses technology for asynchronous real-time data distribution in DRE systems, focusing on the substantial challenges of severely constrained resources in complex dynamic networks. It is developing new models of real-time scheduling theory, and implementations of the algorithms in a prototype sensor network. The models and algorithms being developed in this project will broaden the applicability of existing solutions developed for less-constrained environments. The project is also formalizing a taxonomy to describe the DRE data-distribution problem space. This taxonomy will provide researchers with a common tool to classify and apply future work in this field.<br\/><br\/>This project is being evaluated through theoretical analysis of algorithm goodness and correctness, through simulation, and through transition to the Coast Guard's Automated Identification System (AIS) application to sensor network applications at Raytheon. Through applications such as these, this project is expected to have an impact on many applications that employ real-time data distribution in sensor networks. The project is also contributing to Computer Science education in this emerging area, and through publication of algorithms and open-source release of the prototype software that adds to the base of widely applicable technology for DRE applications.","title":"Real-Time Data Distribution in Asynchronous Network Communications Environments (Real-Time Data DANCE)","awardID":"0410130","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["444421","250753","250754"],"PO":["561889"]},"94542":{"abstract":"National Science Foundation<br\/>Distributed Systems Research <br\/>CISE\/CNS<br\/><br\/><br\/>ABSTRACT<br\/>PROPOSAL NUMBER: 0410918<br\/>PRINCIPAL INVESTIGATOR: Debray, Saumya K.<br\/>INSTITUTION: U of Arizona <br\/>PROPOSAL TITLE: A Holistic Approach to Compiler-Assisted Optimization of Software Systems <br\/><br\/><br\/>This project aims to improve computer software by considering the operating system and application programs running on a processor together in a holistic manner, and consider-ing global as well as individual behaviors of such systems. Each component of a com-puter system, i.e., the operating system and the different applications, runs in its own ad-dress space. Existing approaches to software optimization consider these components as isolated entities and assume nothing about the behavior of, or interactions with, other ad-dress spaces. This has the shortcoming that the software improvement process cannot take advantage of knowledge of interactions between code modules in the different ad-dress spaces. This project aims to develop tools and techniques to address this shortcom-ing. A key element in our approach is the use of compiler techniques in novel ways, and in particular, in a multi-address space systems context rather than a single address space application-level context.<br\/><br\/>The impact of this work will be to improve the performance of software systems across a wide variety of contexts and according to several different metrics. In particular, we ex-pect to be able to improve user applications, operating systems kernels, and system ser-vices, with performance metrics that include execution speed, amount of memory re-quired, fault tolerance, and enhanced security. Our results will be disseminated in the form of publications describing our algorithms, experimental methodology and results, as well as software developed as part of the project, which we will make available via the World-wide web.<br\/><br\/>Dr. Brett D. Fleisch<br\/>Program Director, CISE\/CNS<br\/>June 24, 2004.<br\/>.","title":"A Holistic Approach to Compiler-Assisted Optimization of Software Systems","awardID":"0410918","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["241298","550173"],"PO":["561889"]},"97820":{"abstract":"ITR: COLLABORATIVE RESEARCH: (EVS+NHS)-(int+dmc): 'FAST Copper': Dynamic Optimization of Resources in Frequency, Amplitude, Space, and Time for Broadband Access Networks<br\/><br\/>Mung Chiang, Princeton University<br\/>John Cioffi, Stanford University<br\/>Alexander Fraser, Fraser Research<br\/><br\/>Award 0427677<br\/><br\/>Abstract<br\/><br\/>Broadband access is the commercial and technical future of telecommunications. Higher data rates on access links enable any or all of video, data, and voice\/audio signals. It is widely recognized that the ability to deploy ubiquitous, robust, broadband access services to the majority of U.S. households is vital to economic prosperity, a vibrant civil society, and homeland security. The goal of this 'FAST Copper' project is to help build an engineering foundation to bring broadband information services to everyone with a phone line, including people who live in rural and less-privileged areas. This can be achieved by substantially enhancing the rate and reliability of the existing copper plant access network. Equity of broadband information access in the U.S. will be enhanced as a result. There are two threads of research activities towards this goal: (a) dynamic and joint optimization of resources in Frequency, Amplitude, Space, and Time (FAST) to overcome the attenuation and crosstalk bottlenecks, and (b) integration of communication, networking, computation, modeling, and distributed information management in the multi-user environment of twisted pair networks. Innovations in both physical layer algorithms and network architectures and protocols are pursued. In particular, Dynamic Spectrum Management, a science of multi-user methods for adaptively tuning an access network to specific situations dynamically, is investigated for rate improvements and implementation viability. This proposal has major activities integrating research with education. It also facilitates close collaboration with industry in analyzing highly valuable empirical data and validating research results through extensive lab tests.","title":"ITR: COLLABORATIVE RESEARCH: (EVS+NHS)-(int+dmc): 'FAST Copper': Dynamic Optimization of Resources in Frequency, Amplitude, Space, and Time for Broadband Access Networks","awardID":"0427677","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["561963"],"PO":["434241"]},"98920":{"abstract":"National Science Foundation<br\/>NETS- Research in Network Technologies and Systems <br\/>CISE\/CNS<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Proposal Number: 0435105<br\/>Principal Investigator: Jue, Jason P.<br\/>Institution: University of Texas at Dallas<br\/><br\/>Proposal Number: 0435095<br\/>Principal Investigator: Jianping Wang<br\/>Institution: Georgia Southern University Research and Service Foundation<br\/><br\/>Proposal Title: NeTS-NR Collaborative Research: Multi-Layer Dual-Homing Survivability for the Next-Generation Internet<br\/><br\/><br\/><br\/><br\/>This project investigates multi-layer survivability schemes for the next-generation networks, which are expected to be deployed over a wide range of underlying physical network infrastructures, from wireless networks in the ac-cess to optical networks in the core. An important issue in designing such net-works is to develop effective survivability schemes that can continue to carry critical traffic in the event of network failures. Traditionally, different survivabil-ity mechanisms have been implemented at various layers, independently. This project investigates the survivability schemes in which survivability mecha-nisms may be implemented simultaneously at multiple layers within the net-work in either a coordinated or independent manner. The work focuses primar-ily on multi-layer dual-homing techniques in the wireless and IP layers, protec-tion schemes in the optical layer, and the effective integration of these schemes. By establishing appropriate models and developing new algorithms, the project will provide insights into the trade-offs between coordinated and independent survivability schemes with respect to cost, complexity, and service levels pro-vided in the wireless and IP layers. <br\/><br\/>Dr. Admela Jukan<br\/>Program Director, CISE\/CNS<br\/>Aug 4, 2004.<br\/>.","title":"NeTS-NR Collaborative Research: Multi-Layer Dual-Homing Survivability for the Next-Generation Internet","awardID":"0435105","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["542048"],"PO":["565090"]},"97842":{"abstract":"This ITR project will conduct an in-depth theoretical and experimental study of a new approach to mechanism design (MD), i.e., the science of designing a mechanism (e.g., voting protocol, auction, divorce procedure, or collaborative rating system) so that a desirable outcome is reached despite the fact that agents act in their own self-interest. MD has traditionally been a manual endeavor. The new approach proposed in this research is \"automated mechanism design (AMD),\" where the mechanism is computationally created for the specific problem instance at hand. There are several potential advantages to this approach: 1) it can yield better mechanisms than the ones known to date; 2) it applies to problem classes beyond what has been studied manually to date; 3) it can circumvent seminal economic impossibility results; and 4) it shifts the burden of design from the human to the machine. New applications of AMD, such as voting, mediation, and expressive mechanisms for charity donations, will be studied. Second, approximately optimal AMD, when the designer does not completely know the prior distribution from which the agents types are drawn, will be studied. Third, scalable optimal algorithms for AMD, as well as an AMD software, will be developed. The results have broad impacts. More efficient allocation of social goods, services, information and tasks is possible. Ecommerce and voting applications, for example, would allow for more fair outcomes, where more savvy or better-informed parties can no longer exploit less knowledgeable parties to the interaction. Security can also be enhanced as no party will be motivated or able to manipulate the system to his or her advantage.","title":"ITR - (ECS+ASE) - (dmc+soc): Automated Mechanism Design","awardID":"0427858","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["561267"],"PO":["564456"]},"94575":{"abstract":"Modern advances in reconfigurable analog technologies are allowing field-programmable analog arrays (FPAAs) to dramatically reduce the power consumption while growing in size, flexibility and usefulness. The goal of this project is to develop the first mapping algorithm for floating-gate-based large-scale FPAAs. The target FPAA device consists of floating-gate transistors, which are standard pFET devices whose gate terminals are not connected to signals except through capacitors. Because the gate terminal is well insulated from external signals, the floating gate can maintain a permanent charge. The computational logic in the FPAA is organized in a compact computational analog block (CAB) that consists of op-amps, transistors, multiplier, programmable capacitors, and filters. CABs are tiled across the chip in a regular mesh-type architecture with busses and local interconnects between them. The major parasitic effects on FPAA chips are due to parasitic resistance and capacitance on FPAA interconnects. Therefore, the primary objective during mapping is to minimize the total number of wireless and switches involved in each interconnect. The mapping process is divided into three: CAP clustering, CAP placement, and FPAA routing. The CAB clustering algorithm tries to group analog components in the given circuit into CAB clusters under the device and wire constraints. During CAP placement, each CAB cluster is assigned to a unique CAB slot in the given FPAA architecture so that the wirelength, congestion, and performance degradation are minimized simultaneously. The FPAA router initially routes each interconnect by the shortest path while ignoring any overuse of routing resources. Then it sequentially performs ripping-up and re-routing every connection to minimize overuse of routing resources in the routing solution. The proposed mapping technology is being transferred to a startup company, and tools and training materials are made widely available through an on-line streaming video course. Graduate students involved are gaining experience in digital\/analog signal processing, mixed-signal system design, and physical layout automation algorithms.","title":"Bringing Low Power Reconfigurable Analog Signal Processing to Embedded Systems","awardID":"0411149","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["422053","550108","558209"],"PO":["561889"]},"97732":{"abstract":"ABSTRACT<br\/><br\/>ITR: Collaborative Research (NHS + ASE) (int + dmc):<br\/>Networks of Robots and Sensors for First Responders<br\/><br\/>PI: Daniela Rus, MIT<br\/>Co-PI: Vijay Kumar, U. Pennsylvania<br\/>Co-PI: Sanjiv Singh, CMU<br\/><br\/><br\/>This collaborative ITR project addresses the development of proactive networks of sensors and robots that perceive their environment and respond to it, anticipating information needs by the network and by users of the network, repositioning and organizing themselves to best acquire and deliver the information. Such networked systems combine the most advanced concepts in perception, communication, and control to create computational systems capable of interacting in meaningful ways with the physical environment, extending individual capabilities of each component and user to encompass a much wider area and range of<br\/>data. The PIs envision a physical analog to the Internet-- networks of computers that can actively sense, physically interact with, and reason about the world. While the Internet allows transparent access to information already online, this research will extend the paradigm by allowing users to \"google\" for physical information, setting into motion robots and sensors that team together to acquire information and act on it.<br\/><br\/>Intellectual Merit<br\/><br\/>The proposed research program will be make significant contributions to networked multi-agent systems: control, self-organization, adaptation, and perception. The work will focus on: (1) Control for communication and sensing: the control of robotic agents to maintain communication links or establish new ones, while obtaining the required sensory information and tracking sources; (2) Communication for sensing and perception: the fusion of information from heterogeneous sensors over the network, providing the required information for each agent to plan and control its mobility and providing remotely located human rescue workers with information through immersive displays; and (3) Communication networks for sensing and control: the grouping, scheduling and routing of nodes to adapt to changing, adverse conditions while maintaining guarantees for control of mobility and for sensor fusion and integration.<br\/><br\/>Broader Impact<br\/><br\/>The research will enhance national and homeland security by providing first responder with information about areas that are unsafe and hard to reach for humans in three ways. First, it will speed up the response time by helping in assessment, by augmenting human perception for command and control. Second, it will help in suppression and containment. Third, it will play a role in recovery, as in identification of victims and location of responding personnel. The collaboration with practitioners at the Allegheny Fire Training Academy will ensure that the research is grounded in the real world and has impact in the emergency response community.","title":"ITR: Collaborative Research: -\\(NHS+ASE)-\\(int+dmc\\): Networks of Robots and Sensors for First Responders","awardID":"0426945","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["561623"],"PO":["403839"]},"97974":{"abstract":"This project addresses the area of image and video inpainting, the technique of modifying an image in an undetectable form. The goals and applications of inpainting, which is as ancient as art itself, are numerous, from the restoration of damaged paintings and photographs to the removal of selected objects in a scene and the discovery of data behind occlusions. Image inpainting is also important for less-conventional applications such as wireless transmission and compression and image integration from camera arrays. The goal of this project is to develop a working solution to image, video, three dimensional, and multiple views inpainting and to address applications such as image and film restoration and alteration, image recovery from camera arrays, and filling-in of holes in 3D range data. Biological aspects of inpainting, through its fascinating possible connections with camouflage and the filling-in of the human blind spot, are investigated as well. The theory and applications of this project cover very diverse areas such as image processing, partial differential equations and fluid dynamics, numerical analysis, art, computer graphics, entertainment, and biology.<br\/><br\/>The inpainting problem is addressed as the computation of a smooth continuation of the available spatial and<br\/>temporal information surrounding the region to be filled-in. This is achieved via partial differential equations, which incorporate principles ranging from fluid dynamics to Gestalt's smooth boundary continuation. The combination of these techniques with more classical texture synthesis algorithms is also addressed and exploited in this project. The research addresses the problem in its generality, assuming diverse and large regions to be inpainted, and derives both fundamental theoretical aspects and practical<br\/>working systems.","title":"Image and Video Inpainting","awardID":"0429037","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["549760"],"PO":["564898"]},"96533":{"abstract":"This project, acquiring a large scale (512 processors) Linux computational cluster, provides a research instrument for computing intensive research and education projects that can help advance knowledge and understanding in a diversity of fields, while enabling technologies in systems and compilers, multiscale computational biology, biophysics, bioengineering, earth sciences, and psychology. Sharing benefits of terascale computational power with 32 investigators and 50 NSF-funded projects, this advanced high performance computing instrument, also promotes cross-disciplinary collaboration between tool-building teams and scientific computing teams in bio-computing, geodynamics, and magnetic resonance analysis. Software tool-building addresses performance issues, caching and clustering schemes for dynamic web sites, and designing improved TCP\/IP interfaces. Eliminating the need for many, separate ad-hoc clusters in different departments, the cluster services, among others, the following specific computational research projects:<br\/>* Studying software and performance issues for heterogeneous Grid systems.<br\/>* Caching and clustering schemes for web sites with dynamic content,<br\/>* Designing improved TCP\/IP interfaces for cluster computing,<br\/>* Multiscale computational biology, biophysics, and bioengineering,<br\/>* Modeling of tissues, cells, and cell populations,<br\/>* Modeling of flow and hemolysis in implantable blood pumps,<br\/>* Computer-aided drug discovery,<br\/>* Algorithms for PDE constrained optimization,<br\/>* Novel algorithms for large-scale numerical linear algebra,<br\/>* Using computational fluid dynamics to model thermal convection in the Earth's mantle,<br\/>* Particle dynamic simulations of earth processes,<br\/>* Multiscale seismological simulation,<br\/>* Analysis of functional MRI (fMRI) data,<br\/>* Source modeling of EEG and ERP signals, and<br\/>* Modeling of visual ideal observers.<br\/>Broader Impact: The facility, benefiting more than 100 PhD students, 50 undergraduates, and 30 Postdoctoral fellows, and directly impacting 32 investigators, will be used in classes at the undergraduate and graduate levels and also as a recruiting tool through existing alliance activity (AGEP: Alliance for the Graduate Education and the Professoriate and a \"Spend a Summer with a Scientist\" outreach program). Furthermore, the work exhibits strong emphasis on learning, communication, and interaction across disciplines.","title":"MRI:\"Acquisition\" of Rice Computational Research Cluster (RCRC)","awardID":"0421109","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["551029","500264","309293","462923",253436],"PO":["557609"]},"97754":{"abstract":"This research project is jointly funded by the Information Technology Research program, the Digital Society and Technologies program, and the Office of International Science & Engineering. It will investigate how information technologies that employ sophisticated mathematical techniques are reshaping technical work through a process conceptualized as intensification of abstraction. Intensification of abstraction centers on the replacement of the physical by the virtual, i.e., the manipulation of symbols that represent and substitute for objects. The study will be conducted in the context of automotive engineering design in partnership with General Motors Corporation. It will focus on the way in which information technology tools that employ techniques like finite element analysis and computational fluid dynamics are bringing about changes in how engineers think about and do engineering, changes in organizational structures and processes, changes in engineering knowledge, and changes in the division of engineering labor. It will also trace how these technologies alter relationships between automotive firms and their suppliers and pave the way for outsourcing engineering work. <br\/><br\/>The research will entail detailed ethnographic observations of GM engineers in both US and India, supplemented with interviews in firms that manufacture analysis tools and the researchers who develop the techniques on which the tools are based. To date little systematic research has examined the socio-technical dynamics of these kinds of changes. The intellectual merit of this study lies in its potential to alter how studies of technology and work understand the role of information technologies in a knowledge economy. Since technical and professional occupations now represent the largest sector of the American workforce, intensification of abstraction may transform modern knowledge work as significantly as automation did production and clerical work in the 20th Century. The broader impacts include implications for the U.S. economy and the nation's place in the international division of labor.","title":"ITR: Transformation of Engineering Design: Digitization and Global Distribution of Engineering Work","awardID":"0427173","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["518944","518944","483518","483518"],"PO":["564456"]},"97996":{"abstract":"As part of the joint NSF\/NASA High-Dependability Computing and <br\/>Communication<br\/>Systems Research effort, this project is developing, adapting and <br\/>integrating a variety of program analysis techniques for the Real-time<br\/>Specification for Java (RTSJ). RTSJ is an emerging language extension<br\/>for Java that is designed for implementing concurrent time-critical<br\/>embedded software, for example, the control software on NASA's<br\/>robotic Mars rovers. This type of software is notoriously difficult to<br\/>test and debug, and the model-checking, light-weight static and dynamic<br\/>analysis techniques being developed as part of this project promise to<br\/>identify bugs before software is deployed to the field and to produce<br\/>systems that function more reliably.<br\/><br\/>A cornerstone of this project is the use of controlled experimentation <br\/>to judge the effectiveness of new analysis techniques. As part of this <br\/>effort, RTSJ programs and experimental frameworks will be developed that support<br\/>repeatable experimentation for determining analysis performance and the <br\/>precision of analysis results. Experiment findings will drive the refinement of<br\/>analysis techniques. Case studies using NASA testbed software will serve<br\/>to evaluate the scalability and applicability to NASA-relevant software<br\/>challenges.<br\/><br\/>If successful, this project promises to provide developers of next <br\/>generation real-time embedded software, both at NASA and throughout the embedded<br\/>systems domain, with a suite of powerful quality-assurance tools that <br\/>will allow them to more cost-effectively produce higher-quality systems.<br\/>Given the pace at which software is being embedded in our society's<br\/>infra-structure, this could have broad impacts on the degree to which <br\/>we can rely on such systems.","title":"Collaborative Research: Program Analysis Techniques to Support Dependable RTSJ Applications","awardID":"0429141","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}}],"PIcoPI":["563763"],"PO":["564388"]},"96313":{"abstract":"Abstract<br\/>ITWF Program - FY04<br\/><br\/>CNS 0420371, PI Sandra DeLoatch, Norfolk State U<br\/>Title: Creating an Inclusive Learning Environment: Enhancing Retention of Women and Minorities in Computer Science<br\/><br\/>Collaborative Projects:<br\/>CNS 0420365, PI Donald Davis, Old Dominion U.<br\/>CNS 0420371, PI Sandra DeLoatch, Norfolk State U.<br\/><br\/>Old Dominion University and Norfolk State University have been awarded an ITWF grant to conduct a collaborative four-year implementation project designed to create an inclusive learning environment in computer science and thereby increase retention of women and minority undergraduate students. The two institutions will create an inclusive learning environment through (a) strengthening faculty-student and student-peer relationships using collaborative and multicultural teaching and learning practices and (b) strengthening student self-efficacy, optimism, career management, and collaboration and coping skills. All beginning CS students will participate in a required, semester-long class that presents a realistic preview of the challenges of being a computer science major, techniques and skills for coping with such challenges, training in attitudes and beliefs that foster persistence, and use of role models to describe the career rewards that are possible in computer science. Faculty will be trained in \"wise schooling\" techniques to foster inclusiveness. Faculty will also include pair programming and collaborative learning in programming classes.","title":"Collaborative Research: ITWF - Creating an Inclusive Learning Environment: Enhancing Retention of Women and Minorities in Computer Science","awardID":"0420371","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"1397","name":"CROSS-DIRECTORATE  ACTIV PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["554914"],"PO":["361119"]},"98975":{"abstract":"NeTS - ProWin: Flexible MAC Protocols for Configurable Radios<br\/>Jean Walrand, UC Berkeley<br\/>Award 0435478<br\/><br\/>Abstract<br\/><br\/>Wireless devices are proliferating and have widely different data rate, communication range, and power requirements. Currently, such devices use incompatible communication protocols, which limits their connectivity and restricts the set of applications. We are designing a flexible family of protocols that enables vastly different devices to communicate while preserving their individual requirements. The protocols use an OFDM physical layer. Faster protocols use more parallel channels in parallel. To enable large network utilizations, the devices transmit on pseudo-orthogonal sequences of multiple channels. The protocols select the sequences and perform the necessary rendezvous functions. We use simulations to evaluate the characteristics of the protocols and guide the selection of design parameters. The protocols developed in this project enable very different wireless devices to communicate. They result in backward-compatible systems and should spark the development of new applications that exploit these new communication capabilities. The expected result of the project is a new family of MAC communication protocols validated through extensive simulations. These protocols can be implemented with configurable OFDM radios currently being designed by the industry.","title":"NeTS - NR: Protocols for Flexible and Efficient Frequency Spectrum Utilization","awardID":"0435478","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["406461"],"PO":["7594"]},"98986":{"abstract":"Modern society is becoming increasingly dependent on the Internet for instant access to information, and the broadband access will have a strong positive im-pact on this. This project will create new knowledge on the design, analysis, and operation of novel broadband access network architectures, protocols, and algo-rithms. It will specifically investigate unified scheduling and resource allocation in broadband access networks, as well as network economics for building ``open access networks''. In access networks, control-plane delays are large since end users and the central office (through which users connect to the Internet) are separated by a significant distance, typically several kilometers. Hence, known scheduling algorithms for packet-based networks are difficult to apply. Therefore, in this project, new knowledge will be created on hierarchical scheduling algorithms which are ``cousin fair\" (as opposed to ``sibling fair\"). Remote-scheduling algorithms need to be developed which are fair, support dif-ferent classes of service, provide guarantees on Quality of Service (QoS) and are scalable in number of users. New knowledge will also be created on network economics for building ``open access networks'', designed for competition among multiple service providers.","title":"NeTS-NR: Next-Generation Broadband Access Networks","awardID":"0435525","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518063"],"PO":["565090"]},"98502":{"abstract":"Molecular nanoelectronics is a new and highly promising field of research with tremendous opportunities for fundamental scientific advances as well as for technological breakthroughs in physical design and realization of novel computing and information processing. To fully utilize these unique opportunities for development of a new generation of computational hardware the fundamental mechanisms of charge and spin transport in single molecules must be understood.<br\/><br\/>This project will further advance the field of novel nanoscale architectures and system technologies by establishing predictive capability to model quantum mechanically the electron and spin- transport properties of single molecule organic devices as well as their relationship to the atomic and electronic properties. The PI will develop a first-principles quantum-mechanical theory of electron and spin transport in organic molecules attached to metallic electrodes and predict from first-principles their current-voltage characteristics including spin-polarization of the conductance. The mechanisms and new approaches for control and manipulation of the spin-polarization of an electron current will be studied. First-principles modeling of electron and spin transport in specific metal\/organic molecule\/metal junctions will be performed to study the chemistry and bonding at the metal\/molecule interface as well as their influence on transport properties. Knowledge of structure-property relationships between molecular structures and spin-dependent conductance will provide a unique opportunity to guide future experiments by suggesting new molecular structures for chemical synthesis and transport measurements. The project will have an extensive educational impact by training a graduate student, postdoctoral associate and an undergraduate student in a technologically important area.","title":"QnTM: Quantum Mechanics of Electron and Spin Transport in Single Molecular Nanodevices","awardID":"0432121","effectiveDate":"2004-09-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["458060"],"PO":["474792"]},"96335":{"abstract":"Title: ITWF Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science<br\/><br\/>CNS 0420436, PI Horwitz, Univ. of Wisconsin-Madison<br\/>CNS 0419340, PI Huss-Lederman, Beloit College<br\/>CNS 0420312, PI Munson, Univ. of Wisconsin-Milwaukee<br\/>CNS 0420337, PI Dunsmore, Purdue University<br\/>CNS 0420343, PI Rodger, Duke University<br\/>CNS 0420358, PI Binkley, Loyola College of Maryland<br\/>CNS 0420368, PI Biggers, Georgia Institute of Technology<br\/>CNS 0420433, PI Ryder, Rutgers University<br\/><br\/><br\/>This collaborative ITWF project implements a new approach to introductory computer science with the goal of increasing the enrollment and retention of women and under-represented minorities in undergraduate computer science degree programs. The project adapts the Emerging Scholars Program and the Peer-led Team Learning approaches, which have been proven successful in mathematics and other sciences, to computer science. It is a collaborative project between the University of Wisconsin-Madison, Beloit College, Duke University, Georgia Institute of Technology, Loyola College of Maryland, Purdue University, Rutgers University, and the University of Wisconsin-Milwaukee. The project includes targeted recruitment of students with strong mathematics and science backgrounds to the new course. The course includes students working in small groups on challenging problems with group facilitation by outstanding undergraduates.<br\/> <br\/>The intellectual merit of this project lies in the strong basis on models that have been successful in other disciplines. The collaborative represents a team of investigators with significant expertise in educational reform and transformation. Implementation will take place at the diverse set of institutions represented by the collaborative partners, thus providing an excellent environment for evaluation of this innovative approach and illustrating the possibilities for replication and adoption by a wide range of institutions.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science. The method to be tested is relative low cost and straightforward to implement, thus it has a high potential for broad impact across the country.","title":"ITWF: Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science","awardID":"0420436","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["331999"],"PO":["361119"]},"97787":{"abstract":"It has long been postulated that a human determines the linguistic identity of a sound based on detected evidences that exist at various levels of the speech knowledge hierarchy, from acoustics to pragmatics. Indeed, people do not continuously convert a speech signal into words as an automatic speech recognition (ASR) system attempts to do. Instead, they detect acoustic and auditory evidences, weigh them and combine them to form cognitive hypotheses, and then validate the hypotheses until consistent decisions are reached. The above human-based model of speech processing suggests a candidate framework for developing next generation speech technologies that have the potential to go beyond the current limitations.<br\/><br\/>In order to bridge the performance gap between ASR systems and humans, the narrow notion of speech-to-text in ASR has to be expanded to incorporate all related human information \"hidden\" in speech utterances. Instead of the conventional top-down, network decoding paradigm for ASR, we are establishing a bottom-up, event detection and evidence combination paradigm for speech research to facilitate collaborative Automatic Speech Attribute Transcription (ASAT). The goals of the proposed project are: (1) develop feature detection and knowledge integration modules to demonstrate ASAT and ASR; (2) build an open source, highly shared, plug-'n'-play ASAT cyberinfrastructure for collaborative research to lower entry barriers to ASR; and (3) provide an objective evaluation methodology to monitor technology advances in individual modules and across the entire system.","title":"ITR-(NHS+ASE)-(int+dmc+sim) Automatic Speech Attribute Transcription (ASAT): A Collaborative Speech Research Paradigm and Cyberinfrastructure with Applications to Automatic Speech","awardID":"0427413","effectiveDate":"2004-09-15","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T053","name":"NSA-HLT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V839","name":"NSA-HUMAN LANGUAGE & COM PROG"}}],"PIcoPI":["457582","552047","335186","392479","543555"],"PO":["565215"]},"98887":{"abstract":"National Science Foundation<br\/>NETS- Research in Network Technologies and Systems <br\/>CISE\/CNS<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Proposal Number: 0434940<br\/>Principal Investigator: Loguinov, Dmitri<br\/>Institution: Texas Engineering Experiment Station<br\/>Proposal Title: NeTS - NR: Topology Models for Decentralized Random Graphs<br\/><br\/><br\/>Many networks found in the real world exhibit characteristics drastically differ-ent from those of classical random graphs. Examples range from social net-works and ISP-level Internet to various cellular-level graphs. In addition to the well-known heavy-tailed degree distribution, many naturally self-evolving graphs demonstrate high clustering and short average distances between every pair of nodes. It has been a long-standing problem in the scientific community to model such graphs using algorithmic construction of synthetic graphs with properties similar to those of real networks. While many different topology gen-erators and alternative theories explaining the structure of real-world graphs currently co-exist, their main drawback lies in the requirement for the nodes to cooperate during graph evolution and to possess global knowledge of the entire graph at every time step. To overcome this limitation, this project undertakes a study of distributed, non-cooperative graph construction and offers a novel ap-proach to modeling the numerous small-world networks observed in practice. Using random walks as the main design element, the distributed graph con-struction can naturally lead to high levels of clustering and heavy-tailed degree distributions. Results obtained in this work are expected to advance our under-standing of self-configuring graphs in nature and create usable models that will allow various synthetic structures to achieve desired topological properties through distributed actions of individual users. <br\/><br\/>Dr. Admela Jukan<br\/>Program Director, CISE\/CNS<br\/>August 4, 2004.<br\/>.","title":"NeTS - NR: Topology Models for Decentralized Random Graphs","awardID":"0434940","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550669"],"PO":["565090"]},"97699":{"abstract":"The goal of the proposed work is to build a foundation for enabling a rich set of applications on entirely unstructured, decentralized, and distributed networks. Recently, a number of different research applications have been built on similar platforms in the context of peer-to-peer systems. While these research systems offer great promise, we believe significant work is required in order to build deployable applications over these systems. <br\/><br\/>This work is motivated by the open issues in this area, and is organized into three major thrusts: (1) placement and lookup algorithms that are robust against a range of adversarial failure models, and yet - in contrast to, e.g., DHTs - do not require or assume any structure on the underlying network topology; (2) efficient and resilient techniques for sophisticated querying of P2P namespaces in unstructured environments; and (3) methods that allow peers to explicitly incorporate individual trust and privacy policies into protocol actions. The work is terms of four applications: (1) an ad-hoc public key infrastructure; (2) a robust search and query application for distributed data; (3) a censorship-resistant publishing application; and (4) an application for efficient ad-hoc access to scientific datasets.<br\/>Individually, each of these applications are important building blocks that exercise different aspects of our proposed work, and directly advance the state of the art in the sciences, engineering, and national security. Together, they form a compelling set of motivating examples for the research to be conducted under this project.","title":"ITR - (ASE+NHS) - (DMC+INT+SOC): Resilient Storage and Querying in Decentralized Networks","awardID":"0426683","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["456688","548322","447923","519626",257085],"PO":["561889"]},"98304":{"abstract":"This project is investigating and developing information modeling for comparative visualizations and analyses of complex chemical separations produced by comprehensive two-dimensional gas chromatography (GCxGC). GCxGC is a powerful new technology that provides an order-of-magnitude increase in separation capacity over traditional GC. A few advanced laboratories are pioneering GCxGC for a variety of applications, such as environmental monitoring and health-care, but researchers lack advanced information technologies for analyzing and interpreting the large, complex data generated by GCxGC.<br\/><br\/>The models being developed in this project abstract essential analytical information for comparative visualization and analyses. Analytical methods are being developed to extract model components from the structural characteristics of both GCxGC intensity data and data from GCxGC with mass spectrometry (GCxGC-MS). The models support calibration for varying chemical concentrations and measurements of the quality of fit to the data. Comparative visualizations of the GCxGC information models employ multiple viewing strategies with colorization and animation to provide users with multiple avenues for interactive analyses. Interactive analyses support comparisons with view navigation and controls, queries and edits of model-based information and metadata, and structured reporting.<br\/><br\/>The model-based information technologies facilitate advanced chemical analyses in a broad range of problems. The project is demonstrating their value for two applications of GCxGC. One application analyzes changes of complex mixtures of petroleum hydrocarbons in the environment following an oil spill. The other application uses GCxGC to fingerprint fragrances for classification and identification.","title":"Collaborative Research: SEI: Information Modeling for Comparative Visualizations and Analyses - Informatics for Comprehensive Two-Dimensional Gas Chromatography","awardID":"0431119","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["491467"],"PO":["565136"]},"98326":{"abstract":"Wireless sensor networks have a large array of potential applications,<br\/>including environmental monitoring, home and factory automation, and<br\/>homeland security. This research addresses efficient data collection<br\/>from sensor networks, which is one of the fundamental bottlenecks to<br\/>large-scale deployment of low-cost sensor nodes. Two key difficulties<br\/>are scale (how to manage very large numbers of relatively<br\/>unsophisticated nodes) and energy (communication is energy-intensive,<br\/>but sensor nodes must operate for months or years on battery, or by<br\/>scavenging energy from the environment). This research has two<br\/>complementary research thrusts, both investigating novel techniques<br\/>for data collection from sensor networks, exploiting the natural<br\/>distribution of sensor nodes in space. The first, termed virtual<br\/>radar, enables deployment of extremely simple sensor nodes which do<br\/>not need networking or position location functionality, by moving the<br\/>complexity to a sophisticated data collection node. The second<br\/>approach requires more sophisticated nodes, and increases energy<br\/>efficiency and range by obtaining the functionality of multi-antenna<br\/>transmission by intelligent coordination between neighboring<br\/>(single-antenna) sensor nodes.<br\/><br\/>In the first thrust, termed virtual radar, sensor nodes with activity<br\/>to report electronically reflect a beacon transmitted by a<br\/>\"driveby\" or \"flyby\" collector node, thus<br\/>creating a radar-like geometry. The collector employs sophisticated<br\/>synthetic aperture radar like signal processing techniques to obtain<br\/>an \"image\" of the activity in the sensor field.<br\/>Tracking of events moving across the sensor field, and exploiting<br\/>multiple antennas at the collector, are investigated. The second<br\/>thrust, termed distributed transmission, involves investigation of<br\/>beamforming, diversity and power gains obtained by coordinating<br\/>between neighboring nodes, as a function of the level of<br\/>synchronization achieved among the nodes. Methods of achieving such<br\/>synchronization are also considered.","title":"Distributed Space-Time Communication For Wireless Sensor Networks","awardID":"0431205","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["549356"],"PO":["564898"]},"98106":{"abstract":"Control-Flow Processors<br\/>Abstract<br\/><br\/><br\/>An architecture is presented that unifies fine-grain control-flow and data-flow dependences in the context of contemporary superscalar processors, preserving highly streamlined mechanisms of superscalar processors while endowing them with dataflow properties. Future independent instructions are fetched, executed, and locally finalized, their results propagated and corresponding resources freed, and their cumulative effects sustained regardless of prior unresolved branch mispredictions. Branch mispredictions no longer serialize execution, leaving exceptions and finite resources as the only remaining serializing constraints in the system.<br\/><br\/>In the domain of high-performance microprocessors (which power supercomputers, personal computers, laptops, and even cell phones), there remain a few dogged bottlenecks that fundamentally constrain performance, making it difficult to translate the potential of additional transistors into effective performance gains. The project's broader significance is an approach that aims to overcome one of the remaining grand-challenge problems in scaling microprocessor performance.","title":"Control-Flow Processors","awardID":"0429843","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["518384"],"PO":["550859"]},"98227":{"abstract":"A major challenge in complexity theory is to prove lower bounds on the number of steps necessary to compute a given function in general computational models. It would be important to have techniques that help to find out what is the most efficient solution we can hope to achieve for specific problems. <br\/><br\/>There are methods for proving strong lower bounds for restricted versions of some important models of computation. However, there are no known techniques powerful enough to prove strong lower bounds on the intrinsic complexity of specific computational problems.<br\/><br\/>The long term objective of the proposed research is finding new methods for proving complexity lower bounds and identifying mathematical properties of Boolean functions that determine their computational complexity.<br\/><br\/>The specific plan of research outlined in the proposal involves the analysis of problems in various computational models, such as the cell probe model, branching programs, span programs, and multiparty communication protocols. All the models considered in the proposal are related to some important computational resource. Thus proving strong lower bounds on the complexity of specific Boolean functions in the unrestricted versions of any of these models would represent significant progress towards better understanding the inherent complexity of computational tasks. Because of the connections of these models to the Boolean circuit model, several of the problems and approaches considered may potentially provide new techniques to attack fundamental open problems in complexity theory. The problems considered in the proposal are also interesting on their own right from the point of view of various applications, including cryptographic applications such as secret sharing schemes, private multiparty computation, and data structures.<br\/><br\/>A common theme of the problems considered in the proposal is their connection to communication complexity. Several of the known lower bound techniques in different models are based on techniques related to communication complexity. The proposed research plans to explore these connections further.","title":"Communication Complexity and Circuit Complexity","awardID":"0430695","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["451556"],"PO":["499399"]},"98117":{"abstract":"Checkpointed Processor Architectures<br\/>Abstract<br\/><br\/>The project proposes Checkpointed Processor Architectures (CPA), a hybrid mode of execution based on a combination of traditional in-order commit support and selective state checkpointing. CPA decouples resource recycling from instruction commit permitting more aggressive reclamation and higher utilization. It also performs speculative commit of some long-latency memory operations, allowing subsequent instructions to complete and commit. To recover from corrupted states due to aggressive speculation, CPA processors rely on their checkpointed state. The project will explore the integration of CPA in processors with support for simultaneous multithreading, and with chip multiprocessors. The project will also investigate the synergy between CPA and thread-level speculation, an upcoming technology that bridges the gap between sequential and parallel computing.<br\/><br\/>CPA's departure from traditional instruction processing will allow processors to deliver higher performance growth without oversizing critical resources, which affects the clock rate adversely. As a result, CPA will help overcome the performance stagnation in evolutionary processor architectures. Furthermore, our integrative approach with emerging parallel and speculatively parallel architectures will ensure a broad and lasting impact. Finally, the insights developed in the CPA mechanisms and interactions will help better understand the co-design aspects of microprocessor and parallel architectures, in the lab and in the classroom.","title":"Checkpointed Processor Architectures","awardID":"0429922","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["499395"],"PO":["550859"]},"97028":{"abstract":"Using machine learning and cognitive modeling to understand the fMRI-measured<br\/>brain activation underlying the representations of words and sentences<br\/><br\/>Tom M. Mitchell and Marcel A. Just <br\/><br\/>Project Abstract<br\/><br\/>A number of recent fMRI studies have reported significant and repeatable differences in fMRI brain activation when human subjects perceive pictures or words describing objects from different semantic categories (e.g., pictures or words that describe tools, buildings, or people). It is currently possible to determine with good accuracy which of several semantic categories a person is thinking about, based on their brain activation.<br\/><br\/>We propose new research that builds on these recent discoveries, and seeks to understand (1) human brain activity associated with different semantic categories of objects and actions (nouns and verbs); (2) whether the brain activity associated with semantic categories can be partitioned into more primitive semantic components (e.g., does the brain activity associated with words about tools factor into one component characterizing the tool's visual appearance and a second component characterizing the motor actions involved in using the tool?); and (3) how brain activity associated with individual words is combined into more complex patterns when reading word pairs or simple phrases and sentences.<br\/><br\/>This research involves:(1) applying machine learning algorithms to discover cortex-wide brain activation patterns associated with particular semantic domains, (2) developing a computational model of human language processing that instantiates the representational principles discovered and that makes specific, testable predictions, and (3) conducting new fMRI studies to obtain novel data about human semantic category representations.<br\/><br\/>The intellectual merit of the proposed research is multifaceted. If successful, our research will lead to new scientific insights into how the brain organizes information about meanings of words, objects, and actions. It will also lead to new methods for fMRI data analysis, especially for discovering complex temporal-spatial patterns of fMRI activation that accurately distinguish different mental states. The research will also lead toward a new paradigm for developing computational cognitive models and fitting them to empirical data obtained from fMRI and from behavioral measures.<br\/><br\/>The broader impacts of the proposed research will be amplified by specific outreach activities to several communities. In addition to publishing our scientific results in the cognitive and computational neuroscience literature, we will also actively engage this community by disseminating our new experimental fMRI data through the NSF-funded fMRI Data Center, and by documenting and publishing our new data analysis algorithms on the internet. We will proactively engage the statistical machine learning community, which has much to contribute to development of new fMRI analysis methods, and will develop and disseminate teaching materials for the undergraduate and graduate educational community,including fMRI data sets. Finally, our proposed research has potential impact on the medical research community, especially regarding the study of neurological conditions such as Alzheimer's disease, dyslexia and high-functioning autism - three areas entailing a language disturbance in which we already have active research collaborations, providing a direct conduit for transferring new scientific insights that may arise from this research.","title":"Using Machine Learning and Cognitive Modeling to Understand the fMRI-measured Brain Activation Underlying the Representations of Words and Sentences","awardID":"0423070","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":["384335","533288"],"PO":["564318"]},"87117":{"abstract":"World-Wide Web searchers are often frustrated by a lack of relevant results, or more often, overwhelmed by a result set that is too large to examine for relevancy. With hundreds of millions of queries performed each day, query logs provide a new source of knowledge for this project to learn how users search, what people are searching for, and provide suggestions to future searchers. The goals of this project are to learn what people search for on the Web; to provide query suggestions for uncertain or inexperienced searchers; and, to offer relevant query terms for search engine optimization of a website. To these ends, the bipartite graph of queries and their results are analyzed to identify useful query-query and document-document relationships; queries are clustered into topics, using the new relationships as well as more traditional sources of information; existing information retrieval techniques are adapted to help identify, organize, and track not simply query popularity, but topic popularity; and, information from query logs is utilized to help find preferred queries that express a similar information need. The broader impacts of this work are two-fold. By exploiting the untapped information present in Web search engine query traces, this project increases the understanding of how people search on the Web and for what they are looking. This knowledge is applied to generate algorithms and tools to support searchers as well as those who want to be found by those searchers. These tools, as well as datasets collected or generated, will be made available to the research community via the project Web site (http:\/\/www.cse.lehigh.edu\/~brian\/nsf\/queries-03.html).","title":"Understanding and Enhancing Queries","awardID":"0328825","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["365997"],"PO":["563751"]},"98128":{"abstract":"The first aspect of this research develops an expressive visual speech synthesis module for a prototype virtual actor. The goal is to provide virtual actors with realistic and expressive facial animation given a speech input in real-time. Facial motion in general is one of the most challenging problems in computer animation, since the human face is the most complex muscular region of the human body. At the same time, expressive visual speech is critical for virtual humans that need to interact orally in diverse scenarios.<br\/> The second aspect of this research addresses the problem of expressive visual speech synthesis using a machine learning approach that relies on a database of speech related high-fidelity facial motions. From this training set, a generative model of expressive facial motion is derived that incorporates emotion control while maintaining accurate lip-synching. The emotional content of the input speech can be manually specified by the user or automatically extracted from the audio signal using a Support Vector Machine classifier.<br\/> This research introduces a novel real-time search-based approach for facial motions synthesis. In addition, it is the first piece of work that develops and incorporates an emotion mapping model as an integral part of the facial motion synthesis process.<br\/><br\/>Broader Impact. <br\/> Results will have immediate impact on the entertainment industry and on computer assisted education. Our work provides a missing piece towards the ambitious goal of developing expressive virtual humans. Real-time high quality facial motion synthesis is crucial for interactive games that involve virtual human characters. The US gaming industry is a billion-dollar industry that employs thousands of US citizens. This research makes significant advances in this area and can give this industry an important competitive advantage.<br\/> There are a growing number of social and educational applications that can benefit from high quality and interactive virtual humans, such as interactive training systems, and virtual tutors. In the future, inexpensive virtual tutors could be used to provide customized tutoring to under-achieving children or children with special needs. This research pushes the envelope of the state of the art in facial animation, which, once mature, has the potential to revolutionize the way computers interact with humans.","title":"Speaking with Passion: Real-time Expressive Visual Speech","awardID":"0429983","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[258408],"PO":["532791"]},"98139":{"abstract":"Abstract for proposal 0429901\/0430065<br\/><br\/>Modern technology enables the creation of digital 3D polygon meshes with incredible detail. Current mesh formats, which were designed when models and meshes were orders of magnitude smaller, complicate the processing of large, detailed data. This project will fully develop a new streaming mesh representation, and use it as a framework for algorithms that produce and\/or consume large polygonal and polyhedral meshes. At its core are several simple, new ideas that get around current limitations in computer memory hierarchies. The immediate benefit of compressed storage, faster loading, and better memory use appeal to any application creating large models, including scientific and engineering visualization for data exploration, scanned artifacts for artistic and museum displays, landscape modeling for flood or fire control, mesh generation for scientific computing, virtual environments for collaboration and education, and 3D models for e-commerce. <br\/><br\/>This project identifies the parameters that characterize a streaming mesh, then designs and implements algorithms whose behavior can be analyzed in terms of these parameters. Initial algorithms include surface simplification, compression, and transmission for geometric models for computer graphics, and extend to include 2D and 3D stream-based Delaunay triangulators. The key ideas grew out of work on geometric models in computer graphics; the project's investigators will apply them in more general contexts. The result will be useful software, embodying a computation paradigm that can process arbitrarily large meshes while avoiding geometric artifacts, degradation of quality, and other difficulties of approaches that cut meshes into pieces to fit into available memory. This project will ensure its broader impact though distribution of software (both source code and executables) for streaming and compressing meshes, and stream-based 2D and 3D Delaunay triangulation. The project will impact education of undergraduate and graduate students, and reach out to high school and elementary students through demonstration days. The principle investigators use several means to reach groups that are underrepresented in computer science.","title":"Collaborative Research: Fundamentals and Algorithms for Streaming Meshes","awardID":"0430065","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["408891"],"PO":["532791"]},"98029":{"abstract":"Collaborative Research: Language Processing Technology for Electronic Rulemaking <br\/><br\/>Many people today, including news analysts, opinion pollsters, advertisers, and government regulation writers need to interpret, structure, and rapidly master large quantities of opinion-based text. New research is needed to develop text-processing tools that can perform advanced analysis of large text collections. This research will build on current text processing technologies, such as text clustering, text searching using information retrieval, and extractive summaries, to build and test tools tailored to the specific needs of government personnel working in an electronic rulemaking environment. <br\/><br\/>This project's focus is the federal government's several-thousand regulation writers, employed in some 200 agencies, who formulate, in a tightly scripted procedure, the rules and regulations that define the details of our laws. This project will attempt to solve several novel problems central to language processing research. In turn, it will deploy and evaluate a Rule-Writer's Workbench; a set of language tools that enables regulation writers, singly or jointly, to obtain a detailed and multidimensional overview of the material. <br\/>. <br\/>This research has the potential to impact far beyond IT and social science academia. It will explore such novel issues as author typing, opinion\/affect determination, and near-duplicate detection. If even just a handful of the new technologies are effective, they eventually may help thousands of regulation writers more effectively communicate with and understand the comments of millions of citizens in our increasingly digitized society, and produce better regulatory rules for all of us.","title":"Collaborative Research: Language Processing Technology for Electronic Rulemaking","awardID":"0429293","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["491832"],"PO":["565136"]},"94971":{"abstract":"This is a multidisciplinary research program for investigating both the computational principles and the neural mechanisms underlying our visual perception of three-dimensional (3D) surfaces and shapes in the natural world. Its goal is to understand how surfaces of objects are inferred and represented in the brain. The general approach is first to discover the statistical regularities of patterns and structures in 3D natural scenes and to develop a computational framework for representing and inferring these structures from optical images; and second to test neurophysiologically the predictions generated by the computational framework on the neural basis of surface representation and inference. The fundamental hypothesis is that the visual system functions as a hierarchical probabilistic inference system in which the feedforward and feedback connections among the different visual areas in the cortical hierarchy serve to mediate two-way Bayesian belief propagation. In this framework, the brain is conjectured to actively construct a representation of the visual scene based on the retinal input as well as our prior knowledge and experience of the world. The investigator will carry out a novel statistical study of 3D natural scenes, develop efficient probabilistic computational algorithms for surface inference based on natural scene statistics, explore neural models for implementing such algorithms, and test neurophysiologically these models by recording and analyzing neuronal activity in the early visual areas of primate cerebral cortex. It is a tightly coupled interdisciplinary project that involves synergistic research in computer vision, computational neuroscience and systems neuroscience to address fundamental questions in these three fields. Understanding how the brain makes inference about the visual world will have a significant broad impact on neuroscience, clinical medicine and robotics. This integrated study of a hierarchical visual inference system and its associated probabilistic inference algorithms, rooted in natural scene statistics, will contribute to the foundation for building a new generation of flexible and intelligent robotic vision systems. Such systems will be able to learn and adapt to the statistical regularities of a changing environment and make inferences based on scene contexts. The proposed research program also provides an unique educational vehicle of interdisciplinary training to graduate and undergraduate students that will serve as a catalyst to integrate computer science research and biological research in the scientific community at large.","title":"Statistical and Neural Basis of Surface Inference in Vision","awardID":"0413211","effectiveDate":"2004-09-01","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7339","name":"COMPUTER VISION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1185","name":"SENSORY SYSTEMS"}}],"PIcoPI":["550942"],"PO":["317663"]},"94752":{"abstract":"National Science Foundation<br\/>Distributed Systems Research <br\/>CISE\/CNS<br\/><br\/>ABSTRACT<br\/><br\/>Proposal Number: 0412025\/0412029<br\/>Principal Investigator(s): Schulzrinne, Henning\/Frankl, Phyllis Gail<br\/>Institution(s): Columbia University and Polytechnic University of New York<br\/>Proposal Title: Collaborative Research: 7DS - A Mobile Broadband Dis-tributed System<br\/><br\/><br\/>In an ideal world, mobile users would be able to enjoy affordable broadband Internet access everywhere, including in public transportation vehicles (buses, trains and planes), in outdoor spaces not covered by Wi-Fi access points, and in disaster areas where the broadband wired infrastructure may be broken. Unfor-tunately, such Internet access Nirvana will not be available in the foreseeable future. Neither the broadband Internet nor the emerging 2.5-3G cellular data networks will provide Internet access that is at once broadband, affordable and<br\/>ubiquitous. <br\/><br\/>This project prototypes and deploys 7DS, a distributed system which brings us-ers a significant step closer to Internet access Nirvana. Bridging the gap be-tween the broadband Internet and the cellular data networks, 7DS exploits the increasing density of roaming devices that are endowed with both gigabyte stor-age and short-range, broadband wireless communication capabilities. Using asynchronous communication, 7DS provides a means for roaming users to ob-tain content affordably and at high peak rates; it also provides a means for roaming users to send content into the Internet, again affordably and suitable for large objects. The expected results include (i) a comprehensive prototype for 7DS, demonstrating the feasibility of the 7DS system; (ii) new algorithms and protocols for 7DS, which will be disseminated in major conferences and jour-nals and implemented in the prototype; (iii) actual deployment of the 7DS sys-tem on university campuses, demonstrating how 7DS can bridge the gap be-tween localized broadband Wi-Fi access and ubiquitous narrowband cellular data access.<br\/><br\/>Dr. Brett D. Fleisch<br\/>Program Director, CISE\/CNS<br\/>July 20, 2004<br\/>.","title":"Collaborative Research: 7DS - A Mobile Broadband Distributed System","awardID":"0412025","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["518545"],"PO":["543507"]},"94433":{"abstract":"Hsieh-Klefstad Abstract<br\/>---------<br\/><br\/>This research project is developing new software engineering principles,<br\/>techniques, and programming technology based on an improved understanding<br\/>of how crosscutting concerns, such as real-time behavior and memory<br\/>constraints, interact and can be modularized within embedded middleware.<br\/>This project investigates how a combined component-based and<br\/>aspect-oriented software engineering approach can advance the development<br\/>of embedded applications and middleware. Experience with existing<br\/>middleware for distributed, real-time, and embedded (DRE) systems has<br\/>illustrated both the benefits and the limits of implementing<br\/>configurability through previous approaches to components and aspects.<br\/>The research goal is to achieve expressive power through an<br\/>integration of components and aspects. The new model supports aspect<br\/>definition and application at the component level: aspects are constructed<br\/>through new compositional forms, and conversely, aspects introduce<br\/>functionality at the level of component definitions and interconnections.<br\/>Real-time predictability constraints are addressed through the model's<br\/>support for real-time Java: components and aspects adapt to real-time<br\/>concerns according to their contexts. The model allows developers to<br\/>manage complexity in new ways: by allowing flexible middleware<br\/>configuration; by supporting both component-like encapsulation and<br\/>controlled exposure to aspects; and by providing sound type checking of<br\/>middleware configurations. The new techniques are being validated through<br\/>the development of new, modular, and highly configurable DRE middleware<br\/>for real-time Java. <br\/><br\/>The knowledge that comes from this research will<br\/>drive progress in embedded systems development and enable more effective<br\/>techniques for modularizing concerns across application and middleware<br\/>boundaries. The project's technology is expected to be particularly useful for <br\/>designing and building embedded and real-time software systems, as well as software<br\/>systems in general. Both component systems and middleware have become<br\/>popular commercially; this technology should enable and demonstrate the evolution of future component systems and middleware.","title":"Collaborative Research: EHS: Components and Aspects for Embedded Middleware","awardID":"0410285","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":[247495,"518130","557575"],"PO":["561889"]},"98921":{"abstract":"Abstract: <br\/><br\/>This project investigates distributed algorithms for organizing, structuring, and deploying sensor networks so that they can accomplish a variety of high-level global estimation tasks. Special attention is given to probabilistic methods that can deal with sensor noise, signal interference, and measurement inaccuracies. The overall goal is to encapsulate a small number of paradigms for sensor collaboration, information aggregation, and distributed reasoning that can serve a wide variety of applications and ease the burden of implementing this type of networked software anew each time. Communication patterns are explored that combine sensing, information exchange, and processing actions that jointly perform the required estimation in a lightweight, robust, and uncertainty-aware manner. The net effect is to augment the network stack above the data link layer with another layer that is data-driven and performs collaborative reasoning, exploiting sensed information and its value to the network task. Such task-driven communication patterns, once they have been identified and implemented, will facilitate the quick deployment of sensor networks for new tasks and seed additional applications. The collaboration and reasoning problems addressed are important as well for other distributed systems, including distributed data-bases and peer-to-peer networks.<br\/><br\/>Research on this project will combine design, simulation, theoretical analysis, and the implementation of an experimental sensor network testbed within a university building for exploring and validating these ideas.","title":"NeTS+NOSS: Communication Patterns for Collaborative Reasoning in Sensor Networks","awardID":"0435111","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["353783","521232"],"PO":["434241"]},"97953":{"abstract":"ITR-[ECS]-[soc]: Spectrum Management toward Spectrum Plenty<br\/><br\/>Timothy Brown, University of Colorado - Boulder<br\/><br\/>Award 0428887<br\/><br\/>Abstract<br\/><br\/><br\/>Wireless networking technology is the fastest growing segment in the United States telecommunications market and holds out the promise of providing greater broadband competition, increased connectivity in rural areas, and increased communication density in developing nations that are not able to invest in wired infrastructure. But making this vision a reality entails overcoming three formidable barriers that can only be solved through careful interdisciplinary work that pulls together policy, electrical engineering, and computer science expertise. In particular, policymakers need assistance in: (1) identifying opportunities for \"underlay technologies,\" wherein existing licensed spectrum can be protected while affording access to unlicensed uses, as well as new bands for unlicensed spectrum uses; (2) evaluating the technology - both in hardware and software - that will enable unlicensed uses not to cause undue interference with licensed ones or other unlicensed ones; and (3) determining how to best enforce the requirements - i.e., protocols (or etiquette standards) - that ensure that unlicensed uses can co-exist with one another and with licensed ones without causing undue interference.","title":"ITR-[ECS]-[soc]: Spectrum Management toward Spectrum Plenty","awardID":"0428887","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["543625","529582","293319",257909,"543626"],"PO":["434241"]},"98932":{"abstract":"Abstract:<br\/><br\/>Lightweight embeddable sensor systems are revolutionizing the way that we use computers. They have many potential applications, both in the home and in the workplace, creating systems that automatically act to enhance conditions for living and working while reporting useful information to central collecting points.<br\/><br\/>This research investigates new technologies for low-power wireless sensors, including new computational devices, new operating systems, and new algorithms and protocols for exploiting the resulting capabilities. The methods being employed include advanced circuit design, discrete mathematics, algorithm design and analysis, and specialized tools for the development of new software. The research team includes both computer engineers, telecommunications engineers, and computer scientists.<br\/><br\/>Specific results from our work will include sensor platforms that can operate with very little power, allowing for extended, unattended use. Other results include sensor data recovery mechanisms based on mobile platforms, allowing for rapid data collection as cars or other mobile platforms move through fields of sensors. New software tools will also be developed that collect, combine, and present information to human users in a meaningful manner.<br\/><br\/>Results from this project are being made available to research and development engineers throughout the country. Processors, novel algorithms, software tools, and operating systems will be made available on the Internet, and will be described in scholarly journals and at conferences. An effort is being made, in particular, to make these results available to corporations interested in furthering their application and making them commercially available to the public at large.","title":"NETS-NOSS: Ultra Low-Power Self-Configuring Wireless","awardID":"0435190","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["495285","450625","531874","475375","483774"],"PO":["564777"]},"95302":{"abstract":"The most fundamental aspects of statistical modeling in speech recognition, linear Gaussian statistics, have been essentially unchanged in the past 20 years. Fundamental advancement is required if speech recognition is to become a pervasive technology in a myriad of applications requiring robustness to severe amounts of noise (e.g., cell phones and in-vehicle automotive applications). Nonlinear statistical models for speech were first proposed in the early 1980's when fractals and other such techniques promised great advances in compression. Since then progress has been slow but steady. Recent advances in various areas of speech processing, such as pitch determination and speech modeling, plus staggering advances in computational resources, suggest that these models are now viable for traditional problems such as speaker recognition, speaker verification, and speech recognition. Nonlinear dynamics provide a framework that supports parsimonious statistical models that may overcome many of the limitations of current hidden Markov model based techniques. <br\/><br\/>This research involves extending the traditional supervised-learning HMM paradigm to support a chaotic acoustic model that incorporates a nonlinear statistical model of observation vectors and then evaluating the impact of this model on text-independent speaker verification applications. The primary goal is to understand acoustic variation at the phonetic level in a more comprehensive and efficient manner. The proposed research could go far to enhance the potential practicality of nonlinear speech modeling. In addition, the computational tools and resources to be developed are expected to enhance the existing infrastructure for Internet accessible speech recognition, while promoting better understanding of speech in both research and education.","title":"Nonlinear Statistical Modeling of Speech","awardID":"0414450","effectiveDate":"2004-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V839","name":"NSA-HUMAN LANGUAGE & COM PROG"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["543480"],"PO":["565215"]},"98943":{"abstract":"This research project aims to develop an integrated network layer capable of supporting unicast, multicast, and publish-subscribe services on a given topol-ogy using a single mechanism. Such a service would subsume many of the special-purpose approaches (e.g. overlays) currently being proposed and used, and would support novel applications and mobility in a more direct, unified way. The approach is based on the use of predicates carried in packets to iden-tify packet destinations. In other words, the network defines a set of predicates over end systems; each packet carries a predicate from this set, suitably en-coded, and the job of the network is to deliver the packet (on a best-effort basis) to all end systems that satisfy its destination predicate (and to as few others as possible). The major challenge is to design the enrollment, routing, and for-warding algorithms of the service in such a way that the system can scale up to support networks much larger than the current Internet. The goal is to achieve this with overall performance, administrative, and operational overhead compa-rable to or better than existing approaches. This research project will explore the fundamental relationships and tradeoffs among topology, forwarding effi-ciency, and predicate language. It will develop predicate structures that strike a suitable balance between expressive power and efficiency. Finally, the project will design, analyze and evaluate efficient routing and forwarding algorithms and protocols based on those predicate structures. Results of the research have the potential to enable new networks capable of supporting a greater variety of application services while avoiding problems with wide-area routing administra-tion that hamper the current system.","title":"NeTS-NR: Generalizing the Network Layer","awardID":"0435272","effectiveDate":"2004-09-15","expirationDate":"2010-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["530999","483390"],"PO":["565090"]},"96655":{"abstract":"This project, developing a Highly Interactive Parallelized Display Wall (HIPerWall) new visualization facility, aims at advancing the state of Earth Science modeling and visualization. HIPerWall is a high performance visualization system with a wall-sized ultra high-density tiled display that operates at the perception threshold of the human eye, allowing researchers to view and manipulate their data sets at resolutions commensurate with large-scale grids or dense sensor network data. The facility will be able to display extremely high-resolution datasets that will drive and provide focus for on-going research into management, transfer, and visualization of terabyte-scale data. By rapid, visual comparison of theory with experimental data, scientists should be able to swiftly validate and comprehend theory and practice. Although the proposed research is focused on Earth System Sciences, other research areas will benefit, including,<br\/>Computational Fluid Dynamics <br\/> Direct numerical simulation of turbulent chemically reacting and dispersed 2-phase flows,<br\/>Engineering Mechanics <br\/> System identification using 3D video tracking; <br\/>o Microwave imaging for damage visualization; <br\/>o Remote system monitoring,<br\/>Structural and Earthquake Engineering <br\/>o Advanced scientific visualization of dynamics of systems; <br\/>o Model-based simulation of experimental data from large and medium scale earthquake testing;<br\/>o Analysis of large-scale earthquake field data,<br\/>Materials and Devices <br\/>o Molecular modeling and visualization; <br\/>o Synthesis of structural materials and composites; <br\/>o Mathematical modeling of advanced materials and processes; <br\/>o Material characterization,<br\/>Embodied Interaction in Immersive Systems <br\/>o Novel sensor technologies and modes of interaction for cultural and technical applications,<br\/>Scientific Computing, <br\/>o Large scale data visualization;<br\/>o Storage, compression and access of stored real time simulation data; <br\/>o Image based rendering; <br\/>o 3D data reconstruction, and <br\/>Biomedical Engineering <br\/>o Computer simulation and tissue engineering; <br\/>o Imaging and image understanding.<br\/><br\/>Broader Impact: The facility, to be set in a large classroom, directly contributes to education through courses and recruiting efforts. The display wall benefits collaborations that have impact on areas such as homeland security and emergency response.","title":"MRI: HIPerWall: Development of a High-Performance Visualization System for Collaborative Earth System Sciences","awardID":"0421554","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["475291","554542","338406",253981,"557605"],"PO":["557609"]},"97997":{"abstract":"As part of the joint NSF\/NASA High-Dependability Computing and <br\/>Communication<br\/>Systems Research effort, this project is developing, adapting and <br\/>integrating a variety of program analysis techniques for the Real-time<br\/>Specification for Java (RTSJ). RTSJ is an emerging language extension<br\/>for Java that is designed for implementing concurrent time-critical<br\/>embedded software, for example, the control software on NASA's<br\/>robotic Mars rovers. This type of software is notoriously difficult to<br\/>test and debug, and the model-checking, light-weight static and dynamic<br\/>analysis techniques being developed as part of this project promise to<br\/>identify bugs before software is deployed to the field and to produce<br\/>systems that function more reliably.<br\/><br\/>A cornerstone of this project is the use of controlled experimentation <br\/>to judge the effectiveness of new analysis techniques. As part of this <br\/>effort, RTSJ programs and experimental frameworks will be developed that support<br\/>repeatable experimentation for determining analysis performance and the <br\/>precision of analysis results. Experiment findings will drive the refinement of<br\/>analysis techniques. Case studies using NASA testbed software will serve<br\/>to evaluate the scalability and applicability to NASA-relevant software<br\/>challenges.<br\/><br\/>If successful, this project promises to provide developers of next <br\/>generation real-time embedded software, both at NASA and throughout the embedded<br\/>systems domain, with a suite of powerful quality-assurance tools that <br\/>will allow them to more cost-effectively produce higher-quality systems.<br\/>Given the pace at which software is being embedded in our society's<br\/>infra-structure, this could have broad impacts on the degree to which <br\/>we can rely on such systems.","title":"Collaborative Research: Program Analysis Techniques to Support Dependable RTSJ Applications","awardID":"0429149","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}}],"PIcoPI":["561782","548132","486378","518212"],"PO":["564388"]},"98976":{"abstract":"Radio frequency identification (RFID) is expected to become an important and ubiquitous infrastructure technology. Based on the science and engineering of RFID technology, a new form of space \"Animated Space\" is envisioned to bridge the gap between physical and digital world in which real-world objects can communicate with users in order to convey their purpose, function, and history. Animated Space allows interaction of people in the space and provides timely and additional information, which will enhance human activities and help in developing interest and discussion groups by associating information with objects and places. The designed network-based middleware for animated spaces, ASPEN, empowers the network infrastructure to deliver the information stored in the animated space to mobile users. Some of the unique features of ASPEN include: 1) the innovative mechanism for creating smart objects, 2) protocol for interaction with smart objects and smart devices, 3) sharing of information with other users using synchronous and asynchronous peer-to-peer communication, 4) object-oriented component model for content delivery depending upon user and device profile, 5) dynamic and intelligent content adaptation techniques and 6) efficient information storage in various formats, and reading levels and its retrieval. The animated space can lead to potentially very effective type of information evolution that can complement other information models and can reach a wide variety of people across a spectrum of settings. The work will have enormous potential to benefit society in areas such as education (e.g., informal learning, professional and technical learning, and special education such as delivery of content to people with disabilities) and safety (e.g. in emergency relief cases where multiple devices are used and interoperability of these devices would be beneficial).","title":"NeTS-NR: Economics Mechanisms for Networks","awardID":"0435480","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["554417","406461"],"PO":["565090"]},"96435":{"abstract":"This work, developing a robot platform based on the University of Minnesota Scout robot, proposes a suite of well-orchestrated efforts to design a new Scout robot that addresses some challenges involving flexibility for later design upgrades and mobility over rough terrain. The efforts include a completely new overall design with an impact on performance in terms of mobility, manipulation, and communication capabilities, the creation of a software backbone system for sensory processing and communication among different miniature robots in order to create an effective team, and the development of a saddle pack structure based in the MegaScouts platform. Expected to contribute to the field of miniature robot design resulting in heterogeneous robot teams that will be far more effective in tasks such as search\/rescue operation, the project involves:<br\/> Development of a new Scout robot with a new smaller form factor designed with new mobility, manipulation, and robot-linking mechanisms. A low-cost, flexible platform will be created with multiple direct applications, including serving as an educational tool.<br\/> Creation of a software backbone system addressing autonomous Scout operation, intelligent failure recovery, software reusability, and automatic creation of mission scenarios.<br\/>* Development of a saddle pack system based on the MegaScout platform and used for Scout deployment and control.<br\/>* Investigation of communication methodologies applicable to the Scout platform, focusing on transparent integration of new communication technologies (e.g., ultra-wideband, various 802.11 standards) as these arise, without the design of entirely new communication hardware to fit the Scouts.<br\/>* Development of multi-modal interfaces for the new Scout robot.<br\/>* Experimental validation through a series of experiments involving a large number of the new scout robots in diverse environments to examine the relative merits and tradeoffs involved in team- versus single-robot operations.<br\/>* Transition from experimental robotics to real world applications with the creation of a large number of low-cost (and thus expendable) robots.<br\/>The underlying small mobile Minnesota Scout robot can be employed in a variety of applications, including search\/rescue missions, locating the source of a biological or chemical release, decontamination and decommissioning efforts, and monitoring highly sensitive areas of populations, such as elderly or disabled patients in residential care.<br\/>Broader Impacts involve: <br\/>* Re-designing relevant courses ( Robotics, AI, Communication Systems, introductory CS courses),<br\/>* Integration of the robotics platform into various levels of the curricula, <br\/>* Outreach activities for retaining members of underrepresented groups in CS, CE, EE,<br\/>* Outreach efforts through demonstrations at local K-12 schools and youth groups,<br\/>* Seminars promoting cross-disciplinary interaction,<br\/>* Creation of web resources for web-based design and execution of formation strategies for mobile miniature robotics teams, <br\/>* Innovative use of the algorithms and hardware in sites (elderly care centers with the goals of improving resident's safety).","title":"MRI: Development of a New Generation of Miniature Search\/Rescue Robots","awardID":"0420836","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["564051","557449","553283","288409",253023],"PO":["557609"]},"98987":{"abstract":"NeTS-NR: Real-Time Communication Support in an Ubiquitous Next-Generation Internet<br\/><br\/>Elizabeth Belding-Royer, UC Santa Barbara<br\/><br\/>Award 0435527<br\/><br\/>Abstract<br\/><br\/>The trend in Internet deployment is for more advanced, more capable, and more sophisticated applications combined with a growing part of the infrastructure as untethered, mobile nodes. These trends create a requirement for a truly capable and robust network infrastructure to seamlessly deliver data, including real-time streaming data (e.g. voice and video), even though nodes may have heterogeneous capabilities, be on the move, and\/or be connected via a wireless link. <br\/><br\/>To meet the challenges of the evolving Internet, we are developing new solutions to better handle the emerging network and traffic challenges for the next-generation Internet. The next-generation Internet will need to support traditional services (e.g. streaming voice), next-generation applications (e.g. gaming,<br\/>social computing), and a set of applications we have not yet even conceptualized. We are building a network to support the significant functionality demanded by these applications. Our set of integrated research projects attempts to develop revolutionary cross-layer solutions for the support of voice and multimedia services in mobile networks. Specifically, we focus on three problems: (i) Coding support for real-time voice; (ii) Routing solutions for real-time applications; and (iii) Formalizing and extending wireless network testbeds. <br\/><br\/>As an educational impact, not only are we able to achieve traditional key educational objectives, but we are able to connect our work with specific projects at UCSB that expand education opportunities and diversity.","title":"NeTS: Real-Time Communication Support in an Ubiquitous Next-Generation Internet","awardID":"0435527","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["410030","552796","560332"],"PO":["434241"]},"97557":{"abstract":"The Nanoscale Science and Engineering Center entitled New England Nanomanufacturing Center for Enabling Tools is a partnership between Northeastern University, the University of Massachusetts Lowell, the University of New Hampshire, and Michigan State University. The NSEC unites 34 investigators from 9 departments. <br\/><br\/>The NSEC is likely to impact solutions to three critical and fundamental technical problems in nanomanufacturing:<br\/><br\/>Control of the assembly of 3D heterogeneous systems, including the alignment, registration, and interconnection at three dimensions and with multiple functionalities,<br\/>Processing of nanoscale structures in a high-rate\/high-volume manner, without compromising the beneficial nanoscale properties,<br\/>Testing the long-term reliability of nano components, and detect, remove, or prevent defects and contamination.<br\/><br\/>Novel tools and processes will enable high-rate\/high-volume bottom-up, precise, parallel assembly of nanoelements (such as carbon nanotubes, nanorods, and proteins) and polymer nanostructures. This Center will contribute a fundamental understanding of the interfacial behavior and forces required to assemble, detach, and transfer nanoelements, required for guided self-assembly at high rates and over large areas.<br\/><br\/>The Center is expected to have broader impacts by bridging the gap between scientific research and the creation of commercial products by established and emerging industries, such as electronic, medical, and automotive. Long-standing ties with industry will also facilitate technology transfer. The Center builds on an already existing network of partnerships among industry, universities, and K-12 teachers and students to deliver the much-needed education in nanomanufacturing, including its environmental, economic, and societal implications, to the current and emerging workforce. The collaboration of a private and two public universities from two states, all within a one hour commute, will lead to a new center model, with extensive interaction and education for students, faculty, and outreach partners. The proposed partnership between NENCET and the Museum of Science (Boston) will foster in the general public the understanding that is required for the acceptance and growth of nanomanufacturing. <br\/><br\/>The Center will study the societal implications of nanotechnology, including conducting environmental assessments of the impact of nanomanufacturing during process development. In addition, the Center will evaluate the economic viability in light of environmental and public health findings, and the ethical and regulatory policy issues related to developmental technology.","title":"NSEC: The Center for High-rate Nanomanufacturing (CHN)","awardID":"0425826","effectiveDate":"2004-09-01","expirationDate":"2009-12-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1735","name":"MATERIALS RSCH SCI & ENG CENT"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8815","name":"Studies of Policy Sci Eng Tech"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7681","name":"ENG NNI SPECIAL STUDIES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7702","name":"SOCIETAL IMPLICATIONS OF NANO"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1385","name":"SPECIAL STUDIES AND ANALYSES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1480","name":"ENGINEERING RESEARCH CENTERS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"7218","name":"RET SUPPLEMENTS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"7237","name":"NANO NON-SOLIC SCI & ENG AWD"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0706","name":"Division of DESIGN & MANUFACTURING INNOV","abbr":"DMI"},"pgm":{"id":"7637","name":"NANTOXICOLOGY"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7645","name":"DISCOVERY RESEARCH K-12"}}],"PIcoPI":["539988","382687","282285","465308","487702"],"PO":["562464"]},"96248":{"abstract":"Abstract<br\/><br\/>Title: ITWF Collaborative Research: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science<br\/><br\/>CNS 0420505, PI Kamin, Univ. of Illinois at Urbana-Champaign<br\/>CNS 0420000, PI Califf, Illinois State University<br\/>CNS 0420458, PI Lucht, Heartland Community College<br\/>CNS 0420468, PI Mobasseri, Parkland College<br\/>CNS 0420506, PI Uskov, Bradley University<br\/>CNS 0420321, PI Van Cleave, Eastern Illinois University<br\/><br\/><br\/><br\/>This collaborative ITWF project implements a set of activities designed to increase participation of women and under-represented minorities in undergraduate computer science programs in the state of Illinois. The project includes high school outreach, curriculum reform, mentoring, and other extracurricular activities. It is a collaborative project between the University of Illinois at Urbana-Champaign, Illinois State University, Heartland Community College, Parkland College, Bradley University, and Eastern Illinois University. The project involves building communities among various groups within the state to recruit, support, and retain students in computing courses and programs.<br\/><br\/>The intellectual merit of this project lies in the strong research basis for the intervention models as well as the vertical integration of the models at a range of secondary and post-secondary institutions within the state. The project plan is clear and reasonable with well-defined roles for the partners. The project builds on existing programs and partnerships within the state and includes investigators with significant relevant experience.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science within one state. If successful, the project may provide a sound model for similar broad-based approaches in other states and geographical areas.","title":"Collaborative Research: ITWF: Building Communities: Recruiting and Retention of Underrepresented Groups in Computer Science","awardID":"0420000","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[252343],"PO":["361119"]},"98206":{"abstract":"0430585 <br\/>Wagner, David <br\/>Collaborative Research: Type Qualifiers for Software Security<br\/>0430378 Alex Aiken 0430118 Foster, Jeffrey <br\/><br\/>This research aims to develop tools and techniques to find and eliminate security vulnerabilities in software. The approach is based on static analysis, which by analyzing source code can model all possible executions of a program. The distinguishing feature of the project is to show that very large applications are free from classes of security vulnerabilities. Thus, the focus is not just in finding security holes in software, but in verifying their absence. Previous experience has shown that simple, approximate tools do not find all or even nearly all security vulnerabilities; the higher assurance given by verification is needed. The experimental goal is to apply these techniques to the Linux kernel, a security-critical application with millions of lines of code.<br\/><br\/>The main technical approach being investigated is based on user-defined type qualifiers that refine the standard types of the programming language. Previous work has shown that type qualifiers are a natural and useful way to explicitly specify desired security properties that are normally only implicit in a program. In much the same way that a correctly typed program cannot have run-time type errors, having consistent type qualifiers throughout a program implies that the property expressed by those qualifiers must hold in every execution. The significance of this work is that, if successful, it will improve the understanding of how to perform sophisticated static analysis of very large programs. The broader impact will be in discovering and repairing new security vulnerabilities in widely-used software infrastructure and in verifying that some of that infrastructure is free from at least some security flaws.","title":"Collaborative Research: Type Qualifiers for Software Security","awardID":"0430585","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T470","name":"DARPA-NSF CYBER TRUST PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T951","name":"DARPA - CYBER TRUST PHASE III"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V901","name":"DARPA-NSF CYBER TRUST PROGRAM"}}],"PIcoPI":["550026"],"PO":["564388"]},"98228":{"abstract":"Abtract<br\/>Multicast networks have been proposed in the last years as a new technique for information routing<br\/>and sharing. This new technology has an increasing number of applications in diverse fields, ranging<br\/>from financial data distribution to video-conferencing, automatic software updates and groupware.<br\/>In multicast networks, the objective is to send information from a source to multiple users with a<br\/>single send operation. This approach allows one to save bandwidth, since data can be shared across<br\/>network links. Multicast network applications often require the solution of diffcult combinatorial<br\/>optimization problems. Most of these problems are NP-hard, which makes them very unlikely to<br\/>be solved exactly in polynomial time. Therefore, specialized algorithms must be developed that<br\/>give reasonable good solutions for the instances found in practice. The intrinsic complexity of these<br\/>problems has been a technological barrier for the wide deployment of multicast services.<br\/>We propose to design and study algorithms for some of the most important combinatorial<br\/>problems occurring in the area of multicast networks. One of the problems in this area asks for<br\/>the determination of an optimum route to be followed by packages in a multicast group. This<br\/>is known as the multicast routing problem (MRP). A large number of heuristic algorithms have<br\/>being proposed in the last years to solve the MRP, which is of great interest for network engineers.<br\/>However, most of these heuristics do not give any guarantee of optimality and frequently are not able<br\/>to find the global optimum for the problem. A second problem of great practical importance is that<br\/>of finding the minimum number of cache nodes required to send multicast data when capacities are<br\/>considered in the network links. This is also called the streaming cache placement problem (SCPP).<br\/>The SCPP has been only recently studied, and it presents many opportunities for economy in the<br\/>development of new multicast systems.<br\/>The objective of this project is to study these and related problems occurring in multicast routing.<br\/>Our goal is to find practical methods that can be used to implement efficiently the technologies<br\/>involved with multicast applications. The development of fast algorithms for solving these problems<br\/>represents an important step in allowing full scale implementations of multicast systems.<br\/>Intellectual Merit of the Proposed Activities. Multicast problems are among the most<br\/>difficult in the area of networks from the theoretical point of view. This happens since such problems<br\/>encompass the construction of solutions involving a large number of nodes, interacting in a very<br\/>complicated way. New concepts appearing in this area are, for example, the interplay of diverse<br\/>source and destination nodes to achieve a common objective in a network structure. Our knowledge<br\/>in multicast networks will have applications in other areas of network algorithmic research.<br\/>The techniques proposed to solve the problems discussed above will involve mathematical programming,<br\/>approximation algorithms, metaheuristics for combinatorial optimization, large scale<br\/>computing, and parallel and distributed computing. These techniques are among the specialities of<br\/>the PI and his research group.<br\/>Broader Impact. The techniques developed in the context of this project will have broad impact<br\/>in industrial practices for multicast network systems. A deep understanding of the algorithmic<br\/>issues related to such applications will foster the development of better protocols, new routing implementations and improved end-user software. Beyond this, theoretical advances in this area will<br\/>have natural applications in other network problems, such as routing and transportation systems.<br\/>1","title":"Design and Analysis of Algorithms for Multicast Networks","awardID":"0430709","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["438489"],"PO":["381214"]},"98019":{"abstract":"Collaborative Research: Language Processing Technology for Electronic Rulemaking <br\/><br\/>Many people today, including news analysts, opinion pollsters, advertisers, and government regulation writers need to interpret, structure, and rapidly master large quantities of opinion-based text. New research is needed to develop text-processing tools that can perform advanced analysis of large text collections. This research will build on current text processing technologies, such as text clustering, text searching using information retrieval, and extractive summaries, to build and test tools tailored to the specific needs of government personnel working in an electronic rulemaking environment. <br\/><br\/>This project's focus is the federal government's several-thousand regulation writers, employed in some 200 agencies, who formulate, in a tightly scripted procedure, the rules and regulations that define the details of our laws. This project will attempt to solve several novel problems central to language processing research. In turn, it will deploy and evaluate a Rule-Writer's Workbench; a set of language tools that enables regulation writers, singly or jointly, to obtain a detailed and multidimensional overview of the material. <br\/>. <br\/>This research has the potential to impact far beyond IT and social science academia. It will explore such novel issues as author typing, opinion\/affect determination, and near-duplicate detection. If even just a handful of the new technologies are effective, they eventually may help thousands of regulation writers more effectively communicate with and understand the comments of millions of citizens in our increasingly digitized society, and produce better regulatory rules for all of us.","title":"Collaborative Research: Language Processing Technology for Electronic Rulemaking","awardID":"0429243","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":[258114],"PO":["565136"]},"95842":{"abstract":"Signal Processing for Communications (SP-COM) is an area that focuses on re-search associated with the infrastructure, hardware, and algorithms of future generation digital communications systems. The primary objective of the CRCD\/EI project is to provide scientific and investigative experiences to under-graduate students by immersing them into state-of-the-art communications and signal processing research. The methods employed to accomplish this ob-jective use curriculum strategies that include: a) immersing research-oriented modules in four existing junior and senior level classes, b) offering a new senior level undergraduate course entitled \"Introduction to signal processing and communications research,\" c) the integration of senior-level capstone projects in the ongoing research activities of the PIs, d) the institution of summer research freshman and sophomore camps along with an outreach program. The project will impact student learning by instilling the process of scientific inquiry through a continuous research exposure in the undergraduate curriculum. Several SP-COM research topics, such as those dealing with channel equaliza-tion, source and channel coding, are immersed in courses within the framework of this CRCD project. CRCD curriculum courses and modules involve at least one self-contained computer laboratory experience. ASU's Java-DSP (J-DSP) web-based simulation environment is used for these laboratories. Students can access J-DSP on the web, perform computer laboratory exercises, and submit electronic lab reports. Significant pedagogical foundations and strategies for the transition of research to the curriculum are formed with the assistance of in-structional specialists. Dissemination and assessment strategies include: an annual CRCD workshop, a CRCD interactive web site, publications in research and education journals, industrial dissemination through industry partners.","title":"CRCD\/EI: Combined Research Curriculum Development in Signal Processing for Communications","awardID":"0417604","effectiveDate":"2004-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["544879","486150","478524","544880"],"PO":["551712"]},"94753":{"abstract":"National Science Foundation<br\/>Distributed Systems Research <br\/>CISE\/CNS<br\/><br\/>ABSTRACT<br\/><br\/>Proposal Number: 0412025\/0412029<br\/>Principal Investigator(s): Schulzrinne, Henning\/Frankl, Phyllis Gail<br\/>Institution(s): Columbia University and Polytechnic University of New York<br\/>Proposal Title: Collaborative Research: 7DS - A Mobile Broadband Dis-tributed System<br\/><br\/><br\/>In an ideal world, mobile users would be able to enjoy affordable broadband Internet access everywhere, including in public transportation vehicles (buses, trains and planes), in outdoor spaces not covered by Wi-Fi access points, and in disaster areas where the broadband wired infrastructure may be broken. Unfor-tunately, such Internet access Nirvana will not be available in the foreseeable future. Neither the broadband Internet nor the emerging 2.5-3G cellular data networks will provide Internet access that is at once broadband, affordable and<br\/>ubiquitous. <br\/><br\/>This project prototypes and deploys 7DS, a distributed system which brings us-ers a significant step closer to Internet access Nirvana. Bridging the gap be-tween the broadband Internet and the cellular data networks, 7DS exploits the increasing density of roaming devices that are endowed with both gigabyte stor-age and short-range, broadband wireless communication capabilities. Using asynchronous communication, 7DS provides a means for roaming users to ob-tain content affordably and at high peak rates; it also provides a means for roaming users to send content into the Internet, again affordably and suitable for large objects. The expected results include (i) a comprehensive prototype for 7DS, demonstrating the feasibility of the 7DS system; (ii) new algorithms and protocols for 7DS, which will be disseminated in major conferences and jour-nals and implemented in the prototype; (iii) actual deployment of the 7DS sys-tem on university campuses, demonstrating how 7DS can bridge the gap be-tween localized broadband Wi-Fi access and ubiquitous narrowband cellular data access.<br\/><br\/>Dr. Brett D. Fleisch<br\/>Program Director, CISE\/CNS<br\/>July 20, 2004<br\/>.","title":"Collaborative Research: 7DS - A Mobile Broadband Distributed System","awardID":"0412029","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550020","528387"],"PO":["561889"]},"91486":{"abstract":"This project addresses theoretical and computational aspects of integer programming and combinatorial optimization, using the tools of linear algebra and graph theory. It is focused on the approach called lift-and-project, developed in the nineties and recently incorporated into state-of-the-art software. Lift-and-project cuts are generated from a disjunction involving a combination of inequalities. One topic for investigation is how to simultaneously optimize the weighted combination of inequalities used in the disjunction underlying the cut, and the choice of multipliers in the monoidal strengthening of the resulting cut. Another topic in the same direction offers to improve the performance of Gomory cuts for mixed integer linear programs, by combining inequalities in well-defined ways. Other topics, aimed at understanding the structure of Lehman matrices and almost totally unimodular matrices, or an algorithm for finding an odd hole in a graph, are related to two important classes of problems: set packing and set covering. A better understanding of these classes of problems is a central aspect of the very active research currently occurring in the field of combinatorial optimization.<br\/><br\/>To the extent that this project will be successful, it will advance the state of the art in mixed integer and combinatorial optimization, and thereby enhance our problem solving ability in a broad range of activities, from industrial production to logistics and telecommunications. The tools created here may be as useful in improving homeland security, as they may be instrumental in reinforcing our technological leadership. From the late fifties to the early nineties, integer programming was a way to formulate almost any optimization problem, yet the available computer codes could only handle toy problems of minuscule size. During the last decade the state of the art has radically changed, and today well over half of the integer programs formulated can also be solved. This project is expected to significantly accelerate this change.","title":"Polyhedral and Graph Theoretic Methods in Mixed Integer and Combinatorial Optimization","awardID":"0352885","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":["539128","539129"],"PO":["351577"]},"97910":{"abstract":"Proposal Number: 0428422<br\/><br\/>Title: An Economic Approach to Security<br\/><br\/>PI: Joan Feigenbaum<br\/><br\/>Abstract <br\/><br\/>Internet security is universally seen as an extremely important problem. Moreover, technical solutions developed over the last three decades represent deep and elegant intellectual contributions. Yet few of these solutions are in widespread use. Clearly something is amiss. It has recently been argued, by Anderson and others, that the missing linkis economics: Only through understanding the incentives inherent in various security proposals can one decide which, if any, would actually lead to greater security. This research project is a three-year, multi-institutional, multi-disciplinary investigation of the economics of security in networked environments. Specific research topics include security of interdomain routing, adoptability of trusted platforms, and markets for private information. The intellectual merit and broader impact of the project are intertwined, both based on the potential not only to solve technical problems but also to develop general analytical techniques for evaluating candidate solutions to real security problems in a manner that gives adoption incentives their just due. If successful, it will lead to greater actual security, rather than simply to more available security technology. Educational activity that integrates security, networking, and economics is also a major goal one on which the investigators have experience on both graduate and undergraduate levels.","title":"An Economic Approach to Security","awardID":"0428422","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["560562","450982","516801"],"PO":["521752"]},"93554":{"abstract":"Proposal: NSF-0406325<br\/><br\/>Title: SGER: Exploring pervasive security<br\/><br\/>PI: Zhaoyu Liu<br\/><br\/>Pervasive applications should be able to select the proper security services based on the hardware and environments, without concerns about the implementation and configuration details. However, most existing security systems, which are not built for the light, thin devices of pervasive computing environments, cannot provide quality of protection to applications. The proposed research will explore a capsule-based security system to support flexible quality of protection in pervasive environments. The PI will develop a model of security as services that centers on people, instead on devices, for improving the usability of security. A testbed will be designed and implemented to evaluate and demonstrate the proposed security system. The proposed research will generate excellent topics for graduate and undergraduate education, covering security, robustness, and design of distributed applications and capsule-based systems. The involved students include under-represented minorities from HBCU at North Carolina.","title":"SGER: Exploring Pervasive Security","awardID":"0406325","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":[245227],"PO":["497499"]},"93565":{"abstract":"An important and visible trend in empirical science today is<br\/>the increasing prevalence of large data sets that contain from thousands to<br\/>hundreds of millions of measurements. Examples include data sets arising<br\/>from high throughput measurement techniques such as gene expression arrays,<br\/>proteomics and computer network monitoring. While the analysis of large<br\/>data sets is important to scientists, it is often outside the realm of<br\/>classical statistical methods, and frequently presents new conceptual and<br\/>computational challenges. The funded research has two principle parts. In<br\/>the first, the investigators are studying the application of a relatively<br\/>new development in the field of Data Mining, known as subspace clustering,<br\/>to the exploratory statistical analysis of high dimensional data. In the<br\/>second, the investigators are applying ideas from Statistics and Probability<br\/>to the development of new subspace clustering methods, and to rigorous<br\/>mathematical analyses of their results. Research is being carried out in<br\/>the context of ongoing collaborations with biological scientists, and is<br\/>being incorporated in software that will be used by the collaborating<br\/>scientists to identify and assess significant sample-variable<br\/>associations in a variety of large data sets.<br\/><br\/><br\/>An important and visible trend in empirical science today <br\/>is the increasing prominence of large data sets that contain from<br\/>thousands to hundreds of millions of<br\/>measurements. Examples include data sets arising from high throughput<br\/>measurement techniques such as gene expression arrays, proteomics and<br\/>computer network monitoring. Whereas small to moderate data sets typically<br\/>have more samples than measurements, in large data sets it is common to have<br\/>more measurements than samples, so-called ``high dimension and low sample<br\/>size''. The investigators are studying the application of data mining<br\/>methods known as subspace clustering to the exploratory analysis of high<br\/>dimensional data. Subspace clustering identifies distinguished sample<br\/>variable interactions (submatrices) in a given data matrix. Unlike standard<br\/>two-way clustering, the sample and variable sets for different clusters can<br\/>overlap. The investigators are investigating the noise sensitivity of<br\/>existing subspace clustering algorithms, and are developing and<br\/>implementing new subspace clustering methods for average based selection<br\/>criteria that are better suited for applications where noise is present.<br\/>As an application of these methods, they are using subspace clusters to<br\/>classify high dimensional data. Using a variety of tools from combinatorial<br\/>probability, the investigators are also developing a rigorous theoretical<br\/>framework in which multiple testing and the statistical significance of<br\/>subspace clusters can be addressed. The funded research is being carried out<br\/>in the context of ongoing collaborations with biologists and computer<br\/>scientists.","title":"Analysis of High Dimensional Data Using Subspace Clustering","awardID":"0406361","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["545866","234536"],"PO":["565309"]},"94896":{"abstract":"Hypothesis Formation and Testing in an Interpretive Domain:<br\/>a Model and Intelligent Tutoring System<br\/><br\/>Abstract<br\/><br\/>Since the days of Bacon and Galileo, formulating hypotheses about natural phenomena and testing them against empirical data have been cornerstones of the natural sciences. As a cognitive framework, hypothesis formation and testing are also important in legal reasoning. The legal domain, however, is different from natural science and mathematics in a significant respect. Determining whether a hypothesized rule and proposed outcome are consistent with past legal decisions is much more a matter of interpretation. The aims of this project are to (1) design and evaluate an Artificial Intelligence (AI) cognitive model of framing and testing hypotheses in an interpretive domain, legal reasoning, and (2) incorporate the model in an intelligent tutoring system (ITS) to teach law students the process. <br\/>The project builds upon two recent developments: (1) a newly invented means to frame and evaluate hypotheses predicting the outcomes of new cases based on an AI database of existing precedents; (2) a convenient, on-line corpus of U.S. Supreme Court oral arguments in aural and written form, including many concrete examples of legal hypothesis framing and testing. In response to an advocate's proposed hypothesis of how the case should be decided, the Justices often challenge it by posing hypotheticals, sometimes forcing the advocate to modify or abandon the hypothesis. <br\/>By studying these examples, the researchers, participating law students and law faculty will schematize and model the process of framing and testing legal hypotheses, implement it computationally, evaluate it empirically, and use it to design the ITS. <br\/>The tutor will implement the model in various legal domains, each with a body of legal rules, issues, precedents, and principles, operationalized in a way that supports hypothesis formulation, prediction, testing, and explanation. Using the model, it will guide and challenge students' arguments. It will predict outcomes of cases, help students construct tests and rationales justifying the prediction, and help them evaluate the hypothesis by posing or responding to hypothetical challenges.<br\/>The researchers will evaluate the project's success in terms of: (1) the accuracy of the model's predictions for new cases and the extent it improves case retrieval; (2) how well model-generated arguments compare to those in the Supreme Court oral arguments or generated by law students; (3) how well ITS-trained students compare to a control group taught the same process using conventional law school methods; (4) whether ITS-trained students generate more accurate self-explanations of the Supreme Court oral arguments.<br\/> This work extends AI techniques to a much less well-structured domain than natural science and mathematics, one more like the common sense domains AI has yet to address. By using AI to investigate empirically a cognitive phenomenon, framing and testing hypotheses in an interpretive domain, it will contribute to research in AI & Law, Case-based Reasoning, AI & Education, and Cognitive Science.","title":"Hypothesis Formation and Testing in an Interpretive Domain: a Model and Intelligent Tutoring System","awardID":"0412830","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["488662"],"PO":["564318"]},"94423":{"abstract":"Hsieh-Klefstad Abstract<br\/>---------<br\/><br\/>This research project is developing new software engineering principles,<br\/>techniques, and programming technology based on an improved understanding<br\/>of how crosscutting concerns, such as real-time behavior and memory<br\/>constraints, interact and can be modularized within embedded middleware.<br\/>This project investigates how a combined component-based and<br\/>aspect-oriented software engineering approach can advance the development<br\/>of embedded applications and middleware. Experience with existing<br\/>middleware for distributed, real-time, and embedded (DRE) systems has<br\/>illustrated both the benefits and the limits of implementing<br\/>configurability through previous approaches to components and aspects.<br\/>The research goal is to achieve expressive power through an<br\/>integration of components and aspects. The new model supports aspect<br\/>definition and application at the component level: aspects are constructed<br\/>through new compositional forms, and conversely, aspects introduce<br\/>functionality at the level of component definitions and interconnections.<br\/>Real-time predictability constraints are addressed through the model's<br\/>support for real-time Java: components and aspects adapt to real-time<br\/>concerns according to their contexts. The model allows developers to<br\/>manage complexity in new ways: by allowing flexible middleware<br\/>configuration; by supporting both component-like encapsulation and<br\/>controlled exposure to aspects; and by providing sound type checking of<br\/>middleware configurations. The new techniques are being validated through<br\/>the development of new, modular, and highly configurable DRE middleware<br\/>for real-time Java. <br\/><br\/>The knowledge that comes from this research will<br\/>drive progress in embedded systems development and enable more effective<br\/>techniques for modularizing concerns across application and middleware<br\/>boundaries. The project's technology is expected to be particularly useful for <br\/>designing and building embedded and real-time software systems, as well as software<br\/>systems in general. Both component systems and middleware have become<br\/>popular commercially; this technology should enable and demonstrate the evolution of future component systems and middleware.","title":"Collaborative Research: EHS: Components and Aspects for Embedded Middleware","awardID":"0410218","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["316962"],"PO":["561889"]},"98911":{"abstract":"Abstract: <br\/><br\/>Wireless sensor networks (WSN) have two key advantages over more traditional sensor networks: they can be quickly deployed, and can provide fine-grained sensing. However, many of the proposed solutions use simplifying assumptions about wireless communication and the environment. While many of these current solutions work well in simulation, it is either unknown how the solutions work in the real world or they can be shown to work poorly in practice. Our objectives are to: (i) Assess how the theoretical properties of wireless communication are exhibited in today's and tomorrow's devices, (ii) Establish models of communication realities to feed back into improved simulation tools, (iii) Invent new network protocols that work in real world environments, and (iv) Synthesize novel solutions into a complete system-wide protocol stack for real applications. Our work contributes to an understanding of the limitations of current and future devices and creates viable, deployable systems. New fundamental models are also derived from our work. The expected results of our work are that realistic wireless sensor networks can be deployed in agriculture, environmental science applications, and for emergency response systems. These systems can provide true benefits to society, e.g., more efficient production of food, environmental protection of watershed areas, and saving lives in response to a natural disaster. Dissemination of WSN software through SourceForge enables other groups to build applications on top of our work. Dissemination of our simulation models provides an amplification effect of our research. New courses make novel WSN technologies accessible to graduate and undergraduate students.","title":"NeTS - NOSS: Reality-Aware Sensor Network Protocols","awardID":"0435060","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550342","553633"],"PO":["434241"]},"97822":{"abstract":"ITR: COLLABORATIVE RESEARCH: (EVS+NHS)-(int+dmc): 'FAST Copper': Dynamic Optimization of Resources in Frequency, Amplitude, Space, and Time for Broadband Access Networks<br\/><br\/>Mung Chiang, Princeton University<br\/>John Cioffi, Stanford University<br\/>Alexander Fraser, Fraser Research<br\/><br\/>Award 0427677<br\/><br\/>Abstract<br\/><br\/>Broadband access is the commercial and technical future of telecommunications. Higher data rates on access links enable any or all of video, data, and voice\/audio signals. It is widely recognized that the ability to deploy ubiquitous, robust, broadband access services to the majority of U.S. households is vital to economic prosperity, a vibrant civil society, and homeland security. The goal of this 'FAST Copper' project is to help build an engineering foundation to bring broadband information services to everyone with a phone line, including people who live in rural and less-privileged areas. This can be achieved by substantially enhancing the rate and reliability of the existing copper plant access network. Equity of broadband information access in the U.S. will be enhanced as a result. There are two threads of research activities towards this goal: (a) dynamic and joint optimization of resources in Frequency, Amplitude, Space, and Time (FAST) to overcome the attenuation and crosstalk bottlenecks, and (b) integration of communication, networking, computation, modeling, and distributed information management in the multi-user environment of twisted pair networks. Innovations in both physical layer algorithms and network architectures and protocols are pursued. In particular, Dynamic Spectrum Management, a science of multi-user methods for adaptively tuning an access network to specific situations dynamically, is investigated for rate improvements and implementation viability. This proposal has major activities integrating research with education. It also facilitates close collaboration with industry in analyzing highly valuable empirical data and validating research results through extensive lab tests.","title":"ITR: COLLABORATIVE RESEARCH: (EVS+NHS) - (int+dmc): 'FAST Copper': Dynamic Optimization of Resources in Frequency, Amplitude, Space, and Time for Broadband Access Networks","awardID":"0427687","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":[257441],"PO":["434241"]},"97723":{"abstract":"In the rapidly growing world of Internet infrastructures, we face many challenging new problems. These arise in part because the usual assumptions made in problems of this general type may no longer hold. For example, many typical questions dealing with massive data sets often involve networks or graphs of prohibitively large sizes. Only partial information can be obtained and in addition, this information is changing dynamically. There is an increasing need to develop the theoretical foundation for these myriad complex processes. In particular, there are many unresolved fundamental issues regarding the computational and informational-theoretic complexity of interactive computing, both in the classical setting as well as other emerging computational paradigms. In this proposal, we will investigate several<br\/>inter-related areas :<br\/>- Major open problems in communication complexity.<br\/>- Two information-theoretic identification problems Guessing secrets and Finding favorites.<br\/>- Two directions in quantum information processing quantum decision tree model and quantum communication complexity.<br\/>- Using techniques in the study of the so-called \"power law model\" for realistic networks<br\/>to develop new methods in the analysis of on-line algorithms. Impact Interactive computing is prevalent in almost all areas of computing and communcations with applications in numerous areas of science and engineering, such as security, finance, information retrieval, bioinformatics and beyond. However, the current state of the theoretical foundation for interactive computation is quite primitive and far from satisfactory. The proposed study on the computational complexity of interactive computation is meant to strengthen our understanding and provide insight that is crucial for the design and analysis of interactive algorithms. Because of the fundamental and far-reaching nature of the proposed work, this study will help bring together different areas and crossfertilization typically occur.","title":"ITR Collaborative Research: ASE-DMC Computational complexity for interactive computing","awardID":"0426858","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["452845"],"PO":["499399"]},"94577":{"abstract":"Hybrid systems are characterized by non-trivial interactions between discrete (digital) and continuous (analog) components. A typical example is a digital controller in an analog environment, e.g., a micro-controller in a car or plane. The correct behavior of the system depends critically on the interaction between the controller and its environment. The purpose of this project is to develop algorithms that automatically determine the correctness of such systems using a state exploration technique called Model Checking. <br\/><br\/>Although several methods for hybrid system model checking have been proposed and implemented in research tools, the applications reported in the literature are usually handcrafted examples carefully constructed to illustrate the concepts. The goals of this project are to: (i) develop a new graph-based technique for hybrid system model checking; (ii) develop new methods that combine the power of SAT solvers - which have been successful in hardware verification - with tools for handling continuous variables; and (iii) perform extensive empirical studies to evaluate the relative strengths of several methods for hybrid system verification, including the ones developed in this project, using a set of new extensible benchmark problems (A navigation problem for autonomous vehicles, a leak detection algorithm for pressurized gas pipelines, etc.)","title":"EHS: Graph-Based Refinement Strategies for Hybrid Systems","awardID":"0411152","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7214","name":"HIGHLY DEPENDABLE COMPUTING"}}],"PIcoPI":["553671","460548"],"PO":["561889"]},"97855":{"abstract":"Abstract for Collaboration<br\/>0427985, 0427464, 0427094,0427912,0427695<br\/><br\/>A multidisciplinary team of researchers from Argonne National<br\/>Laboratory, Carnegie Mellon University, Columbia University,<br\/>University of Chicago, Emory University, and University of<br\/>Pennsylvania, with collaborators from the Universities of Graz and<br\/>Lubek, will initiate a long term research project on image-driven,<br\/>inversion-based biophysical modeling. The team includes expertise in<br\/>numerical algorithms and scientific computing, fluid and solid<br\/>biomechanics, PDE optimization, inverse problems, medical image<br\/>analysis and processing, and distributed and grid computing necessary<br\/>to tackle this class of problems.<br\/><br\/>This project aims to create a framework for assimilating multimodal<br\/>dynamic medical image data to produce highly-resolved,<br\/>physically-realistic, patient-specific biomechanics models. While the<br\/>computational and algorithmic aspects of the project are widely<br\/>applicable, the target application will be the construction of<br\/>patient-specific cardiac biomechanics models from 4D image datasets of<br\/>heart motion. Such models are useful for medical diagnosis and<br\/>surgical planning. This places a premium on quick turnaround of the<br\/>computations, which mean they must be fast, scalable, and capable of<br\/>exploiting grid-based computing.<br\/><br\/>Research will focus on three key areas that undergird the project's<br\/>overall goals: registration, inversion, and distributed computing. The<br\/>registration research component will create multilevel algorithms to<br\/>extract cardiac deformation histories from time-varying medical image<br\/>datasets via the solution of sequences of 3D image registration<br\/>problems. The inversion research component will develop multilevel<br\/>algorithms that use these deformation field histories as virtual<br\/>observations to solve inverse problems for cardiac biomechanical<br\/>parameters. The distributed computing research component will create<br\/>tools for performance prediction and resource scheduling that support<br\/>simulations across distributed computational resources.<br\/><br\/>Dovetailing with the research components, the project will undertake<br\/>an educational program designed to communicate the fruits of its work<br\/>and of the wider benefits of the integration of the biomedical<br\/>sciences, computing sciences, and computational sciences, to a more<br\/>general audience of students, disciplinary researchers, and the lay<br\/>public. The professional activities of the team members in the<br\/>inversion, image registration, grid computing, and computational<br\/>science communities will be parlayed to organize workshops and<br\/>international meetings, edit volumes, teach summer schools, develop<br\/>university and short courses, and engage in outreach activities---as<br\/>they have done in the past---but with greater emphasis on the field of<br\/>computational biomedicine. The proposed image-based cardiac<br\/>biomechanics modeling application will provide an excellent<br\/>opportunity to demonstrate the benefits to health and welfare that<br\/>advances in optimization-based registration and inversion algorithms<br\/>and Grid computing can provide.","title":"ITR: Collaborative Research - ASE - (sim+dmc): Image-based Biophysical Modeling: Scalable Registration and Inversion Algorithms and Distributed Computing","awardID":"0427985","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["527004"],"PO":["565272"]},"97745":{"abstract":"A multidisciplinary team of researchers from Argonne National<br\/>Laboratory, Carnegie Mellon University, Columbia University,<br\/>University of Chicago, Emory University, and University of<br\/>Pennsylvania, with collaborators from the Universities of Graz and<br\/>Lubek, will initiate a long term research project on image-driven,<br\/>inversion-based biophysical modeling. The team includes expertise in<br\/>numerical algorithms and scientific computing, fluid and solid<br\/>biomechanics, PDE optimization, inverse problems, medical image<br\/>analysis and processing, and distributed and grid computing necessary<br\/>to tackle this class of problems.<br\/><br\/>This project aims to create a framework for assimilating multimodal<br\/>dynamic medical image data to produce highly-resolved,<br\/>physically-realistic, patient-specific biomechanics models. While the<br\/>computational and algorithmic aspects of the project are widely<br\/>applicable, the target application will be the construction of<br\/>patient-specific cardiac biomechanics models from 4D image datasets of<br\/>heart motion. Such models are useful for medical diagnosis and<br\/>surgical planning. This places a premium on quick turnaround of the<br\/>computations, which mean they must be fast, scalable, and capable of<br\/>exploiting grid-based computing.<br\/><br\/>Research will focus on three key areas that undergird the project's<br\/>overall goals: registration, inversion, and distributed computing. The<br\/>registration research component will create multilevel algorithms to<br\/>extract cardiac deformation histories from time-varying medical image<br\/>datasets via the solution of sequences of 3D image registration<br\/>problems. The inversion research component will develop multilevel<br\/>algorithms that use these deformation field histories as virtual<br\/>observations to solve inverse problems for cardiac biomechanical<br\/>parameters. The distributed computing research component will create<br\/>tools for performance prediction and resource scheduling that support<br\/>simulations across distributed computational resources.<br\/><br\/>Dovetailing with the research components, the project will undertake<br\/>an educational program designed to communicate the fruits of its work<br\/>and of the wider benefits of the integration of the biomedical<br\/>sciences, computing sciences, and computational sciences, to a more<br\/>general audience of students, disciplinary researchers, and the lay<br\/>public. The professional activities of the team members in the<br\/>inversion, image registration, grid computing, and computational<br\/>science communities will be parlayed to organize workshops and<br\/>international meetings, edit volumes, teach summer schools, develop<br\/>university and short courses, and engage in outreach activities---as<br\/>they have done in the past---but with greater emphasis on the field of<br\/>computational biomedicine. The proposed image-based cardiac<br\/>biomechanics modeling application will provide an excellent<br\/>opportunity to demonstrate the benefits to health and welfare that<br\/>advances in optimization-based registration and inversion algorithms<br\/>and Grid computing can provide.","title":"ITR: Collaborative Research - ASE - (sim+dmc): Image-based Biophysical Modeling: Scalable Registration and Inversion Algorithms and Distributed Computing","awardID":"0427094","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["408684"],"PO":["565157"]},"96656":{"abstract":"This project, building a campus wide ultra high-speed optical fiber network that supports scientific application and experiments of high volume data, develops an experimental next-generation instrument to efficiently investigate and compare campus-scale terabit-class lambda network architectures that span from optical-circuits-only to packet-switched-only networks (and a range of hybrid combinations in between). Current commercial approaches to storage systems do not scale in either performance levels or data abstractions. The proposed approach builds on the foundation of the shared-nothing compute cluster emerging from data systems, visualization walls, and high-end instrument interfaces, having raw horsepower to serve and ingest high volumes of data required by applications. Constructing a next generation switch for simultaneously switching 10Gbs streams efficiently, the work aims at building a 21st century photonic instrument to explore the practical tradeoffs of network and application design in bandwidth-rich infrastructure. Supporting large scientific problems and enabling big simulations, the project constructs Quartzite, the experimental, next-generation instrument. While fostering comparative studies, Quartzite, a data-intensive application breadboard, enables stitching together resources, bringing them virtually in. Thus, this wavelength-selective switch creation, communication and delivery project, adds hybrid-networking structure to a unique campus-scale platform and enables the study of network architecture and application design in a band-width-rich infrastructure and the sharing of large data sets across clusters. The work involves high risk, with a promise of even higher impact, since data intensive scientific exploration can be brought into the scientists' lab, by using on-demand high-speed data flows to harness campus- to international-scale resources. The work explores the following issues:<br\/> How surplus of on-demand bandwidth can be exploited by end user applications,<br\/> How distributed systems can be best architected,<br\/> When is a non-shared packet network needed, <br\/> How should control of a hybrid fabric be handled, <br\/> Can applications truly exploit a high-speed parallel infrastructure,<br\/> Is dynamic reconfiguring of campus network to meet transient capacity demands practical,<br\/> Is it beneficial to expose direct circuits to individual endpoints, and<br\/> Do novel packet scheduling strategies for shared links dramatically improve the capacity.<br\/>Broader Impact: The Quartzite-enabled comparisons will influence the network structure of future research university networks, greatly increasing the capability for data-intensive research throughout the country. Working with industrial partners, the hybrid Quartzite core system and software will service us all.","title":"MRI:Development of Quartzite, a Campus-wide, Terabit-Class, Field-Programmable, Hybrid Switching Instrument for Comparative Studies","awardID":"0421555","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["554382","522499","559498","548362"],"PO":["557609"]},"97987":{"abstract":"Collaborative Research: Language Processing Technology for Electronic Rulemaking <br\/><br\/>Many people today, including news analysts, opinion pollsters, advertisers, and government regulation writers need to interpret, structure, and rapidly master large quantities of opinion-based text. New research is needed to develop text-processing tools that can perform advanced analysis of large text collections. This research will build on current text processing technologies, such as text clustering, text searching using information retrieval, and extractive summaries, to build and test tools tailored to the specific needs of government personnel working in an electronic rulemaking environment. <br\/><br\/>This project's focus is the federal government's several-thousand regulation writers, employed in some 200 agencies, who formulate, in a tightly scripted procedure, the rules and regulations that define the details of our laws. This project will attempt to solve several novel problems central to language processing research. In turn, it will deploy and evaluate a Rule-Writer's Workbench; a set of language tools that enables regulation writers, singly or jointly, to obtain a detailed and multidimensional overview of the material. <br\/>. <br\/>This research has the potential to impact far beyond IT and social science academia. It will explore such novel issues as author typing, opinion\/affect determination, and near-duplicate detection. If even just a handful of the new technologies are effective, they eventually may help thousands of regulation writers more effectively communicate with and understand the comments of millions of citizens in our increasingly digitized society, and produce better regulatory rules for all of us.","title":"Collaborative Research: Language Processing Technology for Electronic Rulemaking","awardID":"0429102","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"S064","name":"US FISH AND WILDLIFE SERVICE"}}],"PIcoPI":["541869"],"PO":["565136"]},"97998":{"abstract":"Abstract<br\/><br\/>Programmable Architectures for Low Density Parity Check Codes<br\/>Venkatesh Akella Shu Lin<br\/>University of California University of California<br\/><br\/>Low-density parity check (LDPC) codes are an important class of error control codes that have superior performance and are gaining widespread use in a diverse range of applications from satellite and space communication to magnetic recording to high data rate optical networks based on optical CDMA. The wide range of applications imply a broad range of requirements in terms of data rates, bit and block error rates, performance, decoding speed and power consumption. This necessitates a systematic methodology to design good LDPC codes and hardware\/software platforms to implement them efficiently.<br\/><br\/>Specifically we argue that we need codes and architectures that can (dynamically) adapt to time-varying fluctuations in the physical channel (due to fading, interference etc.) and to the resource constraints of the sender or receiver. The latter is especially important in power critical applications like satellite or space communications. Existing code construction methods and hardware architectures for LDPC codes are typically tailored for one specific code and hence are not capable of adaptation. The goal of this proposal is to address this problem. We propose a systematic methodology for generating a large family of related LDPC codes and a single programmable hardware architecture to encode and decode them efficiently for a variety<br\/>of resource and performance constraints. We propose a joint framework for code construction, implementation platform design and methods for optimizing the implementation of the codes on the platform. We propose to investigate runtime selection of appropriate codes and encoding\/decoding algorithms based on the resource constraints. The main resource we will be interested in is power consumption of the encoder and decoder.<br\/><br\/>The intellectual merit of the proposed research is two fold. First, we propose to study the trade-offs<br\/>between the rate, decoding complexity both in terms of energy and time and error performance. Second, we target programmable architectures that are suitable for optical networking applications, which require very low bit-error rate and decoding rates in tens of gigabits per second. This will push the limit of programmable architectures and yield new insights into high-speed on-chip programmable interconnection network design.<br\/><br\/>The broader impact of the proposed research would be in the area of reconfigurable VLSI fabrics. As<br\/>we move into process technologies below 65 nanometers, building ASICs (application-specific integrated circuits) is increasingly less viable due to the problems of timing closure and the design cost and design cycle time. There is an immediate need for a new kind of computing fabric that can replace ASICs. The proposed research will be addressing this problem indirectly. Given that efficient interconnect design is the key challenge in high-speed LDPC decoding, if we can come up with an energy efficient FPGA-like VLSI fabric that can support very high data rates for LDPC decoding, then it is likely that, that fabric can be used for other high performance applications that have demanding interconnect requirements.","title":"Programmable Architectures for Low Density Parity Check Codes","awardID":"0429154","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["450215","485984"],"PO":["550859"]},"98977":{"abstract":"NeTS-ProWin: An Open, Low Cost, High Quality Software Radio Platform and Testbed<br\/><br\/>Jay Lepreau, University of Utah<br\/><br\/>Award 0435485<br\/><br\/>Abstract<br\/><br\/>This project is focused on software radio, with hardware, software, and testbed management components. It is developing, packaging, distributing to researchers, and deploying in the Utah Emulab testbed, a low-cost, high-performance, and open software radio platform, \"GNU Radio,\" and extending the Emulab testbed to support it. Further development of GNU Radio is a research challenge that will lead to increased understanding of software-programmable radios: maximizing programmability while also supporting high performance and reliable operation. For the hardware, a challenge is keeping costs low while also providing a powerful device. The project will be an enabler of research in the area of programmable wireless networks. Further development of GNU Radio hardware and software, integration of GNU Radio into Emulab (for remote testbed access to researchers), and the distribution of Emulab systems (for local experiments invaluable for wireless research due to space sharing limitations) will be a significant asset to the research community. Public-domain software in conjunction with inexpensive, flexible, programmable hardware integrated within a replicable network testbed is critical to the progress of the flexible wireless systems community. This effort will also produce educational materials in the form of tutorial articles, sample code, and experiment configurations that are critical to furthering education and research in this area. This project contains the elements needed to achieve broad impact on the research community, industry, and society overall in the area of programmable wireless radio networks and spectrum sharing..","title":"NeTS-ProWin: An Open, Low Cost, High Quality Software Radio Platform and Testbed","awardID":"0435485","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["344532","542075","559299"],"PO":["564777"]},"98625":{"abstract":"The PIs will undertake an experimental study and computational modeling of the internal representations and associated processes that underlie action perception and understanding by observers, and action planning and execution by actors. To facilitate both careful experimentation and formal theory, the PIs will approach the behavior representation problem primarily through the visual system, asking how do we understand the actions of others using our vision? That is, how do we perform mappings from image sequences depicting simple actions to the corresponding internal representations that allow action recognition, imitation, etc? The PIs will further explore higher-level cognitive representations and mechanisms used to categorize, reason about, and judge the movements and actions of others. The approach is based on a novel formal theory of the mental representations and processes subserving action understanding and planning, which the PIs believe provides a compact but powerful and extensible computational approach to the analysis and synthesis of complex actions (and action sequences) based on a very small set of atomic postural elements (\"key frames\" or \"anchors\") and the corresponding probabilistic, grammatical rules for their combination. This probabilistic \"pose grammar\" approach to action representation is similar to state of the art techniques used for speech recognition (e.g., hidden Markov models), but with key postural silhouettes taking the place of phonemes; such augmented transition grammars also nicely reflect sophisticated new control-theoretic techniques in robotics for robust anthropomorphic movement. The action representational system is not monolithic, but rather occupies a spectrum of informational structures at hierarchical levels corresponding to different behavior \"spaces\": mechatronic space, used in movement planning and production; cognitive space, involving representations for action recognition, analysis, and evaluation; visual motion space, which encodes and organizes visual motion caused by human action; and linguistic motion space, comprised of conceptual\/symbolic action encoding. Excluding here the latter space, the PIs' theoretic, computational, and experimental efforts seek to clarify and formally describe both the nature of the representations in these spaces and, crucially, the mapping of representations across spaces. Notably, they explore a candidate action representation, referred to as a visuo-motor representation, which, in facilitating the understanding of observed actions, may recapitulate and resonate with the actual motor representations used to generate movement. Moreover, they present a promising approach for obtaining this representation from discrete action elements or anchors.<br\/><br\/>Broader Impacts: This project will lead to significant advancements in both research and applications in psychology (e.g., robust social judgments given degraded biological motion), kinesiology (e.g., analysis\/modeling\/training of movement profiles, as in athletics or pathology\/rehabilitation), robotics (e.g., control of anthropomorphic robots), human and computer vision (e.g., automated action recognition in digital video), and other fields concerned with the interpretation and production of human\/humanoid action.","title":"Collaborative Proposal: HSD-DHB-MOD The Grammars of Human Behavior","awardID":"0433136","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7319","name":"HSD - DYNAMICS OF HUMAN BEHAVI"}}],"PIcoPI":["460460"],"PO":["565227"]},"97899":{"abstract":"Reconfigurable, data-driven resource allocation in complex systems:<br\/>practice and theoretical foundations<br\/><br\/>As web servers are developing into central components in the information infrastructure of our society, it becomes challenging to serve their ever-increasing and diversified customer population while ensuring high availability in a cost-effective way. The complexity of today's web servers systems and the variability of their workload often make effective resource allocation an elusive goal.<br\/><br\/>This proposal seeks support for the development of a data-driven performance-engineering framework to automate the process of robust, workload-aware resource allocation and management in today's complex web server systems. The researcher's focus is on the development of better understanding of the workload resource demands, on the development and implementation of efficient methodologies for bottleneck identification and resource allocation at the system level, and on the development of efficient analytic methodologies for performance prediction. To meet the above targets the following research tasks will be accomplished:<br\/>o A better understanding of the workload resource demands in web servers that serve dynamic pages will be obtained, focusing on identifying the different resource bottlenecks and the workload conditions under which these bottlenecks are triggered.<br\/>o A data collection mechanism at the system level will be devised that will gather statistical information, which can prompt scheduler reconfigurations. This mechanism will provide a better understanding on what system and workload data, and at what level of detail, needs to be monitored at run-time to readily provide to the allocation policies information about the state of the system.<br\/>o New, data-driven scheduling policies will be developed and will be implemented at the system level for the various bottleneck resources that will allow quick system recovery under transient overload conditions.<br\/>o New theoretical results will allow modeling of the workload and resource allocation policies with compact and tractable models. These models will guide parameterization of the resource allocation policies.<br\/><br\/>Intellectual Merit: The proposed research will advance science and engineering by integrating data and analytic models for the development and implementation on actual systems of both workload-aware and system-aware algorithms to modulate resource allocation in web servers serving dynamic pages under constantly changing workload conditions. The proposed research, even assuming that not all results are positive, will attempt to answer several fundamental questions for the development of cost-effective, autonomic systems. The theoretical contributions of this research will advance the state-of-the-art in modeling of complex systems that are subject to continuous and severe changes in workload intensities and demands.<br\/><br\/>Broader Impact: The impact of this research will affect that state-of-the-practice in actual off-the-shelf systems via industrial collaborations, specifically Seagate Research, by providing algorithms and tools that can modulate and automate the process of resource allocation in complex environments. Through this project, the researcher will also be able to impact the education of several students, preparing them to better meet industry demands in the areas of performance modeling and resource allocation in complex environments.","title":"ITR-(ASE)-(dmc+int): Reconfigurable, Data-driven Resource Allocation in Complex Systems: Practice and Theoretical Foundations","awardID":"0428330","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["518455"],"PO":["551712"]},"98504":{"abstract":"Collaborative Research: Intrinsically Motivated Learning in Artificial Agents<br\/>Project Summary<br\/>Humans are unendingly curious; we spontaneously explore and manipulate our surroundings to see what we can make them do; we obtain enjoyment from making discoveries and for making things happen. We often engage in these activities for their own sakes rather than as steps toward solving practical problems. Psychologists call these intrinsically motivated behaviors because rewards are intrinsic in these activities instead of being due to the satisfaction of more primary biological needs. But what we learn during intrinsically motivated behavior is essential for our development as competent autonomous entities able to efficiently solve a wide range of practical problems as they arise. This project's objective is to develop a computational model of intrinsically motivated learning that will allow artificial agents to construct and extend hierarchies of reusable skills that are needed for competent autonomy. This project builds on existing <br\/>research in machine learning, recent advances in the neuroscience of brain reward systems, and classical and contemporary psychological theories of motivation. At the core of the model are recent theoretical and algorithmic advances in computational reinforcement learning, specifically, new concepts related to skills and new learning algorithms for learning with skill hierarchies. The project develops a mathematical framework, implements the model in a series of simulated agents, and demonstrates the advances this will make possible in a series of increasingly complex environments.<br\/>Intellectual Merit-Machine learning methods have become much more powerful in recent years. Despite these advances and their utility, today's learning algorithms fall far short of the possibilities for machine learning. They are typically applied to single, isolated problems for each of which they have to be hand-tuned and for which training data sets have to be carefully prepared. They do not have the generative capacity required to significantly extend their abilities beyond initially built-in representations. They do not address many of the reasons that learning is so useful in allowing animals to cope with new problems as they arise over extended periods of time. Success in this project will provide a fundamental advance in machine learning and move the field in a new direction. Although computational study related to intrinsic motivation is not entirely new, it is currently underdeveloped and does not take advantage of the highly relevant recent advances in the field of computational reinforcement learning and in the neuroscience of brain reward and motivation systems. Furthermore, computational studies do not take advantage of psychological theories of play, curiosity, surprise, and other factors involved in intrinsically motivated learning. This project addresses these shortcoming by taking an explicitly interdisciplinary approach.<br\/>Broader Impacts-The new methods promise to improve our ability to control the behavior of complex systems in ways that will benefit society. Machine learning algorithms have been instrumental in a wide variety of applications in such areas as bioinformatics, manufacturing, communications, robotics, and security systems. It is important strategically, economically, and intellectually to increase the power of machine learning technologies as rapidly as possible. This project attempts to address some of these challenges. This project will strengthen interdisciplinary ties between the machine learning community of computer science and various disciplines devoted to the study of human cognitive development and education. The specific methods of concern in the proposed research have not yet been integrated. There has been very<br\/>little cross-fertilization between the psychological study of intrinsic motivation and machine learning. The proposed research will remedy this situation, thereby helping to create an avenue of communication that can foster future developments in both fields. The project has the potential to contribute to our understanding of general principles underlying human cognitive development, with implications for education, where enhancing intrinsic motivation is a key factor.<br\/>The educational component of the project focuses on graduate education through its training of graduate students. This includes the offering interdisciplinary graduate-level seminars at both U. of Massachusetts and U. of Michigan, to be taught by the PIs on the topic of intrinsically motivated learning. In its recruitment of graduate students, the project will take advantage of the role that U. Massachusetts plays as the lead institution in the NSF funded Northeast Alliance, which supports and mentors underrepresented minority students interested in academic careers in a science, mathematics, or engineering discipline. At U. of Michigan special effort will be mad","title":"Collaborative Research: Intrinsically Motivated Learning in Artificial Agents","awardID":"0432143","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}}],"PIcoPI":["513288"],"PO":["521045"]},"95127":{"abstract":"Print-based textbooks and educational materials supporting the general curriculum present an accessibility barrier for many students, especially those with disabilities. Digital curricular materials and technology-based learning environments provide alternatives by presenting the same content as printed materials, but in formats that are flexible and accessible. In order provide students with appropriately customized learning experiences in a timely fashion and at scale, automatic generation of adapted content is essential.<br\/><br\/>This project introduces the concept of a pedagogical intent ontology to drive the semantic annotation of XML-based digital educational content. The formal description of the pedagogical semantics of individual chunks of educational content and the relationships among those chunks of content, together with a student model, will drive the selection, sequencing, layout and presentation of educational content. The project will develop foundational knowledge and infrastructure components including (1) a pedagogical intent ontology, (2) semantic annotation schemes, (3) an architecture for automated, rule-based adaptation of content, (4) introduction of new models of curriculum design, and (5) research results to shape and justify the adoption of new approaches to, and standards for, the design of educational materials by the publishing community, such as the National Instructional Materials Accessibility Standard.","title":"Dynamic Generation of Individualized Digital Learning Materials for Learners with Disabilities through Automatic Analysis of Pedagogic Intent Semantics and Learner Requirements","awardID":"0413709","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7180","name":"EDUCATIONAL RESEARCH INITIATIV"}}],"PIcoPI":[249461,249462],"PO":["564318"]},"98306":{"abstract":"The Coronal Heating Problem is the longest standing unsolved mystery in astrophysics. Measurements of the temperature distribution along the loop length can be used to support or eliminate various classes of coronal temperature models. The temperature analysis of coronal loops is a state-of-the-art astronomy. In order to make progress, scientific analysis requires a data set of 10 (phase A) and then 100 (Phase B) loops observed by the Extreme UV Imaging Telescope (EIT) aboard the NASA\/European Space Agency spacecraft called SOHO (Solar and Heliospheric Observatory). The combination of EIT, TRACE, and SXT information provides a powerful data set that will yield unprecedented detail on the plasma parameters of a variety of coronal loop structures. The biggest obstacle to completing this project is putting the data set together. EIT has taken over 300,000 images during its 6-year (and counting) mission. The search for interesting images (with coronal loops) is by far the most time consuming aspect of this project. . Currently, this process is performed manually, and is therefore extremely tedious, and hinders the progress of science in this field. The next generation \"EIT\" called MAGRITE, scheduled for launch in a few years on NASA's Solar Dynamics Observatory, should be able to take 300,000 images in about four days and will need state of the art techniques to sift through the massive data to support scientific discoveries.<br\/><br\/>The contribution to solar image mining has the potential to accelerate scientific discovery in solar physics, and other applications that rely on massive image databases. Research that advances state of the art in solar physics will have a significant impact because of the following reasons: (i) the climate connection: the sun is a source of light and heat for life on Earth. Scientists strive to understand how it works, why it changes, and how these changes influence the Earth, (ii) space weather: The sun is the source of the solar wind. Disturbances in the solar wind shake the Earth's magnetic field and pump energy into the radiation belts, and can change the orbits of satellites, shorten mission lifetimes, cause power surges and outages on Earth, and hence need to be predicted. (iii) The sun as a physical laboratory: the sun produces its energy by nuclear fusion, a process that scientists have strived for decades to reproduce by involving hot plasmas in strong magnetic fields. Much of solar astronomy involves observing and understanding plasmas under similar conditions. Students are actively engaged in the research program.","title":"SEI: Mining Solar Images to Support Astrophysics Research","awardID":"0431128","effectiveDate":"2004-09-15","expirationDate":"2005-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["542202","409510"],"PO":["565136"]},"98438":{"abstract":"The rapid advancement of mobile devices and wireless networking technologies and increasing use of embedded devices has extended the scope of traditional real-time systems. Such systems now include coordination among embedded components and dynamic reconfiguration of communication topologies among components. There are many challenges in such highly dynamic embedded hybrid control systems. Traditionally, the programming language community focused on modeling and reasoning about the semantics of interactions between distributed components. Meanwhile the real-time computing community focused on how to manage CPU and network communication resources so that real-time tasks can predictably meet their end-to-end timing constraints. This research seeks to bridge the two areas by abstracting orthogonal concerns in dynamic real-time systems, and then using these separately specified components to support runtime-integrated system behaviors.<br\/><br\/>This research is developing a framework to address key issues in asynchronous dynamic<br\/>real-time embedded systems: coordination, real-time constraints, and re-configurability in a modular fashion that permits separation of concerns. A prototype implementation of the framework includes the defining language constructs for specifying real-time constraints and coordination requirements independent of the internal behavior of individual computational objects. It also provides runtime support that combines the components to achieve integrated system requirements. In particular, the language abstraction for timing constraints is used to the support run-time scheduler, while the language abstraction for interaction topology is used to support message routing. Such a runtime framework cannot only be used as a test-bed to validate the proposed model, but also can verify the practical aspects of the approach.<br\/><br\/>Successful results of the research techniques are expected to have a profound impact on the ease of development of future asynchronous distributed real-time embedded systems. The power of the coordination substrate for real-time embedded systems lies in the fact that it is designed to be modular and dynamically reconfigurable to suit the dynamic nature of distributed real-time embedded systems. The modularity and separation of concerns not only increases the software reusability in both computational domain and coordination domain, but also simplifies the design, development and analysis of large complex real-time embedded systems and hereby increases system dependability.","title":"SGER: A Model for Highly Dynamic Real-Time Systems - Coordination+Timing Constraint+Functionality","awardID":"0431832","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["460574"],"PO":["561889"]},"98207":{"abstract":"This project conducts a dialectic study of location privacy in wireless networks -- a ``good cop'' vs ``bad cop'' exploration of the technical limits and abilities for surveillance in common wireless data networking. The work combines the current state of knowledge in privacy with probabilistic regression. Current location monitoring in wireless networks is integrally related to determining location from radio frequency information; current techniques to enhance privacy depend on the ability to fool observers by varying that RF information without affecting the ability to use the underlying network. This RF information is imprecise and subject to considerable environmental noise. Alternatively, privacy-enhancing mechanisms vary aspects of the media access layer, such as unique keys used to identify stations, in an effort to cloak an individual station and enhance privacy.<br\/><br\/>To date, there has been little investigation in to the issue of unintended disclosure of private information in wireless networks. For example, current monitoring techniques can identify the unique brand of cellphones being used in a region by characteristics of the electronic components used in different brands of cellphones. Normally, such sophisticated analysis requires expensive equipment. As more bandwidth is unregulated, the ability to monitor such bandwidths becomes an intrinsic aspect of the underlying technology. Software defined radio systems have the need and ability to use a number of frequency ranges and to exercise control over the MAC and PHY layers of the wireless medium, and emerging hybrid reconfigurable systems will accelerate the wide spread use of such devices. As such capable handsets become more commonplace, their very programmability will allow a broader range of increasingly sophisticated surveillance.<br\/><br\/>By exploiting a combination of machine learning algorithms and embedded systems, the research funded by this proposal seeks to verify or refute the privacy enhancing aspects of current research. Not only will this help determine the technological limits to existing and proposed privacy mechanisms, but it may help set guidance for policies in such domains. Moreover, the contrapuntal study that attempts to violate location privacy through advanced statistical machine learning may indicate that wireless privacy can not be enforced by technology, and must be dictated by policy. This surveillance technology may also be interesting in its own right, allowing more accurate tracking of parties that have noisy location sensors. The study uses probabilistic regression models to estimate trajectories from radio data collected by a software radio. The algorithms are sought that are simple enough to run on the hybrid reconfigurable logic embedded in the software radio, allowing diverse and realistic experimentation and evaluation.","title":"ITR: Privacy and Surveillance In Wireless Networks","awardID":"0430593","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["543625","290083"],"PO":["561889"]},"98218":{"abstract":"This project aims to study the approximability measures and the design of heuristics for NP-hard optimiza-<br\/>tion problems. This endeavor will result in the development of techniques that enable a deeper understanding<br\/>of the principles that underlie the design of approximation algorithms for NP-hard problems. An approxima-<br\/>tion algorithm is a polynomial time algorithm that produces solutions provably \\close\" to optimal.<br\/>Many of the problems we study are graph theoretic. Graphs are powerful tools that can be employed to<br\/>model objects, as well as the relationships between them. Indeed, many distinct optimization problems can be<br\/>cast in graph theoretic terms. Specifically, graph theory provides an excellent way to model problems related<br\/>to areas such as transportation, network design\/routing, facility location, and cluster analysis. This powerful<br\/>framework allows us to both develop and illustrate the power of different algorithmic tools. In addition to<br\/>graph problems, we also study some fundamental scheduling, data management and broadcasting problems.<br\/>Intellectual Merit: An increased understanding of techniques to develop and apply approximation algo-<br\/>rithms will have a significant impact on both research and practice. As we are well aware, NP complete<br\/>problems are abundant in many scientific and engineering disciplines, any technique that effectively copes<br\/>with this diffculty will have a significant impact on the design of heuristics.<br\/>Broader Impact: The broader scientific goals are to both further the field of algorithms in terms of our<br\/>understanding of what problems can be solved efficiently and what problems cannot. In addition, we explore<br\/>applications of these algorithms in other areas such as networking, GRID computing, parallel computing etc.<br\/>The project will train two full time PhD students in conducting research both in Universities and through<br\/>internships during the summer at National Labs and Industrial Research Centers.","title":"Techniques in Approximation Algorithms","awardID":"0430650","effectiveDate":"2004-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["538796"],"PO":["562944"]},"99318":{"abstract":"This workshop seeks to develop a vision of next-generation wireless broadband, specifically looking at the research topics that need to be addressed to get wireless functionality in the range of one gigabit per second by the end of this decade. The workshop will also explore how federal, state, and local policies impact or encourage that development.<br\/><br\/>This workshop will advance knowledge and understanding of the challenges in using wireless for one gigabit per second networking infrastructure. Wireless will need to play a pivotal role as part of a next-generation broadband strategy, and hence the capabilities and limits of high-speed wireless networking technology and relationships to policy need to be explored.<br\/><br\/>The workshop will provide a strategic overarching vision, a roadmap for wireless technology development, and a focused target to stimulate wireless networking research.","title":"Workshop: Focusing on Wireless as Viable One Gigabit Broadband Strategy, Washington, DC Metro Area","awardID":"0438110","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1766","name":"STRATEGIC TECH FOR INTERNET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[261891],"PO":["7594"]},"98108":{"abstract":"Collaborative Coherence: Streamlining Shared Memory Performance<br\/>Abstract<br\/><br\/><br\/><br\/>The proposed research investigates collaborative coherence, a novel approach for building high-performance shared-memory multiprocessors. In this approach local cache memories collaborate to minimize the occurrence and detrimental performance effects of costly off-chip communication due to permission and data requests. Several problematic behaviors in conventional multiprocessors can be avoided or mitigated by exploiting global knowledge about sharing and reference patterns. This research will result in a deeper understanding of the interactions between processors in shared-memory multiprocessors, and will lead to system designs that have dramatically higher performance and lower power consumption, but are simple, intuitive, and easy to design.<br\/><br\/>The research will have a broad impact on the computer architecture community as a whole, by its development of representative commercial workloads, realization of state-of-the-art simulation infrastructure, and invention of powerful and useful evaluation methodologies. The techniques and methods created will be applied towards the development of increasingly powerful and ubiquitous computing devices whose utility will have a substantial impact on the productivity and creativity of countless end users.<br\/>2006","title":"Collaborative Coherence: Streamlining Shared Memory Performance","awardID":"0429854","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["549841"],"PO":["550859"]},"98119":{"abstract":"PROPOSAL NO: 0429930<br\/>INSTITUTION: Purdue University<br\/>PRINCIPAL INVESTIGATOR: Alam, Muhammad and Roy, Kaushik<br\/>TITLE: Integrated Framework for Reliability- and Process-Variation Aware Design Methodology for VLSI Circuits<br\/><br\/><br\/>Abstract<br\/>Modern integrated circuits (IC) contain tens of millions of transistors. Traditional design of these integrated circuits has relied on the fact that these transistors have almost identical characteristics when they are initially made, and that the characteristics change little during their subsequent usage. Therefore, IC designers have worried about other things like the size of the IC, its speed, battery life, ease of debugging for errors, etc. And this traditional design approach has worked fine for last 25 years. But now-a-days the transistors are becoming so tiny that it is getting impossible to ensure that they have same geometrical and physical characteristics. Equally important, the characteristics of the small transistors can change rapidly when the consumer uses the product. ThePIs hope to answer the question as to how one can design an integrated circuit if one can no longer rely on the uniformity of the transistors, but must account for the fact that each transistor is slightly different and that its property changes with time. One can always assume the very worst case and design for the slowest transistor, but clearly that would be very wasteful. The project are proposes that a much better approach would be to first accurately understand why and how the transistor parameter change (of fluctuate) and to account for this variation explicitly from the very beginning of the IC design process. The design technique is no longer deterministic as it once were, but it now involves statistical design methodologies like making the slower transistors a little wider (transistor sizing) to compensate for their lack of speed or making sure that the architecture distributes the usage burden among a number of transistors so no one transistor becomes so slow that the IC fails. This new approach may allow one to make faster or less power-consuming ICs with a given set of transistors, because designers can now be more aggressive in their design. This in turn, may also allow more time to find alternatives to CMOS, and ease the eventual transition to post-CMOS devices and systems.","title":"Integrated Framework for Reliability- and Process-Variation Aware Design Methodology for VLSI Circuits","awardID":"0429930","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["551012","520673"],"PO":["562984"]},"94610":{"abstract":"Manna - Abstract: <br\/><br\/>Static analysis methods play two vital roles in the design of embedded<br\/>systems: validation and optimization. A static analysis technique<br\/>deduces properties of a given system by analyzing its description.<br\/>Its applicability to a particular system hinges upon its ability to<br\/>deduce interesting properties while balancing the computational cost.<br\/>This research studies a novel class of techniques for<br\/>static analysis that has the potential to significantly increase the<br\/>scope of static analysis. <br\/><br\/>The methodology, called constraint-based static analysis, diverges<br\/>from previous work on static analysis. Whereas traditional<br\/>propagation-based static analysis methods concentrate on iteratively<br\/>constructing better approximations to the desired properties, the<br\/>proposed approach directly solves for the properties. Given a class<br\/>of assertions represented parametrically by a template property, a<br\/>constraint-based method generates and solves constraints on the<br\/>unknown parameters. This shift in strategy seeks the following<br\/>advantages:<br\/><br\/>* It replaces heuristic guesses with a precise and predictable<br\/> approach to approximation. Traditional approaches frequently <br\/> require the use of heuristic guesses via widening and narrowing<br\/> operators, which has limited their applicability.<br\/>* In contrast to propagation-based methods, the new methods can be <br\/> readily optimized to handle special cases effectively.<br\/>* It enables a natural extension to the analysis of nonlinear<br\/> discrete and hybrid systems. <br\/>* The constraint-based methods for real-time and hybrid systems avoid <br\/> explicitly solving differential equations, making them applicable<br\/> to a larger class of systems.<br\/><br\/>The expected benefits of this research are many. Static analysis has not seen a major breakthrough in a decade. The project hopes to revive interest in static analysis and encourage the use of mathematical techniques such as Groebner bases. This research also links constraint solving technology to verification, thus opening<br\/>opportunities for involvement of the constraint solving community<br\/>in problems pertinent to the design of embedded systems. Finally, the<br\/>results of this research bring closer the feasibility of using formal proof of safety properties in certifying software for safety-critical devices.","title":"EHS: Constraint-based Static Analysis of Embedded and Hybrid Systems","awardID":"0411363","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["309451"],"PO":["561889"]},"94500":{"abstract":"From toasters to cell phones and from cars to airplanes, embedded software implements and controls interactions of devices with their environment, and our society is increasingly relying on such devices. Despite the proliferation of embedded devices in almost every engineered product, development of embedded software remains a low level, time consuming and error prone process. This is due to the fact that modern programming languages abstract away from time and platform constraints, while correctness of embedded software relies crucially on hard deadlines. <br\/><br\/>This NSF-funded research aims at developing novel model-based design and implementation methodology for synthesizing reliable embedded software. Hybrid systems models, which allow mixing state-machine based discrete control with differential equation based continuous dynamics, are used for design and analysis. The research explores ways of mapping such models to code guided by correctness, modularity and portability issues. Technical challenges include bridging the gap between the platform-independent and timed semantics of the hybrid models and the executable software generated from it. This includes integrating generation of control tasks with scheduling to ensure optimal performance. The component technologies in the project are being implemented and integrated within a toolkit for experimentation. A computer-aided infusion pump control system, and an unmanned aerial vehicle using Piccolo avionics board, are chosen as target platforms for demonstration of the feasibility and benefits of the approach.","title":"Synthesis of Embedded Software from Hybrid Models","awardID":"0410662","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["553656","497082","526896"],"PO":["561889"]},"95843":{"abstract":"An exciting paradigm is emerging over the last decade that applies pow-erful control and optimization theories to the design and analysis of communi-cation networks, resulting in intellectual and practical impacts much beyond the established frameworks of the 1980s. This trend has been driven by both new needs from the communications and networking fields and recent advances in control and optimization theories. There is already a substantial body of re-search results and applications that need to be transferred to university cur-riculum and the industry. Moreover, new results are being created at a rapid pace, intensifying the need for students and engineers to understand, and ap-ply, these new insights and techniques. The current project develops a new course on control and optimization of communication systems, and associated courseware, that teach students the mentality of tackling engineering problems as dynamic systems to be controlled and linear\/nonlinear objectives to be opti-mized, and equip them with the ability to do so. It covers major communica-tions and networking advances in this area and provide students with hands-on experience on practical problems through numerical and experimental projects. This inter-disciplinary course has a flexible modular structure and the mathe-matical background needed in each module is presented using a 'just-in-time' approach. The project develops instructional materials that can be used in other institutions and the industry. It vigorously pursues various paths of dis-semination. It will transfer recent research advances into the mainstream cur-riculum of CS and EE, and facilitate the spread of knowledge from academia to the industry.","title":"CRCD\/EI: Control and Optimization of Communication Systems","awardID":"0417607","effectiveDate":"2004-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["564049","561963"],"PO":["551712"]},"97911":{"abstract":"Natural and man-made disasters are, by their very nature, unpredictable and rare and thus any monitoring infrastructure for detection of such events will operate with an extremely low duty cycle. Coverage, scalability, and longevity are the key metrics to judge the effectiveness of such networks rather than traditional metrics like latency and bandwidth. This investigation examines monitoring networks from the perspective of minimizing energy usage at all levels of abstraction: circuit, node architecture, signal<br\/>processing, communication, and networking. The overall goal is to develop technologies that enable sensor networks that have unprecedented longevity---on the order of years rather than days or weeks.<br\/><br\/>Research on node design focuses on the development of an ultra-low-power asynchronous microprocessor optimized for sensornetwork applications. Asynchronous circuits enable extremely fine-grained power management, and lead to a significant reduction in energy per operation as well as transition times between active and idle states. Research on communication and networking focuses on collaborative signal processing techniques. Nodes in the system cooperate at the physical layer, resulting in a simultaneous reduction<br\/>in the energy and latency required for information extraction. Both these research vectors are to be evaluated in the context of an experimental hardware testbed developed over the course of this<br\/>project.","title":"ITR: (NHS+ASE) - (int+dmc) - Activity-Driven Computing and Communication for Cooperative Distributed Networks","awardID":"0428427","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["475375","550699"],"PO":["564898"]},"94545":{"abstract":"Margaret Martonosi, Princeton University, Adaptive, Power-Efficeint Processors for Sensors and Embedded Systems <br\/><br\/>Sensor network systems have seen increasing research attention recently, <br\/>with a wide range of scientific and commercial applications. Sensor <br\/>processors need \"agile\" performance that responds quickly to <br\/>high-throughput bursts, with also lower-energy execution when<br\/>possible to minimize energy consumption. Sensor systems have <br\/>limited power budgets, with traditionally most energy going to <br\/>radio communications. But as radios improve and computational<br\/>demands increase, more of the energy budget is shifting back<br\/>to the processor.<br\/><br\/>This research examines processor architectures for agile,<br\/>energy-efficient, stream-based processing in sensor networks<br\/>and other embedded systems. A particular focus is on using<br\/>parallelism (through tiled processing units) for energy management.<br\/>Another key aspect is investigating the interconnect between on-chip<br\/>processing units, and exploring design techniques that let different<br\/>processing elements run at different clock rates. Connecting processing elements by <br\/>a system of hardware queues, for example, allows the chip to exploit <br\/>a thread-based, producer-consumer model to adapt processor settings<br\/>to running threads; this enables efficient energy and speed control<br\/>via dynamic voltage\/frequency scaling. By exposing<br\/>queue\/memory status to near neighbors, processors can use<br\/>control theoretic approaches to coordinate performance\/energy<br\/>needs across local and broader regions. <br\/><br\/>Major research questions include: (i) How much on-chip parallelism<br\/>best balances application performance and energy? (ii) What range of applications <br\/>are applicable to this model? (iii) How to design performance and<br\/>power-efficient speed-control models based on local and global<br\/>control approaches? (iv) What are the roles of distributed and<br\/>hierarchical control techniques? (v) Can control theoretic<br\/>approaches be devised that offer good responsiveness and stability<br\/>in the face of sensing errors and sensing\/actuation delays?","title":"EHS: Adaptive, Power-Efficient Processors for Sensors and Embedded Systems","awardID":"0410937","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["489472","495323"],"PO":["561889"]},"98912":{"abstract":"Currently, the development of revolutionary new network approaches is ham-pered by the lack of methods to evaluate the performance of radically different designs of network architectures, protocols, and applications. The goal of this project is to explore new theoretical concepts and algorithms for predicting the delay and throughput performance of future networks. The project develops a stochastic network calculus that leads to simple models and fast computational methods for networks that are very different from the networks and protocols used today. The research team will determine the capabilities and limitations of this approach and the project will address applications to scheduling in high-speed networks, to the verification of service level agreements, and in the analy-sis of feedback-based buffer management and congestion control algorithms. Efficient computational algorithms derived from the theory permit other re-searchers to use the methods of the calculus without requiring familiarity of the underlying theory. This project presents urgently needed methods for the analysis of the communication infrastructure of the 21st century and it stimu-lates research in analytical methods in science and engineering.","title":"NeTS-NR: Stochastic Network Calculus: Theory and Tools for the Analysis of Future Networks and Applications","awardID":"0435061","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["263351","263351","540768","540768",260718],"PO":["565090"]},"98945":{"abstract":"Proposal Number: 0435292<br\/>PI: John Hartman<br\/>Institution: University of Arizona <br\/>Title: Bootstrapping Broad-Coverage Network Services <br\/><br\/>Abstract: <br\/><br\/>This proposal explores the design and utility of two broad-coverage network services: (1) a topology discovery service that overlay nodes use to locate itself with respect to its peers and the endpoints it serves; and (2) an information service that collects, stores, propagates, aggregates, analyzes, and reacts to the network's changing conditions. The research challenge is to design these services to both provide Internet-scale coverage, and meet the needs of a rich collection of wide-area overlay networks and applications. We will deploy and demonstrate both services on PlanetLab. The impact of this work is to provide \"foundational\" services that can be leveraged to improve the robustness, security, performance, and manageability of the Internet.","title":"Collaborative Research:Bootstrapping Broad-Coverage Network Services","awardID":"0435292","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["383805","485534"],"PO":["292741"]},"98714":{"abstract":"Traditional scientific research is focused within academic disciplines with a marked divide between social and natural sciences. However, scientific research is now crossing disciplinary boundaries, seeing human and natural systems as inextricably linked. This project is ultimately concerned with understanding long-term change in linked human-natural systems. Rapid change is often obvious, whereas long-term change is difficult to observe and even more difficult to study because scientific data typically span, at most, a few decades. Archaeology, on the other hand, collects and analyzes data on human societies and their environments that span centuries or even millennia. Thus, archaeology has the potential to play a unique role in developing and testing scientific models on such topics as demography, economy, and social stability. <br\/>However, the use of archaeological knowledge for these purposes is limited by the inherent complexities on the data. Indeed, it is nearly impossible to execute meaningful analyses that integrate primary data from many archaeological research projects. This research initiates the process of building a cyberinfrastructure for archaeology that would incorporate both new and extant archaeological databases and would use systematized archaeological knowledge and sophisticated computer methods to transcend the problems of data comparability. <br\/>The first component of this grant is a broad-based workshop that will attempt to build a scientific consensus on a vision for a cyberinfrastructure of archaeology, assess the professional and technical challenges, and outline a strategy for achieving that vision. The second component is in-depth exploration of a limited archaeological problem by a team of archaeologists and computer scientists. This component seeks to understand the detailed sorts of knowledge needed to compare and integrate actual data from different field projects (e.g., their preservation and collection strategies) and how to systematically represent that knowledge for computer use. The third component will examine the technical problems posed by archaeological data integration in light of the experience of other disciplines.<br\/>Scientific Merit. A knowledge-based archaeological data-integration system encompassing both new and extant datasets could provide Internet access to extensive social and environmental data archives. Researchers could extract databases of analytically comparable observations, propelling synthetic research to a new level and enabling researchers across scientific disciplines to address large-scale and long-term questions with a level of empirical support that has been unthinkable. This research will also contribute novel computer methods of data integration applicable to other scientific domains in which data are inconsistently collected.<br\/>Broader Impacts. The proposed system has the potential to transform a key component of undergraduate education in archaeology. Employing this knowledge-based system, critical thinking exercises could use large-scale research datasets instead of the \"toy\" problems usually analyzed. <br\/>The proposed system has far-reaching impacts on the infrastructure of social and natural science. It would provide a means to maintain the long-term utility of irreplaceable data in the face of inadequate documentation and rapidly changing technology. Academic, governmental, tribal and private enterprises would all be active consumers of the resulting data integration system. By providing scholars in diverse fields with meaningful access to long-term data on society, population, and environment, archaeology can help explain the complex human and social dynamics that have constituted today's social world and have shaped the modern environment.","title":"Enabling the Study of Long-Term Human and Social Dynamics: A Cyberinfrastructure for Archaeology","awardID":"0433959","effectiveDate":"2004-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7318","name":"HSD - AGENTS OF CHANGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7368","name":"SCI TESTBEDS"}}],"PIcoPI":["522273","497627","509597",260091,"559995","558560"],"PO":["352775"]},"94479":{"abstract":"Freudenberg-Krogh (collaborative) - Abstract<br\/><br\/>The goal of this project is to develop concepts and tools for model-based development of embedded control systems for automotive x-by-wire systems. X-by-wire systems replace mechanical connections between the driver and the vehicle with embedded computers and actuators (e.g., motors) to control the automobile and provide physical responses to the driver. These systems are characterized by multiple, highly integrated and interacting feedback loops. This project is creating new methods for designing these embedded control systems to improve performance while enhancing safety and reliability and reducing development cost. The research draws on control theory to deal with physical dynamics and synthesis of the feedback loops and with formalisms and techniques from computer science to deal with the logical aspects of the embedded software. Using a laboratory implementation of a steer-by-wire system as a test bed, models of the dynamics, including driver behavior, are being analyzed using new compositional methods that make it possible to design elements of the embedded control systems with guaranteed performance characteristics. The theory of fundamental design limitations is being extended and applied to these models to evaluate the tradeoffs between dynamic performance and robustness. Verification methods for hybrid systems (systems with continuous and discrete state variables) are being developed to demonstrate the safety of the system, even when there are failures in sensors and other system components. Tractable verification problems are being developed based on model decompositions reflecting the model structure, time-scale separation, and novel representations of the interaction dynamics. The embedded software design is being implemented and evaluated on the laboratory test bed in cooperation with an industrial partner.","title":"Collaborative Research: Embedded Control Systems for X-by-Wire Applications","awardID":"0410553","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["460153","550636"],"PO":["561889"]},"98978":{"abstract":"National Science Foundation<br\/>NETS - Research in Network Technologies and Systems <br\/>CISE\/CNS<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Proposal Number: 0435490<br\/>Principal Investigator: Ramasubramanian, Srinivasan<br\/>Institution: University of Arizona<br\/><br\/>Proposal Number: 0434872<br\/>Principal Investigator: Somani, Arun<br\/>Institution: Iowa state University<br\/><br\/>Proposal Number: 0434956<br\/>Principal Investigator: Subramaniam, Suresh<br\/>Institution: George Washington University<br\/><br\/>Proposal Title: Collaborative Research: NeTS-NR: Evolutionary Architectures for Ultra-Broadband Access Networks<br\/><br\/>There is a significant mismatch between core and access network capacities currently prevalent. In order to stimulate viable large-scale fiber deployment in the last mile, an evolutionary approach to building high-capacity access net-works is called for. This project develops such an approach by providing solu-tions that can evolve starting from lower-cost wireless-based ones to the ulti-mate fiber-to-the-home (FTTH) solution. Architectural solutions for metro net-works and neighborhood access networks that allow high-speed packet switch-ing and provide efficient aggregation methods to multiplex bandwidth from vari-ous access points are developed. In particular, an evolutionary path from more cost-effective wireless and free-space optics-based solutions to FTTH for neighborhood networking is developed. Solutions ranging from high-speed elec-tronic packet-switching to all-optical WDM\/TDM for metro networking are also investigated. Analytical modeling and simulation tools to evaluate the perform-ance of the architectures are also provided. By targeting a critical area in future networking infrastructure research, the project's outcomes will have immediate and wide practical implications in network development. The results of the pro-ject will lead to a roadmap for the development of the next generation access network infrastructure.<br\/><br\/>Dr. Admela Jukan<br\/>Program Director, CISE\/CNS<br\/>Aug 19, 2004.","title":"Collaborative Research: NeTS-NR: Evolutionary Architectures for Ultra-Broadband Access Networks","awardID":"0435490","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["486214"],"PO":["402055"]},"98989":{"abstract":"Abstract: <br\/><br\/>Sensor networks are finding applications in several areas. They enable tight integration of the physical world with a computing system infrastructure, thereby permitting better information sensing, access and control. However, development of sensor network applications has been extremely difficult: there is very little or no development support. This proposal is aimed at developing programming languages, compilers and middleware services that will make it easier to implement, deploy and manage sensor network applications. The programming languages will provide novel abstractions for defining sensor nodes and groups of nodes, node and group behaviors, and interaction among nodes and groups. The node and group behaviors are completely separated, which supports reusability. The languages will also provide intrinsic support for group level aggregation, state management, group leader selection, and one-many and many-many method invocations. The objective is to capture common patterns of node and group instantiations, data sharing, and communication so that applications can be developed easily. The middleware will implement a scalable infrastructure for group management, inter-node communication, group-node interactions and code distribution. The research will also explore the performance characteristics of the language abstractions and middleware services. The proposed research will have significant impact on development of applications in several areas, including environmental sciences, disaster recovery, civilian infrastructure monitoring, education, precision agriculture and pervasive computing. The research plan also integrates educational and research activities by involving undergraduate and graduate students through courses, open source software development projects, project","title":"Programming Language and Middleware Support for Sensor Network Applications","awardID":"0435531","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["485984","284993"],"PO":["434241"]},"98637":{"abstract":"This comparative study uses ethnographic, interview, and content data analysis to provide a situated social and organizational comparison of three scientific projects with distinct approaches to developing cyberinfrastructures and achieving data interoperability. The three projects are GEON (http:\/\/www.geongrid.org), a geosciences project using a national distributed storage broker to create data sharing across multiple disciplines through developing shared ontologies; LTER (http:\/\/lternet.edu\/), a long-term ecological program using metadata standards to federate data across a single discipline; and Ocean Informatics, an oceanographic team building community and designing a local metadata standard to bridge key data collections to a national standard. <br\/><br\/>Intellectual Need: As new scientific cyberinfrastructures emerge, a central question is how to share data across multiple distributed organizational and social contexts. There have been many suggestions for technical fixes for this pressing concern (particularly important since some of today's great political questions, such as preserving biodiversity and developing a sustainable relationship with the environment pivot on the ability to federate data across organizational and disciplinary contexts). However, there has been little study - and no comparative study - of the organizational and social dimensions of differing interoperability strategies. The working hypothesis for this project, drawing on research in the field of social informatics over the past fifteen years, is that creation of a common shared data infrastructure entails complex negotiations involving the relative institutional weight of the different actors (institutions have a range of motives for subscribing or not to interoperability strategies), the nature of their disciplinary organization (in particular reward structures; openness to interdisciplinary work; history of use of large datasets) and the nature of their domain work (degree of commitment to long-term data storage and re-use; decay rate of data over time; need to draw on large federate datasets). This study will develop grounded understandings of the organizational complexity in producing shared scientific cyberinfrastructure and the costs and benefits of three interoperability approaches: metadata standards, ontologies, and community-driven approaches. <br\/><br\/>Broader Impact: The development of scientific cyberinfrastructure is vital for this country's future economic prosperity and for its ability to respond to key policy issues with scientific and technical dimensions. Cyberinfrastructure is a large-scale contemporary investment; this study will help inform the decisions that today are determining future structural outcomes. At the level of science policy, the project will facilitate understandings of the organizational and social dimensions in building shared infrastructure. The research will produce a policy white paper on data communities and scientific cyberinfrastructure and suggest guidelines for the ongoing formative evaluation of infrastructure development activities. As these new communication tools develop, there is a need for educational programs to sensitize domain scientists, computer scientists and science policy workers to social and organizational issues. The project will produce, as a centerpiece to a Masters level program in cyberinfrastructure, a graduate course about its development, as well as a secondary school lesson module for use in an educational partnership. A 'Cyberinfrastructure Page' website, modeled on 'Inquiry Page' (http:\/\/inquiry.uiuc.edu\/), will incorporate the course and module and allow this project to share results first with the partner communities and then across communities. This will provide the kernel of a resource site for researchers and practitioners in the emergent field of scientific cyberinfrastructure, to share findings and best practices and to engage in collective problem solving.<br\/><br\/>This project is supported by an award from the FY 2004 NSF-wide competition on Human and Social Dynamics (HSD). Coordinated management of the HSD competition and the portfolio of HSD awards involves all NSF directorates and offices.","title":"Interoperability Strategies for Scientific Cyberinfrastructure: A Comparative Study","awardID":"0433369","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7318","name":"HSD - AGENTS OF CHANGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7368","name":"SCI TESTBEDS"}}],"PIcoPI":["532090",259849],"PO":["505334"]},"99979":{"abstract":"Soybean rust, caused by the pathogen Phakopsora pachyrhizi and often referred to as Australasian or Asian rust, is a serious disease of soybean that causes crop losses in many parts of the world, including Asia, India, Africa, Australia, and most recently South America. Much concern has arisen because of the rapid spread of soybean rust around the world within the past ten years. Yield losses from Asian soybean rust can range from 10 to 90% depending on environmental conditions and treatment strategies. There is a critical need to understand the current condition of the crop biosecurity system, baseline the various components, and seek ways to enhance the responsiveness of the overall system. The work builds on the observation that it is possible to detect pre-visual stress in soybeans two weeks prior to visible symptoms appearing on the plant. <br\/>This is due to the fact that a plant's cellular structure is the dominant factor in controlling leaf reflectance in the near infrared range. Remote sensing can then be used to assess the condition of crops. An assessment of current capabilities will be provided by a remote sensing and geospatial technology baseline, which will provide a historical perspective on the progression of soybean rust in South America (environmental, meteorological, cultural, temporal), define the current state-of-the-art for direct and indirect measurements of soybean rust, define the full spectrum (optical, thermal, radar backscatter) characteristics of the disease progression, inventory and assess disease vector models, and provide a conceptual demonstration of the components of the system in an integrated form, including the interplay between social and organizational responses to crop safety threats.<br\/><br\/>Results from this project will lead to new strategies to detect this pathogen early and monitor subsequent disease progression that are likely to be critical components to limiting the economic impact of this disease on U.S. soybean production. The architecture of the system can be adapted to other agents as well. This interdisciplinary research engages not only faculty and technicians, but also undergraduates.","title":"A Comprehensive Threat Management Framework for a Crop Biosecurity National Architecture","awardID":"0442156","effectiveDate":"2004-09-01","expirationDate":"2006-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V790","name":"HOMELAND SECURITY-AGRIC CROP B"}}],"PIcoPI":["533278",263691,263692,263693,263694],"PO":["565136"]},"109115":{"abstract":"The Coronal Heating Problem is the longest standing unsolved mystery in astrophysics. Measurements of the temperature distribution along the loop length can be used to support or eliminate various classes of coronal temperature models. The temperature analysis of coronal loops is a state-of-the-art astronomy. In order to make progress, scientific analysis requires a data set of 10 (phase A) and then 100 (Phase B) loops observed by the Extreme UV Imaging Telescope (EIT) aboard the NASA\/European Space Agency spacecraft called SOHO (Solar and Heliospheric Observatory). The combination of EIT, TRACE, and SXT information provides a powerful data set that will yield unprecedented detail on the plasma parameters of a variety of coronal loop structures. The biggest obstacle to completing this project is putting the data set together. EIT has taken over 300,000 images during its 6-year (and counting) mission. The search for interesting images (with coronal loops) is by far the most time consuming aspect of this project. . Currently, this process is performed manually, and is therefore extremely tedious, and hinders the progress of science in this field. The next generation \"EIT\" called MAGRITE, scheduled for launch in a few years on NASA's Solar Dynamics Observatory, should be able to take 300,000 images in about four days and will need state of the art techniques to sift through the massive data to support scientific discoveries.<br\/><br\/>The contribution to solar image mining has the potential to accelerate scientific discovery in solar physics, and other applications that rely on massive image databases. Research that advances state of the art in solar physics will have a significant impact because of the following reasons: (i) the climate connection: the sun is a source of light and heat for life on Earth. Scientists strive to understand how it works, why it changes, and how these changes influence the Earth, (ii) space weather: The sun is the source of the solar wind. Disturbances in the solar wind shake the Earth's magnetic field and pump energy into the radiation belts, and can change the orbits of satellites, shorten mission lifetimes, cause power surges and outages on Earth, and hence need to be predicted. (iii) The sun as a physical laboratory: the sun produces its energy by nuclear fusion, a process that scientists have strived for decades to reproduce by involving hot plasmas in strong magnetic fields. Much of solar astronomy involves observing and understanding plasmas under similar conditions. Students are actively engaged in the research program.","title":"SEI: Mining Solar Images to Support Astrophysics Research","awardID":"0532443","effectiveDate":"2004-09-21","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["409510"],"PO":["565136"]},"99517":{"abstract":"This grant is supporting travel for student authors to the MASS 2004 conference.<br\/><br\/>Recent research on wireless networks and mobile computing has concentrated on single-hop networks, where network nodes communicating directly to a fixed infrastructure such as cellular or satellite systems. In ad-hoc and sensor networks, multi-hop scenarios where network nodes communicate via other network nodes are dominant. The increasing importance of this area has led to the organization of the 1st IEEE International Conference on Mobile Ad-hoc and Sensor Systems (MASS 2004). MASS 2004 will be held from October 25-27, 2004 in Fort Lauderdale, Florida. The meeting is sponsored by the IEEE Computer Society Technical Committee on Distributed Processing and Technical Committee on Simulation.","title":"Travel Support for 1st IEEE International Conference on Mobile Ad-hoc and Sensor Systems (MASS 2004); October 25-27, 2004; Fort Lauderdale, FL","awardID":"0439636","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["402054"],"PO":["7594"]},"98307":{"abstract":"The goal of this project is to design and develop a statistical-learning tool (STL) for classification and characterization of topographical features on Mars. Major tools for studying the Martian surface are geomorphic mapping and geologic mapping. The standard approach to perform these mappings is through a manual interpretation of images. This laborious approach severely limits the number of Martian sites amenable to study. The STL automates geomorphic mapping and expedites geologic mapping. Thus, it enables fast and quantitative characterization of large sections of the Martian surface. <br\/><br\/>The SLT uses digital topography instead of images to characterize Martian sites. Different topographical variables are fused into a multi-layer data structure. Each pixel in a site carries an array of local and regional topographic information. The automatic recognition and classification of topographic features is performed at the pixel level. This enables the quantitative characterization and comparison of different topographic formations based on statistics of their constituent pixels. The results can be conveniently visualized by means of thematic maps of topography. The capacity of the SLT can be extended by adding other data types (multispectral images) and by applying it to other planetary surfaces. <br\/><br\/>This methodology has a potential to become a powerful investigative tool with a wide range of applications. To facilitate its adoption by the research community the code that implements the SLT and its documentation will be put in the public domain. The results of this work will be disseminated through new courses, seminar talks, and collaborations with other institutes.","title":"Collaborative Research: A Statistical Learning Tool for the Analysis and Characterization of Mars Topography","awardID":"0431130","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7373","name":"ITR-INFORMATION INTEGRATION"}}],"PIcoPI":["371194"],"PO":["563727"]},"98219":{"abstract":"There is a fundamental tradeoff between rate and reliability (diversity)<br\/>in multiple-antenna wireless communications. This research views diversity<br\/>as a systems resource and explores allocation of this resource to achieve a<br\/>desirable rate-diversity tradeoff in multimedia wireless communications.<br\/>Multimedia data is often complex and consists of various components with<br\/>different rate\/reliability requirements. For example, a real-time data<br\/>stream is a candidate to receive more diversity (protection) than<br\/>non-real-time data. Other examples include complex data streams such as<br\/>compressed video, whose various components require different levels of<br\/>error protection. Over-provisioning of diversity to one data component<br\/>will mean the loss of rate to that and other data components, a waste of<br\/>system resources.<br\/><br\/><br\/>The focus of this research is on the creation of a flexible pool<br\/>of space-time resources rather than the design of fixed<br\/>maximum-diversity schemes. The investigators design high-rate <br\/>space-time codes that have a high-diversity code embedded within them. <br\/>This allows a form of wireless communications where the high-rate code<br\/>opportunistically takes advantage of good channel realizations<br\/>while the embedded high-diversity code ensures that at least part<br\/>of the information is decoded reliably. The proposed<br\/>diversity-embedding codes do not require channel knowledge at the<br\/>transmitter and outperform time-sharing schemes. Using the proposed coding scheme, each traffic<br\/>type constitutes a transmission layer that operates at a suitable<br\/>rate-diversity tradeoff point. The investigators explore this point of view with<br\/>designissues, specific code constructions, and application to multimedia<br\/>communications.","title":"A Diversity-Embedding Approach for High-Rate Reliable Multimedia Wireless Communications","awardID":"0430654","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["518585","286843"],"PO":["564898"]},"90420":{"abstract":"PROPOSAL: 0347674<br\/>INSTITUTION: George Washington Univ<br\/>NSF PROGRAM: NETWORKING RESEARCH<br\/>PRINCIPAL INVESTIGATOR: Cheng, Xiuzhen <br\/>TITLE: CAREER: Integrated Resource Conservation in Sensor Networks<br\/><br\/>Abstract<br\/><br\/>Distributed networks of thousands of collaborative sensors<br\/>promise unattended systems for many monitoring, surveillance<br\/>and control applications. Sensor networks are expected to operate for<br\/>long time. This makes network lifetime the central problem for a<br\/>sensor network designer. This project pursues a system-level<br\/>integrated approach to extend network lifetime. More specifically,<br\/>new sensor location discovery methods are being developed that will<br\/>conserve resources such as computational power and radio bandwidth within<br\/>a sensor; new MAC protocols is being designed to optimize for<br\/>low power, low data rate sensor networks; novel approaches are<br\/>investigated for data aggregation services such as event detection and<br\/>target counting. Because sensor self-positioning, MAC control,<br\/>and data aggregation services in a sensor network are strongly dependent<br\/>on each other, their interaction and design are jointly<br\/>explored using an integrated approach for extending network lifetime.","title":"CAREER: Integrated Resource Conservation in Sensor Networks","awardID":"0347674","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560587","557144"],"PO":["557315"]},"97901":{"abstract":"CMGS (Computational Models for Gene Silencing) - used in RNA interference (RNAi), post-transcriptional gene silencing (PTGS), or gene silencing explores the potential for transgenic research, therapeutic intervention, drug discovery, and development of novel biological agents in RNAi technologies. A current trend is the development of high-throughput RNAi screening technologies and commercial enterprises built around such capabilities <br\/><br\/>Intellectual Merits: <br\/><br\/>The CMGS system, by blending molecular modeling, sequence analysis, data representation, and inferencing algorithms into a coherent methodology, serves as a template for understanding how complex systems biology frameworks can be designed. CMGS will hence not only aid in its particular domain of application but also systems biology software projects with similarly broad scope.<br\/><br\/>Broader Impacts:<br\/><br\/>Enhanced participation of under-represented groups: Students from under-represented groups will spend, the summer in research labs at VT, monitored by the PIs, and their students. <br\/>Every GBCB student is educated both in biology and in computation, and hence the program contributes to the immediate national (defense, public health and national priorities) need for young life scientists to be trained in the nature and value of bioinformatics tools and approaches.<br\/>In addition, the GBCB program may attract more women into advanced computational science research than traditional computer science.<br\/>CMGS will also be delivered as a web-based system for use by the broader biological systems modeling community to support interactive prediction and inferencing scenarios. <br\/>We will use CMGS in courses offered under Virginia Tech's GBCB program, demonstrating the utility of multiple modes of investigation.","title":"ITR-(NHS)-(sim): Computational Models for Gene Silencing: Elucidating a Pervasive Biological Defensive Response","awardID":"0428344","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":[257712,"473966","473898","498314",257716],"PO":["562984"]},"98913":{"abstract":"Proposal Number: 0435065<br\/>PI: Thomas Anderson<br\/>Institution: University of Washington, Seattle <br\/>Title: A Shared Facility for Internet Reverse Engineering <br\/><br\/>Abstract: <br\/><br\/>Today, network researchers are hamstrung by a lack of quantitative data about the Internet's structure and operation, much as biologists prior to the Human Genome Project were hampered by a lack of data. To meet this need, the investigators are designing and building an open, shared facility for the continuous measurement, analysis, and archival of the Internet's underlying structure and operational controls. The facility allows any researcher to gain access to a live or archived feed of information about the Internet's structure and to contribute new measurement and analysis tools, thus renewing and improving the facility as a community effort over time. Three factors enable this effort: 1) recent advances in network measurement provide techniques to infer Internet properties from external observations where they were previously hidden by network boundaries; 2) large-scale, wide-area testbeds (exemplified by PlanetLab) provide a distributed platform that hosts the facility; and 3) large-scale data collection and warehousing is feasible and cost-effective given technology trends. The key expected result is the public availability of an unprecedented data set: an annotated map of the entire Internet, complete with a rich set of link, router and operational attributes. This will allow researchers to investigate the extent of problems in practice, construct models of the Internet to predict its behavior, and evaluate proposed protocol designs using real data. The broad impact of this work is to improve the quality and effectiveness of network research, and thus ultimately the security, efficiency and flexibility of the Internet itself.","title":"NeTS - NR: A Shared Facility for Internet Reverse Engineering","awardID":"0435065","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["543394","463055"],"PO":["389815"]},"97824":{"abstract":"A multidisciplinary team of researchers from Argonne National<br\/>Laboratory, Carnegie Mellon University, Columbia University,<br\/>University of Chicago, Emory University, and University of<br\/>Pennsylvania, with collaborators from the Universities of Graz and<br\/>Lubek, will initiate a long term research project on image-driven,<br\/>inversion-based biophysical modeling. The team includes expertise in<br\/>numerical algorithms and scientific computing, fluid and solid<br\/>biomechanics, PDE optimization, inverse problems, medical image<br\/>analysis and processing, and distributed and grid computing necessary<br\/>to tackle this class of problems.<br\/><br\/>This project aims to create a framework for assimilating multimodal<br\/>dynamic medical image data to produce highly-resolved,<br\/>physically-realistic, patient-specific biomechanics models. While the<br\/>computational and algorithmic aspects of the project are widely<br\/>applicable, the target application will be the construction of<br\/>patient-specific cardiac biomechanics models from 4D image datasets of<br\/>heart motion. Such models are useful for medical diagnosis and<br\/>surgical planning. This places a premium on quick turnaround of the<br\/>computations, which mean they must be fast, scalable, and capable of<br\/>exploiting grid-based computing.<br\/><br\/>Research will focus on three key areas that undergird the project's<br\/>overall goals: registration, inversion, and distributed computing. The<br\/>registration research component will create multilevel algorithms to<br\/>extract cardiac deformation histories from time-varying medical image<br\/>datasets via the solution of sequences of 3D image registration<br\/>problems. The inversion research component will develop multilevel<br\/>algorithms that use these deformation field histories as virtual<br\/>observations to solve inverse problems for cardiac biomechanical<br\/>parameters. The distributed computing research component will create<br\/>tools for performance prediction and resource scheduling that support<br\/>simulations across distributed computational resources.<br\/><br\/>Dovetailing with the research components, the project will undertake<br\/>an educational program designed to communicate the fruits of its work<br\/>and of the wider benefits of the integration of the biomedical<br\/>sciences, computing sciences, and computational sciences, to a more<br\/>general audience of students, disciplinary researchers, and the lay<br\/>public. The professional activities of the team members in the<br\/>inversion, image registration, grid computing, and computational<br\/>science communities will be parlayed to organize workshops and<br\/>international meetings, edit volumes, teach summer schools, develop<br\/>university and short courses, and engage in outreach activities---as<br\/>they have done in the past---but with greater emphasis on the field of<br\/>computational biomedicine. The proposed image-based cardiac<br\/>biomechanics modeling application will provide an excellent<br\/>opportunity to demonstrate the benefits to health and welfare that<br\/>advances in optimization-based registration and inversion algorithms<br\/>and Grid computing can provide.","title":"ITR: Collaborative Research - ASE - (sim+dmc): Image-based Biophysical Modeling: Scalable Registration and Inversion Algorithms and Distributed Computing","awardID":"0427695","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":[257448,"559409"],"PO":["564898"]},"98924":{"abstract":"In the ideal world, we would have Personal Information Management (PIM) tools that would enable us to have the right information at the right time, in the right place, in the right form, and of sufficient completeness and quality to perform the current activity. However, significant challenges must be met if PIM is to approach this ideal. Notwithstanding the importance of PIM, the field of PIM research is currently fragmented. The NSF Workshop on Personal Information Management will bring together participants selected to represent a range of perspectives on PIM in order to assess PIM as a need and as a field of inquiry with special focus on the ways in which computing technology can help. The workshop will produce a detailed report outlining a roadmap for PIM research and describing: (1) the current state of PIM as a practice and a field of research; (2) major challenges that must be addressed if PIM is to improve and if the field is to advance; (3) approaches that promise to meet these challenges and specific suggestions on how these approaches can be nurtured, including PIM education. The report will be widely disseminated and is expected to have a major influence on the conceptualization of PIM and on the direction of PIM research. Special care will be taken, in the selection of workshop participants and in the content of the final report, to represent a diversity of user needs including the needs of minorities, the economically disadvantaged, students, the elderly and the disabled.","title":"NSF Workshop on Personal Information Management","awardID":"0435134","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["467745","376063"],"PO":["563751"]},"98935":{"abstract":"NeTS-ProWiN: Broadband Optical\/RF Wireless Networks with Topology and Diversity Control<br\/><br\/>Award 0435206<br\/><br\/>Stuart Milner, Univ. of Maryland - College Park<br\/><br\/>Abstract<br\/><br\/>Optical fiber backbones provide gigabit per second data rates enabling end-to-end multimedia services to homes, offices, classrooms and even mobile users. However, there is a significant gap between such backbones and end users both in availability and capacity. This has been referred to as \"the last (or first) mile problem\" and continues to be the greatest obstacle we face in implementing broadband networks from anywhere to anywhere. <br\/><br\/>In this project, software for autonomous network reconfiguration (topology control) is being developed, which will promote survivability (bi-connectedness), scalable autonomous physical and logical reconfiguration, maximum data rate and maximum availability at all times and everywhere in a wireless backbone. <br\/><br\/>In a unique manner, reconfigurable optical wireless communications, with up to gigabit per second transmission rates are used in combination with directional RF communications. This offers the capability for autonomous physical and logical reconfiguration. This is referred to as topology control, uniquely combining autonomous backbone formation with assured, agile, optical wireless and RF links. <br\/><br\/>Innovative advanced software methodologies and techniques for topology control are being developed. The software includes: traffic engineering and reconfiguration algorithms; multi-objective optimization; and topology discovery, dissemination, and survivability. Software and methodologies designed to respond to degradation in the network link(s) as well as for network recovery will include: traffic engineering; multi-objective optimization techniques with embedded uncertainty modeling; and topology discovery, dissemination and survivability. Evaluation of the algorithms and software will be achieved using analytical and discrete event simulation techniques.","title":"NeTS: PROWIN: Broadband Optical\/RF Wireless Networks with Topology and Diversity Control","awardID":"0435206","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["554332","429454","281865","496361"],"PO":["402055"]},"98946":{"abstract":"NeTS:ProWiN: Programmable Radio Platforms for Highly Dynamic Networks<br\/>Award 0435297<br\/>Patrick White, Stevens Institute of Technology<br\/><br\/>A promising approach for reducing spectrum congestion in wireless networks is to introduce programmable radio platforms equipped with Software Defined Radios (SDR) that can apply cross-layer as well as cross-network optimization to maximize performance over changing RF environments. These programmable radios can independently adjust a variety of communications parameters including, modulation, power-level, and antenna beam pattern. They can also load-share traffic as well as integrate the individual capacities of available wireless networks to meet instantaneous performance requirements and improve coverage. While these capabilities are highly desirable, they create new challenges for the wireless network designer, since a programmable radio has increased capability to influence not only communications in which it is directly involved but also communications between unrelated nodes.<br\/>How should programmable radios adapt their communications parameters to maximize performance while at the same time, minimize interference? This project addresses this question at several levels. First, we define new sub-layer structures within the physical layer for synchronizing pair-wise performance. We introduce primitives, ''adjectives and adverbs,\" for integrating software radios with higher OSI layers. These primitives define the environmental sensing and channel parameter adjustments that will be supported in an SDR. Finally, we define rules (i.e., the etiquette) that should be adopted and enforced to encourage ''proper behavior\" by groups of programmable radios to minimize the effects on unrelated communications.","title":"NeTS:ProWiN: Programmable Radio Platforms for Highly Dynamic Networks","awardID":"0435297","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543625","511247","409087","339664",260839],"PO":["434241"]},"98957":{"abstract":"NeTS-ProWIN: Dynamic Intelligent Management of Spectrum for Ubiquitous Mobile Networks (DIMSUMnet)<br\/><br\/>Paul Kolodzy, Stevens Institute of Technology<br\/><br\/>Award 0435348<br\/><br\/>Abstract<br\/><br\/>Current spectrum allocation rules set by Federal Communications Commission (FCC) have lead to an artificial spectrum scarcity, even though large swaths of spectrum remain underutilized. The new paradigm of Dynamic Spectrum Access shows promise of alleviating this and ushering in new forms of networks. However, most current research on this topic has focused on highly opportunistic, uncoordinated spectrum access for peer-to-peer ad-hoc communications.<br\/><br\/>This research takes a pragmatic viewpoint that coordinated dynamic spectrum access techniques to allocate spectrum on an on-demand basis can be quite beneficial in cellular and Fixed Wireless Access (FWA) networks. This effort addresses the following research problems in this context: (1) Develop a comprehensive understanding of spatio-temporal spectrum usage in existing cellular networks using extensive spectrum measurements in the urban and rural settings. (2) Develop models for spectral utilization and quantify improvements in spectral access efficiency and utilization. (3) Research spatial data representation structures, scalable spectrum servers, and spectrum allocation sharing\/trading policies that are required to support efficient dynamic spectrum access.<br\/><br\/>This project will create a body of RF spectral measurements to determine the locality of spectrum utilization (in time and space). Additionally, the data analysis will lead to new models of spatial-temporal-spectral correlation for urban and suburban environments. Finally, characterization of RF dynamics will be characterized in order to drive choice of spectrum management control parameters leading to optimal application of dynamic spectrum allocation. In summary, this research will result in fundamental contributions to the science of coordinated spectrum access.","title":"NeTS:ProWiN: Dynamic Intelligent Management of Spectrum for Ubiquitous Mobile Networks (DIMSUMnet)","awardID":"0435348","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["260905",260876,"486344","564558"],"PO":["564777"]},"96306":{"abstract":"Title: ITWF Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science<br\/><br\/>CNS 0420436, PI Horwitz, Univ. of Wisconsin-Madison<br\/>CNS 0419340, PI Huss-Lederman, Beloit College<br\/>CNS 0420312, PI Munson, Univ. of Wisconsin-Milwaukee<br\/>CNS 0420337, PI Dunsmore, Purdue University<br\/>CNS 0420343, PI Rodger, Duke University<br\/>CNS 0420358, PI Binkley, Loyola College of Maryland<br\/>CNS 0420368, PI Biggers, Georgia Institute of Technology<br\/>CNS 0420433, PI Ryder, Rutgers University<br\/><br\/><br\/>This collaborative ITWF project implements a new approach to introductory computer science with the goal of increasing the enrollment and retention of women and under-represented minorities in undergraduate computer science degree programs. The project adapts the Emerging Scholars Program and the Peer-led Team Learning approaches, which have been proven successful in mathematics and other sciences, to computer science. It is a collaborative project between the University of Wisconsin-Madison, Beloit College, Duke University, Georgia Institute of Technology, Loyola College of Maryland, Purdue University, Rutgers University, and the University of Wisconsin-Milwaukee. The project includes targeted recruitment of students with strong mathematics and science backgrounds to the new course. The course includes students working in small groups on challenging problems with group facilitation by outstanding undergraduates.<br\/> <br\/>The intellectual merit of this project lies in the strong basis on models that have been successful in other disciplines. The collaborative represents a team of investigators with significant expertise in educational reform and transformation. Implementation will take place at the diverse set of institutions represented by the collaborative partners, thus providing an excellent environment for evaluation of this innovative approach and illustrating the possibilities for replication and adoption by a wide range of institutions.<br\/><br\/>The broader impacts of the project lie with the potential increasing the participation of under-represented groups in computer science. The method to be tested is relative low cost and straightforward to implement, thus it has a high potential for broad impact across the country.","title":"ITWF: Collaborative Research: Increasing the Representation of Undergraduate Women and Minorities in Computer Science","awardID":"0420358","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["409262"],"PO":["361119"]},"98968":{"abstract":"Abstract: <br\/><br\/>In a battery-powered sensor network, energy and communication bandwidth are both limited. Moreover, processing a sensor measurement locally often requires orders of magnitude less energy than communicating it to a distant node, yielding an interesting communication\/computation tradeoff: whenever possible, the network should reduce the need for global communication at the expense of increased local processing and communication. A promising approach for reducing global communication is to perform signal processing to extract key information inside the sensor network in a distributed fashion, thus dramatically reducing global communication requirements without losing fidelity.<br\/><br\/>This project aims to develop a sensor network architecture whose communications hierarchy is aligned with the information flow of its computations. In particular, the research involves developing (1) a multi-overlay sensor network architecture that supports both multi-scale and proximity communication and computation; (2) new multiscale sensor data representations based on wavelet transforms; and (3) network services for sychronization and localization of network nodes. The research includes analysis, simulation, and a small-scale testbed of sensor nodes on the Rice University campus.","title":"NeTS NOSS: AssimNet","awardID":"0435425","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["302291","485219","497441","282239","543600"],"PO":["564777"]},"96427":{"abstract":"This work, supporting one large project on mobile, collaborative, agent-based computing, builds testbeds for a variety of research activities centered around sensor networks, and ties together robotics, wireless sensor networks, and distributed computing. The project, composed of smaller projects on distributed robotics and computer vision, distributed sensor networks, and distributed agent computing, enables both an increase in simulation capability and experimental work to validate these simulations. The robotics and vision project seeks to enable new modes of communication between distributed agents, new techniques for context-aware recognition of people and events, and scalable means for simulating multi-agent learning. The mobile ad-hoc\/sensor network project examines data fusion and in-network processing of sensor information with an application of target tracking and surveillance using heterogeneous sensors, exploring security issues related to data injection attacks in the networks (LEAP) and energy management issues related to employing different techniques for power saving. Additionally, the research involves a project on distributed, mobile agent software. The research activities that will benefit from the proposed infrastructure include projects on<br\/> Distributed robotics involving teams of heterogeneous agents<br\/> Distributed visual observers, <br\/> Swarm agents, <br\/> Multiagent learning, <br\/> Security protocols for wireless sensor networks, <br\/> Distributed surveillance using mobile robots and sensor networks, <br\/> Light-weight agent architectures,<br\/> Agent-based multicasting for distributed virtual environments, and<br\/> Dynamic reconfiguration and middleware for mobile software agents.<br\/>Broader Impact: The infrastructure supports undergraduate and graduate courses on robotics, sensor networks, computer vision, and multi-agent technology, helping spawn student learning and interest in these areas of technology. The results and the software developed will be disseminated to the wider community. Fourteen faculty members will contribute to enhance collaborations with other institutions to address critical problems such as homeland security, healthcare, home and factory automation, disaster recovery, and environmental and infrastructure monitoring.","title":"MRI:Acquisition of an Experimental Testbed for Research and Teaching in Mobile Collaborative Agents","awardID":"0420793","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[252983,252984,"511512","553609","549627"],"PO":["557609"]},"97879":{"abstract":"Integrating and sharing data from multiple sources has been a long-standing challenge in the database community. This problem is crucial in numerous contexts, including data integration for enterprises and organizations, data sharing on the Internet, collaboration among government agencies, and the exchange of scientific data. Many applications of national importance, such as emergency preparedness and response; as well as research in many scientific domains, require integrating and sharing data among participants.<br\/><br\/>Data integration is seriously hampered by an inability to ensure privacy. Without a privacy framework, sources are reluctant to share their data. Problems include fear of disclosing confidential information as well as regulations protecting individual privacy. While there has been progress in computing aggregations of distributed data without disclosing that data; e.g., privacy-preserving distributed data mining, it assumes data integration problems (schema matching, record linkage) are solved. As a consequence, the lack of a privacy-preserving data integration framework has become a key bottleneck to deploying data integration.<br\/><br\/>This project will develop the technology needed to create and manage federated databases while controlling the disclosure of private data. While the emphasis will be on general techniques for data integration that preserve privacy, the project will work in the context of diverse but particularly relevant problem domains, including scientific research and emergency preparedness. Involvement of domain experts from these fields in developing and testing the techniques will ensure impact on areas of national importance.","title":"ITR - (ASE+NHS) - (dmc+int): Privacy-Preserving Data Integration and Sharing","awardID":"0428168","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["438745","562974","531543","499351",257636],"PO":["565136"]},"98869":{"abstract":"NeTS-ProWiN: Cognitive Radios for Open Access to Spectrum<br\/><br\/>Award 0434854<br\/><br\/>Narayan Mandayam, Rutgers<br\/><br\/>Abstract<br\/><br\/>Spectrum regulation has traditionally been driven by improvements in technology, from improved filters to the sophisticated logic and radio techniques that created the cellular revolution. More recently, however, a new paradigm has emerged in which regulation has driven technology. A modest regulatory experiment in \"open spectrum\" that began in the ISM bands has spawned an impressive variety of important technologies and innovative uses, from cordless phones and wireless LANs to meter readers and home entertainment products. Since these systems must adapt to a wide variety of unpredictable conditions, the emerging technologies called \"cognitive radio\" offer significant potential benefits in system capacity and service quality.<br\/><br\/>This investigation begins with the forward-looking assumption that a perfect cognitive radio exists and can configure itself to any transceiver type. Under this assumption, a number of exemplary cognitive strategies are studied to identify the approaches that offer the greatest benefit at the least \"cost\". These strategies include: (1) discovery of available spectrum, (2) information to support efficient operation, (3) negotiation in situations of conflict, (4) coding for efficient sharing, and (5) domination in situations of conflict. Because these strategies are technologically diverse, their costs are measured against the common metrics of hardware and protocol complexity.<br\/><br\/>This work is carried out using a combination of fundamental analysis, computer simulation and physical emulation using testbeds developed at WINLAB. The results will identify the potential benefits and costs of a diverse set of design strategies, and will be disseminated via a workshop for practitioners in the field.","title":"NeTS-ProWin: Cognitive Radios for Open Access to Spectrum","awardID":"0434854","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"V818","name":"DEFENSE-NETS PROGRAM"}}],"PIcoPI":["463100","475434","466323","348167"],"PO":["434241"]},"96449":{"abstract":"Although it is now becoming increasingly common to encounter automatic speech recognition technology embedded in systems and applications used in daily life, the accuracy of recognition systems is frequently inadequate in difficult acoustical environments or in the presence of interfering sound sources. The well-known ability of the human auditory system to process and interpret a desired speech signal effectively, even in the presence of multiple interfering sounds, has caused the auditory system to serve as both an inspiration and a model for the design of automatic speech recognition systems. Nevertheless, most of these efforts to date have been largely unsuccessful, both because of the intrinsic difficulty in identifying those aspects of the speech signal that remain most resilient to interference and distortion, and because of a historical failure to match physiologically- and perceptually-motivated features of sounds to the characteristics of the speech recognition systems that make use of them.<br\/><br\/>This project has three major components. New features for speech recognition systems are being developed that are based on contemporary knowledge of auditory physiology and perception. Techniques based on computational auditory scene analysis are being used to identify and separate those components of a complex sound field that belong to a target speech signal, using missing-feature techniques to restore those components of the target signal that are distorted by interfering sounds. Most importantly, the speech recognition system itself is modified on several levels to take best advantage of the statistical attributes of the features that are extracted.<br\/><br\/>This project will address some of the most difficult problems in speech recognition in difficult acoustical environments. The attainment of our goals would have enormous impact in extending the automatic recognition of natural and causal speech to environments such as automobiles, personal digital assistants, and cell phones. In addition, this project has the potential of helping to unify the auditory and speech research communities that have until now developed largely independent perspectives on how knowledge of human audition can best be applied to robust automatic speech recognition.","title":"Robust Automatic Speech Recognition Based on Auditory Processing and Sound Separation","awardID":"0420866","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T010","name":"NSA-HTL CENTER FOR EXCEL PROJE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V839","name":"NSA-HUMAN LANGUAGE & COM PROG"}}],"PIcoPI":["409820","409821"],"PO":["565215"]},"98506":{"abstract":"The increasing demands of modern computation require innovative solutions to data storage and processing. Conventional architectures are often limited not by processor speed, but by the ability to efficiently handle large amounts of data. Optical architectures for these applications promise potential gains in speed, data throughput, & storage density. In addition, an entirely new class of materials has emerged that is expected to provide practical solutions to these demanding applications; these materials include not only conventional optical & holographic materials, but also of those of biological origin. Bacteriorhodopsin (BR) was among the first proteins to attract attention as a viable component in molecular electronics & nanotechnology. In the native organism, Halobacterium salinarum, the protein acts as a photosynthetic sunlight to chemical energy transducer. Through billions of years of evolution, nature has produced a protein that is remarkably rugged and responds quickly and efficiently to light. The protein's unique properties make it an appealing candidate for a number of devices that use light to record or process information, including holography and optical computer memory storage.<br\/><br\/>Despite bacteriorhodopsin's unique properties, it still lacks the efficiency necessary for commercialization. Fortunately, advanced techniques in molecular biology can be used to optimize the protein for specific device architectures. Through techniques such as random mutagenesis, semi-random mutagenesis, and directed evolution, researchers can custom-tailor protein properties in ways never before possible. The use of directed evolution techniques to produce BR variants for optical recording materials will result in reusable holographic media that require no processing or fixing, and are capable of real-time operation. The goal of this research effort is to develop a new class of fully write-read-erasable dynamic holographic recording media based on genetically-engineered bacteriorhodopsin variants. Each new material will be evaluated to determine which is the most efficient, with respect to a number of standard holographic benchmarks.<br\/><br\/>The targeted application we hope to develop is a bacteriorhodopsin-based holographic associative memory, which simulates the way the human brain works. Associative memory architectures are not new, but their utility has been limited by the absence of materials that facilitate highly efficient implementation (i.e., the lack of truly reusable media). Associative memories allow computers to identify objects and concepts faster and more efficiently- applications include any technology that requires autonomous general-pattern recognition and\/or fast & efficient large-scale database search capabilities. Information processing techniques such as data mining, data reduction, and large-scale complex database searches will be enhanced through the successful development of these architectures. Furthermore, this technology has the potential to play a critical role in the development of artificial intelligence (AI)-successful implementation of AI architectures will require a fast & efficient large-scale database search capability. Incorporation of dynamic write-read-erase materials into pre-existing associative architectures will introduce a level of flexibility not previously possible.<br\/><br\/>To summarize, the proposed effort uses advanced molecular biological techniques to produce genetically-engineered bacteriorhodopsin (BR) proteins for holographic associative memories. The technical merit & broader impacts of this technology must therefore be considered at multiple levels, including (1) development of novel holographic materials & (2) the ramifications of viable associative memories. The former will impact any holographic technology that will benefit from a real-time reusable media (e.g., optical memory & non-destructive testing architectures), while the latter will facilitate any technology that will benefit from the ability to utilize fast & efficient large scale database capabilities (e.g., artificial intelligence, proteomics, and the human genome project). Perhaps the most basic impact of this technology will be the demonstration of random mutagenesis and directed evolution as viable techniques for the production of custom-tailored proteins to be used in a variety of applications.","title":"BIC: Genetically-Engineered Bacteriorhodopsin Proteins for Holographic Associative Memories","awardID":"0432151","effectiveDate":"2004-09-01","expirationDate":"2006-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["380924",259496,"315512"],"PO":["521045"]},"98759":{"abstract":"The use of computer-supported interaction has become a primary feature of communication among group members, due in part to its structural (freedom of time and geographical constraints) and psychological (anonymity) features. As a consequence, many group researchers have investigated the role of group process variables in computer-supported interactions. Because groups communicate via the use of computers in many personal, educational, and professional settings, it is important to continue and encourage the study of group processes in such environments. One theoretical issue that is implicit in many of the studies of group process variables in computer-supported interaction is whether technology is deterministic or determined. Spears and Lea (1994) recognized this issue when discussing whether technology was a panacea, allowing for greater freedom of expression and equality of status, or a panopticon, limiting expression and increasing control due to its ability for surveillance. The purpose of this conference is to bring together a diverse group of researchers with established programs of research on group processes in computer-supported interaction. This conference should serve to make the theme of technological and social determinism more explicit, thus leading to greater unity in the dominant research programs. The proposed conference offers a unique and timely theme, and is cross-disciplinary and cross-cultural.","title":"Conference on Group Processes in Computer-Supported Interaction: Technological and Social Determinism","awardID":"0434200","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1332","name":"SOCIAL PSYCHOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["489570",260261,260262],"PO":["563839"]},"99848":{"abstract":"This grant will support a study by the Computer Science and Telecommunications Board (CSTB) of the National Academy of Science (NAS) that will examine policy and technical issues that arise with the large-scale government use of data mining and information fusion technologies for various national purposes, including, for example, counter-terrorism, law enforcement, public health, and Federal statistics. Of particular interest will be an examination of alternative approaches to both policy and technology that may help to ameliorate privacy risks. Working in collaboration with the Committee on National Statistics of NAS, CSTB will convene an interdisciplinary committee to blend technical and non-technical expertise, engaging both critics and proponents of data mining and information fusion technologies. <br\/><br\/>One or more workshops will be held early in the study process, both to inform the committee and to put useful material on the public record through publication of workshop proceedings. A final study report will be prepared featuring: <br\/><br\/>1. Alternative visions for how broad access to diverse government and non-government databases might be realized, including how access, privacy, and confidentiality could be achieved together; <br\/>2. An economic, legal, policy, social and technical issues roadmap; and <br\/>3. A set of recommendations.","title":"Policy and Technical Dimensions of Large-Scale Government Use of Data Mining and Information Fusion","awardID":"0441216","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V816","name":"BUR OF CENSUS-CNSTAT"}}],"PIcoPI":["298189","298190","560890"],"PO":["371077"]},"98528":{"abstract":"This proposal targets a set of interdisciplinary tasks that directly address the challenges facing<br\/>the burgeoning field of quantum information processing (QIP). In particular, both foundational<br\/>work aimed at enhancing the understanding of fundamental underlying concepts, such as quan-tum<br\/>entanglement, as well as applied work, such as designing quantum algorithms that would<br\/>require only tens of qubits, while still providing better performance than their classical counter-parts,<br\/>are targeted. The technical approaches to be adopted in the proposed work encompass<br\/>a number of different fields, including quantum mechanics, quantum information theory and<br\/>concepts, theory of computation, combinatorics, and classical electromagnetic fields and related<br\/>computational methods.<br\/>Intellectual Merits: A number of fundamental challenges need to be overcome before QIP<br\/>can become a viable computing paradigm. This proposal addresses several of these challenges<br\/>in a novel fashion, including: (i) What kinds of quantum algorithms can one implement in<br\/>systems comprising tens of qubits? This is a very important issue facing the field of quantum<br\/>computation: a system comprising the thousands of qubits necessary to factorize integers beyond<br\/>the capability of existing classical computers is, at best, a long-term goal. In contrast, a system<br\/>comprising tens of qubits is a conceivable goal; however, would there be any quantum algorithm<br\/>that can be implemented on such a small scale computer and yet outperform classical algorithms?<br\/>The proposal presents a quantum algorithm that can be used to simulate Maxwell's equations to<br\/>determine classical electromagnetic mode frequencies of resonant structures, where the complete<br\/>mode field distribution is not required. It is estimated that 50 logical qubits would be sufficient<br\/>to produce useful electromagnetic simulation results. (ii) Is there life beyond Quantum Key<br\/>Distribution? The proposal presents results where the basic tools of quantum cryptography are<br\/>used to build a multi-participant protocol which gives the participants the ability to anonymously<br\/>announce classical information. This protocol is shown to be secure against any and all attacks.<br\/>This is the first ever multi-participant quantum protocol that uses a truly multipartite quantum<br\/>entangled state. (iii) What are examples of nontrivial new quantum algorithms (i.e., other<br\/>than Shor's factorization and Gover's search algorithms? The proposal reports results on the<br\/>development of efficient quantum algorithms for determining the permanent of unitary and<br\/>related matrices using the quantum optical model. A number of such critical open questions<br\/>related to QIP are addressed.<br\/>Broader Impacts: (i) Undergraduate Interdisciplinary Program: In collaboration with the Cal-ifornia<br\/>Nano-science Institute (CNSI) and the Department of Electrical Engineering at UCLA,<br\/>we are in the process of developing a nano-science interdepartmental program. Quantum in-formation<br\/>processing is a key component of this program and the NSF grant will be leveraged<br\/>to support this initiative, and in training graduate and undergraduate students. (ii) Annual<br\/>Workshops On Quantum Information Processing: In collaboration with the NSF Institute of<br\/>Pure and Applied Mathematics (IPAM) at UCLA, an interdisciplinary annual workshop on<br\/>Quantum Information Processing and Computing will be held. (iii) Providing Support for<br\/>Implementation-Oriented DARPA projects on Quantum Computing: Dr. Roychowdhury is the<br\/>principal theoretician for a large interdisciplinary experimental group at UCLA working on de-veloping<br\/>solid-state based quantum information processing technology. The experimental effort<br\/>is currently supported by grants from DARPA and ARO, and the NSF grant will leverage the<br\/>existing program and focus on transferring theoretical results to the experimental groups. (iv)<br\/>Outreach and Minority Student Participation: Both IPAM and CNSI have institutional infras-tructures<br\/>in place to attract minority and K12 students, and we plan to engage them and train<br\/>them through seminars and free access to our workshops.","title":"QnTM: Harnessing Quantum Entaglement: Fundamental Studies, Communication Protocols, and Computing","awardID":"0432296","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}}],"PIcoPI":["455118"],"PO":["521045"]},"98429":{"abstract":"Recent years have seen the advent of DNA-based computation, as well as the development of a<br\/>DNA nanotechnology that produces objects, robust devices and periodic arrays. We propose to<br\/>combine these areas, by using a robust 2-state DNA device and DNA array assembly techniques<br\/>to prototype a programmable finite state machine capable of performing simple computations.<br\/>The goal is to produce a system that is programmable, produces an output and is reusable.<br\/>We exploit connections between Wang tiles, finite state machines (transducers) and com-<br\/>putable functions. The main idea uses DNA TX molecules to represent transducer transitions<br\/>and a sequence of 2-state DNA devices to program the input. Once the input is programmed,<br\/>the computation of the transducer is obtained solely by DNA self-assembly. Further more, iter-<br\/>ations and composition of transducers is also possible and hence all computable functions can<br\/>be obtained.<br\/>The project is composed of two major tasks,<br\/>1. To simulate computation by a finite state machine with output by a single assembly of<br\/>input molecules and TX transition molecules.<br\/>2. To obtain transducer computation with a programmale input by DNA 2-state devices and<br\/>TX molecules.<br\/>Intelectual Merit. The project prototypes a nanomachine that is potentially programmable<br\/>and produces an output that can serve as an input in a new device or as a template for orga-<br\/>nization and growth of nanostructures used in nanoelectronics. The proposed machine has a<br\/>potential for an algorithmic control of this growth. Theoretically, the design of the machine and<br\/>the need for encoding (locally and globally) that is error correcting will lead to development of<br\/>new techniques in algorithmic pattern design.<br\/>Broader Impact. Research in DNA-based computation relies on many disciplines, such as<br\/>computer science, DNA chemistry, nucleic acid enzymology, thermodynamics and molecular<br\/>physics. Few individuals enter in to it with adequate preparation. We will attempt to provide<br\/>some remedy for this problem during the course of this project. The graduate, undergraduate<br\/>and high school students who participate in this work will be uniquely trained and will be<br\/>prepared as unique interdisciplinary research scientists. Three graduate students (two at New<br\/>York University and one at the University of South Florida) will receive graduate training<br\/>through this award. They will meet with each other, and become familiar with the thinking and<br\/>methodologies of their opposite colleagues in the other university. In addition, we will include<br\/>an undergraduate in the project, to gain experience in combining computer science with DNA<br\/>nanotechnology. We aim to include a high school student in the parts of the work for which<br\/>they are eligible (e.g., computation and experiments not entailing the use of radiation).<br\/>Besides their own nanotechnological and mathematical disciplines, the PI and the co-PI are<br\/>prominent members of the DNA-based computation community. Both facets of this commu-<br\/>nity recognize that it is converging with structural DNA nanotechnology. In recognition of<br\/>this interdisciplinary phenomenon, the PI and the co-PI are involved in founding (as president<br\/>and treasurer, respectively) the \\International Society for Nanoscale Science, Computation and<br\/>Engineering\" with a goal to facilitate communication among the members of the participating<br\/>communities, and to recognize and promote the careers of the younger members, by offering<br\/>them recognition and a forum for their ideas.","title":"QnTM: Quantum Channel Capacities and Quantum Complexity","awardID":"0431787","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1705","name":"BIOLOGY & INFORMATION TECHNOLO"}}],"PIcoPI":["518163"],"PO":["521045"]},"98319":{"abstract":"This project seeks to develop the fundamentals of physical layer<br\/>wireless multi-antenna communications to enhance and significantly impact<br\/>the design of current and future-generations of cellular telephony, personal<br\/>communication services, and wireless local area networks.<br\/><br\/>Fundamental limits of delay-sensitive wireless channels for realistic fading<br\/>models will be sought along with the development of innovative power- and<br\/>spectrum-efficient methods for use over multi-antenna systems. These methods<br\/>will extract all the available spatial, temporal, and spectral degrees of<br\/>freedom and diversity under practical constraints on cost and complexity<br\/>that are relevant for hand-held or laptop communication devices. To this<br\/>end, new performance criteria will be formulated based on which the analysis<br\/>and optimization of various complexity-constrained communication schemes<br\/>will be carried out. The planned research will emphasize tight interactions<br\/>among, and the discovery of new methods in, the information and<br\/>communication theoretic foundations of fading channels and the associated<br\/>coding, modulation and signal processing functions.","title":"Delay-Sensitive Wireless Communications","awardID":"0431170","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["508378"],"PO":["432103"]},"92940":{"abstract":"This award includes synergistic research in fundamental communications theory and the development of novel communications technologies. To make these research activities possible the principal investigators (PIs) will establish new and enhance the existing research infrastructure for research programs associated with the Center for Information Technology Research in the Interest of Society (CITRIS) and two of its members: the Berkeley Wireless Research Center (BWRC) and the Wireless Foundations Center (WFC). The purpose of this new infrastructure is to build a research environment that enables investigation of novel technologies for cognitive radios, high data rate transmission over wireless local area networks (WLANs), and wireless sensor networks. <br\/>The wireless explosion that the researchers are witnessing today can be largely attributed to the availability of unlicensed spectrum bands. New unlicensed bands are being allocated, for example the 5GHz of spectrum available worldwide at 60GHz. At the same time, a large majority of available spectrum is locked in by its pre-allocated use in legacy systems. The PIs will investigate methods of overlaying the legacy systems with new wireless systems, which allow the use of ultra-wideband (UWB) radios to operate in the 3-10GHz band. Simultaneously, the FCC is considering allowing unlicensed 'cognitive' radios to overlay allocated bands, such as TV spectrum overlay.<br\/>This award takes a broad and thorough inter-disciplinary approach to developing the fundamental understanding of the operation in new bands, such as 60GHz and UWB, spectrum reuse and spectrum recycling by cognitive radios, together with reducing the requirements of these systems to the basic hardware specifications of the underlying technology.<br\/>The researchers are developing a common computational, test and measurement infrastructure that will allow a quantum leap in wireless technology research and its applications. By building a common computational infrastructure, consisting of compute servers, clusters of workstations and FPGA-based emulation, the researchers will foster the propagation of information from theory to prototypes. To fundamentally understand the physical properties of new bands as well as new methods of spectrum utilization and coexistence of various systems, the researchers will make a major investment in test and measurement infrastructure.<br\/>Broader Impact. This common infrastructure will support the research of over a hundred graduate students, tens of undergraduate researchers and more than ten faculty. To maximize the impact, in addition to the traditional means of publications, the research results will be disseminated through participation in communications standardization processes, participation in government and NSF-sponsored studies on wireless technology and policies, and industry involvement. Research results will be used to form new graduate and undergraduate courses that will be taught in Berkeley and elsewhere.","title":"UC Berkeley Wireless Research Infrastructure Program","awardID":"0403427","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":[243579,"523728","560234"],"PO":["550859"]},"90300":{"abstract":"The goal of this research project is to investigate techniques and develop effective tools for tracing the provenance and flow of data in a network of inter-related databases where each database may be constantly evolving. The following three key areas are investigated: <br\/>(1) Reasoning about provenance for relational\/XML data through constraints. The relationships between databases or versions of databases can often be described by high-level abstractions such as constraints. Hence, tracing the provenance or flow of a piece of data involves reasoning about the movement of a piece of data through constraints. <br\/>(2) An annotation management system based on provenance. This system provides an alternative method for computing provenance. It does so \"eagerly\" by carrying provenance along as annotations when data is transformed. <br\/>(3) An archiving toolkit based on key constraints. A set of utilities for efficiently archiving and managing evolving databases in a semantically meaningful way is provided. The archive is such that the provenance of a piece of data can be easily traced. <br\/>The results of this project have potential applications in many domains, in particular in scientific databases such as bioinformatics. Whenever applicable, results of this project will be prototyped and experimental evaluations will be conducted on both synthetic and real datasets in order to evaluate the effectiveness of the results. The results will also be integrated into an advanced database topics course on data provenance that will be developed and taught at UC Santa Cruz. Project website http:\/\/www.cs.ucsc.edu\/~wctan\/provenance\/ will be used for wide dissemination of all course materials, publications, and software that result from this project.","title":"CAREER: Tracing the Provenance and Flow of Data","awardID":"0347065","effectiveDate":"2004-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["402384"],"PO":["563751"]},"93501":{"abstract":"This project proposes to develop a framework for hardware-assisted speculative program optimization (H-SPOT). H-SPOT optimizes programs aggressively based on actually observed program properties by speculatively performing optimizations that are profitable but cannot be guaranteed to be safe at static compile time. The project develops a transactional processor model that provides architectural support to ensure the correctness of optimizations at run time.<br\/><br\/>The project's technical contributions are: (1) The H-SPOT compiler that provides a<br\/>reformulation of compiler optimizations to apply them even in cases when traditional static compilers would not be able to perform them. It implements dynamic program analysis to obtain information about program properties and uses a cost-benefit model to apply the most promising optimizations. The compiler also develops a static recovery and fix-up code analysis to determine the run-time actions required to ensure the correctness of optimized programs.","title":"NGS: Collaborative Research: Transactional Execution: Making Unsafe Compiler Optimizations Work at Run Time","awardID":"0406124","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":[245092],"PO":["301532"]},"91466":{"abstract":"ABSTRACT<br\/>Special Projects Program - FY04<br\/><br\/>CNS 0352808, PI's Joan M. Francioni and John S. Hurley, Computing Research Association<br\/><br\/>Title: CREU: Collaboration Research Experiences for Undergraduates<br\/><br\/>This project provides support for the Computing Research Association's Committee on the Status of Women in Computing Research (CRA-W) and the Coalition to Diversify Computing (CDC) to join efforts in a new project designed to increase the number of women and minorities who enroll in computer science and engineering graduate studies. The new project provides research experiences to teams of undergraduates - either all women or all minority- to work on a common research project at their home institution. To emphasize interaction in research activities, CREU students apply jointly as teams to work with a faculty mentor, building on prior positive relationships. The teams work for an entire academic year and are encouraged to present their work in talks and papers that they are required to post on their common website. The project is built on a pilot program, CREW, that CRA-W has conducted for women over the last five years. Evaluation of that project was carried out by the LEAD Center at the University of Wisconsin and found to be successful. This new project will make the CREW model available to many more women and will extend its benefits to minority students and their institutions as well.<br\/><br\/>The intellectual merit of this project lies in its potential for increasing the research opportunities for undergraduates and, in some cases, for their mentors. Further, the LEAD evaluation of the program will give us insights into the factors that determine success in the recruitment of women and minorities to graduate Computer Science and Engineering (CS&E) programs. The broader impacts of the project lie with its potential for increasing the numbers and success of women and underrepresented minorities in CS&E graduate programs.","title":"Special Projects: CREU: Collaborative Research Experiences for Undergraduates","awardID":"0352808","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[239558,239559,239560],"PO":["564181"]},"103155":{"abstract":"The World Wide Web contains a vast and ever-growing collection of music audio files representing nearly every musical style, ensemble, genre, country, culture, and time period. However, with the exception of the information conveyed in the title, the contents of such audio files can only be understood by listening to the files. Thus searches of audio files analogous to those performed by text-based search engines are currently impossible. In this project the PI will study and implement solutions to the \"Signal to Score\" problem in which an audio file is transcribed into a format capturing information similar to that contained in a printed musical score. The PI's approach splits the task into two components: \"Signal to Piano Roll\" in which the musical signal is transcribed into a MIDI-like representation, and \"Rhythmic Parsing\" in which the piano roll representation is further transcribed into a musical score or equivalent representation. The goal is to allow the generation of searchable data bases that contain high level music descriptions, which could be used to algorithmically answer questions on musical content such as \"Is the audio file likely to be a blues song?\" or \"What is the time signature of the music?\"","title":"ITR\/IM (CSE): Musical Signal Recognition","awardID":"0501226","effectiveDate":"2004-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["535948"],"PO":["564456"]},"97913":{"abstract":"Energy-aware GUI Design and Run-time Application Adaptation, and Power Management\/Scaling for Mobile Computers<br\/><br\/>Abstract<br\/><br\/>Modern mobile computing systems are an integral part of the lives of millions of users. Although the latest microprocessors enable these devices to provide improved services, reducing energy consumption remains a major design challenge. Energy reduction techniques for interactive mobile systems are not well understood. The objective of this work is to develop methodologies and tools to reduce energy consumption of interactive systems from the display, application and operating system (OS) perspectives. The problems that we will tackle are as follows: Energy-efficient graphical user interface (GUI) design, Energy-aware application adaptation framework, and OS-supported dynamic power management (DPM) and dynamic voltage scaling (DVS).<br\/><br\/>The results of the research will be made available on the Web. It will also be disseminated to the industry through the companies affiliated with the NJCST Center for Embedded System-on-a-Chip Design that the PI heads. Currently, three companies are commercializing tools developed in the PI's group. This offers additional avenues for technology transfer.","title":"Energy-aware GUI Design and Run-time Application Adaptation, and Power Management\/Scaling for Mobile Computers","awardID":"0428446","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["550002"],"PO":["550859"]},"97924":{"abstract":"Digital identity management (DIM) has emerged as a critical foundation for supporting successful interactions in today's globally interconnected society. It is crucial not only for the conduct of business and government but also for a large and growing body of electronic or online social interactions. In its broadest sense, identity management encompasses definitions and life-cycle management for digital identities and profiles, and the environments for exchanging and validating such information, including anonymous and pseudonymous representations. The project addresses a wide variety of digital identity needs by developing required Flexible, Multiple and Dependable Digital Identity (FMDDI) technology, based on a sound underlying set of definitions and principles. The FMDDI technology developed in the project will support multiple forms of identity, including nyms, partial identities, and a variety of user properties, credentials, and roles. Relevant research trusts in the project include: identity schemes and representation formats; use of ontology and issues related to identity interoperability; anonymity, dependability, accountability, and forensic-friendly identification schemes; psychological and social aspects related to the use of digital identities.","title":"The Design and Use of Digital Identities","awardID":"0428554","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["553652","522969","529959",257801],"PO":["565136"]},"95405":{"abstract":"Speech technology potentially allows everyone to participate in today's information revolution and can bridge the language barrier gap. Unfortunately, construction of speech processing systems requires significant resources. With some 4500-6000 languages in the world, traditionally speech processing is prohibitive to all but the most economically viable languages. In spite of recent improvements in speech processing, supporting new languages is a skilled job requiring significant effort from trained individuals. This project overcomes both limitations by providing innovative methods and tools for a users to develop speech processing models, collect appropriate data to build these models, and evaluate the results allowing iterative improvements.<br\/><br\/>Building on the existing GlobalPhone and FestVox projects, knowledge and data will be shared between recognition and synthesis such as phoneme sets, pronunciation dictionaries, acoustic models, and text resources. User studies are applied to indicate how well speech systems can be built, how well tools support their efforts, and what must be improved to create even better systems. This research increases the knowledge of how to rapidly create speech recognizers and synthesizers in new languages. Furthermore, archiving the data gathered on the fly from many native cooperative users will significantly increase the repository of languages and resources.<br\/><br\/>By integrating speech recognition and synthesis technologies into an interactive language creation and evaluation toolkit usable by unskilled users, speech system generation will be revolutionized. Data and components for new languages will become available to everybody improving the mutual understanding and the educational and cultural exchange between the U.S. and other countries.","title":"SPICE: Speech Processing Interactive Creation and Evaluation Toolkit for New Languages","awardID":"0415021","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}}],"PIcoPI":["396893","316983"],"PO":["565215"]},"98925":{"abstract":"NeTS-ProWiN: Collaborative Research - Dynamic Spectrum MAC with Multiparty Support in Adhoc Networks<br\/><br\/>Award 0435306<br\/><br\/>Saswati Sarkar, University of Pennsylvania<br\/><br\/>Abstract<br\/><br\/>Major advances in dynamic spectrum management and the inevitable deregulation of large portions of the radio spectrum will revolutionize future wireless networks, services, and applications. This will lead to an era of spectrum efficient cognitive radios that will enable the deployment of radically different radio architectures, algorithms, and protocols over the next decade. This project is studying the design of a new programmable media access control (MAC) layer for this new environment. The MAC must regulate how future programmable radio devices can efficiently interact with each other using spectrum-aware communication algorithms. In our study, we model the MAC design as decision problems using tools from decision sciences such as stochastic control, optimization, graph theory and estimation theory. We validate the design of the MAC through an experimental implementation consisting of programmable radios. The expected results from the research include the design of a programmable MAC system that can enable a class of new applications, including enhanced reliability communications and spectrum-efficient group communications. The resulting implementation of the proposed programmable MAC platform and its software will enable the development of new intelligent spectrum-aware algorithms and applications. The results of the research will provide a set of foundation algorithms that can be used by the community developing new spectrum-aware radio systems. The research facilitates several life-critical activities e.g., search and rescue missions and disaster relief operations. The research will also enrich the education curriculum of the participating institutions and foster the participation of under-represented groups in engineering.","title":"NeTS-ProWin: Collaborative Research: Dynamic Spectrum MAC with Multiparty Support in Adhoc Networks","awardID":"0435141","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"V818","name":"DEFENSE-NETS PROGRAM"}}],"PIcoPI":["531799"],"PO":["434241"]},"97836":{"abstract":"ITR - ASE - [int+dmc]: Storage Based Supercomputing for Scientific Applications<br\/>Abstract<br\/><br\/>In many scientific computing applications the size of the data sets, already in the range of multiple terabytes, continues to grow rapidly. The time required to move this data from magnetic media, across a system bus into main memory, and then execute code to perform a computation is prohibitive. We are addressing the bottleneck by moving the computations to be implemented close to the magnetic media in fast, customizable hardware tailored to the application. We will explore the benefits associated with our proposed architecture on two specific application domains: genomics and astrophysics. In the genomics domain we will explore new approaches to discovering similarities between biological sequences. In the astrophysics domain we will examine the processing of gamma ray burst data.<br\/><br\/>The results of this research will directly translate into more capability in scientific computations that are dependent upon large data sets. This will have a direct positive impact on the fields of astrophysics and genomics. The impact, however, will go well beyond these domains since the tools, techniques and architecture developed will be applicable to a wide range of scientific computing problems. We are developing a computing system that allows effective exploration of the huge and growing datasets that are central to modern scientific discovery. This new computer architecture is a central and critical instrument, analogous to the telescope and microscope, in moving forward scientific boundaries.","title":"ITR - ASE - [int+dmc]: Storage Based Supercomputing for Scientific Applications","awardID":"0427794","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["511555","511556","402452","511557","522382"],"PO":["562984"]},"97957":{"abstract":"This project focuses on the development of a computational toolbox for investigation of multiscale<br\/>surface processes that are central to nanotechnology as well as other current technologies. Two physical<br\/>systems will be studied that span from nano-scale phenomena to large-scale deterministic transport<br\/>phenomena. The algorithms and software, developed to simulate and extract information from multiscale<br\/>systems, are generic over a broad class of problems, and will contribute well beyond the applications used<br\/>in their development.<br\/>The physical systems include electrodeposition of metallic nanoclusters with additives to achieve<br\/>specific shapes, and environmental degradation through interaction of pits, crevices and cracks. The<br\/>physical systems, chosen for their computational structure, are characteristic of a large class of systems<br\/>where controlled shape evolution is exploited to produce desired structures. Key issues are to understand<br\/>how small-scale surface interactions guide spontaneous self-organization, how to extract insight from<br\/>noisy data and uncertain fundamental understanding, and how to insure quality control at multiple scales<br\/>in manufacturing.<br\/>Computational tools will be developed for simulation and sensitivity analysis in multi-phenomena<br\/>multiscale systems that require methods for coupling of stochastic and deterministic models. Challenges<br\/>for deterministic simulation include the effective use of parallel computers, and dealing with moving<br\/>boundaries, ill-conditioning and stiffness. We will explore classes of preconditioners for the iterative<br\/>methods that solve large linear systems of equations at each time step, in particular a newly-developed<br\/>multigrid method that is well-suited to moving boundary problems. Challenges for stochastic simulation<br\/>include stiffness, which has only recently been recognized as a barrier to efficiency for stochastic<br\/>simulation.<br\/>Sensitivity analysis is an important part of this effort. For the deterministic computations, we will<br\/>make use of recently developed methods that are adaptive in space and time. We will develop new<br\/>sensitivity analysis methods and software for stochastic systems, and couple them to deterministic<br\/>sensitivity analysis for the physical systems of interest. We will facilitate the use of our toolkit by<br\/>extension to larger-scale software systems of a recently-developed environment for the rapid creation of<br\/>GUIs for scientific and numerical software.<br\/>This project addresses the National Priority Area of Advanced Science and Engineering (ASE), and<br\/>the Technical Focus Areas of Innovation in computational modeling or simulation in research or<br\/>education (sim) (primary), and of Innovative approaches to the integration of data, models,<br\/>communications, analysis and\/or control systems, including dynamic, data-driven applications for use in<br\/>prediction, risk-assessment and decision-making (dmc) (secondary).<br\/>Broader Impacts<br\/>The proposed project will impact the National Priority Area of ASE through the development of<br\/>algorithms and software to enhance the use of high performance computers in the investigation of<br\/>multiscale surface processes. The availability of such a toolbox will accelerate fundamental scientific<br\/>research and engineering design in an area with the potential for large economic impact. Software<br\/>developed as a result of this project will be widely distributed in the scientific and engineering, computer<br\/>science and mathematical sciences communities.<br\/>The educational activities feature a multidisciplinary, cross-institutional approach to graduate<br\/>education. Students will work in multidisciplinary teams, with joint thesis advisors from a primary and a<br\/>secondary discipline. This approach has recently been undertaken at UCSB with some success; we plan<br\/>to institutionalize this approach to graduate education in Computational Science and Engineering (CSE)<br\/>at UCSB, and to export the model to UIUC. The model also includes industrial internships, career<br\/>development workshops, and mentoring of undergraduates. Both UIUC and UCSB have been pioneers<br\/>in developing graduate programs in CSE and have programs with a similar structure which will facilitate<br\/>the sharing of educational ideas and innovations across the institutions.","title":"ITR - (ASE) - (sim+dmc): Computational Toolbox for the Investigation of Multiscale Surface Processes","awardID":"0428912","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["261987","524314",257924,"486626"],"PO":["565157"]},"95416":{"abstract":"Current spoken dialog systems are generally not pleasant to interact with. While human interlocutors can deftly negotiate and control pace, and smoothly signal understanding, control intentions, attitude, and so on, most dialog systems deal poorly, if at all, with these dimensions of interaction. Lacking this, dialogs tend to be stilted, awkward and frustrating, tend to demand careful attention, and tend to be time-inefficient. To address these problems, this research program seeks to develop and evaluate techniques that allow dialog systems to interpret and generate non-verbal and other indications of attitude and feeling, thereby improving these real-time aspects of system usability.<br\/><br\/>The PIs are recording human-human dialogs in controlled domains, analyzing the prosodic and contextual cues that humans use. Further, they are seeking to interpret these cues as expressing pragmatic dimensions of the interaction. The result will be a model of real-time interpersonal interaction as manifested in spoken dialog. This model will be useful for the development of more usable systems for voice access to information. The findings may also support the construction of spoken dialog systems for more challenging dialog types, such as teaching, advising and selling.","title":"Modeling Real-Time Interpersonal Interaction in Spoken Communication","awardID":"0415150","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["408502",250208,"408503"],"PO":["565215"]},"97858":{"abstract":"Unmanned air vehicles (UAVs) are playing increasingly prominent roles in the nation's defense programs and strategy. There are innumerable uses for such devices in not only military, but civilian, commerical and homeland security applications such as surveillance and reconnaissance, rapid deployment of communication networks, border patrol, sensing hazardous environments, search and rescue, precision agriculture, etc. The focus of this research is on the use of multiple miniature UAVs (MUAVs) for these applications rather than their larger military counterparts such as Predator and Global Hawk. MUAVs have a number of significant advantages over larger platforms, such as their difficulty in being detected or tracked, their ability to more easily avoid threats, to fly at low altitudes and collect more localized data, to be launched without special equipment or a runway, and to spread out and provide a wide ``aperture'' for performing tasks such as geolocation or providing communications links.<br\/><br\/>The benefits of MUAVs do not come without cost, however. There are a number of difficult challenges that must be overcome before their potential can be realized. These challenges include the following: How can a distributed group of MUAVs cooperate and communicate given their constraints on size, power and motion, and in the presence of interference? How are discrepancies in their individual data sets accounted for so that consensus on strategy can be reached? Their mobility is both a blessing and a curse; can the ever-changing shape of an array of MUAV platforms be adequately tracked or maintained for high-resolution localization or imaging tasks? This research effort is devoted to answering questions such as those above.","title":"ITR - (NHS+ASE) - (dmc+int): Distributed Communications and Control for Multiple Miniature Unmanned Air Vehicles","awardID":"0428004","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["486561",257562,"507827","507827","557396","507826"],"PO":["564898"]},"97748":{"abstract":"This ITR proposal is a request for funding to develop and deploy UltraLight, the first of a new class of integrated information systems that will support the decades-long research program at the Large Hadron Collider (LHC) and other next generation sciences. Physicists at the LHC face unprecedented challenges: (1) massive, globally distributed datasets growing to the 100 petabyte level by 2010; (2) petaflops of distributed computing; and (3) collaborative data analysis by global communities of thousands of scientists. In response to these challenges, the Grid-based infrastructures developed by the LHC collaborations provide massive computing and storage resources, but are limited by their treatment of the network as an external, passive, and largely unmanaged resource. <br\/><br\/>UltraLight will overcome these limitations by monitoring, managing and optimizing the use of the network in realtime, using a distributed set of intelligent global services. The UltraLight hybrid packet- and circuit-switched network infrastructure will employ ultrascale protocols and dynamic building of optical paths to provide efficient fair-sharing on long range networks up to the 10 Gbps range. <br\/><br\/>UltraLight's scope offers exciting and unusual educational outreach opportunities for students. It provides direct and significant support for E&O activities including: application development, experiment participation, infrastructure deployment, and internships at participating institutions. Existing outreach programs within the GriPhyN, iVDGL, and e-VLBI Grid projects, as well as Florida International University's CHEPREO and CIARA programs, will be exploited to attract undergraduates to physics and math, and to inject new important elements of information technology into core graduate science domains.","title":"ITR: ASE: INT: DMC: UltraLight: An Ultrascale Information System for Data Intensive Research","awardID":"0427110","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1221","name":"ELEMENTARY PARTICLE ACCEL USER"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7369","name":"INTERNATIONAL RES NET CONNECT"}}],"PIcoPI":["490798","530692","559256","530885"],"PO":["445352"]},"97759":{"abstract":"The management of massive amounts of data, whether in scientific collections, education curricula repositories, or persistent archives, is an essential part of the conduct of science and education. Each type of data management system requires the application of multiple constraints: data sharing (sociological controls on group interactions, access controls), data display (transformative migrations of content, group specific view mechanisms), data federation (consistency management) and data control (data placement, data synchronization). The constraints may be organized in a hierarchy as global constraints, rule-based object constraints, and process based transformative constraints. This project investigates the specification of constraint granularity, the implementation of constraint languages, and the development of data management systems that support dynamic constraint specification and application. The software is based on the Storage Resource Broker data grid technology that supports federation of digital libraries and scientific collections across academic institutions.<br\/><br\/>The broader impact of the project will be the development of adaptive middleware technologies for distributed data management. Examples include the addition of services to grid environments that preserve consistent metadata management, the addition of services to digital library systems that validate new metadata attributes for new collections, and the addition of services to preservation environments that manage authenticity of archived material. Our goal is to create generic distributed data management infrastructure that can be used at the institution level, within national scale projects such as NSF Information Technology Research efforts, and within international academic collaborations such as the Worldwide Universities Network.","title":"ITR: (ASE+NHS) - (int+dmc): Constraint-based Knowledge Systems for Grids, Digital Libraries, and Persistent Archives","awardID":"0427196","effectiveDate":"2004-09-01","expirationDate":"2008-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7704","name":"Science of Learning Activities"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["527151","554652","459028"],"PO":["565136"]},"99519":{"abstract":"Proposal Number: 0439886<br\/>PI: Jonathan Turner <br\/>Institution: Washington University <br\/><br\/>Proposal Number: 0440940<br\/>PI: Scott Shenker <br\/>Institution: University of California, Berkeley <br\/><br\/>Proposal Number: 0439642<br\/>PI: Thomas E. Anderson <br\/>Institution: University of Washington, Seattle<br\/><br\/>Proposal Number: 0439842<br\/>PI: Larry Peterson <br\/>Institution: Princeton University <br\/><br\/><br\/>Title: Collaborative Research: Virtual Networking - Enabling Innovation in Networks and Services <br\/><br\/>Abstract: <br\/><br\/>The Internet is one of the great technology success stories of the twentieth century, enabling greater access to information and providing new modes of communication among people and organizations. Unfortunately, the Internet's very success is now creating obstacles to innovation in the networking technology that lies at its core. In order<br\/>to free the global communications infrastructure from stagnation, the nation must find ways to enable its continuing renewal. This planning grant is developing a case for network virtualization as a means to enable innovation in networks and services. Virtualization allows multiple logically independent virtual networks to share a common physical infrastructure or substrate. This program is developing a plan for a major new research initiative in network virtualization that includes both basic research, the development of key technology components and the creation of an experimental testbed, to establish feasibility and provide a context in which networking researchers can develop innovative new network architectures and services. The program is articulating the case for network virtualization, soliciting input from the network research community and working with the community to develop recommendations to NSF for a major initiative in this area.","title":"Collaborative Research: Virtual Networking -- Enabling Innovation in Networks and Services","awardID":"0439642","effectiveDate":"2004-09-15","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["463055"],"PO":["292741"]},"98309":{"abstract":"AWARD ABSTRACT <br\/><br\/>This award provides funding for the development of effective and efficient algorithms to analyze large chemical compound databases and identify the compounds that are the most probable for displaying the desired drug-like behavior. These virtual screening algorithms are based on a substructure-based classification framework that utilizes (i) highly efficient frequent subgraph discovery algorithms that mine the chemical compounds to discover all the substructures (topological or geometric) that are critical for the classification task, (ii) sophisticated feature selection and generation algorithms that combine multiple criteria to identify and synthesize a set of substructure-based features that simultaneously simplify the representation of the original compounds while retaining and exposing their key features, and (iii) kernel-based approaches that take into account the relationships between these substructures at different levels of granularity and complexity. The research is integrated with an educational plan that focuses on initiating undergraduate and graduate students to the various computational and data analysis aspects of virtual screening, machine learning, and data mining through courses, summer institutes, and research opportunities.<br\/><br\/>The successful completion of this project will lead to advances in the drug development process by developing computationally efficient and accurate classification algorithms that can be used to replace or supplement biological-assay-based high-throughput screening (HTS) techniques and by producing a general purpose chemical compound classification software toolkit that will contain high-quality implementations of the various algorithms that will be developed and made available to the public. The combination of existing HTS-based approaches with these virtual screening methods will allow a move away from purely random-based testing, toward more meaningful and directed iterative rapid-feedback searches of subsets and focused libraries.","title":"SEI: Virtual Screening Algorithms for Bioactive Compounds Based on Frequent Substructures","awardID":"0431135","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["531622"],"PO":["565136"]},"92941":{"abstract":"Over the past decade, human motion analysis has become an important research area with critical applications. It is attracting significant research efforts in a number of disciplines, such as computer vision (vision-based motion capture, human computer interface, human identification), robotics (navigation), dance and choreography (automatic dance documentation and dance instruction), music (digital conducting) and bioengineering (rehabilitation and motor behavior). Motion analysis is a complex problem due to the 3D nature of the human body; the infinite possibilities of human movements; variability of movement execution between different people; continuously adaptive learning through feedback from and interactions with the environment; and the inherent multiple levels of movement structure in terms of time, space and energy. This makes it unrealistic for a single discipline to address all aspects. Therefore, progress within each discipline moves at a slow pace. <br\/>Intellectual Merit: Arizona State University has founded the Interdisciplinary Research Environment for Motion Analysis (IREMA) initiative that integrates researchers from ten disciplines to create a holistic model for motion analysis research and education. Within IREMA, ground-breaking collaborations have been established through networks of experts, infrastructures and important applications. Using this multi-level, networked research model, the principal investigators (PIs) are able to address many critical issues of real-time motion capture, analysis and feedback. Promising results of social significance are being achieved in areas such as: Rehabilitation Research to Restore Functional Walking Ability for Spinal Cord Injured, Auditory Display Systems for Aiding Interjoint Coordination, Modeling of Human and Robotic Heuristics for Projectile Interception, Movement Based Interactive Arts Environments, Experiential learning environments for children, Extraction and Recognition of Middle and Low Level Features of Movements, Vision-based Motion Capture Using Domain Knowledge. <br\/>Using the research infrastructure (RI) grant the PIs will create a multimodal sensing and feedback environment for human motion analysis research and movement-based interactive applications. They will increase their optical motion capture system to 24 cameras, create a high-speed, high resolution 24 video camera array, complete the building of a pressure sensitive floor, acquire a new EMG system and metabolic sensing equipment, acquire required hardware to integrate optical motion capture data with EMG and 2D visual as well as metabolic sensing, increasing processing and storage capacity, creating a mobile motion capture setup, and deploying the necessary hardware and software for interactive real-time feedback. The above sensing equipment would provide high-speed, high quality, synchronous video capture of multiple views, high-precision marker-based motion capture and pressure sensing in the floor as well as on the treadmill, and audio signals. It will enable the PIs to capture human movement in its full essence. The optical motion-capture data and the pressure sensing data will be fused to provide holistic motion capture. The processed, combined data of these systems will be used to train the video based system so that robust and accurate vision-based motion-capture can be acquired using low-cost video cameras. The physiological equipment will be used in the rehabilitation projects. <br\/>Broader Impact: During this five-year project, the PIs hope to achieve major advances in motion analysis and core computer science areas: computer vision, human-computer interaction, information and data management, geometric computation, knowledge systems and robotics. These advances will have significant social impact by producing major progress in movement rehabilitation and therapy, K-12 education, security applications (gait\/face recognition), and all areas involving movement training (dance, theatre, sports, firefighting, military). Finally, IREMA can serve as a new model for research and interdisciplinary collaboration, which can be adapted to other areas thereby increasing their productivity. This RI grant will establish the necessary infrastructure for paradigm shifts in motion analysis and will facilitate the overall modeling of hybrid research.","title":"CISE RI: An Interdisciplinary Research Environment for Motion Analysis","awardID":"0403428","effectiveDate":"2004-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["286303","528940",243585,"563297",243587],"PO":["565272"]},"102693":{"abstract":"ABSTRACT:<br\/><br\/>Proposal CCR-ITR 0312809 <br\/><br\/>ITR: New Directions in Software Security<br\/><br\/>Amit Sahai<br\/><br\/>It is widely believed that the greatest threat to computer security today is not cryptographic weakness but rather flawed software design and implementation, and weakness in protecting information within software and hardware. This research proposes to develop the area of software security - protecting functional objects from vulnerabilities by means of fully automated software and hardware transformations. The approaches proposed in this research attempt to build a novel and theoretically sound foundation to this field.<br\/><br\/>First, this research considers the broad area of software transformations to counteract security vulnerabilities caused by flaws (\"bugs\") in software. In particular, this project will develop theoretical foundations and tools for preventing attacks which exploit flaws to gain control of remote systems. More generally, this research will aim to classify the security that computationally limited software transformations can provide.<br\/><br\/>Second, this research considers the question of software and hardware privacy -- how to ensure that an adversary cannot learn important secrets by examining software or hardware. In this case, this research will study transformations such that, when the attacker gains access to the transformed software or hardware, it cannot learn specific secrets embedded in the original software or hardware, such as cryptographic keys or potentially even secret algorithmic techniques. This research will propose such transformations for hardware and software under various assumptions, and seek to determine when such protection is impossible.","title":"ITR: New Directions in Software Security","awardID":"0456717","effectiveDate":"2004-09-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["521734"],"PO":["521752"]},"94910":{"abstract":"Robots on the Edge:<br\/>Enabling Non-Specific Multi-Limbed Robots with Autonomous Free-Climbing Capabilities<br\/><br\/>The goal of this program is to develop a fundamental understanding of the problem-solving activity underlying climbing, then to create new technologies based on this understanding that will enable non-specific multi-limbed robots to free-climb natural, unstructured, vertical terrain. Climbing is regarded by human climbers to be a physical problem-solving activity in a highly unstructured environment. Overall, climbing involves a tight combination of fast but insightful reasoning, goal-directed sensing, and reactive execution. Sophisticated planning is required to handle hard constraints (e.g., equilibrium, torque limits, collision) on the agent's motion, as well as softer ones (e.g., uncertainties, risk level, energy consumption). Precise sensing (e.g., tactile, vision) is used to search and detect potential holds in the unstructured rock face, estimate the location and characteristics of contact points, and anticipate or detect slip. Fine control is needed to maintain balance through careful distribution of contact forces. A solution to the climbing problem requires that these activities be fused into a seamless process. This program will seek advances in the specific areas of terrain modeling, multi-constraint trajectory planning and robust motion strategies with an initial emphasis on multi-constraint trajectory planning and control. The LEMUR II robot of JPL will be used to validate experimentally the results of the program. It will be used to demonstrate multi-step climbing in an unknown environment. The goal is to have it climb autonomously an indoor rock wall (similar to a climbing gym).","title":"Robots on the Edge: Enabling Non-Specific Mulit-Limbed Robots with Autonomous Free-Climbing Capabilities","awardID":"0412884","effectiveDate":"2004-09-01","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["370732","264577"],"PO":["335186"]},"94976":{"abstract":"NSF\/RCV- 0413242<br\/><br\/>Segmented Binary Control of Solid-State Shape-Memory-AlloyArrayActuators for Biologically Inspired Robotic Systems<br\/><br\/>H. Harry Asada, P.I.<br\/>Massachusetts Institute of Technology<br\/><br\/>A new approach to the design and control of shape memory alloy (SMA) actuators is presented. SMA wires are divided into many segments and their thermal states are controlled individually as a group of finite state machines. Instead of driving a current to the entire SMA wire and controlling the wire length based on the analogue strain-temperature characteristics, the new method controls the binary state (hot or cold) of individual segments and thereby controls the total displacement proportional to the number of the heated segments, i.e. austenite phase. Although the inherent property of SMA is highly nonlinear and uncertain with a prominent hysteresis, this Segmented Binary Control (SBC) is robust and stable, providing characteristics similar to a stepping motor. Three major aims of the projects are:<br\/>An efficient method for improving speed of response and power consumption is developed by exploiting the inherent hysteresis of SMA. Instead of keeping high temperature continually, the temperature is pulled back to an intermediate \"hold\" temperature that is substantially lower than the Austenite Finish (Af) temperature but is high enough to keep the austenite state. Coordination of the multitude of segments having independent thermal states allows for fast response with zero latency time even for thick SMA wires. <br\/>The segmented architecture of SMA wires is extended to a multi-axis actuator array by arranging them in a two-dimensional array. The multi-axis control is streamlined and coordinated using a two-dimensional segmentation method in order to activate multiple links of a robot mechanism in a coordinated manner. The method is applied to a five-fingered robotic hand capable of taking a variety of postures with a 10-axis SMA actuator array using Peltier effect thermoelectric devices for selective local heating and cooling of SMA wires.<br\/>An inter-departmental research team of undergraduate students (from mechanical, electrical, and materials engineering departments) will be formed to conduct this interdisciplinary project. One doctoral student specializing in robotic actuators will bring the new actuator technology and biologically inspired robots to a new undergraduate robotics course.","title":"Segmented Binary Control of Solid-State Shape-Memory-Alloy Array Actuators for Biologically Inspired Robotic Systems","awardID":"0413242","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["351676"],"PO":["335186"]},"94503":{"abstract":"Ian A. Gravagne, Baylor University, Real-Time Distributed Networks: Dynamics Bandwidth Allocation via Adaptive Sampling <br\/><br\/>This research applies an emerging field of mathematics<br\/>known as Dynamic Equations on Time Scales to the problem of bandwidth<br\/>utilization in real-time distributed control networks. Time scales<br\/>theory allows for the seamless analysis of dynamic processes on<br\/>continuous, discrete, or mixed time domains, including non-uniform<br\/>discrete time domains. Recent advances in time scales show that periodic<br\/>servo control processes on distributed networks can adapt their timing<br\/>characteristics in the presence of aperiodic high-priority traffic<br\/>bursts without losing control of their plants. The adaptive servo timing<br\/>method results in an increase in the effective available bandwidth for<br\/>aperiodic traffic and better integration of the overall<br\/>plant\/processor\/network system. Study of the theory of time scales is<br\/>leading to further advances toward the unification of continuous and<br\/>discrete systems as well. This unique application<br\/>of an area of mathematics previously unknown to the computer science and<br\/>engineering communities has the potential to stimulate external<br\/>research into related topics such as network scheduling and real-time<br\/>control performance.<br\/><br\/>The project will pursue empirical validation of the new theory on a 40-node<br\/>Controller Area Network of embedded processors developed at Baylor<br\/>University. Successful research in this area has immediate<br\/>utility and potential economic impact for a large industrial base<br\/>employing distributed control networks, notably in the automotive,<br\/>aerospace, and manufacturing industries. Baylor's<br\/>relatively new graduate engineering programs will continue to support<br\/>the educational needs of engineers employed by local industries in the underserved Central Texas area.","title":"EHS: Real-Time Distributed Control Networks: Dynamic Bandwidth Allocation via Adaptive Sampling","awardID":"0410685","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["560181","359365","364489"],"PO":["561889"]},"97826":{"abstract":"ITR: COLLABORATIVE RESEARCH: (EVS+NHS)-(int+dmc): 'FAST Copper': Dynamic Optimization of Resources in Frequency, Amplitude, Space, and Time for Broadband Access Networks<br\/><br\/>Mung Chiang, Princeton University<br\/>John Cioffi, Stanford University<br\/>Alexander Fraser, Fraser Research<br\/><br\/>Award 0427677<br\/><br\/>Abstract<br\/><br\/>Broadband access is the commercial and technical future of telecommunications. Higher data rates on access links enable any or all of video, data, and voice\/audio signals. It is widely recognized that the ability to deploy ubiquitous, robust, broadband access services to the majority of U.S. households is vital to economic prosperity, a vibrant civil society, and homeland security. The goal of this 'FAST Copper' project is to help build an engineering foundation to bring broadband information services to everyone with a phone line, including people who live in rural and less-privileged areas. This can be achieved by substantially enhancing the rate and reliability of the existing copper plant access network. Equity of broadband information access in the U.S. will be enhanced as a result. There are two threads of research activities towards this goal: (a) dynamic and joint optimization of resources in Frequency, Amplitude, Space, and Time (FAST) to overcome the attenuation and crosstalk bottlenecks, and (b) integration of communication, networking, computation, modeling, and distributed information management in the multi-user environment of twisted pair networks. Innovations in both physical layer algorithms and network architectures and protocols are pursued. In particular, Dynamic Spectrum Management, a science of multi-user methods for adaptively tuning an access network to specific situations dynamically, is investigated for rate improvements and implementation viability. This proposal has major activities integrating research with education. It also facilitates close collaboration with industry in analyzing highly valuable empirical data and validating research results through extensive lab tests.","title":"ITR: COLLABORATIVE RESEARCH: (EVS+NHS)-( int+dmc): 'FAST Copper': Dynamic Optimization of Resources in Frequency, Amplitude, Space, and Time for Broadband Access Networks","awardID":"0427711","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":[257455],"PO":["565090"]},"98926":{"abstract":"National Science Foundation<br\/>NETS - Research in Network Technologies and Systems <br\/>CISE\/CNS<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Proposal Number: 0435341<br\/>Principal Investigator: Liu, Qingchong<br\/>Institution: Oakland University<br\/><br\/>Proposal Number: 0435155<br\/>Principal Investigator: Chunming Qiao<br\/>Institution: SUNY at Buffalo<br\/><br\/><br\/>Proposal Title: Collaborative Research: NeTS-NR: Ultra-Broadband Optical Wireless Communication Networks<br\/><br\/><br\/>This collaborative research project undertakes a multidisciplinary approach to optical wireless communications (OWC) networks and focuses on the first\/last mile between the existing fiber-optic backbone and many homes and small of-fice buildings. The project aims at developing novel OWC networking and communications theory and techniques including those at the physical layer that overcome the scintillation (variation in light intensity) caused by the at-mospheric turbulence in OWC networks through sub-carrier modulation and coding, and those at the link and network layers that take into consideration the unique capabilities and constraints of OWC when designing optimal topol-ogy, survivable routing, and innovative dynamic reconfiguration algorithms to mitigate the negative effects of heavy or dense fog, as well as reduce the per link cost. As a result of the project effort, an OWC ring network will be built, running multimedia applications. The success of the project is expected to pro-vide an affordable ultra-broadband first\/last mile access, enable new multime-dia applications to be delivered to residential homes and small office buildings, and serve as a stepping stone to the integration of heterogeneous technologies based on radio frequency (e.g., Wireless Local Area Networks, WLAN, and cellu-lar networks) and fibers. <br\/><br\/>Dr. Admela Jukan<br\/>Program Director, CISE\/CNS<br\/>Aug 5, 2004.","title":"Collaborative Research: NeTS-NR: Ultra-Broadband Optical Wireless Communication Networks","awardID":"0435155","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["511691"],"PO":["402055"]},"98948":{"abstract":"NeTS-ProWiN: Collaborative Research - Dynamic Spectrum MAC with Multiparty Support in Adhoc Networks<br\/><br\/>Award 0435306<br\/><br\/>Saswati Sarkar, University of Pennsylvania<br\/><br\/>Abstract<br\/><br\/>Major advances in dynamic spectrum management and the inevitable deregulation of large portions of the radio spectrum will revolutionize future wireless networks, services, and applications. This will lead to an era of spectrum efficient cognitive radios that will enable the deployment of radically different radio architectures, algorithms, and protocols over the next decade. This project is studying the design of a new programmable media access control (MAC) layer for this new environment. The MAC must regulate how future programmable radio devices can efficiently interact with each other using spectrum-aware communication algorithms. In our study, we model the MAC design as decision problems using tools from decision sciences such as stochastic control, optimization, graph theory and estimation theory. We validate the design of the MAC through an experimental implementation consisting of programmable radios. The expected results from the research include the design of a programmable MAC system that can enable a class of new applications, including enhanced reliability communications and spectrum-efficient group communications. The resulting implementation of the proposed programmable MAC platform and its software will enable the development of new intelligent spectrum-aware algorithms and applications. The results of the research will provide a set of foundation algorithms that can be used by the community developing new spectrum-aware radio systems. The research facilitates several life-critical activities e.g., search and rescue missions and disaster relief operations. The research will also enrich the education curriculum of the participating institutions and foster the participation of under-represented groups in engineering.","title":"NeTS-ProWiN: Collaborative Research - Dynamic Spectrum MAC with Multiparty Support in Adhoc Networks","awardID":"0435306","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"V818","name":"DEFENSE-NETS PROGRAM"}}],"PIcoPI":["517945"],"PO":["434241"]},"96528":{"abstract":"This proposal, supporting emerging directions in mixed-signal electronic systems and in (re-)configurable computing, aims at acquiring a collection of hardware equipment to enable hardware-related research in several areas including analog and mixed signal design, CAD for reconfigurable computing projects, and several reconfigurable computing system projects. This research and training facility centers on electronic simulation, rapid prototyping, and testing. Projects specifically address, among others, distributed simulation, MEMS built-in self-test, FPGA CAD environments, reconfigurable computing analysis and adaptation, power-aware FPGA design mapping. The major pieces of the infrastructure include a printed circuit board station, electronic test instruments, reconfigurable computing boards, and optical test equipment. The facility enables realistic hardware experimentation, analysis, and demonstration of the research ideas previously verified largely by simulations in mixed-signal electronic systems and in configurable computing.<br\/><br\/>Broader Impact: Impacts future research directions, graduate students and collaborators; impacts courses, and further extends educational opportunities to minority students. 20 universities will share the equipment. The project also encourages more industrial collaboration.","title":"MRI: Acquisition of Research Instrumentation for Electronic Systems Emulation, Prototyping and Testing","awardID":"0421092","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["258304"],"PO":["557609"]},"98959":{"abstract":"NeTS-ProWiN: High Performance Cognitive Radio Platform with Integrated Physical and Network Layer Capabilities<br\/>Award 0435370<br\/>Bryan Ackland, Rutgers<br\/><br\/>Rutgers University, Georgia Institute of Technology and Lucent Bell Laboratories<br\/><br\/>The objective of this project is to build a high-performance experimental cognitive radio platform based on a novel network-centric architecture for software defined radios. Cognitive radio bands under consideration by the US FCC represent a new approach for co-existence between wireless devices based on intelligent adaptation to the observed radio frequency (RF) environment. Dynamic adaptation capabilities of cognitive radios range from frequency agility to more complex collaborative approaches in which radio nodes self-organize into an ad-hoc multi-hop network. In this project, we are developing an FPGA-based experimental platform which incorporates a number of cognitive radio capabilities including frequency agility, software-defined modulation, programmable etiquette and MAC protocols, and ad-hoc network routing. The hardware architecture contains a mix of software programmable and reconfigurable components, and incorporates a flexible packet processing engine for high-speed (~50 Mbps+) link and network layer functions.<br\/>This project is a team effort involving the Wireless Information Networks Laboratory (WINLAB) at Rutgers University (cognitive radio systems, SDR, and low-power VLSI), Georgia Institute of Technology (agile RF front end) and Lucent Bell Laboratories (flexible radio platforms). The research program has the following thrusts: (1) system-level investigation of cognitive radio spectrum sharing scenarios, (2) design of agile RF transceivers for efficient reconfiguration of frequency, bandwidth and power, (3) architecture, design and validation of baseband and protocol processing modules for a cognitive radio with integrated PHY and networking capabilities, and (4) development of experimental cognitive radio platforms for use in system prototyping and field evaluation of cognitive radio usage scenarios.","title":"NeTs-ProWin: High Performance Cognitive Radio Platform with Integrated Physical and Network Layer Capabilities","awardID":"0435370","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"V818","name":"DEFENSE-NETS PROGRAM"}}],"PIcoPI":[260886,260887,"564746","466323",260890],"PO":["434241"]},"92931":{"abstract":"Researchers at the University of Maryland plan to build a high-performance computing and visualization cluster taking advantage of synergies afforded by coupling central processing units (CPUs), graphics processing units (GPUs), displays, and storage. The infrastructure will be used to support a broad program of computing research that will revolve around understanding, augmenting, and leveraging the power of heterogeneous vector computing enabled by GPU co-processors. The driving force here is the availability of cheap, powerful, and programmable graphics processing units (GPUs) through their commercialization in interactive 3D graphics applications, including interactive games. The CPU-GPU coupled cluster will enable the pursuit of several new research directions in computing, as well as enable a better understanding and fast solutions to several existing interdisciplinary problems through a visualization-assisted computational steering environment. In addition, it will foster research to cast several problems into a better spot on the price-performance curve.<br\/><br\/>Intellectual Impact: The proposed research that will use this cluster falls into several broad interdisciplinary computing areas. The researchers plan to explore visualization of large datasets and algorithms for parallel rendering. In high-performance scientific computing we plan to develop and analyze efficient algorithms for use with complex systems when uncertainty is included in models. The researchers plan to use the cluster for several applications in computational biology, including computational modeling and visualization of proteins, conformational steering in protein structure prediction, folding, and drug design, large-scale phylogeny visualization, and sequence alignment.<br\/><br\/>The researchers also plan to use the cluster for applications in real-time computer vision, real-time 3D virtual audio, and for efficient compilation of signal processing algorithms.<br\/><br\/>Broader Impact: An important aspect of this research is to ensure a high impact of the cluster towards educational and outreach goals. The investigators plan to enrich their current coursework with research results obtained on the cluster. The coupled cluster with a large-area high-resolution display screen will serve as a valuable resource to present, interactively explore, evaluate, and validate the ongoing research in visualization, vision, scientific computing, human-computer interfaces, and computational biology with active participation of graduate as well as undergraduate students.","title":"High Performance and Visualization Cluster for Research in Coupled Computational Steering and Visualization for Large Scale Applications","awardID":"0403313","effectiveDate":"2004-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["501013","450658","564722","532931","543581"],"PO":["565272"]},"92942":{"abstract":"Broader Impact: Timely and effective response to natural or man-made disasters can reduce deaths and injuries, contain or prevent secondary disasters, and reduce the resulting economic losses and social disruption. During a crisis, responding organizations confront grave uncertainties in making critical decisions. There is a strong correlation between the quality of these decisions and the accuracy, timeliness, and reliability of the situational information (e.g., state of the civil, transportation and information infrastructures) and the availability of resources (e.g., medical facilities, rescue and law enforcement units) to the decision-makers. Recently, at UCI and UCSD many projects have been launched that address the technological challenges in with the objective of radically transforming the ability of organizations to gather, manage, use and disseminate information when responding to man-made and natural catastrophes. Dramatic improvements in the speed and accuracy at which information about the crisis flows through the disaster response networks has the potential to revolutionize crisis response saving human lives and property. . The purpose of this infrastructure proposal is to establish an campus-level experimental Information Technology infrastructure, called Responsphere, to serve as a platform for development, testing, and validation of our current research efforts on responding to a crisis. <br\/>Intellectual Merit: Challenges in bringing accurate, timely, and relevant information to decision-makers during crisis response arises due to the scale and complexity of the problem, the diversity of data and data sources, the state of the communication and information infrastructures through which the information flows, and the unique character and dynamic nature of the responding organizations. To address these challenges, our research team is exploring a multidisciplinary approach focusing on the following research elements in the context of crisis response: (1) Enabling humans (rescue workers, observers) to become rich sources of vital crisis-related information; (2) Seamlessly collecting data from heterogeneous sources in highly dynamic disaster situations where the IT infrastructure may have partially failed; (3) Translating low-level noisy data into meaningful events useful for damage assessment and situation awareness; (4) Enabling information sharing and collective decision-making across highly dynamic emergent virtual organizations; (5) Rapidly disseminating information in the form most useful to recipients while observing the fundamental limitations of the underlying communication and information technologies. Validation platforms and testbeds will be deployed in close partnership with first responders from the City and County of LA, San Diego and Irvine Police departments as well as the California Office of Emergency Services in live environments and will help us evaluate the effectiveness of the research.<br\/><br\/>The testbeds created as a part of Responsphere will provide the team with an experimental platform to field-test and refine research on information collection, analysis, sharing, and dissemination in controlled yet realistic settings significantly enhancing their research capability. Specific testbeds include:<br\/> Mobile Incidence Level Response (MILLR) Testbed <br\/> Crisis Assessment, Mitigation, and Analysis (CAMAS) Testbed<br\/> Advanced Traffic Rerouting for Unplanned Events (TRUE) Testbed<br\/>At UC Irvine we will (1) expand the campus 802.11b based wireless infrastructure to cover major outdoor regions, (2) add instrumentation and management tools to the campus wireless environment, (3) add compute, visualization and storage capabilities for crisis management and response research, and (4) expand the available pool of mobile devices and embellish them with specialized video capture and streaming capabilities suitable for field response experiments. At UC San Diego we will (1) establish RF propagation modeling capabilities using GIS and 3D data generation and transformation tools, (2) build a wireless communications infrastructure in the Gas Lamp Quarter downtown, (3) build a command and control prototyping environment in a visualization facility, (4) create a vehicular based mobile command and control platform, (5) design a location\/tracking system and prototype it along with other sensing and communications equipment in a custom man worn implementation (\"manpack\"), and (6) participate in the upgrade of the UCSD Police communication environment.. Specific research components tested in Responsphere are (1) a system for accurate position location in uncertain environments; (2) an integrated end-to-end quality aware distributed data collection system; (3) an end-to-end data analysis system; and (4) system for seamless multimodal interaction involving audio\/video and image information. Other research efforts at UCI and UCSD in the areas of mobile computing, networking, middlewar","title":"An IT Infrastructure for Responding to the Unexpected","awardID":"0403433","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["328469","472358","515756","499298"],"PO":["565272"]},"95813":{"abstract":"0417413<br\/>GA Tech Research Corp - GA Institute of Technology<br\/>Manolios<br\/><br\/>\"CRCD\/EI: Integrating Functional Computer-Aided Reasoning into the Computer Science Curriculum\"<br\/><br\/>This project involves the development of tools, courses, modules, and self-paced online materials that integrate computer-aided reasoning into the Computer Science (CS) curriculum. This project is novel in undergraduate CS education. The use of a state-of-the-art theorem proving technology (ACL2) permits students to get instant, reliable feedback, thereby enabling effective learning and self-paced study. ACL2 is a tool consisting of a functional programming language, a logic, and a theorem-prover, that has been used to prove some of the largest and most complicated theorems ever proved about commercially designed systems. The project involves at least two research challenges: taking a necessarily complex, state-of-the-art, theorem proving system and teaching undergraduates how to be effective users in a portion of a semester, and developing effective courses in other areas, such as hardware design and object oriented programming, that are based on the use of computer-aided reasoning. A sequence of mathematical concepts and mechanical tools, with well-designed graphical user-interfaces, allow students to gradually and seamlessly master ACL2. Integration of computer-aided reasoning into current curricula is accomplished through two courses that make essential use of these tools, thereby giving students a deeper and more complete understanding of the material. The courses cover the following topics: computer organization and design, object-oriented programming using the JVM, theorem proving, and formal methods. One of the undergraduate courses focuses on computer organization and design and the other on the Java Virtual Machine (JVM). In these two courses, computer-aided reasoning is used to give students a deeper understanding of the material. They are required to think about the properties systems and components under consideration should enjoy and how to prove that these properties do in fact hold.","title":"CRCD\/EI: Integrating Functional Computer-Aided Reasoning into the ComputerScience Curriculum","awardID":"0417413","effectiveDate":"2004-09-01","expirationDate":"2008-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["428590","362708","550467"],"PO":["315063"]},"92217":{"abstract":"This collaborative research grant awarded to a multidisciplinary team aims to develop algorithmic tools and a corresponding cyberinfrastructure for the development, coordination, utilization, and dissemination of knowledge regarding the application of optimization-based inverse methods for radiation treatment planning. The PIs bring to this research cross-disciplinary proficiency in Industrial Engineering, Computer Sciences, and Radiation Oncology, building on their recent research in the areas of information technology, optimization, and treatment planning. The algorithm development is based on their newly developed methodologies including slicing approaches and the Nested Partitions framework. Along with the development of algorithms for Radiation Treatment Planning, the PIs also plan to develop a website that will provide an infrastructure to researchers worldwide for the development, coordination, utilization, and dissemination of optimization methods in Radiation Treatment Planning research. <br\/><br\/>Approximately one million new cases of cancer are reported each year in the United States, with many times that number occurring worldwide. It is reported that more than 40 percent of people diagnosed with cancer in the US will undergo treatment with radiation therapy. Given the aging population, these numbers are expected to increase rapidly in coming years. It is expected that research results developed in this project will accelerate the development and understanding of efficient and effective automated Radiation Treatment Planning methods and software, resulting in clinical treatments of significantly higher quality, thereby enhancing both the quality of life and the longevity of cancer patients treated with radiation.","title":"Collaborative Research: Interdisciplinary Center for Radiation Treatment Planning","awardID":"0400294","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7368","name":"SCI TESTBEDS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1787","name":"SERVICE ENTERPRISE SYSTEMS"}}],"PIcoPI":["520911","560408"],"PO":["418612"]},"93548":{"abstract":"This work proposes new run-time, operating system, and performance modeling techniques that enable Quality of Service (QoS) through providing performance guarantee and contention minimization for user jobs in future utility computing servers. Utility Computing is an IT business model where users outsource computing to a vendor that manages computing resources and charges its customers based on the actual computing that they use. Utility computing servers will likely simultaneously run many user jobs with varying performance guarantee requirements.<br\/><br\/>Intellectual Merit:<br\/><br\/>The need to provide performance guarantee in high performance servers. The proposed work seeks to address. The proposed work will make revolutionary advances to the current state of the art technology in batch job submission system, OS job scheduling, and performance modeling. More specifically, the proposed approach consists of three new components: (1) Job Admission Strategy that accepts or rejects jobs based on the servers' ability to meet the requested QoS, (2) Job Scheduling Strategy that boosts the system throughput by minimizing the contention among multiple jobs, and (3) Contention Prediction Model that predicts the degree of contention and its impact on job execution times for a given job schedule.<br\/><br\/>Broader Impact:<br\/><br\/>The proposed work takes QoS issues from their traditional area in computer networks to a new area in servers, run-time systems and operating systems.","title":"NGS: Providing and Maximizing Quality of Service in Utility Computing Servers","awardID":"0406306","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485790"],"PO":["551712"]},"98916":{"abstract":"Proposal Number: 0435087<br\/>PI: Larry Peterson<br\/>Institution: Princeton University <br\/>Title: Bootstrapping Broad-Coverage Network Services <br\/><br\/>Abstract: <br\/><br\/>This proposal explores the design and utility of two broad-coverage network services: (1) a topology discovery service that overlay nodes use to locate itself with respect to its peers and the endpoints it serves; and (2) an information service that collects, stores, propagates, aggregates, analyzes, and reacts to the network's changing conditions. The research challenge is to design these services to both provide Internet-scale coverage, and meet the needs of a rich collection of wide-area overlay networks and applications. We will deploy and demonstrate both services on PlanetLab. The impact of this work is to provide \"foundational\" services that can be leveraged to improve the robustness, security, performance, and manageability of the Internet.","title":"Collaborative Research: NeTS-NR:Bootstrapping Broad-Coverage Network Services","awardID":"0435087","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["533299","560046"],"PO":["292741"]},"97838":{"abstract":"PROPOSAL NO: 0427821<br\/>INSTITUTION: University of California-Santa Barbara<br\/>PRINCIPAL INVESTIGATOR: Marek-Sadowska, Malgorzata<br\/>TITLE: Interconnect Planning in Placement and Logic Synthesis<br\/><br\/><br\/><br\/>Abstract:<br\/>Due to the tremendous progress in technology, VLSI chips become very large and complex, and this trend is expected to continue. The increased chip complexity causes that average interconnect lengths increase and proportionally larger and larger fraction of chip's area is occupied by interconnects. This tendency is not only caused by the increased design complexities, but also by the fact that the existing CAD tools do not scale well. This proposal addresses several issues related to interconnects in submicron technologies at design abstractions higher than routing. In design flow, placement is a step which to a large extent, determines the interconnect characteristics. The intension is to integrate into placement several objectives, which are conventionally solved by point tools on placed (and often on routed) designs. The goal is to develop an efficient, multi-objective incremental placer capable of offering well-understood tradeoffs. Besides incremental corrections at the placement level, methodologies of circuit optimization integrated into placement flow will be studied and developed. Timing-driven placement flow will integrate retiming, sequential budgeting, skew optimization, and simultaneous global routing. It is expected that the work at the placement level will result in efficient optimization techniques and will help in formulating requirements for the higher level tools<br\/>to create easier routable designs.","title":"Interconnect Planning in Placement and Logic Synthesis","awardID":"0427821","effectiveDate":"2004-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["550832"],"PO":["562984"]},"98938":{"abstract":"Existing video streaming networks (VSN) rely on a few dedicated servers to store and distribute videos. Such architecture is very costly, both in terms of server cost and Internet-connection cost. Failures of a single server can also cause the collapse of the entire system. This research project investigates a peer-to-peer based VSN that has the promise to provide low-cost and yet high quality video on-demand service. The system encodes each video into multiple equally important sub-streams (called descriptions) and places each sub-stream on a different peer. When a client wants to see a video, multiple peers act as servers, each sending a different sub-stream of the video to the client. When a serving peer disconnects in the middle of a streaming session, the system looks for a replacement peer that stores the same video sub-stream and has sufficient surplus uplink bandwidth. The video coder is designed such that there is only a modest degradation in video quality in the period before a replacement peer is located. The system design has five interacting components: 1) multiple description video coding; 2) sub-stream placement; 3) admission control; 4) sub-stream server selection; and 5) sub-stream delivery. Both analytical studies and experimentations are conducted to examine the system performance and its gain over infrastructure-based systems. Successful development of the system will enable people to, at very low cost, search and view on-demand enormous libraries of digital video content for the purpose of education, healthcare, entertainment, etc., thus benefiting the society as a whole.","title":"On-Demand P2P Video Streaming: Integration of Video Coding and Network Application Design","awardID":"0435228","effectiveDate":"2004-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550020","525973","491898"],"PO":["402055"]},"96518":{"abstract":"This project involving East Carolina and NCA&T universities, acquiring SGI Origin 3900 systems, supports research of a newly developed Consortium for Computational Chemistry and Materials Science. Combined with training in computational science and engineering, the infrastructure supports 3 core and various ancillary research projects.<br\/><br\/>Core Projects include: Studies on Wurster's Crown-based Devices, Studies of the Effects of Ionizing Radiation on Materials and Biological Systems, and Advances Polymer Composite Fabrication Process Modeling and Simulations. The ancillary projects include: Modeling C60 Reorientation in Various Solvents, Modeling Material Deformation at Nano Length Scales, Computational Modeling and Simulation of Bio-Inspired Adaptive and Reconfigurable Systems, and New Research tools for Collaborative Grid Computing and Visualization. The first core project studies a new, versatile electrochemically-active class of macrocyclic receptors with broad applications (e.g., from sensing to catalysis to molecular magnetism). This research uses ab initio calculations of structures to guide chemical synthesis whose results are then used to refine future calculations. The second interprets chemical effects of exposure to different types of ionizing radiation, concentrating on understanding the changes in the spectral structure observed in bi-layers of frozen glass, biomolecules, and tissue. The third studies chemical and transport phenomena during the fabrication of advanced polymer-based composite materials. New physical models including multi-scale effects in the transport phenomena, coupled with macro-micro flow behavior, rheological transport and dispersion system with embedded nano-particles, and their multi-length scale interactions are of particular interest.<br\/><br\/>Broader Impact: The activity focuses on training and support for faculty, students, and postdocs to apply and develop computational techniques. The training includes advanced course work and participation in research projects. The work fosters research training for underrepresented groups at NCA&T (an HBCU) and ECU (a predominantly women's institution).","title":"MRI: Acquisition of High Performance Computing Resources In Support of the Consortium for Computational Chemistry and Materials Sciences","awardID":"0421063","effectiveDate":"2004-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[253371,"415230",253373,"315477","521896"],"PO":["557609"]},"101430":{"abstract":"The calling of owls is commonly performed in population studies but nowhere in the literature is this calling performed through the use of cellular telephone. This project explores signal processing and audio input\/output technologies coupled with cellular telephones for remote broadcasting, recording and analysis of Owl vocalizations. The broadcast and record methods are evaluated by the frequency of Owl responses and the machine recognition rate on labeled transcriptions of telephone recordings.<br\/><br\/>This project seeks to demonstrate that signal processing technologies using cellular telephone transport are a flexible and viable alternative to conventional call and response methods. Insights gained in this project will greatly facilitate surveys not only on Great <br\/>Horned Owls, but on other species which can be studied by similar methods, such as the Spotted Owls and the Marbled Murrelet, both of which are federally listed endangered species. Results will be disseminated in signal processing, sensor applications and biological science publication venues.","title":"SGER: Cellular Telephone Broadcast and Recording Sensor System for Wildlife Monitoring","awardID":"0450675","effectiveDate":"2004-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["427498"],"PO":["565136"]},"92932":{"abstract":"Scientific Merit The principal investigators (PIs) will create a computing system that tightly couples extremely large-scale online disk storage with high-performance computing. This infrastructure will be shared among several research projects, each of which has a temporary need for large amounts of online storage when processing raw data, but has reduced storage requirements when operating on processed data. Computer Graphics: The PIs will perform precise measurement of the light scattering properties of objects. This will be the most accurate study of this kind ever undertaken, and will lead to a new generation of multidimensional, multi-object graphical rendering techniques. The World Wide Web: The PIs will perform studies measuring and quantifying the evolution of the World Wide Web. Until now, the sheer scale of the Web constrained reported studies of the Web to be performed exactly once. The new large-scale storage facility will enable the PIs to analyze multiple independent snapshots of the Web, to develop precise models for how the Web evolves over time. Astronomy: The PIs will store and analyze data from the newly upgraded Arecibo radio telescope, leading to discovery of new pulsars, including pulsars with millisecond spin periods and those in binary orbits with other neutron stars or black holes. The pulsar data will provide opportunities for research on the equation of state of nuclear matter, gravitation physics, gravitational waves, stellar evolution, relativistic plasma physics, and the magnetized, ionized gas in the Milky Way. The storage system will be hosted at the Cornell Theory Center. Analyzed data products from all projects will be made available over the Internet. Raw data will be shared with researchers throughout the U.S., either through visits to the Cornell Theory Center or by shipping data sets on disk drives.<br\/><br\/>Broader Impact. The PIs have concrete plans for coupling the research with educational activities at all levels, as well as for general public outreach. The CURIE Academy: The PIs will develop novel projects for the Cornell CURIE Academy, a one-week summer engineering immersion experience for high school girls. The first CURIE project will use data obtained with the facility to illustrate fundamental principles of optics and computer graphics.<br\/><br\/>Undergraduate Education: The work will impact undergraduate education in three different ways: (1) Several undergraduate courses are being adapted to make use of Web and astronomical data that will be available through the facility; (2) Cornell undergraduates will be invited to participate in supervised research related to the facility; and (3) The PIs will increase their interaction with Smith College, an undergraduate women's college in Massachusetts.<br\/><br\/>Graduate Education: The facility will naturally provide opportunities for Ph.D. level research. In addition, several graduate courses are planning to address both the research being done on the facility and the general area of data-intensive computing. Public Outreach: The PIs research will be displayed in SciCentr, a virtual science museum run by the Cornell Theory Center accessible on the Web at www.SciCentr.org. SciCentr received museum accreditation through the Association of Science and Technology Centers (ASTC) in May 2004. The PIs will develop a SciCentr exhibition for each research project associated with the new facility.","title":"Petabyte Storage Services For Data-Driven Science","awardID":"0403340","effectiveDate":"2004-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["345714","482473","420975","450550","448639"],"PO":["565272"]},"101463":{"abstract":"Anderson - RTSS Workshop abstract<br\/><br\/>The International Real-Time Systems Symposium (RTSS) is an annual symposium partially sponsored by the IEEE Computer Society. This year's symposium will take<br\/>place in Lisbon, Portugal, December 5-8, 2004.<br\/>This award provides support for student travel grants, and to partially fund the creating of an \"anniversary DVD,\" which will contain the first 25 RTSS proceedings, as well as the .rst 10 RTAS proceedings. RTAS - the Real-time and Embedded Technology and Application Symposium - is a sister conference of RTSS that is also devoted to issues involving real-time and embedded systems. Since both conferences are marking milestone anniversaries this year, this is an appropriate time to look back at what has been accomplished in the area of real-time and<br\/>embedded systems over the last 25 years.<br\/><br\/>The travel grants enable approximately 20 young researchers in the ?eld of embedded and real-time systems to attend RTSS 2004. The DVD will help in disseminating the results of this year's symposium and will be a valuable research tool, as it will allow content searches to be conducted over all 35 stored proceedings. The DVD will also give young researchers direct access to many of the landmark papers in the area of real-time and embedded computing.","title":"Support for International Real-Time Systems Symposium (RTSS); December 5-8, 2004; Lisbon, Portugal","awardID":"0450877","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["31436"],"PO":["561889"]},"102200":{"abstract":"The purpose of this grant is to provide support for student travel to the 2nd ACM SenSys conference, being held in Baltimore, Maryland on November 3-5, 2004. The ACM SenSys conference is a new emerging conference covering all aspects of wireless sensor networking, with participants from the USA, Europe, and Asia. This grant offers support for not only student paper authors, but also for student attendees from a state university serving under-represented populations. This conference travel support insures that deserving students will be able to participate in the conference, thereby nurturing the next generation of researchers.","title":"2004 ACM SenSys (Sensor Systems) Conference Student Travel Support; November 3-5, 2004; Baltimore, MD","awardID":"0454480","effectiveDate":"2004-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["483835"],"PO":["565090"]},"102442":{"abstract":"Markov chain Monte Carlo (MCMC) methods are an important<br\/>algorithmic device in a variety of fields. This project studies<br\/>techniques for rigorous analysis of the convergence properties of<br\/>Markov chains. The emphasis is on refining probabilistic,<br\/>analytic and combinatorial tools (such as coupling, log-Sobolev,<br\/>and canonical paths) to improve existing algorithms and develop<br\/>efficient algorithms for important open problems.<br\/><br\/>Problems arising in computer science, discrete mathematics,<br\/>and physics are of particular interest, e.g., generating random<br\/>colorings and independent sets of bounded-degree graphs,<br\/>approximating the permanent, estimating the volume of a<br\/>convex body, and sampling contingency tables. The project<br\/>also studies inherent connections between phase<br\/>transitions in statistical physics models and convergence<br\/>properties of associated Markov chains.<br\/><br\/>The investigator is developing a new graduate course on MCMC methods.","title":"CAREER: Markov Chain Monte Carlo Methods","awardID":"0455666","effectiveDate":"2004-09-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["517800"],"PO":["499399"]},"101254":{"abstract":"For the 17th consecutive year we are organizing the InternationalWorkshop on Languages and Compilers for Parallel Computing. This workshop covers all aspects of languages, compiler techniques, run-time environments, and architectures for parallel and high-performance computing. Since 1988, the annual LCPC workshops have provided a forum for leading researchers and practitioners to present their latest work and to exchange ideas about future directions. The papers published in the proceedings of the workshop have been widely cited over the years and many of them have represented the _rst public presentation<br\/>of innovative ideas. The participation is truly international with speakers from the US, Japan<br\/>and Europe.<br\/>While the workshop covers many topics, the emphasis has always been software, e.g., compilers, languages, run-time systems, performance evaluation for parallel systems.<br\/>One of the most important aspects of this workshop is its informal setting which allows a frank exchange of new, previously unpublished ideas. Moreover, LCPC has also been an occasion for graduate students to meet more senior researchers in this informal setting.","title":"17th Workshop on Languages and Compilers for Parallel Processing; September 22-25, 2004; West Lafayette, IN","awardID":"0450061","effectiveDate":"2004-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["408878","558595","550995"],"PO":["551712"]},"92987":{"abstract":"Abstract<br\/><br\/>This proposal was received in response to Nanoscale Science and Engineering initiative, NSF 03-043, category NIRT. This program will utilize nanolithographically-patterned arrays to direct the assembly of nanoscale magnetic building blocks into specific architectures. These ordered assemblies will be designed for applications in high frequency, magnetotransport, and mechanical devices. Micromagnetics modeling of individual and collective properties, along with feedback from property measurements, will allow for an active refinement of architectural designs. <br\/><br\/>As scientists develop materials with smaller and smaller sizes, there is a need to be able to integrate these tiny elements into devices of technological significance. In this program, very small components (much smaller than a human hair) will be assembled into ordered arrays by placing them onto surfaces that have specific grooved patterns. The grooves will serve to capture the components (e.g. small metal wires) in specific orientations. These arrangements will then be of interest for potential applications in communication or magnetic devices such as those important to cellular phones and computer hard drives, respectively. Additionally, an outreach component will involve both high school teachers and undergraduates from underrepresented groups in a nanoscience summer research program.","title":"NIRT: Fabrication of Functional Architectures through the Directed Assembly of Nanoscale Building Blocks","awardID":"0403673","effectiveDate":"2004-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}}],"PIcoPI":["527336","534870","538884","491824",243729],"PO":["565157"]},"90446":{"abstract":"The Internet has grown rapidly along several dimensions over the past decade. Yet, the core transport mechanisms used in its operation have not changed much. It is difficult to believe that the assumptions on which network designs were based a decade ago are valid even today. Unfortunately, due to the in-feasibility of collecting sufficient statistics in the past, answers to several fundamental questions related to the transport protocols performance in today's Internet are unknown: \"Is there any congestion in today's Internet? Are transport mechanisms of the past working well for current applications? If not, how can they be redesigned?\" This project addresses these questions through:<br\/><br\/> (1) extensive measurements and analysis to develop a fundamental understanding of transport performance of networks and validate legacy assumptions;<br\/><br\/> (2) investigation of the impact of invalid assumptions on the design, analysis, and evaluation of existing transport mechanisms; and<br\/><br\/> (3) design of new mechanisms and analysis techniques based on the findings.<br\/><br\/>Once completed, this project will help scientifically re-assess the principle and assumptions used in the design of Internet transport protocols in the past and will also benefit several communities. First, experience in measurements and analysis is invaluable to federal, commercial, and academic institutions that are involved in mining for information in large data-sets. Second, the use of measurement tools in Computer Science education will help train graduate and undergraduate students with important skill set and help develop new pedagogical techniques. Third, the design of transport protocols that scale with technological advancement will impact the use of the Internet for scientific research and distributed analysis.","title":"CAREER: Reassessing the Foundations of Internet Transport","awardID":"0347814","effectiveDate":"2004-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["491563"],"PO":["565090"]},"94604":{"abstract":"Advances in radios, sensors, actuators and embedded computing technology have enabled a proliferation of wireless sensing networks. These networks offer an affordable way of performing distributed sensing for a seemingly unbounded set of applications. Accurate positioning is a key enabler for many sensor applications including surveillance networks, robotic sensors, location-based routing in wireless ad-hoc sensor networks, smart spaces and environmental monitoring by mobile sensors. Although GPS can potentially provide accurate positioning, the complexity of the required receivers may be too costly for inexpensive sensor nodes. Furthermore, the GPS signal is extremely weak and positioning can be unreliable inside buildings or under dense foliage. These drawbacks to GPS positioning have led to increasing interest in GPS-less distributed radiolocation methods for wireless sensor systems. This project focuses on techniques GPS-less cooperative radiolocation using time-of-arrival over ISM-band radios (e.g. 802.11b)<br\/><br\/>There are numerous problems that must be solved for adaptive radiolocation in sensor networks. Multiaccess interference occurs if multiple sensors transmit acknowledgements at the same time. The presence of multipath can obscure and interfere with correct estimation of the time-of-arrival causing range errors. The RF power amplifier is a major energy consumer; therefore positioning estimates must be made with minimal communication. The project addresses these problems through: 1) Analysis and development of multiuser estimation algorithms that can jointly estimate times of arrival (TOAs) from multiple sensors. 2) Creation of a reconfigurable computational core, which enables an adaptive radiolocation platform for embedded systems. The core will be designed to enable tradeoffs between different system parameters, including power\/energy, latency and accuracy of the positioning algorithms. 3) Development of new distributed estimation algorithms for sensor networks. 4) Implementation of cooperative radiolocation algorithms in a testbed operating in the 2.4 GHz ISM band. 5) Design of antenna arrays and sensing algorithms for the radiolocation network","title":"Adaptive Radiolocation for Mobile Sensor Networks","awardID":"0411321","effectiveDate":"2004-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["355334","355335","560817"],"PO":["561889"]}}